[
    {
        "idx": 198736,
        "project": "linux",
        "commit_id": "d563131ef23cbc756026f839a82598c8445bc45f",
        "project_url": "https://github.com/torvalds/linux",
        "commit_url": "https://github.com/torvalds/linux/commit/d563131ef23cbc756026f839a82598c8445bc45f",
        "commit_message": "rsi: release skb if rsi_prepare_beacon fails\n\nIn rsi_send_beacon, if rsi_prepare_beacon fails the allocated skb should\nbe released.\n\nSigned-off-by: Navid Emamdoost <navid.emamdoost@gmail.com>\nSigned-off-by: Kalle Valo <kvalo@codeaurora.org>",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static int rsi_send_beacon(struct rsi_common *common)\n{\n\tstruct sk_buff *skb = NULL;\n\tu8 dword_align_bytes = 0;\n\n\tskb = dev_alloc_skb(MAX_MGMT_PKT_SIZE);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tmemset(skb->data, 0, MAX_MGMT_PKT_SIZE);\n\n\tdword_align_bytes = ((unsigned long)skb->data & 0x3f);\n\tif (dword_align_bytes)\n\t\tskb_pull(skb, (64 - dword_align_bytes));\n\tif (rsi_prepare_beacon(common, skb)) {\n\t\trsi_dbg(ERR_ZONE, \"Failed to prepare beacon\\n\");\n\t\treturn -EINVAL;\n\t}\n\tskb_queue_tail(&common->tx_queue[MGMT_BEACON_Q], skb);\n\trsi_set_event(&common->tx_thread.event);\n\trsi_dbg(DATA_TX_ZONE, \"%s: Added to beacon queue\\n\", __func__);\n\n\treturn 0;\n}",
        "func_hash": 130931178778692254191224779038755080046,
        "file_name": "rsi_91x_mgmt.c",
        "file_hash": 125660046646447806158908760119804627111,
        "cwe": [
            "CWE-401"
        ],
        "cve": "CVE-2019-19071",
        "cve_desc": "A memory leak in the rsi_send_beacon() function in drivers/net/wireless/rsi/rsi_91x_mgmt.c in the Linux kernel through 5.3.11 allows attackers to cause a denial of service (memory consumption) by triggering rsi_prepare_beacon() failures, aka CID-d563131ef23c.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2019-19071",
        "func_name": "rsi_send_beacon",
        "diff": [
            "diff --git a/drivers/net/wireless/rsi/rsi_91x_mgmt.c b/drivers/net/wireless/rsi/rsi_91x_mgmt.c\nindex 6c7f26ef6476ae..9cc8a335d519da 100644\n--- a/drivers/net/wireless/rsi/rsi_91x_mgmt.c\n+++ b/drivers/net/wireless/rsi/rsi_91x_mgmt.c\n@@ -1756,6 +1756,7 @@ static int rsi_send_beacon(struct rsi_common *common)\n \t\tskb_pull(skb, (64 - dword_align_bytes));\n \tif (rsi_prepare_beacon(common, skb)) {\n \t\trsi_dbg(ERR_ZONE, \"Failed to prepare beacon\\n\");\n+\t\tdev_kfree_skb(skb);\n \t\treturn -EINVAL;\n \t}\n \tskb_queue_tail(&common->tx_queue[MGMT_BEACON_Q], skb);\n"
        ],
        "func_after": []
    },
    {
        "idx": 198743,
        "project": "LuaJIT",
        "commit_id": "53f82e6e2e858a0a62fd1a2ff47e9866693382e6",
        "project_url": "https://github.com/LuaJIT/LuaJIT",
        "commit_url": "https://github.com/LuaJIT/LuaJIT/commit/53f82e6e2e858a0a62fd1a2ff47e9866693382e6",
        "commit_message": "Fix frame traversal for __gc handler frames.\n\nReported by Changochen.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static ptrdiff_t finderrfunc(lua_State *L)\n{\n  cTValue *frame = L->base-1, *bot = tvref(L->stack);\n  void *cf = L->cframe;\n  while (frame > bot && cf) {\n    while (cframe_nres(cframe_raw(cf)) < 0) {  /* cframe without frame? */\n      if (frame >= restorestack(L, -cframe_nres(cf)))\n\tbreak;\n      if (cframe_errfunc(cf) >= 0)  /* Error handler not inherited (-1)? */\n\treturn cframe_errfunc(cf);\n      cf = cframe_prev(cf);  /* Else unwind cframe and continue searching. */\n      if (cf == NULL)\n\treturn 0;\n    }\n    switch (frame_typep(frame)) {\n    case FRAME_LUA:\n    case FRAME_LUAP:\n      frame = frame_prevl(frame);\n      break;\n    case FRAME_C:\n      cf = cframe_prev(cf);\n      /* fallthrough */\n    case FRAME_VARG:\n      frame = frame_prevd(frame);\n      break;\n    case FRAME_CONT:\n#if LJ_HASFFI\n      if ((frame-1)->u32.lo == LJ_CONT_FFI_CALLBACK)\n\tcf = cframe_prev(cf);\n#endif\n      frame = frame_prevd(frame);\n      break;\n    case FRAME_CP:\n      if (cframe_canyield(cf)) return 0;\n      if (cframe_errfunc(cf) >= 0)\n\treturn cframe_errfunc(cf);\n      frame = frame_prevd(frame);\n      break;\n    case FRAME_PCALL:\n    case FRAME_PCALLH:\n      if (frame_ftsz(frame) >= (ptrdiff_t)(2*sizeof(TValue)))  /* xpcall? */\n\treturn savestack(L, frame-1);  /* Point to xpcall's errorfunc. */\n      return 0;\n    default:\n      lua_assert(0);\n      return 0;\n    }\n  }\n  return 0;\n}",
        "func_hash": 309200300493568288549157158368440611870,
        "file_name": "lj_err.c",
        "file_hash": 339549767514658029818043680727253046808,
        "cwe": [
            "CWE-125"
        ],
        "cve": "CVE-2020-15890",
        "cve_desc": "LuaJit through 2.1.0-beta3 has an out-of-bounds read because __gc handler frame traversal is mishandled.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2020-15890",
        "func_name": "finderrfunc",
        "diff": [
            "diff --git a/src/lj_err.c b/src/lj_err.c\nindex caa7487f28..e3e0c2eb7e 100644\n--- a/src/lj_err.c\n+++ b/src/lj_err.c\n@@ -529,6 +529,7 @@ static ptrdiff_t finderrfunc(lua_State *L)\n       if (cframe_canyield(cf)) return 0;\n       if (cframe_errfunc(cf) >= 0)\n \treturn cframe_errfunc(cf);\n+      cf = cframe_prev(cf);\n       frame = frame_prevd(frame);\n       break;\n     case FRAME_PCALL:\n"
        ],
        "func_after": []
    },
    {
        "idx": 198927,
        "project": "radare2",
        "commit_id": "0a557045476a2969c7079aec9eeb29d02f2809c6",
        "project_url": "https://github.com/radare/radare2",
        "commit_url": "https://github.com/radareorg/radare2/commit/0a557045476a2969c7079aec9eeb29d02f2809c6",
        "commit_message": "Fix oobread and unaligned casts in the NE entrypoint logic ##crash\n\n* Reported by @hmsec via huntr.dev\n* Reproducer: nepocaligns\n* BountyID: ec538fa4-06c6-4050-a141-f60153ddeaac",
        "target": 1,
        "irrelevant": 1,
        "func_before": "RList *r_bin_ne_get_entrypoints(r_bin_ne_obj_t *bin) {\n\tif (!bin->entry_table) {\n\t\treturn NULL;\n\t}\n\tRList *entries = r_list_newf (free);\n\tif (!entries) {\n\t\treturn NULL;\n\t}\n\tRList *segments = r_bin_ne_get_segments (bin);\n\tif (!segments) {\n\t\tr_list_free (entries);\n\t\treturn NULL;\n\t}\n\tif (bin->ne_header->csEntryPoint) {\n\t\tRBinAddr *entry = R_NEW0 (RBinAddr);\n\t\tif (!entry) {\n\t\t\tr_list_free (entries);\n\t\t\treturn NULL;\n\t\t}\n\t\tentry->bits = 16;\n\t\tut32 entry_cs = bin->ne_header->csEntryPoint;\n\t\tRBinSection *s = r_list_get_n (segments, entry_cs - 1);\n\t\tentry->paddr = bin->ne_header->ipEntryPoint + (s? s->paddr: 0);\n\n\t\tr_list_append (entries, entry);\n\t}\n\tint off = 0;\n\tsize_t tableat = bin->header_offset + bin->ne_header->EntryTableOffset;\n\twhile (off < bin->ne_header->EntryTableLength) {\n\t\tif (tableat + off >= r_buf_size (bin->buf)) {\n\t\t\tbreak;\n\t\t}\n\t\tut8 bundle_length = *(ut8 *)(bin->entry_table + off);\n\t\tif (!bundle_length) {\n\t\t\tbreak;\n\t\t}\n\t\toff++;\n\t\tut8 bundle_type = *(ut8 *)(bin->entry_table + off);\n\t\toff++;\n\t\tint i;\n\t\tfor (i = 0; i < bundle_length; i++) {\n\t\t\tif (tableat + off + 4 >= r_buf_size (bin->buf)) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tRBinAddr *entry = R_NEW0 (RBinAddr);\n\t\t\tif (!entry) {\n\t\t\t\tr_list_free (entries);\n\t\t\t\treturn NULL;\n\t\t\t}\n\t\t\toff++;\n\t\t\tif (!bundle_type) { // Skip\n\t\t\t\toff--;\n\t\t\t\tfree (entry);\n\t\t\t\tbreak;\n\t\t\t} else if (bundle_type == 0xff) { // moveable\n\t\t\t\toff += 2;\n\t\t\t\tut8 segnum = *(bin->entry_table + off);\n\t\t\t\toff++;\n\t\t\t\tut16 segoff = *(ut16 *)(bin->entry_table + off);\n\t\t\t\tif (segnum > 0) {\n\t\t\t\t\tentry->paddr = (ut64)bin->segment_entries[segnum - 1].offset * bin->alignment + segoff;\n\t\t\t\t}\n\t\t\t} else { // Fixed\n\t\t\t\tif (bundle_type < bin->ne_header->SegCount) {\n\t\t\t\t\tentry->paddr = (ut64)bin->segment_entries[bundle_type - 1].offset\n\t\t\t\t\t\t* bin->alignment + *(ut16 *)(bin->entry_table + off);\n\t\t\t\t}\n\t\t\t}\n\t\t\toff += 2;\n\t\t\tr_list_append (entries, entry);\n\t\t}\n\t}\n\tr_list_free (segments);\n\tbin->entries = entries;\n\treturn entries;\n}",
        "func_hash": 128571297919304348712196386626162050665,
        "file_name": "ne.c",
        "file_hash": 267767472176864232009512780125221207666,
        "cwe": [
            "CWE-125"
        ],
        "cve": "CVE-2022-1297",
        "cve_desc": "Out-of-bounds Read in r_bin_ne_get_entrypoints function in GitHub repository radareorg/radare2 prior to 5.6.8. This vulnerability may allow attackers to read sensitive information or cause a crash.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-1297",
        "func_name": "r_bin_ne_get_entrypoints",
        "diff": [
            "diff --git a/libr/bin/format/ne/ne.c b/libr/bin/format/ne/ne.c\nindex b907d56e93b17..32aa589e8b7d5 100644\n--- a/libr/bin/format/ne/ne.c\n+++ b/libr/bin/format/ne/ne.c\n@@ -408,14 +408,21 @@ RList *r_bin_ne_get_entrypoints(r_bin_ne_obj_t *bin) {\n \t\t\t\toff += 2;\n \t\t\t\tut8 segnum = *(bin->entry_table + off);\n \t\t\t\toff++;\n-\t\t\t\tut16 segoff = *(ut16 *)(bin->entry_table + off);\n-\t\t\t\tif (segnum > 0) {\n+\t\t\t\tif (off > bin->ne_header->EntryTableLength) {\n+\t\t\t\t\tbreak;\n+\t\t\t\t}\n+\t\t\t\tut16 segoff = r_read_le16 (bin->entry_table + off);\n+\t\t\t\tif (segnum > 0 && segnum < bin->ne_header->SegCount) {\n \t\t\t\t\tentry->paddr = (ut64)bin->segment_entries[segnum - 1].offset * bin->alignment + segoff;\n \t\t\t\t}\n \t\t\t} else { // Fixed\n+\t\t\t\tif (off + 2 >= bin->ne_header->EntryTableLength) {\n+\t\t\t\t\tbreak;\n+\t\t\t\t}\n+\t\t\t\tut16 delta = r_read_le16 (bin->entry_table + off);\n \t\t\t\tif (bundle_type < bin->ne_header->SegCount) {\n \t\t\t\t\tentry->paddr = (ut64)bin->segment_entries[bundle_type - 1].offset\n-\t\t\t\t\t\t* bin->alignment + *(ut16 *)(bin->entry_table + off);\n+\t\t\t\t\t\t* bin->alignment + delta;\n \t\t\t\t}\n \t\t\t}\n \t\t\toff += 2;\n"
        ],
        "func_after": []
    },
    {
        "idx": 198983,
        "project": "swtpm",
        "commit_id": "9f740868fc36761de27df3935513bdebf8852d19",
        "project_url": "https://github.com/stefanberger/swtpm",
        "commit_url": "https://github.com/stefanberger/swtpm/commit/9f740868fc36761de27df3935513bdebf8852d19",
        "commit_message": "swtpm: Check header size indicator against expected size (CID 375869)\n\nThis fix addresses Coverity issue CID 375869.\n\nCheck the header size indicated in the header of the state against the\nexpected size and return an error code in case the header size indicator\nis different. There was only one header size so far since blobheader was\nintroduced, so we don't need to deal with different sizes.\n\nWithout this fix a specially craft header could have cause out-of-bounds\naccesses on the byte array containing the swtpm's state.\n\nSigned-off-by: Stefan Berger <stefanb@linux.ibm.com>",
        "target": 1,
        "irrelevant": 1,
        "func_before": "SWTPM_NVRAM_CheckHeader(unsigned char *data, uint32_t length,\n                        uint32_t *dataoffset, uint16_t *hdrflags,\n                        uint8_t *hdrversion, bool quiet)\n{\n    blobheader *bh = (blobheader *)data;\n\n    if (length < sizeof(bh)) {\n        if (!quiet)\n            logprintf(STDERR_FILENO,\n                      \"not enough bytes for header: %u\\n\", length);\n        return TPM_BAD_PARAMETER;\n    }\n\n    if (ntohl(bh->totlen) != length) {\n        if (!quiet)\n            logprintf(STDERR_FILENO,\n                      \"broken header: bh->totlen %u != %u\\n\",\n                      htonl(bh->totlen), length);\n        return TPM_BAD_PARAMETER;\n    }\n\n    if (bh->min_version > BLOB_HEADER_VERSION) {\n        if (!quiet)\n            logprintf(STDERR_FILENO,\n                      \"Minimum required version for the blob is %d, we \"\n                      \"only support version %d\\n\", bh->min_version,\n                      BLOB_HEADER_VERSION);\n        return TPM_BAD_VERSION;\n    }\n\n    *hdrversion = bh->version;\n    *dataoffset = ntohs(bh->hdrsize);\n    *hdrflags = ntohs(bh->flags);\n\n    return TPM_SUCCESS;\n}",
        "func_hash": 173394517357295307246184358296702159922,
        "file_name": "swtpm_nvfile.c",
        "file_hash": 132354630792840361852785968580616241078,
        "cwe": [
            "CWE-125"
        ],
        "cve": "CVE-2022-23645",
        "cve_desc": "swtpm is a libtpms-based TPM emulator with socket, character device, and Linux CUSE interface. Versions prior to 0.5.3, 0.6.2, and 0.7.1 are vulnerable to out-of-bounds read. A specially crafted header of swtpm's state, where the blobheader's hdrsize indicator has an invalid value, may cause an out-of-bounds access when the byte array representing the state of the TPM is accessed. This will likely crash swtpm or prevent it from starting since the state cannot be understood. Users should upgrade to swtpm v0.5.3, v0.6.2, or v0.7.1 to receive a patch. There are currently no known workarounds.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23645",
        "func_name": "SWTPM_NVRAM_CheckHeader",
        "diff": [
            "diff --git a/src/swtpm/swtpm_nvstore.c b/src/swtpm/swtpm_nvstore.c\nindex 437088370..144d8975e 100644\n--- a/src/swtpm/swtpm_nvstore.c\n+++ b/src/swtpm/swtpm_nvstore.c\n@@ -1075,6 +1075,7 @@ SWTPM_NVRAM_CheckHeader(unsigned char *data, uint32_t length,\n                         uint8_t *hdrversion, bool quiet)\n {\n     blobheader *bh = (blobheader *)data;\n+    uint16_t hdrsize;\n \n     if (length < sizeof(bh)) {\n         if (!quiet)\n@@ -1100,8 +1101,16 @@ SWTPM_NVRAM_CheckHeader(unsigned char *data, uint32_t length,\n         return TPM_BAD_VERSION;\n     }\n \n+    hdrsize = ntohs(bh->hdrsize);\n+    if (hdrsize != sizeof(blobheader)) {\n+        logprintf(STDERR_FILENO,\n+                  \"bad header size: %u != %zu\\n\",\n+                  hdrsize, sizeof(blobheader));\n+        return TPM_BAD_DATASIZE;\n+    }\n+\n     *hdrversion = bh->version;\n-    *dataoffset = ntohs(bh->hdrsize);\n+    *dataoffset = hdrsize;\n     *hdrflags = ntohs(bh->flags);\n \n     return TPM_SUCCESS;\n"
        ],
        "func_after": []
    },
    {
        "idx": 199159,
        "project": "linux",
        "commit_id": "8423f0b6d513b259fdab9c9bf4aaa6188d054c2d",
        "project_url": "https://github.com/torvalds/linux",
        "commit_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=8423f0b6d513b259fdab9c9bf4aaa6188d054c2d",
        "commit_message": "ALSA: pcm: oss: Fix race at SNDCTL_DSP_SYNC\n\nThere is a small race window at snd_pcm_oss_sync() that is called from\nOSS PCM SNDCTL_DSP_SYNC ioctl; namely the function calls\nsnd_pcm_oss_make_ready() at first, then takes the params_lock mutex\nfor the rest.  When the stream is set up again by another thread\nbetween them, it leads to inconsistency, and may result in unexpected\nresults such as NULL dereference of OSS buffer as a fuzzer spotted\nrecently.\n\nThe fix is simply to cover snd_pcm_oss_make_ready() call into the same\nparams_lock mutex with snd_pcm_oss_make_ready_locked() variant.\n\nReported-and-tested-by: butt3rflyh4ck <butterflyhuangxx@gmail.com>\nReviewed-by: Jaroslav Kysela <perex@perex.cz>\nCc: <stable@vger.kernel.org>\nLink: https://lore.kernel.org/r/CAFcO6XN7JDM4xSXGhtusQfS2mSBcx50VJKwQpCq=WeLt57aaZA@mail.gmail.com\nLink: https://lore.kernel.org/r/20220905060714.22549-1-tiwai@suse.de\nSigned-off-by: Takashi Iwai <tiwai@suse.de>",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static int snd_pcm_oss_sync(struct snd_pcm_oss_file *pcm_oss_file)\n{\n\tint err = 0;\n\tunsigned int saved_f_flags;\n\tstruct snd_pcm_substream *substream;\n\tstruct snd_pcm_runtime *runtime;\n\tsnd_pcm_format_t format;\n\tunsigned long width;\n\tsize_t size;\n\n\tsubstream = pcm_oss_file->streams[SNDRV_PCM_STREAM_PLAYBACK];\n\tif (substream != NULL) {\n\t\truntime = substream->runtime;\n\t\tif (atomic_read(&substream->mmap_count))\n\t\t\tgoto __direct;\n\t\terr = snd_pcm_oss_make_ready(substream);\n\t\tif (err < 0)\n\t\t\treturn err;\n\t\tatomic_inc(&runtime->oss.rw_ref);\n\t\tif (mutex_lock_interruptible(&runtime->oss.params_lock)) {\n\t\t\tatomic_dec(&runtime->oss.rw_ref);\n\t\t\treturn -ERESTARTSYS;\n\t\t}\n\t\tformat = snd_pcm_oss_format_from(runtime->oss.format);\n\t\twidth = snd_pcm_format_physical_width(format);\n\t\tif (runtime->oss.buffer_used > 0) {\n#ifdef OSS_DEBUG\n\t\t\tpcm_dbg(substream->pcm, \"sync: buffer_used\\n\");\n#endif\n\t\t\tsize = (8 * (runtime->oss.period_bytes - runtime->oss.buffer_used) + 7) / width;\n\t\t\tsnd_pcm_format_set_silence(format,\n\t\t\t\t\t\t   runtime->oss.buffer + runtime->oss.buffer_used,\n\t\t\t\t\t\t   size);\n\t\t\terr = snd_pcm_oss_sync1(substream, runtime->oss.period_bytes);\n\t\t\tif (err < 0)\n\t\t\t\tgoto unlock;\n\t\t} else if (runtime->oss.period_ptr > 0) {\n#ifdef OSS_DEBUG\n\t\t\tpcm_dbg(substream->pcm, \"sync: period_ptr\\n\");\n#endif\n\t\t\tsize = runtime->oss.period_bytes - runtime->oss.period_ptr;\n\t\t\tsnd_pcm_format_set_silence(format,\n\t\t\t\t\t\t   runtime->oss.buffer,\n\t\t\t\t\t\t   size * 8 / width);\n\t\t\terr = snd_pcm_oss_sync1(substream, size);\n\t\t\tif (err < 0)\n\t\t\t\tgoto unlock;\n\t\t}\n\t\t/*\n\t\t * The ALSA's period might be a bit large than OSS one.\n\t\t * Fill the remain portion of ALSA period with zeros.\n\t\t */\n\t\tsize = runtime->control->appl_ptr % runtime->period_size;\n\t\tif (size > 0) {\n\t\t\tsize = runtime->period_size - size;\n\t\t\tif (runtime->access == SNDRV_PCM_ACCESS_RW_INTERLEAVED)\n\t\t\t\tsnd_pcm_lib_write(substream, NULL, size);\n\t\t\telse if (runtime->access == SNDRV_PCM_ACCESS_RW_NONINTERLEAVED)\n\t\t\t\tsnd_pcm_lib_writev(substream, NULL, size);\n\t\t}\nunlock:\n\t\tmutex_unlock(&runtime->oss.params_lock);\n\t\tatomic_dec(&runtime->oss.rw_ref);\n\t\tif (err < 0)\n\t\t\treturn err;\n\t\t/*\n\t\t * finish sync: drain the buffer\n\t\t */\n\t      __direct:\n\t\tsaved_f_flags = substream->f_flags;\n\t\tsubstream->f_flags &= ~O_NONBLOCK;\n\t\terr = snd_pcm_kernel_ioctl(substream, SNDRV_PCM_IOCTL_DRAIN, NULL);\n\t\tsubstream->f_flags = saved_f_flags;\n\t\tif (err < 0)\n\t\t\treturn err;\n\t\tmutex_lock(&runtime->oss.params_lock);\n\t\truntime->oss.prepare = 1;\n\t\tmutex_unlock(&runtime->oss.params_lock);\n\t}\n\n\tsubstream = pcm_oss_file->streams[SNDRV_PCM_STREAM_CAPTURE];\n\tif (substream != NULL) {\n\t\terr = snd_pcm_oss_make_ready(substream);\n\t\tif (err < 0)\n\t\t\treturn err;\n\t\truntime = substream->runtime;\n\t\terr = snd_pcm_kernel_ioctl(substream, SNDRV_PCM_IOCTL_DROP, NULL);\n\t\tif (err < 0)\n\t\t\treturn err;\n\t\tmutex_lock(&runtime->oss.params_lock);\n\t\truntime->oss.buffer_used = 0;\n\t\truntime->oss.prepare = 1;\n\t\tmutex_unlock(&runtime->oss.params_lock);\n\t}\n\treturn 0;\n}",
        "func_hash": 331549555245265175479800423924118181234,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-362"
        ],
        "cve": "CVE-2022-3303",
        "cve_desc": "A race condition flaw was found in the Linux kernel sound subsystem due to improper locking. It could lead to a NULL pointer dereference while handling the SNDCTL_DSP_SYNC ioctl. A privileged local user (root or member of the audio group) could use this flaw to crash the system, resulting in a denial of service condition",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-3303",
        "func_name": "snd_pcm_oss_sync",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 199681,
        "project": "linux",
        "commit_id": "233087ca063686964a53c829d547c7571e3f67bf",
        "project_url": "https://github.com/torvalds/linux",
        "commit_url": "https://github.com/torvalds/linux/commit/233087ca063686964a53c829d547c7571e3f67bf",
        "commit_message": "floppy: disable FDRAWCMD by default\n\nMinh Yuan reported a concurrency use-after-free issue in the floppy code\nbetween raw_cmd_ioctl and seek_interrupt.\n\n[ It turns out this has been around, and that others have reported the\n  KASAN splats over the years, but Minh Yuan had a reproducer for it and\n  so gets primary credit for reporting it for this fix   - Linus ]\n\nThe problem is, this driver tends to break very easily and nowadays,\nnobody is expected to use FDRAWCMD anyway since it was used to\nmanipulate non-standard formats.  The risk of breaking the driver is\nhigher than the risk presented by this race, and accessing the device\nrequires privileges anyway.\n\nLet's just add a config option to completely disable this ioctl and\nleave it disabled by default.  Distros shouldn't use it, and only those\nrunning on antique hardware might need to enable it.\n\nLink: https://lore.kernel.org/all/000000000000b71cdd05d703f6bf@google.com/\nLink: https://lore.kernel.org/lkml/CAKcFiNC=MfYVW-Jt9A3=FPJpTwCD2PL_ULNCpsCVE5s8ZeBQgQ@mail.gmail.com\nLink: https://lore.kernel.org/all/CAEAjamu1FRhz6StCe_55XY5s389ZP_xmCF69k987En+1z53=eg@mail.gmail.com\nReported-by: Minh Yuan <yuanmingbuaa@gmail.com>\nReported-by: syzbot+8e8958586909d62b6840@syzkaller.appspotmail.com\nReported-by: cruise k <cruise4k@gmail.com>\nReported-by: Kyungtae Kim <kt0755@gmail.com>\nSuggested-by: Linus Torvalds <torvalds@linuxfoundation.org>\nTested-by: Denis Efremov <efremov@linux.com>\nSigned-off-by: Willy Tarreau <w@1wt.eu>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static int fd_locked_ioctl(struct block_device *bdev, fmode_t mode, unsigned int cmd,\n\t\t    unsigned long param)\n{\n\tint drive = (long)bdev->bd_disk->private_data;\n\tint type = ITYPE(drive_state[drive].fd_device);\n\tint i;\n\tint ret;\n\tint size;\n\tunion inparam {\n\t\tstruct floppy_struct g;\t/* geometry */\n\t\tstruct format_descr f;\n\t\tstruct floppy_max_errors max_errors;\n\t\tstruct floppy_drive_params dp;\n\t} inparam;\t\t/* parameters coming from user space */\n\tconst void *outparam;\t/* parameters passed back to user space */\n\n\t/* convert compatibility eject ioctls into floppy eject ioctl.\n\t * We do this in order to provide a means to eject floppy disks before\n\t * installing the new fdutils package */\n\tif (cmd == CDROMEJECT ||\t/* CD-ROM eject */\n\t    cmd == 0x6470) {\t\t/* SunOS floppy eject */\n\t\tDPRINT(\"obsolete eject ioctl\\n\");\n\t\tDPRINT(\"please use floppycontrol --eject\\n\");\n\t\tcmd = FDEJECT;\n\t}\n\n\tif (!((cmd & 0xff00) == 0x0200))\n\t\treturn -EINVAL;\n\n\t/* convert the old style command into a new style command */\n\tret = normalize_ioctl(&cmd, &size);\n\tif (ret)\n\t\treturn ret;\n\n\t/* permission checks */\n\tif (((cmd & 0x40) && !(mode & (FMODE_WRITE | FMODE_WRITE_IOCTL))) ||\n\t    ((cmd & 0x80) && !capable(CAP_SYS_ADMIN)))\n\t\treturn -EPERM;\n\n\tif (WARN_ON(size < 0 || size > sizeof(inparam)))\n\t\treturn -EINVAL;\n\n\t/* copyin */\n\tmemset(&inparam, 0, sizeof(inparam));\n\tif (_IOC_DIR(cmd) & _IOC_WRITE) {\n\t\tret = fd_copyin((void __user *)param, &inparam, size);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tswitch (cmd) {\n\tcase FDEJECT:\n\t\tif (drive_state[drive].fd_ref != 1)\n\t\t\t/* somebody else has this drive open */\n\t\t\treturn -EBUSY;\n\t\tif (lock_fdc(drive))\n\t\t\treturn -EINTR;\n\n\t\t/* do the actual eject. Fails on\n\t\t * non-Sparc architectures */\n\t\tret = fd_eject(UNIT(drive));\n\n\t\tset_bit(FD_DISK_CHANGED_BIT, &drive_state[drive].flags);\n\t\tset_bit(FD_VERIFY_BIT, &drive_state[drive].flags);\n\t\tprocess_fd_request();\n\t\treturn ret;\n\tcase FDCLRPRM:\n\t\tif (lock_fdc(drive))\n\t\t\treturn -EINTR;\n\t\tcurrent_type[drive] = NULL;\n\t\tfloppy_sizes[drive] = MAX_DISK_SIZE << 1;\n\t\tdrive_state[drive].keep_data = 0;\n\t\treturn invalidate_drive(bdev);\n\tcase FDSETPRM:\n\tcase FDDEFPRM:\n\t\treturn set_geometry(cmd, &inparam.g, drive, type, bdev);\n\tcase FDGETPRM:\n\t\tret = get_floppy_geometry(drive, type,\n\t\t\t\t\t  (struct floppy_struct **)&outparam);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tmemcpy(&inparam.g, outparam,\n\t\t\t\toffsetof(struct floppy_struct, name));\n\t\toutparam = &inparam.g;\n\t\tbreak;\n\tcase FDMSGON:\n\t\tdrive_params[drive].flags |= FTD_MSG;\n\t\treturn 0;\n\tcase FDMSGOFF:\n\t\tdrive_params[drive].flags &= ~FTD_MSG;\n\t\treturn 0;\n\tcase FDFMTBEG:\n\t\tif (lock_fdc(drive))\n\t\t\treturn -EINTR;\n\t\tif (poll_drive(true, FD_RAW_NEED_DISK) == -EINTR)\n\t\t\treturn -EINTR;\n\t\tret = drive_state[drive].flags;\n\t\tprocess_fd_request();\n\t\tif (ret & FD_VERIFY)\n\t\t\treturn -ENODEV;\n\t\tif (!(ret & FD_DISK_WRITABLE))\n\t\t\treturn -EROFS;\n\t\treturn 0;\n\tcase FDFMTTRK:\n\t\tif (drive_state[drive].fd_ref != 1)\n\t\t\treturn -EBUSY;\n\t\treturn do_format(drive, &inparam.f);\n\tcase FDFMTEND:\n\tcase FDFLUSH:\n\t\tif (lock_fdc(drive))\n\t\t\treturn -EINTR;\n\t\treturn invalidate_drive(bdev);\n\tcase FDSETEMSGTRESH:\n\t\tdrive_params[drive].max_errors.reporting = (unsigned short)(param & 0x0f);\n\t\treturn 0;\n\tcase FDGETMAXERRS:\n\t\toutparam = &drive_params[drive].max_errors;\n\t\tbreak;\n\tcase FDSETMAXERRS:\n\t\tdrive_params[drive].max_errors = inparam.max_errors;\n\t\tbreak;\n\tcase FDGETDRVTYP:\n\t\toutparam = drive_name(type, drive);\n\t\tSUPBOUND(size, strlen((const char *)outparam) + 1);\n\t\tbreak;\n\tcase FDSETDRVPRM:\n\t\tif (!valid_floppy_drive_params(inparam.dp.autodetect,\n\t\t\t\tinparam.dp.native_format))\n\t\t\treturn -EINVAL;\n\t\tdrive_params[drive] = inparam.dp;\n\t\tbreak;\n\tcase FDGETDRVPRM:\n\t\toutparam = &drive_params[drive];\n\t\tbreak;\n\tcase FDPOLLDRVSTAT:\n\t\tif (lock_fdc(drive))\n\t\t\treturn -EINTR;\n\t\tif (poll_drive(true, FD_RAW_NEED_DISK) == -EINTR)\n\t\t\treturn -EINTR;\n\t\tprocess_fd_request();\n\t\tfallthrough;\n\tcase FDGETDRVSTAT:\n\t\toutparam = &drive_state[drive];\n\t\tbreak;\n\tcase FDRESET:\n\t\treturn user_reset_fdc(drive, (int)param, true);\n\tcase FDGETFDCSTAT:\n\t\toutparam = &fdc_state[FDC(drive)];\n\t\tbreak;\n\tcase FDWERRORCLR:\n\t\tmemset(&write_errors[drive], 0, sizeof(write_errors[drive]));\n\t\treturn 0;\n\tcase FDWERRORGET:\n\t\toutparam = &write_errors[drive];\n\t\tbreak;\n\tcase FDRAWCMD:\n\t\tif (type)\n\t\t\treturn -EINVAL;\n\t\tif (lock_fdc(drive))\n\t\t\treturn -EINTR;\n\t\tset_floppy(drive);\n\t\ti = raw_cmd_ioctl(cmd, (void __user *)param);\n\t\tif (i == -EINTR)\n\t\t\treturn -EINTR;\n\t\tprocess_fd_request();\n\t\treturn i;\n\tcase FDTWADDLE:\n\t\tif (lock_fdc(drive))\n\t\t\treturn -EINTR;\n\t\ttwaddle(current_fdc, current_drive);\n\t\tprocess_fd_request();\n\t\treturn 0;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\tif (_IOC_DIR(cmd) & _IOC_READ)\n\t\treturn fd_copyout((void __user *)param, outparam, size);\n\n\treturn 0;\n}",
        "func_hash": 185600890459651071126358112291118902664,
        "file_name": "floppy.c",
        "file_hash": 276679374674708517482827678033656857128,
        "cwe": [
            "CWE-416"
        ],
        "cve": "CVE-2022-1836",
        "cve_desc": "Rejected reason: DO NOT USE THIS CANDIDATE NUMBER. ConsultIDs: CVE-2022-33981. Reason: This candidate is a reservation duplicate of CVE-2022-33981. Notes: All CVE users should reference CVE-2022-33981 instead of this candidate. All references and descriptions in this candidate have been removed to prevent accidental usage",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-1836",
        "func_name": "fd_locked_ioctl",
        "diff": [
            "diff --git a/drivers/block/Kconfig b/drivers/block/Kconfig\nindex 519b6d38d4df65..fdb81f2794cde1 100644\n--- a/drivers/block/Kconfig\n+++ b/drivers/block/Kconfig\n@@ -33,6 +33,22 @@ config BLK_DEV_FD\n \t  To compile this driver as a module, choose M here: the\n \t  module will be called floppy.\n \n+config BLK_DEV_FD_RAWCMD\n+\tbool \"Support for raw floppy disk commands (DEPRECATED)\"\n+\tdepends on BLK_DEV_FD\n+\thelp\n+\t  If you want to use actual physical floppies and expect to do\n+\t  special low-level hardware accesses to them (access and use\n+\t  non-standard formats, for example), then enable this.\n+\n+\t  Note that the code enabled by this option is rarely used and\n+\t  might be unstable or insecure, and distros should not enable it.\n+\n+\t  Note: FDRAWCMD is deprecated and will be removed from the kernel\n+\t  in the near future.\n+\n+\t  If unsure, say N.\n+\n config AMIGA_FLOPPY\n \ttristate \"Amiga floppy support\"\n \tdepends on AMIGA\ndiff --git a/drivers/block/floppy.c b/drivers/block/floppy.c\nindex 8c647532e3ce99..d5b9ff9bcbb2b8 100644\n--- a/drivers/block/floppy.c\n+++ b/drivers/block/floppy.c\n@@ -2982,6 +2982,8 @@ static const char *drive_name(int type, int drive)\n \t\treturn \"(null)\";\n }\n \n+#ifdef CONFIG_BLK_DEV_FD_RAWCMD\n+\n /* raw commands */\n static void raw_cmd_done(int flag)\n {\n@@ -3181,6 +3183,35 @@ static int raw_cmd_ioctl(int cmd, void __user *param)\n \treturn ret;\n }\n \n+static int floppy_raw_cmd_ioctl(int type, int drive, int cmd,\n+\t\t\t\tvoid __user *param)\n+{\n+\tint ret;\n+\n+\tpr_warn_once(\"Note: FDRAWCMD is deprecated and will be removed from the kernel in the near future.\\n\");\n+\n+\tif (type)\n+\t\treturn -EINVAL;\n+\tif (lock_fdc(drive))\n+\t\treturn -EINTR;\n+\tset_floppy(drive);\n+\tret = raw_cmd_ioctl(cmd, param);\n+\tif (ret == -EINTR)\n+\t\treturn -EINTR;\n+\tprocess_fd_request();\n+\treturn ret;\n+}\n+\n+#else /* CONFIG_BLK_DEV_FD_RAWCMD */\n+\n+static int floppy_raw_cmd_ioctl(int type, int drive, int cmd,\n+\t\t\t\tvoid __user *param)\n+{\n+\treturn -EOPNOTSUPP;\n+}\n+\n+#endif\n+\n static int invalidate_drive(struct block_device *bdev)\n {\n \t/* invalidate the buffer track to force a reread */\n@@ -3369,7 +3400,6 @@ static int fd_locked_ioctl(struct block_device *bdev, fmode_t mode, unsigned int\n {\n \tint drive = (long)bdev->bd_disk->private_data;\n \tint type = ITYPE(drive_state[drive].fd_device);\n-\tint i;\n \tint ret;\n \tint size;\n \tunion inparam {\n@@ -3520,16 +3550,7 @@ static int fd_locked_ioctl(struct block_device *bdev, fmode_t mode, unsigned int\n \t\toutparam = &write_errors[drive];\n \t\tbreak;\n \tcase FDRAWCMD:\n-\t\tif (type)\n-\t\t\treturn -EINVAL;\n-\t\tif (lock_fdc(drive))\n-\t\t\treturn -EINTR;\n-\t\tset_floppy(drive);\n-\t\ti = raw_cmd_ioctl(cmd, (void __user *)param);\n-\t\tif (i == -EINTR)\n-\t\t\treturn -EINTR;\n-\t\tprocess_fd_request();\n-\t\treturn i;\n+\t\treturn floppy_raw_cmd_ioctl(type, drive, cmd, (void __user *)param);\n \tcase FDTWADDLE:\n \t\tif (lock_fdc(drive))\n \t\t\treturn -EINTR;\n"
        ],
        "func_after": []
    },
    {
        "idx": 199712,
        "project": "linux",
        "commit_id": "8700af2cc18c919b2a83e74e0479038fd113c15d",
        "project_url": "https://github.com/torvalds/linux",
        "commit_url": "https://github.com/torvalds/linux/commit/8700af2cc18c919b2a83e74e0479038fd113c15d",
        "commit_message": "RDMA/rtrs-clt: Fix possible double free in error case\n\nCallback function rtrs_clt_dev_release() for put_device() calls kfree(clt)\nto free memory. We shouldn't call kfree(clt) again, and we can't use the\nclt after kfree too.\n\nReplace device_register() with device_initialize() and device_add() so that\ndev_set_name can() be used appropriately.\n\nMove mutex_destroy() to the release function so it can be called in\nthe alloc_clt err path.\n\nFixes: eab098246625 (\"RDMA/rtrs-clt: Refactor the failure cases in alloc_clt\")\nLink: https://lore.kernel.org/r/20220217030929.323849-1-haris.iqbal@ionos.com\nReported-by: Miaoqian Lin <linmq006@gmail.com>\nSigned-off-by: Md Haris Iqbal <haris.iqbal@ionos.com>\nReviewed-by: Jack Wang <jinpu.wang@ionos.com>\nSigned-off-by: Jason Gunthorpe <jgg@nvidia.com>",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static void rtrs_clt_dev_release(struct device *dev)\n{\n\tstruct rtrs_clt_sess *clt = container_of(dev, struct rtrs_clt_sess,\n\t\t\t\t\t\t dev);\n\n\tkfree(clt);\n}",
        "func_hash": 64652297556654438298355501352205556509,
        "file_name": "rtrs-clt.c",
        "file_hash": 149775209474441169700962555059878991264,
        "cwe": [
            "CWE-415"
        ],
        "cve": "CVE-2022-29156",
        "cve_desc": "drivers/infiniband/ulp/rtrs/rtrs-clt.c in the Linux kernel before 5.16.12 has a double free related to rtrs_clt_dev_release.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-29156",
        "func_name": "rtrs_clt_dev_release",
        "diff": [
            "diff --git a/drivers/infiniband/ulp/rtrs/rtrs-clt.c b/drivers/infiniband/ulp/rtrs/rtrs-clt.c\nindex 7c3f98e57889f8..6164b07a164427 100644\n--- a/drivers/infiniband/ulp/rtrs/rtrs-clt.c\n+++ b/drivers/infiniband/ulp/rtrs/rtrs-clt.c\n@@ -2682,6 +2682,8 @@ static void rtrs_clt_dev_release(struct device *dev)\n \tstruct rtrs_clt_sess *clt = container_of(dev, struct rtrs_clt_sess,\n \t\t\t\t\t\t dev);\n \n+\tmutex_destroy(&clt->paths_ev_mutex);\n+\tmutex_destroy(&clt->paths_mutex);\n \tkfree(clt);\n }\n \n@@ -2711,6 +2713,8 @@ static struct rtrs_clt_sess *alloc_clt(const char *sessname, size_t paths_num,\n \t\treturn ERR_PTR(-ENOMEM);\n \t}\n \n+\tclt->dev.class = rtrs_clt_dev_class;\n+\tclt->dev.release = rtrs_clt_dev_release;\n \tuuid_gen(&clt->paths_uuid);\n \tINIT_LIST_HEAD_RCU(&clt->paths_list);\n \tclt->paths_num = paths_num;\n@@ -2727,43 +2731,41 @@ static struct rtrs_clt_sess *alloc_clt(const char *sessname, size_t paths_num,\n \tinit_waitqueue_head(&clt->permits_wait);\n \tmutex_init(&clt->paths_ev_mutex);\n \tmutex_init(&clt->paths_mutex);\n+\tdevice_initialize(&clt->dev);\n \n-\tclt->dev.class = rtrs_clt_dev_class;\n-\tclt->dev.release = rtrs_clt_dev_release;\n \terr = dev_set_name(&clt->dev, \"%s\", sessname);\n \tif (err)\n-\t\tgoto err;\n+\t\tgoto err_put;\n+\n \t/*\n \t * Suppress user space notification until\n \t * sysfs files are created\n \t */\n \tdev_set_uevent_suppress(&clt->dev, true);\n-\terr = device_register(&clt->dev);\n-\tif (err) {\n-\t\tput_device(&clt->dev);\n-\t\tgoto err;\n-\t}\n+\terr = device_add(&clt->dev);\n+\tif (err)\n+\t\tgoto err_put;\n \n \tclt->kobj_paths = kobject_create_and_add(\"paths\", &clt->dev.kobj);\n \tif (!clt->kobj_paths) {\n \t\terr = -ENOMEM;\n-\t\tgoto err_dev;\n+\t\tgoto err_del;\n \t}\n \terr = rtrs_clt_create_sysfs_root_files(clt);\n \tif (err) {\n \t\tkobject_del(clt->kobj_paths);\n \t\tkobject_put(clt->kobj_paths);\n-\t\tgoto err_dev;\n+\t\tgoto err_del;\n \t}\n \tdev_set_uevent_suppress(&clt->dev, false);\n \tkobject_uevent(&clt->dev.kobj, KOBJ_ADD);\n \n \treturn clt;\n-err_dev:\n-\tdevice_unregister(&clt->dev);\n-err:\n+err_del:\n+\tdevice_del(&clt->dev);\n+err_put:\n \tfree_percpu(clt->pcpu_path);\n-\tkfree(clt);\n+\tput_device(&clt->dev);\n \treturn ERR_PTR(err);\n }\n \n@@ -2771,9 +2773,10 @@ static void free_clt(struct rtrs_clt_sess *clt)\n {\n \tfree_permits(clt);\n \tfree_percpu(clt->pcpu_path);\n-\tmutex_destroy(&clt->paths_ev_mutex);\n-\tmutex_destroy(&clt->paths_mutex);\n-\t/* release callback will free clt in last put */\n+\n+\t/*\n+\t * release callback will free clt and destroy mutexes in last put\n+\t */\n \tdevice_unregister(&clt->dev);\n }\n \n"
        ],
        "func_after": []
    },
    {
        "idx": 199767,
        "project": "hexchat",
        "commit_id": "4e061a43b3453a9856d34250c3913175c45afe9d",
        "project_url": "https://github.com/hexchat/hexchat",
        "commit_url": "https://github.com/hexchat/hexchat/commit/4e061a43b3453a9856d34250c3913175c45afe9d",
        "commit_message": "Clean up handling CAP LS",
        "target": 1,
        "irrelevant": 0,
        "func_before": "inbound_cap_ls (server *serv, char *nick, char *extensions_str,\n\t\t\t\t\t const message_tags_data *tags_data)\n{\n\tchar buffer[256];\t/* buffer for requesting capabilities and emitting the signal */\n\tguint32 want_cap; /* format the CAP REQ string based on previous capabilities being requested or not */\n\tguint32 want_sasl; /* CAP END shouldn't be sent when SASL is requested, it needs further responses */\n\tchar **extensions;\n\tint i;\n\n\tEMIT_SIGNAL_TIMESTAMP (XP_TE_CAPLIST, serv->server_session, nick,\n\t\t\t\t\t\t\t\t  extensions_str, NULL, NULL, 0, tags_data->timestamp);\n\twant_cap = 0;\n\twant_sasl = 0;\n\n\textensions = g_strsplit (extensions_str, \" \", 0);\n\n\tstrcpy (buffer, \"CAP REQ :\");\n\n\tfor (i=0; extensions[i]; i++)\n\t{\n\t\tconst char *extension = extensions[i];\n\n\t\tif (!strcmp (extension, \"identify-msg\"))\n\t\t{\n\t\t\tstrcat (buffer, \"identify-msg \");\n\t\t\twant_cap = 1;\n\t\t}\n\t\tif (!strcmp (extension, \"multi-prefix\"))\n\t\t{\n\t\t\tstrcat (buffer, \"multi-prefix \");\n\t\t\twant_cap = 1;\n\t\t}\n\t\tif (!strcmp (extension, \"away-notify\"))\n\t\t{\n\t\t\tstrcat (buffer, \"away-notify \");\n\t\t\twant_cap = 1;\n\t\t}\n\t\tif (!strcmp (extension, \"account-notify\"))\n\t\t{\n\t\t\tstrcat (buffer, \"account-notify \");\n\t\t\twant_cap = 1;\n\t\t}\n\t\tif (!strcmp (extension, \"extended-join\"))\n\t\t{\n\t\t\tstrcat (buffer, \"extended-join \");\n\t\t\twant_cap = 1;\n\t\t}\n\t\tif (!strcmp (extension, \"userhost-in-names\"))\n\t\t{\n\t\t\tstrcat (buffer, \"userhost-in-names \");\n\t\t\twant_cap = 1;\n\t\t}\n\n\t\t/* bouncers can prefix a name space to the extension so we should use.\n\t\t * znc <= 1.0 uses \"znc.in/server-time\" and newer use \"znc.in/server-time-iso\".\n\t\t */\n\t\tif (!strcmp (extension, \"znc.in/server-time-iso\"))\n\t\t{\n\t\t\tstrcat (buffer, \"znc.in/server-time-iso \");\n\t\t\twant_cap = 1;\n\t\t}\n\t\tif (!strcmp (extension, \"znc.in/server-time\"))\n\t\t{\n\t\t\tstrcat (buffer, \"znc.in/server-time \");\n\t\t\twant_cap = 1;\n\t\t}\n\t\tif (prefs.hex_irc_cap_server_time\n\t\t\t && !strcmp (extension, \"server-time\"))\n\t\t{\n\t\t\tstrcat (buffer, \"server-time \");\n\t\t\twant_cap = 1;\n\t\t}\n\t\t\n\t\t/* if the SASL password is set AND auth mode is set to SASL, request SASL auth */\n\t\tif (!strcmp (extension, \"sasl\")\n\t\t\t&& ((serv->loginmethod == LOGIN_SASL && strlen (serv->password) != 0)\n\t\t\t|| (serv->loginmethod == LOGIN_SASLEXTERNAL && serv->have_cert)))\n\t\t{\n\t\t\tstrcat (buffer, \"sasl \");\n\t\t\twant_cap = 1;\n\t\t\twant_sasl = 1;\n\t\t}\n\t}\n\n\tg_strfreev (extensions);\n\n\tif (want_cap)\n\t{\n\t\t/* buffer + 9 = emit buffer without \"CAP REQ :\" */\n\t\tEMIT_SIGNAL_TIMESTAMP (XP_TE_CAPREQ, serv->server_session,\n\t\t\t\t\t\t\t\t\t  buffer + 9, NULL, NULL, NULL, 0,\n\t\t\t\t\t\t\t\t\t  tags_data->timestamp);\n\t\ttcp_sendf (serv, \"%s\\r\\n\", g_strchomp (buffer));\n\t}\n\tif (!want_sasl)\n\t{\n\t\t/* if we use SASL, CAP END is dealt via raw numerics */\n\t\tserv->sent_capend = TRUE;\n\t\ttcp_send_len (serv, \"CAP END\\r\\n\", 9);\n\t}\n}",
        "func_hash": 289376674180826741553106169575003472652,
        "file_name": "inbound.c",
        "file_hash": 202497518967624726910452754426675896941,
        "cwe": [
            "CWE-22"
        ],
        "cve": "CVE-2016-2087",
        "cve_desc": "Directory traversal vulnerability in the client in HexChat 2.11.0 allows remote IRC servers to read or modify arbitrary files via a .. (dot dot) in the server name.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2016-2087",
        "func_name": "inbound_cap_ls",
        "diff": [
            "diff --git a/src/common/inbound.c b/src/common/inbound.c\nindex ef26890b9..645cc824a 100644\n--- a/src/common/inbound.c\n+++ b/src/common/inbound.c\n@@ -1699,20 +1699,37 @@ inbound_cap_ack (server *serv, char *nick, char *extensions,\n \t}\n }\n \n+static const char * const supported_caps[] = {\n+\t\"identify-msg\",\n+\n+\t/* IRCv3.1 */\n+\t\"multi-prefix\",\n+\t\"away-notify\",\n+\t\"account-notify\",\n+\t\"extended-join\",\n+\t/* \"sasl\", Handled manually */\n+\n+\t/* IRCv3.2 */\n+\t\"server-time\"\n+\t\"userhost-in-names\",\n+\n+\t/* ZNC */\n+\t\"znc.in/server-time-iso\",\n+\t\"znc.in/server-time\",\n+};\n+\n void\n inbound_cap_ls (server *serv, char *nick, char *extensions_str,\n \t\t\t\t\t const message_tags_data *tags_data)\n {\n \tchar buffer[256];\t/* buffer for requesting capabilities and emitting the signal */\n-\tguint32 want_cap; /* format the CAP REQ string based on previous capabilities being requested or not */\n-\tguint32 want_sasl; /* CAP END shouldn't be sent when SASL is requested, it needs further responses */\n+\tgboolean want_cap = FALSE; /* format the CAP REQ string based on previous capabilities being requested or not */\n+\tgboolean want_sasl = FALSE; /* CAP END shouldn't be sent when SASL is requested, it needs further responses */\n \tchar **extensions;\n \tint i;\n \n \tEMIT_SIGNAL_TIMESTAMP (XP_TE_CAPLIST, serv->server_session, nick,\n \t\t\t\t\t\t\t\t  extensions_str, NULL, NULL, 0, tags_data->timestamp);\n-\twant_cap = 0;\n-\twant_sasl = 0;\n \n \textensions = g_strsplit (extensions_str, \" \", 0);\n \n@@ -1721,66 +1738,27 @@ inbound_cap_ls (server *serv, char *nick, char *extensions_str,\n \tfor (i=0; extensions[i]; i++)\n \t{\n \t\tconst char *extension = extensions[i];\n+\t\tgsize x;\n \n-\t\tif (!strcmp (extension, \"identify-msg\"))\n-\t\t{\n-\t\t\tstrcat (buffer, \"identify-msg \");\n-\t\t\twant_cap = 1;\n-\t\t}\n-\t\tif (!strcmp (extension, \"multi-prefix\"))\n-\t\t{\n-\t\t\tstrcat (buffer, \"multi-prefix \");\n-\t\t\twant_cap = 1;\n-\t\t}\n-\t\tif (!strcmp (extension, \"away-notify\"))\n-\t\t{\n-\t\t\tstrcat (buffer, \"away-notify \");\n-\t\t\twant_cap = 1;\n-\t\t}\n-\t\tif (!strcmp (extension, \"account-notify\"))\n-\t\t{\n-\t\t\tstrcat (buffer, \"account-notify \");\n-\t\t\twant_cap = 1;\n-\t\t}\n-\t\tif (!strcmp (extension, \"extended-join\"))\n-\t\t{\n-\t\t\tstrcat (buffer, \"extended-join \");\n-\t\t\twant_cap = 1;\n-\t\t}\n-\t\tif (!strcmp (extension, \"userhost-in-names\"))\n+\t\t/* if the SASL password is set AND auth mode is set to SASL, request SASL auth */\n+\t\tif (!g_strcmp0 (extension, \"sasl\") &&\n+\t\t\t((serv->loginmethod == LOGIN_SASL && strlen (serv->password) != 0)\n+\t\t\t\t|| (serv->loginmethod == LOGIN_SASLEXTERNAL && serv->have_cert)))\n \t\t{\n-\t\t\tstrcat (buffer, \"userhost-in-names \");\n-\t\t\twant_cap = 1;\n+\t\t\twant_cap = TRUE;\n+\t\t\twant_sasl = TRUE;\n+\t\t\tg_strlcat (buffer, \"sasl \", sizeof(buffer));\n+\t\t\tcontinue;\n \t\t}\n \n-\t\t/* bouncers can prefix a name space to the extension so we should use.\n-\t\t * znc <= 1.0 uses \"znc.in/server-time\" and newer use \"znc.in/server-time-iso\".\n-\t\t */\n-\t\tif (!strcmp (extension, \"znc.in/server-time-iso\"))\n-\t\t{\n-\t\t\tstrcat (buffer, \"znc.in/server-time-iso \");\n-\t\t\twant_cap = 1;\n-\t\t}\n-\t\tif (!strcmp (extension, \"znc.in/server-time\"))\n-\t\t{\n-\t\t\tstrcat (buffer, \"znc.in/server-time \");\n-\t\t\twant_cap = 1;\n-\t\t}\n-\t\tif (prefs.hex_irc_cap_server_time\n-\t\t\t && !strcmp (extension, \"server-time\"))\n+\t\tfor (x = 0; x < G_N_ELEMENTS(supported_caps); ++x)\n \t\t{\n-\t\t\tstrcat (buffer, \"server-time \");\n-\t\t\twant_cap = 1;\n-\t\t}\n-\t\t\n-\t\t/* if the SASL password is set AND auth mode is set to SASL, request SASL auth */\n-\t\tif (!strcmp (extension, \"sasl\")\n-\t\t\t&& ((serv->loginmethod == LOGIN_SASL && strlen (serv->password) != 0)\n-\t\t\t|| (serv->loginmethod == LOGIN_SASLEXTERNAL && serv->have_cert)))\n-\t\t{\n-\t\t\tstrcat (buffer, \"sasl \");\n-\t\t\twant_cap = 1;\n-\t\t\twant_sasl = 1;\n+\t\t\tif (!g_strcmp0 (extension, supported_caps[x]))\n+\t\t\t{\n+\t\t\t\tg_strlcat (buffer, extension, sizeof(buffer));\n+\t\t\t\tg_strlcat (buffer, \" \", sizeof(buffer));\n+\t\t\t\twant_cap = TRUE;\n+\t\t\t}\n \t\t}\n \t}\n \n"
        ],
        "func_after": []
    },
    {
        "idx": 199778,
        "project": "puma",
        "commit_id": "acdc3ae571dfae0e045cf09a295280127db65c7f",
        "project_url": "https://github.com/puma/puma",
        "commit_url": "https://github.com/puma/puma/commit/acdc3ae571dfae0e045cf09a295280127db65c7f",
        "commit_message": "Merge pull request from GHSA-48w2-rm65-62xx\n\n* Fix HTTP request smuggling vulnerability\n\nSee GHSA-48w2-rm65-62xx or CVE-2021-41136 for more info.\n\n* 4.3.9 release note\n\n* 5.5.1 release note\n\n* 5.5.1",
        "target": 1,
        "irrelevant": 0,
        "func_before": "size_t puma_parser_execute(puma_parser *parser, const char *buffer, size_t len, size_t off)  {\n  const char *p, *pe;\n  int cs = parser->cs;\n\n  assert(off <= len && \"offset past end of buffer\");\n\n  p = buffer+off;\n  pe = buffer+len;\n\n  /* assert(*pe == '\\0' && \"pointer does not end on NUL\"); */\n  assert((size_t) (pe - p) == len - off && \"pointers aren't same distance\");\n\n  \n#line 87 \"ext/puma_http11/http11_parser.c\"\n\t{\n\tif ( p == pe )\n\t\tgoto _test_eof;\n\tswitch ( cs )\n\t{\ncase 1:\n\tswitch( (*p) ) {\n\t\tcase 36: goto tr0;\n\t\tcase 95: goto tr0;\n\t}\n\tif ( (*p) < 48 ) {\n\t\tif ( 45 <= (*p) && (*p) <= 46 )\n\t\t\tgoto tr0;\n\t} else if ( (*p) > 57 ) {\n\t\tif ( 65 <= (*p) && (*p) <= 90 )\n\t\t\tgoto tr0;\n\t} else\n\t\tgoto tr0;\n\tgoto st0;\nst0:\ncs = 0;\n\tgoto _out;\ntr0:\n#line 37 \"ext/puma_http11/http11_parser.rl\"\n\t{ MARK(mark, p); }\n\tgoto st2;\nst2:\n\tif ( ++p == pe )\n\t\tgoto _test_eof2;\ncase 2:\n#line 118 \"ext/puma_http11/http11_parser.c\"\n\tswitch( (*p) ) {\n\t\tcase 32: goto tr2;\n\t\tcase 36: goto st27;\n\t\tcase 95: goto st27;\n\t}\n\tif ( (*p) < 48 ) {\n\t\tif ( 45 <= (*p) && (*p) <= 46 )\n\t\t\tgoto st27;\n\t} else if ( (*p) > 57 ) {\n\t\tif ( 65 <= (*p) && (*p) <= 90 )\n\t\t\tgoto st27;\n\t} else\n\t\tgoto st27;\n\tgoto st0;\ntr2:\n#line 50 \"ext/puma_http11/http11_parser.rl\"\n\t{\n    parser->request_method(parser, PTR_TO(mark), LEN(mark, p));\n  }\n\tgoto st3;\nst3:\n\tif ( ++p == pe )\n\t\tgoto _test_eof3;\ncase 3:\n#line 143 \"ext/puma_http11/http11_parser.c\"\n\tswitch( (*p) ) {\n\t\tcase 42: goto tr4;\n\t\tcase 43: goto tr5;\n\t\tcase 47: goto tr6;\n\t\tcase 58: goto tr7;\n\t}\n\tif ( (*p) < 65 ) {\n\t\tif ( 45 <= (*p) && (*p) <= 57 )\n\t\t\tgoto tr5;\n\t} else if ( (*p) > 90 ) {\n\t\tif ( 97 <= (*p) && (*p) <= 122 )\n\t\t\tgoto tr5;\n\t} else\n\t\tgoto tr5;\n\tgoto st0;\ntr4:\n#line 37 \"ext/puma_http11/http11_parser.rl\"\n\t{ MARK(mark, p); }\n\tgoto st4;\nst4:\n\tif ( ++p == pe )\n\t\tgoto _test_eof4;\ncase 4:\n#line 167 \"ext/puma_http11/http11_parser.c\"\n\tswitch( (*p) ) {\n\t\tcase 32: goto tr8;\n\t\tcase 35: goto tr9;\n\t}\n\tgoto st0;\ntr8:\n#line 53 \"ext/puma_http11/http11_parser.rl\"\n\t{\n    parser->request_uri(parser, PTR_TO(mark), LEN(mark, p));\n  }\n\tgoto st5;\ntr31:\n#line 37 \"ext/puma_http11/http11_parser.rl\"\n\t{ MARK(mark, p); }\n#line 56 \"ext/puma_http11/http11_parser.rl\"\n\t{\n    parser->fragment(parser, PTR_TO(mark), LEN(mark, p));\n  }\n\tgoto st5;\ntr33:\n#line 56 \"ext/puma_http11/http11_parser.rl\"\n\t{\n    parser->fragment(parser, PTR_TO(mark), LEN(mark, p));\n  }\n\tgoto st5;\ntr37:\n#line 69 \"ext/puma_http11/http11_parser.rl\"\n\t{\n    parser->request_path(parser, PTR_TO(mark), LEN(mark,p));\n  }\n#line 53 \"ext/puma_http11/http11_parser.rl\"\n\t{\n    parser->request_uri(parser, PTR_TO(mark), LEN(mark, p));\n  }\n\tgoto st5;\ntr41:\n#line 60 \"ext/puma_http11/http11_parser.rl\"\n\t{ MARK(query_start, p); }\n#line 61 \"ext/puma_http11/http11_parser.rl\"\n\t{\n    parser->query_string(parser, PTR_TO(query_start), LEN(query_start, p));\n  }\n#line 53 \"ext/puma_http11/http11_parser.rl\"\n\t{\n    parser->request_uri(parser, PTR_TO(mark), LEN(mark, p));\n  }\n\tgoto st5;\ntr44:\n#line 61 \"ext/puma_http11/http11_parser.rl\"\n\t{\n    parser->query_string(parser, PTR_TO(query_start), LEN(query_start, p));\n  }\n#line 53 \"ext/puma_http11/http11_parser.rl\"\n\t{\n    parser->request_uri(parser, PTR_TO(mark), LEN(mark, p));\n  }\n\tgoto st5;\nst5:\n\tif ( ++p == pe )\n\t\tgoto _test_eof5;\ncase 5:\n#line 229 \"ext/puma_http11/http11_parser.c\"\n\tif ( (*p) == 72 )\n\t\tgoto tr10;\n\tgoto st0;\ntr10:\n#line 37 \"ext/puma_http11/http11_parser.rl\"\n\t{ MARK(mark, p); }\n\tgoto st6;\nst6:\n\tif ( ++p == pe )\n\t\tgoto _test_eof6;\ncase 6:\n#line 241 \"ext/puma_http11/http11_parser.c\"\n\tif ( (*p) == 84 )\n\t\tgoto st7;\n\tgoto st0;\nst7:\n\tif ( ++p == pe )\n\t\tgoto _test_eof7;\ncase 7:\n\tif ( (*p) == 84 )\n\t\tgoto st8;\n\tgoto st0;\nst8:\n\tif ( ++p == pe )\n\t\tgoto _test_eof8;\ncase 8:\n\tif ( (*p) == 80 )\n\t\tgoto st9;\n\tgoto st0;\nst9:\n\tif ( ++p == pe )\n\t\tgoto _test_eof9;\ncase 9:\n\tif ( (*p) == 47 )\n\t\tgoto st10;\n\tgoto st0;\nst10:\n\tif ( ++p == pe )\n\t\tgoto _test_eof10;\ncase 10:\n\tif ( 48 <= (*p) && (*p) <= 57 )\n\t\tgoto st11;\n\tgoto st0;\nst11:\n\tif ( ++p == pe )\n\t\tgoto _test_eof11;\ncase 11:\n\tif ( (*p) == 46 )\n\t\tgoto st12;\n\tif ( 48 <= (*p) && (*p) <= 57 )\n\t\tgoto st11;\n\tgoto st0;\nst12:\n\tif ( ++p == pe )\n\t\tgoto _test_eof12;\ncase 12:\n\tif ( 48 <= (*p) && (*p) <= 57 )\n\t\tgoto st13;\n\tgoto st0;\nst13:\n\tif ( ++p == pe )\n\t\tgoto _test_eof13;\ncase 13:\n\tif ( (*p) == 13 )\n\t\tgoto tr18;\n\tif ( 48 <= (*p) && (*p) <= 57 )\n\t\tgoto st13;\n\tgoto st0;\ntr18:\n#line 65 \"ext/puma_http11/http11_parser.rl\"\n\t{\n    parser->http_version(parser, PTR_TO(mark), LEN(mark, p));\n  }\n\tgoto st14;\ntr26:\n#line 46 \"ext/puma_http11/http11_parser.rl\"\n\t{ MARK(mark, p); }\n#line 47 \"ext/puma_http11/http11_parser.rl\"\n\t{\n    parser->http_field(parser, PTR_TO(field_start), parser->field_len, PTR_TO(mark), LEN(mark, p));\n  }\n\tgoto st14;\ntr29:\n#line 47 \"ext/puma_http11/http11_parser.rl\"\n\t{\n    parser->http_field(parser, PTR_TO(field_start), parser->field_len, PTR_TO(mark), LEN(mark, p));\n  }\n\tgoto st14;\nst14:\n\tif ( ++p == pe )\n\t\tgoto _test_eof14;\ncase 14:\n#line 322 \"ext/puma_http11/http11_parser.c\"\n\tif ( (*p) == 10 )\n\t\tgoto st15;\n\tgoto st0;\nst15:\n\tif ( ++p == pe )\n\t\tgoto _test_eof15;\ncase 15:\n\tswitch( (*p) ) {\n\t\tcase 13: goto st16;\n\t\tcase 33: goto tr21;\n\t\tcase 124: goto tr21;\n\t\tcase 126: goto tr21;\n\t}\n\tif ( (*p) < 45 ) {\n\t\tif ( (*p) > 39 ) {\n\t\t\tif ( 42 <= (*p) && (*p) <= 43 )\n\t\t\t\tgoto tr21;\n\t\t} else if ( (*p) >= 35 )\n\t\t\tgoto tr21;\n\t} else if ( (*p) > 46 ) {\n\t\tif ( (*p) < 65 ) {\n\t\t\tif ( 48 <= (*p) && (*p) <= 57 )\n\t\t\t\tgoto tr21;\n\t\t} else if ( (*p) > 90 ) {\n\t\t\tif ( 94 <= (*p) && (*p) <= 122 )\n\t\t\t\tgoto tr21;\n\t\t} else\n\t\t\tgoto tr21;\n\t} else\n\t\tgoto tr21;\n\tgoto st0;\nst16:\n\tif ( ++p == pe )\n\t\tgoto _test_eof16;\ncase 16:\n\tif ( (*p) == 10 )\n\t\tgoto tr22;\n\tgoto st0;\ntr22:\n#line 73 \"ext/puma_http11/http11_parser.rl\"\n\t{\n    parser->body_start = p - buffer + 1;\n    parser->header_done(parser, p + 1, pe - p - 1);\n    {p++; cs = 46; goto _out;}\n  }\n\tgoto st46;\nst46:\n\tif ( ++p == pe )\n\t\tgoto _test_eof46;\ncase 46:\n#line 373 \"ext/puma_http11/http11_parser.c\"\n\tgoto st0;\ntr21:\n#line 40 \"ext/puma_http11/http11_parser.rl\"\n\t{ MARK(field_start, p); }\n#line 41 \"ext/puma_http11/http11_parser.rl\"\n\t{ snake_upcase_char((char *)p); }\n\tgoto st17;\ntr23:\n#line 41 \"ext/puma_http11/http11_parser.rl\"\n\t{ snake_upcase_char((char *)p); }\n\tgoto st17;\nst17:\n\tif ( ++p == pe )\n\t\tgoto _test_eof17;\ncase 17:\n#line 389 \"ext/puma_http11/http11_parser.c\"\n\tswitch( (*p) ) {\n\t\tcase 33: goto tr23;\n\t\tcase 58: goto tr24;\n\t\tcase 124: goto tr23;\n\t\tcase 126: goto tr23;\n\t}\n\tif ( (*p) < 45 ) {\n\t\tif ( (*p) > 39 ) {\n\t\t\tif ( 42 <= (*p) && (*p) <= 43 )\n\t\t\t\tgoto tr23;\n\t\t} else if ( (*p) >= 35 )\n\t\t\tgoto tr23;\n\t} else if ( (*p) > 46 ) {\n\t\tif ( (*p) < 65 ) {\n\t\t\tif ( 48 <= (*p) && (*p) <= 57 )\n\t\t\t\tgoto tr23;\n\t\t} else if ( (*p) > 90 ) {\n\t\t\tif ( 94 <= (*p) && (*p) <= 122 )\n\t\t\t\tgoto tr23;\n\t\t} else\n\t\t\tgoto tr23;\n\t} else\n\t\tgoto tr23;\n\tgoto st0;\ntr24:\n#line 42 \"ext/puma_http11/http11_parser.rl\"\n\t{\n    parser->field_len = LEN(field_start, p);\n  }\n\tgoto st18;\ntr27:\n#line 46 \"ext/puma_http11/http11_parser.rl\"\n\t{ MARK(mark, p); }\n\tgoto st18;\nst18:\n\tif ( ++p == pe )\n\t\tgoto _test_eof18;\ncase 18:\n#line 428 \"ext/puma_http11/http11_parser.c\"\n\tswitch( (*p) ) {\n\t\tcase 13: goto tr26;\n\t\tcase 32: goto tr27;\n\t}\n\tgoto tr25;\ntr25:\n#line 46 \"ext/puma_http11/http11_parser.rl\"\n\t{ MARK(mark, p); }\n\tgoto st19;\nst19:\n\tif ( ++p == pe )\n\t\tgoto _test_eof19;\ncase 19:\n#line 442 \"ext/puma_http11/http11_parser.c\"\n\tif ( (*p) == 13 )\n\t\tgoto tr29;\n\tgoto st19;\ntr9:\n#line 53 \"ext/puma_http11/http11_parser.rl\"\n\t{\n    parser->request_uri(parser, PTR_TO(mark), LEN(mark, p));\n  }\n\tgoto st20;\ntr38:\n#line 69 \"ext/puma_http11/http11_parser.rl\"\n\t{\n    parser->request_path(parser, PTR_TO(mark), LEN(mark,p));\n  }\n#line 53 \"ext/puma_http11/http11_parser.rl\"\n\t{\n    parser->request_uri(parser, PTR_TO(mark), LEN(mark, p));\n  }\n\tgoto st20;\ntr42:\n#line 60 \"ext/puma_http11/http11_parser.rl\"\n\t{ MARK(query_start, p); }\n#line 61 \"ext/puma_http11/http11_parser.rl\"\n\t{\n    parser->query_string(parser, PTR_TO(query_start), LEN(query_start, p));\n  }\n#line 53 \"ext/puma_http11/http11_parser.rl\"\n\t{\n    parser->request_uri(parser, PTR_TO(mark), LEN(mark, p));\n  }\n\tgoto st20;\ntr45:\n#line 61 \"ext/puma_http11/http11_parser.rl\"\n\t{\n    parser->query_string(parser, PTR_TO(query_start), LEN(query_start, p));\n  }\n#line 53 \"ext/puma_http11/http11_parser.rl\"\n\t{\n    parser->request_uri(parser, PTR_TO(mark), LEN(mark, p));\n  }\n\tgoto st20;\nst20:\n\tif ( ++p == pe )\n\t\tgoto _test_eof20;\ncase 20:\n#line 488 \"ext/puma_http11/http11_parser.c\"\n\tswitch( (*p) ) {\n\t\tcase 32: goto tr31;\n\t\tcase 60: goto st0;\n\t\tcase 62: goto st0;\n\t\tcase 127: goto st0;\n\t}\n\tif ( (*p) > 31 ) {\n\t\tif ( 34 <= (*p) && (*p) <= 35 )\n\t\t\tgoto st0;\n\t} else if ( (*p) >= 0 )\n\t\tgoto st0;\n\tgoto tr30;\ntr30:\n#line 37 \"ext/puma_http11/http11_parser.rl\"\n\t{ MARK(mark, p); }\n\tgoto st21;\nst21:\n\tif ( ++p == pe )\n\t\tgoto _test_eof21;\ncase 21:\n#line 509 \"ext/puma_http11/http11_parser.c\"\n\tswitch( (*p) ) {\n\t\tcase 32: goto tr33;\n\t\tcase 60: goto st0;\n\t\tcase 62: goto st0;\n\t\tcase 127: goto st0;\n\t}\n\tif ( (*p) > 31 ) {\n\t\tif ( 34 <= (*p) && (*p) <= 35 )\n\t\t\tgoto st0;\n\t} else if ( (*p) >= 0 )\n\t\tgoto st0;\n\tgoto st21;\ntr5:\n#line 37 \"ext/puma_http11/http11_parser.rl\"\n\t{ MARK(mark, p); }\n\tgoto st22;\nst22:\n\tif ( ++p == pe )\n\t\tgoto _test_eof22;\ncase 22:\n#line 530 \"ext/puma_http11/http11_parser.c\"\n\tswitch( (*p) ) {\n\t\tcase 43: goto st22;\n\t\tcase 58: goto st23;\n\t}\n\tif ( (*p) < 48 ) {\n\t\tif ( 45 <= (*p) && (*p) <= 46 )\n\t\t\tgoto st22;\n\t} else if ( (*p) > 57 ) {\n\t\tif ( (*p) > 90 ) {\n\t\t\tif ( 97 <= (*p) && (*p) <= 122 )\n\t\t\t\tgoto st22;\n\t\t} else if ( (*p) >= 65 )\n\t\t\tgoto st22;\n\t} else\n\t\tgoto st22;\n\tgoto st0;\ntr7:\n#line 37 \"ext/puma_http11/http11_parser.rl\"\n\t{ MARK(mark, p); }\n\tgoto st23;\nst23:\n\tif ( ++p == pe )\n\t\tgoto _test_eof23;\ncase 23:\n#line 555 \"ext/puma_http11/http11_parser.c\"\n\tswitch( (*p) ) {\n\t\tcase 32: goto tr8;\n\t\tcase 34: goto st0;\n\t\tcase 35: goto tr9;\n\t\tcase 60: goto st0;\n\t\tcase 62: goto st0;\n\t\tcase 127: goto st0;\n\t}\n\tif ( 0 <= (*p) && (*p) <= 31 )\n\t\tgoto st0;\n\tgoto st23;\ntr6:\n#line 37 \"ext/puma_http11/http11_parser.rl\"\n\t{ MARK(mark, p); }\n\tgoto st24;\nst24:\n\tif ( ++p == pe )\n\t\tgoto _test_eof24;\ncase 24:\n#line 575 \"ext/puma_http11/http11_parser.c\"\n\tswitch( (*p) ) {\n\t\tcase 32: goto tr37;\n\t\tcase 34: goto st0;\n\t\tcase 35: goto tr38;\n\t\tcase 60: goto st0;\n\t\tcase 62: goto st0;\n\t\tcase 63: goto tr39;\n\t\tcase 127: goto st0;\n\t}\n\tif ( 0 <= (*p) && (*p) <= 31 )\n\t\tgoto st0;\n\tgoto st24;\ntr39:\n#line 69 \"ext/puma_http11/http11_parser.rl\"\n\t{\n    parser->request_path(parser, PTR_TO(mark), LEN(mark,p));\n  }\n\tgoto st25;\nst25:\n\tif ( ++p == pe )\n\t\tgoto _test_eof25;\ncase 25:\n#line 598 \"ext/puma_http11/http11_parser.c\"\n\tswitch( (*p) ) {\n\t\tcase 32: goto tr41;\n\t\tcase 34: goto st0;\n\t\tcase 35: goto tr42;\n\t\tcase 60: goto st0;\n\t\tcase 62: goto st0;\n\t\tcase 127: goto st0;\n\t}\n\tif ( 0 <= (*p) && (*p) <= 31 )\n\t\tgoto st0;\n\tgoto tr40;\ntr40:\n#line 60 \"ext/puma_http11/http11_parser.rl\"\n\t{ MARK(query_start, p); }\n\tgoto st26;\nst26:\n\tif ( ++p == pe )\n\t\tgoto _test_eof26;\ncase 26:\n#line 618 \"ext/puma_http11/http11_parser.c\"\n\tswitch( (*p) ) {\n\t\tcase 32: goto tr44;\n\t\tcase 34: goto st0;\n\t\tcase 35: goto tr45;\n\t\tcase 60: goto st0;\n\t\tcase 62: goto st0;\n\t\tcase 127: goto st0;\n\t}\n\tif ( 0 <= (*p) && (*p) <= 31 )\n\t\tgoto st0;\n\tgoto st26;\nst27:\n\tif ( ++p == pe )\n\t\tgoto _test_eof27;\ncase 27:\n\tswitch( (*p) ) {\n\t\tcase 32: goto tr2;\n\t\tcase 36: goto st28;\n\t\tcase 95: goto st28;\n\t}\n\tif ( (*p) < 48 ) {\n\t\tif ( 45 <= (*p) && (*p) <= 46 )\n\t\t\tgoto st28;\n\t} else if ( (*p) > 57 ) {\n\t\tif ( 65 <= (*p) && (*p) <= 90 )\n\t\t\tgoto st28;\n\t} else\n\t\tgoto st28;\n\tgoto st0;\nst28:\n\tif ( ++p == pe )\n\t\tgoto _test_eof28;\ncase 28:\n\tswitch( (*p) ) {\n\t\tcase 32: goto tr2;\n\t\tcase 36: goto st29;\n\t\tcase 95: goto st29;\n\t}\n\tif ( (*p) < 48 ) {\n\t\tif ( 45 <= (*p) && (*p) <= 46 )\n\t\t\tgoto st29;\n\t} else if ( (*p) > 57 ) {\n\t\tif ( 65 <= (*p) && (*p) <= 90 )\n\t\t\tgoto st29;\n\t} else\n\t\tgoto st29;\n\tgoto st0;\nst29:\n\tif ( ++p == pe )\n\t\tgoto _test_eof29;\ncase 29:\n\tswitch( (*p) ) {\n\t\tcase 32: goto tr2;\n\t\tcase 36: goto st30;\n\t\tcase 95: goto st30;\n\t}\n\tif ( (*p) < 48 ) {\n\t\tif ( 45 <= (*p) && (*p) <= 46 )\n\t\t\tgoto st30;\n\t} else if ( (*p) > 57 ) {\n\t\tif ( 65 <= (*p) && (*p) <= 90 )\n\t\t\tgoto st30;\n\t} else\n\t\tgoto st30;\n\tgoto st0;\nst30:\n\tif ( ++p == pe )\n\t\tgoto _test_eof30;\ncase 30:\n\tswitch( (*p) ) {\n\t\tcase 32: goto tr2;\n\t\tcase 36: goto st31;\n\t\tcase 95: goto st31;\n\t}\n\tif ( (*p) < 48 ) {\n\t\tif ( 45 <= (*p) && (*p) <= 46 )\n\t\t\tgoto st31;\n\t} else if ( (*p) > 57 ) {\n\t\tif ( 65 <= (*p) && (*p) <= 90 )\n\t\t\tgoto st31;\n\t} else\n\t\tgoto st31;\n\tgoto st0;\nst31:\n\tif ( ++p == pe )\n\t\tgoto _test_eof31;\ncase 31:\n\tswitch( (*p) ) {\n\t\tcase 32: goto tr2;\n\t\tcase 36: goto st32;\n\t\tcase 95: goto st32;\n\t}\n\tif ( (*p) < 48 ) {\n\t\tif ( 45 <= (*p) && (*p) <= 46 )\n\t\t\tgoto st32;\n\t} else if ( (*p) > 57 ) {\n\t\tif ( 65 <= (*p) && (*p) <= 90 )\n\t\t\tgoto st32;\n\t} else\n\t\tgoto st32;\n\tgoto st0;\nst32:\n\tif ( ++p == pe )\n\t\tgoto _test_eof32;\ncase 32:\n\tswitch( (*p) ) {\n\t\tcase 32: goto tr2;\n\t\tcase 36: goto st33;\n\t\tcase 95: goto st33;\n\t}\n\tif ( (*p) < 48 ) {\n\t\tif ( 45 <= (*p) && (*p) <= 46 )\n\t\t\tgoto st33;\n\t} else if ( (*p) > 57 ) {\n\t\tif ( 65 <= (*p) && (*p) <= 90 )\n\t\t\tgoto st33;\n\t} else\n\t\tgoto st33;\n\tgoto st0;\nst33:\n\tif ( ++p == pe )\n\t\tgoto _test_eof33;\ncase 33:\n\tswitch( (*p) ) {\n\t\tcase 32: goto tr2;\n\t\tcase 36: goto st34;\n\t\tcase 95: goto st34;\n\t}\n\tif ( (*p) < 48 ) {\n\t\tif ( 45 <= (*p) && (*p) <= 46 )\n\t\t\tgoto st34;\n\t} else if ( (*p) > 57 ) {\n\t\tif ( 65 <= (*p) && (*p) <= 90 )\n\t\t\tgoto st34;\n\t} else\n\t\tgoto st34;\n\tgoto st0;\nst34:\n\tif ( ++p == pe )\n\t\tgoto _test_eof34;\ncase 34:\n\tswitch( (*p) ) {\n\t\tcase 32: goto tr2;\n\t\tcase 36: goto st35;\n\t\tcase 95: goto st35;\n\t}\n\tif ( (*p) < 48 ) {\n\t\tif ( 45 <= (*p) && (*p) <= 46 )\n\t\t\tgoto st35;\n\t} else if ( (*p) > 57 ) {\n\t\tif ( 65 <= (*p) && (*p) <= 90 )\n\t\t\tgoto st35;\n\t} else\n\t\tgoto st35;\n\tgoto st0;\nst35:\n\tif ( ++p == pe )\n\t\tgoto _test_eof35;\ncase 35:\n\tswitch( (*p) ) {\n\t\tcase 32: goto tr2;\n\t\tcase 36: goto st36;\n\t\tcase 95: goto st36;\n\t}\n\tif ( (*p) < 48 ) {\n\t\tif ( 45 <= (*p) && (*p) <= 46 )\n\t\t\tgoto st36;\n\t} else if ( (*p) > 57 ) {\n\t\tif ( 65 <= (*p) && (*p) <= 90 )\n\t\t\tgoto st36;\n\t} else\n\t\tgoto st36;\n\tgoto st0;\nst36:\n\tif ( ++p == pe )\n\t\tgoto _test_eof36;\ncase 36:\n\tswitch( (*p) ) {\n\t\tcase 32: goto tr2;\n\t\tcase 36: goto st37;\n\t\tcase 95: goto st37;\n\t}\n\tif ( (*p) < 48 ) {\n\t\tif ( 45 <= (*p) && (*p) <= 46 )\n\t\t\tgoto st37;\n\t} else if ( (*p) > 57 ) {\n\t\tif ( 65 <= (*p) && (*p) <= 90 )\n\t\t\tgoto st37;\n\t} else\n\t\tgoto st37;\n\tgoto st0;\nst37:\n\tif ( ++p == pe )\n\t\tgoto _test_eof37;\ncase 37:\n\tswitch( (*p) ) {\n\t\tcase 32: goto tr2;\n\t\tcase 36: goto st38;\n\t\tcase 95: goto st38;\n\t}\n\tif ( (*p) < 48 ) {\n\t\tif ( 45 <= (*p) && (*p) <= 46 )\n\t\t\tgoto st38;\n\t} else if ( (*p) > 57 ) {\n\t\tif ( 65 <= (*p) && (*p) <= 90 )\n\t\t\tgoto st38;\n\t} else\n\t\tgoto st38;\n\tgoto st0;\nst38:\n\tif ( ++p == pe )\n\t\tgoto _test_eof38;\ncase 38:\n\tswitch( (*p) ) {\n\t\tcase 32: goto tr2;\n\t\tcase 36: goto st39;\n\t\tcase 95: goto st39;\n\t}\n\tif ( (*p) < 48 ) {\n\t\tif ( 45 <= (*p) && (*p) <= 46 )\n\t\t\tgoto st39;\n\t} else if ( (*p) > 57 ) {\n\t\tif ( 65 <= (*p) && (*p) <= 90 )\n\t\t\tgoto st39;\n\t} else\n\t\tgoto st39;\n\tgoto st0;\nst39:\n\tif ( ++p == pe )\n\t\tgoto _test_eof39;\ncase 39:\n\tswitch( (*p) ) {\n\t\tcase 32: goto tr2;\n\t\tcase 36: goto st40;\n\t\tcase 95: goto st40;\n\t}\n\tif ( (*p) < 48 ) {\n\t\tif ( 45 <= (*p) && (*p) <= 46 )\n\t\t\tgoto st40;\n\t} else if ( (*p) > 57 ) {\n\t\tif ( 65 <= (*p) && (*p) <= 90 )\n\t\t\tgoto st40;\n\t} else\n\t\tgoto st40;\n\tgoto st0;\nst40:\n\tif ( ++p == pe )\n\t\tgoto _test_eof40;\ncase 40:\n\tswitch( (*p) ) {\n\t\tcase 32: goto tr2;\n\t\tcase 36: goto st41;\n\t\tcase 95: goto st41;\n\t}\n\tif ( (*p) < 48 ) {\n\t\tif ( 45 <= (*p) && (*p) <= 46 )\n\t\t\tgoto st41;\n\t} else if ( (*p) > 57 ) {\n\t\tif ( 65 <= (*p) && (*p) <= 90 )\n\t\t\tgoto st41;\n\t} else\n\t\tgoto st41;\n\tgoto st0;\nst41:\n\tif ( ++p == pe )\n\t\tgoto _test_eof41;\ncase 41:\n\tswitch( (*p) ) {\n\t\tcase 32: goto tr2;\n\t\tcase 36: goto st42;\n\t\tcase 95: goto st42;\n\t}\n\tif ( (*p) < 48 ) {\n\t\tif ( 45 <= (*p) && (*p) <= 46 )\n\t\t\tgoto st42;\n\t} else if ( (*p) > 57 ) {\n\t\tif ( 65 <= (*p) && (*p) <= 90 )\n\t\t\tgoto st42;\n\t} else\n\t\tgoto st42;\n\tgoto st0;\nst42:\n\tif ( ++p == pe )\n\t\tgoto _test_eof42;\ncase 42:\n\tswitch( (*p) ) {\n\t\tcase 32: goto tr2;\n\t\tcase 36: goto st43;\n\t\tcase 95: goto st43;\n\t}\n\tif ( (*p) < 48 ) {\n\t\tif ( 45 <= (*p) && (*p) <= 46 )\n\t\t\tgoto st43;\n\t} else if ( (*p) > 57 ) {\n\t\tif ( 65 <= (*p) && (*p) <= 90 )\n\t\t\tgoto st43;\n\t} else\n\t\tgoto st43;\n\tgoto st0;\nst43:\n\tif ( ++p == pe )\n\t\tgoto _test_eof43;\ncase 43:\n\tswitch( (*p) ) {\n\t\tcase 32: goto tr2;\n\t\tcase 36: goto st44;\n\t\tcase 95: goto st44;\n\t}\n\tif ( (*p) < 48 ) {\n\t\tif ( 45 <= (*p) && (*p) <= 46 )\n\t\t\tgoto st44;\n\t} else if ( (*p) > 57 ) {\n\t\tif ( 65 <= (*p) && (*p) <= 90 )\n\t\t\tgoto st44;\n\t} else\n\t\tgoto st44;\n\tgoto st0;\nst44:\n\tif ( ++p == pe )\n\t\tgoto _test_eof44;\ncase 44:\n\tswitch( (*p) ) {\n\t\tcase 32: goto tr2;\n\t\tcase 36: goto st45;\n\t\tcase 95: goto st45;\n\t}\n\tif ( (*p) < 48 ) {\n\t\tif ( 45 <= (*p) && (*p) <= 46 )\n\t\t\tgoto st45;\n\t} else if ( (*p) > 57 ) {\n\t\tif ( 65 <= (*p) && (*p) <= 90 )\n\t\t\tgoto st45;\n\t} else\n\t\tgoto st45;\n\tgoto st0;\nst45:\n\tif ( ++p == pe )\n\t\tgoto _test_eof45;\ncase 45:\n\tif ( (*p) == 32 )\n\t\tgoto tr2;\n\tgoto st0;\n\t}\n\t_test_eof2: cs = 2; goto _test_eof; \n\t_test_eof3: cs = 3; goto _test_eof; \n\t_test_eof4: cs = 4; goto _test_eof; \n\t_test_eof5: cs = 5; goto _test_eof; \n\t_test_eof6: cs = 6; goto _test_eof; \n\t_test_eof7: cs = 7; goto _test_eof; \n\t_test_eof8: cs = 8; goto _test_eof; \n\t_test_eof9: cs = 9; goto _test_eof; \n\t_test_eof10: cs = 10; goto _test_eof; \n\t_test_eof11: cs = 11; goto _test_eof; \n\t_test_eof12: cs = 12; goto _test_eof; \n\t_test_eof13: cs = 13; goto _test_eof; \n\t_test_eof14: cs = 14; goto _test_eof; \n\t_test_eof15: cs = 15; goto _test_eof; \n\t_test_eof16: cs = 16; goto _test_eof; \n\t_test_eof46: cs = 46; goto _test_eof; \n\t_test_eof17: cs = 17; goto _test_eof; \n\t_test_eof18: cs = 18; goto _test_eof; \n\t_test_eof19: cs = 19; goto _test_eof; \n\t_test_eof20: cs = 20; goto _test_eof; \n\t_test_eof21: cs = 21; goto _test_eof; \n\t_test_eof22: cs = 22; goto _test_eof; \n\t_test_eof23: cs = 23; goto _test_eof; \n\t_test_eof24: cs = 24; goto _test_eof; \n\t_test_eof25: cs = 25; goto _test_eof; \n\t_test_eof26: cs = 26; goto _test_eof; \n\t_test_eof27: cs = 27; goto _test_eof; \n\t_test_eof28: cs = 28; goto _test_eof; \n\t_test_eof29: cs = 29; goto _test_eof; \n\t_test_eof30: cs = 30; goto _test_eof; \n\t_test_eof31: cs = 31; goto _test_eof; \n\t_test_eof32: cs = 32; goto _test_eof; \n\t_test_eof33: cs = 33; goto _test_eof; \n\t_test_eof34: cs = 34; goto _test_eof; \n\t_test_eof35: cs = 35; goto _test_eof; \n\t_test_eof36: cs = 36; goto _test_eof; \n\t_test_eof37: cs = 37; goto _test_eof; \n\t_test_eof38: cs = 38; goto _test_eof; \n\t_test_eof39: cs = 39; goto _test_eof; \n\t_test_eof40: cs = 40; goto _test_eof; \n\t_test_eof41: cs = 41; goto _test_eof; \n\t_test_eof42: cs = 42; goto _test_eof; \n\t_test_eof43: cs = 43; goto _test_eof; \n\t_test_eof44: cs = 44; goto _test_eof; \n\t_test_eof45: cs = 45; goto _test_eof; \n\n\t_test_eof: {}\n\t_out: {}\n\t}\n\n#line 117 \"ext/puma_http11/http11_parser.rl\"\n\n  if (!puma_parser_has_error(parser))\n    parser->cs = cs;\n  parser->nread += p - (buffer + off);\n\n  assert(p <= pe && \"buffer overflow after parsing execute\");\n  assert(parser->nread <= len && \"nread longer than length\");\n  assert(parser->body_start <= len && \"body starts after buffer end\");\n  assert(parser->mark < len && \"mark is after buffer end\");\n  assert(parser->field_len <= len && \"field has length longer than whole buffer\");\n  assert(parser->field_start < len && \"field starts after buffer end\");\n\n  return(parser->nread);\n}",
        "func_hash": 94439113710401505299900606066823977917,
        "file_name": "http11_parser.c",
        "file_hash": 59830834973701402944362779116096200943,
        "cwe": [
            "CWE-444"
        ],
        "cve": "CVE-2021-41136",
        "cve_desc": "Puma is a HTTP 1.1 server for Ruby/Rack applications. Prior to versions 5.5.1 and 4.3.9, using `puma` with a proxy which forwards HTTP header values which contain the LF character could allow HTTP request smugggling. A client could smuggle a request through a proxy, causing the proxy to send a response back to another unknown client. The only proxy which has this behavior, as far as the Puma team is aware of, is Apache Traffic Server. If the proxy uses persistent connections and the client adds another request in via HTTP pipelining, the proxy may mistake it as the first request's body. Puma, however, would see it as two requests, and when processing the second request, send back a response that the proxy does not expect. If the proxy has reused the persistent connection to Puma to send another request for a different client, the second response from the first client will be sent to the second client. This vulnerability was patched in Puma 5.5.1 and 4.3.9. As a workaround, do not use Apache Traffic Server with `puma`.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-41136",
        "func_name": "puma_parser_execute",
        "diff": [
            "diff --git a/History.md b/History.md\nindex be3d97d552..f2c72b3bca 100644\n--- a/History.md\n+++ b/History.md\n@@ -1,3 +1,8 @@\n+## 5.5.1 / 2021-10-12\n+\n+* Security\n+  * Do not allow LF as a line ending in a header (CVE-2021-41136)\n+\n ## 5.5.0 / 2021-09-19\n \n * Features\n@@ -251,6 +256,11 @@\n   * Support parallel tests in verbose progress reporting ([#2223])\n   * Refactor error handling in server accept loop ([#2239])\n \n+## 4.3.9 / 2021-10-12\n+\n+* Security\n+  * Do not allow LF as a line ending in a header (CVE-2021-41136)\n+\n ## 4.3.8 / 2021-05-11\n \n * Security\ndiff --git a/ext/puma_http11/http11_parser.c b/ext/puma_http11/http11_parser.c\nindex 2da0263e3e..6c571b34ee 100644\n--- a/ext/puma_http11/http11_parser.c\n+++ b/ext/puma_http11/http11_parser.c\n@@ -426,10 +426,13 @@ case 17:\n case 18:\n #line 428 \"ext/puma_http11/http11_parser.c\"\n \tswitch( (*p) ) {\n+\t\tcase 9: goto tr25;\n \t\tcase 13: goto tr26;\n \t\tcase 32: goto tr27;\n \t}\n-\tgoto tr25;\n+\tif ( 33 <= (*p) && (*p) <= 126 )\n+\t\tgoto tr25;\n+\tgoto st0;\n tr25:\n #line 46 \"ext/puma_http11/http11_parser.rl\"\n \t{ MARK(mark, p); }\n@@ -438,10 +441,14 @@ case 18:\n \tif ( ++p == pe )\n \t\tgoto _test_eof19;\n case 19:\n-#line 442 \"ext/puma_http11/http11_parser.c\"\n-\tif ( (*p) == 13 )\n-\t\tgoto tr29;\n-\tgoto st19;\n+#line 445 \"ext/puma_http11/http11_parser.c\"\n+\tswitch( (*p) ) {\n+\t\tcase 9: goto st19;\n+\t\tcase 13: goto tr29;\n+\t}\n+\tif ( 32 <= (*p) && (*p) <= 126 )\n+\t\tgoto st19;\n+\tgoto st0;\n tr9:\n #line 53 \"ext/puma_http11/http11_parser.rl\"\n \t{\n@@ -484,7 +491,7 @@ case 19:\n \tif ( ++p == pe )\n \t\tgoto _test_eof20;\n case 20:\n-#line 488 \"ext/puma_http11/http11_parser.c\"\n+#line 495 \"ext/puma_http11/http11_parser.c\"\n \tswitch( (*p) ) {\n \t\tcase 32: goto tr31;\n \t\tcase 60: goto st0;\n@@ -505,7 +512,7 @@ case 20:\n \tif ( ++p == pe )\n \t\tgoto _test_eof21;\n case 21:\n-#line 509 \"ext/puma_http11/http11_parser.c\"\n+#line 516 \"ext/puma_http11/http11_parser.c\"\n \tswitch( (*p) ) {\n \t\tcase 32: goto tr33;\n \t\tcase 60: goto st0;\n@@ -526,7 +533,7 @@ case 21:\n \tif ( ++p == pe )\n \t\tgoto _test_eof22;\n case 22:\n-#line 530 \"ext/puma_http11/http11_parser.c\"\n+#line 537 \"ext/puma_http11/http11_parser.c\"\n \tswitch( (*p) ) {\n \t\tcase 43: goto st22;\n \t\tcase 58: goto st23;\n@@ -551,7 +558,7 @@ case 22:\n \tif ( ++p == pe )\n \t\tgoto _test_eof23;\n case 23:\n-#line 555 \"ext/puma_http11/http11_parser.c\"\n+#line 562 \"ext/puma_http11/http11_parser.c\"\n \tswitch( (*p) ) {\n \t\tcase 32: goto tr8;\n \t\tcase 34: goto st0;\n@@ -571,7 +578,7 @@ case 23:\n \tif ( ++p == pe )\n \t\tgoto _test_eof24;\n case 24:\n-#line 575 \"ext/puma_http11/http11_parser.c\"\n+#line 582 \"ext/puma_http11/http11_parser.c\"\n \tswitch( (*p) ) {\n \t\tcase 32: goto tr37;\n \t\tcase 34: goto st0;\n@@ -594,7 +601,7 @@ case 24:\n \tif ( ++p == pe )\n \t\tgoto _test_eof25;\n case 25:\n-#line 598 \"ext/puma_http11/http11_parser.c\"\n+#line 605 \"ext/puma_http11/http11_parser.c\"\n \tswitch( (*p) ) {\n \t\tcase 32: goto tr41;\n \t\tcase 34: goto st0;\n@@ -614,7 +621,7 @@ case 25:\n \tif ( ++p == pe )\n \t\tgoto _test_eof26;\n case 26:\n-#line 618 \"ext/puma_http11/http11_parser.c\"\n+#line 625 \"ext/puma_http11/http11_parser.c\"\n \tswitch( (*p) ) {\n \t\tcase 32: goto tr44;\n \t\tcase 34: goto st0;\ndiff --git a/ext/puma_http11/http11_parser_common.rl b/ext/puma_http11/http11_parser_common.rl\nindex ba5f8a56d6..5eba09f2c0 100644\n--- a/ext/puma_http11/http11_parser_common.rl\n+++ b/ext/puma_http11/http11_parser_common.rl\n@@ -43,7 +43,7 @@\n \n   field_name = ( token -- \":\" )+ >start_field $snake_upcase_field %write_field;\n \n-  field_value = any* >start_value %write_value;\n+  field_value = ( print | \"\\t\" )* >start_value %write_value;\n \n   message_header = field_name \":\" \" \"* field_value :> CRLF;\n \ndiff --git a/ext/puma_http11/org/jruby/puma/Http11Parser.java b/ext/puma_http11/org/jruby/puma/Http11Parser.java\nindex 0bba664f4e..f5db1b6987 100644\n--- a/ext/puma_http11/org/jruby/puma/Http11Parser.java\n+++ b/ext/puma_http11/org/jruby/puma/Http11Parser.java\n@@ -34,9 +34,9 @@ private static short[] init__puma_parser_key_offsets_0()\n {\n \treturn new short [] {\n \t    0,    0,    8,   17,   27,   29,   30,   31,   32,   33,   34,   36,\n-\t   39,   41,   44,   45,   61,   62,   78,   80,   81,   89,   97,  107,\n-\t  115,  124,  132,  140,  149,  158,  167,  176,  185,  194,  203,  212,\n-\t  221,  230,  239,  248,  257,  266,  275,  284,  293,  302,  303\n+\t   39,   41,   44,   45,   61,   62,   78,   83,   87,   95,  103,  113,\n+\t  121,  130,  138,  146,  155,  164,  173,  182,  191,  200,  209,  218,\n+\t  227,  236,  245,  254,  263,  272,  281,  290,  299,  308,  309\n \t};\n }\n \n@@ -52,14 +52,13 @@ private static char[] init__puma_parser_trans_keys_0()\n \t   46,   48,   57,   48,   57,   13,   48,   57,   10,   13,   33,  124,\n \t  126,   35,   39,   42,   43,   45,   46,   48,   57,   65,   90,   94,\n \t  122,   10,   33,   58,  124,  126,   35,   39,   42,   43,   45,   46,\n-\t   48,   57,   65,   90,   94,  122,   13,   32,   13,   32,   60,   62,\n-\t  127,    0,   31,   34,   35,   32,   60,   62,  127,    0,   31,   34,\n-\t   35,   43,   58,   45,   46,   48,   57,   65,   90,   97,  122,   32,\n-\t   34,   35,   60,   62,  127,    0,   31,   32,   34,   35,   60,   62,\n-\t   63,  127,    0,   31,   32,   34,   35,   60,   62,  127,    0,   31,\n-\t   32,   34,   35,   60,   62,  127,    0,   31,   32,   36,   95,   45,\n-\t   46,   48,   57,   65,   90,   32,   36,   95,   45,   46,   48,   57,\n-\t   65,   90,   32,   36,   95,   45,   46,   48,   57,   65,   90,   32,\n+\t   48,   57,   65,   90,   94,  122,    9,   13,   32,   33,  126,    9,\n+\t   13,   32,  126,   32,   60,   62,  127,    0,   31,   34,   35,   32,\n+\t   60,   62,  127,    0,   31,   34,   35,   43,   58,   45,   46,   48,\n+\t   57,   65,   90,   97,  122,   32,   34,   35,   60,   62,  127,    0,\n+\t   31,   32,   34,   35,   60,   62,   63,  127,    0,   31,   32,   34,\n+\t   35,   60,   62,  127,    0,   31,   32,   34,   35,   60,   62,  127,\n+\t    0,   31,   32,   36,   95,   45,   46,   48,   57,   65,   90,   32,\n \t   36,   95,   45,   46,   48,   57,   65,   90,   32,   36,   95,   45,\n \t   46,   48,   57,   65,   90,   32,   36,   95,   45,   46,   48,   57,\n \t   65,   90,   32,   36,   95,   45,   46,   48,   57,   65,   90,   32,\n@@ -71,7 +70,8 @@ private static char[] init__puma_parser_trans_keys_0()\n \t   65,   90,   32,   36,   95,   45,   46,   48,   57,   65,   90,   32,\n \t   36,   95,   45,   46,   48,   57,   65,   90,   32,   36,   95,   45,\n \t   46,   48,   57,   65,   90,   32,   36,   95,   45,   46,   48,   57,\n-\t   65,   90,   32,    0\n+\t   65,   90,   32,   36,   95,   45,   46,   48,   57,   65,   90,   32,\n+\t   36,   95,   45,   46,   48,   57,   65,   90,   32,    0\n \t};\n }\n \n@@ -82,7 +82,7 @@ private static byte[] init__puma_parser_single_lengths_0()\n {\n \treturn new byte [] {\n \t    0,    2,    3,    4,    2,    1,    1,    1,    1,    1,    0,    1,\n-\t    0,    1,    1,    4,    1,    4,    2,    1,    4,    4,    2,    6,\n+\t    0,    1,    1,    4,    1,    4,    3,    2,    4,    4,    2,    6,\n \t    7,    6,    6,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n \t    3,    3,    3,    3,    3,    3,    3,    3,    3,    1,    0\n \t};\n@@ -95,7 +95,7 @@ private static byte[] init__puma_parser_range_lengths_0()\n {\n \treturn new byte [] {\n \t    0,    3,    3,    3,    0,    0,    0,    0,    0,    0,    1,    1,\n-\t    1,    1,    0,    6,    0,    6,    0,    0,    2,    2,    4,    1,\n+\t    1,    1,    0,    6,    0,    6,    1,    1,    2,    2,    4,    1,\n \t    1,    1,    1,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n \t    3,    3,    3,    3,    3,    3,    3,    3,    3,    0,    0\n \t};\n@@ -108,9 +108,9 @@ private static short[] init__puma_parser_index_offsets_0()\n {\n \treturn new short [] {\n \t    0,    0,    6,   13,   21,   24,   26,   28,   30,   32,   34,   36,\n-\t   39,   41,   44,   46,   57,   59,   70,   73,   75,   82,   89,   96,\n-\t  104,  113,  121,  129,  136,  143,  150,  157,  164,  171,  178,  185,\n-\t  192,  199,  206,  213,  220,  227,  234,  241,  248,  255,  257\n+\t   39,   41,   44,   46,   57,   59,   70,   75,   79,   86,   93,  100,\n+\t  108,  117,  125,  133,  140,  147,  154,  161,  168,  175,  182,  189,\n+\t  196,  203,  210,  217,  224,  231,  238,  245,  252,  259,  261\n \t};\n }\n \n@@ -125,23 +125,23 @@ private static byte[] init__puma_parser_indicies_0()\n \t   10,    1,   11,    1,   12,    1,   13,    1,   14,    1,   15,    1,\n \t   16,   15,    1,   17,    1,   18,   17,    1,   19,    1,   20,   21,\n \t   21,   21,   21,   21,   21,   21,   21,   21,    1,   22,    1,   23,\n-\t   24,   23,   23,   23,   23,   23,   23,   23,   23,    1,   26,   27,\n-\t   25,   29,   28,   30,    1,    1,    1,    1,    1,   31,   32,    1,\n-\t    1,    1,    1,    1,   33,   34,   35,   34,   34,   34,   34,    1,\n-\t    8,    1,    9,    1,    1,    1,    1,   35,   36,    1,   38,    1,\n-\t    1,   39,    1,    1,   37,   40,    1,   42,    1,    1,    1,    1,\n-\t   41,   43,    1,   45,    1,    1,    1,    1,   44,    2,   46,   46,\n-\t   46,   46,   46,    1,    2,   47,   47,   47,   47,   47,    1,    2,\n-\t   48,   48,   48,   48,   48,    1,    2,   49,   49,   49,   49,   49,\n-\t    1,    2,   50,   50,   50,   50,   50,    1,    2,   51,   51,   51,\n-\t   51,   51,    1,    2,   52,   52,   52,   52,   52,    1,    2,   53,\n-\t   53,   53,   53,   53,    1,    2,   54,   54,   54,   54,   54,    1,\n-\t    2,   55,   55,   55,   55,   55,    1,    2,   56,   56,   56,   56,\n-\t   56,    1,    2,   57,   57,   57,   57,   57,    1,    2,   58,   58,\n-\t   58,   58,   58,    1,    2,   59,   59,   59,   59,   59,    1,    2,\n-\t   60,   60,   60,   60,   60,    1,    2,   61,   61,   61,   61,   61,\n-\t    1,    2,   62,   62,   62,   62,   62,    1,    2,   63,   63,   63,\n-\t   63,   63,    1,    2,    1,    1,    0\n+\t   24,   23,   23,   23,   23,   23,   23,   23,   23,    1,   25,   26,\n+\t   27,   25,    1,   28,   29,   28,    1,   30,    1,    1,    1,    1,\n+\t    1,   31,   32,    1,    1,    1,    1,    1,   33,   34,   35,   34,\n+\t   34,   34,   34,    1,    8,    1,    9,    1,    1,    1,    1,   35,\n+\t   36,    1,   38,    1,    1,   39,    1,    1,   37,   40,    1,   42,\n+\t    1,    1,    1,    1,   41,   43,    1,   45,    1,    1,    1,    1,\n+\t   44,    2,   46,   46,   46,   46,   46,    1,    2,   47,   47,   47,\n+\t   47,   47,    1,    2,   48,   48,   48,   48,   48,    1,    2,   49,\n+\t   49,   49,   49,   49,    1,    2,   50,   50,   50,   50,   50,    1,\n+\t    2,   51,   51,   51,   51,   51,    1,    2,   52,   52,   52,   52,\n+\t   52,    1,    2,   53,   53,   53,   53,   53,    1,    2,   54,   54,\n+\t   54,   54,   54,    1,    2,   55,   55,   55,   55,   55,    1,    2,\n+\t   56,   56,   56,   56,   56,    1,    2,   57,   57,   57,   57,   57,\n+\t    1,    2,   58,   58,   58,   58,   58,    1,    2,   59,   59,   59,\n+\t   59,   59,    1,    2,   60,   60,   60,   60,   60,    1,    2,   61,\n+\t   61,   61,   61,   61,    1,    2,   62,   62,   62,   62,   62,    1,\n+\t    2,   63,   63,   63,   63,   63,    1,    2,    1,    1,    0\n \t};\n }\n \ndiff --git a/lib/puma/const.rb b/lib/puma/const.rb\nindex dbe42b21c0..24528572d6 100644\n--- a/lib/puma/const.rb\n+++ b/lib/puma/const.rb\n@@ -100,7 +100,7 @@ class UnsupportedOption < RuntimeError\n   # too taxing on performance.\n   module Const\n \n-    PUMA_VERSION = VERSION = \"5.5.0\".freeze\n+    PUMA_VERSION = VERSION = \"5.5.1\".freeze\n     CODE_NAME = \"Zawgyi\".freeze\n \n     PUMA_SERVER_STRING = ['puma', PUMA_VERSION, CODE_NAME].join(' ').freeze\ndiff --git a/test/test_http11.rb b/test/test_http11.rb\nindex 9e49b7b376..1d7f11589e 100644\n--- a/test/test_http11.rb\n+++ b/test/test_http11.rb\n@@ -208,4 +208,34 @@ def test_trims_whitespace_from_headers\n \n     assert_equal \"Strip This\", req[\"HTTP_X_STRIP_ME\"]\n   end\n+\n+  def test_newline_smuggler\n+    parser = Puma::HttpParser.new\n+    req = {}\n+    http = \"GET / HTTP/1.1\\r\\nHost: localhost:8080\\r\\nDummy: x\\nDummy2: y\\r\\n\\r\\n\"\n+\n+    parser.execute(req, http, 0) rescue nil # We test the raise elsewhere.\n+\n+    assert parser.error?, \"Parser SHOULD have error\"\n+  end\n+\n+  def test_newline_smuggler_two\n+    parser = Puma::HttpParser.new\n+    req = {}\n+    http = \"GET / HTTP/1.1\\r\\nHost: localhost:8080\\r\\nDummy: x\\r\\nDummy: y\\nDummy2: z\\r\\n\\r\\n\"\n+\n+    parser.execute(req, http, 0) rescue nil\n+\n+    assert parser.error?, \"Parser SHOULD have error\"\n+  end\n+\n+  def test_htab_in_header_val\n+    parser = Puma::HttpParser.new\n+    req = {}\n+    http = \"GET / HTTP/1.1\\r\\nHost: localhost:8080\\r\\nDummy: Valid\\tValue\\r\\n\\r\\n\"\n+\n+    parser.execute(req, http, 0)\n+\n+    assert_equal \"Valid\\tValue\", req['HTTP_DUMMY']\n+  end\n end\n"
        ],
        "func_after": []
    },
    {
        "idx": 199833,
        "project": "chafa",
        "commit_id": "e4b777c7b7c144cd16a0ea96108267b1004fe6c9",
        "project_url": "https://github.com/hpjansson/chafa",
        "commit_url": "https://github.com/hpjansson/chafa/commit/e4b777c7b7c144cd16a0ea96108267b1004fe6c9",
        "commit_message": "libnsgif: Fix null pointer deref on frameless GIF input\n\nA crafted GIF file with no frame data could cause a null pointer\ndereference leading to denial of service (crash). Reported by\n@JieyongMa via huntr.dev.",
        "target": 1,
        "irrelevant": 1,
        "func_before": "gif_internal_decode_frame(gif_animation *gif,\n                          unsigned int frame,\n                          bool clear_image)\n{\n        unsigned int index = 0;\n        const unsigned char *gif_data, *gif_end;\n        ssize_t gif_bytes;\n        unsigned int width, height, offset_x, offset_y;\n        unsigned int flags, colour_table_size, interlace;\n        unsigned int *colour_table;\n        unsigned int *frame_data = 0;\t// Set to 0 for no warnings\n        unsigned int *frame_scanline;\n        ssize_t save_buffer_position;\n        unsigned int return_value = 0;\n        unsigned int x, y, decode_y, burst_bytes;\n        register unsigned char colour;\n\n        /* Ensure this frame is supposed to be decoded */\n        if (gif->frames[frame].display == false) {\n                return GIF_OK;\n        }\n\n        /* Ensure the frame is in range to decode */\n        if (frame > gif->frame_count_partial) {\n                return GIF_INSUFFICIENT_DATA;\n        }\n\n        /* done if frame is already decoded */\n        if ((!clear_image) &&\n            ((int)frame == gif->decoded_frame)) {\n                return GIF_OK;\n        }\n\n        /* Get the start of our frame data and the end of the GIF data */\n        gif_data = gif->gif_data + gif->frames[frame].frame_pointer;\n        gif_end = gif->gif_data + gif->buffer_size;\n        gif_bytes = (gif_end - gif_data);\n\n        /*\n         * Ensure there is a minimal amount of data to proceed.  The shortest\n         * block of data is a 10-byte image descriptor + 1-byte gif trailer\n         */\n        if (gif_bytes < 12) {\n                return GIF_INSUFFICIENT_FRAME_DATA;\n        }\n\n        /* Save the buffer position */\n        save_buffer_position = gif->buffer_position;\n        gif->buffer_position = gif_data - gif->gif_data;\n\n        /* Skip any extensions because they have allready been processed */\n        if ((return_value = gif_skip_frame_extensions(gif)) != GIF_OK) {\n                goto gif_decode_frame_exit;\n        }\n        gif_data = (gif->gif_data + gif->buffer_position);\n        gif_bytes = (gif_end - gif_data);\n\n        /* Ensure we have enough data for the 10-byte image descriptor + 1-byte\n         * gif trailer\n         */\n        if (gif_bytes < 12) {\n                return_value = GIF_INSUFFICIENT_FRAME_DATA;\n                goto gif_decode_frame_exit;\n        }\n\n        /* 10-byte Image Descriptor is:\n         *\n         *\t+0\tCHAR\tImage Separator (0x2c)\n         *\t+1\tSHORT\tImage Left Position\n         *\t+3\tSHORT\tImage Top Position\n         *\t+5\tSHORT\tWidth\n         *\t+7\tSHORT\tHeight\n         *\t+9\tCHAR\t__Packed Fields__\n         *\t\t\t1BIT\tLocal Colour Table Flag\n         *\t\t\t1BIT\tInterlace Flag\n         *\t\t\t1BIT\tSort Flag\n         *\t\t\t2BITS\tReserved\n         *\t\t\t3BITS\tSize of Local Colour Table\n         */\n        if (gif_data[0] != GIF_IMAGE_SEPARATOR) {\n                return_value = GIF_DATA_ERROR;\n                goto gif_decode_frame_exit;\n        }\n        offset_x = gif_data[1] | (gif_data[2] << 8);\n        offset_y = gif_data[3] | (gif_data[4] << 8);\n        width = gif_data[5] | (gif_data[6] << 8);\n        height = gif_data[7] | (gif_data[8] << 8);\n\n        /* Boundary checking - shouldn't ever happen except unless the data has\n         * been modified since initialisation.\n         */\n        if ((offset_x + width > gif->width) ||\n            (offset_y + height > gif->height)) {\n                return_value = GIF_DATA_ERROR;\n                goto gif_decode_frame_exit;\n        }\n\n        /* Decode the flags */\n        flags = gif_data[9];\n        colour_table_size = 2 << (flags & GIF_COLOUR_TABLE_SIZE_MASK);\n        interlace = flags & GIF_INTERLACE_MASK;\n\n        /* Advance data pointer to next block either colour table or image\n         * data.\n         */\n        gif_data += 10;\n        gif_bytes = (gif_end - gif_data);\n\n        /* Set up the colour table */\n        if (flags & GIF_COLOUR_TABLE_MASK) {\n                if (gif_bytes < (int)(3 * colour_table_size)) {\n                        return_value = GIF_INSUFFICIENT_FRAME_DATA;\n                        goto gif_decode_frame_exit;\n                }\n                colour_table = gif->local_colour_table;\n                if (!clear_image) {\n                        for (index = 0; index < colour_table_size; index++) {\n                                /* Gif colour map contents are r,g,b.\n                                 *\n                                 * We want to pack them bytewise into the\n                                 * colour table, such that the red component\n                                 * is in byte 0 and the alpha component is in\n                                 * byte 3.\n                                 */\n                                unsigned char *entry =\n                                        (unsigned char *) &colour_table[index];\n\n                                entry[0] = gif_data[0];\t/* r */\n                                entry[1] = gif_data[1];\t/* g */\n                                entry[2] = gif_data[2];\t/* b */\n                                entry[3] = 0xff;\t/* a */\n\n                                gif_data += 3;\n                        }\n                } else {\n                        gif_data += 3 * colour_table_size;\n                }\n                gif_bytes = (gif_end - gif_data);\n        } else {\n                colour_table = gif->global_colour_table;\n        }\n\n        /* Ensure sufficient data remains */\n        if (gif_bytes < 1) {\n                return_value = GIF_INSUFFICIENT_FRAME_DATA;\n                goto gif_decode_frame_exit;\n        }\n\n        /* check for an end marker */\n        if (gif_data[0] == GIF_TRAILER) {\n                return_value = GIF_OK;\n                goto gif_decode_frame_exit;\n        }\n\n        /* Get the frame data */\n        assert(gif->bitmap_callbacks.bitmap_get_buffer);\n        frame_data = (void *)gif->bitmap_callbacks.bitmap_get_buffer(gif->frame_image);\n        if (!frame_data) {\n                return GIF_INSUFFICIENT_MEMORY;\n        }\n\n        /* If we are clearing the image we just clear, if not decode */\n        if (!clear_image) {\n                lzw_result res;\n                const uint8_t *stack_base;\n                const uint8_t *stack_pos;\n\n                /* Ensure we have enough data for a 1-byte LZW code size +\n                 * 1-byte gif trailer\n                 */\n                if (gif_bytes < 2) {\n                        return_value = GIF_INSUFFICIENT_FRAME_DATA;\n                        goto gif_decode_frame_exit;\n                }\n\n                /* If we only have a 1-byte LZW code size + 1-byte gif trailer,\n                 * we're finished\n                 */\n                if ((gif_bytes == 2) && (gif_data[1] == GIF_TRAILER)) {\n                        return_value = GIF_OK;\n                        goto gif_decode_frame_exit;\n                }\n\n                /* If the previous frame's disposal method requires we restore\n                 * the background colour or this is the first frame, clear\n                 * the frame data\n                 */\n                if ((frame == 0) || (gif->decoded_frame == GIF_INVALID_FRAME)) {\n                        memset((char*)frame_data,\n                               GIF_TRANSPARENT_COLOUR,\n                               gif->width * gif->height * sizeof(int));\n                        gif->decoded_frame = frame;\n                        /* The line below would fill the image with its\n                         * background color, but because GIFs support\n                         * transparency we likely wouldn't want to do that. */\n                        /* memset((char*)frame_data, colour_table[gif->background_index], gif->width * gif->height * sizeof(int)); */\n                } else if ((frame != 0) &&\n                           (gif->frames[frame - 1].disposal_method == GIF_FRAME_CLEAR)) {\n                        return_value = gif_internal_decode_frame(gif,\n                                                                 (frame - 1),\n                                                                 true);\n                        if (return_value != GIF_OK) {\n                                goto gif_decode_frame_exit;\n                        }\n\n                } else if ((frame != 0) &&\n                           (gif->frames[frame - 1].disposal_method == GIF_FRAME_RESTORE)) {\n                        /*\n                         * If the previous frame's disposal method requires we\n                         * restore the previous image, find the last image set\n                         * to \"do not dispose\" and get that frame data\n                         */\n                        int last_undisposed_frame = frame - 2;\n                        while ((last_undisposed_frame >= 0) &&\n                               (gif->frames[last_undisposed_frame].disposal_method == GIF_FRAME_RESTORE)) {\n                                last_undisposed_frame--;\n                        }\n\n                        /* If we don't find one, clear the frame data */\n                        if (last_undisposed_frame == -1) {\n                                /* see notes above on transparency\n                                 * vs. background color\n                                 */\n                                memset((char*)frame_data,\n                                       GIF_TRANSPARENT_COLOUR,\n                                       gif->width * gif->height * sizeof(int));\n                        } else {\n                                return_value = gif_internal_decode_frame(gif, last_undisposed_frame, false);\n                                if (return_value != GIF_OK) {\n                                        goto gif_decode_frame_exit;\n                                }\n                                /* Get this frame's data */\n                                assert(gif->bitmap_callbacks.bitmap_get_buffer);\n                                frame_data = (void *)gif->bitmap_callbacks.bitmap_get_buffer(gif->frame_image);\n                                if (!frame_data) {\n                                        return GIF_INSUFFICIENT_MEMORY;\n                                }\n                        }\n                }\n                gif->decoded_frame = frame;\n                gif->buffer_position = (gif_data - gif->gif_data) + 1;\n\n                /* Initialise the LZW decoding */\n                res = lzw_decode_init(gif->lzw_ctx, gif->gif_data,\n                                gif->buffer_size, gif->buffer_position,\n                                gif_data[0], &stack_base, &stack_pos);\n                if (res != LZW_OK) {\n                        return gif_error_from_lzw(res);\n                }\n\n                /* Decompress the data */\n                for (y = 0; y < height; y++) {\n                        if (interlace) {\n                                decode_y = gif_interlaced_line(height, y) + offset_y;\n                        } else {\n                                decode_y = y + offset_y;\n                        }\n                        frame_scanline = frame_data + offset_x + (decode_y * gif->width);\n\n                        /* Rather than decoding pixel by pixel, we try to burst\n                         * out streams of data to remove the need for end-of\n                         * data checks every pixel.\n                         */\n                        x = width;\n                        while (x > 0) {\n                                burst_bytes = (stack_pos - stack_base);\n                                if (burst_bytes > 0) {\n                                        if (burst_bytes > x) {\n                                                burst_bytes = x;\n                                        }\n                                        x -= burst_bytes;\n                                        while (burst_bytes-- > 0) {\n                                                colour = *--stack_pos;\n                                                if (((gif->frames[frame].transparency) &&\n                                                     (colour != gif->frames[frame].transparency_index)) ||\n                                                    (!gif->frames[frame].transparency)) {\n                                                        *frame_scanline = colour_table[colour];\n                                                }\n                                                frame_scanline++;\n                                        }\n                                } else {\n                                        res = lzw_decode(gif->lzw_ctx, &stack_pos);\n                                        if (res != LZW_OK) {\n                                                /* Unexpected end of frame, try to recover */\n                                                if (res == LZW_OK_EOD) {\n                                                        return_value = GIF_OK;\n                                                } else {\n                                                        return_value = gif_error_from_lzw(res);\n                                                }\n                                                goto gif_decode_frame_exit;\n                                        }\n                                }\n                        }\n                }\n        } else {\n                /* Clear our frame */\n                if (gif->frames[frame].disposal_method == GIF_FRAME_CLEAR) {\n                        for (y = 0; y < height; y++) {\n                                frame_scanline = frame_data + offset_x + ((offset_y + y) * gif->width);\n                                if (gif->frames[frame].transparency) {\n                                        memset(frame_scanline,\n                                               GIF_TRANSPARENT_COLOUR,\n                                               width * 4);\n                                } else {\n                                        memset(frame_scanline,\n                                               colour_table[gif->background_index],\n                                               width * 4);\n                                }\n                        }\n                }\n        }\ngif_decode_frame_exit:\n\n        /* Check if we should test for optimisation */\n        if (gif->frames[frame].virgin) {\n                if (gif->bitmap_callbacks.bitmap_test_opaque) {\n                        gif->frames[frame].opaque = gif->bitmap_callbacks.bitmap_test_opaque(gif->frame_image);\n                } else {\n                        gif->frames[frame].opaque = false;\n                }\n                gif->frames[frame].virgin = false;\n        }\n\n        if (gif->bitmap_callbacks.bitmap_set_opaque) {\n                gif->bitmap_callbacks.bitmap_set_opaque(gif->frame_image, gif->frames[frame].opaque);\n        }\n\n        if (gif->bitmap_callbacks.bitmap_modified) {\n                gif->bitmap_callbacks.bitmap_modified(gif->frame_image);\n        }\n\n        /* Restore the buffer position */\n        gif->buffer_position = save_buffer_position;\n\n        return return_value;\n}",
        "func_hash": 44351140165833891890072470559672892000,
        "file_name": "libnsgif.c",
        "file_hash": 198094748346353506643883012228634204471,
        "cwe": [
            "CWE-476"
        ],
        "cve": "CVE-2022-1507",
        "cve_desc": "chafa: NULL Pointer Dereference in function gif_internal_decode_frame at libnsgif.c:599 allows attackers to cause a denial of service (crash) via a crafted input file. in GitHub repository hpjansson/chafa prior to 1.10.2. chafa: NULL Pointer Dereference in function gif_internal_decode_frame at libnsgif.c:599 allows attackers to cause a denial of service (crash) via a crafted input file.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-1507",
        "func_name": "gif_internal_decode_frame",
        "diff": [
            "diff --git a/libnsgif/libnsgif.c b/libnsgif/libnsgif.c\nindex fc4bda22..fa55d7b5 100644\n--- a/libnsgif/libnsgif.c\n+++ b/libnsgif/libnsgif.c\n@@ -595,6 +595,12 @@ gif_internal_decode_frame(gif_animation *gif,\n         unsigned int x, y, decode_y, burst_bytes;\n         register unsigned char colour;\n \n+        /* If the GIF has no frame data, frame holders will not be allocated in\n+         * gif_initialise() */\n+        if (gif->frames == NULL) {\n+                return GIF_INSUFFICIENT_DATA;\n+        }\n+\n         /* Ensure this frame is supposed to be decoded */\n         if (gif->frames[frame].display == false) {\n                 return GIF_OK;\n"
        ],
        "func_after": []
    },
    {
        "idx": 199834,
        "project": "vim",
        "commit_id": "f12129f1714f7d2301935bb21d896609bdac221c",
        "project_url": "https://github.com/vim/vim",
        "commit_url": "https://github.com/vim/vim/commit/f12129f1714f7d2301935bb21d896609bdac221c",
        "commit_message": "patch 9.0.0020: with some completion reading past end of string\n\nProblem:    With some completion reading past end of string.\nSolution:   Check the length of the string.",
        "target": 1,
        "irrelevant": 1,
        "func_before": "ins_compl_stop(int c, int prev_mode, int retval)\n{\n    char_u\t*ptr;\n    int\t\twant_cindent;\n\n    // Get here when we have finished typing a sequence of ^N and\n    // ^P or other completion characters in CTRL-X mode.  Free up\n    // memory that was used, and make sure we can redo the insert.\n    if (compl_curr_match != NULL || compl_leader != NULL || c == Ctrl_E)\n    {\n\t// If any of the original typed text has been changed, eg when\n\t// ignorecase is set, we must add back-spaces to the redo\n\t// buffer.  We add as few as necessary to delete just the part\n\t// of the original text that has changed.\n\t// When using the longest match, edited the match or used\n\t// CTRL-E then don't use the current match.\n\tif (compl_curr_match != NULL && compl_used_match && c != Ctrl_E)\n\t    ptr = compl_curr_match->cp_str;\n\telse\n\t    ptr = NULL;\n\tins_compl_fixRedoBufForLeader(ptr);\n    }\n\n    want_cindent = (get_can_cindent() && cindent_on());\n\n    // When completing whole lines: fix indent for 'cindent'.\n    // Otherwise, break line if it's too long.\n    if (compl_cont_mode == CTRL_X_WHOLE_LINE)\n    {\n\t// re-indent the current line\n\tif (want_cindent)\n\t{\n\t    do_c_expr_indent();\n\t    want_cindent = FALSE;\t// don't do it again\n\t}\n    }\n    else\n    {\n\tint prev_col = curwin->w_cursor.col;\n\n\t// put the cursor on the last char, for 'tw' formatting\n\tif (prev_col > 0)\n\t    dec_cursor();\n\t// only format when something was inserted\n\tif (!arrow_used && !ins_need_undo_get() && c != Ctrl_E)\n\t    insertchar(NUL, 0, -1);\n\tif (prev_col > 0\n\t\t&& ml_get_curline()[curwin->w_cursor.col] != NUL)\n\t    inc_cursor();\n    }\n\n    // If the popup menu is displayed pressing CTRL-Y means accepting\n    // the selection without inserting anything.  When\n    // compl_enter_selects is set the Enter key does the same.\n    if ((c == Ctrl_Y || (compl_enter_selects\n\t\t    && (c == CAR || c == K_KENTER || c == NL)))\n\t    && pum_visible())\n\tretval = TRUE;\n\n    // CTRL-E means completion is Ended, go back to the typed text.\n    // but only do this, if the Popup is still visible\n    if (c == Ctrl_E)\n    {\n\tins_compl_delete();\n\tif (compl_leader != NULL)\n\t    ins_bytes(compl_leader + get_compl_len());\n\telse if (compl_first_match != NULL)\n\t    ins_bytes(compl_orig_text + get_compl_len());\n\tretval = TRUE;\n    }\n\n    auto_format(FALSE, TRUE);\n\n    // Trigger the CompleteDonePre event to give scripts a chance to\n    // act upon the completion before clearing the info, and restore\n    // ctrl_x_mode, so that complete_info() can be used.\n    ctrl_x_mode = prev_mode;\n    ins_apply_autocmds(EVENT_COMPLETEDONEPRE);\n\n    ins_compl_free();\n    compl_started = FALSE;\n    compl_matches = 0;\n    if (!shortmess(SHM_COMPLETIONMENU))\n\tmsg_clr_cmdline();\t// necessary for \"noshowmode\"\n    ctrl_x_mode = CTRL_X_NORMAL;\n    compl_enter_selects = FALSE;\n    if (edit_submode != NULL)\n    {\n\tedit_submode = NULL;\n\tshowmode();\n    }\n\n#ifdef FEAT_CMDWIN\n    if (c == Ctrl_C && cmdwin_type != 0)\n\t// Avoid the popup menu remains displayed when leaving the\n\t// command line window.\n\tupdate_screen(0);\n#endif\n    // Indent now if a key was typed that is in 'cinkeys'.\n    if (want_cindent && in_cinkeys(KEY_COMPLETE, ' ', inindent(0)))\n\tdo_c_expr_indent();\n    // Trigger the CompleteDone event to give scripts a chance to act\n    // upon the end of completion.\n    ins_apply_autocmds(EVENT_COMPLETEDONE);\n\n    return retval;\n}",
        "func_hash": 319633245097677404453951244574334910213,
        "file_name": "insexpand.c",
        "file_hash": 292997256287164132386360145530649653298,
        "cwe": [
            "CWE-125"
        ],
        "cve": "CVE-2022-2286",
        "cve_desc": "Out-of-bounds Read in GitHub repository vim/vim prior to 9.0.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-2286",
        "func_name": "ins_compl_stop",
        "diff": [
            "diff --git a/src/insexpand.c b/src/insexpand.c\nindex 4a5feac9dc1f71..734550ffd231f7 100644\n--- a/src/insexpand.c\n+++ b/src/insexpand.c\n@@ -2209,11 +2209,21 @@ ins_compl_stop(int c, int prev_mode, int retval)\n     // but only do this, if the Popup is still visible\n     if (c == Ctrl_E)\n     {\n+\tchar_u *p = NULL;\n+\n \tins_compl_delete();\n \tif (compl_leader != NULL)\n-\t    ins_bytes(compl_leader + get_compl_len());\n+\t    p = compl_leader;\n \telse if (compl_first_match != NULL)\n-\t    ins_bytes(compl_orig_text + get_compl_len());\n+\t    p = compl_orig_text;\n+\tif (p != NULL)\n+\t{\n+\t    int\t    compl_len = get_compl_len();\n+\t    int\t    len = (int)STRLEN(p);\n+\n+\t    if (len > compl_len)\n+\t\tins_bytes_len(p + compl_len, len - compl_len);\n+\t}\n \tretval = TRUE;\n     }\n \ndiff --git a/src/testdir/test_ins_complete.vim b/src/testdir/test_ins_complete.vim\nindex 365c646a19c652..20c2b4f48f4142 100644\n--- a/src/testdir/test_ins_complete.vim\n+++ b/src/testdir/test_ins_complete.vim\n@@ -2184,4 +2184,12 @@ func Test_complete_smartindent()\n   delfunction! FooBarComplete\n endfunc\n \n+func Test_complete_overrun()\n+  \" this was going past the end of the copied text\n+  new\n+  sil norm si\u0094\u00140\u0003s\u000f0\u0018\f\u0005\n+  bwipe!\n+endfunc\n+\n+\n \" vim: shiftwidth=2 sts=2 expandtab\ndiff --git a/src/version.c b/src/version.c\nindex 42e9135e1f6d09..26cb768a825417 100644\n--- a/src/version.c\n+++ b/src/version.c\n@@ -735,6 +735,8 @@ static char *(features[]) =\n \n static int included_patches[] =\n {   /* Add new patch number below this line */\n+/**/\n+    20,\n /**/\n     19,\n /**/\n"
        ],
        "func_after": []
    },
    {
        "idx": 199836,
        "project": "pjproject",
        "commit_id": "077b465c33f0aec05a49cd2ca456f9a1b112e896",
        "project_url": "https://github.com/pjsip/pjproject",
        "commit_url": "https://github.com/pjsip/pjproject/commit/077b465c33f0aec05a49cd2ca456f9a1b112e896",
        "commit_message": "Merge pull request from GHSA-7fw8-54cv-r7pm",
        "target": 1,
        "irrelevant": 1,
        "func_before": "PJ_DEF(int) pj_scan_get_char( pj_scanner *scanner )\n{\n    int chr = *scanner->curptr;\n\n    if (!chr) {\n\tpj_scan_syntax_err(scanner);\n\treturn 0;\n    }\n\n    ++scanner->curptr;\n\n    if (PJ_SCAN_IS_PROBABLY_SPACE(*scanner->curptr) && scanner->skip_ws) {\n\tpj_scan_skip_whitespace(scanner);\n    }\n    return chr;\n}",
        "func_hash": 113292852369107945981597354542276439074,
        "file_name": "scanner.c",
        "file_hash": null,
        "cwe": [
            "CWE-125"
        ],
        "cve": "CVE-2022-21723",
        "cve_desc": "PJSIP is a free and open source multimedia communication library written in C language implementing standard based protocols such as SIP, SDP, RTP, STUN, TURN, and ICE. In versions 2.11.1 and prior, parsing an incoming SIP message that contains a malformed multipart can potentially cause out-of-bound read access. This issue affects all PJSIP users that accept SIP multipart. The patch is available as commit in the `master` branch. There are no known workarounds.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-21723",
        "func_name": "PJ_DEF",
        "diff": [
            "diff --git a/pjlib-util/src/pjlib-util/scanner.c b/pjlib-util/src/pjlib-util/scanner.c\nindex 27a0b88310..a54edf2d8e 100644\n--- a/pjlib-util/src/pjlib-util/scanner.c\n+++ b/pjlib-util/src/pjlib-util/scanner.c\n@@ -444,16 +444,21 @@ PJ_DEF(void) pj_scan_get_n( pj_scanner *scanner,\n \n PJ_DEF(int) pj_scan_get_char( pj_scanner *scanner )\n {\n-    int chr = *scanner->curptr;\n+    register char *s = scanner->curptr;\n+    int chr;\n \n-    if (!chr) {\n+    if (s >= scanner->end || !*s) {\n \tpj_scan_syntax_err(scanner);\n \treturn 0;\n     }\n \n-    ++scanner->curptr;\n+    chr = *s;\n \n-    if (PJ_SCAN_IS_PROBABLY_SPACE(*scanner->curptr) && scanner->skip_ws) {\n+    ++s;\n+    scanner->curptr = s;\n+    if (PJ_SCAN_CHECK_EOF(s) && PJ_SCAN_IS_PROBABLY_SPACE(*s) &&\n+    \tscanner->skip_ws)\n+    {\n \tpj_scan_skip_whitespace(scanner);\n     }\n     return chr;\n"
        ],
        "func_after": []
    },
    {
        "idx": 199841,
        "project": "radare2",
        "commit_id": "feaa4e7f7399c51ee6f52deb84dc3f795b4035d6",
        "project_url": "https://github.com/radare/radare2",
        "commit_url": "https://github.com/radareorg/radare2/commit/feaa4e7f7399c51ee6f52deb84dc3f795b4035d6",
        "commit_message": "Fix null deref in xnu.kernelcache ##crash\n\n* Reported by @xshad3 via huntr.dev",
        "target": 1,
        "irrelevant": 1,
        "func_before": "static bool load_buffer(RBinFile *bf, void **bin_obj, RBuffer *buf, ut64 loadaddr, Sdb *sdb) {\n\tRBuffer *fbuf = r_buf_ref (buf);\n\tstruct MACH0_(opts_t) opts;\n\tMACH0_(opts_set_default) (&opts, bf);\n\tstruct MACH0_(obj_t) *main_mach0 = MACH0_(new_buf) (fbuf, &opts);\n\tif (!main_mach0) {\n\t\treturn false;\n\t}\n\n\tRRebaseInfo *rebase_info = r_rebase_info_new_from_mach0 (fbuf, main_mach0);\n\tRKernelCacheObj *obj = NULL;\n\n\tRPrelinkRange *prelink_range = get_prelink_info_range_from_mach0 (main_mach0);\n\tif (!prelink_range) {\n\t\tgoto beach;\n\t}\n\n\tobj = R_NEW0 (RKernelCacheObj);\n\tif (!obj) {\n\t\tR_FREE (prelink_range);\n\t\tgoto beach;\n\t}\n\n\tRCFValueDict *prelink_info = NULL;\n\tif (main_mach0->hdr.filetype != MH_FILESET && prelink_range->range.size) {\n\t\tprelink_info = r_cf_value_dict_parse (fbuf, prelink_range->range.offset,\n\t\t\t\tprelink_range->range.size, R_CF_OPTION_SKIP_NSDATA);\n\t\tif (!prelink_info) {\n\t\t\tR_FREE (prelink_range);\n\t\t\tR_FREE (obj);\n\t\t\tgoto beach;\n\t\t}\n\t}\n\n\tif (!pending_bin_files) {\n\t\tpending_bin_files = r_list_new ();\n\t\tif (!pending_bin_files) {\n\t\t\tR_FREE (prelink_range);\n\t\t\tR_FREE (obj);\n\t\t\tR_FREE (prelink_info);\n\t\t\tgoto beach;\n\t\t}\n\t}\n\n\tobj->mach0 = main_mach0;\n\tobj->rebase_info = rebase_info;\n\tobj->prelink_info = prelink_info;\n\tobj->cache_buf = fbuf;\n\tobj->pa2va_exec = prelink_range->pa2va_exec;\n\tobj->pa2va_data = prelink_range->pa2va_data;\n\n\tR_FREE (prelink_range);\n\n\t*bin_obj = obj;\n\n\tr_list_push (pending_bin_files, bf);\n\n\tif (rebase_info || main_mach0->chained_starts) {\n\t\tRIO *io = bf->rbin->iob.io;\n\t\tswizzle_io_read (obj, io);\n\t}\n\n\treturn true;\n\nbeach:\n\tr_buf_free (fbuf);\n\tobj->cache_buf = NULL;\n\tMACH0_(mach0_free) (main_mach0);\n\treturn false;\n}",
        "func_hash": 233224811640274540394040555084759924603,
        "file_name": "bin_xnu_kernelcache.c",
        "file_hash": 125322815790464606650182134413161579767,
        "cwe": [
            "CWE-476"
        ],
        "cve": "CVE-2022-0419",
        "cve_desc": "NULL Pointer Dereference in GitHub repository radareorg/radare2 prior to 5.6.0.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-0419",
        "func_name": "load_buffer",
        "diff": [
            "diff --git a/libr/bin/p/bin_xnu_kernelcache.c b/libr/bin/p/bin_xnu_kernelcache.c\nindex 36b1c2db08744..df5b1fe7d0c3e 100644\n--- a/libr/bin/p/bin_xnu_kernelcache.c\n+++ b/libr/bin/p/bin_xnu_kernelcache.c\n@@ -242,7 +242,9 @@ static bool load_buffer(RBinFile *bf, void **bin_obj, RBuffer *buf, ut64 loadadd\n \n beach:\n \tr_buf_free (fbuf);\n-\tobj->cache_buf = NULL;\n+\tif (obj) {\n+\t\tobj->cache_buf = NULL;\n+\t}\n \tMACH0_(mach0_free) (main_mach0);\n \treturn false;\n }\n"
        ],
        "func_after": []
    },
    {
        "idx": 199851,
        "project": "vim",
        "commit_id": "6e28703a8e41f775f64e442c5d11ce1ff599aa3f",
        "project_url": "https://github.com/vim/vim",
        "commit_url": "https://github.com/vim/vim/commit/6e28703a8e41f775f64e442c5d11ce1ff599aa3f",
        "commit_message": "patch 8.2.4359: crash when repeatedly using :retab\n\nProblem:    crash when repeatedly using :retab.\nSolution:   Bail out when the line is getting too long.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "ex_retab(exarg_T *eap)\n{\n    linenr_T\tlnum;\n    int\t\tgot_tab = FALSE;\n    long\tnum_spaces = 0;\n    long\tnum_tabs;\n    long\tlen;\n    long\tcol;\n    long\tvcol;\n    long\tstart_col = 0;\t\t// For start of white-space string\n    long\tstart_vcol = 0;\t\t// For start of white-space string\n    long\told_len;\n    char_u\t*ptr;\n    char_u\t*new_line = (char_u *)1; // init to non-NULL\n    int\t\tdid_undo;\t\t// called u_save for current line\n#ifdef FEAT_VARTABS\n    int\t\t*new_vts_array = NULL;\n    char_u\t*new_ts_str;\t\t// string value of tab argument\n#else\n    int\t\ttemp;\n    int\t\tnew_ts;\n#endif\n    int\t\tsave_list;\n    linenr_T\tfirst_line = 0;\t\t// first changed line\n    linenr_T\tlast_line = 0;\t\t// last changed line\n\n    save_list = curwin->w_p_list;\n    curwin->w_p_list = 0;\t    // don't want list mode here\n\n#ifdef FEAT_VARTABS\n    new_ts_str = eap->arg;\n    if (tabstop_set(eap->arg, &new_vts_array) == FAIL)\n\treturn;\n    while (vim_isdigit(*(eap->arg)) || *(eap->arg) == ',')\n\t++(eap->arg);\n\n    // This ensures that either new_vts_array and new_ts_str are freshly\n    // allocated, or new_vts_array points to an existing array and new_ts_str\n    // is null.\n    if (new_vts_array == NULL)\n    {\n\tnew_vts_array = curbuf->b_p_vts_array;\n\tnew_ts_str = NULL;\n    }\n    else\n\tnew_ts_str = vim_strnsave(new_ts_str, eap->arg - new_ts_str);\n#else\n    ptr = eap->arg;\n    new_ts = getdigits(&ptr);\n    if (new_ts < 0 && *eap->arg == '-')\n    {\n\temsg(_(e_argument_must_be_positive));\n\treturn;\n    }\n    if (new_ts < 0 || new_ts > TABSTOP_MAX)\n    {\n\tsemsg(_(e_invalid_argument_str), eap->arg);\n\treturn;\n    }\n    if (new_ts == 0)\n\tnew_ts = curbuf->b_p_ts;\n#endif\n    for (lnum = eap->line1; !got_int && lnum <= eap->line2; ++lnum)\n    {\n\tptr = ml_get(lnum);\n\tcol = 0;\n\tvcol = 0;\n\tdid_undo = FALSE;\n\tfor (;;)\n\t{\n\t    if (VIM_ISWHITE(ptr[col]))\n\t    {\n\t\tif (!got_tab && num_spaces == 0)\n\t\t{\n\t\t    // First consecutive white-space\n\t\t    start_vcol = vcol;\n\t\t    start_col = col;\n\t\t}\n\t\tif (ptr[col] == ' ')\n\t\t    num_spaces++;\n\t\telse\n\t\t    got_tab = TRUE;\n\t    }\n\t    else\n\t    {\n\t\tif (got_tab || (eap->forceit && num_spaces > 1))\n\t\t{\n\t\t    // Retabulate this string of white-space\n\n\t\t    // len is virtual length of white string\n\t\t    len = num_spaces = vcol - start_vcol;\n\t\t    num_tabs = 0;\n\t\t    if (!curbuf->b_p_et)\n\t\t    {\n#ifdef FEAT_VARTABS\n\t\t\tint t, s;\n\n\t\t\ttabstop_fromto(start_vcol, vcol,\n\t\t\t\t\tcurbuf->b_p_ts, new_vts_array, &t, &s);\n\t\t\tnum_tabs = t;\n\t\t\tnum_spaces = s;\n#else\n\t\t\ttemp = new_ts - (start_vcol % new_ts);\n\t\t\tif (num_spaces >= temp)\n\t\t\t{\n\t\t\t    num_spaces -= temp;\n\t\t\t    num_tabs++;\n\t\t\t}\n\t\t\tnum_tabs += num_spaces / new_ts;\n\t\t\tnum_spaces -= (num_spaces / new_ts) * new_ts;\n#endif\n\t\t    }\n\t\t    if (curbuf->b_p_et || got_tab ||\n\t\t\t\t\t(num_spaces + num_tabs < len))\n\t\t    {\n\t\t\tif (did_undo == FALSE)\n\t\t\t{\n\t\t\t    did_undo = TRUE;\n\t\t\t    if (u_save((linenr_T)(lnum - 1),\n\t\t\t\t\t\t(linenr_T)(lnum + 1)) == FAIL)\n\t\t\t    {\n\t\t\t\tnew_line = NULL;\t// flag out-of-memory\n\t\t\t\tbreak;\n\t\t\t    }\n\t\t\t}\n\n\t\t\t// len is actual number of white characters used\n\t\t\tlen = num_spaces + num_tabs;\n\t\t\told_len = (long)STRLEN(ptr);\n\t\t\tnew_line = alloc(old_len - col + start_col + len + 1);\n\t\t\tif (new_line == NULL)\n\t\t\t    break;\n\t\t\tif (start_col > 0)\n\t\t\t    mch_memmove(new_line, ptr, (size_t)start_col);\n\t\t\tmch_memmove(new_line + start_col + len,\n\t\t\t\t      ptr + col, (size_t)(old_len - col + 1));\n\t\t\tptr = new_line + start_col;\n\t\t\tfor (col = 0; col < len; col++)\n\t\t\t    ptr[col] = (col < num_tabs) ? '\\t' : ' ';\n\t\t\tif (ml_replace(lnum, new_line, FALSE) == OK)\n\t\t\t    // \"new_line\" may have been copied\n\t\t\t    new_line = curbuf->b_ml.ml_line_ptr;\n\t\t\tif (first_line == 0)\n\t\t\t    first_line = lnum;\n\t\t\tlast_line = lnum;\n\t\t\tptr = new_line;\n\t\t\tcol = start_col + len;\n\t\t    }\n\t\t}\n\t\tgot_tab = FALSE;\n\t\tnum_spaces = 0;\n\t    }\n\t    if (ptr[col] == NUL)\n\t\tbreak;\n\t    vcol += chartabsize(ptr + col, (colnr_T)vcol);\n\t    if (has_mbyte)\n\t\tcol += (*mb_ptr2len)(ptr + col);\n\t    else\n\t\t++col;\n\t}\n\tif (new_line == NULL)\t\t    // out of memory\n\t    break;\n\tline_breakcheck();\n    }\n    if (got_int)\n\temsg(_(e_interrupted));\n\n#ifdef FEAT_VARTABS\n    // If a single value was given then it can be considered equal to\n    // either the value of 'tabstop' or the value of 'vartabstop'.\n    if (tabstop_count(curbuf->b_p_vts_array) == 0\n\t&& tabstop_count(new_vts_array) == 1\n\t&& curbuf->b_p_ts == tabstop_first(new_vts_array))\n\t; // not changed\n    else if (tabstop_count(curbuf->b_p_vts_array) > 0\n        && tabstop_eq(curbuf->b_p_vts_array, new_vts_array))\n\t; // not changed\n    else\n\tredraw_curbuf_later(NOT_VALID);\n#else\n    if (curbuf->b_p_ts != new_ts)\n\tredraw_curbuf_later(NOT_VALID);\n#endif\n    if (first_line != 0)\n\tchanged_lines(first_line, 0, last_line + 1, 0L);\n\n    curwin->w_p_list = save_list;\t// restore 'list'\n\n#ifdef FEAT_VARTABS\n    if (new_ts_str != NULL)\t\t// set the new tabstop\n    {\n\t// If 'vartabstop' is in use or if the value given to retab has more\n\t// than one tabstop then update 'vartabstop'.\n\tint *old_vts_ary = curbuf->b_p_vts_array;\n\n\tif (tabstop_count(old_vts_ary) > 0 || tabstop_count(new_vts_array) > 1)\n\t{\n\t    set_string_option_direct((char_u *)\"vts\", -1, new_ts_str,\n\t\t\t\t\t\t\tOPT_FREE|OPT_LOCAL, 0);\n\t    curbuf->b_p_vts_array = new_vts_array;\n\t    vim_free(old_vts_ary);\n\t}\n\telse\n\t{\n\t    // 'vartabstop' wasn't in use and a single value was given to\n\t    // retab then update 'tabstop'.\n\t    curbuf->b_p_ts = tabstop_first(new_vts_array);\n\t    vim_free(new_vts_array);\n\t}\n\tvim_free(new_ts_str);\n    }\n#else\n    curbuf->b_p_ts = new_ts;\n#endif\n    coladvance(curwin->w_curswant);\n\n    u_clearline();\n}",
        "func_hash": 55704685563391152697895881333081984969,
        "file_name": "indent.c",
        "file_hash": 264017227782989622614587099376842569247,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2022-0572",
        "cve_desc": "Heap-based Buffer Overflow in GitHub repository vim/vim prior to 8.2.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-0572",
        "func_name": "ex_retab",
        "diff": [
            "diff --git a/src/indent.c b/src/indent.c\nindex 9b137b0b425a94..232c534973af6b 100644\n--- a/src/indent.c\n+++ b/src/indent.c\n@@ -1750,6 +1750,11 @@ ex_retab(exarg_T *eap)\n \t    if (ptr[col] == NUL)\n \t\tbreak;\n \t    vcol += chartabsize(ptr + col, (colnr_T)vcol);\n+\t    if (vcol >= MAXCOL)\n+\t    {\n+\t\temsg(_(e_resulting_text_too_long));\n+\t\tbreak;\n+\t    }\n \t    if (has_mbyte)\n \t\tcol += (*mb_ptr2len)(ptr + col);\n \t    else\ndiff --git a/src/testdir/test_retab.vim b/src/testdir/test_retab.vim\nindex c7190aaa6699d9..6133e8fb4abcaf 100644\n--- a/src/testdir/test_retab.vim\n+++ b/src/testdir/test_retab.vim\n@@ -70,6 +70,8 @@ func Test_retab()\n   call assert_equal(\"    a       b        c    \",         Retab('!', 3))\n   call assert_equal(\"    a       b        c    \",         Retab('',  5))\n   call assert_equal(\"    a       b        c    \",         Retab('!', 5))\n+\n+  set tabstop& expandtab&\n endfunc\n \n func Test_retab_error()\n@@ -80,4 +82,21 @@ func Test_retab_error()\n   call assert_fails('ret 80000000000000000000', 'E475:')\n endfunc\n \n+func Test_retab_endless()\n+  new\n+  call setline(1, \"\\t0\\t\")\n+  let caught = 'no'\n+  try\n+    while 1\n+      set ts=4000\n+      retab 4\n+    endwhile\n+  catch /E1240/\n+    let caught = 'yes'\n+  endtry\n+  bwipe!\n+  set tabstop&\n+endfunc\n+\n+\n \" vim: shiftwidth=2 sts=2 expandtab\ndiff --git a/src/version.c b/src/version.c\nindex 636757c3b6a61c..aaafadf89de709 100644\n--- a/src/version.c\n+++ b/src/version.c\n@@ -750,6 +750,8 @@ static char *(features[]) =\n \n static int included_patches[] =\n {   /* Add new patch number below this line */\n+/**/\n+    4359,\n /**/\n     4358,\n /**/\n"
        ],
        "func_after": []
    },
    {
        "idx": 199918,
        "project": "vim",
        "commit_id": "2813f38e021c6e6581c0c88fcf107e41788bc835",
        "project_url": "https://github.com/vim/vim",
        "commit_url": "https://github.com/vim/vim/commit/2813f38e021c6e6581c0c88fcf107e41788bc835",
        "commit_message": "patch 8.2.5072: using uninitialized value and freed memory in spell command\n\nProblem:    Using uninitialized value and freed memory in spell command.\nSolution:   Initialize \"attr\".  Check for empty line early.",
        "target": 1,
        "irrelevant": 1,
        "func_before": "spell_move_to(\n    win_T\t*wp,\n    int\t\tdir,\t\t// FORWARD or BACKWARD\n    int\t\tallwords,\t// TRUE for \"[s\"/\"]s\", FALSE for \"[S\"/\"]S\"\n    int\t\tcurline,\n    hlf_T\t*attrp)\t\t// return: attributes of bad word or NULL\n\t\t\t\t// (only when \"dir\" is FORWARD)\n{\n    linenr_T\tlnum;\n    pos_T\tfound_pos;\n    int\t\tfound_len = 0;\n    char_u\t*line;\n    char_u\t*p;\n    char_u\t*endp;\n    hlf_T\tattr;\n    int\t\tlen;\n#ifdef FEAT_SYN_HL\n    int\t\thas_syntax = syntax_present(wp);\n#endif\n    int\t\tcol;\n    int\t\tcan_spell;\n    char_u\t*buf = NULL;\n    int\t\tbuflen = 0;\n    int\t\tskip = 0;\n    int\t\tcapcol = -1;\n    int\t\tfound_one = FALSE;\n    int\t\twrapped = FALSE;\n\n    if (no_spell_checking(wp))\n\treturn 0;\n\n    /*\n     * Start looking for bad word at the start of the line, because we can't\n     * start halfway a word, we don't know where it starts or ends.\n     *\n     * When searching backwards, we continue in the line to find the last\n     * bad word (in the cursor line: before the cursor).\n     *\n     * We concatenate the start of the next line, so that wrapped words work\n     * (e.g. \"et<line-break>cetera\").  Doesn't work when searching backwards\n     * though...\n     */\n    lnum = wp->w_cursor.lnum;\n    CLEAR_POS(&found_pos);\n\n    while (!got_int)\n    {\n\tline = ml_get_buf(wp->w_buffer, lnum, FALSE);\n\n\tlen = (int)STRLEN(line);\n\tif (buflen < len + MAXWLEN + 2)\n\t{\n\t    vim_free(buf);\n\t    buflen = len + MAXWLEN + 2;\n\t    buf = alloc(buflen);\n\t    if (buf == NULL)\n\t\tbreak;\n\t}\n\n\t// In first line check first word for Capital.\n\tif (lnum == 1)\n\t    capcol = 0;\n\n\t// For checking first word with a capital skip white space.\n\tif (capcol == 0)\n\t    capcol = getwhitecols(line);\n\telse if (curline && wp == curwin)\n\t{\n\t    // For spellbadword(): check if first word needs a capital.\n\t    col = getwhitecols(line);\n\t    if (check_need_cap(lnum, col))\n\t\tcapcol = col;\n\n\t    // Need to get the line again, may have looked at the previous\n\t    // one.\n\t    line = ml_get_buf(wp->w_buffer, lnum, FALSE);\n\t}\n\n\t// Copy the line into \"buf\" and append the start of the next line if\n\t// possible.\n\tSTRCPY(buf, line);\n\tif (lnum < wp->w_buffer->b_ml.ml_line_count)\n\t    spell_cat_line(buf + STRLEN(buf),\n\t\t\t  ml_get_buf(wp->w_buffer, lnum + 1, FALSE), MAXWLEN);\n\n\tp = buf + skip;\n\tendp = buf + len;\n\twhile (p < endp)\n\t{\n\t    // When searching backward don't search after the cursor.  Unless\n\t    // we wrapped around the end of the buffer.\n\t    if (dir == BACKWARD\n\t\t    && lnum == wp->w_cursor.lnum\n\t\t    && !wrapped\n\t\t    && (colnr_T)(p - buf) >= wp->w_cursor.col)\n\t\tbreak;\n\n\t    // start of word\n\t    attr = HLF_COUNT;\n\t    len = spell_check(wp, p, &attr, &capcol, FALSE);\n\n\t    if (attr != HLF_COUNT)\n\t    {\n\t\t// We found a bad word.  Check the attribute.\n\t\tif (allwords || attr == HLF_SPB)\n\t\t{\n\t\t    // When searching forward only accept a bad word after\n\t\t    // the cursor.\n\t\t    if (dir == BACKWARD\n\t\t\t    || lnum != wp->w_cursor.lnum\n\t\t\t    || (wrapped\n\t\t\t\t|| (colnr_T)(curline ? p - buf + len\n\t\t\t\t\t\t     : p - buf)\n\t\t\t\t\t\t  > wp->w_cursor.col))\n\t\t    {\n#ifdef FEAT_SYN_HL\n\t\t\tif (has_syntax)\n\t\t\t{\n\t\t\t    col = (int)(p - buf);\n\t\t\t    (void)syn_get_id(wp, lnum, (colnr_T)col,\n\t\t\t\t\t\t    FALSE, &can_spell, FALSE);\n\t\t\t    if (!can_spell)\n\t\t\t\tattr = HLF_COUNT;\n\t\t\t}\n\t\t\telse\n#endif\n\t\t\t    can_spell = TRUE;\n\n\t\t\tif (can_spell)\n\t\t\t{\n\t\t\t    found_one = TRUE;\n\t\t\t    found_pos.lnum = lnum;\n\t\t\t    found_pos.col = (int)(p - buf);\n\t\t\t    found_pos.coladd = 0;\n\t\t\t    if (dir == FORWARD)\n\t\t\t    {\n\t\t\t\t// No need to search further.\n\t\t\t\twp->w_cursor = found_pos;\n\t\t\t\tvim_free(buf);\n\t\t\t\tif (attrp != NULL)\n\t\t\t\t    *attrp = attr;\n\t\t\t\treturn len;\n\t\t\t    }\n\t\t\t    else if (curline)\n\t\t\t\t// Insert mode completion: put cursor after\n\t\t\t\t// the bad word.\n\t\t\t\tfound_pos.col += len;\n\t\t\t    found_len = len;\n\t\t\t}\n\t\t    }\n\t\t    else\n\t\t\tfound_one = TRUE;\n\t\t}\n\t    }\n\n\t    // advance to character after the word\n\t    p += len;\n\t    capcol -= len;\n\t}\n\n\tif (dir == BACKWARD && found_pos.lnum != 0)\n\t{\n\t    // Use the last match in the line (before the cursor).\n\t    wp->w_cursor = found_pos;\n\t    vim_free(buf);\n\t    return found_len;\n\t}\n\n\tif (curline)\n\t    break;\t// only check cursor line\n\n\t// If we are back at the starting line and searched it again there\n\t// is no match, give up.\n\tif (lnum == wp->w_cursor.lnum && wrapped)\n\t    break;\n\n\t// Advance to next line.\n\tif (dir == BACKWARD)\n\t{\n\t    if (lnum > 1)\n\t\t--lnum;\n\t    else if (!p_ws)\n\t\tbreak;\t    // at first line and 'nowrapscan'\n\t    else\n\t    {\n\t\t// Wrap around to the end of the buffer.  May search the\n\t\t// starting line again and accept the last match.\n\t\tlnum = wp->w_buffer->b_ml.ml_line_count;\n\t\twrapped = TRUE;\n\t\tif (!shortmess(SHM_SEARCH))\n\t\t    give_warning((char_u *)_(top_bot_msg), TRUE);\n\t    }\n\t    capcol = -1;\n\t}\n\telse\n\t{\n\t    if (lnum < wp->w_buffer->b_ml.ml_line_count)\n\t\t++lnum;\n\t    else if (!p_ws)\n\t\tbreak;\t    // at first line and 'nowrapscan'\n\t    else\n\t    {\n\t\t// Wrap around to the start of the buffer.  May search the\n\t\t// starting line again and accept the first match.\n\t\tlnum = 1;\n\t\twrapped = TRUE;\n\t\tif (!shortmess(SHM_SEARCH))\n\t\t    give_warning((char_u *)_(bot_top_msg), TRUE);\n\t    }\n\n\t    // If we are back at the starting line and there is no match then\n\t    // give up.\n\t    if (lnum == wp->w_cursor.lnum && !found_one)\n\t\tbreak;\n\n\t    // Skip the characters at the start of the next line that were\n\t    // included in a match crossing line boundaries.\n\t    if (attr == HLF_COUNT)\n\t\tskip = (int)(p - endp);\n\t    else\n\t\tskip = 0;\n\n\t    // Capcol skips over the inserted space.\n\t    --capcol;\n\n\t    // But after empty line check first word in next line\n\t    if (*skipwhite(line) == NUL)\n\t\tcapcol = 0;\n\t}\n\n\tline_breakcheck();\n    }\n\n    vim_free(buf);\n    return 0;\n}",
        "func_hash": 325648624112738029614022837693568870938,
        "file_name": "spell.c",
        "file_hash": 86411941404865310721318848603964614236,
        "cwe": [
            "CWE-416"
        ],
        "cve": "CVE-2022-2042",
        "cve_desc": "Use After Free in GitHub repository vim/vim prior to 8.2.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-2042",
        "func_name": "spell_move_to",
        "diff": [
            "diff --git a/src/spell.c b/src/spell.c\nindex 48a2203e3f042..d866a2df7265c 100644\n--- a/src/spell.c\n+++ b/src/spell.c\n@@ -1275,7 +1275,7 @@ spell_move_to(\n     char_u\t*line;\n     char_u\t*p;\n     char_u\t*endp;\n-    hlf_T\tattr;\n+    hlf_T\tattr = 0;\n     int\t\tlen;\n #ifdef FEAT_SYN_HL\n     int\t\thas_syntax = syntax_present(wp);\n@@ -1308,6 +1308,8 @@ spell_move_to(\n \n     while (!got_int)\n     {\n+\tint empty_line;\n+\n \tline = ml_get_buf(wp->w_buffer, lnum, FALSE);\n \n \tlen = (int)STRLEN(line);\n@@ -1340,7 +1342,9 @@ spell_move_to(\n \t}\n \n \t// Copy the line into \"buf\" and append the start of the next line if\n-\t// possible.\n+\t// possible.  Note: this ml_get_buf() may make \"line\" invalid, check\n+\t// for empty line first.\n+\tempty_line = *skipwhite(line) == NUL;\n \tSTRCPY(buf, line);\n \tif (lnum < wp->w_buffer->b_ml.ml_line_count)\n \t    spell_cat_line(buf + STRLEN(buf),\n@@ -1487,7 +1491,7 @@ spell_move_to(\n \t    --capcol;\n \n \t    // But after empty line check first word in next line\n-\t    if (*skipwhite(line) == NUL)\n+\t    if (empty_line)\n \t\tcapcol = 0;\n \t}\n \ndiff --git a/src/testdir/test_spell_utf8.vim b/src/testdir/test_spell_utf8.vim\nindex ef08f953521c7..f9f85a63ae99f 100644\n--- a/src/testdir/test_spell_utf8.vim\n+++ b/src/testdir/test_spell_utf8.vim\n@@ -802,5 +802,20 @@ func Test_word_index()\n   call delete('Xtmpfile')\n endfunc\n \n+func Test_check_empty_line()\n+  \" This was using freed memory\n+  enew\n+  spellgood! \ufb02\n+  norm z=\n+  norm yy\n+  sil! norm P]svc\n+  norm P]s\n+\n+  \" set 'encoding' to clear the wordt list\n+  set enc=latin1\n+  set enc=utf-8\n+  bwipe!\n+endfunc\n+\n \n \" vim: shiftwidth=2 sts=2 expandtab\ndiff --git a/src/version.c b/src/version.c\nindex ebfd0d45feef0..8f5a4ff71b607 100644\n--- a/src/version.c\n+++ b/src/version.c\n@@ -734,6 +734,8 @@ static char *(features[]) =\n \n static int included_patches[] =\n {   /* Add new patch number below this line */\n+/**/\n+    5072,\n /**/\n     5071,\n /**/\n"
        ],
        "func_after": []
    },
    {
        "idx": 199952,
        "project": "MilkyTracker",
        "commit_id": "3a5474f9102cbdc10fbd9e7b1b2c8d3f3f45d91b",
        "project_url": "https://github.com/milkytracker/MilkyTracker",
        "commit_url": "https://github.com/milkytracker/MilkyTracker/commit/3a5474f9102cbdc10fbd9e7b1b2c8d3f3f45d91b",
        "commit_message": "Fix possible stack corruption with XM instrument headers claiming a size of less than 4\n\nCloses #275",
        "target": 1,
        "irrelevant": 0,
        "func_before": "mp_sint32 LoaderXM::load(XMFileBase& f, XModule* module)\n{\n\tmp_ubyte insData[230];\t\t\n\tmp_sint32 smpReloc[MP_MAXINSSAMPS];\n\tmp_ubyte nbu[MP_MAXINSSAMPS];\n\tmp_uint32 fileSize = 0;\n\t\t\t\n\tmodule->cleanUp();\n\n\t// this will make code much easier to read\n\tTXMHeader*\t\theader = &module->header;\n\tTXMInstrument*\tinstr  = module->instr;\n\tTXMSample*\t\tsmp\t   = module->smp;\n\tTXMPattern*\t\tphead  = module->phead;\t\n\n\t// we're already out of memory here\n\tif (!phead || !instr || !smp)\n\t\treturn MP_OUT_OF_MEMORY;\n\t\n\tfileSize = f.sizeWithBaseOffset();\n\t\n\tf.read(&header->sig,1,17);\n\tf.read(&header->name,1,20);\n\tf.read(&header->whythis1a,1,1);\n\theader->whythis1a=0;\n\tf.read(&header->tracker,1,20);\n\tf.readWords(&header->ver,1);\n\t\n\tif (header->ver != 0x102 && \n\t\theader->ver != 0x103 && // untested\n\t\theader->ver != 0x104)\n\t\treturn MP_LOADER_FAILED;\n\t\n\tf.readDwords(&header->hdrsize,1);\n\t\n\theader->hdrsize-=4;\n\t\n\tmp_uint32 hdrSize = 0x110;\n\tif (header->hdrsize > hdrSize)\n\t\thdrSize = header->hdrsize;\n\t\t\t\t\n\tmp_ubyte* hdrBuff = new mp_ubyte[hdrSize];\n\tmemset(hdrBuff, 0, hdrSize);\n\t\n\tf.read(hdrBuff, 1, header->hdrsize);\n\t\n\theader->ordnum = LittleEndian::GET_WORD(hdrBuff);\n\theader->restart = LittleEndian::GET_WORD(hdrBuff+2);\n\theader->channum = LittleEndian::GET_WORD(hdrBuff+4);\n\theader->patnum = LittleEndian::GET_WORD(hdrBuff+6);\n\theader->insnum = LittleEndian::GET_WORD(hdrBuff+8);\n\theader->freqtab = LittleEndian::GET_WORD(hdrBuff+10);\n\theader->tempo = LittleEndian::GET_WORD(hdrBuff+12);\n\theader->speed = LittleEndian::GET_WORD(hdrBuff+14);\n\tmemcpy(header->ord, hdrBuff+16, 256);\n\tif(header->ordnum > MP_MAXORDERS)\n\t\theader->ordnum = MP_MAXORDERS;\n\tif(header->insnum > MP_MAXINS)\n\t\treturn MP_LOADER_FAILED;\n\n\tdelete[] hdrBuff;\n\t\n\theader->mainvol=255;\n\theader->flags = XModule::MODULE_XMNOTECLIPPING | \n\t\tXModule::MODULE_XMARPEGGIO | \n\t\tXModule::MODULE_XMPORTANOTEBUFFER | \n\t\tXModule::MODULE_XMVOLCOLUMNVIBRATO;\n\n\theader->uppernotebound = 119;\n\t\n\tmp_sint32 i,y,sc;\n\tfor (i=0;i<32;i++) header->pan[i]=0x80;\n\t\n\t// old version?\n\tif (header->ver == 0x102 || header->ver == 0x103)\n\t{\n\t\tmp_sint32 s = 0;\n\t\tmp_sint32 e = 0;\n\t\tfor (y=0;y<header->insnum;y++) {\n\t\t\t\n\t\t\tf.readDwords(&instr[y].size,1);\n\t\t\tf.read(&instr[y].name,1,22);\t\t\n\t\t\tf.read(&instr[y].type,1,1);\n\t\t\tmp_uword numSamples = 0;\n\t\t\tf.readWords(&numSamples,1);\n\t\t\tif(numSamples > MP_MAXINSSAMPS)\n\t\t\t\treturn MP_LOADER_FAILED;\n\t\t\tinstr[y].samp = numSamples;\n\n\t\t\tif (instr[y].size == 29)\n\t\t\t{\n#ifdef MILKYTRACKER\n\t\t\t\ts+=16;\n#endif\n\t\t\t\tfor (mp_sint32 i = 0; i < 120; i++)\n\t\t\t\t\tinstr[y].snum[i] = -1;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tf.readDwords(&instr[y].shsize,1);\n\n\t\t\tmemset(insData, 0, 230);\n\t\t\t\n\t\t\tif (instr[y].size - 33 > 230)\n\t\t\t\treturn MP_OUT_OF_MEMORY;\n\t\t\t\n\t\t\tf.read(insData, 1, instr[y].size - 33);\n\t\t\t\t\t\t\n\t\t\tif (instr[y].samp) {\n\t\t\t\tmp_ubyte* insDataPtr = insData;\n\t\t\t\t\n\t\t\t\tmemcpy(nbu, insDataPtr, MP_MAXINSSAMPS);\n\t\t\t\tinsDataPtr+=MP_MAXINSSAMPS;\n\t\t\t\t\n\t\t\t\tTEnvelope venv;\n\t\t\t\tTEnvelope penv;\n\t\t\t\tmemset(&venv,0,sizeof(venv));\n\t\t\t\tmemset(&penv,0,sizeof(penv));\n\t\t\t\t\n\t\t\t\tmp_sint32 k;\n\t\t\t\tfor (k = 0; k < XM_ENVELOPENUMPOINTS; k++)\n\t\t\t\t{\n\t\t\t\t\tvenv.env[k][0] = LittleEndian::GET_WORD(insDataPtr);\n\t\t\t\t\tvenv.env[k][1] = LittleEndian::GET_WORD(insDataPtr+2);\n\t\t\t\t\tinsDataPtr+=4;\n\t\t\t\t}\n\t\t\t\tfor (k = 0; k < XM_ENVELOPENUMPOINTS; k++)\n\t\t\t\t{\n\t\t\t\t\tpenv.env[k][0] = LittleEndian::GET_WORD(insDataPtr);\n\t\t\t\t\tpenv.env[k][1] = LittleEndian::GET_WORD(insDataPtr+2);\n\t\t\t\t\tinsDataPtr+=4;\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tvenv.num = *insDataPtr++;\t\n\t\t\t\tif (venv.num > XM_ENVELOPENUMPOINTS) venv.num = XM_ENVELOPENUMPOINTS;\n\t\t\t\tpenv.num = *insDataPtr++;\t\n\t\t\t\tif (penv.num > XM_ENVELOPENUMPOINTS) penv.num = XM_ENVELOPENUMPOINTS;\n\t\t\t\tvenv.sustain = *insDataPtr++;\n\t\t\t\tvenv.loops = *insDataPtr++;\n\t\t\t\tvenv.loope = *insDataPtr++;\n\t\t\t\tpenv.sustain = *insDataPtr++;\n\t\t\t\tpenv.loops = *insDataPtr++;\n\t\t\t\tpenv.loope = *insDataPtr++;\n\t\t\t\tvenv.type = *insDataPtr++;\n\t\t\t\tpenv.type = *insDataPtr++;\t\t\t\t\n\t\t\t\t\n\t\t\t\tmp_ubyte vibtype, vibsweep, vibdepth, vibrate;\n\t\t\t\tmp_uword volfade;\n\t\t\t\t\n\t\t\t\tvibtype = *insDataPtr++;\n\t\t\t\tvibsweep = *insDataPtr++;\n\t\t\t\tvibdepth = *insDataPtr++;\n\t\t\t\tvibrate = *insDataPtr++;\n\t\t\t\t\n\t\t\t\tvibdepth<<=1;\n\t\t\t\t\n\t\t\t\tvolfade = LittleEndian::GET_WORD(insDataPtr);\n\t\t\t\tinsDataPtr+=2;\n\t\t\t\tvolfade<<=1;\n\t\t\t\t\n\t\t\t\t//instr[y].res = LittleEndian::GET_WORD(insDataPtr);\n\t\t\t\tinsDataPtr+=2;\n\t\t\t\t\n\t\t\t\tfor (mp_sint32 l=0;l<XM_ENVELOPENUMPOINTS;l++) {\n\t\t\t\t\tvenv.env[l][1]<<=2;\n\t\t\t\t\tpenv.env[l][1]<<=2;\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tif (!module->addVolumeEnvelope(venv)) \n\t\t\t\t\treturn MP_OUT_OF_MEMORY;\n\t\t\t\tif (!module->addPanningEnvelope(penv)) \n\t\t\t\t\treturn MP_OUT_OF_MEMORY;\n\t\t\t\t\n\t\t\t\tmp_sint32 g=0, sc;\n\t\t\t\tfor (sc=0;sc<instr[y].samp;sc++) {\n\t\t\t\t\t\n\t\t\t\t\tsmp[g+s].flags=3;\n\t\t\t\t\tsmp[g+s].venvnum=e+1;\n\t\t\t\t\tsmp[g+s].penvnum=e+1;\n\t\t\t\t\t\n\t\t\t\t\tsmp[g+s].vibtype=vibtype;\n\t\t\t\t\tsmp[g+s].vibsweep=vibsweep;\n\t\t\t\t\tsmp[g+s].vibdepth=vibdepth;\n\t\t\t\t\tsmp[g+s].vibrate=vibrate;\n\t\t\t\t\tsmp[g+s].volfade=volfade;\n\t\t\t\t\t\n\t\t\t\t\t// not sure why I did that, actually doesn't make sense\n\t\t\t\t\t//if (!(venv.type&1)) smp[g+s].volfade=0;\n\t\t\t\t\t\n\t\t\t\t\tf.readDwords(&smp[g+s].samplen,1);\n\t\t\t\t\tf.readDwords(&smp[g+s].loopstart,1);\n\t\t\t\t\tf.readDwords(&smp[g+s].looplen,1);\n\t\t\t\t\tsmp[g+s].vol=XModule::vol64to255(f.readByte());\n\t\t\t\t\t//f.read(&smp[g+s].vol,1,1);\n\t\t\t\t\tf.read(&smp[g+s].finetune,1,1);\n\t\t\t\t\tf.read(&smp[g+s].type,1,1);\n#ifdef VERBOSE\n\t\t\t\t\tprintf(\"Before: %i, After: %i\\n\", smp[g+s].type, smp[g+s].type & (3+16));\n#endif\n\t\t\t\t\tf.read(&smp[g+s].pan,1,1);\n\t\t\t\t\tf.read(&smp[g+s].relnote,1,1);\n\t\t\t\t\tf.read(&smp[g+s].res,1,1);\n\t\t\t\t\tf.read(&smp[g+s].name,1,22);\n\t\t\t\t\t\n\t\t\t\t\tchar line[30];\n\t\t\t\t\tmemset(line, 0, sizeof(line));\n\t\t\t\t\tXModule::convertStr(line, smp[g+s].name, 23, false);\t\t\t\t\t\n\t\t\t\t\tif (line[0])\n\t\t\t\t\t\tmodule->addSongMessageLine(line);\n\t\t\t\t\t\n\t\t\t\t\t// ignore empty samples\n#ifndef MILKYTRACKER\n\t\t\t\t\t// ignore empty samples when not being a tracker\n\t\t\t\t\tif (smp[g+s].samplen) {\n\t\t\t\t\t\tsmpReloc[sc] = g;\n\t\t\t\t\t\tg++;\n\t\t\t\t\t}\n\t\t\t\t\telse\n\t\t\t\t\t\tsmpReloc[sc] = -1;\n#else\n\t\t\t\t\tsmpReloc[sc] = g;\n\t\t\t\t\tg++;\n#endif\n\t\t\t\t}\n\n\t\t\t\tinstr[y].samp = g;\n\n\t\t\t\tfor (sc = 0; sc < MP_MAXINSSAMPS; sc++) {\n\t\t\t\t\tif (smpReloc[nbu[sc]] == -1)\n\t\t\t\t\t\tinstr[y].snum[sc] = -1;\n\t\t\t\t\telse\n\t\t\t\t\t\tinstr[y].snum[sc] = smpReloc[nbu[sc]]+s;\t\t\t\t\t\n\t\t\t\t}\n\n\t\t\t\te++;\n\t\t\t\t\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tfor (mp_sint32 i = 0; i < 120; i++)\n\t\t\t\t\tinstr[y].snum[i] = -1;\n\t\t\t}\n\n#ifdef MILKYTRACKER\n\t\t\ts+=16;\n#else\n\t\t\ts+=instr[y].samp;\n#endif\t\t\t\t\n\t\t\t\t\n\t\t\t\n\t\t}\n\t\t\n\t\theader->smpnum=s;\n\t\theader->volenvnum=e;\n\t\theader->panenvnum=e;\n\t}\n\t\n\tfor (y=0;y<header->patnum;y++) {\n\t\t\n\t\tif (header->ver == 0x104 || header->ver == 0x103)\n\t\t{\n\t\t\tf.readDwords(&phead[y].len,1);\n\t\t\tf.read(&phead[y].ptype,1,1);\n\t\t\tf.readWords(&phead[y].rows,1);\n\t\t\tf.readWords(&phead[y].patdata,1);\n\t\t}\n\t\telse\n\t\t{\n\t\t\tf.readDwords(&phead[y].len,1);\n\t\t\tf.read(&phead[y].ptype,1,1);\n\t\t\tphead[y].rows = (mp_uword)f.readByte()+1;\n\t\t\tf.readWords(&phead[y].patdata,1);\t\t\t\n\t\t}\n\t\t\n\t\tphead[y].effnum=2;\n\t\tphead[y].channum=(mp_ubyte)header->channum;\n\t\t\n\t\tphead[y].patternData = new mp_ubyte[phead[y].rows*header->channum*6];\n\t\t\n\t\t// out of memory?\n\t\tif (phead[y].patternData == NULL)\n\t\t{\n\t\t\treturn MP_OUT_OF_MEMORY;\n\t\t}\n\t\t\n\t\tmemset(phead[y].patternData,0,phead[y].rows*header->channum*6);\n\t\t\n\t\tif (phead[y].patdata) {\n\t\t\tmp_ubyte *buffer = new mp_ubyte[phead[y].patdata];\n\t\t\t\n\t\t\t// out of memory?\n\t\t\tif (buffer == NULL)\n\t\t\t{\n\t\t\t\treturn MP_OUT_OF_MEMORY;\t\t\t\n\t\t\t}\n\t\t\t\n\t\t\tf.read(buffer,1,phead[y].patdata);\n\t\t\t\n\t\t\t//printf(\"%i\\n\", phead[y].patdata);\n\t\t\t\n\t\t\tmp_sint32 pc = 0, bc = 0;\n\t\t\tfor (mp_sint32 r=0;r<phead[y].rows;r++) {\n\t\t\t\tfor (mp_sint32 c=0;c<header->channum;c++) {\n\t\t\t\t\t\n\t\t\t\t\tmp_ubyte slot[5];\n\t\t\t\t\tmemset(slot,0,5);\n\t\t\t\t\t\n\t\t\t\t\tif ((buffer[pc]&128)) {\n\t\t\t\t\t\t\n\t\t\t\t\t\tmp_ubyte pb = buffer[pc];\n\t\t\t\t\t\tpc++;\n\t\t\t\t\t\t\n\t\t\t\t\t\tif ((pb&1)) {\n\t\t\t\t\t\t\t//phead[y].patternData[bc]=buffer[pc];\n\t\t\t\t\t\t\tslot[0]=buffer[pc];\n\t\t\t\t\t\t\tpc++;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif ((pb&2)) {\n\t\t\t\t\t\t\t//phead[y].patternData[bc+1]=buffer[pc];\n\t\t\t\t\t\t\tslot[1]=buffer[pc];\n\t\t\t\t\t\t\tpc++;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif ((pb&4)) {\n\t\t\t\t\t\t\t//phead[y].patternData[bc+2]=buffer[pc];\n\t\t\t\t\t\t\tslot[2]=buffer[pc];\n\t\t\t\t\t\t\tpc++;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif ((pb&8)) {\n\t\t\t\t\t\t\t//phead[y].patternData[bc+3]=buffer[pc];\n\t\t\t\t\t\t\tslot[3]=buffer[pc];\n\t\t\t\t\t\t\tpc++;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif ((pb&16)) {\n\t\t\t\t\t\t\t//phead[y].patternData[bc+4]=buffer[pc];\n\t\t\t\t\t\t\tslot[4]=buffer[pc];\n\t\t\t\t\t\t\tpc++;\n\t\t\t\t\t\t}\n\t\t\t\t\t\t\n\t\t\t\t\t}\n\t\t\t\t\telse {\n\t\t\t\t\t\t//memcpy(phead[y].patternData+bc,buffer+pc,5);\n\t\t\t\t\t\tmemcpy(slot,buffer+pc,5);\n\t\t\t\t\t\tpc+=5;\n\t\t\t\t\t}\n\t\t\t\t\t\n\t\t\t\t\tchar gl=0;\n\t\t\t\t\tfor (mp_sint32 i=0;i<XModule::numValidXMEffects;i++)\n\t\t\t\t\t\tif (slot[3]==XModule::validXMEffects[i]) gl=1;\n\t\t\t\t\t\n\t\t\t\t\tif (!gl) slot[3]=slot[4]=0;\n\t\t\t\t\t\n\t\t\t\t\tif ((slot[3]==0xC)||(slot[3]==0x10)) {\n\t\t\t\t\t\tslot[4] = XModule::vol64to255(slot[4]);\n\t\t\t\t\t\t/*mp_sint32 bl = slot[4];\n\t\t\t\t\t\tif (bl>64) bl=64;\n\t\t\t\t\t\tslot[4]=(bl*261120)>>16;*/\n\t\t\t\t\t}\n\t\t\t\t\t\n\t\t\t\t\tif ((!slot[3])&&(slot[4])) slot[3]=0x20;\n\t\t\t\t\t\n\t\t\t\t\tif (slot[3]==0xE) {\n\t\t\t\t\t\tslot[3]=(slot[4]>>4)+0x30;\n\t\t\t\t\t\tslot[4]=slot[4]&0xf;\n\t\t\t\t\t}\n\t\t\t\t\t\n\t\t\t\t\tif (slot[3]==0x21) {\n\t\t\t\t\t\tslot[3]=(slot[4]>>4)+0x40;\n\t\t\t\t\t\tslot[4]=slot[4]&0xf;\n\t\t\t\t\t}\n\t\t\t\t\t\n\t\t\t\t\tif (slot[0]==97) slot[0]=XModule::NOTE_OFF;\n\t\t\t\t\t\n\t\t\t\t\tphead[y].patternData[bc]=slot[0];\n\t\t\t\t\tphead[y].patternData[bc+1]=slot[1];\n\t\t\t\t\t\n\t\t\t\t\tXModule::convertXMVolumeEffects(slot[2], phead[y].patternData[bc+2], phead[y].patternData[bc+3]);\n\n\t\t\t\t\tphead[y].patternData[bc+4]=slot[3];\n\t\t\t\t\tphead[y].patternData[bc+5]=slot[4];\n\t\t\t\t\t\n\t\t\t\t\t/*if ((y==3)&&(c==2)) {\n\t\t\t\t\t\tfor (mp_sint32 bl=0;bl<6;bl++) cprintf(\"%x \",phead[y].patternData[bc+bl]);\n\t\t\t\t\tcprintf(\"\\r\\n\");\n\t\t\t\t\tgetch();\n\t\t\t\t\t};*/\n\t\t\t\t\t\n\t\t\t\t\t/*printf(\"Note : %i\\r\\n\",phead[y].patternData[bc]);\n\t\t\t\t\tprintf(\"Ins  : %i\\r\\n\",phead[y].patternData[bc+1]);\n\t\t\t\t\tprintf(\"Vol  : %i\\r\\n\",phead[y].patternData[bc+2]);\n\t\t\t\t\tprintf(\"Eff  : %i\\r\\n\",phead[y].patternData[bc+3]);\n\t\t\t\t\tprintf(\"Effop: %i\\r\\n\",phead[y].patternData[bc+4]);\n\t\t\t\t\tgetch();*/\n\t\t\t\t\t\n\t\t\t\t\tbc+=6;\n\t\t\t\t} // for c\n\t\t\t\t\t\n\t\t\t} // for r\n\t\t\t\t\n\t\t\tdelete[] buffer;\n\t\t}\n\t\t\t\n\t}\n\t\t\n\tif (header->ver == 0x104)\n\t{\n\t\tmp_sint32 s = 0;\n\t\tmp_sint32 e = 0;\n\t\tfor (y=0;y<header->insnum;y++) {\n\n\t\t\t// fixes MOOH.XM loading problems\n\t\t\t// seems to store more instruments in the header than in the actual file\n\t\t\tif (f.posWithBaseOffset() >= fileSize)\n\t\t\t\tbreak;\n\t\t\n\t\t\t//TXMInstrument* ins = &instr[y];\n\t\t\n\t\t\tf.readDwords(&instr[y].size,1);\n\t\t\t\n\t\t\tif (instr[y].size < 29)\n\t\t\t{\n\t\t\t\tmp_ubyte buffer[29];\n\t\t\t\tmemset(buffer, 0, sizeof(buffer));\n\t\t\t\tf.read(buffer, 1, instr[y].size - 4);\n\t\t\t\tmemcpy(instr[y].name, buffer, 22);\n\t\t\t\tinstr[y].type = buffer[22];\n\t\t\t\tinstr[y].samp = LittleEndian::GET_WORD(buffer + 23);\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tf.read(&instr[y].name,1,22);\t\t\n\t\t\t\tf.read(&instr[y].type,1,1);\n\t\t\t\tf.readWords(&instr[y].samp,1);\n\t\t\t}\n\t\t\tif (instr[y].samp > MP_MAXINSSAMPS)\n\t\t\t\treturn MP_LOADER_FAILED;\n\n\t\t\t//printf(\"%i, %i\\n\", instr[y].size, instr[y].samp);\n\n\t\t\tif (instr[y].size <= 29)\n\t\t\t{\n#ifdef MILKYTRACKER\n\t\t\t\ts+=16;\n#endif\n\t\t\t\tfor (mp_sint32 i = 0; i < 120; i++)\n\t\t\t\t\tinstr[y].snum[i] = -1;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tf.readDwords(&instr[y].shsize,1);\n#ifdef VERBOSE\n\t\t\tprintf(\"%i/%i: %i, %i, %i, %s\\n\",y,header->insnum-1,instr[y].size,instr[y].shsize,instr[y].samp,instr[y].name);\t\t\t\n#endif\n\t\t\tmemset(insData, 0, 230);\n\t\t\t\n\t\t\tif (instr[y].size - 33 > 230)\n\t\t\t{\n\t\t\t\t//return -7;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\t\n\t\t\tf.read(insData, 1, instr[y].size - 33);\n\t\t\t\n\t\t\t/*printf(\"%i\\r\\n\",instr[y].size);\n\t\t\tprintf(\"%s\\r\\n\",instr[y].name);\n\t\t\tprintf(\"%i\\r\\n\",instr[y].type);\n\t\t\tprintf(\"%i\\r\\n\",instr[y].samp);\n\t\t\tprintf(\"%i\\r\\n\",instr[y].shsize);*/\n\t\t\t//getch();\n\t\t\t\t\t\n\t\t\tmemset(smpReloc, 0, sizeof(smpReloc));\n\t\t\t\n\t\t\tif (instr[y].samp) {\n\t\t\t\tmp_ubyte* insDataPtr = insData;\n\t\t\t\t\n\t\t\t\t//f.read(&nbu,1,96);\n\t\t\t\t\n\t\t\t\tmemcpy(nbu, insDataPtr, MP_MAXINSSAMPS);\n\t\t\t\tinsDataPtr+=MP_MAXINSSAMPS;\n\t\t\t\t\n\t\t\t\tTEnvelope venv;\n\t\t\t\tTEnvelope penv;\n\t\t\t\tmemset(&venv,0,sizeof(venv));\n\t\t\t\tmemset(&penv,0,sizeof(penv));\n\t\t\t\t\n\t\t\t\tmp_sint32 k;\n\t\t\t\tfor (k = 0; k < XM_ENVELOPENUMPOINTS; k++)\n\t\t\t\t{\n\t\t\t\t\tvenv.env[k][0] = LittleEndian::GET_WORD(insDataPtr);\n\t\t\t\t\tvenv.env[k][1] = LittleEndian::GET_WORD(insDataPtr+2);\n\t\t\t\t\tinsDataPtr+=4;\n\t\t\t\t}\n\t\t\t\tfor (k = 0; k < XM_ENVELOPENUMPOINTS; k++)\n\t\t\t\t{\n\t\t\t\t\tpenv.env[k][0] = LittleEndian::GET_WORD(insDataPtr);\n\t\t\t\t\tpenv.env[k][1] = LittleEndian::GET_WORD(insDataPtr+2);\n\t\t\t\t\tinsDataPtr+=4;\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tvenv.num = *insDataPtr++;\t\n\t\t\t\tif (venv.num > XM_ENVELOPENUMPOINTS) venv.num = XM_ENVELOPENUMPOINTS;\n\t\t\t\tpenv.num = *insDataPtr++;\t\t\t\t\t\n\t\t\t\tif (penv.num > XM_ENVELOPENUMPOINTS) penv.num = XM_ENVELOPENUMPOINTS;\n\t\t\t\tvenv.sustain = *insDataPtr++;\n\t\t\t\tvenv.loops = *insDataPtr++;\n\t\t\t\tvenv.loope = *insDataPtr++;\n\t\t\t\tpenv.sustain = *insDataPtr++;\n\t\t\t\tpenv.loops = *insDataPtr++;\n\t\t\t\tpenv.loope = *insDataPtr++;\n\t\t\t\tvenv.type = *insDataPtr++;\n\t\t\t\tpenv.type = *insDataPtr++;\t\t\t\t\n\t\t\t\t\n\t\t\t\tmp_ubyte vibtype, vibsweep, vibdepth, vibrate;\n\t\t\t\tmp_uword volfade;\n\t\t\t\t\n\t\t\t\tvibtype = *insDataPtr++;\n\t\t\t\tvibsweep = *insDataPtr++;\n\t\t\t\tvibdepth = *insDataPtr++;\n\t\t\t\tvibrate = *insDataPtr++;\n\t\t\t\t\n\t\t\t\tvibdepth<<=1;\n\t\t\t\t\n\t\t\t\t//f.readWords(&volfade,1);\n\t\t\t\tvolfade = LittleEndian::GET_WORD(insDataPtr);\n\t\t\t\tinsDataPtr+=2;\n\t\t\t\tvolfade<<=1;\n\t\t\t\t\n\t\t\t\t//instr[y].res = LittleEndian::GET_WORD(insDataPtr);\n\t\t\t\tinsDataPtr+=2;\n\t\t\t\t\n\t\t\t\tfor (mp_sint32 l=0;l<XM_ENVELOPENUMPOINTS;l++) {\n\t\t\t\t\tvenv.env[l][1]<<=2;\n\t\t\t\t\tpenv.env[l][1]<<=2;\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tif (!module->addVolumeEnvelope(venv)) \n\t\t\t\t\treturn MP_OUT_OF_MEMORY;\n\t\t\t\tif (!module->addPanningEnvelope(penv)) \n\t\t\t\t\treturn MP_OUT_OF_MEMORY;\n\t\t\t\t\n\t\t\t\tmp_sint32 g=0, sc;\n\t\t\t\tfor (sc=0;sc<instr[y].samp;sc++) {\n\t\t\t\t\t//TXMSample* smpl = &smp[g+s];\n\t\t\t\t\t\n\t\t\t\t\tsmp[g+s].flags=3;\n\t\t\t\t\tsmp[g+s].venvnum=e+1;\n\t\t\t\t\tsmp[g+s].penvnum=e+1;\n\t\t\t\t\t\n\t\t\t\t\tsmp[g+s].vibtype=vibtype;\n\t\t\t\t\tsmp[g+s].vibsweep=vibsweep;\n\t\t\t\t\tsmp[g+s].vibdepth=vibdepth;\n\t\t\t\t\tsmp[g+s].vibrate=vibrate;\n\t\t\t\t\tsmp[g+s].volfade=volfade;\n\t\t\t\t\t\n\t\t\t\t\t// not sure why I did that, actually doesn't make sense\n\t\t\t\t\t//if (!(venv.type&1)) smp[g+s].volfade=0;\n\t\t\t\t\t\n\t\t\t\t\tf.readDwords(&smp[g+s].samplen,1);\n\t\t\t\t\t\n\t\t\t\t\tf.readDwords(&smp[g+s].loopstart,1);\n\t\t\t\t\tf.readDwords(&smp[g+s].looplen,1);\n\t\t\t\t\tsmp[g+s].vol=XModule::vol64to255(f.readByte());\n\t\t\t\t\t//f.read(&smp[g+s].vol,1,1);\n\t\t\t\t\tf.read(&smp[g+s].finetune,1,1);\n\t\t\t\t\tf.read(&smp[g+s].type,1,1);\n#ifdef VERBOSE\n\t\t\t\t\tprintf(\"Before: %i, After: %i\\n\", smp[g+s].type, smp[g+s].type & (3+16));\n#endif\n\t\t\t\t\tf.read(&smp[g+s].pan,1,1);\n\t\t\t\t\tf.read(&smp[g+s].relnote,1,1);\n\t\t\t\t\tf.read(&smp[g+s].res,1,1);\n\t\t\t\t\tf.read(&smp[g+s].name,1,22);\n\n\t\t\t\t\tchar line[30];\n\t\t\t\t\tmemset(line, 0, sizeof(line));\n\t\t\t\t\tXModule::convertStr(line, smp[g+s].name, 23, false);\t\t\t\t\t\n\t\t\t\t\tif (line[0])\n\t\t\t\t\t\tmodule->addSongMessageLine(line);\n\t\t\t\t\t\n#ifndef MILKYTRACKER\n\t\t\t\t\t// ignore empty samples when not being a tracker\n\t\t\t\t\tif (smp[g+s].samplen) {\n\t\t\t\t\t\tsmpReloc[sc] = g;\n\t\t\t\t\t\tg++;\n\t\t\t\t\t}\n\t\t\t\t\telse\n\t\t\t\t\t\tsmpReloc[sc] = -1;\n#else\n\t\t\t\t\tsmpReloc[sc] = g;\n\t\t\t\t\tg++;\n#endif\n\t\t\t\t}\n\n\t\t\t\tinstr[y].samp = g;\n\n\t\t\t\tfor (sc = 0; sc < MP_MAXINSSAMPS; sc++) {\t\t\t\t\t\n\t\t\t\t\tif (smpReloc[nbu[sc]] == -1)\n\t\t\t\t\t\tinstr[y].snum[sc] = -1;\n\t\t\t\t\telse\n\t\t\t\t\t\tinstr[y].snum[sc] = smpReloc[nbu[sc]]+s;\n\t\t\t\t}\n\t\t\t\t\t\t\n\t\t\t\tfor (sc=0;sc<instr[y].samp;sc++) {\n\t\t\t\t\n\t\t\t\t\tif (smp[s].samplen)\n\t\t\t\t\t{\n\t\t\t\t\t\tbool adpcm = (smp[s].res == 0xAD);\n\t\t\t\t\t\n\t\t\t\t\t\tmp_uint32 oldSize = smp[s].samplen;\n\t\t\t\t\t\tif (smp[s].type&16) \n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tsmp[s].samplen>>=1;\n\t\t\t\t\t\t\tsmp[s].loopstart>>=1;\n\t\t\t\t\t\t\tsmp[s].looplen>>=1;\n\t\t\t\t\t\t}\n\t\t\t\t\t\t\n\t\t\t\t\t\tmp_sint32 result = module->loadModuleSample(f, s, \n\t\t\t\t\t\t\t\t\t\t\t\t\t adpcm ? XModule::ST_PACKING_ADPCM : XModule::ST_DELTA, \n\t\t\t\t\t\t\t\t\t\t\t\t\t adpcm ? (XModule::ST_PACKING_ADPCM | XModule::ST_16BIT) : (XModule::ST_DELTA | XModule::ST_16BIT), \n\t\t\t\t\t\t\t\t\t\t\t\t\t oldSize);\n\t\t\t\t\t\tif (result != MP_OK)\n\t\t\t\t\t\t\treturn result;\t\t\t\t\t\n\t\t\t\t\t\t\n\t\t\t\t\t\tif (adpcm)\n\t\t\t\t\t\t\tsmp[s].res = 0;\n\t\t\t\t\t}\n\t\t\t\t\t\n\t\t\t\t\ts++;\n\t\t\t\t\t\n\t\t\t\t\tif (s>=MP_MAXSAMPLES)\n\t\t\t\t\t\treturn MP_OUT_OF_MEMORY;\n\t\t\t\t\t\n\t\t\t\t}\n\n\t\t\t\te++;\n\t\t\t\t\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tfor (mp_sint32 i = 0; i < 120; i++)\n\t\t\t\t\tinstr[y].snum[i] = -1;\n\t\t\t}\n\n#ifdef MILKYTRACKER\n\t\t\ts+=16 - instr[y].samp;\n#endif\t\t\t\t\n\t\t\t\n\t\t}\n\t\t\n\t\theader->smpnum=s;\n\t\theader->volenvnum=e;\n\t\theader->panenvnum=e;\t\t\n\t\t\n\t}\n\telse\n\t{\n\t\tmp_sint32 s = 0;\n\t\tfor (y=0;y<header->insnum;y++) {\n\t\t\tfor (sc=0;sc<instr[y].samp;sc++) {\n\n\t\t\t\tif (smp[s].samplen)\n\t\t\t\t{\n\t\t\t\t\tmp_uint32 oldSize = smp[s].samplen;\n\t\t\t\t\tif (smp[s].type&16) \n\t\t\t\t\t{\n\t\t\t\t\t\tsmp[s].samplen>>=1;\n\t\t\t\t\t\tsmp[s].loopstart>>=1;\n\t\t\t\t\t\tsmp[s].looplen>>=1;\n\t\t\t\t\t}\n\t\t\t\t\t\n\t\t\t\t\tmp_sint32 result = module->loadModuleSample(f, s, XModule::ST_DELTA, XModule::ST_DELTA | XModule::ST_16BIT, oldSize);\n\t\t\t\t\tif (result != MP_OK)\n\t\t\t\t\t\treturn result;\t\t\t\t\t\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\ts++;\n\t\t\t\t\n\t\t\t\tif (s>=MP_MAXSAMPLES)\n\t\t\t\t\treturn MP_OUT_OF_MEMORY;\t\t\t\t\n\t\t\t}\n\t\t\t\n#ifdef MILKYTRACKER\n\t\t\ts+=16 - instr[y].samp;\n#endif\n\t\t\t\n\t\t}\t\t\n\t}\n\t\n\t// convert modplug stereo samples\n\tfor (mp_sint32 s = 0; s < header->smpnum; s++)\n\t{\n\t\tif (smp[s].type & 32)\n\t\t{\t\t\n\t\t\t// that's what's allowed, stupid modplug tracker\n\t\t\tsmp[s].type &= 3+16;\t\t\t\t\t\n\n\t\t\tif (smp[s].sample == NULL)\n\t\t\t\tcontinue;\n\t\t\t\n\t\t\tif (!(smp[s].type&16)) {\t\t\t\n\t\t\t\tsmp[s].samplen>>=1;\n\t\t\t\tsmp[s].loopstart>>=1;\n\t\t\t\tsmp[s].looplen>>=1;\n\t\t\t\t\n\t\t\t\tmp_sbyte* sample = (mp_sbyte*)smp[s].sample;\n\t\t\t\tmp_sint32 samplen = smp[s].samplen;\n\t\t\t\tfor (mp_sint32 i = 0; i < samplen; i++)\n\t\t\t\t{\n\t\t\t\t\tmp_sint32 s = ((mp_sint32)sample[i] + (mp_sint32)sample[i + samplen]) >> 1;\n\t\t\t\t\tif (s < -128) s = -128;\n\t\t\t\t\tif (s > 127) s = 127;\n\t\t\t\t\tsample[i] = (mp_sbyte)s;\n\t\t\t\t}\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tsmp[s].samplen>>=1;\n\t\t\t\tsmp[s].loopstart>>=1;\n\t\t\t\tsmp[s].looplen>>=1;\n\t\t\t\t\n\t\t\t\tmp_sword* sample = (mp_sword*)smp[s].sample;\n\t\t\t\tmp_sint32 samplen = smp[s].samplen;\n\t\t\t\tfor (mp_sint32 i = 0; i < samplen; i++)\n\t\t\t\t{\n\t\t\t\t\tmp_sint32 s = ((mp_sint32)sample[i] + (mp_sint32)sample[i + samplen]) >> 1;\n\t\t\t\t\tif (s < -32768) s = -32768;\n\t\t\t\t\tif (s > 32767) s = 32767;\n\t\t\t\t\tsample[i] = (mp_sword)s;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t\n\t\t// correct loop type 0x03 (undefined)\n\t\t// will become ping pong loop\n\t\t// note that FT2 will refuse to load XM files with such a loop type\n\t\tif ((smp[s].type & 0x3) == 0x3)\n\t\t\tsmp[s].type&=~1;\t\t\n\t}\n\n\t// correct number of patterns if necessary, otherwise the post processing will remove\n\t// the \"invalid\" patterns from the order list\n\tbool addPatterns = false;\n\tfor (i = 0; i < header->ordnum; i++)\n\t\tif (header->ord[i]+1 > header->patnum)\n\t\t{\n\t\t\theader->patnum = header->ord[i]+1;\t\n\t\t\taddPatterns = true;\n\t\t}\n\t\n\t// if the pattern number has been adjusted, add some empty patterns\n\tif (addPatterns)\n\t{\n\t\tfor (i = 0; i < header->patnum; i++)\n\t\t\tif (phead[i].patternData == NULL)\n\t\t\t{\n\t\t\t\tphead[i].rows = 64;\n\t\t\t\tphead[i].effnum = 2;\n\t\t\t\tphead[i].channum = (mp_ubyte)header->channum;\n\n\t\t\t\tphead[i].patternData = new mp_ubyte[phead[i].rows*header->channum*6];\n\t\t\t\n\t\t\t\t// out of memory?\n\t\t\t\tif (phead[i].patternData == NULL)\n\t\t\t\t{\n\t\t\t\t\treturn MP_OUT_OF_MEMORY;\n\t\t\t\t}\n\t\t\n\t\t\t\tmemset(phead[i].patternData,0,phead[i].rows*header->channum*6);\n\t\t\t}\n\t}\n\t\n\t// check for MODPLUG extensions\n\tif (f.posWithBaseOffset() + 8 <= fileSize)\n\t{\n\t\tchar buffer[4];\n\t\tf.read(buffer, 1, 4);\n\t\tif (memcmp(buffer, \"text\", 4) == 0)\n\t\t{\n\t\t\tmp_uint32 len = f.readDword();\n\t\t\tmodule->allocateSongMessage(len+1);\n\t\t\t\n\t\t\tmemset(module->message, 0, len+1);\n\t\t\t\n\t\t\tf.read(module->message, 1, len);\n\t\t}\n\t}\n\t\n\tmodule->postProcessSamples();\n\t\n\treturn MP_OK;\n}",
        "func_hash": 297622282182467898464562664481031169978,
        "file_name": "LoaderXM.cpp",
        "file_hash": null,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2022-34927",
        "cve_desc": "MilkyTracker v1.03.00 was discovered to contain a stack overflow via the component LoaderXM::load. This vulnerability is triggered when the program is supplied a crafted XM module file.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-34927",
        "func_name": "LoaderXM::load",
        "diff": [
            "diff --git a/src/milkyplay/LoaderXM.cpp b/src/milkyplay/LoaderXM.cpp\nindex f87f5c11..303e3493 100644\n--- a/src/milkyplay/LoaderXM.cpp\n+++ b/src/milkyplay/LoaderXM.cpp\n@@ -478,7 +478,7 @@ mp_sint32 LoaderXM::load(XMFileBase& f, XModule* module)\n \t\t\n \t\t\tf.readDwords(&instr[y].size,1);\n \t\t\t\n-\t\t\tif (instr[y].size < 29)\n+\t\t\tif (instr[y].size >= 4 && instr[y].size < 29)\n \t\t\t{\n \t\t\t\tmp_ubyte buffer[29];\n \t\t\t\tmemset(buffer, 0, sizeof(buffer));\n"
        ],
        "func_after": []
    },
    {
        "idx": 199984,
        "project": "vim",
        "commit_id": "37f47958b8a2a44abc60614271d9537e7f14e51a",
        "project_url": "https://github.com/vim/vim",
        "commit_url": "https://github.com/vim/vim/commit/37f47958b8a2a44abc60614271d9537e7f14e51a",
        "commit_message": "patch 8.2.4253: using freed memory when substitute with function call\n\nProblem:    Using freed memory when substitute uses a recursive function call.\nSolution:   Make a copy of the substitute text.",
        "target": 1,
        "irrelevant": 1,
        "func_before": "ex_substitute(exarg_T *eap)\n{\n    linenr_T\tlnum;\n    long\ti = 0;\n    regmmatch_T regmatch;\n    static subflags_T subflags = {FALSE, FALSE, FALSE, TRUE, FALSE,\n\t\t\t\t\t\t\t      FALSE, FALSE, 0};\n#ifdef FEAT_EVAL\n    subflags_T\tsubflags_save;\n#endif\n    int\t\tsave_do_all;\t\t// remember user specified 'g' flag\n    int\t\tsave_do_ask;\t\t// remember user specified 'c' flag\n    char_u\t*pat = NULL, *sub = NULL;\t// init for GCC\n    int\t\tdelimiter;\n    int\t\tsublen;\n    int\t\tgot_quit = FALSE;\n    int\t\tgot_match = FALSE;\n    int\t\ttemp;\n    int\t\twhich_pat;\n    char_u\t*cmd;\n    int\t\tsave_State;\n    linenr_T\tfirst_line = 0;\t\t// first changed line\n    linenr_T\tlast_line= 0;\t\t// below last changed line AFTER the\n\t\t\t\t\t// change\n    linenr_T\told_line_count = curbuf->b_ml.ml_line_count;\n    linenr_T\tline2;\n    long\tnmatch;\t\t\t// number of lines in match\n    char_u\t*sub_firstline;\t\t// allocated copy of first sub line\n    int\t\tendcolumn = FALSE;\t// cursor in last column when done\n    pos_T\told_cursor = curwin->w_cursor;\n    int\t\tstart_nsubs;\n#ifdef FEAT_EVAL\n    int\t\tsave_ma = 0;\n#endif\n\n    cmd = eap->arg;\n    if (!global_busy)\n    {\n\tsub_nsubs = 0;\n\tsub_nlines = 0;\n    }\n    start_nsubs = sub_nsubs;\n\n    if (eap->cmdidx == CMD_tilde)\n\twhich_pat = RE_LAST;\t// use last used regexp\n    else\n\twhich_pat = RE_SUBST;\t// use last substitute regexp\n\n\t\t\t\t// new pattern and substitution\n    if (eap->cmd[0] == 's' && *cmd != NUL && !VIM_ISWHITE(*cmd)\n\t\t&& vim_strchr((char_u *)\"0123456789cegriIp|\\\"\", *cmd) == NULL)\n    {\n\t\t\t\t// don't accept alphanumeric for separator\n\tif (check_regexp_delim(*cmd) == FAIL)\n\t    return;\n#ifdef FEAT_EVAL\n\tif (in_vim9script() && check_global_and_subst(eap->cmd, eap->arg)\n\t\t\t\t\t\t\t\t      == FAIL)\n\t    return;\n#endif\n\n\t/*\n\t * undocumented vi feature:\n\t *  \"\\/sub/\" and \"\\?sub?\" use last used search pattern (almost like\n\t *  //sub/r).  \"\\&sub&\" use last substitute pattern (like //sub/).\n\t */\n\tif (*cmd == '\\\\')\n\t{\n\t    ++cmd;\n\t    if (vim_strchr((char_u *)\"/?&\", *cmd) == NULL)\n\t    {\n\t\temsg(_(e_backslash_should_be_followed_by));\n\t\treturn;\n\t    }\n\t    if (*cmd != '&')\n\t\twhich_pat = RE_SEARCH;\t    // use last '/' pattern\n\t    pat = (char_u *)\"\";\t\t    // empty search pattern\n\t    delimiter = *cmd++;\t\t    // remember delimiter character\n\t}\n\telse\t\t// find the end of the regexp\n\t{\n\t    which_pat = RE_LAST;\t    // use last used regexp\n\t    delimiter = *cmd++;\t\t    // remember delimiter character\n\t    pat = cmd;\t\t\t    // remember start of search pat\n\t    cmd = skip_regexp_ex(cmd, delimiter, magic_isset(),\n\t\t\t\t\t\t\t&eap->arg, NULL, NULL);\n\t    if (cmd[0] == delimiter)\t    // end delimiter found\n\t\t*cmd++ = NUL;\t\t    // replace it with a NUL\n\t}\n\n\t/*\n\t * Small incompatibility: vi sees '\\n' as end of the command, but in\n\t * Vim we want to use '\\n' to find/substitute a NUL.\n\t */\n\tsub = cmd;\t    // remember the start of the substitution\n\tcmd = skip_substitute(cmd, delimiter);\n\n\tif (!eap->skip)\n\t{\n\t    // In POSIX vi \":s/pat/%/\" uses the previous subst. string.\n\t    if (STRCMP(sub, \"%\") == 0\n\t\t\t\t && vim_strchr(p_cpo, CPO_SUBPERCENT) != NULL)\n\t    {\n\t\tif (old_sub == NULL)\t// there is no previous command\n\t\t{\n\t\t    emsg(_(e_no_previous_substitute_regular_expression));\n\t\t    return;\n\t\t}\n\t\tsub = old_sub;\n\t    }\n\t    else\n\t    {\n\t\tvim_free(old_sub);\n\t\told_sub = vim_strsave(sub);\n\t    }\n\t}\n    }\n    else if (!eap->skip)\t// use previous pattern and substitution\n    {\n\tif (old_sub == NULL)\t// there is no previous command\n\t{\n\t    emsg(_(e_no_previous_substitute_regular_expression));\n\t    return;\n\t}\n\tpat = NULL;\t\t// search_regcomp() will use previous pattern\n\tsub = old_sub;\n\n\t// Vi compatibility quirk: repeating with \":s\" keeps the cursor in the\n\t// last column after using \"$\".\n\tendcolumn = (curwin->w_curswant == MAXCOL);\n    }\n\n    // Recognize \":%s/\\n//\" and turn it into a join command, which is much\n    // more efficient.\n    // TODO: find a generic solution to make line-joining operations more\n    // efficient, avoid allocating a string that grows in size.\n    if (pat != NULL && STRCMP(pat, \"\\\\n\") == 0\n\t    && *sub == NUL\n\t    && (*cmd == NUL || (cmd[1] == NUL && (*cmd == 'g' || *cmd == 'l'\n\t\t\t\t\t     || *cmd == 'p' || *cmd == '#'))))\n    {\n\tlinenr_T    joined_lines_count;\n\n\tif (eap->skip)\n\t    return;\n\tcurwin->w_cursor.lnum = eap->line1;\n\tif (*cmd == 'l')\n\t    eap->flags = EXFLAG_LIST;\n\telse if (*cmd == '#')\n\t    eap->flags = EXFLAG_NR;\n\telse if (*cmd == 'p')\n\t    eap->flags = EXFLAG_PRINT;\n\n\t// The number of lines joined is the number of lines in the range plus\n\t// one.  One less when the last line is included.\n\tjoined_lines_count = eap->line2 - eap->line1 + 1;\n\tif (eap->line2 < curbuf->b_ml.ml_line_count)\n\t    ++joined_lines_count;\n\tif (joined_lines_count > 1)\n\t{\n\t    (void)do_join(joined_lines_count, FALSE, TRUE, FALSE, TRUE);\n\t    sub_nsubs = joined_lines_count - 1;\n\t    sub_nlines = 1;\n\t    (void)do_sub_msg(FALSE);\n\t    ex_may_print(eap);\n\t}\n\n\tif ((cmdmod.cmod_flags & CMOD_KEEPPATTERNS) == 0)\n\t    save_re_pat(RE_SUBST, pat, magic_isset());\n\t// put pattern in history\n\tadd_to_history(HIST_SEARCH, pat, TRUE, NUL);\n\n\treturn;\n    }\n\n    /*\n     * Find trailing options.  When '&' is used, keep old options.\n     */\n    if (*cmd == '&')\n\t++cmd;\n    else\n    {\n#ifdef FEAT_EVAL\n\tif (in_vim9script())\n\t{\n\t    // ignore 'gdefault' and 'edcompatible'\n\t    subflags.do_all = FALSE;\n\t    subflags.do_ask = FALSE;\n\t}\n\telse\n#endif\n\tif (!p_ed)\n\t{\n\t    if (p_gd)\t\t// default is global on\n\t\tsubflags.do_all = TRUE;\n\t    else\n\t\tsubflags.do_all = FALSE;\n\t    subflags.do_ask = FALSE;\n\t}\n\tsubflags.do_error = TRUE;\n\tsubflags.do_print = FALSE;\n\tsubflags.do_list = FALSE;\n\tsubflags.do_count = FALSE;\n\tsubflags.do_number = FALSE;\n\tsubflags.do_ic = 0;\n    }\n    while (*cmd)\n    {\n\t/*\n\t * Note that 'g' and 'c' are always inverted, also when p_ed is off.\n\t * 'r' is never inverted.\n\t */\n\tif (*cmd == 'g')\n\t    subflags.do_all = !subflags.do_all;\n\telse if (*cmd == 'c')\n\t    subflags.do_ask = !subflags.do_ask;\n\telse if (*cmd == 'n')\n\t    subflags.do_count = TRUE;\n\telse if (*cmd == 'e')\n\t    subflags.do_error = !subflags.do_error;\n\telse if (*cmd == 'r')\t    // use last used regexp\n\t    which_pat = RE_LAST;\n\telse if (*cmd == 'p')\n\t    subflags.do_print = TRUE;\n\telse if (*cmd == '#')\n\t{\n\t    subflags.do_print = TRUE;\n\t    subflags.do_number = TRUE;\n\t}\n\telse if (*cmd == 'l')\n\t{\n\t    subflags.do_print = TRUE;\n\t    subflags.do_list = TRUE;\n\t}\n\telse if (*cmd == 'i')\t    // ignore case\n\t    subflags.do_ic = 'i';\n\telse if (*cmd == 'I')\t    // don't ignore case\n\t    subflags.do_ic = 'I';\n\telse\n\t    break;\n\t++cmd;\n    }\n    if (subflags.do_count)\n\tsubflags.do_ask = FALSE;\n\n    save_do_all = subflags.do_all;\n    save_do_ask = subflags.do_ask;\n\n    /*\n     * check for a trailing count\n     */\n    cmd = skipwhite(cmd);\n    if (VIM_ISDIGIT(*cmd))\n    {\n\ti = getdigits(&cmd);\n\tif (i <= 0 && !eap->skip && subflags.do_error)\n\t{\n\t    emsg(_(e_positive_count_required));\n\t    return;\n\t}\n\teap->line1 = eap->line2;\n\teap->line2 += i - 1;\n\tif (eap->line2 > curbuf->b_ml.ml_line_count)\n\t    eap->line2 = curbuf->b_ml.ml_line_count;\n    }\n\n    /*\n     * check for trailing command or garbage\n     */\n    cmd = skipwhite(cmd);\n    if (*cmd && *cmd != '\"')\t    // if not end-of-line or comment\n    {\n\tset_nextcmd(eap, cmd);\n\tif (eap->nextcmd == NULL)\n\t{\n\t    semsg(_(e_trailing_characters_str), cmd);\n\t    return;\n\t}\n    }\n\n    if (eap->skip)\t    // not executing commands, only parsing\n\treturn;\n\n    if (!subflags.do_count && !curbuf->b_p_ma)\n    {\n\t// Substitution is not allowed in non-'modifiable' buffer\n\temsg(_(e_cannot_make_changes_modifiable_is_off));\n\treturn;\n    }\n\n    if (search_regcomp(pat, RE_SUBST, which_pat, SEARCH_HIS, &regmatch) == FAIL)\n    {\n\tif (subflags.do_error)\n\t    emsg(_(e_invalid_command));\n\treturn;\n    }\n\n    // the 'i' or 'I' flag overrules 'ignorecase' and 'smartcase'\n    if (subflags.do_ic == 'i')\n\tregmatch.rmm_ic = TRUE;\n    else if (subflags.do_ic == 'I')\n\tregmatch.rmm_ic = FALSE;\n\n    sub_firstline = NULL;\n\n    /*\n     * ~ in the substitute pattern is replaced with the old pattern.\n     * We do it here once to avoid it to be replaced over and over again.\n     * But don't do it when it starts with \"\\=\", then it's an expression.\n     */\n    if (!(sub[0] == '\\\\' && sub[1] == '='))\n\tsub = regtilde(sub, magic_isset());\n\n    /*\n     * Check for a match on each line.\n     */\n    line2 = eap->line2;\n    for (lnum = eap->line1; lnum <= line2 && !(got_quit\n#if defined(FEAT_EVAL)\n\t\t|| aborting()\n#endif\n\t\t); ++lnum)\n    {\n\tnmatch = vim_regexec_multi(&regmatch, curwin, curbuf, lnum,\n\t\t\t\t\t\t       (colnr_T)0, NULL, NULL);\n\tif (nmatch)\n\t{\n\t    colnr_T\tcopycol;\n\t    colnr_T\tmatchcol;\n\t    colnr_T\tprev_matchcol = MAXCOL;\n\t    char_u\t*new_end, *new_start = NULL;\n\t    unsigned\tnew_start_len = 0;\n\t    char_u\t*p1;\n\t    int\t\tdid_sub = FALSE;\n\t    int\t\tlastone;\n\t    int\t\tlen, copy_len, needed_len;\n\t    long\tnmatch_tl = 0;\t// nr of lines matched below lnum\n\t    int\t\tdo_again;\t// do it again after joining lines\n\t    int\t\tskip_match = FALSE;\n\t    linenr_T\tsub_firstlnum;\t// nr of first sub line\n#ifdef FEAT_PROP_POPUP\n\t    int\t\tapc_flags = APC_SAVE_FOR_UNDO | APC_SUBSTITUTE;\n\t    colnr_T\ttotal_added =  0;\n#endif\n\n\t    /*\n\t     * The new text is build up step by step, to avoid too much\n\t     * copying.  There are these pieces:\n\t     * sub_firstline\tThe old text, unmodified.\n\t     * copycol\t\tColumn in the old text where we started\n\t     *\t\t\tlooking for a match; from here old text still\n\t     *\t\t\tneeds to be copied to the new text.\n\t     * matchcol\t\tColumn number of the old text where to look\n\t     *\t\t\tfor the next match.  It's just after the\n\t     *\t\t\tprevious match or one further.\n\t     * prev_matchcol\tColumn just after the previous match (if any).\n\t     *\t\t\tMostly equal to matchcol, except for the first\n\t     *\t\t\tmatch and after skipping an empty match.\n\t     * regmatch.*pos\tWhere the pattern matched in the old text.\n\t     * new_start\tThe new text, all that has been produced so\n\t     *\t\t\tfar.\n\t     * new_end\t\tThe new text, where to append new text.\n\t     *\n\t     * lnum\t\tThe line number where we found the start of\n\t     *\t\t\tthe match.  Can be below the line we searched\n\t     *\t\t\twhen there is a \\n before a \\zs in the\n\t     *\t\t\tpattern.\n\t     * sub_firstlnum\tThe line number in the buffer where to look\n\t     *\t\t\tfor a match.  Can be different from \"lnum\"\n\t     *\t\t\twhen the pattern or substitute string contains\n\t     *\t\t\tline breaks.\n\t     *\n\t     * Special situations:\n\t     * - When the substitute string contains a line break, the part up\n\t     *   to the line break is inserted in the text, but the copy of\n\t     *   the original line is kept.  \"sub_firstlnum\" is adjusted for\n\t     *   the inserted lines.\n\t     * - When the matched pattern contains a line break, the old line\n\t     *   is taken from the line at the end of the pattern.  The lines\n\t     *   in the match are deleted later, \"sub_firstlnum\" is adjusted\n\t     *   accordingly.\n\t     *\n\t     * The new text is built up in new_start[].  It has some extra\n\t     * room to avoid using alloc()/free() too often.  new_start_len is\n\t     * the length of the allocated memory at new_start.\n\t     *\n\t     * Make a copy of the old line, so it won't be taken away when\n\t     * updating the screen or handling a multi-line match.  The \"old_\"\n\t     * pointers point into this copy.\n\t     */\n\t    sub_firstlnum = lnum;\n\t    copycol = 0;\n\t    matchcol = 0;\n\n\t    // At first match, remember current cursor position.\n\t    if (!got_match)\n\t    {\n\t\tsetpcmark();\n\t\tgot_match = TRUE;\n\t    }\n\n\t    /*\n\t     * Loop until nothing more to replace in this line.\n\t     * 1. Handle match with empty string.\n\t     * 2. If do_ask is set, ask for confirmation.\n\t     * 3. substitute the string.\n\t     * 4. if do_all is set, find next match\n\t     * 5. break if there isn't another match in this line\n\t     */\n\t    for (;;)\n\t    {\n\t\t// Advance \"lnum\" to the line where the match starts.  The\n\t\t// match does not start in the first line when there is a line\n\t\t// break before \\zs.\n\t\tif (regmatch.startpos[0].lnum > 0)\n\t\t{\n\t\t    lnum += regmatch.startpos[0].lnum;\n\t\t    sub_firstlnum += regmatch.startpos[0].lnum;\n\t\t    nmatch -= regmatch.startpos[0].lnum;\n\t\t    VIM_CLEAR(sub_firstline);\n\t\t}\n\n\t\t// Match might be after the last line for \"\\n\\zs\" matching at\n\t\t// the end of the last line.\n\t\tif (lnum > curbuf->b_ml.ml_line_count)\n\t\t    break;\n\n\t\tif (sub_firstline == NULL)\n\t\t{\n\t\t    sub_firstline = vim_strsave(ml_get(sub_firstlnum));\n\t\t    if (sub_firstline == NULL)\n\t\t    {\n\t\t\tvim_free(new_start);\n\t\t\tgoto outofmem;\n\t\t    }\n\t\t}\n\n\t\t// Save the line number of the last change for the final\n\t\t// cursor position (just like Vi).\n\t\tcurwin->w_cursor.lnum = lnum;\n\t\tdo_again = FALSE;\n\n\t\t/*\n\t\t * 1. Match empty string does not count, except for first\n\t\t * match.  This reproduces the strange vi behaviour.\n\t\t * This also catches endless loops.\n\t\t */\n\t\tif (matchcol == prev_matchcol\n\t\t\t&& regmatch.endpos[0].lnum == 0\n\t\t\t&& matchcol == regmatch.endpos[0].col)\n\t\t{\n\t\t    if (sub_firstline[matchcol] == NUL)\n\t\t\t// We already were at the end of the line.  Don't look\n\t\t\t// for a match in this line again.\n\t\t\tskip_match = TRUE;\n\t\t    else\n\t\t    {\n\t\t\t // search for a match at next column\n\t\t\tif (has_mbyte)\n\t\t\t    matchcol += mb_ptr2len(sub_firstline + matchcol);\n\t\t\telse\n\t\t\t    ++matchcol;\n\t\t    }\n\t\t    goto skip;\n\t\t}\n\n\t\t// Normally we continue searching for a match just after the\n\t\t// previous match.\n\t\tmatchcol = regmatch.endpos[0].col;\n\t\tprev_matchcol = matchcol;\n\n\t\t/*\n\t\t * 2. If do_count is set only increase the counter.\n\t\t *    If do_ask is set, ask for confirmation.\n\t\t */\n\t\tif (subflags.do_count)\n\t\t{\n\t\t    // For a multi-line match, put matchcol at the NUL at\n\t\t    // the end of the line and set nmatch to one, so that\n\t\t    // we continue looking for a match on the next line.\n\t\t    // Avoids that \":s/\\nB\\@=//gc\" get stuck.\n\t\t    if (nmatch > 1)\n\t\t    {\n\t\t\tmatchcol = (colnr_T)STRLEN(sub_firstline);\n\t\t\tnmatch = 1;\n\t\t\tskip_match = TRUE;\n\t\t    }\n\t\t    sub_nsubs++;\n\t\t    did_sub = TRUE;\n#ifdef FEAT_EVAL\n\t\t    // Skip the substitution, unless an expression is used,\n\t\t    // then it is evaluated in the sandbox.\n\t\t    if (!(sub[0] == '\\\\' && sub[1] == '='))\n#endif\n\t\t\tgoto skip;\n\t\t}\n\n\t\tif (subflags.do_ask)\n\t\t{\n\t\t    int typed = 0;\n\n\t\t    // change State to CONFIRM, so that the mouse works\n\t\t    // properly\n\t\t    save_State = State;\n\t\t    State = CONFIRM;\n\t\t    setmouse();\t\t// disable mouse in xterm\n\t\t    curwin->w_cursor.col = regmatch.startpos[0].col;\n\t\t    if (curwin->w_p_crb)\n\t\t\tdo_check_cursorbind();\n\n\t\t    // When 'cpoptions' contains \"u\" don't sync undo when\n\t\t    // asking for confirmation.\n\t\t    if (vim_strchr(p_cpo, CPO_UNDO) != NULL)\n\t\t\t++no_u_sync;\n\n\t\t    /*\n\t\t     * Loop until 'y', 'n', 'q', CTRL-E or CTRL-Y typed.\n\t\t     */\n\t\t    while (subflags.do_ask)\n\t\t    {\n\t\t\tif (exmode_active)\n\t\t\t{\n\t\t\t    char_u\t*resp;\n\t\t\t    colnr_T\tsc, ec;\n\n\t\t\t    print_line_no_prefix(lnum,\n\t\t\t\t\t subflags.do_number, subflags.do_list);\n\n\t\t\t    getvcol(curwin, &curwin->w_cursor, &sc, NULL, NULL);\n\t\t\t    curwin->w_cursor.col = regmatch.endpos[0].col - 1;\n\t\t\t    if (curwin->w_cursor.col < 0)\n\t\t\t\tcurwin->w_cursor.col = 0;\n\t\t\t    getvcol(curwin, &curwin->w_cursor, NULL, NULL, &ec);\n\t\t\t    curwin->w_cursor.col = regmatch.startpos[0].col;\n\t\t\t    if (subflags.do_number || curwin->w_p_nu)\n\t\t\t    {\n\t\t\t\tint numw = number_width(curwin) + 1;\n\t\t\t\tsc += numw;\n\t\t\t\tec += numw;\n\t\t\t    }\n\t\t\t    msg_start();\n\t\t\t    for (i = 0; i < (long)sc; ++i)\n\t\t\t\tmsg_putchar(' ');\n\t\t\t    for ( ; i <= (long)ec; ++i)\n\t\t\t\tmsg_putchar('^');\n\n\t\t\t    resp = getexmodeline('?', NULL, 0, TRUE);\n\t\t\t    if (resp != NULL)\n\t\t\t    {\n\t\t\t\ttyped = *resp;\n\t\t\t\tvim_free(resp);\n\t\t\t    }\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t    char_u *orig_line = NULL;\n\t\t\t    int    len_change = 0;\n\t\t\t    int\t   save_p_lz = p_lz;\n#ifdef FEAT_FOLDING\n\t\t\t    int save_p_fen = curwin->w_p_fen;\n\n\t\t\t    curwin->w_p_fen = FALSE;\n#endif\n\t\t\t    // Invert the matched string.\n\t\t\t    // Remove the inversion afterwards.\n\t\t\t    temp = RedrawingDisabled;\n\t\t\t    RedrawingDisabled = 0;\n\n\t\t\t    // avoid calling update_screen() in vgetorpeek()\n\t\t\t    p_lz = FALSE;\n\n\t\t\t    if (new_start != NULL)\n\t\t\t    {\n\t\t\t\t// There already was a substitution, we would\n\t\t\t\t// like to show this to the user.  We cannot\n\t\t\t\t// really update the line, it would change\n\t\t\t\t// what matches.  Temporarily replace the line\n\t\t\t\t// and change it back afterwards.\n\t\t\t\torig_line = vim_strsave(ml_get(lnum));\n\t\t\t\tif (orig_line != NULL)\n\t\t\t\t{\n\t\t\t\t    char_u *new_line = concat_str(new_start,\n\t\t\t\t\t\t     sub_firstline + copycol);\n\n\t\t\t\t    if (new_line == NULL)\n\t\t\t\t\tVIM_CLEAR(orig_line);\n\t\t\t\t    else\n\t\t\t\t    {\n\t\t\t\t\t// Position the cursor relative to the\n\t\t\t\t\t// end of the line, the previous\n\t\t\t\t\t// substitute may have inserted or\n\t\t\t\t\t// deleted characters before the\n\t\t\t\t\t// cursor.\n\t\t\t\t\tlen_change = (int)STRLEN(new_line)\n\t\t\t\t\t\t     - (int)STRLEN(orig_line);\n\t\t\t\t\tcurwin->w_cursor.col += len_change;\n\t\t\t\t\tml_replace(lnum, new_line, FALSE);\n\t\t\t\t    }\n\t\t\t\t}\n\t\t\t    }\n\n\t\t\t    search_match_lines = regmatch.endpos[0].lnum\n\t\t\t\t\t\t  - regmatch.startpos[0].lnum;\n\t\t\t    search_match_endcol = regmatch.endpos[0].col\n\t\t\t\t\t\t\t\t + len_change;\n\t\t\t    highlight_match = TRUE;\n\n\t\t\t    update_topline();\n\t\t\t    validate_cursor();\n\t\t\t    update_screen(SOME_VALID);\n\t\t\t    highlight_match = FALSE;\n\t\t\t    redraw_later(SOME_VALID);\n\n#ifdef FEAT_FOLDING\n\t\t\t    curwin->w_p_fen = save_p_fen;\n#endif\n\t\t\t    if (msg_row == Rows - 1)\n\t\t\t\tmsg_didout = FALSE;\t// avoid a scroll-up\n\t\t\t    msg_starthere();\n\t\t\t    i = msg_scroll;\n\t\t\t    msg_scroll = 0;\t\t// truncate msg when\n\t\t\t\t\t\t\t// needed\n\t\t\t    msg_no_more = TRUE;\n\t\t\t    // write message same highlighting as for\n\t\t\t    // wait_return\n\t\t\t    smsg_attr(HL_ATTR(HLF_R),\n\t\t\t\t_(\"replace with %s (y/n/a/q/l/^E/^Y)?\"), sub);\n\t\t\t    msg_no_more = FALSE;\n\t\t\t    msg_scroll = i;\n\t\t\t    showruler(TRUE);\n\t\t\t    windgoto(msg_row, msg_col);\n\t\t\t    RedrawingDisabled = temp;\n\n#ifdef USE_ON_FLY_SCROLL\n\t\t\t    dont_scroll = FALSE; // allow scrolling here\n#endif\n\t\t\t    ++no_mapping;\t// don't map this key\n\t\t\t    ++allow_keys;\t// allow special keys\n\t\t\t    typed = plain_vgetc();\n\t\t\t    --allow_keys;\n\t\t\t    --no_mapping;\n\n\t\t\t    // clear the question\n\t\t\t    msg_didout = FALSE;\t// don't scroll up\n\t\t\t    msg_col = 0;\n\t\t\t    gotocmdline(TRUE);\n\t\t\t    p_lz = save_p_lz;\n\n\t\t\t    // restore the line\n\t\t\t    if (orig_line != NULL)\n\t\t\t\tml_replace(lnum, orig_line, FALSE);\n\t\t\t}\n\n\t\t\tneed_wait_return = FALSE; // no hit-return prompt\n\t\t\tif (typed == 'q' || typed == ESC || typed == Ctrl_C\n#ifdef UNIX\n\t\t\t\t|| typed == intr_char\n#endif\n\t\t\t\t)\n\t\t\t{\n\t\t\t    got_quit = TRUE;\n\t\t\t    break;\n\t\t\t}\n\t\t\tif (typed == 'n')\n\t\t\t    break;\n\t\t\tif (typed == 'y')\n\t\t\t    break;\n\t\t\tif (typed == 'l')\n\t\t\t{\n\t\t\t    // last: replace and then stop\n\t\t\t    subflags.do_all = FALSE;\n\t\t\t    line2 = lnum;\n\t\t\t    break;\n\t\t\t}\n\t\t\tif (typed == 'a')\n\t\t\t{\n\t\t\t    subflags.do_ask = FALSE;\n\t\t\t    break;\n\t\t\t}\n\t\t\tif (typed == Ctrl_E)\n\t\t\t    scrollup_clamp();\n\t\t\telse if (typed == Ctrl_Y)\n\t\t\t    scrolldown_clamp();\n\t\t    }\n\t\t    State = save_State;\n\t\t    setmouse();\n\t\t    if (vim_strchr(p_cpo, CPO_UNDO) != NULL)\n\t\t\t--no_u_sync;\n\n\t\t    if (typed == 'n')\n\t\t    {\n\t\t\t// For a multi-line match, put matchcol at the NUL at\n\t\t\t// the end of the line and set nmatch to one, so that\n\t\t\t// we continue looking for a match on the next line.\n\t\t\t// Avoids that \":%s/\\nB\\@=//gc\" and \":%s/\\n/,\\r/gc\"\n\t\t\t// get stuck when pressing 'n'.\n\t\t\tif (nmatch > 1)\n\t\t\t{\n\t\t\t    matchcol = (colnr_T)STRLEN(sub_firstline);\n\t\t\t    skip_match = TRUE;\n\t\t\t}\n\t\t\tgoto skip;\n\t\t    }\n\t\t    if (got_quit)\n\t\t\tgoto skip;\n\t\t}\n\n\t\t// Move the cursor to the start of the match, so that we can\n\t\t// use \"\\=col(\".\").\n\t\tcurwin->w_cursor.col = regmatch.startpos[0].col;\n\n\t\t/*\n\t\t * 3. substitute the string.\n\t\t */\n#ifdef FEAT_EVAL\n\t\tsave_ma = curbuf->b_p_ma;\n\t\tif (subflags.do_count)\n\t\t{\n\t\t    // prevent accidentally changing the buffer by a function\n\t\t    curbuf->b_p_ma = FALSE;\n\t\t    sandbox++;\n\t\t}\n\t\t// Save flags for recursion.  They can change for e.g.\n\t\t// :s/^/\\=execute(\"s#^##gn\")\n\t\tsubflags_save = subflags;\n#endif\n\t\t// get length of substitution part\n\t\tsublen = vim_regsub_multi(&regmatch,\n\t\t\t\t    sub_firstlnum - regmatch.startpos[0].lnum,\n\t\t\t       sub, sub_firstline, FALSE, magic_isset(), TRUE);\n#ifdef FEAT_EVAL\n\t\t// If getting the substitute string caused an error, don't do\n\t\t// the replacement.\n\t\t// Don't keep flags set by a recursive call.\n\t\tsubflags = subflags_save;\n\t\tif (aborting() || subflags.do_count)\n\t\t{\n\t\t    curbuf->b_p_ma = save_ma;\n\t\t    if (sandbox > 0)\n\t\t\tsandbox--;\n\t\t    goto skip;\n\t\t}\n#endif\n\n\t\t// When the match included the \"$\" of the last line it may\n\t\t// go beyond the last line of the buffer.\n\t\tif (nmatch > curbuf->b_ml.ml_line_count - sub_firstlnum + 1)\n\t\t{\n\t\t    nmatch = curbuf->b_ml.ml_line_count - sub_firstlnum + 1;\n\t\t    skip_match = TRUE;\n\t\t}\n\n\t\t// Need room for:\n\t\t// - result so far in new_start (not for first sub in line)\n\t\t// - original text up to match\n\t\t// - length of substituted part\n\t\t// - original text after match\n\t\t// Adjust text properties here, since we have all information\n\t\t// needed.\n\t\tif (nmatch == 1)\n\t\t{\n\t\t    p1 = sub_firstline;\n#ifdef FEAT_PROP_POPUP\n\t\t    if (curbuf->b_has_textprop)\n\t\t    {\n\t\t\tint bytes_added = sublen - 1 - (regmatch.endpos[0].col\n\t\t\t\t\t\t   - regmatch.startpos[0].col);\n\n\t\t\t// When text properties are changed, need to save for\n\t\t\t// undo first, unless done already.\n\t\t\tif (adjust_prop_columns(lnum,\n\t\t\t\t\ttotal_added + regmatch.startpos[0].col,\n\t\t\t\t\t\t       bytes_added, apc_flags))\n\t\t\t    apc_flags &= ~APC_SAVE_FOR_UNDO;\n\t\t\t// Offset for column byte number of the text property\n\t\t\t// in the resulting buffer afterwards.\n\t\t\ttotal_added += bytes_added;\n\t\t    }\n#endif\n\t\t}\n\t\telse\n\t\t{\n\t\t    p1 = ml_get(sub_firstlnum + nmatch - 1);\n\t\t    nmatch_tl += nmatch - 1;\n\t\t}\n\t\tcopy_len = regmatch.startpos[0].col - copycol;\n\t\tneeded_len = copy_len + ((unsigned)STRLEN(p1)\n\t\t\t\t       - regmatch.endpos[0].col) + sublen + 1;\n\t\tif (new_start == NULL)\n\t\t{\n\t\t    /*\n\t\t     * Get some space for a temporary buffer to do the\n\t\t     * substitution into (and some extra space to avoid\n\t\t     * too many calls to alloc()/free()).\n\t\t     */\n\t\t    new_start_len = needed_len + 50;\n\t\t    if ((new_start = alloc(new_start_len)) == NULL)\n\t\t\tgoto outofmem;\n\t\t    *new_start = NUL;\n\t\t    new_end = new_start;\n\t\t}\n\t\telse\n\t\t{\n\t\t    /*\n\t\t     * Check if the temporary buffer is long enough to do the\n\t\t     * substitution into.  If not, make it larger (with a bit\n\t\t     * extra to avoid too many calls to alloc()/free()).\n\t\t     */\n\t\t    len = (unsigned)STRLEN(new_start);\n\t\t    needed_len += len;\n\t\t    if (needed_len > (int)new_start_len)\n\t\t    {\n\t\t\tnew_start_len = needed_len + 50;\n\t\t\tif ((p1 = alloc(new_start_len)) == NULL)\n\t\t\t{\n\t\t\t    vim_free(new_start);\n\t\t\t    goto outofmem;\n\t\t\t}\n\t\t\tmch_memmove(p1, new_start, (size_t)(len + 1));\n\t\t\tvim_free(new_start);\n\t\t\tnew_start = p1;\n\t\t    }\n\t\t    new_end = new_start + len;\n\t\t}\n\n\t\t/*\n\t\t * copy the text up to the part that matched\n\t\t */\n\t\tmch_memmove(new_end, sub_firstline + copycol, (size_t)copy_len);\n\t\tnew_end += copy_len;\n\n\t\t(void)vim_regsub_multi(&regmatch,\n\t\t\t\t    sub_firstlnum - regmatch.startpos[0].lnum,\n\t\t\t\t      sub, new_end, TRUE, magic_isset(), TRUE);\n\t\tsub_nsubs++;\n\t\tdid_sub = TRUE;\n\n\t\t// Move the cursor to the start of the line, to avoid that it\n\t\t// is beyond the end of the line after the substitution.\n\t\tcurwin->w_cursor.col = 0;\n\n\t\t// For a multi-line match, make a copy of the last matched\n\t\t// line and continue in that one.\n\t\tif (nmatch > 1)\n\t\t{\n\t\t    sub_firstlnum += nmatch - 1;\n\t\t    vim_free(sub_firstline);\n\t\t    sub_firstline = vim_strsave(ml_get(sub_firstlnum));\n\t\t    // When going beyond the last line, stop substituting.\n\t\t    if (sub_firstlnum <= line2)\n\t\t\tdo_again = TRUE;\n\t\t    else\n\t\t\tsubflags.do_all = FALSE;\n\t\t}\n\n\t\t// Remember next character to be copied.\n\t\tcopycol = regmatch.endpos[0].col;\n\n\t\tif (skip_match)\n\t\t{\n\t\t    // Already hit end of the buffer, sub_firstlnum is one\n\t\t    // less than what it ought to be.\n\t\t    vim_free(sub_firstline);\n\t\t    sub_firstline = vim_strsave((char_u *)\"\");\n\t\t    copycol = 0;\n\t\t}\n\n\t\t/*\n\t\t * Now the trick is to replace CTRL-M chars with a real line\n\t\t * break.  This would make it impossible to insert a CTRL-M in\n\t\t * the text.  The line break can be avoided by preceding the\n\t\t * CTRL-M with a backslash.  To be able to insert a backslash,\n\t\t * they must be doubled in the string and are halved here.\n\t\t * That is Vi compatible.\n\t\t */\n\t\tfor (p1 = new_end; *p1; ++p1)\n\t\t{\n\t\t    if (p1[0] == '\\\\' && p1[1] != NUL)  // remove backslash\n\t\t    {\n\t\t\tSTRMOVE(p1, p1 + 1);\n#ifdef FEAT_PROP_POPUP\n\t\t\tif (curbuf->b_has_textprop)\n\t\t\t{\n\t\t\t    // When text properties are changed, need to save\n\t\t\t    // for undo first, unless done already.\n\t\t\t    if (adjust_prop_columns(lnum,\n\t\t\t\t\t(colnr_T)(p1 - new_start), -1,\n\t\t\t\t\tapc_flags))\n\t\t\t\tapc_flags &= ~APC_SAVE_FOR_UNDO;\n\t\t\t}\n#endif\n\t\t    }\n\t\t    else if (*p1 == CAR)\n\t\t    {\n\t\t\tif (u_inssub(lnum) == OK)   // prepare for undo\n\t\t\t{\n\t\t\t    colnr_T\tplen = (colnr_T)(p1 - new_start + 1);\n\n\t\t\t    *p1 = NUL;\t\t    // truncate up to the CR\n\t\t\t    ml_append(lnum - 1, new_start, plen, FALSE);\n\t\t\t    mark_adjust(lnum + 1, (linenr_T)MAXLNUM, 1L, 0L);\n\t\t\t    if (subflags.do_ask)\n\t\t\t\tappended_lines(lnum - 1, 1L);\n\t\t\t    else\n\t\t\t    {\n\t\t\t\tif (first_line == 0)\n\t\t\t\t    first_line = lnum;\n\t\t\t\tlast_line = lnum + 1;\n\t\t\t    }\n#ifdef FEAT_PROP_POPUP\n\t\t\t    adjust_props_for_split(lnum + 1, lnum, plen, 1);\n#endif\n\t\t\t    // all line numbers increase\n\t\t\t    ++sub_firstlnum;\n\t\t\t    ++lnum;\n\t\t\t    ++line2;\n\t\t\t    // move the cursor to the new line, like Vi\n\t\t\t    ++curwin->w_cursor.lnum;\n\t\t\t    // copy the rest\n\t\t\t    STRMOVE(new_start, p1 + 1);\n\t\t\t    p1 = new_start - 1;\n\t\t\t}\n\t\t    }\n\t\t    else if (has_mbyte)\n\t\t\tp1 += (*mb_ptr2len)(p1) - 1;\n\t\t}\n\n\t\t/*\n\t\t * 4. If do_all is set, find next match.\n\t\t * Prevent endless loop with patterns that match empty\n\t\t * strings, e.g. :s/$/pat/g or :s/[a-z]* /(&)/g.\n\t\t * But \":s/\\n/#/\" is OK.\n\t\t */\nskip:\n\t\t// We already know that we did the last subst when we are at\n\t\t// the end of the line, except that a pattern like\n\t\t// \"bar\\|\\nfoo\" may match at the NUL.  \"lnum\" can be below\n\t\t// \"line2\" when there is a \\zs in the pattern after a line\n\t\t// break.\n\t\tlastone = (skip_match\n\t\t\t|| got_int\n\t\t\t|| got_quit\n\t\t\t|| lnum > line2\n\t\t\t|| !(subflags.do_all || do_again)\n\t\t\t|| (sub_firstline[matchcol] == NUL && nmatch <= 1\n\t\t\t\t\t && !re_multiline(regmatch.regprog)));\n\t\tnmatch = -1;\n\n\t\t/*\n\t\t * Replace the line in the buffer when needed.  This is\n\t\t * skipped when there are more matches.\n\t\t * The check for nmatch_tl is needed for when multi-line\n\t\t * matching must replace the lines before trying to do another\n\t\t * match, otherwise \"\\@<=\" won't work.\n\t\t * When the match starts below where we start searching also\n\t\t * need to replace the line first (using \\zs after \\n).\n\t\t */\n\t\tif (lastone\n\t\t\t|| nmatch_tl > 0\n\t\t\t|| (nmatch = vim_regexec_multi(&regmatch, curwin,\n\t\t\t\t\t\t\tcurbuf, sub_firstlnum,\n\t\t\t\t\t\t    matchcol, NULL, NULL)) == 0\n\t\t\t|| regmatch.startpos[0].lnum > 0)\n\t\t{\n\t\t    if (new_start != NULL)\n\t\t    {\n\t\t\t/*\n\t\t\t * Copy the rest of the line, that didn't match.\n\t\t\t * \"matchcol\" has to be adjusted, we use the end of\n\t\t\t * the line as reference, because the substitute may\n\t\t\t * have changed the number of characters.  Same for\n\t\t\t * \"prev_matchcol\".\n\t\t\t */\n\t\t\tSTRCAT(new_start, sub_firstline + copycol);\n\t\t\tmatchcol = (colnr_T)STRLEN(sub_firstline) - matchcol;\n\t\t\tprev_matchcol = (colnr_T)STRLEN(sub_firstline)\n\t\t\t\t\t\t\t      - prev_matchcol;\n\n\t\t\tif (u_savesub(lnum) != OK)\n\t\t\t    break;\n\t\t\tml_replace(lnum, new_start, TRUE);\n\n\t\t\tif (nmatch_tl > 0)\n\t\t\t{\n\t\t\t    /*\n\t\t\t     * Matched lines have now been substituted and are\n\t\t\t     * useless, delete them.  The part after the match\n\t\t\t     * has been appended to new_start, we don't need\n\t\t\t     * it in the buffer.\n\t\t\t     */\n\t\t\t    ++lnum;\n\t\t\t    if (u_savedel(lnum, nmatch_tl) != OK)\n\t\t\t\tbreak;\n\t\t\t    for (i = 0; i < nmatch_tl; ++i)\n\t\t\t\tml_delete(lnum);\n\t\t\t    mark_adjust(lnum, lnum + nmatch_tl - 1,\n\t\t\t\t\t\t   (long)MAXLNUM, -nmatch_tl);\n\t\t\t    if (subflags.do_ask)\n\t\t\t\tdeleted_lines(lnum, nmatch_tl);\n\t\t\t    --lnum;\n\t\t\t    line2 -= nmatch_tl; // nr of lines decreases\n\t\t\t    nmatch_tl = 0;\n\t\t\t}\n\n\t\t\t// When asking, undo is saved each time, must also set\n\t\t\t// changed flag each time.\n\t\t\tif (subflags.do_ask)\n\t\t\t    changed_bytes(lnum, 0);\n\t\t\telse\n\t\t\t{\n\t\t\t    if (first_line == 0)\n\t\t\t\tfirst_line = lnum;\n\t\t\t    last_line = lnum + 1;\n\t\t\t}\n\n\t\t\tsub_firstlnum = lnum;\n\t\t\tvim_free(sub_firstline);    // free the temp buffer\n\t\t\tsub_firstline = new_start;\n\t\t\tnew_start = NULL;\n\t\t\tmatchcol = (colnr_T)STRLEN(sub_firstline) - matchcol;\n\t\t\tprev_matchcol = (colnr_T)STRLEN(sub_firstline)\n\t\t\t\t\t\t\t      - prev_matchcol;\n\t\t\tcopycol = 0;\n\t\t    }\n\t\t    if (nmatch == -1 && !lastone)\n\t\t\tnmatch = vim_regexec_multi(&regmatch, curwin, curbuf,\n\t\t\t\t\t  sub_firstlnum, matchcol, NULL, NULL);\n\n\t\t    /*\n\t\t     * 5. break if there isn't another match in this line\n\t\t     */\n\t\t    if (nmatch <= 0)\n\t\t    {\n\t\t\t// If the match found didn't start where we were\n\t\t\t// searching, do the next search in the line where we\n\t\t\t// found the match.\n\t\t\tif (nmatch == -1)\n\t\t\t    lnum -= regmatch.startpos[0].lnum;\n\t\t\tbreak;\n\t\t    }\n\t\t}\n\n\t\tline_breakcheck();\n\t    }\n\n\t    if (did_sub)\n\t\t++sub_nlines;\n\t    vim_free(new_start);\t// for when substitute was cancelled\n\t    VIM_CLEAR(sub_firstline);\t// free the copy of the original line\n\t}\n\n\tline_breakcheck();\n    }\n\n    if (first_line != 0)\n    {\n\t// Need to subtract the number of added lines from \"last_line\" to get\n\t// the line number before the change (same as adding the number of\n\t// deleted lines).\n\ti = curbuf->b_ml.ml_line_count - old_line_count;\n\tchanged_lines(first_line, 0, last_line - i, i);\n    }\n\noutofmem:\n    vim_free(sub_firstline); // may have to free allocated copy of the line\n\n    // \":s/pat//n\" doesn't move the cursor\n    if (subflags.do_count)\n\tcurwin->w_cursor = old_cursor;\n\n    if (sub_nsubs > start_nsubs)\n    {\n\tif ((cmdmod.cmod_flags & CMOD_LOCKMARKS) == 0)\n\t{\n\t    // Set the '[ and '] marks.\n\t    curbuf->b_op_start.lnum = eap->line1;\n\t    curbuf->b_op_end.lnum = line2;\n\t    curbuf->b_op_start.col = curbuf->b_op_end.col = 0;\n\t}\n\n\tif (!global_busy)\n\t{\n\t    // when interactive leave cursor on the match\n\t    if (!subflags.do_ask)\n\t    {\n\t\tif (endcolumn)\n\t\t    coladvance((colnr_T)MAXCOL);\n\t\telse\n\t\t    beginline(BL_WHITE | BL_FIX);\n\t    }\n\t    if (!do_sub_msg(subflags.do_count) && subflags.do_ask)\n\t\tmsg(\"\");\n\t}\n\telse\n\t    global_need_beginline = TRUE;\n\tif (subflags.do_print)\n\t    print_line(curwin->w_cursor.lnum,\n\t\t\t\t\t subflags.do_number, subflags.do_list);\n    }\n    else if (!global_busy)\n    {\n\tif (got_int)\t\t// interrupted\n\t    emsg(_(e_interrupted));\n\telse if (got_match)\t// did find something but nothing substituted\n\t    msg(\"\");\n\telse if (subflags.do_error)\t// nothing found\n\t    semsg(_(e_pattern_not_found_str), get_search_pat());\n    }\n\n#ifdef FEAT_FOLDING\n    if (subflags.do_ask && hasAnyFolding(curwin))\n\t// Cursor position may require updating\n\tchanged_window_setting();\n#endif\n\n    vim_regfree(regmatch.regprog);\n\n    // Restore the flag values, they can be used for \":&&\".\n    subflags.do_all = save_do_all;\n    subflags.do_ask = save_do_ask;\n}",
        "func_hash": 259196751787508005925510441148614080583,
        "file_name": "ex_cmds.c",
        "file_hash": 59965875084146466287270368497703800580,
        "cwe": [
            "CWE-416"
        ],
        "cve": "CVE-2022-0413",
        "cve_desc": "Use After Free in GitHub repository vim/vim prior to 8.2.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-0413",
        "func_name": "ex_substitute",
        "diff": [
            "diff --git a/src/ex_cmds.c b/src/ex_cmds.c\nindex 099d9cfeedd784..9d99571f72ab87 100644\n--- a/src/ex_cmds.c\n+++ b/src/ex_cmds.c\n@@ -3687,6 +3687,7 @@ ex_substitute(exarg_T *eap)\n     int\t\tsave_do_all;\t\t// remember user specified 'g' flag\n     int\t\tsave_do_ask;\t\t// remember user specified 'c' flag\n     char_u\t*pat = NULL, *sub = NULL;\t// init for GCC\n+    char_u\t*sub_copy = NULL;\n     int\t\tdelimiter;\n     int\t\tsublen;\n     int\t\tgot_quit = FALSE;\n@@ -3980,11 +3981,20 @@ ex_substitute(exarg_T *eap)\n     sub_firstline = NULL;\n \n     /*\n-     * ~ in the substitute pattern is replaced with the old pattern.\n-     * We do it here once to avoid it to be replaced over and over again.\n-     * But don't do it when it starts with \"\\=\", then it's an expression.\n+     * If the substitute pattern starts with \"\\=\" then it's an expression.\n+     * Make a copy, a recursive function may free it.\n+     * Otherwise, '~' in the substitute pattern is replaced with the old\n+     * pattern.  We do it here once to avoid it to be replaced over and over\n+     * again.\n      */\n-    if (!(sub[0] == '\\\\' && sub[1] == '='))\n+    if (sub[0] == '\\\\' && sub[1] == '=')\n+    {\n+\tsub = vim_strsave(sub);\n+\tif (sub == NULL)\n+\t    return;\n+\tsub_copy = sub;\n+    }\n+    else\n \tsub = regtilde(sub, magic_isset());\n \n     /*\n@@ -4790,6 +4800,7 @@ ex_substitute(exarg_T *eap)\n #endif\n \n     vim_regfree(regmatch.regprog);\n+    vim_free(sub_copy);\n \n     // Restore the flag values, they can be used for \":&&\".\n     subflags.do_all = save_do_all;\ndiff --git a/src/testdir/test_substitute.vim b/src/testdir/test_substitute.vim\nindex 0806fd2de6267e..35b6b8a0245d39 100644\n--- a/src/testdir/test_substitute.vim\n+++ b/src/testdir/test_substitute.vim\n@@ -980,4 +980,21 @@ func Test_substitute_gdefault()\n   bw!\n endfunc\n \n+\" This was using \"old_sub\" after it was freed.\n+func Test_using_old_sub()\n+  set compatible maxfuncdepth=10\n+  new\n+  call setline(1, 'some text.')\n+  func Repl()\n+    ~\n+    s/\n+  endfunc\n+  silent!  s/\\%')/\\=Repl()\n+\n+  delfunc Repl\n+  bwipe!\n+  set nocompatible\n+endfunc\n+\n+\n \" vim: shiftwidth=2 sts=2 expandtab\ndiff --git a/src/version.c b/src/version.c\nindex e5499ade6628a2..25dcfe316bef2c 100644\n--- a/src/version.c\n+++ b/src/version.c\n@@ -750,6 +750,8 @@ static char *(features[]) =\n \n static int included_patches[] =\n {   /* Add new patch number below this line */\n+/**/\n+    4253,\n /**/\n     4252,\n /**/\n"
        ],
        "func_after": []
    },
    {
        "idx": 200113,
        "project": "ImageMagick",
        "commit_id": "389ecc365a7c61404ba078a72c3fa5a3cf1b4101",
        "project_url": "https://github.com/ImageMagick/ImageMagick",
        "commit_url": "https://github.com/ImageMagick/ImageMagick/commit/389ecc365a7c61404ba078a72c3fa5a3cf1b4101",
        "commit_message": "https://github.com/ImageMagick/ImageMagick/issues/1221",
        "target": 1,
        "irrelevant": 1,
        "func_before": "static Image *ReadMATImageV4(const ImageInfo *image_info,Image *image,\n  ExceptionInfo *exception)\n{\n  typedef struct {\n    unsigned char Type[4];\n    unsigned int nRows;\n    unsigned int nCols;\n    unsigned int imagf;\n    unsigned int nameLen;\n  } MAT4_HDR;\n\n  long\n    ldblk;\n\n  EndianType\n    endian;\n\n  Image\n    *rotated_image;\n\n  MagickBooleanType\n    status;\n\n  MAT4_HDR\n    HDR;\n\n  QuantumInfo\n    *quantum_info;\n\n  QuantumFormatType\n    format_type;\n\n  register ssize_t\n    i;\n\n  ssize_t\n    count,\n    y;\n\n  unsigned char\n    *pixels;\n\n  unsigned int\n    depth;\n\n\n  quantum_info=(QuantumInfo *) NULL;\n  (void) SeekBlob(image,0,SEEK_SET);\n  while (EOFBlob(image) == MagickFalse)\n  {\n    /*\n     Object parser loop.\n    */\n    ldblk=ReadBlobLSBLong(image);\n    if ((ldblk > 9999) || (ldblk < 0))\n      break;\n    HDR.Type[3]=ldblk % 10; ldblk /= 10;  /* T digit */\n    HDR.Type[2]=ldblk % 10; ldblk /= 10;  /* P digit */\n    HDR.Type[1]=ldblk % 10; ldblk /= 10;  /* O digit */\n    HDR.Type[0]=ldblk;        /* M digit */\n    if (HDR.Type[3] != 0)\n      break;  /* Data format */\n    if (HDR.Type[2] != 0)\n      break;  /* Always 0 */\n    if (HDR.Type[0] == 0)\n      {\n        HDR.nRows=ReadBlobLSBLong(image);\n        HDR.nCols=ReadBlobLSBLong(image);\n        HDR.imagf=ReadBlobLSBLong(image);\n        HDR.nameLen=ReadBlobLSBLong(image);\n        endian=LSBEndian;\n      }\n    else\n      {\n        HDR.nRows=ReadBlobMSBLong(image);\n        HDR.nCols=ReadBlobMSBLong(image);\n        HDR.imagf=ReadBlobMSBLong(image);\n        HDR.nameLen=ReadBlobMSBLong(image);\n        endian=MSBEndian;\n      }\n    if ((HDR.imagf != 0) && (HDR.imagf != 1))\n      break;\n    if (HDR.nameLen > 0xFFFF)\n      return(DestroyImageList(image));\n    for (i=0; i < (ssize_t) HDR.nameLen; i++)\n    {\n      int\n        byte;\n\n      /*\n        Skip matrix name.\n      */\n      byte=ReadBlobByte(image);\n      if (byte == EOF)\n        {\n          ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n            image->filename);\n          break;\n        }\n    }\n    image->columns=(size_t) HDR.nRows;\n    image->rows=(size_t) HDR.nCols;\n    if ((image->columns == 0) || (image->rows == 0))\n      return(DestroyImageList(image));\n    if (image_info->ping != MagickFalse)\n      {\n        Swap(image->columns,image->rows);\n        if(HDR.imagf==1) ldblk *= 2;\n        SeekBlob(image, HDR.nCols*ldblk, SEEK_CUR);\n        if ((image->columns == 0) || (image->rows == 0))\n          return(image->previous == (Image *) NULL ? DestroyImageList(image)\n            : image);\n        goto skip_reading_current;\n      }\n    status=SetImageExtent(image,image->columns,image->rows,exception);\n    if (status == MagickFalse)\n      return(DestroyImageList(image));\n    (void) SetImageBackgroundColor(image,exception);\n    (void) SetImageColorspace(image,GRAYColorspace,exception);\n    quantum_info=AcquireQuantumInfo(image_info,image);\n    if (quantum_info == (QuantumInfo *) NULL)\n      return(DestroyImageList(image));\n    switch(HDR.Type[1])\n    {\n      case 0:\n        format_type=FloatingPointQuantumFormat;\n        depth=64;\n        break;\n      case 1:\n        format_type=FloatingPointQuantumFormat;\n        depth=32;\n        break;\n      case 2:\n        format_type=UnsignedQuantumFormat;\n        depth=16;\n        break;\n      case 3:\n        format_type=SignedQuantumFormat;\n        depth=16;\n        break;\n      case 4:\n        format_type=UnsignedQuantumFormat;\n        depth=8;\n        break;\n      default:\n        format_type=UnsignedQuantumFormat;\n        depth=8;\n        break;\n    }\n    image->depth=depth;\n    if (HDR.Type[0] != 0)\n      SetQuantumEndian(image,quantum_info,MSBEndian);\n    status=SetQuantumFormat(image,quantum_info,format_type);\n    status=SetQuantumDepth(image,quantum_info,depth);\n    status=SetQuantumEndian(image,quantum_info,endian);\n    SetQuantumScale(quantum_info,1.0);\n    pixels=(unsigned char *) GetQuantumPixels(quantum_info);\n    for (y=0; y < (ssize_t) image->rows; y++)\n    {\n      register Quantum\n        *magick_restrict q;\n\n      count=ReadBlob(image,depth/8*image->columns,(char *) pixels);\n      if (count == -1)\n        break;\n      q=QueueAuthenticPixels(image,0,image->rows-y-1,image->columns,1,\n        exception);\n      if (q == (Quantum *) NULL)\n        break;\n      (void) ImportQuantumPixels(image,(CacheView *) NULL,quantum_info,\n        GrayQuantum,pixels,exception);\n      if ((HDR.Type[1] == 2) || (HDR.Type[1] == 3))\n        FixSignedValues(image,q,(int) image->columns);\n      if (SyncAuthenticPixels(image,exception) == MagickFalse)\n        break;\n      if (image->previous == (Image *) NULL)\n        {\n          status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n            image->rows);\n          if (status == MagickFalse)\n            break;\n        }\n    }\n    if (HDR.imagf == 1)\n      for (y=0; y < (ssize_t) image->rows; y++)\n      {\n        /*\n          Read complex pixels.\n        */\n        count=ReadBlob(image,depth/8*image->columns,(char *) pixels);\n        if (count == -1)\n          break;\n        if (HDR.Type[1] == 0)\n          InsertComplexDoubleRow(image,(double *) pixels,y,0,0,exception);\n        else\n          InsertComplexFloatRow(image,(float *) pixels,y,0,0,exception);\n      }\n    if (quantum_info != (QuantumInfo *) NULL)\n      quantum_info=DestroyQuantumInfo(quantum_info);\n    if (EOFBlob(image) != MagickFalse)\n      {\n        ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n          image->filename);\n        break;\n      }\n    rotated_image=RotateImage(image,90.0,exception);\n    if (rotated_image != (Image *) NULL)\n      {\n        rotated_image->page.x=0;\n        rotated_image->page.y=0;\n        rotated_image->colors = image->colors;\n        DestroyBlob(rotated_image);\n        rotated_image->blob=ReferenceBlob(image->blob);\n        AppendImageToList(&image,rotated_image);\n        DeleteImageFromList(&image);\n      }\n    /*\n      Proceed to next image.\n    */\n    if (image_info->number_scenes != 0)\n      if (image->scene >= (image_info->scene+image_info->number_scenes-1))\n        break;\n    /*\n      Allocate next image structure.\n    */\nskip_reading_current:\n    AcquireNextImage(image_info,image,exception);\n    if (GetNextImageInList(image) == (Image *) NULL)\n      {\n        status=MagickFalse;\n        break;\n      }\n    image=SyncNextImageInList(image);\n    status=SetImageProgress(image,LoadImagesTag,TellBlob(image),\n      GetBlobSize(image));\n    if (status == MagickFalse)\n      break;\n  }\n  (void) CloseBlob(image);\n  if (status == MagickFalse)\n    return(DestroyImageList(image));\n  return(GetFirstImageInList(image));\n}",
        "func_hash": 285338942932126464684406061663699404409,
        "file_name": "mat.c",
        "file_hash": 152895055268444149031499537279657208937,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2018-14551",
        "cve_desc": "The ReadMATImageV4 function in coders/mat.c in ImageMagick 7.0.8-7 uses an uninitialized variable, leading to memory corruption.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2018-14551",
        "func_name": "ReadMATImageV4",
        "diff": [
            "diff --git a/coders/mat.c b/coders/mat.c\nindex 5858ff53457..d3a2db86b2b 100644\n--- a/coders/mat.c\n+++ b/coders/mat.c\n@@ -631,9 +631,9 @@ static Image *ReadMATImageV4(const ImageInfo *image_info,Image *image,\n   unsigned int\n     depth;\n \n-\n   quantum_info=(QuantumInfo *) NULL;\n   (void) SeekBlob(image,0,SEEK_SET);\n+  status=MagickTrue;\n   while (EOFBlob(image) == MagickFalse)\n   {\n     /*\n"
        ],
        "func_after": []
    },
    {
        "idx": 200157,
        "project": "exim",
        "commit_id": "e2f5dc151e2e79058e93924e6d35510557f0535d",
        "project_url": "https://github.com/Exim/exim",
        "commit_url": "http://git.exim.org/exim.git/commit/e2f5dc151e2e79058e93924e6d35510557f0535d",
        "commit_message": "Check configure file permissions even for non-default files if still privileged\n\n(Bug 1044, CVE-2010-4345)",
        "target": 1,
        "irrelevant": 0,
        "func_before": "readconf_main(void)\n{\nint sep = 0;\nstruct stat statbuf;\nuschar *s, *filename;\nuschar *list = config_main_filelist;\n\n/* Loop through the possible file names */\n\nwhile((filename = string_nextinlist(&list, &sep, big_buffer, big_buffer_size))\n       != NULL)\n  {\n  /* Cut out all the fancy processing unless specifically wanted */\n\n  #if defined(CONFIGURE_FILE_USE_NODE) || defined(CONFIGURE_FILE_USE_EUID)\n  uschar *suffix = filename + Ustrlen(filename);\n\n  /* Try for the node-specific file if a node name exists */\n\n  #ifdef CONFIGURE_FILE_USE_NODE\n  struct utsname uts;\n  if (uname(&uts) >= 0)\n    {\n    #ifdef CONFIGURE_FILE_USE_EUID\n    sprintf(CS suffix, \".%ld.%.256s\", (long int)original_euid, uts.nodename);\n    config_file = Ufopen(filename, \"rb\");\n    if (config_file == NULL)\n    #endif  /* CONFIGURE_FILE_USE_EUID */\n      {\n      sprintf(CS suffix, \".%.256s\", uts.nodename);\n      config_file = Ufopen(filename, \"rb\");\n      }\n    }\n  #endif  /* CONFIGURE_FILE_USE_NODE */\n\n  /* Otherwise, try the generic name, possibly with the euid added */\n\n  #ifdef CONFIGURE_FILE_USE_EUID\n  if (config_file == NULL)\n    {\n    sprintf(CS suffix, \".%ld\", (long int)original_euid);\n    config_file = Ufopen(filename, \"rb\");\n    }\n  #endif  /* CONFIGURE_FILE_USE_EUID */\n\n  /* Finally, try the unadorned name */\n\n  if (config_file == NULL)\n    {\n    *suffix = 0;\n    config_file = Ufopen(filename, \"rb\");\n    }\n  #else  /* if neither defined */\n\n  /* This is the common case when the fancy processing is not included. */\n\n  config_file = Ufopen(filename, \"rb\");\n  #endif\n\n  /* If the file does not exist, continue to try any others. For any other\n  error, break out (and die). */\n\n  if (config_file != NULL || errno != ENOENT) break;\n  }\n\n/* On success, save the name for verification; config_filename is used when\nlogging configuration errors (it changes for .included files) whereas\nconfig_main_filename is the name shown by -bP. Failure to open a configuration\nfile is a serious disaster. */\n\nif (config_file != NULL)\n  {\n  config_filename = config_main_filename = string_copy(filename);\n  }\nelse\n  {\n  if (filename == NULL)\n    log_write(0, LOG_MAIN|LOG_PANIC_DIE, \"non-existent configuration file(s): \"\n      \"%s\", config_main_filelist);\n  else\n    log_write(0, LOG_MAIN|LOG_PANIC_DIE, \"%s\", string_open_failed(errno,\n      \"configuration file %s\", filename));\n  }\n\n/* Check the status of the file we have opened, unless it was specified on\nthe command line, in which case privilege was given away at the start. */\n\nif (!config_changed)\n  {\n  if (fstat(fileno(config_file), &statbuf) != 0)\n    log_write(0, LOG_MAIN|LOG_PANIC_DIE, \"failed to stat configuration file %s\",\n      big_buffer);\n\n  if ((statbuf.st_uid != root_uid                /* owner not root */\n       #ifdef CONFIGURE_OWNER\n       && statbuf.st_uid != config_uid           /* owner not the special one */\n       #endif\n         ) ||                                    /* or */\n      (statbuf.st_gid != root_gid                /* group not root & */\n       #ifdef CONFIGURE_GROUP\n       && statbuf.st_gid != config_gid           /* group not the special one */\n       #endif\n       && (statbuf.st_mode & 020) != 0) ||       /* group writeable  */\n                                                 /* or */\n      ((statbuf.st_mode & 2) != 0))              /* world writeable  */\n\n    log_write(0, LOG_MAIN|LOG_PANIC_DIE, \"Exim configuration file %s has the \"\n      \"wrong owner, group, or mode\", big_buffer);\n  }\n\n/* Process the main configuration settings. They all begin with a lower case\nletter. If we see something starting with an upper case letter, it is taken as\na macro definition. */\n\nwhile ((s = get_config_line()) != NULL)\n  {\n  if (isupper(s[0])) read_macro_assignment(s);\n\n  else if (Ustrncmp(s, \"domainlist\", 10) == 0)\n    read_named_list(&domainlist_anchor, &domainlist_count,\n      MAX_NAMED_LIST, s+10, US\"domain list\");\n\n  else if (Ustrncmp(s, \"hostlist\", 8) == 0)\n    read_named_list(&hostlist_anchor, &hostlist_count,\n      MAX_NAMED_LIST, s+8, US\"host list\");\n\n  else if (Ustrncmp(s, US\"addresslist\", 11) == 0)\n    read_named_list(&addresslist_anchor, &addresslist_count,\n      MAX_NAMED_LIST, s+11, US\"address list\");\n\n  else if (Ustrncmp(s, US\"localpartlist\", 13) == 0)\n    read_named_list(&localpartlist_anchor, &localpartlist_count,\n      MAX_NAMED_LIST, s+13, US\"local part list\");\n\n  else\n    (void) readconf_handle_option(s, optionlist_config, optionlist_config_size,\n      NULL, US\"main option \\\"%s\\\" unknown\");\n  }\n\n\n/* If local_sender_retain is set, local_from_check must be unset. */\n\nif (local_sender_retain && local_from_check)\n  log_write(0, LOG_MAIN|LOG_PANIC_DIE, \"both local_from_check and \"\n    \"local_sender_retain are set; this combination is not allowed\");\n\n/* If the timezone string is empty, set it to NULL, implying no TZ variable\nwanted. */\n\nif (timezone_string != NULL && *timezone_string == 0) timezone_string = NULL;\n\n/* The max retry interval must not be greater than 24 hours. */\n\nif (retry_interval_max > 24*60*60) retry_interval_max = 24*60*60;\n\n/* remote_max_parallel must be > 0 */\n\nif (remote_max_parallel <= 0) remote_max_parallel = 1;\n\n/* Save the configured setting of freeze_tell, so we can re-instate it at the\nstart of a new SMTP message. */\n\nfreeze_tell_config = freeze_tell;\n\n/* The primary host name may be required for expansion of spool_directory\nand log_file_path, so make sure it is set asap. It is obtained from uname(),\nbut if that yields an unqualified value, make a FQDN by using gethostbyname to\ncanonize it. Some people like upper case letters in their host names, so we\ndon't force the case. */\n\nif (primary_hostname == NULL)\n  {\n  uschar *hostname;\n  struct utsname uts;\n  if (uname(&uts) < 0)\n    log_write(0, LOG_MAIN|LOG_PANIC_DIE, \"uname() failed to yield host name\");\n  hostname = US uts.nodename;\n\n  if (Ustrchr(hostname, '.') == NULL)\n    {\n    int af = AF_INET;\n    struct hostent *hostdata;\n\n    #if HAVE_IPV6\n    if (!disable_ipv6 && (dns_ipv4_lookup == NULL ||\n         match_isinlist(hostname, &dns_ipv4_lookup, 0, NULL, NULL, MCL_DOMAIN,\n           TRUE, NULL) != OK))\n      af = AF_INET6;\n    #else\n    af = AF_INET;\n    #endif\n\n    for (;;)\n      {\n      #if HAVE_IPV6\n        #if HAVE_GETIPNODEBYNAME\n        int error_num;\n        hostdata = getipnodebyname(CS hostname, af, 0, &error_num);\n        #else\n        hostdata = gethostbyname2(CS hostname, af);\n        #endif\n      #else\n      hostdata = gethostbyname(CS hostname);\n      #endif\n\n      if (hostdata != NULL)\n        {\n        hostname = US hostdata->h_name;\n        break;\n        }\n\n      if (af == AF_INET) break;\n      af = AF_INET;\n      }\n    }\n\n  primary_hostname = string_copy(hostname);\n  }\n\n/* Set up default value for smtp_active_hostname */\n\nsmtp_active_hostname = primary_hostname;\n\n/* If spool_directory wasn't set in the build-time configuration, it must have\ngot set above. Of course, writing to the log may not work if log_file_path is\nnot set, but it will at least get to syslog or somewhere, with any luck. */\n\nif (*spool_directory == 0)\n  log_write(0, LOG_MAIN|LOG_PANIC_DIE, \"spool_directory undefined: cannot \"\n    \"proceed\");\n\n/* Expand the spool directory name; it may, for example, contain the primary\nhost name. Same comment about failure. */\n\ns = expand_string(spool_directory);\nif (s == NULL)\n  log_write(0, LOG_MAIN|LOG_PANIC_DIE, \"failed to expand spool_directory \"\n    \"\\\"%s\\\": %s\", spool_directory, expand_string_message);\nspool_directory = s;\n\n/* Expand log_file_path, which must contain \"%s\" in any component that isn't\nthe null string or \"syslog\". It is also allowed to contain one instance of %D.\nHowever, it must NOT contain % followed by anything else. */\n\nif (*log_file_path != 0)\n  {\n  uschar *ss, *sss;\n  int sep = ':';                       /* Fixed for log file path */\n  s = expand_string(log_file_path);\n  if (s == NULL)\n    log_write(0, LOG_MAIN|LOG_PANIC_DIE, \"failed to expand log_file_path \"\n      \"\\\"%s\\\": %s\", log_file_path, expand_string_message);\n\n  ss = s;\n  while ((sss = string_nextinlist(&ss,&sep,big_buffer,big_buffer_size)) != NULL)\n    {\n    uschar *t;\n    if (sss[0] == 0 || Ustrcmp(sss, \"syslog\") == 0) continue;\n    t = Ustrstr(sss, \"%s\");\n    if (t == NULL)\n      log_write(0, LOG_MAIN|LOG_PANIC_DIE, \"log_file_path \\\"%s\\\" does not \"\n        \"contain \\\"%%s\\\"\", sss);\n    *t = 'X';\n    t = Ustrchr(sss, '%');\n    if (t != NULL)\n      {\n      if (t[1] != 'D' || Ustrchr(t+2, '%') != NULL)\n        log_write(0, LOG_MAIN|LOG_PANIC_DIE, \"log_file_path \\\"%s\\\" contains \"\n          \"unexpected \\\"%%\\\" character\", s);\n      }\n    }\n\n  log_file_path = s;\n  }\n\n/* Interpret syslog_facility into an integer argument for 'ident' param to\nopenlog(). Default is LOG_MAIL set in globals.c. Allow the user to omit the\nleading \"log_\". */\n\nif (syslog_facility_str != NULL)\n  {\n  int i;\n  uschar *s = syslog_facility_str;\n\n  if ((Ustrlen(syslog_facility_str) >= 4) &&\n        (strncmpic(syslog_facility_str, US\"log_\", 4) == 0))\n    s += 4;\n\n  for (i = 0; i < syslog_list_size; i++)\n    {\n    if (strcmpic(s, syslog_list[i].name) == 0)\n      {\n      syslog_facility = syslog_list[i].value;\n      break;\n      }\n    }\n\n  if (i >= syslog_list_size)\n    {\n    log_write(0, LOG_PANIC_DIE|LOG_CONFIG,\n      \"failed to interpret syslog_facility \\\"%s\\\"\", syslog_facility_str);\n    }\n  }\n\n/* Expand pid_file_path */\n\nif (*pid_file_path != 0)\n  {\n  s = expand_string(pid_file_path);\n  if (s == NULL)\n    log_write(0, LOG_MAIN|LOG_PANIC_DIE, \"failed to expand pid_file_path \"\n      \"\\\"%s\\\": %s\", pid_file_path, expand_string_message);\n  pid_file_path = s;\n  }\n\n/* Compile the regex for matching a UUCP-style \"From_\" line in an incoming\nmessage. */\n\nregex_From = regex_must_compile(uucp_from_pattern, FALSE, TRUE);\n\n/* Unpick the SMTP rate limiting options, if set */\n\nif (smtp_ratelimit_mail != NULL)\n  {\n  unpick_ratelimit(smtp_ratelimit_mail, &smtp_rlm_threshold,\n    &smtp_rlm_base, &smtp_rlm_factor, &smtp_rlm_limit);\n  }\n\nif (smtp_ratelimit_rcpt != NULL)\n  {\n  unpick_ratelimit(smtp_ratelimit_rcpt, &smtp_rlr_threshold,\n    &smtp_rlr_base, &smtp_rlr_factor, &smtp_rlr_limit);\n  }\n\n/* The qualify domains default to the primary host name */\n\nif (qualify_domain_sender == NULL)\n  qualify_domain_sender = primary_hostname;\nif (qualify_domain_recipient == NULL)\n  qualify_domain_recipient = qualify_domain_sender;\n\n/* Setting system_filter_user in the configuration sets the gid as well if a\nname is given, but a numerical value does not. */\n\nif (system_filter_uid_set && !system_filter_gid_set)\n  {\n  struct passwd *pw = getpwuid(system_filter_uid);\n  if (pw == NULL)\n    log_write(0, LOG_MAIN|LOG_PANIC_DIE, \"Failed to look up uid %ld\",\n      (long int)system_filter_uid);\n  system_filter_gid = pw->pw_gid;\n  system_filter_gid_set = TRUE;\n  }\n\n/* If the errors_reply_to field is set, check that it is syntactically valid\nand ensure it contains a domain. */\n\nif (errors_reply_to != NULL)\n  {\n  uschar *errmess;\n  int start, end, domain;\n  uschar *recipient = parse_extract_address(errors_reply_to, &errmess,\n    &start, &end, &domain, FALSE);\n\n  if (recipient == NULL)\n    log_write(0, LOG_PANIC_DIE|LOG_CONFIG,\n      \"error in errors_reply_to (%s): %s\", errors_reply_to, errmess);\n\n  if (domain == 0)\n    log_write(0, LOG_PANIC_DIE|LOG_CONFIG,\n      \"errors_reply_to (%s) does not contain a domain\", errors_reply_to);\n  }\n\n/* If smtp_accept_queue or smtp_accept_max_per_host is set, then\nsmtp_accept_max must also be set. */\n\nif (smtp_accept_max == 0 &&\n    (smtp_accept_queue > 0 || smtp_accept_max_per_host != NULL))\n  log_write(0, LOG_PANIC_DIE|LOG_CONFIG,\n    \"smtp_accept_max must be set if smtp_accept_queue or \"\n    \"smtp_accept_max_per_host is set\");\n\n/* Set up the host number if anything is specified. It is an expanded string\nso that it can be computed from the host name, for example. We do this last\nso as to ensure that everything else is set up before the expansion. */\n\nif (host_number_string != NULL)\n  {\n  uschar *end;\n  uschar *s = expand_string(host_number_string);\n  long int n = Ustrtol(s, &end, 0);\n  while (isspace(*end)) end++;\n  if (*end != 0)\n    log_write(0, LOG_PANIC_DIE|LOG_CONFIG,\n      \"localhost_number value is not a number: %s\", s);\n  if (n > LOCALHOST_MAX)\n    log_write(0, LOG_PANIC_DIE|LOG_CONFIG,\n      \"localhost_number is greater than the maximum allowed value (%d)\",\n        LOCALHOST_MAX);\n  host_number = n;\n  }\n\n#ifdef SUPPORT_TLS\n/* If tls_verify_hosts is set, tls_verify_certificates must also be set */\n\nif ((tls_verify_hosts != NULL || tls_try_verify_hosts != NULL) &&\n     tls_verify_certificates == NULL)\n  log_write(0, LOG_PANIC_DIE|LOG_CONFIG,\n    \"tls_%sverify_hosts is set, but tls_verify_certificates is not set\",\n    (tls_verify_hosts != NULL)? \"\" : \"try_\");\n\n/* If openssl_options is set, validate it */\nif (openssl_options != NULL)\n  {\n# ifdef USE_GNUTLS\n  log_write(0, LOG_PANIC_DIE|LOG_CONFIG,\n    \"openssl_options is set but we're using GnuTLS\");\n# else\n  long dummy;\n  if (!(tls_openssl_options_parse(openssl_options, &dummy)))\n    log_write(0, LOG_PANIC_DIE|LOG_CONFIG,\n      \"openssl_options parse error: %s\", openssl_options);\n# endif\n  }\n#endif\n}",
        "func_hash": 74987850300315727501245353003929658606,
        "file_name": "readconf.c",
        "file_hash": 217124537327695199621061480517955399637,
        "cwe": [
            "CWE-264"
        ],
        "cve": "CVE-2010-4345",
        "cve_desc": "Exim 4.72 and earlier allows local users to gain privileges by leveraging the ability of the exim user account to specify an alternate configuration file with a directive that contains arbitrary commands, as demonstrated by the spool_directory directive.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2010-4345",
        "func_name": "readconf_main",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 200163,
        "project": "linux",
        "commit_id": "817b8b9c5396d2b2d92311b46719aad5d3339dbe",
        "project_url": "https://github.com/torvalds/linux",
        "commit_url": "https://github.com/torvalds/linux/commit/817b8b9c5396d2b2d92311b46719aad5d3339dbe",
        "commit_message": "HID: elo: fix memory leak in elo_probe\n\nWhen hid_parse() in elo_probe() fails, it forgets to call usb_put_dev to\ndecrease the refcount.\n\nFix this by adding usb_put_dev() in the error handling code of elo_probe().\n\nFixes: fbf42729d0e9 (\"HID: elo: update the reference count of the usb device structure\")\nReported-by: syzkaller <syzkaller@googlegroups.com>\nSigned-off-by: Dongliang Mu <mudongliangabcd@gmail.com>\nSigned-off-by: Jiri Kosina <jkosina@suse.cz>",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static int elo_probe(struct hid_device *hdev, const struct hid_device_id *id)\n{\n\tstruct elo_priv *priv;\n\tint ret;\n\tstruct usb_device *udev;\n\n\tif (!hid_is_usb(hdev))\n\t\treturn -EINVAL;\n\n\tpriv = kzalloc(sizeof(*priv), GFP_KERNEL);\n\tif (!priv)\n\t\treturn -ENOMEM;\n\n\tINIT_DELAYED_WORK(&priv->work, elo_work);\n\tudev = interface_to_usbdev(to_usb_interface(hdev->dev.parent));\n\tpriv->usbdev = usb_get_dev(udev);\n\n\thid_set_drvdata(hdev, priv);\n\n\tret = hid_parse(hdev);\n\tif (ret) {\n\t\thid_err(hdev, \"parse failed\\n\");\n\t\tgoto err_free;\n\t}\n\n\tret = hid_hw_start(hdev, HID_CONNECT_DEFAULT);\n\tif (ret) {\n\t\thid_err(hdev, \"hw start failed\\n\");\n\t\tgoto err_free;\n\t}\n\n\tif (elo_broken_firmware(priv->usbdev)) {\n\t\thid_info(hdev, \"broken firmware found, installing workaround\\n\");\n\t\tqueue_delayed_work(wq, &priv->work, ELO_PERIODIC_READ_INTERVAL);\n\t}\n\n\treturn 0;\nerr_free:\n\tkfree(priv);\n\treturn ret;\n}",
        "func_hash": 119771214080354607700352502150468808097,
        "file_name": "hid-elo.c",
        "file_hash": 34235452733984026251117954935462979934,
        "cwe": [
            "CWE-200"
        ],
        "cve": "CVE-2022-27950",
        "cve_desc": "In drivers/hid/hid-elo.c in the Linux kernel before 5.16.11, a memory leak exists for a certain hid_parse error condition.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-27950",
        "func_name": "elo_probe",
        "diff": [
            "diff --git a/drivers/hid/hid-elo.c b/drivers/hid/hid-elo.c\nindex 8e960d7b233b3a..9b42b0cdeef06b 100644\n--- a/drivers/hid/hid-elo.c\n+++ b/drivers/hid/hid-elo.c\n@@ -262,6 +262,7 @@ static int elo_probe(struct hid_device *hdev, const struct hid_device_id *id)\n \n \treturn 0;\n err_free:\n+\tusb_put_dev(udev);\n \tkfree(priv);\n \treturn ret;\n }\n"
        ],
        "func_after": []
    },
    {
        "idx": 195246,
        "project": "gpac",
        "commit_id": "cf6771c857eb9a290e2c19ddacfdd3ed98b27618",
        "project_url": "https://github.com/gpac/gpac",
        "commit_url": "https://github.com/gpac/gpac/commit/cf6771c857eb9a290e2c19ddacfdd3ed98b27618",
        "commit_message": "fixed #1898",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static s32 avc_parse_slice(GF_BitStream *bs, AVCState *avc, Bool svc_idr_flag, AVCSliceInfo *si)\n{\n\ts32 pps_id, num_ref_idx_l0_active_minus1 = 0, num_ref_idx_l1_active_minus1 = 0;\n\n\t/*s->current_picture.reference= h->nal_ref_idc != 0;*/\n\tgf_bs_read_ue_log(bs, \"first_mb_in_slice\");\n\tsi->slice_type = gf_bs_read_ue_log(bs, \"slice_type\");\n\tif (si->slice_type > 9) return -1;\n\n\tpps_id = gf_bs_read_ue_log(bs, \"pps_id\");\n\tif (pps_id > 255) return -1;\n\tsi->pps = &avc->pps[pps_id];\n\tif (!si->pps->slice_group_count) return -2;\n\tsi->sps = &avc->sps[si->pps->sps_id];\n\tif (!si->sps->log2_max_frame_num) return -2;\n\tavc->sps_active_idx = si->pps->sps_id;\n\tavc->pps_active_idx = pps_id;\n\n\tsi->frame_num = gf_bs_read_int_log(bs, si->sps->log2_max_frame_num, \"frame_num\");\n\n\tsi->field_pic_flag = 0;\n\tsi->bottom_field_flag = 0;\n\tif (!si->sps->frame_mbs_only_flag) {\n\t\tsi->field_pic_flag = gf_bs_read_int_log(bs, 1, \"field_pic_flag\");\n\t\tif (si->field_pic_flag)\n\t\t\tsi->bottom_field_flag = gf_bs_read_int_log(bs, 1, \"bottom_field_flag\");\n\t}\n\n\tif ((si->nal_unit_type == GF_AVC_NALU_IDR_SLICE) || svc_idr_flag)\n\t\tsi->idr_pic_id = gf_bs_read_ue_log(bs, \"idr_pic_id\");\n\n\tif (si->sps->poc_type == 0) {\n\t\tsi->poc_lsb = gf_bs_read_int_log(bs, si->sps->log2_max_poc_lsb, \"poc_lsb\");\n\t\tif (si->pps->pic_order_present && !si->field_pic_flag) {\n\t\t\tsi->delta_poc_bottom = gf_bs_read_se_log(bs, \"poc_lsb\");\n\t\t}\n\t}\n\telse if ((si->sps->poc_type == 1) && !si->sps->delta_pic_order_always_zero_flag) {\n\t\tsi->delta_poc[0] = gf_bs_read_se_log(bs, \"delta_poc0\");\n\t\tif ((si->pps->pic_order_present == 1) && !si->field_pic_flag)\n\t\t\tsi->delta_poc[1] = gf_bs_read_se_log(bs, \"delta_poc1\");\n\t}\n\n\tif (si->pps->redundant_pic_cnt_present) {\n\t\tsi->redundant_pic_cnt = gf_bs_read_ue_log(bs, \"redundant_pic_cnt\");\n\t}\n\n\tif (si->slice_type % 5 == GF_AVC_TYPE_B) {\n\t\tgf_bs_read_int_log(bs, 1, \"direct_spatial_mv_pred_flag\");\n\t}\n\n\tnum_ref_idx_l0_active_minus1 = si->pps->num_ref_idx_l0_default_active_minus1;\n\tnum_ref_idx_l1_active_minus1 = si->pps->num_ref_idx_l1_default_active_minus1;\n\n\tif (si->slice_type % 5 == GF_AVC_TYPE_P || si->slice_type % 5 == GF_AVC_TYPE_SP || si->slice_type % 5 == GF_AVC_TYPE_B) {\n\t\tBool num_ref_idx_active_override_flag = gf_bs_read_int_log(bs, 1, \"num_ref_idx_active_override_flag\");\n\t\tif (num_ref_idx_active_override_flag) {\n\t\t\tnum_ref_idx_l0_active_minus1 = gf_bs_read_ue_log(bs, \"num_ref_idx_l0_active_minus1\");\n\t\t\tif (si->slice_type % 5 == GF_AVC_TYPE_B) {\n\t\t\t\tnum_ref_idx_l1_active_minus1 = gf_bs_read_ue_log(bs, \"num_ref_idx_l1_active_minus1\");\n\t\t\t}\n\t\t}\n\t}\n\n\tif (si->nal_unit_type == 20 || si->nal_unit_type == 21) {\n\t\t//ref_pic_list_mvc_modification(); /* specified in Annex H */\n\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CODING, (\"[avc-h264] unimplemented ref_pic_list_mvc_modification() in slide header\\n\"));\n\t\tassert(0);\n\t\treturn -1;\n\t}\n\telse {\n\t\tref_pic_list_modification(bs, si->slice_type);\n\t}\n\n\tif ((si->pps->weighted_pred_flag && (si->slice_type % 5 == GF_AVC_TYPE_P || si->slice_type % 5 == GF_AVC_TYPE_SP))\n\t\t|| (si->pps->weighted_bipred_idc == 1 && si->slice_type % 5 == GF_AVC_TYPE_B)) {\n\t\tpred_weight_table(bs, si->slice_type, si->sps->ChromaArrayType, num_ref_idx_l0_active_minus1, num_ref_idx_l1_active_minus1);\n\t}\n\n\tif (si->nal_ref_idc != 0) {\n\t\tdec_ref_pic_marking(bs, (si->nal_unit_type == GF_AVC_NALU_IDR_SLICE));\n\t}\n\n\tif (si->pps->entropy_coding_mode_flag && si->slice_type % 5 != GF_AVC_TYPE_I && si->slice_type % 5 != GF_AVC_TYPE_SI) {\n\t\tgf_bs_read_ue_log(bs, \"cabac_init_idc\");\n\t}\n\n\t/*slice_qp_delta = */gf_bs_read_se(bs);\n\tif (si->slice_type % 5 == GF_AVC_TYPE_SP || si->slice_type % 5 == GF_AVC_TYPE_SI) {\n\t\tif (si->slice_type % 5 == GF_AVC_TYPE_SP) {\n\t\t\tgf_bs_read_int_log(bs, 1, \"sp_for_switch_flag\");\n\t\t}\n\t\tgf_bs_read_se_log(bs, \"slice_qs_delta\");\n\t}\n\n\tif (si->pps->deblocking_filter_control_present_flag) {\n\t\tif (gf_bs_read_ue_log(bs, \"disable_deblocking_filter_idc\") != 1) {\n\t\t\tgf_bs_read_se_log(bs, \"slice_alpha_c0_offset_div2\");\n\t\t\tgf_bs_read_se_log(bs, \"slice_beta_offset_div2\");\n\t\t}\n\t}\n\n\tif (si->pps->slice_group_count > 1 && si->pps->mb_slice_group_map_type >= 3 && si->pps->mb_slice_group_map_type <= 5) {\n\t\tgf_bs_read_int_log(bs, (u32)ceil(log1p((si->pps->pic_size_in_map_units_minus1 + 1) / (si->pps->slice_group_change_rate_minus1 + 1) ) / log(2)), \"slice_group_change_cycle\");\n\t}\n\treturn 0;\n}",
        "func_hash": 250322460567095926906340260446333370263,
        "file_name": "av_parsers.c",
        "file_hash": 168517587328341017594269375399465893964,
        "cwe": [
            "CWE-476"
        ],
        "cve": "CVE-2021-40564",
        "cve_desc": "A Segmentation fault caused by null pointer dereference vulnerability eists in Gpac through 1.0.2 via the avc_parse_slice function in av_parsers.c when using mp4box, which causes a denial of service.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-40564",
        "func_name": "avc_parse_slice",
        "diff": [
            "diff --git a/src/media_tools/av_parsers.c b/src/media_tools/av_parsers.c\nindex 4ea0db8a90..0cc096d1a3 100644\n--- a/src/media_tools/av_parsers.c\n+++ b/src/media_tools/av_parsers.c\n@@ -4705,8 +4705,12 @@ u32 gf_bs_read_ue_log_idx3(GF_BitStream *bs, const char *fname, s32 idx1, s32 id\n \t}\n \n \tif (nb_lead) {\n+\t\tu32 leads=1;\n \t\tval = gf_bs_read_int(bs, nb_lead);\n-\t\tval += (1 << nb_lead) - 1;\n+\t\tleads <<= nb_lead;\n+\t\tleads -= 1;\n+\t\tval += leads;\n+//\t\tval += (1 << nb_lead) - 1;\n \t\tbits += nb_lead;\n \t}\n \n@@ -5671,7 +5675,7 @@ static s32 avc_parse_slice(GF_BitStream *bs, AVCState *avc, Bool svc_idr_flag, A\n \tif (si->slice_type > 9) return -1;\n \n \tpps_id = gf_bs_read_ue_log(bs, \"pps_id\");\n-\tif (pps_id > 255) return -1;\n+\tif ((pps_id<0) || (pps_id > 255)) return -1;\n \tsi->pps = &avc->pps[pps_id];\n \tif (!si->pps->slice_group_count) return -2;\n \tsi->sps = &avc->sps[si->pps->sps_id];\n"
        ],
        "func_after": []
    },
    {
        "idx": 195261,
        "project": "tensorflow",
        "commit_id": "955059813cc325dc1db5e2daa6221271406d4439",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/955059813cc325dc1db5e2daa6221271406d4439",
        "commit_message": "Check for type inference error on node construction.\n\nPiperOrigin-RevId: 409415804\nChange-Id: Ieb6e020906b96f522bf8e2fa103715ddbbdc434a",
        "target": 1,
        "irrelevant": 0,
        "func_before": "Node* Graph::AddNode(NodeDef node_def, Status* status) {\n  const OpRegistrationData* op_reg_data;\n  status->Update(ops_.LookUp(node_def.op(), &op_reg_data));\n  if (!status->ok()) return nullptr;\n\n  DataTypeVector inputs;\n  DataTypeVector outputs;\n  status->Update(\n      InOutTypesForNode(node_def, op_reg_data->op_def, &inputs, &outputs));\n  if (!status->ok()) {\n    *status = AttachDef(*status, node_def);\n    return nullptr;\n  }\n\n  Node::NodeClass node_class = op_reg_data->is_function_op\n                                   ? Node::NC_FUNCTION_OP\n                                   : Node::GetNodeClassForOp(node_def.op());\n\n  if (op_reg_data->type_ctor != nullptr) {\n    VLOG(3) << \"AddNode: found type constructor for \" << node_def.name();\n    const auto ctor_type =\n        full_type::SpecializeType(AttrSlice(node_def), op_reg_data->op_def);\n    const FullTypeDef ctor_typedef = ctor_type.ValueOrDie();\n    if (ctor_typedef.type_id() != TFT_UNSET) {\n      *(node_def.mutable_experimental_type()) = ctor_typedef;\n    }\n  } else {\n    VLOG(3) << \"AddNode: no type constructor for \" << node_def.name();\n  }\n\n  Node* node = AllocateNode(std::make_shared<NodeProperties>(\n                                &op_reg_data->op_def, std::move(node_def),\n                                inputs, outputs, op_reg_data->fwd_type_fn),\n                            nullptr, node_class);\n  return node;\n}",
        "func_hash": 216608112162338080739127582529653382623,
        "file_name": "graph.cc",
        "file_hash": 171004513035817799651733534811388619872,
        "cwe": [
            "CWE-754"
        ],
        "cve": "CVE-2022-23590",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. A `GraphDef` from a TensorFlow `SavedModel` can be maliciously altered to cause a TensorFlow process to crash due to encountering a `StatusOr` value that is an error and forcibly extracting the value from it. We have patched the issue in multiple GitHub commits and these will be included in TensorFlow 2.8.0 and TensorFlow 2.7.1, as both are affected.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23590",
        "func_name": "Graph::AddNode",
        "diff": [
            "diff --git a/tensorflow/core/graph/graph.cc b/tensorflow/core/graph/graph.cc\nindex 397a45c97737ab..2e3703b66030f4 100644\n--- a/tensorflow/core/graph/graph.cc\n+++ b/tensorflow/core/graph/graph.cc\n@@ -561,6 +561,11 @@ Node* Graph::AddNode(NodeDef node_def, Status* status) {\n     VLOG(3) << \"AddNode: found type constructor for \" << node_def.name();\n     const auto ctor_type =\n         full_type::SpecializeType(AttrSlice(node_def), op_reg_data->op_def);\n+    if (!ctor_type.ok()) {\n+      *status = errors::InvalidArgument(\"type error: \",\n+                                        ctor_type.status().ToString());\n+      return nullptr;\n+    }\n     const FullTypeDef ctor_typedef = ctor_type.ValueOrDie();\n     if (ctor_typedef.type_id() != TFT_UNSET) {\n       *(node_def.mutable_experimental_type()) = ctor_typedef;\n"
        ],
        "func_after": []
    },
    {
        "idx": 195264,
        "project": "pcre2",
        "commit_id": "d4fa336fbcc388f89095b184ba6d99422cfc676c",
        "project_url": "https://github.com/PCRE2Project/pcre2",
        "commit_url": "https://github.com/PCRE2Project/pcre2/commit/d4fa336fbcc388f89095b184ba6d99422cfc676c",
        "commit_message": "Fix incorrect value reading in JIT.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static void compile_xclass_matchingpath(compiler_common *common, PCRE2_SPTR cc, jump_list **backtracks)\n{\nDEFINE_COMPILER;\njump_list *found = NULL;\njump_list **list = (cc[0] & XCL_NOT) == 0 ? &found : backtracks;\nsljit_uw c, charoffset, max = 256, min = READ_CHAR_MAX;\nstruct sljit_jump *jump = NULL;\nPCRE2_SPTR ccbegin;\nint compares, invertcmp, numberofcmps;\n#if defined SUPPORT_UNICODE && (PCRE2_CODE_UNIT_WIDTH == 8 || PCRE2_CODE_UNIT_WIDTH == 16)\nBOOL utf = common->utf;\n#endif /* SUPPORT_UNICODE && PCRE2_CODE_UNIT_WIDTH == [8|16] */\n\n#ifdef SUPPORT_UNICODE\nsljit_u32 unicode_status = 0;\nint typereg = TMP1;\nconst sljit_u32 *other_cases;\nsljit_uw typeoffset;\n#endif /* SUPPORT_UNICODE */\n\n/* Scanning the necessary info. */\ncc++;\nccbegin = cc;\ncompares = 0;\n\nif (cc[-1] & XCL_MAP)\n  {\n  min = 0;\n  cc += 32 / sizeof(PCRE2_UCHAR);\n  }\n\nwhile (*cc != XCL_END)\n  {\n  compares++;\n  if (*cc == XCL_SINGLE)\n    {\n    cc ++;\n    GETCHARINCTEST(c, cc);\n    if (c > max) max = c;\n    if (c < min) min = c;\n#ifdef SUPPORT_UNICODE\n    unicode_status |= XCLASS_SAVE_CHAR;\n#endif /* SUPPORT_UNICODE */\n    }\n  else if (*cc == XCL_RANGE)\n    {\n    cc ++;\n    GETCHARINCTEST(c, cc);\n    if (c < min) min = c;\n    GETCHARINCTEST(c, cc);\n    if (c > max) max = c;\n#ifdef SUPPORT_UNICODE\n    unicode_status |= XCLASS_SAVE_CHAR;\n#endif /* SUPPORT_UNICODE */\n    }\n#ifdef SUPPORT_UNICODE\n  else\n    {\n    SLJIT_ASSERT(*cc == XCL_PROP || *cc == XCL_NOTPROP);\n    cc++;\n    if (*cc == PT_CLIST && *cc == XCL_PROP)\n      {\n      other_cases = PRIV(ucd_caseless_sets) + cc[1];\n      while (*other_cases != NOTACHAR)\n        {\n        if (*other_cases > max) max = *other_cases;\n        if (*other_cases < min) min = *other_cases;\n        other_cases++;\n        }\n      }\n    else\n      {\n      max = READ_CHAR_MAX;\n      min = 0;\n      }\n\n    switch(*cc)\n      {\n      case PT_ANY:\n      /* Any either accepts everything or ignored. */\n      if (cc[-1] == XCL_PROP)\n        {\n        compile_char1_matchingpath(common, OP_ALLANY, cc, backtracks, FALSE);\n        if (list == backtracks)\n          add_jump(compiler, backtracks, JUMP(SLJIT_JUMP));\n        return;\n        }\n      break;\n\n      case PT_LAMP:\n      case PT_GC:\n      case PT_PC:\n      case PT_ALNUM:\n      unicode_status |= XCLASS_HAS_TYPE;\n      break;\n\n      case PT_SCX:\n      unicode_status |= XCLASS_HAS_SCRIPT_EXTENSION;\n      if (cc[-1] == XCL_NOTPROP)\n        {\n        unicode_status |= XCLASS_SCRIPT_EXTENSION_NOTPROP;\n        break;\n        }\n      compares++;\n      /* Fall through */ \n\n      case PT_SC:\n      unicode_status |= XCLASS_HAS_SCRIPT;\n      break;\n\n      case PT_SPACE:\n      case PT_PXSPACE:\n      case PT_WORD:\n      case PT_PXGRAPH:\n      case PT_PXPRINT:\n      case PT_PXPUNCT:\n      unicode_status |= XCLASS_SAVE_CHAR | XCLASS_HAS_TYPE;\n      break;\n\n      case PT_CLIST:\n      case PT_UCNC:\n      unicode_status |= XCLASS_SAVE_CHAR;\n      break;\n\n      case PT_BOOL:\n      unicode_status |= XCLASS_HAS_BOOL;\n      break;\n\n      case PT_BIDICL:\n      unicode_status |= XCLASS_HAS_BIDICL;\n      break;\n\n      default:\n      SLJIT_UNREACHABLE();\n      break;\n      }\n    cc += 2;\n    }\n#endif /* SUPPORT_UNICODE */\n  }\nSLJIT_ASSERT(compares > 0);\n\n/* We are not necessary in utf mode even in 8 bit mode. */\ncc = ccbegin;\nif ((cc[-1] & XCL_NOT) != 0)\n  read_char(common, min, max, backtracks, READ_CHAR_UPDATE_STR_PTR);\nelse\n  {\n#ifdef SUPPORT_UNICODE\n  read_char(common, min, max, (unicode_status & XCLASS_NEEDS_UCD) ? backtracks : NULL, 0);\n#else /* !SUPPORT_UNICODE */\n  read_char(common, min, max, NULL, 0);\n#endif /* SUPPORT_UNICODE */\n  }\n\nif ((cc[-1] & XCL_HASPROP) == 0)\n  {\n  if ((cc[-1] & XCL_MAP) != 0)\n    {\n    jump = CMP(SLJIT_GREATER, TMP1, 0, SLJIT_IMM, 255);\n    if (!optimize_class(common, (const sljit_u8 *)cc, (((const sljit_u8 *)cc)[31] & 0x80) != 0, TRUE, &found))\n      {\n      OP2(SLJIT_AND, TMP2, 0, TMP1, 0, SLJIT_IMM, 0x7);\n      OP2(SLJIT_LSHR, TMP1, 0, TMP1, 0, SLJIT_IMM, 3);\n      OP1(SLJIT_MOV_U8, TMP1, 0, SLJIT_MEM1(TMP1), (sljit_sw)cc);\n      OP2(SLJIT_SHL, TMP2, 0, SLJIT_IMM, 1, TMP2, 0);\n      OP2U(SLJIT_AND | SLJIT_SET_Z, TMP1, 0, TMP2, 0);\n      add_jump(compiler, &found, JUMP(SLJIT_NOT_ZERO));\n      }\n\n    add_jump(compiler, backtracks, JUMP(SLJIT_JUMP));\n    JUMPHERE(jump);\n\n    cc += 32 / sizeof(PCRE2_UCHAR);\n    }\n  else\n    {\n    OP2(SLJIT_SUB, TMP2, 0, TMP1, 0, SLJIT_IMM, min);\n    add_jump(compiler, (cc[-1] & XCL_NOT) == 0 ? backtracks : &found, CMP(SLJIT_GREATER, TMP2, 0, SLJIT_IMM, max - min));\n    }\n  }\nelse if ((cc[-1] & XCL_MAP) != 0)\n  {\n  OP1(SLJIT_MOV, RETURN_ADDR, 0, TMP1, 0);\n#ifdef SUPPORT_UNICODE\n  unicode_status |= XCLASS_CHAR_SAVED;\n#endif /* SUPPORT_UNICODE */\n  if (!optimize_class(common, (const sljit_u8 *)cc, FALSE, TRUE, list))\n    {\n#if PCRE2_CODE_UNIT_WIDTH == 8\n    jump = NULL;\n    if (common->utf)\n#endif /* PCRE2_CODE_UNIT_WIDTH == 8 */\n      jump = CMP(SLJIT_GREATER, TMP1, 0, SLJIT_IMM, 255);\n\n    OP2(SLJIT_AND, TMP2, 0, TMP1, 0, SLJIT_IMM, 0x7);\n    OP2(SLJIT_LSHR, TMP1, 0, TMP1, 0, SLJIT_IMM, 3);\n    OP1(SLJIT_MOV_U8, TMP1, 0, SLJIT_MEM1(TMP1), (sljit_sw)cc);\n    OP2(SLJIT_SHL, TMP2, 0, SLJIT_IMM, 1, TMP2, 0);\n    OP2U(SLJIT_AND | SLJIT_SET_Z, TMP1, 0, TMP2, 0);\n    add_jump(compiler, list, JUMP(SLJIT_NOT_ZERO));\n\n#if PCRE2_CODE_UNIT_WIDTH == 8\n    if (common->utf)\n#endif /* PCRE2_CODE_UNIT_WIDTH == 8 */\n      JUMPHERE(jump);\n    }\n\n  OP1(SLJIT_MOV, TMP1, 0, RETURN_ADDR, 0);\n  cc += 32 / sizeof(PCRE2_UCHAR);\n  }\n\n#ifdef SUPPORT_UNICODE\nif (unicode_status & XCLASS_NEEDS_UCD)\n  {\n  if ((unicode_status & (XCLASS_SAVE_CHAR | XCLASS_CHAR_SAVED)) == XCLASS_SAVE_CHAR)\n    OP1(SLJIT_MOV, RETURN_ADDR, 0, TMP1, 0);\n\n#if PCRE2_CODE_UNIT_WIDTH == 32\n  if (!common->utf)\n    {\n    jump = CMP(SLJIT_LESS, TMP1, 0, SLJIT_IMM, MAX_UTF_CODE_POINT + 1);\n    OP1(SLJIT_MOV, TMP1, 0, SLJIT_IMM, UNASSIGNED_UTF_CHAR);\n    JUMPHERE(jump);\n    }\n#endif /* PCRE2_CODE_UNIT_WIDTH == 32 */\n\n  OP2(SLJIT_LSHR, TMP2, 0, TMP1, 0, SLJIT_IMM, UCD_BLOCK_SHIFT);\n  OP2(SLJIT_SHL, TMP2, 0, TMP2, 0, SLJIT_IMM, 1);\n  OP1(SLJIT_MOV_U16, TMP2, 0, SLJIT_MEM1(TMP2), (sljit_sw)PRIV(ucd_stage1));\n  OP2(SLJIT_AND, TMP1, 0, TMP1, 0, SLJIT_IMM, UCD_BLOCK_MASK);\n  OP2(SLJIT_SHL, TMP2, 0, TMP2, 0, SLJIT_IMM, UCD_BLOCK_SHIFT);\n  OP2(SLJIT_ADD, TMP1, 0, TMP1, 0, TMP2, 0);\n  OP1(SLJIT_MOV, TMP2, 0, SLJIT_IMM, (sljit_sw)PRIV(ucd_stage2));\n  OP1(SLJIT_MOV_U16, TMP2, 0, SLJIT_MEM2(TMP2, TMP1), 1);\n  OP2(SLJIT_SHL, TMP1, 0, TMP2, 0, SLJIT_IMM, 3);\n  OP2(SLJIT_SHL, TMP2, 0, TMP2, 0, SLJIT_IMM, 2);\n  OP2(SLJIT_ADD, TMP2, 0, TMP2, 0, TMP1, 0);\n\n  ccbegin = cc;\n\n  if (unicode_status & XCLASS_HAS_BIDICL)\n    {\n    OP1(SLJIT_MOV_U16, TMP1, 0, SLJIT_MEM1(TMP2), (sljit_sw)PRIV(ucd_records) + SLJIT_OFFSETOF(ucd_record, scriptx_bidiclass));\n    OP2(SLJIT_LSHR, TMP1, 0, TMP1, 0, SLJIT_IMM, UCD_BIDICLASS_SHIFT);\n\n    while (*cc != XCL_END)\n      {\n      if (*cc == XCL_SINGLE)\n        {\n        cc ++;\n        GETCHARINCTEST(c, cc);\n        }\n      else if (*cc == XCL_RANGE)\n        {\n        cc ++;\n        GETCHARINCTEST(c, cc);\n        GETCHARINCTEST(c, cc);\n        }\n      else\n        {\n        SLJIT_ASSERT(*cc == XCL_PROP || *cc == XCL_NOTPROP);\n        cc++;\n        if (*cc == PT_BIDICL)\n          {\n          compares--;\n          invertcmp = (compares == 0 && list != backtracks);\n          if (cc[-1] == XCL_NOTPROP)\n            invertcmp ^= 0x1;\n          jump = CMP(SLJIT_EQUAL ^ invertcmp, TMP1, 0, SLJIT_IMM, (int)cc[1]);\n          add_jump(compiler, compares > 0 ? list : backtracks, jump);\n          }\n        cc += 2;\n        }\n      }\n\n    cc = ccbegin;\n    }\n\n  if (unicode_status & XCLASS_HAS_BOOL)\n    {\n    OP1(SLJIT_MOV_U16, TMP1, 0, SLJIT_MEM1(TMP2), (sljit_sw)PRIV(ucd_records) + SLJIT_OFFSETOF(ucd_record, bprops));\n    OP2(SLJIT_AND, TMP1, 0, TMP1, 0, SLJIT_IMM, UCD_BPROPS_MASK);\n    OP2(SLJIT_SHL, TMP1, 0, TMP1, 0, SLJIT_IMM, 2);\n\n    while (*cc != XCL_END)\n      {\n      if (*cc == XCL_SINGLE)\n        {\n        cc ++;\n        GETCHARINCTEST(c, cc);\n        }\n      else if (*cc == XCL_RANGE)\n        {\n        cc ++;\n        GETCHARINCTEST(c, cc);\n        GETCHARINCTEST(c, cc);\n        }\n      else\n        {\n        SLJIT_ASSERT(*cc == XCL_PROP || *cc == XCL_NOTPROP);\n        cc++;\n        if (*cc == PT_BOOL)\n          {\n          compares--;\n          invertcmp = (compares == 0 && list != backtracks);\n          if (cc[-1] == XCL_NOTPROP)\n            invertcmp ^= 0x1;\n\n          OP2U(SLJIT_AND32 | SLJIT_SET_Z, SLJIT_MEM1(TMP1), (sljit_sw)(PRIV(ucd_boolprop_sets) + (cc[1] >> 5)), SLJIT_IMM, (sljit_sw)1 << (cc[1] & 0x1f));\n          add_jump(compiler, compares > 0 ? list : backtracks, JUMP(SLJIT_NOT_ZERO ^ invertcmp));\n          }\n        cc += 2;\n        }\n      }\n\n    cc = ccbegin;\n    }\n\n  if (unicode_status & XCLASS_HAS_SCRIPT)\n    {\n    OP1(SLJIT_MOV_U8, TMP1, 0, SLJIT_MEM1(TMP2), (sljit_sw)PRIV(ucd_records) + SLJIT_OFFSETOF(ucd_record, script));\n\n    while (*cc != XCL_END)\n      {\n      if (*cc == XCL_SINGLE)\n        {\n        cc ++;\n        GETCHARINCTEST(c, cc);\n        }\n      else if (*cc == XCL_RANGE)\n        {\n        cc ++;\n        GETCHARINCTEST(c, cc);\n        GETCHARINCTEST(c, cc);\n        }\n      else\n        {\n        SLJIT_ASSERT(*cc == XCL_PROP || *cc == XCL_NOTPROP);\n        cc++;\n        switch (*cc)\n          {\n          case PT_SCX:\n          if (cc[-1] == XCL_NOTPROP)\n            break;\n          /* Fall through */ \n\n          case PT_SC:\n          compares--;\n          invertcmp = (compares == 0 && list != backtracks);\n          if (cc[-1] == XCL_NOTPROP)\n            invertcmp ^= 0x1;\n\n          add_jump(compiler, compares > 0 ? list : backtracks, CMP(SLJIT_EQUAL ^ invertcmp, TMP1, 0, SLJIT_IMM, (int)cc[1]));\n          }\n        cc += 2;\n        }\n      }\n\n    cc = ccbegin;\n    }\n\n  if (unicode_status & XCLASS_HAS_SCRIPT_EXTENSION)\n    {\n    OP1(SLJIT_MOV_U16, TMP1, 0, SLJIT_MEM1(TMP2), (sljit_sw)PRIV(ucd_records) + SLJIT_OFFSETOF(ucd_record, scriptx_bidiclass));\n    OP2(SLJIT_AND, TMP1, 0, TMP1, 0, SLJIT_IMM, UCD_SCRIPTX_MASK);\n    OP2(SLJIT_SHL, TMP1, 0, TMP1, 0, SLJIT_IMM, 2);\n\n    if (unicode_status & XCLASS_SCRIPT_EXTENSION_NOTPROP)\n      {\n      if (unicode_status & XCLASS_HAS_TYPE)\n        {\n        if (unicode_status & XCLASS_SAVE_CHAR)\n          {\n          OP1(SLJIT_MOV, SLJIT_MEM1(SLJIT_SP), LOCALS0, TMP2, 0);\n          unicode_status |= XCLASS_SCRIPT_EXTENSION_RESTORE_LOCALS0;\n          }\n        else\n          {\n          OP1(SLJIT_MOV, RETURN_ADDR, 0, TMP2, 0);\n          unicode_status |= XCLASS_SCRIPT_EXTENSION_RESTORE_RETURN_ADDR;\n          }\n        }\n      OP1(SLJIT_MOV_U8, TMP2, 0, SLJIT_MEM1(TMP2), (sljit_sw)PRIV(ucd_records) + SLJIT_OFFSETOF(ucd_record, script));\n      }\n\n    while (*cc != XCL_END)\n      {\n      if (*cc == XCL_SINGLE)\n        {\n        cc ++;\n        GETCHARINCTEST(c, cc);\n        }\n      else if (*cc == XCL_RANGE)\n        {\n        cc ++;\n        GETCHARINCTEST(c, cc);\n        GETCHARINCTEST(c, cc);\n        }\n      else\n        {\n        SLJIT_ASSERT(*cc == XCL_PROP || *cc == XCL_NOTPROP);\n        cc++;\n        if (*cc == PT_SCX)\n          {\n          compares--;\n          invertcmp = (compares == 0 && list != backtracks);\n\n          jump = NULL;\n          if (cc[-1] == XCL_NOTPROP)\n            {\n            jump = CMP(SLJIT_EQUAL, TMP2, 0, SLJIT_IMM, (int)cc[1]);\n            if (invertcmp)\n              {\n              add_jump(compiler, backtracks, jump);\n              jump = NULL;\n              }\n            invertcmp ^= 0x1;\n            }\n\n          OP2U(SLJIT_AND32 | SLJIT_SET_Z, SLJIT_MEM1(TMP1), (sljit_sw)(PRIV(ucd_script_sets) + (cc[1] >> 5)), SLJIT_IMM, (sljit_sw)1 << (cc[1] & 0x1f));\n          add_jump(compiler, compares > 0 ? list : backtracks, JUMP(SLJIT_NOT_ZERO ^ invertcmp));\n\n          if (jump != NULL)\n            JUMPHERE(jump);\n          }\n        cc += 2;\n        }\n      }\n\n    if (unicode_status & XCLASS_SCRIPT_EXTENSION_RESTORE_LOCALS0)\n      OP1(SLJIT_MOV, TMP2, 0, SLJIT_MEM1(SLJIT_SP), LOCALS0);\n    else if (unicode_status & XCLASS_SCRIPT_EXTENSION_RESTORE_RETURN_ADDR)\n      OP1(SLJIT_MOV, TMP2, 0, RETURN_ADDR, 0);\n    cc = ccbegin;\n    }\n\n  if (unicode_status & XCLASS_SAVE_CHAR)\n    OP1(SLJIT_MOV, TMP1, 0, RETURN_ADDR, 0);\n\n  if (unicode_status & XCLASS_HAS_TYPE)\n    {\n    if (unicode_status & XCLASS_SAVE_CHAR)\n      typereg = RETURN_ADDR;\n\n    OP1(SLJIT_MOV_U8, typereg, 0, SLJIT_MEM1(TMP2), (sljit_sw)PRIV(ucd_records) + SLJIT_OFFSETOF(ucd_record, chartype));\n    }\n  }\n#endif /* SUPPORT_UNICODE */\n\n/* Generating code. */\ncharoffset = 0;\nnumberofcmps = 0;\n#ifdef SUPPORT_UNICODE\ntypeoffset = 0;\n#endif /* SUPPORT_UNICODE */\n\nwhile (*cc != XCL_END)\n  {\n  compares--;\n  invertcmp = (compares == 0 && list != backtracks);\n  jump = NULL;\n\n  if (*cc == XCL_SINGLE)\n    {\n    cc ++;\n    GETCHARINCTEST(c, cc);\n\n    if (numberofcmps < 3 && (*cc == XCL_SINGLE || *cc == XCL_RANGE))\n      {\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP1, 0, SLJIT_IMM, (sljit_sw)(c - charoffset));\n      OP_FLAGS(numberofcmps == 0 ? SLJIT_MOV : SLJIT_OR, TMP2, 0, SLJIT_EQUAL);\n      numberofcmps++;\n      }\n    else if (numberofcmps > 0)\n      {\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP1, 0, SLJIT_IMM, (sljit_sw)(c - charoffset));\n      OP_FLAGS(SLJIT_OR | SLJIT_SET_Z, TMP2, 0, SLJIT_EQUAL);\n      jump = JUMP(SLJIT_NOT_ZERO ^ invertcmp);\n      numberofcmps = 0;\n      }\n    else\n      {\n      jump = CMP(SLJIT_EQUAL ^ invertcmp, TMP1, 0, SLJIT_IMM, (sljit_sw)(c - charoffset));\n      numberofcmps = 0;\n      }\n    }\n  else if (*cc == XCL_RANGE)\n    {\n    cc ++;\n    GETCHARINCTEST(c, cc);\n    SET_CHAR_OFFSET(c);\n    GETCHARINCTEST(c, cc);\n\n    if (numberofcmps < 3 && (*cc == XCL_SINGLE || *cc == XCL_RANGE))\n      {\n      OP2U(SLJIT_SUB | SLJIT_SET_LESS_EQUAL, TMP1, 0, SLJIT_IMM, (sljit_sw)(c - charoffset));\n      OP_FLAGS(numberofcmps == 0 ? SLJIT_MOV : SLJIT_OR, TMP2, 0, SLJIT_LESS_EQUAL);\n      numberofcmps++;\n      }\n    else if (numberofcmps > 0)\n      {\n      OP2U(SLJIT_SUB | SLJIT_SET_LESS_EQUAL, TMP1, 0, SLJIT_IMM, (sljit_sw)(c - charoffset));\n      OP_FLAGS(SLJIT_OR | SLJIT_SET_Z, TMP2, 0, SLJIT_LESS_EQUAL);\n      jump = JUMP(SLJIT_NOT_ZERO ^ invertcmp);\n      numberofcmps = 0;\n      }\n    else\n      {\n      jump = CMP(SLJIT_LESS_EQUAL ^ invertcmp, TMP1, 0, SLJIT_IMM, (sljit_sw)(c - charoffset));\n      numberofcmps = 0;\n      }\n    }\n#ifdef SUPPORT_UNICODE\n  else\n    {\n    SLJIT_ASSERT(*cc == XCL_PROP || *cc == XCL_NOTPROP);\n    if (*cc == XCL_NOTPROP)\n      invertcmp ^= 0x1;\n    cc++;\n    switch(*cc)\n      {\n      case PT_ANY:\n      if (!invertcmp)\n        jump = JUMP(SLJIT_JUMP);\n      break;\n\n      case PT_LAMP:\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, typereg, 0, SLJIT_IMM, ucp_Lu - typeoffset);\n      OP_FLAGS(SLJIT_MOV, TMP2, 0, SLJIT_EQUAL);\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, typereg, 0, SLJIT_IMM, ucp_Ll - typeoffset);\n      OP_FLAGS(SLJIT_OR, TMP2, 0, SLJIT_EQUAL);\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, typereg, 0, SLJIT_IMM, ucp_Lt - typeoffset);\n      OP_FLAGS(SLJIT_OR | SLJIT_SET_Z, TMP2, 0, SLJIT_EQUAL);\n      jump = JUMP(SLJIT_NOT_ZERO ^ invertcmp);\n      break;\n\n      case PT_GC:\n      c = PRIV(ucp_typerange)[(int)cc[1] * 2];\n      SET_TYPE_OFFSET(c);\n      jump = CMP(SLJIT_LESS_EQUAL ^ invertcmp, typereg, 0, SLJIT_IMM, PRIV(ucp_typerange)[(int)cc[1] * 2 + 1] - c);\n      break;\n\n      case PT_PC:\n      jump = CMP(SLJIT_EQUAL ^ invertcmp, typereg, 0, SLJIT_IMM, (int)cc[1] - typeoffset);\n      break;\n\n      case PT_SC:\n      case PT_SCX:\n      case PT_BOOL:\n      case PT_BIDICL:\n      compares++;\n      /* Do nothing. */\n      break;\n\n      case PT_SPACE:\n      case PT_PXSPACE:\n      SET_CHAR_OFFSET(9);\n      OP2U(SLJIT_SUB | SLJIT_SET_LESS_EQUAL, TMP1, 0, SLJIT_IMM, 0xd - 0x9);\n      OP_FLAGS(SLJIT_MOV, TMP2, 0, SLJIT_LESS_EQUAL);\n\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP1, 0, SLJIT_IMM, 0x85 - 0x9);\n      OP_FLAGS(SLJIT_OR, TMP2, 0, SLJIT_EQUAL);\n\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP1, 0, SLJIT_IMM, 0x180e - 0x9);\n      OP_FLAGS(SLJIT_OR, TMP2, 0, SLJIT_EQUAL);\n\n      SET_TYPE_OFFSET(ucp_Zl);\n      OP2U(SLJIT_SUB | SLJIT_SET_LESS_EQUAL, typereg, 0, SLJIT_IMM, ucp_Zs - ucp_Zl);\n      OP_FLAGS(SLJIT_OR | SLJIT_SET_Z, TMP2, 0, SLJIT_LESS_EQUAL);\n      jump = JUMP(SLJIT_NOT_ZERO ^ invertcmp);\n      break;\n\n      case PT_WORD:\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP1, 0, SLJIT_IMM, (sljit_sw)(CHAR_UNDERSCORE - charoffset));\n      OP_FLAGS(SLJIT_MOV, TMP2, 0, SLJIT_EQUAL);\n      /* Fall through. */\n\n      case PT_ALNUM:\n      SET_TYPE_OFFSET(ucp_Ll);\n      OP2U(SLJIT_SUB | SLJIT_SET_LESS_EQUAL, typereg, 0, SLJIT_IMM, ucp_Lu - ucp_Ll);\n      OP_FLAGS((*cc == PT_ALNUM) ? SLJIT_MOV : SLJIT_OR, TMP2, 0, SLJIT_LESS_EQUAL);\n      SET_TYPE_OFFSET(ucp_Nd);\n      OP2U(SLJIT_SUB | SLJIT_SET_LESS_EQUAL, typereg, 0, SLJIT_IMM, ucp_No - ucp_Nd);\n      OP_FLAGS(SLJIT_OR | SLJIT_SET_Z, TMP2, 0, SLJIT_LESS_EQUAL);\n      jump = JUMP(SLJIT_NOT_ZERO ^ invertcmp);\n      break;\n\n      case PT_CLIST:\n      other_cases = PRIV(ucd_caseless_sets) + cc[1];\n\n      /* At least three characters are required.\n         Otherwise this case would be handled by the normal code path. */\n      SLJIT_ASSERT(other_cases[0] != NOTACHAR && other_cases[1] != NOTACHAR && other_cases[2] != NOTACHAR);\n      SLJIT_ASSERT(other_cases[0] < other_cases[1] && other_cases[1] < other_cases[2]);\n\n      /* Optimizing character pairs, if their difference is power of 2. */\n      if (is_powerof2(other_cases[1] ^ other_cases[0]))\n        {\n        if (charoffset == 0)\n          OP2(SLJIT_OR, TMP2, 0, TMP1, 0, SLJIT_IMM, other_cases[1] ^ other_cases[0]);\n        else\n          {\n          OP2(SLJIT_ADD, TMP2, 0, TMP1, 0, SLJIT_IMM, (sljit_sw)charoffset);\n          OP2(SLJIT_OR, TMP2, 0, TMP2, 0, SLJIT_IMM, other_cases[1] ^ other_cases[0]);\n          }\n        OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP2, 0, SLJIT_IMM, other_cases[1]);\n        OP_FLAGS(SLJIT_MOV, TMP2, 0, SLJIT_EQUAL);\n        other_cases += 2;\n        }\n      else if (is_powerof2(other_cases[2] ^ other_cases[1]))\n        {\n        if (charoffset == 0)\n          OP2(SLJIT_OR, TMP2, 0, TMP1, 0, SLJIT_IMM, other_cases[2] ^ other_cases[1]);\n        else\n          {\n          OP2(SLJIT_ADD, TMP2, 0, TMP1, 0, SLJIT_IMM, (sljit_sw)charoffset);\n          OP2(SLJIT_OR, TMP2, 0, TMP2, 0, SLJIT_IMM, other_cases[1] ^ other_cases[0]);\n          }\n        OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP2, 0, SLJIT_IMM, other_cases[2]);\n        OP_FLAGS(SLJIT_MOV, TMP2, 0, SLJIT_EQUAL);\n\n        OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP1, 0, SLJIT_IMM, (sljit_sw)(other_cases[0] - charoffset));\n        OP_FLAGS(SLJIT_OR | ((other_cases[3] == NOTACHAR) ? SLJIT_SET_Z : 0), TMP2, 0, SLJIT_EQUAL);\n\n        other_cases += 3;\n        }\n      else\n        {\n        OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP1, 0, SLJIT_IMM, (sljit_sw)(*other_cases++ - charoffset));\n        OP_FLAGS(SLJIT_MOV, TMP2, 0, SLJIT_EQUAL);\n        }\n\n      while (*other_cases != NOTACHAR)\n        {\n        OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP1, 0, SLJIT_IMM, (sljit_sw)(*other_cases++ - charoffset));\n        OP_FLAGS(SLJIT_OR | ((*other_cases == NOTACHAR) ? SLJIT_SET_Z : 0), TMP2, 0, SLJIT_EQUAL);\n        }\n      jump = JUMP(SLJIT_NOT_ZERO ^ invertcmp);\n      break;\n\n      case PT_UCNC:\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP1, 0, SLJIT_IMM, (sljit_sw)(CHAR_DOLLAR_SIGN - charoffset));\n      OP_FLAGS(SLJIT_MOV, TMP2, 0, SLJIT_EQUAL);\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP1, 0, SLJIT_IMM, (sljit_sw)(CHAR_COMMERCIAL_AT - charoffset));\n      OP_FLAGS(SLJIT_OR, TMP2, 0, SLJIT_EQUAL);\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP1, 0, SLJIT_IMM, (sljit_sw)(CHAR_GRAVE_ACCENT - charoffset));\n      OP_FLAGS(SLJIT_OR, TMP2, 0, SLJIT_EQUAL);\n\n      SET_CHAR_OFFSET(0xa0);\n      OP2U(SLJIT_SUB | SLJIT_SET_LESS_EQUAL, TMP1, 0, SLJIT_IMM, (sljit_sw)(0xd7ff - charoffset));\n      OP_FLAGS(SLJIT_OR, TMP2, 0, SLJIT_LESS_EQUAL);\n      SET_CHAR_OFFSET(0);\n      OP2U(SLJIT_SUB | SLJIT_SET_GREATER_EQUAL, TMP1, 0, SLJIT_IMM, 0xe000 - 0);\n      OP_FLAGS(SLJIT_OR | SLJIT_SET_Z, TMP2, 0, SLJIT_GREATER_EQUAL);\n      jump = JUMP(SLJIT_NOT_ZERO ^ invertcmp);\n      break;\n\n      case PT_PXGRAPH:\n      /* C and Z groups are the farthest two groups. */\n      SET_TYPE_OFFSET(ucp_Ll);\n      OP2U(SLJIT_SUB | SLJIT_SET_GREATER, typereg, 0, SLJIT_IMM, ucp_So - ucp_Ll);\n      OP_FLAGS(SLJIT_MOV, TMP2, 0, SLJIT_GREATER);\n\n      jump = CMP(SLJIT_NOT_EQUAL, typereg, 0, SLJIT_IMM, ucp_Cf - ucp_Ll);\n\n      /* In case of ucp_Cf, we overwrite the result. */\n      SET_CHAR_OFFSET(0x2066);\n      OP2U(SLJIT_SUB | SLJIT_SET_LESS_EQUAL, TMP1, 0, SLJIT_IMM, 0x2069 - 0x2066);\n      OP_FLAGS(SLJIT_MOV, TMP2, 0, SLJIT_LESS_EQUAL);\n\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP1, 0, SLJIT_IMM, 0x061c - 0x2066);\n      OP_FLAGS(SLJIT_OR, TMP2, 0, SLJIT_EQUAL);\n\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP1, 0, SLJIT_IMM, 0x180e - 0x2066);\n      OP_FLAGS(SLJIT_OR, TMP2, 0, SLJIT_EQUAL);\n\n      JUMPHERE(jump);\n      jump = CMP(SLJIT_ZERO ^ invertcmp, TMP2, 0, SLJIT_IMM, 0);\n      break;\n\n      case PT_PXPRINT:\n      /* C and Z groups are the farthest two groups. */\n      SET_TYPE_OFFSET(ucp_Ll);\n      OP2U(SLJIT_SUB | SLJIT_SET_GREATER, typereg, 0, SLJIT_IMM, ucp_So - ucp_Ll);\n      OP_FLAGS(SLJIT_MOV, TMP2, 0, SLJIT_GREATER);\n\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, typereg, 0, SLJIT_IMM, ucp_Zs - ucp_Ll);\n      OP_FLAGS(SLJIT_AND, TMP2, 0, SLJIT_NOT_EQUAL);\n\n      jump = CMP(SLJIT_NOT_EQUAL, typereg, 0, SLJIT_IMM, ucp_Cf - ucp_Ll);\n\n      /* In case of ucp_Cf, we overwrite the result. */\n      SET_CHAR_OFFSET(0x2066);\n      OP2U(SLJIT_SUB | SLJIT_SET_LESS_EQUAL, TMP1, 0, SLJIT_IMM, 0x2069 - 0x2066);\n      OP_FLAGS(SLJIT_MOV, TMP2, 0, SLJIT_LESS_EQUAL);\n\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP1, 0, SLJIT_IMM, 0x061c - 0x2066);\n      OP_FLAGS(SLJIT_OR, TMP2, 0, SLJIT_EQUAL);\n\n      JUMPHERE(jump);\n      jump = CMP(SLJIT_ZERO ^ invertcmp, TMP2, 0, SLJIT_IMM, 0);\n      break;\n\n      case PT_PXPUNCT:\n      SET_TYPE_OFFSET(ucp_Sc);\n      OP2U(SLJIT_SUB | SLJIT_SET_LESS_EQUAL, typereg, 0, SLJIT_IMM, ucp_So - ucp_Sc);\n      OP_FLAGS(SLJIT_MOV, TMP2, 0, SLJIT_LESS_EQUAL);\n\n      SET_CHAR_OFFSET(0);\n      OP2U(SLJIT_SUB | SLJIT_SET_LESS_EQUAL, TMP1, 0, SLJIT_IMM, 0x7f);\n      OP_FLAGS(SLJIT_AND, TMP2, 0, SLJIT_LESS_EQUAL);\n\n      SET_TYPE_OFFSET(ucp_Pc);\n      OP2U(SLJIT_SUB | SLJIT_SET_LESS_EQUAL, typereg, 0, SLJIT_IMM, ucp_Ps - ucp_Pc);\n      OP_FLAGS(SLJIT_OR | SLJIT_SET_Z, TMP2, 0, SLJIT_LESS_EQUAL);\n      jump = JUMP(SLJIT_NOT_ZERO ^ invertcmp);\n      break;\n\n      default:\n      SLJIT_UNREACHABLE();\n      break;\n      }\n    cc += 2;\n    }\n#endif /* SUPPORT_UNICODE */\n\n  if (jump != NULL)\n    add_jump(compiler, compares > 0 ? list : backtracks, jump);\n  }\n\nif (found != NULL)\n  set_jumps(found, LABEL());\n}",
        "func_hash": 183419698766008283102134937176756315954,
        "file_name": "pcre2_jit_compile.c",
        "file_hash": 284265016287060690142505784626516203619,
        "cwe": [
            "CWE-125"
        ],
        "cve": "CVE-2022-1586",
        "cve_desc": "An out-of-bounds read vulnerability was discovered in the PCRE2 library in the compile_xclass_matchingpath() function of the pcre2_jit_compile.c file. This involves a unicode property matching issue in JIT-compiled regular expressions. The issue occurs because the character was not fully read in case-less matching within JIT.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-1586",
        "func_name": "compile_xclass_matchingpath",
        "diff": [
            "diff --git a/src/pcre2_jit_compile.c b/src/pcre2_jit_compile.c\nindex 94f6a5887..7fcdac863 100644\n--- a/src/pcre2_jit_compile.c\n+++ b/src/pcre2_jit_compile.c\n@@ -7489,7 +7489,7 @@ while (*cc != XCL_END)\n     {\n     SLJIT_ASSERT(*cc == XCL_PROP || *cc == XCL_NOTPROP);\n     cc++;\n-    if (*cc == PT_CLIST && *cc == XCL_PROP)\n+    if (*cc == PT_CLIST && cc[-1] == XCL_PROP)\n       {\n       other_cases = PRIV(ucd_caseless_sets) + cc[1];\n       while (*other_cases != NOTACHAR)\n"
        ],
        "func_after": []
    },
    {
        "idx": 195274,
        "project": "tensorflow",
        "commit_id": "0a365c029e437be0349c31f8d4c9926b69fa3fa1",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/0a365c029e437be0349c31f8d4c9926b69fa3fa1",
        "commit_message": "Prevent null pointer dereference in constant folding.\n\nUnder certain conditions, an invalid protobuf saved model with invalid nodes would be loaded. During optimization phase, Grappler optimizer will then dereference a null pointer.\n\nPiperOrigin-RevId: 409683530\nChange-Id: I1f10340a7ec384bc9bc587300390f1078cf5caa0",
        "target": 1,
        "irrelevant": 1,
        "func_before": "bool ConstantFolding::MulConvPushDown(GraphDef* optimized_graph, NodeDef* node,\n                                      const GraphProperties& properties) {\n  // Push down multiplication on ConvND.\n  //                       *                  ConvND\n  //                     /   \\                /    \\\n  //                 ConvND  C2    -- >      X      *\n  //                  / \\                          / \\\n  //                 X  C1                       C1  C2\n  //\n  // where C1 and C2 are constants and X is non-constant.\n  //\n  // TODO(rmlarsen): Use PrepareConstantPushDown() to simplify this code.\n\n  if (!IsAnyMul(*node) || NumNonControlInputs(*node) != 2) return false;\n\n  NodeDef* mul_left_child = node_map_->GetNode(node->input(0));\n  NodeDef* mul_right_child = node_map_->GetNode(node->input(1));\n  // One child must be constant, and the second must be Conv op.\n  const bool left_child_is_constant = IsReallyConstant(*mul_left_child);\n  const bool right_child_is_constant = IsReallyConstant(*mul_right_child);\n  if (!left_child_is_constant && !right_child_is_constant) {\n    return false;\n  }\n  NodeDef* conv_node =\n      left_child_is_constant ? mul_right_child : mul_left_child;\n  if (!IsConv2D(*conv_node) && !IsConv3D(*conv_node)) {\n    return false;\n  }\n  if (node->device() != mul_left_child->device() ||\n      node->device() != mul_right_child->device()) {\n    return false;\n  }\n\n  // Make sure that it is safe to change the value of the convolution\n  // output.\n  if (conv_node->input_size() < 2 ||\n      NumNonControlOutputs(*conv_node, *node_map_) > 1 ||\n      nodes_to_preserve_.find(conv_node->name()) != nodes_to_preserve_.end()) {\n    return false;\n  }\n\n  // Identify the nodes to swap.\n  NodeDef* conv_left_child = node_map_->GetNode(conv_node->input(0));\n  NodeDef* conv_right_child = node_map_->GetNode(conv_node->input(1));\n  const bool conv_left_is_constant = IsReallyConstant(*conv_left_child);\n  const bool conv_right_is_constant = IsReallyConstant(*conv_right_child);\n  if (!conv_left_is_constant && !conv_right_is_constant) {\n    // At least one of the convolution inputs should be constant.\n    return false;\n  }\n  if (conv_left_is_constant && conv_right_is_constant) {\n    // Leverage regular constant folding to handle this.\n    return false;\n  }\n  const auto& mul_props = properties.GetOutputProperties(node->name());\n  const auto& conv_props = properties.GetOutputProperties(conv_node->name());\n  if (mul_props.empty() || conv_props.empty()) {\n    return false;\n  }\n  const auto& mul_shape = mul_props[0].shape();\n  const auto& conv_shape = conv_props[0].shape();\n  if (!ShapesSymbolicallyEqual(mul_shape, conv_shape)) {\n    return false;\n  }\n\n  const auto& input_props = properties.GetInputProperties(conv_node->name());\n  if (input_props.size() < 2) {\n    return false;\n  }\n  const auto& filter_shape = input_props[1].shape();\n\n  NodeDef* const_node =\n      left_child_is_constant ? mul_left_child : mul_right_child;\n  const auto& const_props = properties.GetOutputProperties(const_node->name());\n  if (const_props.empty()) {\n    return false;\n  }\n  const auto& const_shape = const_props[0].shape();\n  if (!IsValidConstShapeForMulConvPushDown(\n          conv_node->attr().at(\"data_format\").s(), filter_shape, const_shape)) {\n    return false;\n  }\n\n  string mul_new_name = AddPrefixToNodeName(\"merged_input\", conv_node->name());\n  if (node_map_->NodeExists(mul_new_name)) {\n    return false;\n  }\n  // Make sure we don't introduce loops in the graph by removing control\n  // dependencies from the conv2d node to c2.\n  string conv_const_input =\n      conv_left_is_constant ? conv_node->input(0) : conv_node->input(1);\n  if (MaybeRemoveControlInput(conv_node->name(), const_node, optimized_graph,\n                              node_map_.get())) {\n    // Add a control dep from c1 to c2 to ensure c2 is in the right frame\n    MaybeAddControlInput(conv_const_input, const_node, optimized_graph,\n                         node_map_.get());\n  }\n\n  conv_node->set_name(node->name());\n  node->set_name(mul_new_name);\n  if (conv_left_is_constant) {\n    node_map_->UpdateInput(conv_node->name(), node->input(0), mul_new_name);\n    conv_node->set_input(0, mul_new_name);\n  } else {\n    node_map_->UpdateInput(conv_node->name(), node->input(1), mul_new_name);\n    conv_node->set_input(1, mul_new_name);\n  }\n  NodeDef* conv_const_node =\n      conv_left_is_constant ? conv_left_child : conv_right_child;\n  if (left_child_is_constant) {\n    node->set_input(1, conv_const_node->name());\n  } else {\n    node->set_input(0, conv_const_node->name());\n  }\n  node_map_->AddNode(mul_new_name, node);\n\n  return true;\n}",
        "func_hash": 134451371039665673916173676790439576039,
        "file_name": "constant_folding.cc",
        "file_hash": 221573695858123615640237954647315751120,
        "cwe": [
            "CWE-476"
        ],
        "cve": "CVE-2022-23589",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. Under certain scenarios, Grappler component of TensorFlow can trigger a null pointer dereference. There are 2 places where this can occur, for the same malicious alteration of a `SavedModel` file (fixing the first one would trigger the same dereference in the second place). First, during constant folding, the `GraphDef` might not have the required nodes for the binary operation. If a node is missing, the correposning `mul_*child` would be null, and the dereference in the subsequent line would be incorrect. We have a similar issue during `IsIdentityConsumingSwitch`. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23589",
        "func_name": "ConstantFolding::MulConvPushDown",
        "diff": [
            "diff --git a/tensorflow/core/grappler/optimizers/constant_folding.cc b/tensorflow/core/grappler/optimizers/constant_folding.cc\nindex 281806be20259f..a05823f71d09f4 100644\n--- a/tensorflow/core/grappler/optimizers/constant_folding.cc\n+++ b/tensorflow/core/grappler/optimizers/constant_folding.cc\n@@ -3505,6 +3505,9 @@ bool ConstantFolding::MulConvPushDown(GraphDef* optimized_graph, NodeDef* node,\n \n   NodeDef* mul_left_child = node_map_->GetNode(node->input(0));\n   NodeDef* mul_right_child = node_map_->GetNode(node->input(1));\n+  if (mul_left_child == nullptr || mul_right_child == nullptr) {\n+    return false;\n+  }\n   // One child must be constant, and the second must be Conv op.\n   const bool left_child_is_constant = IsReallyConstant(*mul_left_child);\n   const bool right_child_is_constant = IsReallyConstant(*mul_right_child);\n"
        ],
        "func_after": []
    },
    {
        "idx": 195289,
        "project": "tensorflow",
        "commit_id": "adbbabdb0d3abb3cdeac69e38a96de1d678b24b3",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/adbbabdb0d3abb3cdeac69e38a96de1d678b24b3",
        "commit_message": "Further validate sparse tensor for `SparseCount`: indices must be valid within dense shape.\n\nPiperOrigin-RevId: 414888122\nChange-Id: I4552bd74c135ecd4bcb5448acc0a3ce9402d8286",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext* context) override {\n    const Tensor& indices = context->input(0);\n    const Tensor& values = context->input(1);\n    const Tensor& shape = context->input(2);\n    const Tensor& weights = context->input(3);\n    bool use_weights = weights.NumElements() > 0;\n\n    OP_REQUIRES(context, TensorShapeUtils::IsMatrix(indices.shape()),\n                errors::InvalidArgument(\n                    \"Input indices must be a 2-dimensional tensor. Got: \",\n                    indices.shape().DebugString()));\n    OP_REQUIRES(context, TensorShapeUtils::IsVector(values.shape()),\n                errors::InvalidArgument(\"Input values must be a vector. Got: \",\n                                        values.shape().DebugString()));\n    OP_REQUIRES(context, TensorShapeUtils::IsVector(shape.shape()),\n                errors::InvalidArgument(\"Input shape must be a vector. Got: \",\n                                        shape.shape().DebugString()));\n    OP_REQUIRES(context,\n                values.shape().dim_size(0) == indices.shape().dim_size(0),\n                errors::InvalidArgument(\n                    \"Number of values must match first dimension of indices.\",\n                    \"Got \", values.shape().dim_size(0),\n                    \" values, indices shape: \", indices.shape().DebugString()));\n    OP_REQUIRES(\n        context, shape.shape().dim_size(0) == indices.shape().dim_size(1),\n        errors::InvalidArgument(\n            \"Number of dimensions must match second dimension of indices.\",\n            \"Got \", shape.shape().dim_size(0),\n            \" dimensions, indices shape: \", indices.shape().DebugString()));\n    OP_REQUIRES(context, shape.NumElements() > 0,\n                errors::InvalidArgument(\n                    \"The shape argument requires at least one element.\"));\n\n    if (use_weights) {\n      OP_REQUIRES(\n          context, weights.shape() == values.shape(),\n          errors::InvalidArgument(\n              \"Weights and values must have the same shape. Weight shape: \",\n              weights.shape().DebugString(),\n              \"; values shape: \", values.shape().DebugString()));\n    }\n\n    bool is_1d = shape.NumElements() == 1;\n    auto shape_vector = shape.flat<int64_t>();\n    int num_batches = is_1d ? 1 : shape_vector(0);\n    int num_values = values.NumElements();\n\n    const auto indices_values = indices.matrix<int64_t>();\n    const auto values_values = values.flat<T>();\n    const auto weight_values = weights.flat<W>();\n\n    auto per_batch_counts = BatchedMap<W>(num_batches);\n\n    T max_value = 0;\n\n    for (int idx = 0; idx < num_values; ++idx) {\n      int batch = is_1d ? 0 : indices_values(idx, 0);\n      if (batch >= num_batches) {\n        OP_REQUIRES(context, batch < num_batches,\n                    errors::InvalidArgument(\n                        \"Indices value along the first dimension must be \",\n                        \"lower than the first index of the shape.\", \"Got \",\n                        batch, \" as batch and \", num_batches,\n                        \" as the first dimension of the shape.\"));\n      }\n      const auto& value = values_values(idx);\n      if (value >= 0 && (maxlength_ <= 0 || value < maxlength_)) {\n        if (binary_output_) {\n          per_batch_counts[batch][value] = 1;\n        } else if (use_weights) {\n          per_batch_counts[batch][value] += weight_values(idx);\n        } else {\n          per_batch_counts[batch][value]++;\n        }\n        if (value > max_value) {\n          max_value = value;\n        }\n      }\n    }\n\n    int num_output_values = GetOutputSize(max_value, maxlength_, minlength_);\n    OP_REQUIRES_OK(context, OutputSparse<W>(per_batch_counts, num_output_values,\n                                            is_1d, context));\n  }",
        "func_hash": 100138829425874082218930421940516836043,
        "file_name": "count_ops.cc",
        "file_hash": 221778566959720819887290009238961995785,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2022-21740",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The implementation of `SparseCountSparseOutput` is vulnerable to a heap overflow. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-21740",
        "func_name": "Compute",
        "diff": [
            "diff --git a/tensorflow/core/kernels/count_ops.cc b/tensorflow/core/kernels/count_ops.cc\nindex 1f99e0783e26f6..cc101b66f81403 100644\n--- a/tensorflow/core/kernels/count_ops.cc\n+++ b/tensorflow/core/kernels/count_ops.cc\n@@ -206,6 +206,23 @@ class SparseCount : public OpKernel {\n     OP_REQUIRES(context, shape.NumElements() > 0,\n                 errors::InvalidArgument(\n                     \"The shape argument requires at least one element.\"));\n+    // Validate indices: each index must be valid for the corresponding\n+    // dimension. This could be possibly done better.\n+    const auto indices_values = indices.matrix<int64_t>();\n+    const auto shape_vector = shape.vec<int64_t>();\n+    int num_values = values.NumElements();  // same as first dim of indices\n+    int rank = indices.shape().dim_size(1);\n+    for (int i = 0; i < num_values; ++i) {\n+      for (int j = 0; j < rank; ++j) {\n+        OP_REQUIRES(\n+            context,\n+            indices_values(i, j) >= 0 && indices_values(i, j) < shape_vector(j),\n+            errors::InvalidArgument(\n+                \"Invalid index value at \", i, \": dimension \", j, \" has value \",\n+                indices_values(i, j), \" which is not in [0, \", shape_vector(j),\n+                \") (as given by dense shape \", shape.DebugString()));\n+      }\n+    }\n \n     if (use_weights) {\n       OP_REQUIRES(\n@@ -217,11 +234,8 @@ class SparseCount : public OpKernel {\n     }\n \n     bool is_1d = shape.NumElements() == 1;\n-    auto shape_vector = shape.flat<int64_t>();\n     int num_batches = is_1d ? 1 : shape_vector(0);\n-    int num_values = values.NumElements();\n \n-    const auto indices_values = indices.matrix<int64_t>();\n     const auto values_values = values.flat<T>();\n     const auto weight_values = weights.flat<W>();\n \n"
        ],
        "func_after": []
    },
    {
        "idx": 195291,
        "project": "tensorflow",
        "commit_id": "ef1d027be116f25e25bb94a60da491c2cf55bd0b",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/ef1d027be116f25e25bb94a60da491c2cf55bd0b",
        "commit_message": "Prevent copying uninitialized data in `AssignOp`.\n\nThis prevents harder to debug undefined behaviors that cannot be traced back to the original tensor after assignments occur earlier in the graph execution. Several of these undefined behaviors are just reference bindings to null pointers, which are caught when running under ubsan/asan.\n\nPiperOrigin-RevId: 408654780\nChange-Id: Iad2ec40d43f5fd7ea016c20283356c12d5ddeab1",
        "target": 1,
        "irrelevant": 1,
        "func_before": "  void Compute(OpKernelContext* context) override {\n    const Tensor& rhs = context->input(1);\n\n    // We always return the input ref.\n    context->forward_ref_input_to_ref_output(0, 0);\n\n    // We can't always know how this value will be used downstream, so make\n    // conservative assumptions in specifying constraints on the memory\n    // allocation attributes, unless the Grappler graph analysis determined that\n    // it was safe not to.\n    AllocatorAttributes attr;\n    if (!relax_constraints_) {\n      attr.set_gpu_compatible(true);\n      attr.set_nic_compatible(true);\n    }\n\n    {\n      mutex_lock l(*context->input_ref_mutex(0));\n      const Tensor& old_lhs = context->mutable_input(0, /* lock_held */ true);\n      const bool same_shape = old_lhs.shape().IsSameSize(rhs.shape());\n      if (validate_shape_) {\n        OP_REQUIRES(context, same_shape,\n                    errors::InvalidArgument(\n                        \"Assign requires shapes of both tensors to match. \"\n                        \"lhs shape= \",\n                        old_lhs.shape().DebugString(),\n                        \" rhs shape= \", rhs.shape().DebugString()));\n      }\n\n      // In the code below we try to minimize the amount of memory allocation\n      // and copying by trying the following two shortcuts:\n      // 1. If the lhs is initialized and has the same number of elements as\n      //    the rhs we can avoid a memory allocation.\n      // 2. If we can reuse the rhs buffer we avoid both a memory allocation\n      //    and copying.\n\n      // 1. Try to copy into an existing buffer.\n      if (old_lhs.IsInitialized() &&\n          old_lhs.shape().num_elements() == rhs.shape().num_elements()) {\n        // The existing lhs tensor has already been initialized and the right\n        // hand side can fit in the underlying buffer.\n        Tensor reshaped_old_lhs;\n        if (same_shape) {\n          reshaped_old_lhs = old_lhs;\n        } else {\n          CHECK(reshaped_old_lhs.CopyFrom(old_lhs, rhs.shape()));\n          context->replace_ref_input(0, reshaped_old_lhs,\n                                     /* lock_held */ true);\n        }\n        if (use_exclusive_lock_) {\n          Copy(context, &reshaped_old_lhs, rhs);\n          return;\n        }\n      } else {\n        // 2. Try to reuse the rhs.\n        std::unique_ptr<Tensor> input_alias = context->forward_input(\n            1, OpKernelContext::Params::kNoReservation /*output_index*/,\n            rhs.dtype(), rhs.shape(), DEVICE_MEMORY, attr);\n        if (input_alias != nullptr) {\n          // Update the ref to point to the new buffer.\n          context->replace_ref_input(0, *input_alias, /* lock_held */ true);\n          return;\n        }\n\n        // Otherwise, create a new tensor whose shape matches the\n        // right hand side, hand off to lhs and copy the rhs into it.\n        Tensor copy_tensor;\n        OP_REQUIRES_OK(context,\n                       context->allocate_temp(old_lhs.dtype(), rhs.shape(),\n                                              &copy_tensor, attr));\n        // We track memory of variables in variable ops instead of in this\n        // assign op.\n        context->clear_recorded_memory();\n        context->replace_ref_input(0, copy_tensor, /* lock_held */ true);\n        if (use_exclusive_lock_) {\n          Copy(context, &copy_tensor, rhs);\n          return;\n        }\n      }\n    }\n\n    // The tensor has already been initialized and the right hand side\n    // matches the left hand side's shape. We have been told to do the\n    // copy outside the lock.\n    Tensor old_unlocked_lhs = context->mutable_input(0, /* lock_held */ false);\n    Copy(context, &old_unlocked_lhs, rhs);\n  }",
        "func_hash": 110563830933859876998490806365273446744,
        "file_name": "assign_op.h",
        "file_hash": 69919930869774703131816695670485389180,
        "cwe": [
            "CWE-908"
        ],
        "cve": "CVE-2022-23573",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The implementation of `AssignOp` can result in copying uninitialized data to a new tensor. This later results in undefined behavior. The implementation has a check that the left hand side of the assignment is initialized (to minimize number of allocations), but does not check that the right hand side is also initialized. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23573",
        "func_name": "Compute",
        "diff": [
            "diff --git a/tensorflow/core/kernels/assign_op.h b/tensorflow/core/kernels/assign_op.h\nindex ca822a58cdacc4..1e84436b27e0d8 100644\n--- a/tensorflow/core/kernels/assign_op.h\n+++ b/tensorflow/core/kernels/assign_op.h\n@@ -50,6 +50,12 @@ class AssignOp : public OpKernel {\n     // We always return the input ref.\n     context->forward_ref_input_to_ref_output(0, 0);\n \n+    // Prevent copying uninitialized data, to solve harder to debug undefined\n+    // behaviors that cannot be traced back to the original tensor.\n+    OP_REQUIRES(\n+        context, rhs.IsInitialized(),\n+        errors::Internal(\"Right hand side of AssignOp is not initialized\"));\n+\n     // We can't always know how this value will be used downstream, so make\n     // conservative assumptions in specifying constraints on the memory\n     // allocation attributes, unless the Grappler graph analysis determined that\n"
        ],
        "func_after": []
    },
    {
        "idx": 195293,
        "project": "mruby",
        "commit_id": "ae3c99767a27f5c6c584162e2adc6a5d0eb2c54e",
        "project_url": "https://github.com/mruby/mruby",
        "commit_url": "https://github.com/mruby/mruby/commit/ae3c99767a27f5c6c584162e2adc6a5d0eb2c54e",
        "commit_message": "codegen.c: fixed a bug in hash code generation with `!val`.",
        "target": 1,
        "irrelevant": 1,
        "func_before": "gen_hash(codegen_scope *s, node *tree, int val, int limit)\n{\n  int slimit = GEN_VAL_STACK_MAX;\n  if (cursp() >= GEN_LIT_ARY_MAX) slimit = INT16_MAX;\n  int len = 0;\n  mrb_bool update = FALSE;\n\n  while (tree) {\n    if (nint(tree->car->car->car) == NODE_KW_REST_ARGS) {\n      if (len > 0) {\n        pop_n(len*2);\n        if (!update) {\n          genop_2(s, OP_HASH, cursp(), len);\n        }\n        else {\n          pop();\n          genop_2(s, OP_HASHADD, cursp(), len);\n        }\n        push();\n      }\n      codegen(s, tree->car->cdr, val);\n      if (len > 0 || update) {\n        pop(); pop();\n        genop_1(s, OP_HASHCAT, cursp());\n        push();\n      }\n      update = TRUE;\n      len = 0;\n    }\n    else {\n      codegen(s, tree->car->car, val);\n      codegen(s, tree->car->cdr, val);\n      len++;\n    }\n    tree = tree->cdr;\n    if (val && cursp() >= slimit) {\n      pop_n(len*2);\n      if (!update) {\n        genop_2(s, OP_HASH, cursp(), len);\n      }\n      else {\n        pop();\n        genop_2(s, OP_HASHADD, cursp(), len);\n      }\n      push();\n      update = TRUE;\n      len = 0;\n    }\n  }\n  if (update) {\n    if (val && len > 0) {\n      pop_n(len*2+1);\n      genop_2(s, OP_HASHADD, cursp(), len);\n      push();\n    }\n    return -1;                  /* variable length */\n  }\n  return len;\n}",
        "func_hash": 193019522040384116683756187518117428466,
        "file_name": "codegen.c",
        "file_hash": 187346573288549092337421927147361320618,
        "cwe": [
            "CWE-476"
        ],
        "cve": "CVE-2022-0481",
        "cve_desc": "NULL Pointer Dereference in Homebrew mruby prior to 3.2.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-0481",
        "func_name": "gen_hash",
        "diff": [
            "diff --git a/mrbgems/mruby-compiler/core/codegen.c b/mrbgems/mruby-compiler/core/codegen.c\nindex 8c906fa21c..a7420a62ba 100644\n--- a/mrbgems/mruby-compiler/core/codegen.c\n+++ b/mrbgems/mruby-compiler/core/codegen.c\n@@ -1603,7 +1603,7 @@ gen_hash(codegen_scope *s, node *tree, int val, int limit)\n \n   while (tree) {\n     if (nint(tree->car->car->car) == NODE_KW_REST_ARGS) {\n-      if (len > 0) {\n+      if (val && len > 0) {\n         pop_n(len*2);\n         if (!update) {\n           genop_2(s, OP_HASH, cursp(), len);\n@@ -1615,7 +1615,7 @@ gen_hash(codegen_scope *s, node *tree, int val, int limit)\n         push();\n       }\n       codegen(s, tree->car->cdr, val);\n-      if (len > 0 || update) {\n+      if (val && (len > 0 || update)) {\n         pop(); pop();\n         genop_1(s, OP_HASHCAT, cursp());\n         push();\n"
        ],
        "func_after": []
    },
    {
        "idx": 195294,
        "project": "tensorflow",
        "commit_id": "f57315566d7094f322b784947093406c2aea0d7d",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/f57315566d7094f322b784947093406c2aea0d7d",
        "commit_message": "Add a check for Key being scalar tensor for MapStage and OrderedMapStage ops.\n\nAccording to documentation[1][2], key must be int64 value, but this wasn't enforced and the ops would fail with check failure for non-scalar key value.\n\n[1]https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/ordered-map-stage\n[2]https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/map-stage\n\nPiperOrigin-RevId: 413822112\nChange-Id: I9d118faf990e6361900aa32272eff486ad9f0e2e",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext* ctx) override {\n    StagingMap<Ordered>* map = nullptr;\n    OP_REQUIRES_OK(ctx, GetStagingMap(ctx, def(), &map));\n    core::ScopedUnref scope(map);\n    typename StagingMap<Ordered>::OptionalTuple tuple;\n\n    const Tensor* key_tensor;\n    const Tensor* indices_tensor;\n    OpInputList values_tensor;\n\n    OP_REQUIRES_OK(ctx, ctx->input(\"key\", &key_tensor));\n    OP_REQUIRES_OK(ctx, ctx->input(\"indices\", &indices_tensor));\n    OP_REQUIRES_OK(ctx, ctx->input_list(\"values\", &values_tensor));\n    OP_REQUIRES(ctx, key_tensor->NumElements() > 0,\n                errors::InvalidArgument(\"key must not be empty\"));\n\n    // Create copy for insertion into Staging Area\n    Tensor key(*key_tensor);\n\n    // Create the tuple to store\n    for (std::size_t i = 0; i < values_tensor.size(); ++i) {\n      tuple.push_back(values_tensor[i]);\n    }\n\n    // Store the tuple in the map\n    OP_REQUIRES_OK(ctx, map->put(&key, indices_tensor, &tuple));\n  }",
        "func_hash": 121343016950748954777477429164526353429,
        "file_name": "map_stage_op.cc",
        "file_hash": 156634864064326951745718193254274952325,
        "cwe": [
            "CWE-843"
        ],
        "cve": "CVE-2022-21734",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The implementation of `MapStage` is vulnerable a `CHECK`-fail if the key tensor is not a scalar. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-21734",
        "func_name": "Compute",
        "diff": [
            "diff --git a/tensorflow/core/kernels/map_stage_op.cc b/tensorflow/core/kernels/map_stage_op.cc\nindex aee53ae78d3af8..463e2a8ced5c2d 100644\n--- a/tensorflow/core/kernels/map_stage_op.cc\n+++ b/tensorflow/core/kernels/map_stage_op.cc\n@@ -536,6 +536,11 @@ class MapStageOp : public OpKernel {\n     OP_REQUIRES(ctx, key_tensor->NumElements() > 0,\n                 errors::InvalidArgument(\"key must not be empty\"));\n \n+    OP_REQUIRES(ctx, key_tensor->NumElements() == 1,\n+                errors::InvalidArgument(\n+                    \"key must be an int64 scalar, got tensor with shape: \",\n+                    key_tensor->shape()));\n+\n     // Create copy for insertion into Staging Area\n     Tensor key(*key_tensor);\n \ndiff --git a/tensorflow/python/kernel_tests/data_structures/map_stage_op_test.py b/tensorflow/python/kernel_tests/data_structures/map_stage_op_test.py\nindex 313b5244ee15c3..8600ad1f8d726b 100644\n--- a/tensorflow/python/kernel_tests/data_structures/map_stage_op_test.py\n+++ b/tensorflow/python/kernel_tests/data_structures/map_stage_op_test.py\n@@ -12,8 +12,11 @@\n # See the License for the specific language governing permissions and\n # limitations under the License.\n # ==============================================================================\n-from tensorflow.python.framework import errors\n+import numpy as np\n+\n+from tensorflow.python.framework import constant_op\n from tensorflow.python.framework import dtypes\n+from tensorflow.python.framework import errors\n from tensorflow.python.framework import ops\n from tensorflow.python.framework import test_util\n from tensorflow.python.ops import array_ops\n@@ -28,7 +31,7 @@ class MapStageTest(test.TestCase):\n \n   @test_util.run_deprecated_v1\n   def testSimple(self):\n-    with ops.Graph().as_default() as G:\n+    with ops.Graph().as_default() as g:\n       with ops.device('/cpu:0'):\n         x = array_ops.placeholder(dtypes.float32)\n         pi = array_ops.placeholder(dtypes.int64)\n@@ -40,9 +43,9 @@ def testSimple(self):\n         k, y = stager.get(gi)\n         y = math_ops.reduce_max(math_ops.matmul(y, y))\n \n-    G.finalize()\n+    g.finalize()\n \n-    with self.session(graph=G) as sess:\n+    with self.session(graph=g) as sess:\n       sess.run(stage, feed_dict={x: -1, pi: 0})\n       for i in range(10):\n         _, yval = sess.run([stage, y], feed_dict={x: i, pi: i + 1, gi: i})\n@@ -50,7 +53,7 @@ def testSimple(self):\n \n   @test_util.run_deprecated_v1\n   def testMultiple(self):\n-    with ops.Graph().as_default() as G:\n+    with ops.Graph().as_default() as g:\n       with ops.device('/cpu:0'):\n         x = array_ops.placeholder(dtypes.float32)\n         pi = array_ops.placeholder(dtypes.int64)\n@@ -62,9 +65,9 @@ def testMultiple(self):\n         k, (z, y) = stager.get(gi)\n         y = math_ops.reduce_max(z * math_ops.matmul(y, y))\n \n-    G.finalize()\n+    g.finalize()\n \n-    with self.session(graph=G) as sess:\n+    with self.session(graph=g) as sess:\n       sess.run(stage, feed_dict={x: -1, pi: 0})\n       for i in range(10):\n         _, yval = sess.run([stage, y], feed_dict={x: i, pi: i + 1, gi: i})\n@@ -73,26 +76,25 @@ def testMultiple(self):\n \n   @test_util.run_deprecated_v1\n   def testDictionary(self):\n-    with ops.Graph().as_default() as G:\n+    with ops.Graph().as_default() as g:\n       with ops.device('/cpu:0'):\n         x = array_ops.placeholder(dtypes.float32)\n         pi = array_ops.placeholder(dtypes.int64)\n         gi = array_ops.placeholder(dtypes.int64)\n         v = 2. * (array_ops.zeros([128, 128]) + x)\n       with ops.device(test.gpu_device_name()):\n-        stager = data_flow_ops.MapStagingArea(\n-            [dtypes.float32, dtypes.float32],\n-            shapes=[[], [128, 128]],\n-            names=['x', 'v'])\n+        stager = data_flow_ops.MapStagingArea([dtypes.float32, dtypes.float32],\n+                                              shapes=[[], [128, 128]],\n+                                              names=['x', 'v'])\n         stage = stager.put(pi, {'x': x, 'v': v})\n         key, ret = stager.get(gi)\n         z = ret['x']\n         y = ret['v']\n         y = math_ops.reduce_max(z * math_ops.matmul(y, y))\n \n-    G.finalize()\n+    g.finalize()\n \n-    with self.session(graph=G) as sess:\n+    with self.session(graph=g) as sess:\n       sess.run(stage, feed_dict={x: -1, pi: 0})\n       for i in range(10):\n         _, yval = sess.run([stage, y], feed_dict={x: i, pi: i + 1, gi: i})\n@@ -102,7 +104,7 @@ def testDictionary(self):\n   def testColocation(self):\n     gpu_dev = test.gpu_device_name()\n \n-    with ops.Graph().as_default() as G:\n+    with ops.Graph().as_default() as g:\n       with ops.device('/cpu:0'):\n         x = array_ops.placeholder(dtypes.float32)\n         v = 2. * (array_ops.zeros([128, 128]) + x)\n@@ -119,58 +121,56 @@ def testColocation(self):\n         self.assertEqual(y.device, '/device:CPU:0')\n         self.assertEqual(z[0].device, '/device:CPU:0')\n \n-    G.finalize()\n+    g.finalize()\n \n   @test_util.run_deprecated_v1\n   def testPeek(self):\n-    with ops.Graph().as_default() as G:\n+    with ops.Graph().as_default() as g:\n       with ops.device('/cpu:0'):\n         x = array_ops.placeholder(dtypes.int32, name='x')\n         pi = array_ops.placeholder(dtypes.int64)\n         gi = array_ops.placeholder(dtypes.int64)\n         p = array_ops.placeholder(dtypes.int32, name='p')\n       with ops.device(test.gpu_device_name()):\n-        stager = data_flow_ops.MapStagingArea(\n-            [\n-                dtypes.int32,\n-            ], shapes=[[]])\n+        stager = data_flow_ops.MapStagingArea([\n+            dtypes.int32,\n+        ], shapes=[[]])\n         stage = stager.put(pi, [x], [0])\n         peek = stager.peek(gi)\n         size = stager.size()\n \n-    G.finalize()\n+    g.finalize()\n \n     n = 10\n \n-    with self.session(graph=G) as sess:\n+    with self.session(graph=g) as sess:\n       for i in range(n):\n         sess.run(stage, feed_dict={x: i, pi: i})\n \n       for i in range(n):\n-        self.assertTrue(sess.run(peek, feed_dict={gi: i})[0] == i)\n+        self.assertEqual(sess.run(peek, feed_dict={gi: i})[0], i)\n \n-      self.assertTrue(sess.run(size) == 10)\n+      self.assertEqual(sess.run(size), 10)\n \n   @test_util.run_deprecated_v1\n   def testSizeAndClear(self):\n-    with ops.Graph().as_default() as G:\n+    with ops.Graph().as_default() as g:\n       with ops.device('/cpu:0'):\n         x = array_ops.placeholder(dtypes.float32, name='x')\n         pi = array_ops.placeholder(dtypes.int64)\n         gi = array_ops.placeholder(dtypes.int64)\n         v = 2. * (array_ops.zeros([128, 128]) + x)\n       with ops.device(test.gpu_device_name()):\n-        stager = data_flow_ops.MapStagingArea(\n-            [dtypes.float32, dtypes.float32],\n-            shapes=[[], [128, 128]],\n-            names=['x', 'v'])\n+        stager = data_flow_ops.MapStagingArea([dtypes.float32, dtypes.float32],\n+                                              shapes=[[], [128, 128]],\n+                                              names=['x', 'v'])\n         stage = stager.put(pi, {'x': x, 'v': v})\n         size = stager.size()\n         clear = stager.clear()\n \n-    G.finalize()\n+    g.finalize()\n \n-    with self.session(graph=G) as sess:\n+    with self.session(graph=g) as sess:\n       sess.run(stage, feed_dict={x: -1, pi: 3})\n       self.assertEqual(sess.run(size), 1)\n       sess.run(stage, feed_dict={x: -1, pi: 1})\n@@ -182,22 +182,23 @@ def testSizeAndClear(self):\n   def testCapacity(self):\n     capacity = 3\n \n-    with ops.Graph().as_default() as G:\n+    with ops.Graph().as_default() as g:\n       with ops.device('/cpu:0'):\n         x = array_ops.placeholder(dtypes.int32, name='x')\n         pi = array_ops.placeholder(dtypes.int64, name='pi')\n         gi = array_ops.placeholder(dtypes.int64, name='gi')\n       with ops.device(test.gpu_device_name()):\n-        stager = data_flow_ops.MapStagingArea(\n-            [\n-                dtypes.int32,\n-            ], capacity=capacity, shapes=[[]])\n+        stager = data_flow_ops.MapStagingArea([\n+            dtypes.int32,\n+        ],\n+                                              capacity=capacity,\n+                                              shapes=[[]])\n \n       stage = stager.put(pi, [x], [0])\n       get = stager.get()\n       size = stager.size()\n \n-    G.finalize()\n+    g.finalize()\n \n     from six.moves import queue as Queue\n     import threading\n@@ -205,7 +206,7 @@ def testCapacity(self):\n     queue = Queue.Queue()\n     n = 8\n \n-    with self.session(graph=G) as sess:\n+    with self.session(graph=g) as sess:\n       # Stage data in a separate thread which will block\n       # when it hits the staging area's capacity and thus\n       # not fill the queue with n tokens\n@@ -234,13 +235,13 @@ def thread_run():\n                                              capacity))\n \n       # Should have capacity elements in the staging area\n-      self.assertTrue(sess.run(size) == capacity)\n+      self.assertEqual(sess.run(size), capacity)\n \n       # Clear the staging area completely\n       for i in range(n):\n         sess.run(get)\n \n-      self.assertTrue(sess.run(size) == 0)\n+      self.assertEqual(sess.run(size), 0)\n \n   @test_util.run_deprecated_v1\n   def testMemoryLimit(self):\n@@ -248,28 +249,28 @@ def testMemoryLimit(self):\n     chunk = 200 * 1024  # 256K\n     capacity = memory_limit // chunk\n \n-    with ops.Graph().as_default() as G:\n+    with ops.Graph().as_default() as g:\n       with ops.device('/cpu:0'):\n         x = array_ops.placeholder(dtypes.uint8, name='x')\n         pi = array_ops.placeholder(dtypes.int64, name='pi')\n         gi = array_ops.placeholder(dtypes.int64, name='gi')\n       with ops.device(test.gpu_device_name()):\n-        stager = data_flow_ops.MapStagingArea(\n-            [dtypes.uint8], memory_limit=memory_limit, shapes=[[]])\n+        stager = data_flow_ops.MapStagingArea([dtypes.uint8],\n+                                              memory_limit=memory_limit,\n+                                              shapes=[[]])\n         stage = stager.put(pi, [x], [0])\n         get = stager.get()\n         size = stager.size()\n \n-    G.finalize()\n+    g.finalize()\n \n     from six.moves import queue as Queue\n     import threading\n-    import numpy as np\n \n     queue = Queue.Queue()\n     n = 8\n \n-    with self.session(graph=G) as sess:\n+    with self.session(graph=g) as sess:\n       # Stage data in a separate thread which will block\n       # when it hits the staging area's capacity and thus\n       # not fill the queue with n tokens\n@@ -299,56 +300,57 @@ def thread_run():\n                                              capacity))\n \n       # Should have capacity elements in the staging area\n-      self.assertTrue(sess.run(size) == capacity)\n+      self.assertEqual(sess.run(size), capacity)\n \n       # Clear the staging area completely\n       for i in range(n):\n         sess.run(get)\n \n-      self.assertTrue(sess.run(size) == 0)\n+      self.assertEqual(sess.run(size), 0)\n \n   @test_util.run_deprecated_v1\n   def testOrdering(self):\n     import six\n     import random\n \n-    with ops.Graph().as_default() as G:\n+    with ops.Graph().as_default() as g:\n       with ops.device('/cpu:0'):\n         x = array_ops.placeholder(dtypes.int32, name='x')\n         pi = array_ops.placeholder(dtypes.int64, name='pi')\n         gi = array_ops.placeholder(dtypes.int64, name='gi')\n       with ops.device(test.gpu_device_name()):\n-        stager = data_flow_ops.MapStagingArea(\n-            [\n-                dtypes.int32,\n-            ], shapes=[[]], ordered=True)\n+        stager = data_flow_ops.MapStagingArea([\n+            dtypes.int32,\n+        ],\n+                                              shapes=[[]],\n+                                              ordered=True)\n         stage = stager.put(pi, [x], [0])\n         get = stager.get()\n         size = stager.size()\n \n-    G.finalize()\n+    g.finalize()\n \n     n = 10\n \n-    with self.session(graph=G) as sess:\n+    with self.session(graph=g) as sess:\n       # Keys n-1..0\n       keys = list(reversed(six.moves.range(n)))\n \n       for i in keys:\n         sess.run(stage, feed_dict={pi: i, x: i})\n \n-      self.assertTrue(sess.run(size) == n)\n+      self.assertEqual(sess.run(size), n)\n \n       # Check that key, values come out in ascending order\n       for i, k in enumerate(reversed(keys)):\n         get_key, values = sess.run(get)\n         self.assertTrue(i == k == get_key == values)\n \n-      self.assertTrue(sess.run(size) == 0)\n+      self.assertEqual(sess.run(size), 0)\n \n   @test_util.run_deprecated_v1\n   def testPartialDictInsert(self):\n-    with ops.Graph().as_default() as G:\n+    with ops.Graph().as_default() as g:\n       with ops.device('/cpu:0'):\n         x = array_ops.placeholder(dtypes.float32)\n         f = array_ops.placeholder(dtypes.float32)\n@@ -366,41 +368,39 @@ def testPartialDictInsert(self):\n         size = stager.size()\n         isize = stager.incomplete_size()\n \n-    G.finalize()\n+    g.finalize()\n \n-    with self.session(graph=G) as sess:\n+    with self.session(graph=g) as sess:\n       # 0 complete and incomplete entries\n-      self.assertTrue(sess.run([size, isize]) == [0, 0])\n+      self.assertEqual(sess.run([size, isize]), [0, 0])\n       # Stage key 0, x and f tuple entries\n       sess.run(stage_xf, feed_dict={pi: 0, x: 1, f: 2})\n-      self.assertTrue(sess.run([size, isize]) == [0, 1])\n+      self.assertEqual(sess.run([size, isize]), [0, 1])\n       # Stage key 1, x and f tuple entries\n       sess.run(stage_xf, feed_dict={pi: 1, x: 1, f: 2})\n-      self.assertTrue(sess.run([size, isize]) == [0, 2])\n+      self.assertEqual(sess.run([size, isize]), [0, 2])\n \n       # Now complete key 0 with tuple entry v\n       sess.run(stage_v, feed_dict={pi: 0, v: 1})\n       # 1 complete and 1 incomplete entry\n-      self.assertTrue(sess.run([size, isize]) == [1, 1])\n+      self.assertEqual(sess.run([size, isize]), [1, 1])\n       # We can now obtain tuple associated with key 0\n-      self.assertTrue(\n-          sess.run([key, ret], feed_dict={\n-              gi: 0\n-          }) == [0, {\n+      self.assertEqual(\n+          sess.run([key, ret], feed_dict={gi: 0}),\n+          [0, {\n               'x': 1,\n               'f': 2,\n               'v': 1\n           }])\n \n       # 0 complete and 1 incomplete entry\n-      self.assertTrue(sess.run([size, isize]) == [0, 1])\n+      self.assertEqual(sess.run([size, isize]), [0, 1])\n       # Now complete key 1 with tuple entry v\n       sess.run(stage_v, feed_dict={pi: 1, v: 3})\n       # We can now obtain tuple associated with key 1\n-      self.assertTrue(\n-          sess.run([key, ret], feed_dict={\n-              gi: 1\n-          }) == [1, {\n+      self.assertEqual(\n+          sess.run([key, ret], feed_dict={gi: 1}),\n+          [1, {\n               'x': 1,\n               'f': 2,\n               'v': 3\n@@ -408,7 +408,7 @@ def testPartialDictInsert(self):\n \n   @test_util.run_deprecated_v1\n   def testPartialIndexInsert(self):\n-    with ops.Graph().as_default() as G:\n+    with ops.Graph().as_default() as g:\n       with ops.device('/cpu:0'):\n         x = array_ops.placeholder(dtypes.float32)\n         f = array_ops.placeholder(dtypes.float32)\n@@ -424,35 +424,35 @@ def testPartialIndexInsert(self):\n         size = stager.size()\n         isize = stager.incomplete_size()\n \n-    G.finalize()\n+    g.finalize()\n \n-    with self.session(graph=G) as sess:\n+    with self.session(graph=g) as sess:\n       # 0 complete and incomplete entries\n-      self.assertTrue(sess.run([size, isize]) == [0, 0])\n+      self.assertEqual(sess.run([size, isize]), [0, 0])\n       # Stage key 0, x and f tuple entries\n       sess.run(stage_xf, feed_dict={pi: 0, x: 1, f: 2})\n-      self.assertTrue(sess.run([size, isize]) == [0, 1])\n+      self.assertEqual(sess.run([size, isize]), [0, 1])\n       # Stage key 1, x and f tuple entries\n       sess.run(stage_xf, feed_dict={pi: 1, x: 1, f: 2})\n-      self.assertTrue(sess.run([size, isize]) == [0, 2])\n+      self.assertEqual(sess.run([size, isize]), [0, 2])\n \n       # Now complete key 0 with tuple entry v\n       sess.run(stage_v, feed_dict={pi: 0, v: 1})\n       # 1 complete and 1 incomplete entry\n-      self.assertTrue(sess.run([size, isize]) == [1, 1])\n+      self.assertEqual(sess.run([size, isize]), [1, 1])\n       # We can now obtain tuple associated with key 0\n-      self.assertTrue(sess.run([key, ret], feed_dict={gi: 0}) == [0, [1, 1, 2]])\n+      self.assertEqual(sess.run([key, ret], feed_dict={gi: 0}), [0, [1, 1, 2]])\n \n       # 0 complete and 1 incomplete entry\n-      self.assertTrue(sess.run([size, isize]) == [0, 1])\n+      self.assertEqual(sess.run([size, isize]), [0, 1])\n       # Now complete key 1 with tuple entry v\n       sess.run(stage_v, feed_dict={pi: 1, v: 3})\n       # We can now obtain tuple associated with key 1\n-      self.assertTrue(sess.run([key, ret], feed_dict={gi: 1}) == [1, [1, 3, 2]])\n+      self.assertEqual(sess.run([key, ret], feed_dict={gi: 1}), [1, [1, 3, 2]])\n \n   @test_util.run_deprecated_v1\n   def testPartialDictGetsAndPeeks(self):\n-    with ops.Graph().as_default() as G:\n+    with ops.Graph().as_default() as g:\n       with ops.device('/cpu:0'):\n         x = array_ops.placeholder(dtypes.float32)\n         f = array_ops.placeholder(dtypes.float32)\n@@ -476,40 +476,38 @@ def testPartialDictGetsAndPeeks(self):\n         size = stager.size()\n         isize = stager.incomplete_size()\n \n-    G.finalize()\n+    g.finalize()\n \n-    with self.session(graph=G) as sess:\n+    with self.session(graph=g) as sess:\n       # 0 complete and incomplete entries\n-      self.assertTrue(sess.run([size, isize]) == [0, 0])\n+      self.assertEqual(sess.run([size, isize]), [0, 0])\n       # Stage key 0, x and f tuple entries\n       sess.run(stage_xf, feed_dict={pi: 0, x: 1, f: 2})\n-      self.assertTrue(sess.run([size, isize]) == [0, 1])\n+      self.assertEqual(sess.run([size, isize]), [0, 1])\n       # Stage key 1, x and f tuple entries\n       sess.run(stage_xf, feed_dict={pi: 1, x: 1, f: 2})\n-      self.assertTrue(sess.run([size, isize]) == [0, 2])\n+      self.assertEqual(sess.run([size, isize]), [0, 2])\n \n       # Now complete key 0 with tuple entry v\n       sess.run(stage_v, feed_dict={pi: 0, v: 1})\n       # 1 complete and 1 incomplete entry\n-      self.assertTrue(sess.run([size, isize]) == [1, 1])\n+      self.assertEqual(sess.run([size, isize]), [1, 1])\n \n       # We can now peek at 'x' and 'f' values associated with key 0\n-      self.assertTrue(sess.run(peek_xf, feed_dict={pei: 0}) == {'x': 1, 'f': 2})\n+      self.assertEqual(sess.run(peek_xf, feed_dict={pei: 0}), {'x': 1, 'f': 2})\n       # Peek at 'v' value associated with key 0\n-      self.assertTrue(sess.run(peek_v, feed_dict={pei: 0}) == {'v': 1})\n+      self.assertEqual(sess.run(peek_v, feed_dict={pei: 0}), {'v': 1})\n       # 1 complete and 1 incomplete entry\n-      self.assertTrue(sess.run([size, isize]) == [1, 1])\n+      self.assertEqual(sess.run([size, isize]), [1, 1])\n \n       # We can now obtain 'x' and 'f' values associated with key 0\n-      self.assertTrue(\n-          sess.run([key_xf, get_xf], feed_dict={\n-              gi: 0\n-          }) == [0, {\n+      self.assertEqual(\n+          sess.run([key_xf, get_xf], feed_dict={gi: 0}), [0, {\n               'x': 1,\n               'f': 2\n           }])\n       # Still have 1 complete and 1 incomplete entry\n-      self.assertTrue(sess.run([size, isize]) == [1, 1])\n+      self.assertEqual(sess.run([size, isize]), [1, 1])\n \n       # We can no longer get 'x' and 'f' from key 0\n       with self.assertRaises(errors.InvalidArgumentError) as cm:\n@@ -517,40 +515,36 @@ def testPartialDictGetsAndPeeks(self):\n \n       exc_str = (\"Tensor at index '0' for key '0' \" 'has already been removed.')\n \n-      self.assertTrue(exc_str in cm.exception.message)\n+      self.assertIn(exc_str, cm.exception.message)\n \n       # Obtain 'v' value associated with key 0\n-      self.assertTrue(\n-          sess.run([key_v, get_v], feed_dict={\n-              gi: 0\n-          }) == [0, {\n+      self.assertEqual(\n+          sess.run([key_v, get_v], feed_dict={gi: 0}), [0, {\n               'v': 1\n           }])\n       # 0 complete and 1 incomplete entry\n-      self.assertTrue(sess.run([size, isize]) == [0, 1])\n+      self.assertEqual(sess.run([size, isize]), [0, 1])\n \n       # Now complete key 1 with tuple entry v\n       sess.run(stage_v, feed_dict={pi: 1, v: 1})\n       # 1 complete and 1 incomplete entry\n-      self.assertTrue(sess.run([size, isize]) == [1, 0])\n+      self.assertEqual(sess.run([size, isize]), [1, 0])\n \n       # Pop without key to obtain 'x' and 'f' values associated with key 1\n-      self.assertTrue(sess.run([pop_key_xf, pop_xf]) == [1, {'x': 1, 'f': 2}])\n+      self.assertEqual(sess.run([pop_key_xf, pop_xf]), [1, {'x': 1, 'f': 2}])\n       # still 1 complete and 1 incomplete entry\n-      self.assertTrue(sess.run([size, isize]) == [1, 0])\n+      self.assertEqual(sess.run([size, isize]), [1, 0])\n       # We can now obtain 'x' and 'f' values associated with key 1\n-      self.assertTrue(\n-          sess.run([pop_key_v, pop_v], feed_dict={\n-              pi: 1\n-          }) == [1, {\n+      self.assertEqual(\n+          sess.run([pop_key_v, pop_v], feed_dict={pi: 1}), [1, {\n               'v': 1\n           }])\n       # Nothing is left\n-      self.assertTrue(sess.run([size, isize]) == [0, 0])\n+      self.assertEqual(sess.run([size, isize]), [0, 0])\n \n   @test_util.run_deprecated_v1\n   def testPartialIndexGets(self):\n-    with ops.Graph().as_default() as G:\n+    with ops.Graph().as_default() as g:\n       with ops.device('/cpu:0'):\n         x = array_ops.placeholder(dtypes.float32)\n         f = array_ops.placeholder(dtypes.float32)\n@@ -568,28 +562,72 @@ def testPartialIndexGets(self):\n         size = stager.size()\n         isize = stager.incomplete_size()\n \n-    G.finalize()\n+    g.finalize()\n \n-    with self.session(graph=G) as sess:\n+    with self.session(graph=g) as sess:\n       # Stage complete tuple\n       sess.run(stage_xvf, feed_dict={pi: 0, x: 1, f: 2, v: 3})\n \n-      self.assertTrue(sess.run([size, isize]) == [1, 0])\n+      self.assertEqual(sess.run([size, isize]), [1, 0])\n \n       # Partial get using indices\n-      self.assertTrue(\n-          sess.run([key_xf, get_xf], feed_dict={\n-              gi: 0\n-          }) == [0, [1, 2]])\n+      self.assertEqual(\n+          sess.run([key_xf, get_xf], feed_dict={gi: 0}), [0, [1, 2]])\n \n       # Still some of key 0 left\n-      self.assertTrue(sess.run([size, isize]) == [1, 0])\n+      self.assertEqual(sess.run([size, isize]), [1, 0])\n \n       # Partial get of remaining index\n-      self.assertTrue(sess.run([key_v, get_v], feed_dict={gi: 0}) == [0, [3]])\n+      self.assertEqual(sess.run([key_v, get_v], feed_dict={gi: 0}), [0, [3]])\n \n       # All gone\n-      self.assertTrue(sess.run([size, isize]) == [0, 0])\n+      self.assertEqual(sess.run([size, isize]), [0, 0])\n+\n+  @test_util.run_deprecated_v1\n+  def testNonScalarKeyOrderedMap(self):\n+    with ops.Graph().as_default() as g:\n+      x = array_ops.placeholder(dtypes.float32)\n+      v = 2. * (array_ops.zeros([128, 128]) + x)\n+      t = data_flow_ops.gen_data_flow_ops.ordered_map_stage(\n+          key=constant_op.constant(value=[1], shape=(1, 3), dtype=dtypes.int64),\n+          indices=np.array([[6]]),\n+          values=[x, v],\n+          dtypes=[dtypes.int64],\n+          capacity=0,\n+          memory_limit=0,\n+          container='container1',\n+          shared_name='',\n+          name=None)\n+\n+    g.finalize()\n+\n+    with self.session(graph=g) as sess:\n+      with self.assertRaisesRegex(errors.InvalidArgumentError,\n+                                  'key must be an int64 scalar'):\n+        sess.run(t, feed_dict={x: 1})\n+\n+  @test_util.run_deprecated_v1\n+  def testNonScalarKeyUnorderedMap(self):\n+    with ops.Graph().as_default() as g:\n+      x = array_ops.placeholder(dtypes.float32)\n+      v = 2. * (array_ops.zeros([128, 128]) + x)\n+      t = data_flow_ops.gen_data_flow_ops.map_stage(\n+          key=constant_op.constant(value=[1], shape=(1, 3), dtype=dtypes.int64),\n+          indices=np.array([[6]]),\n+          values=[x, v],\n+          dtypes=[dtypes.int64],\n+          capacity=0,\n+          memory_limit=0,\n+          container='container1',\n+          shared_name='',\n+          name=None)\n+\n+    g.finalize()\n+\n+    with self.session(graph=g) as sess:\n+      with self.assertRaisesRegex(errors.InvalidArgumentError,\n+                                  'key must be an int64 scalar'):\n+        sess.run(t, feed_dict={x: 1})\n \n \n if __name__ == '__main__':\n"
        ],
        "func_after": []
    },
    {
        "idx": 195295,
        "project": "mruby",
        "commit_id": "c8c083cb750606b2da81582cd8e43b442bb143e6",
        "project_url": "https://github.com/mruby/mruby",
        "commit_url": "https://github.com/mruby/mruby/commit/c8c083cb750606b2da81582cd8e43b442bb143e6",
        "commit_message": "codegen.c: need to pack argument when `n==13` too.\n\nBecause we have extra 2 arguments coming (kw and rhs).",
        "target": 1,
        "irrelevant": 0,
        "func_before": "gen_assignment(codegen_scope *s, node *tree, node *rhs, int sp, int val)\n{\n  int idx;\n  int type = nint(tree->car);\n\n  switch (type) {\n  case NODE_GVAR:\n  case NODE_ARG:\n  case NODE_LVAR:\n  case NODE_IVAR:\n  case NODE_CVAR:\n  case NODE_CONST:\n  case NODE_NIL:\n  case NODE_MASGN:\n    if (rhs) {\n      codegen(s, rhs, VAL);\n      pop();\n      sp = cursp();\n    }\n    break;\n\n  case NODE_COLON2:\n  case NODE_CALL:\n  case NODE_SCALL:\n    /* keep evaluation order */\n    break;\n\n  case NODE_NVAR:\n    codegen_error(s, \"Can't assign to numbered parameter\");\n    break;\n\n  default:\n    codegen_error(s, \"unknown lhs\");\n    break;\n  }\n\n  tree = tree->cdr;\n  switch (type) {\n  case NODE_GVAR:\n    gen_setxv(s, OP_SETGV, sp, nsym(tree), val);\n    break;\n  case NODE_ARG:\n  case NODE_LVAR:\n    idx = lv_idx(s, nsym(tree));\n    if (idx > 0) {\n      if (idx != sp) {\n        gen_move(s, idx, sp, val);\n      }\n      break;\n    }\n    else {                      /* upvar */\n      gen_setupvar(s, sp, nsym(tree));\n    }\n    break;\n  case NODE_IVAR:\n    gen_setxv(s, OP_SETIV, sp, nsym(tree), val);\n    break;\n  case NODE_CVAR:\n    gen_setxv(s, OP_SETCV, sp, nsym(tree), val);\n    break;\n  case NODE_CONST:\n    gen_setxv(s, OP_SETCONST, sp, nsym(tree), val);\n    break;\n  case NODE_COLON2:\n    if (sp) {\n      gen_move(s, cursp(), sp, 0);\n    }\n    sp = cursp();\n    push();\n    codegen(s, tree->car, VAL);\n    if (rhs) {\n      codegen(s, rhs, VAL); pop();\n      gen_move(s, sp, cursp(), 0);\n    }\n    pop_n(2);\n    idx = new_sym(s, nsym(tree->cdr));\n    genop_2(s, OP_SETMCNST, sp, idx);\n    break;\n\n  case NODE_CALL:\n  case NODE_SCALL:\n    {\n      int noself = 0, safe = (type == NODE_SCALL), skip = 0, top, call, n = 0;\n      mrb_sym mid = nsym(tree->cdr->car);\n\n      top = cursp();\n      if (val || sp == cursp()) {\n        push();                   /* room for retval */\n      }\n      call = cursp();\n      if (!tree->car) {\n        noself = 1;\n        push();\n      }\n      else {\n        codegen(s, tree->car, VAL); /* receiver */\n      }\n      if (safe) {\n        int recv = cursp()-1;\n        gen_move(s, cursp(), recv, 1);\n        skip = genjmp2_0(s, OP_JMPNIL, cursp(), val);\n      }\n      tree = tree->cdr->cdr->car;\n      if (tree) {\n        if (tree->car) {            /* positional arguments */\n          n = gen_values(s, tree->car, VAL, (tree->cdr->car)?13:14);\n          if (n < 0) {              /* variable length */\n            n = 15;\n            push();\n          }\n        }\n        if (tree->cdr->car) {       /* keyword arguments */\n          if (n == 14) {\n            pop_n(n);\n            genop_2(s, OP_ARRAY, cursp(), n);\n            push();\n            n = 15;\n          }\n          gen_hash(s, tree->cdr->car->cdr, VAL, 0);\n          if (n < 14) {\n            n++;\n          }\n          else {\n            pop_n(2);\n            genop_2(s, OP_ARYPUSH, cursp(), 1);\n          }\n          push();\n        }\n      }\n      if (rhs) {\n        codegen(s, rhs, VAL);\n        pop();\n      }\n      else {\n        gen_move(s, cursp(), sp, 0);\n      }\n      if (val) {\n        gen_move(s, top, cursp(), 1);\n      }\n      if (n < 15) {\n        n++;\n        if (n == 15) {\n          pop_n(14);\n          genop_2(s, OP_ARRAY, cursp(), 15);\n        }\n      }\n      else {\n        pop();\n        genop_2(s, OP_ARYPUSH, cursp(), 1);\n      }\n      s->sp = call;\n      if (mid == MRB_OPSYM_2(s->mrb, aref) && n == 2) {\n        genop_1(s, OP_SETIDX, cursp());\n      }\n      else {\n        genop_3(s, noself ? OP_SSEND : OP_SEND, cursp(), new_sym(s, attrsym(s, mid)), n);\n      }\n      if (safe) {\n        dispatch(s, skip);\n      }\n      s->sp = top;\n    }\n    break;\n\n  case NODE_MASGN:\n    gen_massignment(s, tree->car, sp, val);\n    break;\n\n  /* splat without assignment */\n  case NODE_NIL:\n    break;\n\n  default:\n    codegen_error(s, \"unknown lhs\");\n    break;\n  }\n  if (val) push();\n}",
        "func_hash": 41954898060187653186067747247923282324,
        "file_name": "codegen.c",
        "file_hash": 166306575091061367964033452033729491771,
        "cwe": [
            "CWE-125"
        ],
        "cve": "CVE-2022-1276",
        "cve_desc": "Out-of-bounds Read in mrb_get_args in GitHub repository mruby/mruby prior to 3.2. Possible arbitrary code execution if being exploited.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-1276",
        "func_name": "gen_assignment",
        "diff": [
            "diff --git a/mrbgems/mruby-compiler/core/codegen.c b/mrbgems/mruby-compiler/core/codegen.c\nindex 8f7b5b0133..e222094be3 100644\n--- a/mrbgems/mruby-compiler/core/codegen.c\n+++ b/mrbgems/mruby-compiler/core/codegen.c\n@@ -1905,7 +1905,7 @@ gen_assignment(codegen_scope *s, node *tree, node *rhs, int sp, int val)\n           }\n         }\n         if (tree->cdr->car) {       /* keyword arguments */\n-          if (n == 14) {\n+          if (n == 13 || n == 14) {\n             pop_n(n);\n             genop_2(s, OP_ARRAY, cursp(), n);\n             push();\n"
        ],
        "func_after": []
    },
    {
        "idx": 195296,
        "project": "uWebSockets",
        "commit_id": "03fca626a95130ab80f86adada54b29d27242759",
        "project_url": "https://github.com/uWebSockets/uWebSockets",
        "commit_url": "https://github.com/uWebSockets/uWebSockets/commit/03fca626a95130ab80f86adada54b29d27242759",
        "commit_message": "Fix overflow of triggered topics",
        "target": 1,
        "irrelevant": 0,
        "func_before": "    void publish(Topic *iterator, size_t start, size_t stop, std::string_view topic, std::pair<std::string_view, std::string_view> message) {\n        /* If we already have 64 triggered topics make sure to drain it here */\n        if (numTriggeredTopics == 64) {\n            drain();\n        }\n\n        /* Iterate over all segments in given topic */\n        for (; stop != std::string::npos; start = stop + 1) {\n            stop = topic.find('/', start);\n            std::string_view segment = topic.substr(start, stop - start);\n\n            /* It is very important to disallow wildcards when publishing.\n             * We will not catch EVERY misuse this lazy way, but enough to hinder\n             * explosive recursion.\n             * Terminating wildcards MAY still get triggered along the way, if for\n             * instace the error is found late while iterating the topic segments. */\n            if (segment.length() == 1) {\n                if (segment[0] == '+' || segment[0] == '#') {\n                    return;\n                }\n            }\n\n            /* Do we have a terminating wildcard child? */\n            if (iterator->terminatingWildcardChild) {\n                iterator->terminatingWildcardChild->messages[messageId] = message;\n\n                /* Add this topic to triggered */\n                if (!iterator->terminatingWildcardChild->triggered) {\n                    triggeredTopics[numTriggeredTopics++] = iterator->terminatingWildcardChild;\n                    iterator->terminatingWildcardChild->triggered = true;\n                }\n            }\n\n            /* Do we have a wildcard child? */\n            if (iterator->wildcardChild) {\n                publish(iterator->wildcardChild, stop + 1, stop, topic, message);\n            }\n\n            std::map<std::string_view, Topic *>::iterator it = iterator->children.find(segment);\n            if (it == iterator->children.end()) {\n                /* Stop trying to match by exact string */\n                return;\n            }\n\n            iterator = it->second;\n        }\n\n        /* If we went all the way we matched exactly */\n        iterator->messages[messageId] = message;\n\n        /* Add this topic to triggered */\n        if (!iterator->triggered) {\n            triggeredTopics[numTriggeredTopics++] = iterator;\n            iterator->triggered = true;\n        }\n    }",
        "func_hash": 134169268379037550524482088626348972483,
        "file_name": "TopicTree.h",
        "file_hash": 203813195164088557620454025257855576407,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2020-36406",
        "cve_desc": "uWebSockets 18.11.0 and 18.12.0 has a stack-based buffer overflow in uWS::TopicTree::trimTree (called from uWS::TopicTree::unsubscribeAll). NOTE: the vendor's position is that this is \"a minor issue or not even an issue at all\" because the developer of an application (that uses uWebSockets) should not be allowing the large number of triggered topics to accumulate",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2020-36406",
        "func_name": "publish",
        "diff": [
            "diff --git a/src/TopicTree.h b/src/TopicTree.h\nindex 0b945b348..80dd180da 100644\n--- a/src/TopicTree.h\n+++ b/src/TopicTree.h\n@@ -124,10 +124,6 @@ struct TopicTree {\n \n     /* Should be getData and commit? */\n     void publish(Topic *iterator, size_t start, size_t stop, std::string_view topic, std::pair<std::string_view, std::string_view> message) {\n-        /* If we already have 64 triggered topics make sure to drain it here */\n-        if (numTriggeredTopics == 64) {\n-            drain();\n-        }\n \n         /* Iterate over all segments in given topic */\n         for (; stop != std::string::npos; start = stop + 1) {\n@@ -151,6 +147,11 @@ struct TopicTree {\n \n                 /* Add this topic to triggered */\n                 if (!iterator->terminatingWildcardChild->triggered) {\n+                    /* If we already have 64 triggered topics make sure to drain it here */\n+                    if (numTriggeredTopics == 64) {\n+                        drain();\n+                    }\n+\n                     triggeredTopics[numTriggeredTopics++] = iterator->terminatingWildcardChild;\n                     iterator->terminatingWildcardChild->triggered = true;\n                 }\n@@ -175,6 +176,11 @@ struct TopicTree {\n \n         /* Add this topic to triggered */\n         if (!iterator->triggered) {\n+            /* If we already have 64 triggered topics make sure to drain it here */\n+            if (numTriggeredTopics == 64) {\n+                drain();\n+            }\n+\n             triggeredTopics[numTriggeredTopics++] = iterator;\n             iterator->triggered = true;\n         }\n"
        ],
        "func_after": []
    },
    {
        "idx": 195302,
        "project": "radare2",
        "commit_id": "37897226a1a31f982bfefdc4aeefc2e50355c73c",
        "project_url": "https://github.com/radare/radare2",
        "commit_url": "https://github.com/radare/radare2/commit/37897226a1a31f982bfefdc4aeefc2e50355c73c",
        "commit_message": "Fix use-after-free in iobank rbtree usage ##io\n\n* See havoc4 bin for reproducer\n* Reported via huntr.dev by 'Cen Zhang'",
        "target": 1,
        "irrelevant": 1,
        "func_before": "R_API bool r_io_bank_map_add_top(RIO *io, const ut32 bankid, const ut32 mapid) {\n\tRIOBank *bank = r_io_bank_get (io, bankid);\n\tRIOMap *map = r_io_map_get (io, mapid);\n\tr_return_val_if_fail (io && bank && map, false);\n\tRIOMapRef *mapref = _mapref_from_map (map);\n\tif (!mapref) {\n\t\treturn false;\n\t}\n\tRIOSubMap *sm = r_io_submap_new (io, mapref);\n\tif (!sm) {\n\t\tfree (mapref);\n\t\treturn false;\n\t}\n\tRRBNode *entry = _find_entry_submap_node (bank, sm);\n\tif (!entry) {\n\t\t// no intersection with any submap, so just insert\n\t\tif (!r_crbtree_insert (bank->submaps, sm, _find_sm_by_from_vaddr_cb, NULL)) {\n\t\t\tfree (sm);\n\t\t\tfree (mapref);\n\t\t\treturn false;\n\t\t}\n\t\tr_list_append (bank->maprefs, mapref);\n\t\treturn true;\n\t}\n\tbank->last_used = NULL;\n\tRIOSubMap *bd = (RIOSubMap *)entry->data;\n\tif (r_io_submap_to (bd) == r_io_submap_to (sm) &&\n\t\tr_io_submap_from (bd) >= r_io_submap_from (sm)) {\n\t\t// _find_entry_submap_node guarantees, that there is no submap\n\t\t// prior to bd in the range of sm, so instead of deleting and inserting\n\t\t// we can just memcpy\n\t\tmemcpy (bd, sm, sizeof (RIOSubMap));\n\t\tfree (sm);\n\t\tr_list_append (bank->maprefs, mapref);\n\t\treturn true;\n\t}\n\tif (r_io_submap_from (bd) < r_io_submap_from (sm) &&\n\t\tr_io_submap_to (sm) < r_io_submap_to (bd)) {\n\t\t// split bd into 2 maps => bd and bdsm\n\t\tRIOSubMap *bdsm = R_NEWCOPY (RIOSubMap, bd);\n\t\tif (!bdsm) {\n\t\t\tfree (sm);\n\t\t\tfree (mapref);\n\t\t\treturn false;\n\t\t}\n\t\tr_io_submap_set_from (bdsm, r_io_submap_to (sm) + 1);\n\t\tr_io_submap_set_to (bd, r_io_submap_from (sm) - 1);\n\t\t// TODO: insert and check return value, before adjusting sm size\n\t\tif (!r_crbtree_insert (bank->submaps, sm, _find_sm_by_from_vaddr_cb, NULL)) {\n\t\t\tfree (sm);\n\t\t\tfree (bdsm);\n\t\t\tfree (mapref);\n\t\t\treturn false;\n\t\t}\n\t\tif (!r_crbtree_insert (bank->submaps, bdsm, _find_sm_by_from_vaddr_cb, NULL)) {\n\t\t\tr_crbtree_delete (bank->submaps, sm, _find_sm_by_from_vaddr_cb, NULL);\n\t\t\tfree (sm);\n\t\t\tfree (bdsm);\n\t\t\tfree (mapref);\n\t\t\treturn false;\n\t\t}\n\t\tr_list_append (bank->maprefs, mapref);\n\t\treturn true;\n\t}\n\n\t// guaranteed intersection\n\tif (r_io_submap_from (bd) < r_io_submap_from (sm)) {\n\t\tr_io_submap_set_to (bd, r_io_submap_from (sm) - 1);\n\t\tentry = r_rbnode_next (entry);\n\t}\n\twhile (entry && r_io_submap_to (((RIOSubMap *)entry->data)) <= r_io_submap_to (sm)) {\n\t\t//delete all submaps that are completly included in sm\n\t\tRRBNode *next = r_rbnode_next (entry);\n\t\t// this can be optimized, there is no need to do search here\n\t\tr_crbtree_delete (bank->submaps, entry->data, _find_sm_by_from_vaddr_cb, NULL);\n\t\tentry = next;\n\t}\n\tif (entry && r_io_submap_from (((RIOSubMap *)entry->data)) <= r_io_submap_to (sm)) {\n\t\tbd = (RIOSubMap *)entry->data;\n\t\tr_io_submap_set_from (bd, r_io_submap_to (sm) + 1);\n\t}\n\tif (!r_crbtree_insert (bank->submaps, sm, _find_sm_by_from_vaddr_cb, NULL)) {\n\t\tfree (sm);\n\t\tfree (mapref);\n\t\treturn false;\n\t}\n\tr_list_append (bank->maprefs, mapref);\n\treturn true;\n}",
        "func_hash": 263882270236510290912687350121854207445,
        "file_name": "io_bank.c",
        "file_hash": 277027272439454961064680108781981809665,
        "cwe": [
            "CWE-125"
        ],
        "cve": "CVE-2022-0139",
        "cve_desc": "Use After Free in GitHub repository radareorg/radare2 prior to 5.6.0.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-0139",
        "func_name": "r_io_bank_map_add_top",
        "diff": [
            "diff --git a/libr/io/io_bank.c b/libr/io/io_bank.c\nindex 228e422d65633..882dfc48d18f0 100644\n--- a/libr/io/io_bank.c\n+++ b/libr/io/io_bank.c\n@@ -230,7 +230,10 @@ R_API bool r_io_bank_map_add_top(RIO *io, const ut32 bankid, const ut32 mapid) {\n \t\t//delete all submaps that are completly included in sm\n \t\tRRBNode *next = r_rbnode_next (entry);\n \t\t// this can be optimized, there is no need to do search here\n-\t\tr_crbtree_delete (bank->submaps, entry->data, _find_sm_by_from_vaddr_cb, NULL);\n+\t\tbool a = r_crbtree_delete (bank->submaps, entry->data, _find_sm_by_from_vaddr_cb, NULL);\n+\t\tif (!a) {\n+\t\t\tbreak;\n+\t\t}\n \t\tentry = next;\n \t}\n \tif (entry && r_io_submap_from (((RIOSubMap *)entry->data)) <= r_io_submap_to (sm)) {\n"
        ],
        "func_after": []
    },
    {
        "idx": 195308,
        "project": "flatpak",
        "commit_id": "462fca2c666e0cd2b60d6d2593a7216a83047aaf",
        "project_url": "https://github.com/flatpak/flatpak",
        "commit_url": "https://github.com/flatpak/flatpak/commit/462fca2c666e0cd2b60d6d2593a7216a83047aaf",
        "commit_message": "run: Don't allow chroot()\n\nIf we don't allow pivot_root() then there seems no reason why we should\nallow chroot().\n\nPartially fixes GHSA-67h7-w3jq-vh4q.\n\nSigned-off-by: Simon McVittie <smcv@collabora.com>",
        "target": 1,
        "irrelevant": 0,
        "func_before": "setup_seccomp (FlatpakBwrap   *bwrap,\n               const char     *arch,\n               gulong          allowed_personality,\n               FlatpakRunFlags run_flags,\n               GError        **error)\n{\n  gboolean multiarch = (run_flags & FLATPAK_RUN_FLAG_MULTIARCH) != 0;\n  gboolean devel = (run_flags & FLATPAK_RUN_FLAG_DEVEL) != 0;\n\n  __attribute__((cleanup (cleanup_seccomp))) scmp_filter_ctx seccomp = NULL;\n\n  /**** BEGIN NOTE ON CODE SHARING\n   *\n   * There are today a number of different Linux container\n   * implementations.  That will likely continue for long into the\n   * future.  But we can still try to share code, and it's important\n   * to do so because it affects what library and application writers\n   * can do, and we should support code portability between different\n   * container tools.\n   *\n   * This syscall blocklist is copied from linux-user-chroot, which was in turn\n   * clearly influenced by the Sandstorm.io blocklist.\n   *\n   * If you make any changes here, I suggest sending the changes along\n   * to other sandbox maintainers.  Using the libseccomp list is also\n   * an appropriate venue:\n   * https://groups.google.com/forum/#!forum/libseccomp\n   *\n   * A non-exhaustive list of links to container tooling that might\n   * want to share this blocklist:\n   *\n   *  https://github.com/sandstorm-io/sandstorm\n   *    in src/sandstorm/supervisor.c++\n   *  https://github.com/flatpak/flatpak.git\n   *    in common/flatpak-run.c\n   *  https://git.gnome.org/browse/linux-user-chroot\n   *    in src/setup-seccomp.c\n   *\n   * Other useful resources:\n   * https://github.com/systemd/systemd/blob/HEAD/src/shared/seccomp-util.c\n   * https://github.com/moby/moby/blob/HEAD/profiles/seccomp/default.json\n   *\n   **** END NOTE ON CODE SHARING\n   */\n  struct\n  {\n    int                  scall;\n    int                  errnum;\n    struct scmp_arg_cmp *arg;\n  } syscall_blocklist[] = {\n    /* Block dmesg */\n    {SCMP_SYS (syslog), EPERM},\n    /* Useless old syscall */\n    {SCMP_SYS (uselib), EPERM},\n    /* Don't allow disabling accounting */\n    {SCMP_SYS (acct), EPERM},\n    /* 16-bit code is unnecessary in the sandbox, and modify_ldt is a\n       historic source of interesting information leaks. */\n    {SCMP_SYS (modify_ldt), EPERM},\n    /* Don't allow reading current quota use */\n    {SCMP_SYS (quotactl), EPERM},\n\n    /* Don't allow access to the kernel keyring */\n    {SCMP_SYS (add_key), EPERM},\n    {SCMP_SYS (keyctl), EPERM},\n    {SCMP_SYS (request_key), EPERM},\n\n    /* Scary VM/NUMA ops */\n    {SCMP_SYS (move_pages), EPERM},\n    {SCMP_SYS (mbind), EPERM},\n    {SCMP_SYS (get_mempolicy), EPERM},\n    {SCMP_SYS (set_mempolicy), EPERM},\n    {SCMP_SYS (migrate_pages), EPERM},\n\n    /* Don't allow subnamespace setups: */\n    {SCMP_SYS (unshare), EPERM},\n    {SCMP_SYS (setns), EPERM},\n    {SCMP_SYS (mount), EPERM},\n    {SCMP_SYS (umount), EPERM},\n    {SCMP_SYS (umount2), EPERM},\n    {SCMP_SYS (pivot_root), EPERM},\n#if defined(__s390__) || defined(__s390x__) || defined(__CRIS__)\n    /* Architectures with CONFIG_CLONE_BACKWARDS2: the child stack\n     * and flags arguments are reversed so the flags come second */\n    {SCMP_SYS (clone), EPERM, &SCMP_A1 (SCMP_CMP_MASKED_EQ, CLONE_NEWUSER, CLONE_NEWUSER)},\n#else\n    /* Normally the flags come first */\n    {SCMP_SYS (clone), EPERM, &SCMP_A0 (SCMP_CMP_MASKED_EQ, CLONE_NEWUSER, CLONE_NEWUSER)},\n#endif\n\n    /* Don't allow faking input to the controlling tty (CVE-2017-5226) */\n    {SCMP_SYS (ioctl), EPERM, &SCMP_A1 (SCMP_CMP_MASKED_EQ, 0xFFFFFFFFu, (int) TIOCSTI)},\n\n    /* seccomp can't look into clone3()'s struct clone_args to check whether\n     * the flags are OK, so we have no choice but to block clone3().\n     * Return ENOSYS so user-space will fall back to clone().\n     * (GHSA-67h7-w3jq-vh4q; see also https://github.com/moby/moby/commit/9f6b562d) */\n    {SCMP_SYS (clone3), ENOSYS},\n\n    /* New mount manipulation APIs can also change our VFS. There's no\n     * legitimate reason to do these in the sandbox, so block all of them\n     * rather than thinking about which ones might be dangerous.\n     * (GHSA-67h7-w3jq-vh4q) */\n    {SCMP_SYS (open_tree), ENOSYS},\n    {SCMP_SYS (move_mount), ENOSYS},\n    {SCMP_SYS (fsopen), ENOSYS},\n    {SCMP_SYS (fsconfig), ENOSYS},\n    {SCMP_SYS (fsmount), ENOSYS},\n    {SCMP_SYS (fspick), ENOSYS},\n    {SCMP_SYS (mount_setattr), ENOSYS},\n  };\n\n  struct\n  {\n    int                  scall;\n    int                  errnum;\n    struct scmp_arg_cmp *arg;\n  } syscall_nondevel_blocklist[] = {\n    /* Profiling operations; we expect these to be done by tools from outside\n     * the sandbox.  In particular perf has been the source of many CVEs.\n     */\n    {SCMP_SYS (perf_event_open), EPERM},\n    /* Don't allow you to switch to bsd emulation or whatnot */\n    {SCMP_SYS (personality), EPERM, &SCMP_A0 (SCMP_CMP_NE, allowed_personality)},\n    {SCMP_SYS (ptrace), EPERM}\n  };\n  /* Blocklist all but unix, inet, inet6 and netlink */\n  struct\n  {\n    int             family;\n    FlatpakRunFlags flags_mask;\n  } socket_family_allowlist[] = {\n    /* NOTE: Keep in numerical order */\n    { AF_UNSPEC, 0 },\n    { AF_LOCAL, 0 },\n    { AF_INET, 0 },\n    { AF_INET6, 0 },\n    { AF_NETLINK, 0 },\n    { AF_CAN, FLATPAK_RUN_FLAG_CANBUS },\n    { AF_BLUETOOTH, FLATPAK_RUN_FLAG_BLUETOOTH },\n  };\n  int last_allowed_family;\n  int i, r;\n  g_auto(GLnxTmpfile) seccomp_tmpf  = { 0, };\n\n  seccomp = seccomp_init (SCMP_ACT_ALLOW);\n  if (!seccomp)\n    return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Initialize seccomp failed\"));\n\n  if (arch != NULL)\n    {\n      uint32_t arch_id = 0;\n      const uint32_t *extra_arches = NULL;\n\n      if (strcmp (arch, \"i386\") == 0)\n        {\n          arch_id = SCMP_ARCH_X86;\n        }\n      else if (strcmp (arch, \"x86_64\") == 0)\n        {\n          arch_id = SCMP_ARCH_X86_64;\n          extra_arches = seccomp_x86_64_extra_arches;\n        }\n      else if (strcmp (arch, \"arm\") == 0)\n        {\n          arch_id = SCMP_ARCH_ARM;\n        }\n#ifdef SCMP_ARCH_AARCH64\n      else if (strcmp (arch, \"aarch64\") == 0)\n        {\n          arch_id = SCMP_ARCH_AARCH64;\n          extra_arches = seccomp_aarch64_extra_arches;\n        }\n#endif\n\n      /* We only really need to handle arches on multiarch systems.\n       * If only one arch is supported the default is fine */\n      if (arch_id != 0)\n        {\n          /* This *adds* the target arch, instead of replacing the\n             native one. This is not ideal, because we'd like to only\n             allow the target arch, but we can't really disallow the\n             native arch at this point, because then bubblewrap\n             couldn't continue running. */\n          r = seccomp_arch_add (seccomp, arch_id);\n          if (r < 0 && r != -EEXIST)\n            return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to add architecture to seccomp filter\"));\n\n          if (multiarch && extra_arches != NULL)\n            {\n              for (i = 0; extra_arches[i] != 0; i++)\n                {\n                  r = seccomp_arch_add (seccomp, extra_arches[i]);\n                  if (r < 0 && r != -EEXIST)\n                    return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to add multiarch architecture to seccomp filter\"));\n                }\n            }\n        }\n    }\n\n  /* TODO: Should we filter the kernel keyring syscalls in some way?\n   * We do want them to be used by desktop apps, but they could also perhaps\n   * leak system stuff or secrets from other apps.\n   */\n\n  for (i = 0; i < G_N_ELEMENTS (syscall_blocklist); i++)\n    {\n      int scall = syscall_blocklist[i].scall;\n      int errnum = syscall_blocklist[i].errnum;\n\n      g_return_val_if_fail (errnum == EPERM || errnum == ENOSYS, FALSE);\n\n      if (syscall_blocklist[i].arg)\n        r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (errnum), scall, 1, *syscall_blocklist[i].arg);\n      else\n        r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (errnum), scall, 0);\n      if (r < 0 && r == -EFAULT /* unknown syscall */)\n        return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to block syscall %d\"), scall);\n    }\n\n  if (!devel)\n    {\n      for (i = 0; i < G_N_ELEMENTS (syscall_nondevel_blocklist); i++)\n        {\n          int scall = syscall_nondevel_blocklist[i].scall;\n          int errnum = syscall_nondevel_blocklist[i].errnum;\n\n          g_return_val_if_fail (errnum == EPERM || errnum == ENOSYS, FALSE);\n\n          if (syscall_nondevel_blocklist[i].arg)\n            r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (errnum), scall, 1, *syscall_nondevel_blocklist[i].arg);\n          else\n            r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (errnum), scall, 0);\n\n          if (r < 0 && r == -EFAULT /* unknown syscall */)\n            return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to block syscall %d\"), scall);\n        }\n    }\n\n  /* Socket filtering doesn't work on e.g. i386, so ignore failures here\n   * However, we need to user seccomp_rule_add_exact to avoid libseccomp doing\n   * something else: https://github.com/seccomp/libseccomp/issues/8 */\n  last_allowed_family = -1;\n  for (i = 0; i < G_N_ELEMENTS (socket_family_allowlist); i++)\n    {\n      int family = socket_family_allowlist[i].family;\n      int disallowed;\n\n      if (socket_family_allowlist[i].flags_mask != 0 &&\n          (socket_family_allowlist[i].flags_mask & run_flags) != socket_family_allowlist[i].flags_mask)\n        continue;\n\n      for (disallowed = last_allowed_family + 1; disallowed < family; disallowed++)\n        {\n          /* Blocklist the in-between valid families */\n          seccomp_rule_add_exact (seccomp, SCMP_ACT_ERRNO (EAFNOSUPPORT), SCMP_SYS (socket), 1, SCMP_A0 (SCMP_CMP_EQ, disallowed));\n        }\n      last_allowed_family = family;\n    }\n  /* Blocklist the rest */\n  seccomp_rule_add_exact (seccomp, SCMP_ACT_ERRNO (EAFNOSUPPORT), SCMP_SYS (socket), 1, SCMP_A0 (SCMP_CMP_GE, last_allowed_family + 1));\n\n  if (!glnx_open_anonymous_tmpfile_full (O_RDWR | O_CLOEXEC, \"/tmp\", &seccomp_tmpf, error))\n    return FALSE;\n\n  if (seccomp_export_bpf (seccomp, seccomp_tmpf.fd) != 0)\n    return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to export bpf\"));\n\n  lseek (seccomp_tmpf.fd, 0, SEEK_SET);\n\n  flatpak_bwrap_add_args_data_fd (bwrap,\n                                  \"--seccomp\", glnx_steal_fd (&seccomp_tmpf.fd), NULL);\n\n  return TRUE;\n}",
        "func_hash": 116661486604620809625071911593237669795,
        "file_name": "flatpak-run.c",
        "file_hash": 32398709380082441128978861691951488575,
        "cwe": [
            "CWE-20"
        ],
        "cve": "CVE-2021-41133",
        "cve_desc": "Flatpak is a system for building, distributing, and running sandboxed desktop applications on Linux. In versions prior to 1.10.4 and 1.12.0, Flatpak apps with direct access to AF_UNIX sockets such as those used by Wayland, Pipewire or pipewire-pulse can trick portals and other host-OS services into treating the Flatpak app as though it was an ordinary, non-sandboxed host-OS process. They can do this by manipulating the VFS using recent mount-related syscalls that are not blocked by Flatpak's denylist seccomp filter, in order to substitute a crafted `/.flatpak-info` or make that file disappear entirely. Flatpak apps that act as clients for AF_UNIX sockets such as those used by Wayland, Pipewire or pipewire-pulse can escalate the privileges that the corresponding services will believe the Flatpak app has. Note that protocols that operate entirely over the D-Bus session bus (user bus), system bus or accessibility bus are not affected by this. This is due to the use of a proxy process `xdg-dbus-proxy`, whose VFS cannot be manipulated by the Flatpak app, when interacting with these buses. Patches exist for versions 1.10.4 and 1.12.0, and as of time of publication, a patch for version 1.8.2 is being planned. There are no workarounds aside from upgrading to a patched version.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-41133",
        "func_name": "setup_seccomp",
        "diff": [
            "diff --git a/common/flatpak-run.c b/common/flatpak-run.c\nindex a6ef5042af..7861343795 100644\n--- a/common/flatpak-run.c\n+++ b/common/flatpak-run.c\n@@ -2937,6 +2937,7 @@ setup_seccomp (FlatpakBwrap   *bwrap,\n     {SCMP_SYS (umount), EPERM},\n     {SCMP_SYS (umount2), EPERM},\n     {SCMP_SYS (pivot_root), EPERM},\n+    {SCMP_SYS (chroot), EPERM},\n #if defined(__s390__) || defined(__s390x__) || defined(__CRIS__)\n     /* Architectures with CONFIG_CLONE_BACKWARDS2: the child stack\n      * and flags arguments are reversed so the flags come second */\n"
        ],
        "func_after": []
    },
    {
        "idx": 195309,
        "project": "squid",
        "commit_id": "5e2ea2b13bd98f53e29964ca26bb0d602a8a12b9",
        "project_url": "https://github.com/squid-cache/squid",
        "commit_url": "https://github.com/squid-cache/squid/commit/5e2ea2b13bd98f53e29964ca26bb0d602a8a12b9",
        "commit_message": "Improve handling of Gopher responses (#1022)",
        "target": 1,
        "irrelevant": 0,
        "func_before": "gopherToHTML(GopherStateData * gopherState, char *inbuf, int len)\n{\n    char *pos = inbuf;\n    char *lpos = NULL;\n    char *tline = NULL;\n    LOCAL_ARRAY(char, line, TEMP_BUF_SIZE);\n    LOCAL_ARRAY(char, tmpbuf, TEMP_BUF_SIZE);\n    char *name = NULL;\n    char *selector = NULL;\n    char *host = NULL;\n    char *port = NULL;\n    char *escaped_selector = NULL;\n    const char *icon_url = NULL;\n    char gtype;\n    StoreEntry *entry = NULL;\n\n    memset(tmpbuf, '\\0', TEMP_BUF_SIZE);\n    memset(line, '\\0', TEMP_BUF_SIZE);\n\n    entry = gopherState->entry;\n\n    if (gopherState->conversion == GopherStateData::HTML_INDEX_PAGE) {\n        char *html_url = html_quote(entry->url());\n        gopherHTMLHeader(entry, \"Gopher Index %s\", html_url);\n        storeAppendPrintf(entry,\n                          \"<p>This is a searchable Gopher index. Use the search\\n\"\n                          \"function of your browser to enter search terms.\\n\"\n                          \"<ISINDEX>\\n\");\n        gopherHTMLFooter(entry);\n        /* now let start sending stuff to client */\n        entry->flush();\n        gopherState->HTML_header_added = 1;\n\n        return;\n    }\n\n    if (gopherState->conversion == GopherStateData::HTML_CSO_PAGE) {\n        char *html_url = html_quote(entry->url());\n        gopherHTMLHeader(entry, \"CSO Search of %s\", html_url);\n        storeAppendPrintf(entry,\n                          \"<P>A CSO database usually contains a phonebook or\\n\"\n                          \"directory.  Use the search function of your browser to enter\\n\"\n                          \"search terms.</P><ISINDEX>\\n\");\n        gopherHTMLFooter(entry);\n        /* now let start sending stuff to client */\n        entry->flush();\n        gopherState->HTML_header_added = 1;\n\n        return;\n    }\n\n    String outbuf;\n\n    if (!gopherState->HTML_header_added) {\n        if (gopherState->conversion == GopherStateData::HTML_CSO_RESULT)\n            gopherHTMLHeader(entry, \"CSO Search Result\", NULL);\n        else\n            gopherHTMLHeader(entry, \"Gopher Menu\", NULL);\n\n        outbuf.append (\"<PRE>\");\n\n        gopherState->HTML_header_added = 1;\n\n        gopherState->HTML_pre = 1;\n    }\n\n    while (pos < inbuf + len) {\n        int llen;\n        int left = len - (pos - inbuf);\n        lpos = (char *)memchr(pos, '\\n', left);\n        if (lpos) {\n            ++lpos;             /* Next line is after \\n */\n            llen = lpos - pos;\n        } else {\n            llen = left;\n        }\n        if (gopherState->len + llen >= TEMP_BUF_SIZE) {\n            debugs(10, DBG_IMPORTANT, \"GopherHTML: Buffer overflow. Lost some data on URL: \" << entry->url()  );\n            llen = TEMP_BUF_SIZE - gopherState->len - 1;\n            gopherState->overflowed = true; // may already be true\n        }\n        if (!lpos) {\n            /* there is no complete line in inbuf */\n            /* copy it to temp buffer */\n            /* note: llen is adjusted above */\n            memcpy(gopherState->buf + gopherState->len, pos, llen);\n            gopherState->len += llen;\n            break;\n        }\n        if (gopherState->len != 0) {\n            /* there is something left from last tx. */\n            memcpy(line, gopherState->buf, gopherState->len);\n            memcpy(line + gopherState->len, pos, llen);\n            llen += gopherState->len;\n            gopherState->len = 0;\n        } else {\n            memcpy(line, pos, llen);\n        }\n        line[llen + 1] = '\\0';\n        /* move input to next line */\n        pos = lpos;\n\n        /* at this point. We should have one line in buffer to process */\n\n        if (*line == '.') {\n            /* skip it */\n            memset(line, '\\0', TEMP_BUF_SIZE);\n            continue;\n        }\n\n        switch (gopherState->conversion) {\n\n        case GopherStateData::HTML_INDEX_RESULT:\n\n        case GopherStateData::HTML_DIR: {\n            tline = line;\n            gtype = *tline;\n            ++tline;\n            name = tline;\n            selector = strchr(tline, TAB);\n\n            if (selector) {\n                *selector = '\\0';\n                ++selector;\n                host = strchr(selector, TAB);\n\n                if (host) {\n                    *host = '\\0';\n                    ++host;\n                    port = strchr(host, TAB);\n\n                    if (port) {\n                        char *junk;\n                        port[0] = ':';\n                        junk = strchr(host, TAB);\n\n                        if (junk)\n                            *junk++ = 0;    /* Chop port */\n                        else {\n                            junk = strchr(host, '\\r');\n\n                            if (junk)\n                                *junk++ = 0;    /* Chop port */\n                            else {\n                                junk = strchr(host, '\\n');\n\n                                if (junk)\n                                    *junk++ = 0;    /* Chop port */\n                            }\n                        }\n\n                        if ((port[1] == '0') && (!port[2]))\n                            port[0] = 0;    /* 0 means none */\n                    }\n\n                    /* escape a selector here */\n                    escaped_selector = xstrdup(rfc1738_escape_part(selector));\n\n                    switch (gtype) {\n\n                    case GOPHER_DIRECTORY:\n                        icon_url = mimeGetIconURL(\"internal-menu\");\n                        break;\n\n                    case GOPHER_HTML:\n\n                    case GOPHER_FILE:\n                        icon_url = mimeGetIconURL(\"internal-text\");\n                        break;\n\n                    case GOPHER_INDEX:\n\n                    case GOPHER_CSO:\n                        icon_url = mimeGetIconURL(\"internal-index\");\n                        break;\n\n                    case GOPHER_IMAGE:\n\n                    case GOPHER_GIF:\n\n                    case GOPHER_PLUS_IMAGE:\n                        icon_url = mimeGetIconURL(\"internal-image\");\n                        break;\n\n                    case GOPHER_SOUND:\n\n                    case GOPHER_PLUS_SOUND:\n                        icon_url = mimeGetIconURL(\"internal-sound\");\n                        break;\n\n                    case GOPHER_PLUS_MOVIE:\n                        icon_url = mimeGetIconURL(\"internal-movie\");\n                        break;\n\n                    case GOPHER_TELNET:\n\n                    case GOPHER_3270:\n                        icon_url = mimeGetIconURL(\"internal-telnet\");\n                        break;\n\n                    case GOPHER_BIN:\n\n                    case GOPHER_MACBINHEX:\n\n                    case GOPHER_DOSBIN:\n\n                    case GOPHER_UUENCODED:\n                        icon_url = mimeGetIconURL(\"internal-binary\");\n                        break;\n\n                    case GOPHER_INFO:\n                        icon_url = NULL;\n                        break;\n\n                    case GOPHER_WWW:\n                        icon_url = mimeGetIconURL(\"internal-link\");\n                        break;\n\n                    default:\n                        icon_url = mimeGetIconURL(\"internal-unknown\");\n                        break;\n                    }\n\n                    memset(tmpbuf, '\\0', TEMP_BUF_SIZE);\n\n                    if ((gtype == GOPHER_TELNET) || (gtype == GOPHER_3270)) {\n                        if (strlen(escaped_selector) != 0)\n                            snprintf(tmpbuf, TEMP_BUF_SIZE, \"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"telnet://%s@%s%s%s/\\\">%s</A>\\n\",\n                                     icon_url, escaped_selector, rfc1738_escape_part(host),\n                                     *port ? \":\" : \"\", port, html_quote(name));\n                        else\n                            snprintf(tmpbuf, TEMP_BUF_SIZE, \"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"telnet://%s%s%s/\\\">%s</A>\\n\",\n                                     icon_url, rfc1738_escape_part(host), *port ? \":\" : \"\",\n                                     port, html_quote(name));\n\n                    } else if (gtype == GOPHER_INFO) {\n                        snprintf(tmpbuf, TEMP_BUF_SIZE, \"\\t%s\\n\", html_quote(name));\n                    } else {\n                        if (strncmp(selector, \"GET /\", 5) == 0) {\n                            /* WWW link */\n                            snprintf(tmpbuf, TEMP_BUF_SIZE, \"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"http://%s/%s\\\">%s</A>\\n\",\n                                     icon_url, host, rfc1738_escape_unescaped(selector + 5), html_quote(name));\n                        } else if (gtype == GOPHER_WWW) {\n                            snprintf(tmpbuf, TEMP_BUF_SIZE, \"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"%s\\\">%s</A>\\n\",\n                                     icon_url, rfc1738_escape_unescaped(selector), html_quote(name));\n                        } else {\n                            /* Standard link */\n                            snprintf(tmpbuf, TEMP_BUF_SIZE, \"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"gopher://%s/%c%s\\\">%s</A>\\n\",\n                                     icon_url, host, gtype, escaped_selector, html_quote(name));\n                        }\n                    }\n\n                    safe_free(escaped_selector);\n                    outbuf.append(tmpbuf);\n                } else {\n                    memset(line, '\\0', TEMP_BUF_SIZE);\n                    continue;\n                }\n            } else {\n                memset(line, '\\0', TEMP_BUF_SIZE);\n                continue;\n            }\n\n            break;\n            }           /* HTML_DIR, HTML_INDEX_RESULT */\n\n        case GopherStateData::HTML_CSO_RESULT: {\n            if (line[0] == '-') {\n                int code, recno;\n                char *s_code, *s_recno, *result;\n\n                s_code = strtok(line + 1, \":\\n\");\n                s_recno = strtok(NULL, \":\\n\");\n                result = strtok(NULL, \"\\n\");\n\n                if (!result)\n                    break;\n\n                code = atoi(s_code);\n\n                recno = atoi(s_recno);\n\n                if (code != 200)\n                    break;\n\n                if (gopherState->cso_recno != recno) {\n                    snprintf(tmpbuf, TEMP_BUF_SIZE, \"</PRE><HR noshade size=\\\"1px\\\"><H2>Record# %d<br><i>%s</i></H2>\\n<PRE>\", recno, html_quote(result));\n                    gopherState->cso_recno = recno;\n                } else {\n                    snprintf(tmpbuf, TEMP_BUF_SIZE, \"%s\\n\", html_quote(result));\n                }\n\n                outbuf.append(tmpbuf);\n                break;\n            } else {\n                int code;\n                char *s_code, *result;\n\n                s_code = strtok(line, \":\");\n                result = strtok(NULL, \"\\n\");\n\n                if (!result)\n                    break;\n\n                code = atoi(s_code);\n\n                switch (code) {\n\n                case 200: {\n                    /* OK */\n                    /* Do nothing here */\n                    break;\n                }\n\n                case 102:   /* Number of matches */\n\n                case 501:   /* No Match */\n\n                case 502: { /* Too Many Matches */\n                    /* Print the message the server returns */\n                    snprintf(tmpbuf, TEMP_BUF_SIZE, \"</PRE><HR noshade size=\\\"1px\\\"><H2>%s</H2>\\n<PRE>\", html_quote(result));\n                    outbuf.append(tmpbuf);\n                    break;\n                }\n\n                }\n            }\n\n            break;\n            }           /* HTML_CSO_RESULT */\n        default:\n            break;      /* do nothing */\n\n        }           /* switch */\n\n    }               /* while loop */\n\n    if (outbuf.size() > 0) {\n        entry->append(outbuf.rawBuf(), outbuf.size());\n        /* now let start sending stuff to client */\n        entry->flush();\n    }\n\n    outbuf.clean();\n    return;\n}",
        "func_hash": 274182330078791984686066092776381139807,
        "file_name": "gopher.cc",
        "file_hash": 53940162348551394934251092714566998881,
        "cwe": [
            "CWE-400"
        ],
        "cve": "CVE-2021-46784",
        "cve_desc": "In Squid 3.x through 3.5.28, 4.x through 4.17, and 5.x before 5.6, due to improper buffer management, a Denial of Service can occur when processing long Gopher server responses.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-46784",
        "func_name": "gopherToHTML",
        "diff": [
            "diff --git a/src/gopher.cc b/src/gopher.cc\nindex 95afd9528f1..409c1808c62 100644\n--- a/src/gopher.cc\n+++ b/src/gopher.cc\n@@ -365,7 +365,6 @@ gopherToHTML(GopherStateData * gopherState, char *inbuf, int len)\n     char *lpos = NULL;\n     char *tline = NULL;\n     LOCAL_ARRAY(char, line, TEMP_BUF_SIZE);\n-    LOCAL_ARRAY(char, tmpbuf, TEMP_BUF_SIZE);\n     char *name = NULL;\n     char *selector = NULL;\n     char *host = NULL;\n@@ -375,7 +374,6 @@ gopherToHTML(GopherStateData * gopherState, char *inbuf, int len)\n     char gtype;\n     StoreEntry *entry = NULL;\n \n-    memset(tmpbuf, '\\0', TEMP_BUF_SIZE);\n     memset(line, '\\0', TEMP_BUF_SIZE);\n \n     entry = gopherState->entry;\n@@ -410,7 +408,7 @@ gopherToHTML(GopherStateData * gopherState, char *inbuf, int len)\n         return;\n     }\n \n-    String outbuf;\n+    SBuf outbuf;\n \n     if (!gopherState->HTML_header_added) {\n         if (gopherState->conversion == GopherStateData::HTML_CSO_RESULT)\n@@ -582,37 +580,34 @@ gopherToHTML(GopherStateData * gopherState, char *inbuf, int len)\n                         break;\n                     }\n \n-                    memset(tmpbuf, '\\0', TEMP_BUF_SIZE);\n-\n                     if ((gtype == GOPHER_TELNET) || (gtype == GOPHER_3270)) {\n                         if (strlen(escaped_selector) != 0)\n-                            snprintf(tmpbuf, TEMP_BUF_SIZE, \"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"telnet://%s@%s%s%s/\\\">%s</A>\\n\",\n+                            outbuf.appendf(\"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"telnet://%s@%s%s%s/\\\">%s</A>\\n\",\n                                      icon_url, escaped_selector, rfc1738_escape_part(host),\n                                      *port ? \":\" : \"\", port, html_quote(name));\n                         else\n-                            snprintf(tmpbuf, TEMP_BUF_SIZE, \"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"telnet://%s%s%s/\\\">%s</A>\\n\",\n+                            outbuf.appendf(\"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"telnet://%s%s%s/\\\">%s</A>\\n\",\n                                      icon_url, rfc1738_escape_part(host), *port ? \":\" : \"\",\n                                      port, html_quote(name));\n \n                     } else if (gtype == GOPHER_INFO) {\n-                        snprintf(tmpbuf, TEMP_BUF_SIZE, \"\\t%s\\n\", html_quote(name));\n+                        outbuf.appendf(\"\\t%s\\n\", html_quote(name));\n                     } else {\n                         if (strncmp(selector, \"GET /\", 5) == 0) {\n                             /* WWW link */\n-                            snprintf(tmpbuf, TEMP_BUF_SIZE, \"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"http://%s/%s\\\">%s</A>\\n\",\n+                            outbuf.appendf(\"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"http://%s/%s\\\">%s</A>\\n\",\n                                      icon_url, host, rfc1738_escape_unescaped(selector + 5), html_quote(name));\n                         } else if (gtype == GOPHER_WWW) {\n-                            snprintf(tmpbuf, TEMP_BUF_SIZE, \"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"%s\\\">%s</A>\\n\",\n+                            outbuf.appendf(\"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"gopher://%s/%c%s\\\">%s</A>\\n\",\n                                      icon_url, rfc1738_escape_unescaped(selector), html_quote(name));\n                         } else {\n                             /* Standard link */\n-                            snprintf(tmpbuf, TEMP_BUF_SIZE, \"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"gopher://%s/%c%s\\\">%s</A>\\n\",\n+                            outbuf.appendf(\"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"gopher://%s/%c%s\\\">%s</A>\\n\",\n                                      icon_url, host, gtype, escaped_selector, html_quote(name));\n                         }\n                     }\n \n                     safe_free(escaped_selector);\n-                    outbuf.append(tmpbuf);\n                 } else {\n                     memset(line, '\\0', TEMP_BUF_SIZE);\n                     continue;\n@@ -645,13 +640,12 @@ gopherToHTML(GopherStateData * gopherState, char *inbuf, int len)\n                     break;\n \n                 if (gopherState->cso_recno != recno) {\n-                    snprintf(tmpbuf, TEMP_BUF_SIZE, \"</PRE><HR noshade size=\\\"1px\\\"><H2>Record# %d<br><i>%s</i></H2>\\n<PRE>\", recno, html_quote(result));\n+                    outbuf.appendf(\"</PRE><HR noshade size=\\\"1px\\\"><H2>Record# %d<br><i>%s</i></H2>\\n<PRE>\", recno, html_quote(result));\n                     gopherState->cso_recno = recno;\n                 } else {\n-                    snprintf(tmpbuf, TEMP_BUF_SIZE, \"%s\\n\", html_quote(result));\n+                    outbuf.appendf(\"%s\\n\", html_quote(result));\n                 }\n \n-                outbuf.append(tmpbuf);\n                 break;\n             } else {\n                 int code;\n@@ -679,8 +673,7 @@ gopherToHTML(GopherStateData * gopherState, char *inbuf, int len)\n \n                 case 502: { /* Too Many Matches */\n                     /* Print the message the server returns */\n-                    snprintf(tmpbuf, TEMP_BUF_SIZE, \"</PRE><HR noshade size=\\\"1px\\\"><H2>%s</H2>\\n<PRE>\", html_quote(result));\n-                    outbuf.append(tmpbuf);\n+                    outbuf.appendf(\"</PRE><HR noshade size=\\\"1px\\\"><H2>%s</H2>\\n<PRE>\", html_quote(result));\n                     break;\n                 }\n \n@@ -696,13 +689,12 @@ gopherToHTML(GopherStateData * gopherState, char *inbuf, int len)\n \n     }               /* while loop */\n \n-    if (outbuf.size() > 0) {\n-        entry->append(outbuf.rawBuf(), outbuf.size());\n+    if (outbuf.length() > 0) {\n+        entry->append(outbuf.rawContent(), outbuf.length());\n         /* now let start sending stuff to client */\n         entry->flush();\n     }\n \n-    outbuf.clean();\n     return;\n }\n \n"
        ],
        "func_after": []
    },
    {
        "idx": 195328,
        "project": "gpac",
        "commit_id": "30ac5e5236b790accd1f25347eebf2dc8c6c1bcb",
        "project_url": "https://github.com/gpac/gpac",
        "commit_url": "https://github.com/gpac/gpac/commit/30ac5e5236b790accd1f25347eebf2dc8c6c1bcb",
        "commit_message": "fixed #1897",
        "target": 1,
        "irrelevant": 0,
        "func_before": "char *gf_text_get_utf8_line(char *szLine, u32 lineSize, FILE *txt_in, s32 unicode_type)\n{\n\tu32 i, j, len;\n\tchar *sOK;\n\tchar szLineConv[1024];\n\tunsigned short *sptr;\n\n\tmemset(szLine, 0, sizeof(char)*lineSize);\n\tsOK = gf_fgets(szLine, lineSize, txt_in);\n\tif (!sOK) return NULL;\n\tif (unicode_type<=1) {\n\t\tj=0;\n\t\tlen = (u32) strlen(szLine);\n\t\tfor (i=0; i<len; i++) {\n\t\t\tif (!unicode_type && (szLine[i] & 0x80)) {\n\t\t\t\t/*non UTF8 (likely some win-CP)*/\n\t\t\t\tif ((szLine[i+1] & 0xc0) != 0x80) {\n\t\t\t\t\tszLineConv[j] = 0xc0 | ( (szLine[i] >> 6) & 0x3 );\n\t\t\t\t\tj++;\n\t\t\t\t\tszLine[i] &= 0xbf;\n\t\t\t\t}\n\t\t\t\t/*UTF8 2 bytes char*/\n\t\t\t\telse if ( (szLine[i] & 0xe0) == 0xc0) {\n\t\t\t\t\tszLineConv[j] = szLine[i];\n\t\t\t\t\ti++;\n\t\t\t\t\tj++;\n\t\t\t\t}\n\t\t\t\t/*UTF8 3 bytes char*/\n\t\t\t\telse if ( (szLine[i] & 0xf0) == 0xe0) {\n\t\t\t\t\tszLineConv[j] = szLine[i];\n\t\t\t\t\ti++;\n\t\t\t\t\tj++;\n\t\t\t\t\tszLineConv[j] = szLine[i];\n\t\t\t\t\ti++;\n\t\t\t\t\tj++;\n\t\t\t\t}\n\t\t\t\t/*UTF8 4 bytes char*/\n\t\t\t\telse if ( (szLine[i] & 0xf8) == 0xf0) {\n\t\t\t\t\tszLineConv[j] = szLine[i];\n\t\t\t\t\ti++;\n\t\t\t\t\tj++;\n\t\t\t\t\tszLineConv[j] = szLine[i];\n\t\t\t\t\ti++;\n\t\t\t\t\tj++;\n\t\t\t\t\tszLineConv[j] = szLine[i];\n\t\t\t\t\ti++;\n\t\t\t\t\tj++;\n\t\t\t\t} else {\n\t\t\t\t\ti+=1;\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t}\n\t\t\tszLineConv[j] = szLine[i];\n\t\t\tj++;\n\t\t}\n\t\tszLineConv[j] = 0;\n\t\tstrcpy(szLine, szLineConv);\n\t\treturn sOK;\n\t}\n\n#ifdef GPAC_BIG_ENDIAN\n\tif (unicode_type==3)\n#else\n\tif (unicode_type==2)\n#endif\n\t{\n\t\ti=0;\n\t\twhile (1) {\n\t\t\tchar c;\n\t\t\tif (!szLine[i] && !szLine[i+1]) break;\n\t\t\tc = szLine[i+1];\n\t\t\tszLine[i+1] = szLine[i];\n\t\t\tszLine[i] = c;\n\t\t\ti+=2;\n\t\t}\n\t}\n\tsptr = (u16 *)szLine;\n\ti = (u32) gf_utf8_wcstombs(szLineConv, 1024, (const unsigned short **) &sptr);\n\tszLineConv[i] = 0;\n\tstrcpy(szLine, szLineConv);\n\t/*this is ugly indeed: since input is UTF16-LE, there are many chances the gf_fgets never reads the \\0 after a \\n*/\n\tif (unicode_type==3) gf_fgetc(txt_in);\n\treturn sOK;\n}",
        "func_hash": 117427486429117846714647428036887377373,
        "file_name": "load_text.c",
        "file_hash": 196742273187479774331460388493063544419,
        "cwe": [
            "CWE-415"
        ],
        "cve": "CVE-2021-40574",
        "cve_desc": "The binary MP4Box in Gpac 1.0.1 has a double-free vulnerability in the gf_text_get_utf8_line function in load_text.c, which allows attackers to cause a denial of service, even code execution and escalation of privileges.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-40574",
        "func_name": "gf_text_get_utf8_line",
        "diff": [
            "diff --git a/src/filters/load_text.c b/src/filters/load_text.c\nindex 4f41d2d3bf..b82d2991b1 100644\n--- a/src/filters/load_text.c\n+++ b/src/filters/load_text.c\n@@ -255,7 +255,7 @@ char *gf_text_get_utf8_line(char *szLine, u32 lineSize, FILE *txt_in, s32 unicod\n {\n \tu32 i, j, len;\n \tchar *sOK;\n-\tchar szLineConv[1024];\n+\tchar szLineConv[2048];\n \tunsigned short *sptr;\n \n \tmemset(szLine, 0, sizeof(char)*lineSize);\n@@ -328,7 +328,7 @@ char *gf_text_get_utf8_line(char *szLine, u32 lineSize, FILE *txt_in, s32 unicod\n \t\t}\n \t}\n \tsptr = (u16 *)szLine;\n-\ti = (u32) gf_utf8_wcstombs(szLineConv, 1024, (const unsigned short **) &sptr);\n+\ti = (u32) gf_utf8_wcstombs(szLineConv, 2048, (const unsigned short **) &sptr);\n \tszLineConv[i] = 0;\n \tstrcpy(szLine, szLineConv);\n \t/*this is ugly indeed: since input is UTF16-LE, there are many chances the gf_fgets never reads the \\0 after a \\n*/\n@@ -2338,6 +2338,8 @@ static GF_Err gf_text_process_sub(GF_Filter *filter, GF_TXTIn *ctx)\n \t\twhile (szLine[i+1] && szLine[i+1]!='}') {\n \t\t\tszTime[i] = szLine[i+1];\n \t\t\ti++;\n+\t\t\tif (i>=19)\n+\t\t\t\tbreak;\n \t\t}\n \t\tszTime[i] = 0;\n \t\tctx->start = atoi(szTime);\n"
        ],
        "func_after": []
    },
    {
        "idx": 195331,
        "project": "tensorflow",
        "commit_id": "08d7b00c0a5a20926363849f611729f53f3ec022",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/08d7b00c0a5a20926363849f611729f53f3ec022",
        "commit_message": "Fix Segfault in Concat V2 shape function.\n\nPiperOrigin-RevId: 412120654\nChange-Id: I3ff915faea694f9ad8b00024e9af2de9909011be",
        "target": 1,
        "irrelevant": 0,
        "func_before": "Status ConcatShapeHelper(InferenceContext* c, int start_value_index,\n                         int end_value_index, int dim_index) {\n  ShapeHandle unused;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(dim_index), 0, &unused));\n  const Tensor* concat_dim_t = c->input_tensor(dim_index);\n  if (concat_dim_t == nullptr) {\n    // Return an unknown shape with same rank as inputs, or an unknown rank\n    // if no input's rank is known.\n\n    // Find rank.\n    int32_t rank = InferenceContext::kUnknownRank;\n    for (int i = start_value_index; i < end_value_index; ++i) {\n      if (rank == InferenceContext::kUnknownRank) rank = c->Rank(c->input(i));\n      if (rank != InferenceContext::kUnknownRank) {\n        break;\n      }\n    }\n    if (rank == InferenceContext::kUnknownRank) {\n      c->set_output(0, c->UnknownShape());\n      return Status::OK();\n    } else if (rank == 0) {\n      return errors::InvalidArgument(\n          \"Can't concatenate scalars (use tf.stack instead)\");\n    } else {\n      for (int i = start_value_index; i < end_value_index; ++i) {\n        // Check that all the inputs are of the correct rank.\n        TF_RETURN_IF_ERROR(c->WithRank(c->input(i), rank, &unused));\n      }\n    }\n    // Build result of <rank> different unknown dims.\n    std::vector<DimensionHandle> dims;\n    dims.reserve(rank);\n    for (int i = 0; i < rank; ++i) dims.push_back(c->UnknownDim());\n    c->set_output(0, c->MakeShape(dims));\n    return Status::OK();\n  }\n\n  // Merge all the non-concat dims, and sum the concat dim to make an output\n  // shape.\n  int64_t concat_dim;\n  if (concat_dim_t->dtype() == DT_INT32) {\n    concat_dim = static_cast<int64_t>(concat_dim_t->flat<int32>()(0));\n  } else {\n    concat_dim = concat_dim_t->flat<int64_t>()(0);\n  }\n\n  // Minimum required number of dimensions.\n  const int min_rank = concat_dim < 0 ? -concat_dim : concat_dim + 1;\n\n  ShapeHandle output_before;\n  ShapeHandle output_after;\n\n  ShapeHandle input = c->input(end_value_index - 1);\n  TF_RETURN_IF_ERROR(c->WithRankAtLeast(input, min_rank, &input));\n  TF_RETURN_IF_ERROR(c->Subshape(input, 0, concat_dim, &output_before));\n  DimensionHandle output_middle = c->Dim(input, concat_dim);\n  if (concat_dim == -1) {\n    output_after = c->Scalar();  // no dimensions.\n  } else {\n    TF_RETURN_IF_ERROR(c->Subshape(input, concat_dim + 1, &output_after));\n  }\n\n  for (int i = end_value_index - 2; i >= start_value_index; --i) {\n    ShapeHandle before;\n    ShapeHandle after;\n    input = c->input(i);\n    TF_RETURN_IF_ERROR(c->WithRankAtLeast(input, min_rank, &input));\n    TF_RETURN_IF_ERROR(c->Subshape(input, 0, concat_dim, &before));\n    DimensionHandle middle = c->Dim(input, concat_dim);\n    if (concat_dim == -1) {\n      after = c->Scalar();\n    } else {\n      TF_RETURN_IF_ERROR(c->Subshape(input, concat_dim + 1, &after));\n    }\n\n    TF_RETURN_IF_ERROR(c->Merge(before, output_before, &output_before));\n    TF_RETURN_IF_ERROR(c->Add(output_middle, middle, &output_middle));\n    TF_RETURN_IF_ERROR(c->Merge(after, output_after, &output_after));\n  }\n\n  ShapeHandle s;\n  TF_RETURN_IF_ERROR(\n      c->Concatenate(output_before, c->Vector(output_middle), &s));\n  TF_RETURN_IF_ERROR(c->Concatenate(s, output_after, &s));\n  c->set_output(0, s);\n  return Status::OK();\n}",
        "func_hash": 115004012549325804010611397133680502113,
        "file_name": "common_shape_fns.cc",
        "file_hash": 114394888048780454732842913577124501919,
        "cwe": [
            "CWE-843"
        ],
        "cve": "CVE-2022-21731",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The implementation of shape inference for `ConcatV2` can be used to trigger a denial of service attack via a segfault caused by a type confusion. The `axis` argument is translated into `concat_dim` in the `ConcatShapeHelper` helper function. Then, a value for `min_rank` is computed based on `concat_dim`. This is then used to validate that the `values` tensor has at least the required rank. However, `WithRankAtLeast` receives the lower bound as a 64-bits value and then compares it against the maximum 32-bits integer value that could be represented. Due to the fact that `min_rank` is a 32-bits value and the value of `axis`, the `rank` argument is a negative value, so the error check is bypassed. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-21731",
        "func_name": "ConcatShapeHelper",
        "diff": [
            "diff --git a/tensorflow/core/framework/common_shape_fns.cc b/tensorflow/core/framework/common_shape_fns.cc\nindex 95f2670e0571da..4a5ce9ae661ffd 100644\n--- a/tensorflow/core/framework/common_shape_fns.cc\n+++ b/tensorflow/core/framework/common_shape_fns.cc\n@@ -2005,7 +2005,7 @@ Status ConcatShapeHelper(InferenceContext* c, int start_value_index,\n   }\n \n   // Minimum required number of dimensions.\n-  const int min_rank = concat_dim < 0 ? -concat_dim : concat_dim + 1;\n+  const int64 min_rank = concat_dim < 0 ? -concat_dim : concat_dim + 1;\n \n   ShapeHandle output_before;\n   ShapeHandle output_after;\ndiff --git a/tensorflow/python/kernel_tests/array_ops/concat_op_test.py b/tensorflow/python/kernel_tests/array_ops/concat_op_test.py\nindex a957665903176f..a5460861f9dd8b 100644\n--- a/tensorflow/python/kernel_tests/array_ops/concat_op_test.py\n+++ b/tensorflow/python/kernel_tests/array_ops/concat_op_test.py\n@@ -16,6 +16,7 @@\n \n import numpy as np\n \n+from tensorflow.python.eager import def_function\n from tensorflow.python.framework import constant_op\n from tensorflow.python.framework import dtypes\n from tensorflow.python.framework import errors_impl\n@@ -570,6 +571,17 @@ def testConcatInvalidAxis(self):\n         t2 = [2]\n         gen_array_ops.concat_v2([t1, t2], 1).eval()\n \n+  def testConcatInvalidAxisInTfFunction(self):\n+\n+    @def_function.function\n+    def concat_wrapper():\n+      y = gen_array_ops.concat_v2(\n+          values=[[1, 2, 3], [4, 5, 6]], axis=0xb500005b)\n+      return y\n+\n+    with self.assertRaises(ValueError):\n+      concat_wrapper()\n+\n   def testConcatNegativeAxis(self):\n     with test_util.use_gpu():\n       t1 = [[1, 2, 3], [4, 5, 6]]\n"
        ],
        "func_after": []
    },
    {
        "idx": 195334,
        "project": "gpac",
        "commit_id": "b03c9f252526bb42fbd1b87b9f5e339c3cf2390a",
        "project_url": "https://github.com/gpac/gpac",
        "commit_url": "https://github.com/gpac/gpac/commit/b03c9f252526bb42fbd1b87b9f5e339c3cf2390a",
        "commit_message": "fixed #1890",
        "target": 1,
        "irrelevant": 1,
        "func_before": "GF_Err iloc_box_read(GF_Box *s, GF_BitStream *bs)\n{\n\tu32 item_count, extent_count, i, j;\n\tGF_ItemLocationBox *ptr = (GF_ItemLocationBox *)s;\n\n\tISOM_DECREASE_SIZE(ptr, 2)\n\tptr->offset_size = gf_bs_read_int(bs, 4);\n\tptr->length_size = gf_bs_read_int(bs, 4);\n\tptr->base_offset_size = gf_bs_read_int(bs, 4);\n\tif (ptr->version == 1 || ptr->version == 2) {\n\t\tptr->index_size = gf_bs_read_int(bs, 4);\n\t} else {\n\t\tgf_bs_read_int(bs, 4);\n\t}\n\tif (ptr->version < 2) {\n\t\tISOM_DECREASE_SIZE(ptr, 2)\n\t\titem_count = gf_bs_read_u16(bs);\n\t} else {\n\t\tISOM_DECREASE_SIZE(ptr, 4)\n\t\titem_count = gf_bs_read_u32(bs);\n\t}\n\n\tfor (i = 0; i < item_count; i++) {\n\t\tGF_ItemLocationEntry *location_entry = (GF_ItemLocationEntry *)gf_malloc(sizeof(GF_ItemLocationEntry));\n\t\tif (!location_entry) return GF_OUT_OF_MEM;\n\n\t\tgf_list_add(ptr->location_entries, location_entry);\n\t\tif (ptr->version < 2) {\n\t\t\tISOM_DECREASE_SIZE(ptr, 2)\n\t\t\tlocation_entry->item_ID = gf_bs_read_u16(bs);\n\t\t} else {\n\t\t\tISOM_DECREASE_SIZE(ptr, 4)\n\t\t\tlocation_entry->item_ID = gf_bs_read_u32(bs);\n\t\t}\n\t\tif (ptr->version == 1 || ptr->version == 2) {\n\t\t\tISOM_DECREASE_SIZE(ptr, 2)\n\t\t\tlocation_entry->construction_method = gf_bs_read_u16(bs);\n\t\t}\n\t\telse {\n\t\t\tlocation_entry->construction_method = 0;\n\t\t}\n\t\tISOM_DECREASE_SIZE(ptr, (2 + ptr->base_offset_size) )\n\t\tlocation_entry->data_reference_index = gf_bs_read_u16(bs);\n\t\tlocation_entry->base_offset = gf_bs_read_int(bs, 8*ptr->base_offset_size);\n#ifndef GPAC_DISABLE_ISOM_WRITE\n\t\tlocation_entry->original_base_offset = location_entry->base_offset;\n#endif\n\n\t\tISOM_DECREASE_SIZE(ptr, 2)\n\t\textent_count = gf_bs_read_u16(bs);\n\t\tlocation_entry->extent_entries = gf_list_new();\n\t\tfor (j = 0; j < extent_count; j++) {\n\t\t\tGF_ItemExtentEntry *extent_entry = (GF_ItemExtentEntry *)gf_malloc(sizeof(GF_ItemExtentEntry));\n\t\t\tif (!extent_entry) return GF_OUT_OF_MEM;\n\t\t\t\n\t\t\tgf_list_add(location_entry->extent_entries, extent_entry);\n\t\t\tif ((ptr->version == 1 || ptr->version == 2) && ptr->index_size > 0) {\n\t\t\t\tISOM_DECREASE_SIZE(ptr, ptr->index_size)\n\t\t\t\textent_entry->extent_index = gf_bs_read_int(bs, 8 * ptr->index_size);\n\t\t\t}\n\t\t\telse {\n\t\t\t\textent_entry->extent_index = 0;\n\t\t\t}\n\t\t\tISOM_DECREASE_SIZE(ptr, (ptr->offset_size+ptr->length_size) )\n\n\t\t\textent_entry->extent_offset = gf_bs_read_int(bs, 8*ptr->offset_size);\n\t\t\textent_entry->extent_length = gf_bs_read_int(bs, 8*ptr->length_size);\n#ifndef GPAC_DISABLE_ISOM_WRITE\n\t\t\textent_entry->original_extent_offset = extent_entry->extent_offset;\n#endif\n\t\t}\n\t}\n\treturn GF_OK;\n}",
        "func_hash": 85275035202223574859308673912965262169,
        "file_name": "box_code_meta.c",
        "file_hash": 315220373545459860670428553876078791185,
        "cwe": [
            "CWE-415"
        ],
        "cve": "CVE-2021-40573",
        "cve_desc": "The binary MP4Box in Gpac 1.0.1 has a double-free vulnerability in the gf_list_del function in list.c, which allows attackers to cause a denial of service.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-40573",
        "func_name": "iloc_box_read",
        "diff": [
            "diff --git a/src/isomedia/box_code_meta.c b/src/isomedia/box_code_meta.c\nindex e3f0556c00..cdd0948a6d 100644\n--- a/src/isomedia/box_code_meta.c\n+++ b/src/isomedia/box_code_meta.c\n@@ -282,7 +282,8 @@ GF_Err iloc_box_read(GF_Box *s, GF_BitStream *bs)\n \t}\n \n \tfor (i = 0; i < item_count; i++) {\n-\t\tGF_ItemLocationEntry *location_entry = (GF_ItemLocationEntry *)gf_malloc(sizeof(GF_ItemLocationEntry));\n+\t\tGF_ItemLocationEntry *location_entry;\n+\t\tGF_SAFEALLOC(location_entry, GF_ItemLocationEntry);\n \t\tif (!location_entry) return GF_OUT_OF_MEM;\n \n \t\tgf_list_add(ptr->location_entries, location_entry);\n@@ -311,7 +312,8 @@ GF_Err iloc_box_read(GF_Box *s, GF_BitStream *bs)\n \t\textent_count = gf_bs_read_u16(bs);\n \t\tlocation_entry->extent_entries = gf_list_new();\n \t\tfor (j = 0; j < extent_count; j++) {\n-\t\t\tGF_ItemExtentEntry *extent_entry = (GF_ItemExtentEntry *)gf_malloc(sizeof(GF_ItemExtentEntry));\n+\t\t\tGF_ItemExtentEntry *extent_entry;\n+\t\t\tGF_SAFEALLOC(extent_entry, GF_ItemExtentEntry);\n \t\t\tif (!extent_entry) return GF_OUT_OF_MEM;\n \t\t\t\n \t\t\tgf_list_add(location_entry->extent_entries, extent_entry);\n"
        ],
        "func_after": []
    },
    {
        "idx": 195338,
        "project": "gpac",
        "commit_id": "5ce0c906ed8599d218036b18b78e8126a496f137",
        "project_url": "https://github.com/gpac/gpac",
        "commit_url": "https://github.com/gpac/gpac/commit/5ce0c906ed8599d218036b18b78e8126a496f137",
        "commit_message": "fixed #1892",
        "target": 1,
        "irrelevant": 1,
        "func_before": "static void naludmx_queue_param_set(GF_NALUDmxCtx *ctx, char *data, u32 size, u32 ps_type, s32 ps_id)\n{\n\tGF_List *list = NULL, *alt_list = NULL;\n\tGF_NALUFFParam *sl;\n\tu32 i, count;\n\tu32 crc = gf_crc_32(data, size);\n\n\tif (ctx->codecid==GF_CODECID_HEVC) {\n\t\tswitch (ps_type) {\n\t\tcase GF_HEVC_NALU_VID_PARAM:\n\t\t\tif (!ctx->vps) ctx->vps = gf_list_new();\n\t\t\tlist = ctx->vps;\n\t\t\tbreak;\n\t\tcase GF_HEVC_NALU_SEQ_PARAM:\n\t\t\tlist = ctx->sps;\n\t\t\tbreak;\n\t\tcase GF_HEVC_NALU_PIC_PARAM:\n\t\t\tlist = ctx->pps;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tassert(0);\n\t\t\treturn;\n\t\t}\n\t} else if (ctx->codecid==GF_CODECID_VVC) {\n\t\tswitch (ps_type) {\n\t\tcase GF_VVC_NALU_VID_PARAM:\n\t\t\tif (!ctx->vps) ctx->vps = gf_list_new();\n\t\t\tlist = ctx->vps;\n\t\t\tbreak;\n\t\tcase GF_VVC_NALU_SEQ_PARAM:\n\t\t\tlist = ctx->sps;\n\t\t\tbreak;\n\t\tcase GF_VVC_NALU_PIC_PARAM:\n\t\t\tlist = ctx->pps;\n\t\t\tbreak;\n\t\tcase GF_VVC_NALU_DEC_PARAM:\n\t\t\tif (!ctx->vvc_dci) ctx->vvc_dci = gf_list_new();\n\t\t\tlist = ctx->vvc_dci;\n\t\t\tbreak;\n\t\tcase GF_VVC_NALU_APS_PREFIX:\n\t\t\tif (!ctx->vvc_aps_pre) ctx->vvc_aps_pre = gf_list_new();\n\t\t\tlist = ctx->vvc_aps_pre;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tassert(0);\n\t\t\treturn;\n\t\t}\n\t} else {\n\t\tswitch (ps_type) {\n\t\tcase GF_AVC_NALU_SVC_SUBSEQ_PARAM:\n\t\tcase GF_AVC_NALU_SEQ_PARAM:\n\t\t\tlist = ctx->sps;\n\t\t\tbreak;\n\t\tcase GF_AVC_NALU_PIC_PARAM:\n\t\t\tlist = ctx->pps;\n\t\t\talt_list = ctx->pps_svc;\n\t\t\tbreak;\n\t\tcase GF_AVC_NALU_SEQ_PARAM_EXT:\n\t\t\tif (!ctx->sps_ext) ctx->sps_ext = gf_list_new();\n\t\t\tlist = ctx->sps_ext;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tassert(0);\n\t\t\treturn;\n\t\t}\n\t}\n\tsl = NULL;\n\tcount = gf_list_count(list);\n\tfor (i=0; i<count; i++) {\n\t\tsl = gf_list_get(list, i);\n\t\tif (sl->id != ps_id) {\n\t\t\tsl = NULL;\n\t\t\tcontinue;\n\t\t}\n\t\t//same ID, same CRC, we don't change our state\n\t\tif (sl->crc == crc) return;\n\t\tbreak;\n\t}\n\t//handle alt PPS list for SVC\n\tif (!sl && alt_list) {\n\t\tcount = gf_list_count(alt_list);\n\t\tfor (i=0; i<count; i++) {\n\t\t\tsl = gf_list_get(alt_list, i);\n\t\t\tif (sl->id != ps_id) {\n\t\t\t\tsl = NULL;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\t//same ID, same CRC, we don't change our state\n\t\t\tif (sl->crc == crc) return;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (sl) {\n\t\t//otherwise we keep this new param set\n\t\tsl->data = gf_realloc(sl->data, size);\n\t\tmemcpy(sl->data, data, size);\n\t\tsl->size = size;\n\t\tsl->crc = crc;\n\t\tctx->ps_modified = GF_TRUE;\n\t\treturn;\n\t}\n\t//TODO we might want to purge the list after a while !!\n\n\tGF_SAFEALLOC(sl, GF_NALUFFParam);\n\tif (!sl) return;\n\tsl->data = gf_malloc(sizeof(char) * size);\n\tif (!sl->data) {\n\t\tgf_free(sl);\n\t\treturn;\n\t}\n\tmemcpy(sl->data, data, size);\n\tsl->size = size;\n\tsl->id = ps_id;\n\tsl->crc = crc;\n\n\tctx->ps_modified = GF_TRUE;\n\tgf_list_add(list, sl);\n}",
        "func_hash": 290272188072466406075146604851063657628,
        "file_name": "reframe_nalu.c",
        "file_hash": 268905417897981194112099324827197288724,
        "cwe": [
            "CWE-476"
        ],
        "cve": "CVE-2021-40563",
        "cve_desc": "A Segmentation fault exists casued by null pointer dereference exists in Gpac through 1.0.1 via the naludmx_create_avc_decoder_config function in reframe_nalu.c when using mp4box, which causes a denial of service.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-40563",
        "func_name": "naludmx_queue_param_set",
        "diff": [
            "diff --git a/src/filters/reframe_nalu.c b/src/filters/reframe_nalu.c\nindex 5077805819..aad8ad9640 100644\n--- a/src/filters/reframe_nalu.c\n+++ b/src/filters/reframe_nalu.c\n@@ -1680,8 +1680,10 @@ static void naludmx_queue_param_set(GF_NALUDmxCtx *ctx, char *data, u32 size, u3\n {\n \tGF_List *list = NULL, *alt_list = NULL;\n \tGF_NALUFFParam *sl;\n-\tu32 i, count;\n-\tu32 crc = gf_crc_32(data, size);\n+\tu32 i, count, crc;\n+\n+\tif (!size) return;\n+\tcrc = gf_crc_32(data, size);\n \n \tif (ctx->codecid==GF_CODECID_HEVC) {\n \t\tswitch (ps_type) {\n"
        ],
        "func_after": []
    },
    {
        "idx": 195340,
        "project": "tensorflow",
        "commit_id": "e952a89b7026b98fe8cbe626514a93ed68b7c510",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/e952a89b7026b98fe8cbe626514a93ed68b7c510",
        "commit_message": "Prevent overflow in sparse dense cwise ops.\n\nPiperOrigin-RevId: 415543171\nChange-Id: I22dab7c41be2121ab5efe5403ca0e2f9b7cb24b8",
        "target": 1,
        "irrelevant": 1,
        "func_before": "  void Compute(OpKernelContext *ctx) override {\n    const Tensor *indices_t, *values_t, *shape_t, *dense_t;\n    OP_REQUIRES_OK(ctx, ctx->input(\"sp_indices\", &indices_t));\n    OP_REQUIRES_OK(ctx, ctx->input(\"sp_values\", &values_t));\n    OP_REQUIRES_OK(ctx, ctx->input(\"sp_shape\", &shape_t));\n    OP_REQUIRES_OK(ctx, ctx->input(\"dense\", &dense_t));\n\n    // Validations.\n    OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(indices_t->shape()),\n                errors::InvalidArgument(\n                    \"Input sp_indices should be a matrix but received shape: \",\n                    indices_t->shape().DebugString()));\n    OP_REQUIRES(ctx,\n                TensorShapeUtils::IsVector(values_t->shape()) &&\n                    TensorShapeUtils::IsVector(shape_t->shape()),\n                errors::InvalidArgument(\n                    \"Inputs sp_values and sp_shape should be vectors \"\n                    \"but received shapes: \",\n                    values_t->shape().DebugString(), \" and \",\n                    shape_t->shape().DebugString()));\n    OP_REQUIRES(\n        ctx, TensorShapeUtils::IsVector(shape_t->shape()),\n        errors::InvalidArgument(\"Input sp_shape must be a vector. Got: \",\n                                shape_t->shape().DebugString()));\n    OP_REQUIRES(\n        ctx, values_t->dim_size(0) == indices_t->dim_size(0),\n        errors::InvalidArgument(\n            \"The first dimension of values and indices should match. (\",\n            values_t->dim_size(0), \" vs. \", indices_t->dim_size(0), \")\"));\n    OP_REQUIRES(\n        ctx, shape_t->shape().dim_size(0) == indices_t->shape().dim_size(1),\n        errors::InvalidArgument(\n            \"Number of dimensions must match second dimension of indices. \",\n            \"Got \", shape_t->shape().dim_size(0),\n            \" dimensions, indices shape: \", indices_t->shape().DebugString()));\n    OP_REQUIRES(ctx, shape_t->NumElements() > 0,\n                errors::InvalidArgument(\n                    \"The shape argument requires at least one element.\"));\n\n    const auto indices_mat = indices_t->matrix<int64_t>();\n    const auto shape_vec = shape_t->vec<int64_t>();\n    const auto lhs_dims = BCast::FromShape(TensorShape(shape_vec));\n    const auto rhs_dims = BCast::FromShape(dense_t->shape());\n    BCast b(lhs_dims, rhs_dims, false);  // false for keeping the same num dims.\n\n    // True iff (size(lhs) >= size(rhs)) and all dims in lhs is greater or equal\n    // to dims in rhs (from right to left).\n    auto VecGreaterEq = [](ArraySlice<int64_t> lhs, ArraySlice<int64_t> rhs) {\n      if (lhs.size() < rhs.size()) return false;\n      for (size_t i = 0; i < rhs.size(); ++i) {\n        if (lhs[lhs.size() - 1 - i] < rhs[rhs.size() - 1 - i]) return false;\n      }\n      return true;\n    };\n    OP_REQUIRES(ctx, VecGreaterEq(lhs_dims, rhs_dims) && b.IsValid(),\n                errors::InvalidArgument(\n                    \"SparseDenseBinaryOpShared broadcasts dense to sparse \"\n                    \"only; got incompatible shapes: [\",\n                    absl::StrJoin(lhs_dims, \",\"), \"] vs. [\",\n                    absl::StrJoin(rhs_dims, \",\"), \"]\"));\n\n    Tensor *output_values = nullptr;\n    Tensor dense_gathered;\n    const int64_t nnz = indices_t->dim_size(0);\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_output(0, TensorShape({nnz}), &output_values));\n    OP_REQUIRES_OK(\n        ctx, ctx->allocate_temp(DataTypeToEnum<T>::value, TensorShape({nnz}),\n                                &dense_gathered));\n    bool op_is_div = false;\n    if (absl::StrContains(ctx->op_kernel().type_string_view(), \"Div\")) {\n      op_is_div = true;\n    }\n    // Pulls relevant entries from the dense side, with reshape and broadcasting\n    // *of the dense side* taken into account.  Use a TensorRef to avoid blowing\n    // up memory.\n    //\n    // We can directly use the sparse indices to look up dense side, because\n    // \"b.y_reshape()\" and \"b.y_bcast()\" are guaranteed to have rank \"ndims\".\n    auto dense_gathered_flat = dense_gathered.flat<T>();\n    const int ndims = lhs_dims.size();\n    switch (ndims) {\n#define CASE(NDIM)                                                             \\\n  case NDIM: {                                                                 \\\n    TensorRef<Eigen::Tensor<const T, NDIM, Eigen::RowMajor>> rhs_ref =         \\\n        dense_t->shaped<T, NDIM>(b.y_reshape())                                \\\n            .broadcast(BCast::ToIndexArray<NDIM>(b.y_bcast()));                \\\n    Eigen::array<Eigen::DenseIndex, NDIM> idx;                                 \\\n    bool indices_valid = true;                                                 \\\n    for (int i = 0; i < nnz; ++i) {                                            \\\n      for (int d = 0; d < NDIM; ++d) {                                         \\\n        idx[d] = internal::SubtleMustCopy(indices_mat(i, d));                  \\\n        if (!FastBoundsCheck(idx[d], rhs_ref.dimension(d))) {                  \\\n          indices_valid = false;                                               \\\n        }                                                                      \\\n      }                                                                        \\\n      OP_REQUIRES(                                                             \\\n          ctx, indices_valid,                                                  \\\n          errors::InvalidArgument(\"Provided indices are out-of-bounds w.r.t. \" \\\n                                  \"dense side with broadcasted shape\"));       \\\n      dense_gathered_flat(i) = rhs_ref.coeff(idx);                             \\\n      if (op_is_div) {                                                         \\\n        OP_REQUIRES(ctx, dense_gathered_flat(i) != 0,                          \\\n                    errors::InvalidArgument(                                   \\\n                        \"SparseDenseCwiseDiv cannot divide by zero,\"           \\\n                        \"but input dense tensor contains zero \"));             \\\n      }                                                                        \\\n    }                                                                          \\\n    break;                                                                     \\\n  }\n\n      CASE(1);\n      CASE(2);\n      CASE(3);\n      CASE(4);\n      CASE(5);\n      default:\n        OP_REQUIRES(\n            ctx, false,\n            errors::InvalidArgument(\"Only tensors with ranks between 1 and 5 \"\n                                    \"are currently supported.  Tensor rank: \",\n                                    ndims));\n#undef CASE\n    }\n\n    output_values->flat<T>().device(ctx->eigen_device<Device>()) =\n        values_t->flat<T>().binaryExpr(dense_gathered_flat,\n                                       typename Functor::func());\n  }",
        "func_hash": 171281295800875024521736226102204042037,
        "file_name": "sparse_dense_binary_op_shared.cc",
        "file_hash": 32986558098184077015668984064800916453,
        "cwe": [
            "CWE-190"
        ],
        "cve": "CVE-2022-23567",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The implementations of `Sparse*Cwise*` ops are vulnerable to integer overflows. These can be used to trigger large allocations (so, OOM based denial of service) or `CHECK`-fails when building new `TensorShape` objects (so, assert failures based denial of service). We are missing some validation on the shapes of the input tensors as well as directly constructing a large `TensorShape` with user-provided dimensions. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23567",
        "func_name": "Compute",
        "diff": [
            "diff --git a/tensorflow/core/kernels/sparse_dense_binary_op_shared.cc b/tensorflow/core/kernels/sparse_dense_binary_op_shared.cc\nindex db27abfda7e537..29534bf0a2625c 100644\n--- a/tensorflow/core/kernels/sparse_dense_binary_op_shared.cc\n+++ b/tensorflow/core/kernels/sparse_dense_binary_op_shared.cc\n@@ -99,7 +99,9 @@ class SparseDenseBinaryOpShared : public OpKernel {\n \n     const auto indices_mat = indices_t->matrix<int64_t>();\n     const auto shape_vec = shape_t->vec<int64_t>();\n-    const auto lhs_dims = BCast::FromShape(TensorShape(shape_vec));\n+    TensorShape lhs_shape;\n+    OP_REQUIRES_OK(ctx, TensorShape::BuildTensorShape(shape_vec, &lhs_shape));\n+    const auto lhs_dims = BCast::FromShape(lhs_shape);\n     const auto rhs_dims = BCast::FromShape(dense_t->shape());\n     BCast b(lhs_dims, rhs_dims, false);  // false for keeping the same num dims.\n \n"
        ],
        "func_after": []
    },
    {
        "idx": 195341,
        "project": "tensorflow",
        "commit_id": "b9bd6cfd1c50e6807846af9a86f9b83cafc9c8ae",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/b9bd6cfd1c50e6807846af9a86f9b83cafc9c8ae",
        "commit_message": "Prevent integer overflow in `OpLevelCostEstimator::CalculateOutputSize`.\n\nIn order to not change the API, we return a negative value in case of overflow. A better fix is to change the API to return a status instead.\n\nPiperOrigin-RevId: 408701427\nChange-Id: Idf31e7f0bf18ca824d084fdd355e1f653f145c20",
        "target": 1,
        "irrelevant": 1,
        "func_before": "int64_t OpLevelCostEstimator::CalculateOutputSize(const OpInfo& op_info,\n                                                  bool* found_unknown_shapes) {\n  int64_t total_output_size = 0;\n  // Use float as default for calculations.\n  for (const auto& output : op_info.outputs()) {\n    DataType dt = output.dtype();\n    const auto& original_output_shape = output.shape();\n    int64_t output_size = DataTypeSize(BaseType(dt));\n    int num_dims = std::max(1, original_output_shape.dim_size());\n    auto output_shape = MaybeGetMinimumShape(original_output_shape, num_dims,\n                                             found_unknown_shapes);\n    for (const auto& dim : output_shape.dim()) {\n      output_size *= dim.size();\n    }\n    total_output_size += output_size;\n    VLOG(1) << \"Output Size: \" << output_size\n            << \" Total Output Size:\" << total_output_size;\n  }\n  return total_output_size;\n}",
        "func_hash": 227979151511968058279234771045953567425,
        "file_name": "op_level_cost_estimator.cc",
        "file_hash": 48778957117537504326053940607597623217,
        "cwe": [
            "CWE-190"
        ],
        "cve": "CVE-2022-23576",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The implementation of `OpLevelCostEstimator::CalculateOutputSize` is vulnerable to an integer overflow if an attacker can create an operation which would involve tensors with large enough number of elements. We can have a large enough number of dimensions in `output_shape.dim()` or just a small number of dimensions being large enough to cause an overflow in the multiplication. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23576",
        "func_name": "OpLevelCostEstimator::CalculateOutputSize",
        "diff": [
            "diff --git a/tensorflow/core/grappler/costs/BUILD b/tensorflow/core/grappler/costs/BUILD\nindex 66e0c6cd7c5f15..b267a0f2787f34 100644\n--- a/tensorflow/core/grappler/costs/BUILD\n+++ b/tensorflow/core/grappler/costs/BUILD\n@@ -340,6 +340,7 @@ cc_library(\n         \"//tensorflow/core:lib\",\n         \"//tensorflow/core:protos_all_cc\",\n         \"//tensorflow/core/grappler/clusters:utils\",\n+        \"//tensorflow/core/util:overflow\",\n     ] + tf_protos_grappler(),\n )\n \ndiff --git a/tensorflow/core/grappler/costs/op_level_cost_estimator.cc b/tensorflow/core/grappler/costs/op_level_cost_estimator.cc\nindex 10acbf54595da4..5e328542ab1452 100644\n--- a/tensorflow/core/grappler/costs/op_level_cost_estimator.cc\n+++ b/tensorflow/core/grappler/costs/op_level_cost_estimator.cc\n@@ -27,6 +27,7 @@ limitations under the License.\n #include \"tensorflow/core/grappler/costs/op_context.h\"\n #include \"tensorflow/core/grappler/costs/utils.h\"\n #include \"tensorflow/core/platform/errors.h\"\n+#include \"tensorflow/core/util/overflow.h\"\n \n namespace tensorflow {\n namespace grappler {\n@@ -1607,7 +1608,14 @@ int64_t OpLevelCostEstimator::CalculateOutputSize(const OpInfo& op_info,\n     auto output_shape = MaybeGetMinimumShape(original_output_shape, num_dims,\n                                              found_unknown_shapes);\n     for (const auto& dim : output_shape.dim()) {\n-      output_size *= dim.size();\n+      int64_t new_output_size =\n+          MultiplyWithoutOverflow(output_size, dim.size());\n+      if (new_output_size < 0) {\n+        VLOG(1) << \"Overflow encountered when estimating cost, multiplying \"\n+                << output_size << \" with \" << dim.size();\n+        return -1;\n+      }\n+      output_size = new_output_size;\n     }\n     total_output_size += output_size;\n     VLOG(1) << \"Output Size: \" << output_size\n"
        ],
        "func_after": []
    },
    {
        "idx": 195343,
        "project": "tensorflow",
        "commit_id": "002408c3696b173863228223d535f9de72a101a9",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/002408c3696b173863228223d535f9de72a101a9",
        "commit_message": "Add negative bound check for row and column pooling_sequence in FractionalAvgPoolGrad op to avoid out of bound heap access\n\nPiperOrigin-RevId: 413837346\nChange-Id: I2b86034101df31bee161abcb781755e236c7bccd",
        "target": 1,
        "irrelevant": 1,
        "func_before": "  void Compute(OpKernelContext* context) override {\n    // Here's the basic idea:\n    // Batch and depth dimension are independent from row and col dimension. And\n    // because FractionalAvgPool currently only support pooling along row and\n    // col, we can basically think of this 4D tensor backpropagation as\n    // operation of a series of 2D planes.\n    //\n    // For each element of a 'slice' (2D plane) of output_backprop, we need to\n    // figure out its contributors when doing FractionalAvgPool operation. This\n    // can be done based on row_pooling_sequence, col_pooling_seq and\n    // overlapping.\n    // Once we figure out the original contributors, we just need to evenly\n    // divide the value of this element among these contributors.\n    //\n    // Internally, we divide the out_backprop tensor and store it in a temporary\n    // tensor of double type. And cast it to the corresponding type.\n    typedef Eigen::Map<const Eigen::Matrix<T, Eigen::Dynamic, Eigen::Dynamic>>\n        ConstEigenMatrixMap;\n    typedef Eigen::Map<Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic>>\n        EigenDoubleMatrixMap;\n\n    // Grab the inputs.\n    const Tensor& orig_input_tensor_shape = context->input(0);\n    OP_REQUIRES(context,\n                orig_input_tensor_shape.dims() == 1 &&\n                    orig_input_tensor_shape.NumElements() == 4,\n                errors::InvalidArgument(\"original input tensor shape must be\"\n                                        \"1-dimensional and 4 elements\"));\n    const Tensor& out_backprop = context->input(1);\n    const Tensor& row_seq_tensor = context->input(2);\n    const Tensor& col_seq_tensor = context->input(3);\n\n    const int64_t out_batch = out_backprop.dim_size(0);\n    const int64_t out_rows = out_backprop.dim_size(1);\n    const int64_t out_cols = out_backprop.dim_size(2);\n    const int64_t out_depth = out_backprop.dim_size(3);\n\n    OP_REQUIRES(context, row_seq_tensor.NumElements() > out_rows,\n                errors::InvalidArgument(\"Given out_backprop shape \",\n                                        out_backprop.shape().DebugString(),\n                                        \", row_seq_tensor must have at least \",\n                                        out_rows + 1, \" elements, but got \",\n                                        row_seq_tensor.NumElements()));\n    OP_REQUIRES(context, col_seq_tensor.NumElements() > out_cols,\n                errors::InvalidArgument(\"Given out_backprop shape \",\n                                        out_backprop.shape().DebugString(),\n                                        \", col_seq_tensor must have at least \",\n                                        out_cols + 1, \" elements, but got \",\n                                        col_seq_tensor.NumElements()));\n\n    auto row_seq_tensor_flat = row_seq_tensor.flat<int64_t>();\n    auto col_seq_tensor_flat = col_seq_tensor.flat<int64_t>();\n    auto orig_input_tensor_shape_flat = orig_input_tensor_shape.flat<int64_t>();\n\n    const int64_t in_batch = orig_input_tensor_shape_flat(0);\n    const int64_t in_rows = orig_input_tensor_shape_flat(1);\n    const int64_t in_cols = orig_input_tensor_shape_flat(2);\n    const int64_t in_depth = orig_input_tensor_shape_flat(3);\n    OP_REQUIRES(\n        context, in_batch != 0,\n        errors::InvalidArgument(\"Batch dimension of input must not be 0\"));\n    OP_REQUIRES(\n        context, in_rows != 0,\n        errors::InvalidArgument(\"Rows dimension of input must not be 0\"));\n    OP_REQUIRES(\n        context, in_cols != 0,\n        errors::InvalidArgument(\"Columns dimension of input must not be 0\"));\n    OP_REQUIRES(\n        context, in_depth != 0,\n        errors::InvalidArgument(\"Depth dimension of input must not be 0\"));\n\n    constexpr int tensor_in_and_out_dims = 4;\n    // Transform orig_input_tensor_shape into TensorShape\n    TensorShape in_shape;\n    for (auto i = 0; i < tensor_in_and_out_dims; ++i) {\n      in_shape.AddDim(orig_input_tensor_shape_flat(i));\n    }\n\n    // Create intermediate in_backprop.\n    Tensor in_backprop_tensor_temp;\n    OP_REQUIRES_OK(context, context->forward_input_or_allocate_temp(\n                                {0}, DataTypeToEnum<double>::v(), in_shape,\n                                &in_backprop_tensor_temp));\n    in_backprop_tensor_temp.flat<double>().setZero();\n    // Transform 4D tensor to 2D matrix.\n    EigenDoubleMatrixMap in_backprop_tensor_temp_mat(\n        in_backprop_tensor_temp.flat<double>().data(), in_depth,\n        in_cols * in_rows * in_batch);\n    ConstEigenMatrixMap out_backprop_mat(out_backprop.flat<T>().data(),\n                                         out_depth,\n                                         out_cols * out_rows * out_batch);\n    // Loop through each element of out_backprop and evenly distribute the\n    // element to the corresponding pooling cell.\n    const int64_t in_max_row_index = in_rows - 1;\n    const int64_t in_max_col_index = in_cols - 1;\n    for (int64_t b = 0; b < out_batch; ++b) {\n      for (int64_t r = 0; r < out_rows; ++r) {\n        const int64_t in_row_start = row_seq_tensor_flat(r);\n        int64_t in_row_end = overlapping_ ? row_seq_tensor_flat(r + 1)\n                                          : row_seq_tensor_flat(r + 1) - 1;\n        in_row_end = std::min(in_row_end, in_max_row_index);\n        for (int64_t c = 0; c < out_cols; ++c) {\n          const int64_t in_col_start = col_seq_tensor_flat(c);\n          int64_t in_col_end = overlapping_ ? col_seq_tensor_flat(c + 1)\n                                            : col_seq_tensor_flat(c + 1) - 1;\n          in_col_end = std::min(in_col_end, in_max_col_index);\n\n          const int64_t num_elements_in_pooling_cell =\n              (in_row_end - in_row_start + 1) * (in_col_end - in_col_start + 1);\n          const int64_t out_index = (b * out_rows + r) * out_cols + c;\n          // Now we can evenly distribute out_backprop(b, h, w, *) to\n          // in_backprop(b, hs:he, ws:we, *).\n          for (int64_t in_r = in_row_start; in_r <= in_row_end; ++in_r) {\n            for (int64_t in_c = in_col_start; in_c <= in_col_end; ++in_c) {\n              const int64_t in_index = (b * in_rows + in_r) * in_cols + in_c;\n              // Walk through each channel (depth).\n              for (int64_t d = 0; d < out_depth; ++d) {\n                const double out_backprop_element = static_cast<double>(\n                    out_backprop_mat.coeffRef(d, out_index));\n                double& in_backprop_ref =\n                    in_backprop_tensor_temp_mat.coeffRef(d, in_index);\n                in_backprop_ref +=\n                    out_backprop_element / num_elements_in_pooling_cell;\n              }\n            }\n          }\n        }\n      }\n    }\n\n    // Depending on the type, cast double to type T.\n    Tensor* in_backprop_tensor = nullptr;\n    OP_REQUIRES_OK(context, context->forward_input_or_allocate_output(\n                                {0}, 0, in_shape, &in_backprop_tensor));\n    auto in_backprop_tensor_flat = in_backprop_tensor->flat<T>();\n    auto in_backprop_tensor_temp_flat = in_backprop_tensor_temp.flat<double>();\n    for (int64_t i = 0; i < in_backprop_tensor_flat.size(); ++i) {\n      in_backprop_tensor_flat(i) =\n          static_cast<T>(in_backprop_tensor_temp_flat(i));\n    }\n  }",
        "func_hash": 91555834572386312187860770421206034544,
        "file_name": "fractional_avg_pool_op.cc",
        "file_hash": 221866619851129952189561551151828727755,
        "cwe": [
            "CWE-125"
        ],
        "cve": "CVE-2022-21730",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The implementation of `FractionalAvgPoolGrad` does not consider cases where the input tensors are invalid allowing an attacker to read from outside of bounds of heap. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-21730",
        "func_name": "Compute",
        "diff": [
            "diff --git a/tensorflow/core/kernels/fractional_avg_pool_op.cc b/tensorflow/core/kernels/fractional_avg_pool_op.cc\nindex afc72287edadc1..b3e65aeaee22f8 100644\n--- a/tensorflow/core/kernels/fractional_avg_pool_op.cc\n+++ b/tensorflow/core/kernels/fractional_avg_pool_op.cc\n@@ -311,15 +311,26 @@ class FractionalAvgPoolGradOp : public OpKernel {\n     for (int64_t b = 0; b < out_batch; ++b) {\n       for (int64_t r = 0; r < out_rows; ++r) {\n         const int64_t in_row_start = row_seq_tensor_flat(r);\n+\n         int64_t in_row_end = overlapping_ ? row_seq_tensor_flat(r + 1)\n                                           : row_seq_tensor_flat(r + 1) - 1;\n         in_row_end = std::min(in_row_end, in_max_row_index);\n+        OP_REQUIRES(context, in_row_start >= 0 && in_row_end >= 0,\n+                    errors::InvalidArgument(\n+                        \"Row sequence tensor values must not be negative, got \",\n+                        row_seq_tensor_flat));\n+\n         for (int64_t c = 0; c < out_cols; ++c) {\n           const int64_t in_col_start = col_seq_tensor_flat(c);\n           int64_t in_col_end = overlapping_ ? col_seq_tensor_flat(c + 1)\n                                             : col_seq_tensor_flat(c + 1) - 1;\n           in_col_end = std::min(in_col_end, in_max_col_index);\n \n+          OP_REQUIRES(\n+              context, in_col_start >= 0 && in_col_end >= 0,\n+              errors::InvalidArgument(\n+                  \"Column sequence tensor values must not be negative, got \",\n+                  col_seq_tensor_flat));\n           const int64_t num_elements_in_pooling_cell =\n               (in_row_end - in_row_start + 1) * (in_col_end - in_col_start + 1);\n           const int64_t out_index = (b * out_rows + r) * out_cols + c;\ndiff --git a/tensorflow/python/kernel_tests/nn_ops/fractional_avg_pool_op_test.py b/tensorflow/python/kernel_tests/nn_ops/fractional_avg_pool_op_test.py\nindex ae75c424264622..7b153ae1ed7084 100644\n--- a/tensorflow/python/kernel_tests/nn_ops/fractional_avg_pool_op_test.py\n+++ b/tensorflow/python/kernel_tests/nn_ops/fractional_avg_pool_op_test.py\n@@ -20,6 +20,7 @@\n \n from tensorflow.python.framework import constant_op\n from tensorflow.python.framework import dtypes\n+from tensorflow.python.framework import errors\n from tensorflow.python.framework import test_util\n from tensorflow.python.ops import array_ops\n from tensorflow.python.ops import gen_nn_ops\n@@ -306,6 +307,32 @@ def testDifferentInputTensorShape(self):\n           input_b, row_seq, col_seq, overlapping)\n       self.assertSequenceEqual(expected.shape, actual.shape)\n \n+  def testNegativeSeqValuesForGradOp(self):\n+    with self.assertRaisesRegex(\n+        errors.InvalidArgumentError,\n+        r\"Row sequence tensor values must not be negative.*\"):\n+      y = nn_ops.gen_nn_ops.fractional_avg_pool_grad(\n+          orig_input_tensor_shape=[2, 2, 2, 2],\n+          out_backprop=[[[[1, 2], [3, 4], [5, 6]], [[7, 8], [9, 10], [11,\n+                                                                      12]]]],\n+          row_pooling_sequence=[-10, 1, 2, 3],\n+          col_pooling_sequence=[1, 2, 3, 4],\n+          overlapping=True)\n+\n+      self.evaluate(y)\n+      with self.assertRaisesRegex(\n+          errors.InvalidArgumentError,\n+          r\"Column sequence tensor values must not be negative.*\"):\n+        z = nn_ops.gen_nn_ops.fractional_avg_pool_grad(\n+            orig_input_tensor_shape=[2, 2, 2, 2],\n+            out_backprop=[[[[1, 2], [3, 4], [5, 6]], [[7, 8], [9, 10], [11,\n+                                                                        12]]]],\n+            row_pooling_sequence=[10, 1, 2, 3],\n+            col_pooling_sequence=[1, 2, -3, 4],\n+            overlapping=True)\n+\n+        self.evaluate(z)\n+\n \n class FractionalAvgPoolGradTest(test.TestCase):\n   \"\"\"Tests for FractionalAvgPoolGrad.\n"
        ],
        "func_after": []
    },
    {
        "idx": 197318,
        "project": "tensorflow",
        "commit_id": "cff267650c6a1b266e4b4500f69fbc49cdd773c5",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/cff267650c6a1b266e4b4500f69fbc49cdd773c5",
        "commit_message": "Fix tf.raw_ops.DeleteSessionTensor vulnerability with invalid `handle`.\n\nCheck that `handle` input is actually a scalar before treating it as such.\n\nPiperOrigin-RevId: 445228994",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor& handle = ctx->input(0);\n    const string& name = handle.scalar<tstring>()();\n    auto session_state = ctx->session_state();\n    OP_REQUIRES(ctx, session_state != nullptr,\n                errors::FailedPrecondition(\n                    \"DeleteSessionTensor called on null session state\"));\n    OP_REQUIRES_OK(ctx, session_state->DeleteTensor(name));\n  }",
        "func_hash": 169160525191336828594160871802042029438,
        "file_name": "session_ops.cc",
        "file_hash": 314434656782851829699760158294919826764,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2022-29194",
        "cve_desc": "TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, the implementation of `tf.raw_ops.DeleteSessionTensor` does not fully validate the input arguments. This results in a `CHECK`-failure which can be used to trigger a denial of service attack. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-29194",
        "func_name": "Compute",
        "diff": [
            "diff --git a/tensorflow/core/kernels/session_ops.cc b/tensorflow/core/kernels/session_ops.cc\nindex bb47288b1575ad..2feb79a24e329e 100644\n--- a/tensorflow/core/kernels/session_ops.cc\n+++ b/tensorflow/core/kernels/session_ops.cc\n@@ -134,6 +134,8 @@ class DeleteSessionTensorOp : public OpKernel {\n \n   void Compute(OpKernelContext* ctx) override {\n     const Tensor& handle = ctx->input(0);\n+    OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(handle.shape()),\n+                errors::InvalidArgument(\"`handle` must be scalar\"));\n     const string& name = handle.scalar<tstring>()();\n     auto session_state = ctx->session_state();\n     OP_REQUIRES(ctx, session_state != nullptr,\n"
        ],
        "func_after": []
    },
    {
        "idx": 197326,
        "project": "tensorflow",
        "commit_id": "f09caa532b6e1ac8d2aa61b7832c78c5b79300c6",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/f09caa532b6e1ac8d2aa61b7832c78c5b79300c6",
        "commit_message": "Fix EinsumHelper::ParseEquation to avoid uninitialized accesses.\n\nEinsumHelper::ParseEquation is supposed to return true or false in\ninput_has_ellipsis and output_has_ellipsis to indicate whether there is\nellipsis in the inputs and output. Previously, when there is no ellipsis in the\ninputs or output, the routine doesn't assign false to the variables. This\nchange initializes the two variables with false to fix the problem.\nPiperOrigin-RevId: 391772004\nChange-Id: I17b6c88aadef4131470378e48cced054bf252e86",
        "target": 1,
        "irrelevant": 1,
        "func_before": "  static Status ParseEquation(const string& equation,\n                              OperandLabels* input_labels,\n                              Labels* output_labels,\n                              std::vector<DimensionType>* label_types,\n                              OperandLabelCounts* input_label_counts,\n                              LabelCounts* output_label_counts,\n                              gtl::InlinedVector<bool, 2>* input_has_ellipsis,\n                              bool* output_has_ellipsis) {\n    gtl::InlinedVector<string, 2> input_str;\n    string output_str;\n    TF_RETURN_IF_ERROR(ParseEinsumEquation(equation, &input_str, &output_str));\n\n    // Temporary map from single character labels to (consecutive) integer\n    // labels.\n    absl::flat_hash_map<char, int> label_mapping;\n    int num_inputs = input_str.size();\n    input_labels->resize(num_inputs);\n\n    // Map from single characters to integer labels.\n    for (int i = 0; i < num_inputs; ++i) {\n      MapToLabels(input_str[i], &input_labels->at(i), &label_mapping);\n    }\n    MapToLabels(output_str, output_labels, &label_mapping);\n\n    // Compute counts for input and output labels.\n    int num_labels = label_mapping.size();\n    input_label_counts->resize(num_inputs);\n    input_has_ellipsis->resize(num_inputs);\n    for (int i = 0; i < num_inputs; ++i) {\n      input_label_counts->at(i).resize(num_labels);\n      for (const int label : input_labels->at(i)) {\n        if (label != kEllipsisLabel)\n          input_label_counts->at(i)[label] += 1;\n        else\n          input_has_ellipsis->at(i) = true;\n      }\n    }\n    output_label_counts->resize(num_labels);\n    for (const int label : *output_labels) {\n      if (label != kEllipsisLabel)\n        output_label_counts->at(label) += 1;\n      else\n        *output_has_ellipsis = true;\n    }\n\n    // Map each label to a unique DimensionType.\n    label_types->resize(num_labels);\n    for (int label = 0; label < num_labels; ++label) {\n      if (label == kEllipsisLabel) continue;\n      bool removed = (*output_label_counts)[label] == 0;\n      bool unique = num_inputs == 1 || (*input_label_counts)[0][label] == 0 ||\n                    (*input_label_counts)[1][label] == 0;\n      (*label_types)[label] = GetDimensionType(removed, unique);\n    }\n    return Status::OK();\n  }",
        "func_hash": 245883315476396879421677768643467596549,
        "file_name": "einsum_op_impl.h",
        "file_hash": 325930431028150928108252149027684363493,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2021-41201",
        "cve_desc": "TensorFlow is an open source platform for machine learning. In affeced versions during execution, `EinsumHelper::ParseEquation()` is supposed to set the flags in `input_has_ellipsis` vector and `*output_has_ellipsis` boolean to indicate whether there is ellipsis in the corresponding inputs and output. However, the code only changes these flags to `true` and never assigns `false`. This results in unitialized variable access if callers assume that `EinsumHelper::ParseEquation()` always sets these flags. The fix will be included in TensorFlow 2.7.0. We will also cherrypick this commit on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-41201",
        "func_name": "ParseEquation",
        "diff": [
            "diff --git a/tensorflow/core/kernels/linalg/einsum_op_impl.h b/tensorflow/core/kernels/linalg/einsum_op_impl.h\nindex 5c41e38954d626..6f64334555131c 100644\n--- a/tensorflow/core/kernels/linalg/einsum_op_impl.h\n+++ b/tensorflow/core/kernels/linalg/einsum_op_impl.h\n@@ -153,6 +153,7 @@ struct EinsumHelper {\n     input_has_ellipsis->resize(num_inputs);\n     for (int i = 0; i < num_inputs; ++i) {\n       input_label_counts->at(i).resize(num_labels);\n+      input_has_ellipsis->at(i) = false;\n       for (const int label : input_labels->at(i)) {\n         if (label != kEllipsisLabel)\n           input_label_counts->at(i)[label] += 1;\n@@ -161,6 +162,7 @@ struct EinsumHelper {\n       }\n     }\n     output_label_counts->resize(num_labels);\n+    *output_has_ellipsis = false;\n     for (const int label : *output_labels) {\n       if (label != kEllipsisLabel)\n         output_label_counts->at(label) += 1;\n"
        ],
        "func_after": []
    },
    {
        "idx": 197359,
        "project": "tensorflow",
        "commit_id": "68867bf01239d9e1048f98cbad185bf4761bedd3",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/68867bf01239d9e1048f98cbad185bf4761bedd3",
        "commit_message": "Prevent unitialized variable use in grappler.\n\nPiperOrigin-RevId: 399702928\nChange-Id: Id7e75451fbff297692dfb687f60ea04b25c96b24",
        "target": 1,
        "irrelevant": 1,
        "func_before": "Status AutoParallel::Initialize(const GrapplerItem& item) {\n  num_gpus_ = GetNumAvailableGPUs();\n  LOG(INFO) << \"Number of GPUs: \" << num_gpus_;\n  item_ = &item;\n  graph_ = item.graph;\n  LOG(INFO) << \"Original graph size: \" << graph_.node_size();\n  if (item.fetch.empty()) {\n    return Status(error::INVALID_ARGUMENT, \"No fetch nodes provided.\");\n  }\n\n  if (item.MainVariables().empty()) {\n    return Status(error::INVALID_ARGUMENT, \"No variables provided.\");\n  }\n\n  for (const auto& init : item.init_ops) {\n    VLOG(1) << \"Init node: \" << init;\n  }\n\n  for (const auto& fetch : item.fetch) {\n    VLOG(1) << \"Fetch node: \" << fetch;\n  }\n\n  for (const auto& var : item.MainVariables()) {\n    VLOG(2) << \"Variable: \" << var->name();\n  }\n\n  const std::set<string> apply_gradients_ops = {\"ApplyGradientDescent\",\n                                                \"ApplyProximalGradientDescent\",\n                                                \"ApplyAdadelta\",\n                                                \"ApplyAdagrad\",\n                                                \"ApplyProximalAdagrad\",\n                                                \"ApplyAdagradDA\",\n                                                \"ApplyFtrl\",\n                                                \"ApplyMomentum\",\n                                                \"ApplyAdam\",\n                                                \"ApplyRMSProp\",\n                                                \"ApplyCenteredRMSProp\"};\n  for (int i = 0; i < graph_.node_size(); i++) {\n    all_nodes_.insert(\n        std::make_pair(graph_.node(i).name(), graph_.mutable_node(i)));\n    if (apply_gradients_ops.find(graph_.node(i).op()) !=\n        apply_gradients_ops.end()) {\n      apply_gradients_nodes_.insert(graph_.node(i).name());\n      VLOG(2) << \"Apply gradients node: \" << graph_.node(i).name();\n    }\n  }\n\n  auto div_const_node = AddNodeDivConst();\n  all_nodes_.insert(std::make_pair(div_const_node->name(), div_const_node));\n  std::map<string, int> gradient_pos = {{\"ApplyGradientDescent\", 2},\n                                        {\"ApplyProximalGradientDescent\", 4},\n                                        {\"ApplyAdadelta\", 6},\n                                        {\"ApplyAdagrad\", 3},\n                                        {\"ApplyProximalAdagrad\", 5},\n                                        {\"ApplyAdagradDA\", 3},\n                                        {\"ApplyFtrl\", 3},\n                                        {\"ApplyMomentum\", 3},\n                                        {\"ApplyAdam\", 9},\n                                        {\"ApplyRMSProp\", 7},\n                                        {\"ApplyCenteredRMSProp\", 8}};\n  for (const auto& apply_gradient_node_name : apply_gradients_nodes_) {\n    auto apply_gradients_op = all_nodes_[apply_gradient_node_name]->op();\n    auto apply_gradients_node = all_nodes_[apply_gradient_node_name];\n\n    auto div_node = AddNodeDiv(\n        apply_gradient_node_name,\n        apply_gradients_node->input(gradient_pos[apply_gradients_op]),\n        div_const_node->name());\n    all_nodes_.insert(std::make_pair(div_node->name(), div_node));\n    *apply_gradients_node->mutable_input(gradient_pos[apply_gradients_op]) =\n        div_node->name();\n  }\n  LOG(INFO) << \"Graph size after adding div nodes: \" << all_nodes_.size();\n\n  std::vector<const NodeDef*> train_nodes;\n  TF_RETURN_IF_ERROR(ComputeTransitiveFanin(graph_, item.fetch, &train_nodes));\n  LOG(INFO) << \"Number of training nodes: \" << train_nodes.size();\n\n  const NodeDef* dequeue_node;\n  for (const auto& train_node : train_nodes) {\n    if (IsDequeueOp(*train_node)) {\n      dequeue_node = train_node;\n      break;\n    }\n  }\n\n  std::vector<const NodeDef*> input_nodes;\n  if (dequeue_node) {\n    LOG(INFO) << \"Dequeue node: \" << dequeue_node->name();\n    TF_RETURN_IF_ERROR(ComputeTransitiveFanin(graph_, {dequeue_node->name()},\n                                              {}, &input_nodes));\n  }\n  LOG(INFO) << \"Number of input nodes: \" << input_nodes.size();\n\n  std::set<string> dont_replicate_nodes;\n  for (const auto& variable : item.MainVariables()) {\n    dont_replicate_nodes.insert(variable->name());\n  }\n\n  for (const auto& init : item.init_ops) {\n    dont_replicate_nodes.insert(NodeName(init));\n  }\n\n  // Don't replicate all input nodes, except the dequeue node.\n  for (const auto& input_node : input_nodes) {\n    if (input_node->name() != dequeue_node->name()) {\n      dont_replicate_nodes.insert(input_node->name());\n    }\n  }\n\n  for (const auto& node : train_nodes) {\n    if (dont_replicate_nodes.find(node->name()) == dont_replicate_nodes.end()) {\n      replica_nodes_.insert(node->name());\n    }\n  }\n  LOG(INFO) << \"Number of replica nodes: \" << replica_nodes_.size();\n\n  for (const auto& node : all_nodes_) {\n    if (replica_nodes_.find(node.first) == replica_nodes_.end()) {\n      shared_nodes_.insert(node.first);\n    }\n  }\n  LOG(INFO) << \"Number of shared nodes: \" << shared_nodes_.size();\n  return Status::OK();\n}",
        "func_hash": 251567762309539032923316029186493191559,
        "file_name": "auto_parallel.cc",
        "file_hash": 291637818016549468794962575194747709507,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2021-41225",
        "cve_desc": "TensorFlow is an open source platform for machine learning. In affected versions TensorFlow's Grappler optimizer has a use of unitialized variable. If the `train_nodes` vector (obtained from the saved model that gets optimized) does not contain a `Dequeue` node, then `dequeue_node` is left unitialized. The fix will be included in TensorFlow 2.7.0. We will also cherrypick this commit on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-41225",
        "func_name": "AutoParallel::Initialize",
        "diff": [
            "diff --git a/tensorflow/core/grappler/optimizers/auto_parallel.cc b/tensorflow/core/grappler/optimizers/auto_parallel.cc\nindex 097a57ce364b61..0865892796b898 100644\n--- a/tensorflow/core/grappler/optimizers/auto_parallel.cc\n+++ b/tensorflow/core/grappler/optimizers/auto_parallel.cc\n@@ -152,7 +152,7 @@ Status AutoParallel::Initialize(const GrapplerItem& item) {\n   TF_RETURN_IF_ERROR(ComputeTransitiveFanin(graph_, item.fetch, &train_nodes));\n   LOG(INFO) << \"Number of training nodes: \" << train_nodes.size();\n \n-  const NodeDef* dequeue_node;\n+  const NodeDef* dequeue_node = nullptr;\n   for (const auto& train_node : train_nodes) {\n     if (IsDequeueOp(*train_node)) {\n       dequeue_node = train_node;\ndiff --git a/tensorflow/core/grappler/optimizers/auto_parallel_test.cc b/tensorflow/core/grappler/optimizers/auto_parallel_test.cc\nindex 1c3186f1ee6e68..3af03a09613883 100644\n--- a/tensorflow/core/grappler/optimizers/auto_parallel_test.cc\n+++ b/tensorflow/core/grappler/optimizers/auto_parallel_test.cc\n@@ -126,6 +126,30 @@ TEST_F(AutoParallelTest, SimpleParallel) {\n   EXPECT_EQ(\"^AutoParallel-Control-Fetch\", node_gradient.input(0));\n }\n \n+TEST_F(AutoParallelTest, SimpleParallelNoDequeue) {\n+  tensorflow::Scope s = tensorflow::Scope::DisabledShapeInferenceScope();\n+  Output constant_a = ops::Const(s.WithOpName(\"constant_a\"), 1.0f, {1});\n+  Output constant_c = ops::Const(s.WithOpName(\"constant_c\"), 1.0f, {1});\n+  Output constant_b = ops::Const(s.WithOpName(\"constant_b\"), 1, {1});\n+  Output var = ops::Variable(s.WithOpName(\"var\"), {1}, DT_FLOAT);\n+  Output assign = ops::Assign(s.WithOpName(\"assign\"), {var}, {constant_a});\n+  Output add = ops::AddN(s.WithOpName(\"add\"), {constant_a, constant_c});\n+  Output learning_rate = ops::Const(s.WithOpName(\"learning_rate\"), 0.01f, {1});\n+  Output apply_gradient = ops::ApplyGradientDescent(\n+      s.WithOpName(\"apply_gradient\"), {var}, {learning_rate}, {add});\n+\n+  GrapplerItem item;\n+  item.init_ops.push_back(\"assign\");\n+  item.fetch.push_back(\"apply_gradient\");\n+  item.init_ops.push_back(\"assign\");\n+  TF_CHECK_OK(s.ToGraphDef(&item.graph));\n+\n+  AutoParallel parallel(2);\n+  GraphDef output;\n+  Status status = parallel.Optimize(nullptr, item, &output);\n+  TF_EXPECT_OK(status);\n+}\n+\n }  // namespace\n }  // namespace grappler\n }  // namespace tensorflow\n"
        ],
        "func_after": []
    },
    {
        "idx": 197395,
        "project": "tensorflow",
        "commit_id": "4071d8e2f6c45c1955a811fee757ca2adbe462c1",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/4071d8e2f6c45c1955a811fee757ca2adbe462c1",
        "commit_message": "Fix FPE issue with `tf.raw_ops.Reverse`.\n\nPiperOrigin-RevId: 371176973\nChange-Id: Ic6d483bfc95313ec2299c2d1c956cfe96c96626c",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext* context) override {\n    const Tensor& input = context->input(0);\n    const Tensor& dims = context->input(1);\n\n    if (TensorShapeUtils::IsScalar(input.shape())) {\n      context->set_output(0, input);\n    } else {\n      const int input_dims = input.dims();\n      OP_REQUIRES(context, TensorShapeUtils::IsVector(dims.shape()),\n                  errors::InvalidArgument(\"'dims' must be 1-dimension, not \",\n                                          dims.dims()));\n\n      OP_REQUIRES(\n          context, input_dims == dims.dim_size(0),\n          errors::InvalidArgument(\n              \"'dims' must have the same number of values as 'input' has \"\n              \"dimensions. 'input' has \",\n              input_dims, \"'dims' has \", dims.dim_size(0), \" values\"));\n      OP_REQUIRES(context, input_dims <= 8,\n                  errors::Unimplemented(\n                      \"reverse is not implemented for tensors of rank > 8.\"));\n\n      Tensor* output = nullptr;\n      OP_REQUIRES_OK(context,\n                     context->allocate_output(0, input.shape(), &output));\n\n#define HANDLE_REVERSE(NDIMS)                                               \\\n  case NDIMS:                                                               \\\n    HandleReverseCase<Device, T, NDIMS>(context, dims.vec<bool>(), output); \\\n    return;\n\n      switch (input_dims) {\n        HANDLE_REVERSE(0);\n        HANDLE_REVERSE(1);\n        HANDLE_REVERSE(2);\n        HANDLE_REVERSE(3);\n        HANDLE_REVERSE(4);\n        HANDLE_REVERSE(5);\n        HANDLE_REVERSE(6);\n        HANDLE_REVERSE(7);\n        HANDLE_REVERSE(8);\n      }\n#undef HANDLE_REVERSE\n    }\n  }",
        "func_hash": 320359893140451578623172737965362672352,
        "file_name": "reverse_op.cc",
        "file_hash": 11850357512767152498311955295464965693,
        "cwe": [
            "CWE-369"
        ],
        "cve": "CVE-2021-29556",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. An attacker can cause a denial of service via a FPE runtime error in `tf.raw_ops.Reverse`. This is because the implementation(https://github.com/tensorflow/tensorflow/blob/36229ea9e9451dac14a8b1f4711c435a1d84a594/tensorflow/core/kernels/reverse_op.cc#L75-L76) performs a division based on the first dimension of the tensor argument. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-29556",
        "func_name": "Compute",
        "diff": [
            "diff --git a/tensorflow/core/kernels/reverse_op.cc b/tensorflow/core/kernels/reverse_op.cc\nindex 5555a141b6c7bd..560fac71336679 100644\n--- a/tensorflow/core/kernels/reverse_op.cc\n+++ b/tensorflow/core/kernels/reverse_op.cc\n@@ -155,6 +155,12 @@ class ReverseOp : public OpKernel {\n \n   void Compute(OpKernelContext* context) override {\n     const Tensor& input = context->input(0);\n+    // If input is provided, check to make sure the first dimension is valid.\n+    if (input.dims() > 0) {\n+      OP_REQUIRES(\n+          context, input.dim_size(0) != 0,\n+          errors::InvalidArgument(\"Invalid input first dimension. Found 0.\"));\n+    }\n     const Tensor& dims = context->input(1);\n \n     if (TensorShapeUtils::IsScalar(input.shape())) {\n"
        ],
        "func_after": []
    },
    {
        "idx": 197466,
        "project": "tensorflow",
        "commit_id": "9e82dce6e6bd1f36a57e08fa85af213e2b2f2622",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/9e82dce6e6bd1f36a57e08fa85af213e2b2f2622",
        "commit_message": "Fix NPE in restoring code.\n\nPiperOrigin-RevId: 388303253\nChange-Id: Ia8c68568cb854bca538909a182b31a618d68ce55",
        "target": 1,
        "irrelevant": 0,
        "func_before": "void RestoreTensor(OpKernelContext* context,\n                   checkpoint::TensorSliceReader::OpenTableFunction open_func,\n                   int preferred_shard, bool restore_slice, int restore_index) {\n  const Tensor& file_pattern_t = context->input(0);\n  {\n    const int64_t size = file_pattern_t.NumElements();\n    OP_REQUIRES(\n        context, size == 1,\n        errors::InvalidArgument(\n            \"Input 0 (file_pattern) must be a string scalar; got a tensor of \",\n            size, \"elements\"));\n  }\n  const string& file_pattern = file_pattern_t.flat<tstring>()(0);\n\n  const Tensor& tensor_name_t = context->input(1);\n  const string& tensor_name = tensor_name_t.flat<tstring>()(restore_index);\n\n  // If we cannot find a cached reader we will allocate our own.\n  std::unique_ptr<checkpoint::TensorSliceReader> allocated_reader;\n\n  const checkpoint::TensorSliceReader* reader = nullptr;\n\n  if (context->slice_reader_cache()) {\n    reader = context->slice_reader_cache()->GetReader(file_pattern, open_func,\n                                                      preferred_shard);\n  }\n  if (!reader) {\n    allocated_reader.reset(new checkpoint::TensorSliceReader(\n        file_pattern, open_func, preferred_shard));\n    reader = allocated_reader.get();\n  }\n  OP_REQUIRES_OK(context, CHECK_NOTNULL(reader)->status());\n\n  // Get the shape and type from the save file.\n  DataType type;\n  TensorShape saved_shape;\n  OP_REQUIRES(\n      context, reader->HasTensor(tensor_name, &saved_shape, &type),\n      errors::NotFound(\"Tensor name \\\"\", tensor_name,\n                       \"\\\" not found in checkpoint files \", file_pattern));\n  OP_REQUIRES(\n      context, type == context->expected_output_dtype(restore_index),\n      errors::InvalidArgument(\"Expected to restore a tensor of type \",\n                              DataTypeString(context->expected_output_dtype(0)),\n                              \", got a tensor of type \", DataTypeString(type),\n                              \" instead: tensor_name = \", tensor_name));\n\n  // Shape of the output and slice to load.\n  TensorShape output_shape(saved_shape);\n  TensorSlice slice_to_load(saved_shape.dims());\n  if (restore_slice) {\n    const tstring& shape_spec =\n        context->input(2).flat<tstring>()(restore_index);\n    if (!shape_spec.empty()) {\n      TensorShape parsed_shape;\n      OP_REQUIRES_OK(context, checkpoint::ParseShapeAndSlice(\n                                  shape_spec, &parsed_shape, &slice_to_load,\n                                  &output_shape));\n      OP_REQUIRES(\n          context, parsed_shape.IsSameSize(saved_shape),\n          errors::InvalidArgument(\n              \"Shape in shape_and_slice spec does not match the shape in the \"\n              \"save file: \",\n              parsed_shape.DebugString(),\n              \", save file shape: \", saved_shape.DebugString()));\n    }\n  }\n\n  Tensor* t = nullptr;\n  OP_REQUIRES_OK(context,\n                 context->allocate_output(restore_index, output_shape, &t));\n\n  if (output_shape.num_elements() == 0) return;\n\n#define READER_COPY(T)                                                \\\n  case DataTypeToEnum<T>::value:                                      \\\n    OP_REQUIRES(context,                                              \\\n                reader->CopySliceData(tensor_name, slice_to_load,     \\\n                                      t->flat<T>().data()),           \\\n                errors::InvalidArgument(\"Error copying slice data\")); \\\n    break;\n\n  switch (type) {\n    TF_CALL_SAVE_RESTORE_TYPES(READER_COPY)\n    default:\n      context->SetStatus(errors::Unimplemented(\n          \"Restoring data type \", DataTypeString(type), \" not yet supported\"));\n  }\n#undef READER_COPY\n}",
        "func_hash": 252467620619020665053463064048093339685,
        "file_name": "save_restore_tensor.cc",
        "file_hash": 5161981891248921294380940461341356456,
        "cwe": [
            "CWE-476"
        ],
        "cve": "CVE-2021-37639",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. When restoring tensors via raw APIs, if the tensor name is not provided, TensorFlow can be tricked into dereferencing a null pointer. Alternatively, attackers can read memory outside the bounds of heap allocated data by providing some tensor names but not enough for a successful restoration. The [implementation](https://github.com/tensorflow/tensorflow/blob/47a06f40411a69c99f381495f490536972152ac0/tensorflow/core/kernels/save_restore_tensor.cc#L158-L159) retrieves the tensor list corresponding to the `tensor_name` user controlled input and immediately retrieves the tensor at the restoration index (controlled via `preferred_shard` argument). This occurs without validating that the provided list has enough values. If the list is empty this results in dereferencing a null pointer (undefined behavior). If, however, the list has some elements, if the restoration index is outside the bounds this results in heap OOB read. We have patched the issue in GitHub commit 9e82dce6e6bd1f36a57e08fa85af213e2b2f2622. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37639",
        "func_name": "RestoreTensor",
        "diff": [
            "diff --git a/tensorflow/core/kernels/save_restore_tensor.cc b/tensorflow/core/kernels/save_restore_tensor.cc\nindex 953c1dfb6290b4..dcbed428a5a5ac 100644\n--- a/tensorflow/core/kernels/save_restore_tensor.cc\n+++ b/tensorflow/core/kernels/save_restore_tensor.cc\n@@ -151,11 +151,18 @@ void RestoreTensor(OpKernelContext* context,\n         context, size == 1,\n         errors::InvalidArgument(\n             \"Input 0 (file_pattern) must be a string scalar; got a tensor of \",\n-            size, \"elements\"));\n+            size, \" elements\"));\n   }\n   const string& file_pattern = file_pattern_t.flat<tstring>()(0);\n \n   const Tensor& tensor_name_t = context->input(1);\n+  {\n+    const int64_t size = tensor_name_t.NumElements();\n+    OP_REQUIRES(context, size > restore_index,\n+                errors::InvalidArgument(\n+                    \"Input 1 (file_pattern) must be a have at least \",\n+                    restore_index + 1, \" elements\"));\n+  }\n   const string& tensor_name = tensor_name_t.flat<tstring>()(restore_index);\n \n   // If we cannot find a cached reader we will allocate our own.\n"
        ],
        "func_after": []
    },
    {
        "idx": 197499,
        "project": "gpac",
        "commit_id": "dc7de8d3d604426c7a6e628d90cb9fb88e7b4c2c",
        "project_url": "https://github.com/gpac/gpac",
        "commit_url": "https://github.com/gpac/gpac/commit/dc7de8d3d604426c7a6e628d90cb9fb88e7b4c2c",
        "commit_message": "fixed #2212",
        "target": 1,
        "irrelevant": 1,
        "func_before": "GF_Err BD_DecMFFieldVec(GF_BifsDecoder * codec, GF_BitStream *bs, GF_Node *node, GF_FieldInfo *field, Bool is_mem_com)\n{\n\tGF_Err e;\n\tu32 NbBits, nbFields;\n\tu32 i;\n\tGF_ChildNodeItem *last;\n\tu8 qp_local, qp_on, initial_qp;\n\tGF_FieldInfo sffield;\n\n\tmemset(&sffield, 0, sizeof(GF_FieldInfo));\n\tsffield.fieldIndex = field->fieldIndex;\n\tsffield.fieldType = gf_sg_vrml_get_sf_type(field->fieldType);\n\tsffield.NDTtype = field->NDTtype;\n\tsffield.name = field->name;\n\n\tinitial_qp = qp_local = qp_on = 0;\n\n\t//vector description - alloc the MF size before\n\tNbBits = gf_bs_read_int(bs, 5);\n\tnbFields = gf_bs_read_int(bs, NbBits);\n\n\tif (codec->ActiveQP) {\n\t\tinitial_qp = 1;\n\t\t/*this is for QP 14*/\n\t\tgf_bifs_dec_qp14_set_length(codec, nbFields);\n\t}\n\n\tif (field->fieldType != GF_SG_VRML_MFNODE) {\n\t\te = gf_sg_vrml_mf_alloc(field->far_ptr, field->fieldType, nbFields);\n\t\tif (e) return e;\n\n\t\tfor (i=0; i<nbFields; i++) {\n\t\t\te = gf_sg_vrml_mf_get_item(field->far_ptr, field->fieldType, & sffield.far_ptr, i);\n\t\t\tif (e) return e;\n\t\t\te = gf_bifs_dec_sf_field(codec, bs, node, &sffield, GF_FALSE);\n\t\t\tif (e) return e;\n\t\t}\n\t} else {\n\t\tlast = NULL;\n\t\tfor (i=0; i<nbFields; i++) {\n\t\t\tGF_Node *new_node = gf_bifs_dec_node(codec, bs, field->NDTtype);\n\t\t\tif (new_node) {\n\t\t\t\te = gf_node_register(new_node, is_mem_com ? NULL : node);\n\t\t\t\tif (e) return e;\n\n\t\t\t\tif (node) {\n\t\t\t\t\t/*special case for QP, register as the current QP*/\n\t\t\t\t\tif (gf_node_get_tag(new_node) == TAG_MPEG4_QuantizationParameter) {\n\t\t\t\t\t\tqp_local = ((M_QuantizationParameter *)new_node)->isLocal;\n\t\t\t\t\t\t/*we have a QP in the same scope, remove previous\n\t\t\t\t\t\tNB: we assume this is the right behavior, the spec doesn't say\n\t\t\t\t\t\twhether QP is cumulative or not*/\n\t\t\t\t\t\tif (qp_on) gf_bifs_dec_qp_remove(codec, GF_FALSE);\n\n\t\t\t\t\t\te = gf_bifs_dec_qp_set(codec, new_node);\n\t\t\t\t\t\tif (e) return e;\n\t\t\t\t\t\tqp_on = 1;\n\t\t\t\t\t\tif (qp_local) qp_local = 2;\n\t\t\t\t\t\tif (codec->force_keep_qp) {\n\t\t\t\t\t\t\te = gf_node_list_add_child_last(field->far_ptr, new_node, &last);\n\t\t\t\t\t\t\tif (e) return e;\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tgf_node_register(new_node, NULL);\n\t\t\t\t\t\t\tgf_node_unregister(new_node, node);\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\te = gf_node_list_add_child_last(field->far_ptr, new_node, &last);\n\t\t\t\t\t\tif (e) return e;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t/*proto coding*/\n\t\t\t\telse if (codec->pCurrentProto) {\n\t\t\t\t\t/*TO DO: what happens if this is a QP node on the interface ?*/\n\t\t\t\t\te = gf_node_list_add_child_last( (GF_ChildNodeItem **)field->far_ptr, new_node, &last);\n\t\t\t\t\tif (e) return e;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn codec->LastError ? codec->LastError : GF_NON_COMPLIANT_BITSTREAM;\n\t\t\t}\n\t\t}\n\t\t/*according to the spec, the QP applies to the current node itself, not just children.\n\t\tIf IsLocal is TRUE remove the node*/\n\t\tif (qp_on && qp_local) {\n\t\t\tif (qp_local == 2) {\n//\t\t\t\tqp_local = 1;\n\t\t\t} else {\n\t\t\t\t//ask to get rid of QP and reactivate if we had a QP when entering the node\n\t\t\t\tgf_bifs_dec_qp_remove(codec, initial_qp);\n//\t\t\t\tqp_local = 0;\n\t\t\t}\n\t\t}\n\t}\n\t/*finally delete the QP if any (local or not) as we get out of this node*/\n\tif (qp_on) gf_bifs_dec_qp_remove(codec, GF_TRUE);\n\treturn GF_OK;\n}",
        "func_hash": 181633592491715085539951152559525218380,
        "file_name": "field_decode.c",
        "file_hash": 27053036293524314453415412309723108309,
        "cwe": [
            "CWE-416"
        ],
        "cve": "CVE-2022-2453",
        "cve_desc": "Use After Free in GitHub repository gpac/gpac prior to 2.1-DEV.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-2453",
        "func_name": "BD_DecMFFieldVec",
        "diff": [
            "diff --git a/src/bifs/field_decode.c b/src/bifs/field_decode.c\nindex 5537da7d3d..65d045b02a 100644\n--- a/src/bifs/field_decode.c\n+++ b/src/bifs/field_decode.c\n@@ -427,64 +427,71 @@ GF_Err BD_DecMFFieldVec(GF_BifsDecoder * codec, GF_BitStream *bs, GF_Node *node,\n \t\t\te = gf_bifs_dec_sf_field(codec, bs, node, &sffield, GF_FALSE);\n \t\t\tif (e) return e;\n \t\t}\n-\t} else {\n-\t\tlast = NULL;\n-\t\tfor (i=0; i<nbFields; i++) {\n-\t\t\tGF_Node *new_node = gf_bifs_dec_node(codec, bs, field->NDTtype);\n-\t\t\tif (new_node) {\n-\t\t\t\te = gf_node_register(new_node, is_mem_com ? NULL : node);\n-\t\t\t\tif (e) return e;\n-\n-\t\t\t\tif (node) {\n-\t\t\t\t\t/*special case for QP, register as the current QP*/\n-\t\t\t\t\tif (gf_node_get_tag(new_node) == TAG_MPEG4_QuantizationParameter) {\n-\t\t\t\t\t\tqp_local = ((M_QuantizationParameter *)new_node)->isLocal;\n-\t\t\t\t\t\t/*we have a QP in the same scope, remove previous\n-\t\t\t\t\t\tNB: we assume this is the right behavior, the spec doesn't say\n-\t\t\t\t\t\twhether QP is cumulative or not*/\n-\t\t\t\t\t\tif (qp_on) gf_bifs_dec_qp_remove(codec, GF_FALSE);\n+\t\treturn GF_OK;\n+\t}\n \n-\t\t\t\t\t\te = gf_bifs_dec_qp_set(codec, new_node);\n-\t\t\t\t\t\tif (e) return e;\n-\t\t\t\t\t\tqp_on = 1;\n-\t\t\t\t\t\tif (qp_local) qp_local = 2;\n-\t\t\t\t\t\tif (codec->force_keep_qp) {\n-\t\t\t\t\t\t\te = gf_node_list_add_child_last(field->far_ptr, new_node, &last);\n-\t\t\t\t\t\t\tif (e) return e;\n-\t\t\t\t\t\t} else {\n-\t\t\t\t\t\t\tgf_node_register(new_node, NULL);\n-\t\t\t\t\t\t\tgf_node_unregister(new_node, node);\n-\t\t\t\t\t\t}\n-\t\t\t\t\t} else {\n+\te = GF_OK;\n+\tlast = NULL;\n+\tfor (i=0; i<nbFields; i++) {\n+\t\tGF_Node *new_node = gf_bifs_dec_node(codec, bs, field->NDTtype);\n+\t\tif (new_node) {\n+\t\t\te = gf_node_register(new_node, is_mem_com ? NULL : node);\n+\t\t\tif (e) goto exit;\n+\n+\t\t\tif (node) {\n+\t\t\t\t/*special case for QP, register as the current QP*/\n+\t\t\t\tif (gf_node_get_tag(new_node) == TAG_MPEG4_QuantizationParameter) {\n+\t\t\t\t\tqp_local = ((M_QuantizationParameter *)new_node)->isLocal;\n+\t\t\t\t\t/*we have a QP in the same scope, remove previous\n+\t\t\t\t\tNB: we assume this is the right behavior, the spec doesn't say\n+\t\t\t\t\twhether QP is cumulative or not*/\n+\t\t\t\t\tif (qp_on) gf_bifs_dec_qp_remove(codec, GF_FALSE);\n+\n+\t\t\t\t\te = gf_bifs_dec_qp_set(codec, new_node);\n+\t\t\t\t\tif (e) goto exit;\n+\t\t\t\t\tqp_on = 1;\n+\t\t\t\t\tif (qp_local) qp_local = 2;\n+\t\t\t\t\tif (codec->force_keep_qp) {\n \t\t\t\t\t\te = gf_node_list_add_child_last(field->far_ptr, new_node, &last);\n-\t\t\t\t\t\tif (e) return e;\n+\t\t\t\t\t\tif (e) goto exit;\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tgf_node_register(new_node, NULL);\n+\t\t\t\t\t\tgf_node_unregister(new_node, node);\n \t\t\t\t\t}\n+\t\t\t\t} else {\n+\t\t\t\t\te = gf_node_list_add_child_last(field->far_ptr, new_node, &last);\n+\t\t\t\t\tif (e) goto exit;\n \t\t\t\t}\n-\t\t\t\t/*proto coding*/\n-\t\t\t\telse if (codec->pCurrentProto) {\n-\t\t\t\t\t/*TO DO: what happens if this is a QP node on the interface ?*/\n-\t\t\t\t\te = gf_node_list_add_child_last( (GF_ChildNodeItem **)field->far_ptr, new_node, &last);\n-\t\t\t\t\tif (e) return e;\n-\t\t\t\t}\n-\t\t\t} else {\n-\t\t\t\treturn codec->LastError ? codec->LastError : GF_NON_COMPLIANT_BITSTREAM;\n \t\t\t}\n+\t\t\t/*proto coding*/\n+\t\t\telse if (codec->pCurrentProto) {\n+\t\t\t\t/*TO DO: what happens if this is a QP node on the interface ?*/\n+\t\t\t\te = gf_node_list_add_child_last( (GF_ChildNodeItem **)field->far_ptr, new_node, &last);\n+\t\t\t\tif (e)goto exit;\n+\t\t\t}\n+\t\t} else {\n+\t\t\te = codec->LastError ? codec->LastError : GF_NON_COMPLIANT_BITSTREAM;\n+\t\t\tgoto exit;\n \t\t}\n-\t\t/*according to the spec, the QP applies to the current node itself, not just children.\n-\t\tIf IsLocal is TRUE remove the node*/\n-\t\tif (qp_on && qp_local) {\n-\t\t\tif (qp_local == 2) {\n+\t}\n+\n+exit:\n+\n+\t/*according to the spec, the QP applies to the current node itself, not just children.\n+\tIf IsLocal is TRUE remove the node*/\n+\tif (qp_on && qp_local) {\n+\t\tif (qp_local == 2) {\n //\t\t\t\tqp_local = 1;\n-\t\t\t} else {\n-\t\t\t\t//ask to get rid of QP and reactivate if we had a QP when entering the node\n-\t\t\t\tgf_bifs_dec_qp_remove(codec, initial_qp);\n+\t\t} else {\n+\t\t\t//ask to get rid of QP and reactivate if we had a QP when entering the node\n+\t\t\tgf_bifs_dec_qp_remove(codec, initial_qp);\n //\t\t\t\tqp_local = 0;\n-\t\t\t}\n \t\t}\n \t}\n+\n \t/*finally delete the QP if any (local or not) as we get out of this node*/\n \tif (qp_on) gf_bifs_dec_qp_remove(codec, GF_TRUE);\n-\treturn GF_OK;\n+\treturn e;\n }\n \n \n"
        ],
        "func_after": []
    },
    {
        "idx": 197511,
        "project": "libjpeg",
        "commit_id": "187035b9726710b4fe11d565c7808975c930895d",
        "project_url": "https://github.com/thorfdbg/libjpeg",
        "commit_url": "https://github.com/thorfdbg/libjpeg/commit/187035b9726710b4fe11d565c7808975c930895d",
        "commit_message": "The code now checks for consistency of the MCU sizes across\nhierarchical levels, and fails in case they are different.",
        "target": 1,
        "irrelevant": 1,
        "func_before": "void HierarchicalBitmapRequester::PrepareForDecoding(void)\n{\n#if ACCUSOFT_CODE\n\n  UBYTE i;\n\n  BuildCommon();\n\n  if (m_ppDecodingMCU == NULL) {\n    m_ppDecodingMCU = (struct Line **)m_pEnviron->AllocMem(sizeof(struct Line *) * m_ucCount*8);\n    memset(m_ppDecodingMCU,0,sizeof(struct Line *) * m_ucCount * 8);\n  }\n\n  if (m_ppUpsampler == NULL) {\n    m_ppUpsampler = (class UpsamplerBase **)m_pEnviron->AllocMem(sizeof(class UpsamplerBase *) * m_ucCount);\n    memset(m_ppUpsampler,0,sizeof(class Upsampler *) * m_ucCount);\n\n    for(i = 0;i < m_ucCount;i++) {\n      class Component *comp = m_pFrame->ComponentOf(i);\n      UBYTE sx = comp->SubXOf();\n      UBYTE sy = comp->SubYOf();\n\n      if (sx > 1 || sy > 1) {\n        m_ppUpsampler[i] = UpsamplerBase::CreateUpsampler(m_pEnviron,sx,sy,\n                                                          m_ulPixelWidth,m_ulPixelHeight,\n                                                          m_pFrame->TablesOf()->isChromaCentered());\n        m_bSubsampling   = true;\n      }\n    }\n  }\n\n  if (m_pLargestScale)\n    m_pLargestScale->PrepareForDecoding();\n#endif\n}",
        "func_hash": 63468052144489012470048601021040613418,
        "file_name": "hierarchicalbitmaprequester.cpp",
        "file_hash": 34345221108539770458549868924228630502,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2022-31796",
        "cve_desc": "libjpeg 1.63 has a heap-based buffer over-read in HierarchicalBitmapRequester::FetchRegion in hierarchicalbitmaprequester.cpp because the MCU size can be different between allocation and use.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-31796",
        "func_name": "HierarchicalBitmapRequester::PrepareForDecoding",
        "diff": [
            "diff --git a/README b/README\nindex 40ef320..124c958 100644\n--- a/README\n+++ b/README\n@@ -460,6 +460,8 @@ out-of-bounds symbol triggered and out-of-bounds array access and could\n have crashed the decoder. The code is now more carefully changing the\r\n validity of the symbols and aborts with an error if it finds illegal\r\n codes.\r\n+The code now also checks the consistency of the MCU sizes in the\r\n+hierarchical process and fails if they differ across levels.\r\n \r\n --------------------------------------------------------------------------\r\n \r\ndiff --git a/README.history b/README.history\nindex 672d08d..09f0d87 100644\n--- a/README.history\n+++ b/README.history\n@@ -564,5 +564,7 @@ out-of-bounds symbol triggered and out-of-bounds array access and could\n have crashed the decoder. The code is now more carefully changing the\r\n validity of the symbols and aborts with an error if it finds illegal\r\n codes.\r\n+The code now also checks the consistency of the MCU sizes in the\r\n+hierarchical process and fails if they differ across levels.\r\n \r\n --------------------------------------------------------------------------\r\ndiff --git a/control/hierarchicalbitmaprequester.cpp b/control/hierarchicalbitmaprequester.cpp\nindex 14aefd1..bc636f6 100644\n--- a/control/hierarchicalbitmaprequester.cpp\n+++ b/control/hierarchicalbitmaprequester.cpp\n@@ -45,7 +45,7 @@\n ** decoding. It also keeps the top-level color transformer and the\n ** toplevel subsampling expander.\n **\n-** $Id: hierarchicalbitmaprequester.cpp,v 1.42 2020/04/08 10:05:41 thor Exp $\n+** $Id: hierarchicalbitmaprequester.cpp,v 1.43 2022/05/24 05:42:35 thor Exp $\n **\n */\n \n@@ -245,6 +245,16 @@ void HierarchicalBitmapRequester::PrepareForDecoding(void)\n       UBYTE sx = comp->SubXOf();\n       UBYTE sy = comp->SubYOf();\n \n+      if (m_pLargestScale) {\n+        class Frame *frame = m_pLargestScale->FrameOf();\n+        while(frame) {\n+          if (frame->ComponentOf(i)->SubXOf() != sx || frame->ComponentOf(i)->SubYOf() != sy)\n+            JPG_THROW(MALFORMED_STREAM,\"HierarchicalBitmapRequester::PrepareForDecoding\",\n+                      \"component subsampling is inconsistent across hierarchical levels\");\n+          frame = frame->NextOf();\n+        }\n+      }\n+\n       if (sx > 1 || sy > 1) {\n         m_ppUpsampler[i] = UpsamplerBase::CreateUpsampler(m_pEnviron,sx,sy,\n                                                           m_ulPixelWidth,m_ulPixelHeight,\n"
        ],
        "func_after": []
    },
    {
        "idx": 197517,
        "project": "glewlwyd",
        "commit_id": "0efd112bb62f566877750ad62ee828bff579b4e2",
        "project_url": "https://github.com/babelouest/glewlwyd",
        "commit_url": "https://github.com/babelouest/glewlwyd/commit/0efd112bb62f566877750ad62ee828bff579b4e2",
        "commit_message": "Fix fido2 signature validation bug",
        "target": 1,
        "irrelevant": 1,
        "func_before": "static json_t * check_attestation_fido_u2f(json_t * j_params, unsigned char * credential_id, size_t credential_id_len, unsigned char * cert_x, size_t cert_x_len, unsigned char * cert_y, size_t cert_y_len, cbor_item_t * att_stmt, unsigned char * rpid_hash, size_t rpid_hash_len, const unsigned char * client_data) {\n  json_t * j_error = json_array(), * j_return;\n  cbor_item_t * key = NULL, * x5c = NULL, * sig = NULL, * att_cert = NULL;\n  int i, ret;\n  char * message = NULL;\n  gnutls_pubkey_t pubkey = NULL;\n  gnutls_x509_crt_t cert = NULL;\n  gnutls_datum_t cert_dat, data, signature, cert_issued_by;\n  unsigned char data_signed[200], client_data_hash[32], cert_export[32], cert_export_b64[64];\n  size_t data_signed_offset = 0, client_data_hash_len = 32, cert_export_len = 32, cert_export_b64_len = 0;\n  \n  if (j_error != NULL) {\n    do {\n      if (gnutls_x509_crt_init(&cert)) {\n        json_array_append_new(j_error, json_string(\"check_attestation_fido_u2f - Error gnutls_x509_crt_init\"));\n        break;\n      }\n      if (gnutls_pubkey_init(&pubkey)) {\n        json_array_append_new(j_error, json_string(\"check_attestation_fido_u2f - Error gnutls_pubkey_init\"));\n        break;\n      }\n      \n      // Step 1\n      if (att_stmt == NULL || !cbor_isa_map(att_stmt) || cbor_map_size(att_stmt) != 2) {\n        json_array_append_new(j_error, json_string(\"CBOR map value 'attStmt' invalid format\"));\n        break;\n      }\n      for (i=0; i<2; i++) {\n        key = cbor_map_handle(att_stmt)[i].key;\n        if (cbor_isa_string(key)) {\n          if (0 == o_strncmp((const char *)cbor_string_handle(key), \"x5c\", MIN(o_strlen(\"x5c\"), cbor_string_length(key)))) {\n            x5c = cbor_map_handle(att_stmt)[i].value;\n          } else if (0 == o_strncmp((const char *)cbor_string_handle(key), \"sig\", MIN(o_strlen(\"sig\"), cbor_string_length(key)))) {\n            sig = cbor_map_handle(att_stmt)[i].value;\n          } else {\n            message = msprintf(\"attStmt map element %d key is not valid: '%.*s'\", i, cbor_string_length(key), cbor_string_handle(key));\n            json_array_append_new(j_error, json_string(message));\n            o_free(message);\n            break;\n          }\n        } else {\n          message = msprintf(\"attStmt map element %d key is not a string\", i);\n          json_array_append_new(j_error, json_string(message));\n          o_free(message);\n          break;\n        }\n      }\n      if (x5c == NULL || !cbor_isa_array(x5c) || cbor_array_size(x5c) != 1) {\n        json_array_append_new(j_error, json_string(\"CBOR map value 'x5c' invalid format\"));\n        break;\n      }\n      att_cert = cbor_array_get(x5c, 0);\n      cert_dat.data = cbor_bytestring_handle(att_cert);\n      cert_dat.size = cbor_bytestring_length(att_cert);\n      if ((ret = gnutls_x509_crt_import(cert, &cert_dat, GNUTLS_X509_FMT_DER)) < 0) {\n        json_array_append_new(j_error, json_string(\"Error importing x509 certificate\"));\n        y_log_message(Y_LOG_LEVEL_DEBUG, \"check_attestation_fido_u2f - Error gnutls_pcert_import_x509_raw: %d\", ret);\n        break;\n      }\n      if (json_object_get(j_params, \"root-ca-list\") != json_null() && validate_certificate_from_root(j_params, cert, x5c) != G_OK) {\n        json_array_append_new(j_error, json_string(\"Unrecognized certificate authority\"));\n        if (gnutls_x509_crt_get_issuer_dn2(cert, &cert_issued_by) >= 0) {\n          message = msprintf(\"Unrecognized certificate autohority: %.*s\", cert_issued_by.size, cert_issued_by.data);\n          y_log_message(Y_LOG_LEVEL_DEBUG, \"check_attestation_fido_u2f - %s\", message);\n          o_free(message);\n          gnutls_free(cert_issued_by.data);\n        } else {\n          y_log_message(Y_LOG_LEVEL_DEBUG, \"check_attestation_fido_u2f - Unrecognized certificate autohority (unable to get issuer dn)\");\n        }\n        break;\n      }\n      if ((ret = gnutls_pubkey_import_x509(pubkey, cert, 0)) < 0) {\n        json_array_append_new(j_error, json_string(\"Error importing x509 certificate\"));\n        y_log_message(Y_LOG_LEVEL_DEBUG, \"check_attestation_fido_u2f - Error gnutls_pubkey_import_x509: %d\", ret);\n        break;\n      }\n      if ((ret = gnutls_x509_crt_get_key_id(cert, GNUTLS_KEYID_USE_SHA256, cert_export, &cert_export_len)) < 0) {\n        json_array_append_new(j_error, json_string(\"Error exporting x509 certificate\"));\n        y_log_message(Y_LOG_LEVEL_DEBUG, \"check_attestation_fido_u2f - Error gnutls_x509_crt_get_key_id: %d\", ret);\n        break;\n      }\n      if (!o_base64_encode(cert_export, cert_export_len, cert_export_b64, &cert_export_b64_len)) {\n        json_array_append_new(j_error, json_string(\"Internal error\"));\n        y_log_message(Y_LOG_LEVEL_DEBUG, \"check_attestation_fido_u2f - Error o_base64_encode cert_export\");\n        break;\n      }\n      if (!generate_digest_raw(digest_SHA256, client_data, o_strlen((char *)client_data), client_data_hash, &client_data_hash_len)) {\n        json_array_append_new(j_error, json_string(\"Internal error\"));\n        y_log_message(Y_LOG_LEVEL_ERROR, \"check_attestation_fido_u2f - Error generate_digest_raw client_data\");\n        break;\n      }\n\n      if (sig == NULL || !cbor_isa_bytestring(sig)) {\n        json_array_append_new(j_error, json_string(\"Error sig is not a bytestring\"));\n        break;\n      }\n      \n      // Build bytestring to verify signature\n      data_signed[0] = 0x0;\n      data_signed_offset = 1;\n      \n      memcpy(data_signed+data_signed_offset, rpid_hash, rpid_hash_len);\n      data_signed_offset += rpid_hash_len;\n      \n      memcpy(data_signed+data_signed_offset, client_data_hash, client_data_hash_len);\n      data_signed_offset+=client_data_hash_len;\n      \n      memcpy(data_signed+data_signed_offset, credential_id, credential_id_len);\n      data_signed_offset+=credential_id_len;\n      \n      data_signed[data_signed_offset] = 0x04;\n      data_signed_offset++;\n      \n      memcpy(data_signed+data_signed_offset, cert_x, cert_x_len);\n      data_signed_offset+=cert_x_len;\n      \n      memcpy(data_signed+data_signed_offset, cert_y, cert_y_len);\n      data_signed_offset+=cert_y_len;\n        \n      // Let's verify sig over data_signed\n      data.data = data_signed;\n      data.size = data_signed_offset;\n      \n      signature.data = cbor_bytestring_handle(sig);\n      signature.size = cbor_bytestring_length(sig);\n      \n      if (gnutls_pubkey_verify_data2(pubkey, GNUTLS_SIGN_ECDSA_SHA256, 0, &data, &signature)) {\n        json_array_append_new(j_error, json_string(\"Invalid signature\"));\n      }\n      \n    } while (0);\n    \n    if (json_array_size(j_error)) {\n      j_return = json_pack(\"{sisO}\", \"result\", G_ERROR_PARAM, \"error\", j_error);\n    } else {\n      j_return = json_pack(\"{sis{ss%}}\", \"result\", G_OK, \"data\", \"certificate\", cert_export_b64, cert_export_b64_len);\n    }\n    json_decref(j_error);\n    gnutls_pubkey_deinit(pubkey);\n    gnutls_x509_crt_deinit(cert);\n    if (att_cert != NULL) {\n      cbor_decref(&att_cert);\n    }\n    \n  } else {\n    y_log_message(Y_LOG_LEVEL_ERROR, \"check_attestation_fido_u2f - Error allocating resources for j_error\");\n    j_return = json_pack(\"{si}\", \"result\", G_ERROR);\n  }\n  return j_return;\n}",
        "func_hash": 49651774096588820525757021354786445533,
        "file_name": "webauthn.c",
        "file_hash": 936897033794891929844876941061119587,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2021-40818",
        "cve_desc": "scheme/webauthn.c in Glewlwyd SSO server through 2.5.3 has a buffer overflow during FIDO2 signature validation in webauthn registration.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-40818",
        "func_name": "check_attestation_fido_u2f",
        "diff": [
            "diff --git a/src/scheme/webauthn.c b/src/scheme/webauthn.c\nindex 282405528..5b4eb8a4f 100644\n--- a/src/scheme/webauthn.c\n+++ b/src/scheme/webauthn.c\n@@ -1543,7 +1543,7 @@ static json_t * check_attestation_fido_u2f(json_t * j_params, unsigned char * cr\n   gnutls_pubkey_t pubkey = NULL;\n   gnutls_x509_crt_t cert = NULL;\n   gnutls_datum_t cert_dat, data, signature, cert_issued_by;\n-  unsigned char data_signed[200], client_data_hash[32], cert_export[32], cert_export_b64[64];\n+  unsigned char * data_signed = NULL, client_data_hash[32], cert_export[32], cert_export_b64[64];\n   size_t data_signed_offset = 0, client_data_hash_len = 32, cert_export_len = 32, cert_export_b64_len = 0;\n   \n   if (j_error != NULL) {\n@@ -1632,6 +1632,12 @@ static json_t * check_attestation_fido_u2f(json_t * j_params, unsigned char * cr\n         break;\n       }\n       \n+      if ((data_signed = o_malloc(rpid_hash_len+client_data_hash_len+credential_id_len+cert_x_len+cert_y_len+2)) == NULL) {\n+        y_log_message(Y_LOG_LEVEL_DEBUG, \"check_attestation_fido_u2f - Error allocating data_signed\");\n+        json_array_append_new(j_error, json_string(\"Internal error\"));\n+        break;\n+      }\n+      \n       // Build bytestring to verify signature\n       data_signed[0] = 0x0;\n       data_signed_offset = 1;\n@@ -1666,6 +1672,7 @@ static json_t * check_attestation_fido_u2f(json_t * j_params, unsigned char * cr\n       }\n       \n     } while (0);\n+    o_free(data_signed);\n     \n     if (json_array_size(j_error)) {\n       j_return = json_pack(\"{sisO}\", \"result\", G_ERROR_PARAM, \"error\", j_error);\n"
        ],
        "func_after": []
    },
    {
        "idx": 197518,
        "project": "tensorflow",
        "commit_id": "098e7762d909bac47ce1dbabe6dfd06294cb9d58",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/098e7762d909bac47ce1dbabe6dfd06294cb9d58",
        "commit_message": "Fix tf.raw_ops.QuantizeAndDequantizeV4Grad vulnerability with invalid input_min or input_max.\n\nCheck that argument is actually a scalar before treating it as such.\n\nPiperOrigin-RevId: 445198280",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor& gradient = ctx->input(0);\n    const Tensor& input = ctx->input(1);\n    Tensor* input_backprop = nullptr;\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_output(0, input.shape(), &input_backprop));\n    OP_REQUIRES(\n        ctx, axis_ >= -1,\n        errors::InvalidArgument(\"Axis must be at least -1. Found \", axis_));\n    OP_REQUIRES(ctx, (axis_ == -1 || axis_ < input.shape().dims()),\n                errors::InvalidArgument(\n                    \"Axis should be -1 or 0 or a positive value less than \",\n                    input.shape().dims(), \"but given axis value was \", axis_));\n\n    OP_REQUIRES(\n        ctx, input.IsSameSize(gradient),\n        errors::InvalidArgument(\"gradient and input must be the same size\"));\n    const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);\n    const Tensor& input_min_tensor = ctx->input(2);\n    OP_REQUIRES(ctx,\n                input_min_tensor.dims() == 0 || input_min_tensor.dims() == 1,\n                errors::InvalidArgument(\n                    \"Input min tensor must have dimension 1. Recieved \",\n                    input_min_tensor.dims(), \".\"));\n    const Tensor& input_max_tensor = ctx->input(3);\n    OP_REQUIRES(ctx,\n                input_max_tensor.dims() == 0 || input_max_tensor.dims() == 1,\n                errors::InvalidArgument(\n                    \"Input max tensor must have dimension 1. Recieved \",\n                    input_max_tensor.dims(), \".\"));\n    if (axis_ != -1) {\n      OP_REQUIRES(\n          ctx, input_min_tensor.dim_size(0) == depth,\n          errors::InvalidArgument(\"min has incorrect size, expected \", depth,\n                                  \" was \", input_min_tensor.dim_size(0)));\n      OP_REQUIRES(\n          ctx, input_max_tensor.dim_size(0) == depth,\n          errors::InvalidArgument(\"max has incorrect size, expected \", depth,\n                                  \" was \", input_max_tensor.dim_size(0)));\n    }\n\n    TensorShape min_max_shape(input_min_tensor.shape());\n    Tensor* input_min_backprop;\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_output(1, min_max_shape, &input_min_backprop));\n\n    Tensor* input_max_backprop;\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_output(2, min_max_shape, &input_max_backprop));\n\n    if (axis_ == -1) {\n      functor::QuantizeAndDequantizeOneScaleGradientFunctor<Device, T> f;\n      f(ctx->eigen_device<Device>(), gradient.template flat<T>(),\n        input.template flat<T>(), input_min_tensor.scalar<T>(),\n        input_max_tensor.scalar<T>(), input_backprop->template flat<T>(),\n        input_min_backprop->template scalar<T>(),\n        input_max_backprop->template scalar<T>());\n    } else {\n      functor::QuantizeAndDequantizePerChannelGradientFunctor<Device, T> f;\n      f(ctx->eigen_device<Device>(),\n        gradient.template flat_inner_outer_dims<T, 3>(axis_ - 1),\n        input.template flat_inner_outer_dims<T, 3>(axis_ - 1),\n        &input_min_tensor, &input_max_tensor,\n        input_backprop->template flat_inner_outer_dims<T, 3>(axis_ - 1),\n        input_min_backprop->template flat<T>(),\n        input_max_backprop->template flat<T>());\n    }\n  }",
        "func_hash": 234673676615434385684756936171703208879,
        "file_name": "quantize_and_dequantize_op.cc",
        "file_hash": 339380707229520344979853528458088260159,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2022-29192",
        "cve_desc": "TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, the implementation of `tf.raw_ops.QuantizeAndDequantizeV4Grad` does not fully validate the input arguments. This results in a `CHECK`-failure which can be used to trigger a denial of service attack. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-29192",
        "func_name": "Compute",
        "diff": [
            "diff --git a/tensorflow/core/kernels/quantize_and_dequantize_op.cc b/tensorflow/core/kernels/quantize_and_dequantize_op.cc\nindex d63a49a04be621..da9257fb9c9af1 100644\n--- a/tensorflow/core/kernels/quantize_and_dequantize_op.cc\n+++ b/tensorflow/core/kernels/quantize_and_dequantize_op.cc\n@@ -174,13 +174,13 @@ class QuantizeAndDequantizeV4GradientOp : public OpKernel {\n     OP_REQUIRES(ctx,\n                 input_min_tensor.dims() == 0 || input_min_tensor.dims() == 1,\n                 errors::InvalidArgument(\n-                    \"Input min tensor must have dimension 1. Recieved \",\n+                    \"Input min tensor must have dimension 0 or 1. Received \",\n                     input_min_tensor.dims(), \".\"));\n     const Tensor& input_max_tensor = ctx->input(3);\n     OP_REQUIRES(ctx,\n                 input_max_tensor.dims() == 0 || input_max_tensor.dims() == 1,\n                 errors::InvalidArgument(\n-                    \"Input max tensor must have dimension 1. Recieved \",\n+                    \"Input max tensor must have dimension 0 or 1. Received \",\n                     input_max_tensor.dims(), \".\"));\n     if (axis_ != -1) {\n       OP_REQUIRES(\n@@ -203,6 +203,12 @@ class QuantizeAndDequantizeV4GradientOp : public OpKernel {\n                    ctx->allocate_output(2, min_max_shape, &input_max_backprop));\n \n     if (axis_ == -1) {\n+      OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(input_min_tensor.shape()),\n+                  errors::InvalidArgument(\n+                      \"input_min must be a scalar if axis is unspecified\"));\n+      OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(input_max_tensor.shape()),\n+                  errors::InvalidArgument(\n+                      \"input_max must be a scalar if axis is unspecified\"));\n       functor::QuantizeAndDequantizeOneScaleGradientFunctor<Device, T> f;\n       f(ctx->eigen_device<Device>(), gradient.template flat<T>(),\n         input.template flat<T>(), input_min_tensor.scalar<T>(),\n"
        ],
        "func_after": []
    },
    {
        "idx": 197565,
        "project": "wolfMQTT",
        "commit_id": "84d4b53122e0fa0280c7872350b89d5777dabbb2",
        "project_url": "https://github.com/wolfSSL/wolfMQTT",
        "commit_url": "https://github.com/wolfSSL/wolfMQTT/commit/84d4b53122e0fa0280c7872350b89d5777dabbb2",
        "commit_message": "Fix wolfmqtt-fuzzer: Null-dereference WRITE in MqttProps_Free",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static int MqttClient_WaitType(MqttClient *client, void *packet_obj,\n    byte wait_type, word16 wait_packet_id, int timeout_ms)\n{\n    int rc;\n    word16 packet_id;\n    MqttPacketType packet_type;\n#ifdef WOLFMQTT_MULTITHREAD\n    MqttPendResp *pendResp;\n    int readLocked;\n#endif\n    MqttMsgStat* mms_stat;\n    int waitMatchFound;\n\n    if (client == NULL || packet_obj == NULL) {\n        return MQTT_CODE_ERROR_BAD_ARG;\n    }\n\n    /* all packet type structures must have MqttMsgStat at top */\n    mms_stat = (MqttMsgStat*)packet_obj;\n\nwait_again:\n\n    /* initialize variables */\n    packet_id = 0;\n    packet_type = MQTT_PACKET_TYPE_RESERVED;\n#ifdef WOLFMQTT_MULTITHREAD\n    pendResp = NULL;\n    readLocked = 0;\n#endif\n    waitMatchFound = 0;\n\n#ifdef WOLFMQTT_DEBUG_CLIENT\n    PRINTF(\"MqttClient_WaitType: Type %s (%d), ID %d\",\n        MqttPacket_TypeDesc((MqttPacketType)wait_type),\n            wait_type, wait_packet_id);\n#endif\n\n    switch ((int)*mms_stat)\n    {\n        case MQTT_MSG_BEGIN:\n        {\n        #ifdef WOLFMQTT_MULTITHREAD\n            /* Lock recv socket mutex */\n            rc = wm_SemLock(&client->lockRecv);\n            if (rc != 0) {\n                PRINTF(\"MqttClient_WaitType: recv lock error!\");\n                return rc;\n            }\n            readLocked = 1;\n        #endif\n\n            /* reset the packet state */\n            client->packet.stat = MQTT_PK_BEGIN;\n        }\n        FALL_THROUGH;\n\n    #ifdef WOLFMQTT_V5\n        case MQTT_MSG_AUTH:\n    #endif\n        case MQTT_MSG_WAIT:\n        {\n        #ifdef WOLFMQTT_MULTITHREAD\n            /* Check to see if packet type and id have already completed */\n            pendResp = NULL;\n            rc = wm_SemLock(&client->lockClient);\n            if (rc == 0) {\n                if (MqttClient_RespList_Find(client, (MqttPacketType)wait_type, \n                    wait_packet_id, &pendResp)) {\n                    if (pendResp->packetDone) {\n                        /* pending response is already done, so return */\n                        rc = pendResp->packet_ret;\n                    #ifdef WOLFMQTT_DEBUG_CLIENT\n                        PRINTF(\"PendResp already Done %p: Rc %d\", pendResp, rc);\n                    #endif\n                        MqttClient_RespList_Remove(client, pendResp);\n                        wm_SemUnlock(&client->lockClient);\n                        wm_SemUnlock(&client->lockRecv);\n                        return rc;\n                    }\n                }\n                wm_SemUnlock(&client->lockClient);\n            }\n            else {\n                break; /* error */\n            }\n        #endif /* WOLFMQTT_MULTITHREAD */\n\n            *mms_stat = MQTT_MSG_WAIT;\n\n            /* Wait for packet */\n            rc = MqttPacket_Read(client, client->rx_buf, client->rx_buf_len,\n                    timeout_ms);\n            /* handle failure */\n            if (rc <= 0) {\n                break;\n            }\n\n            /* capture length read */\n            client->packet.buf_len = rc;\n\n            /* Decode Packet - get type and id */\n            rc = MqttClient_DecodePacket(client, client->rx_buf,\n                client->packet.buf_len, NULL, &packet_type, NULL, &packet_id);\n            if (rc < 0) {\n                break;\n            }\n\n        #ifdef WOLFMQTT_DEBUG_CLIENT\n            PRINTF(\"Read Packet: Len %d, Type %d, ID %d\",\n                client->packet.buf_len, packet_type, packet_id);\n        #endif\n\n            *mms_stat = MQTT_MSG_READ;\n        }\n        FALL_THROUGH;\n\n        case MQTT_MSG_READ:\n        case MQTT_MSG_READ_PAYLOAD:\n        {\n            MqttPacketType use_packet_type;\n            void* use_packet_obj;\n\n        #ifdef WOLFMQTT_MULTITHREAD\n            readLocked = 1; /* if in this state read is locked */\n        #endif\n\n            /* read payload state only happens for publish messages */\n            if (*mms_stat == MQTT_MSG_READ_PAYLOAD) {\n                packet_type = MQTT_PACKET_TYPE_PUBLISH;\n            }\n\n            /* Determine if we received data for this request */\n            if ((wait_type == MQTT_PACKET_TYPE_ANY ||\n                 wait_type == packet_type ||\n                 MqttIsPubRespPacket(packet_type) == MqttIsPubRespPacket(wait_type)) &&\n               (wait_packet_id == 0 || wait_packet_id == packet_id))\n            {\n                use_packet_obj = packet_obj;\n                waitMatchFound = 1;\n            }\n            else {\n                /* use generic packet object */\n                use_packet_obj = &client->msg;\n            }\n            use_packet_type = packet_type;\n\n        #ifdef WOLFMQTT_MULTITHREAD\n            /* Check to see if we have a pending response for this packet */\n            pendResp = NULL;\n            rc = wm_SemLock(&client->lockClient);\n            if (rc == 0) {\n                if (MqttClient_RespList_Find(client, packet_type, packet_id,\n                                                               &pendResp)) {\n                    /* we found packet match this incoming read packet */\n                    pendResp->packetProcessing = 1;\n                    use_packet_obj = pendResp->packet_obj;\n                    use_packet_type = pendResp->packet_type;\n                    /* req from another thread... not a match */\n                    waitMatchFound = 0;\n                }\n                wm_SemUnlock(&client->lockClient);\n            }\n            else {\n                break; /* error */\n            }\n        #endif /* WOLFMQTT_MULTITHREAD */\n\n            /* Perform packet handling for publish callback and QoS */\n            rc = MqttClient_HandlePacket(client, use_packet_type,\n                use_packet_obj, timeout_ms);\n\n        #ifdef WOLFMQTT_NONBLOCK\n            if (rc == MQTT_CODE_CONTINUE) {\n                /* we have received some data, so keep the recv\n                    mutex lock active and return */\n                return rc;\n            }\n        #endif\n\n            /* handle success case */\n            if (rc >= 0) {\n                rc = MQTT_CODE_SUCCESS;\n            }\n\n        #ifdef WOLFMQTT_MULTITHREAD\n            if (pendResp) {\n                /* Mark pending response entry done */\n                if (wm_SemLock(&client->lockClient) == 0) {\n                    pendResp->packetDone = 1;\n                    pendResp->packet_ret = rc;\n                #ifdef WOLFMQTT_DEBUG_CLIENT\n                    PRINTF(\"PendResp Done %p\", pendResp);\n                #endif\n                    pendResp = NULL;\n                    wm_SemUnlock(&client->lockClient);\n                }\n            }\n        #endif /* WOLFMQTT_MULTITHREAD */\n            break;\n        }\n\n        case MQTT_MSG_WRITE:\n        case MQTT_MSG_WRITE_PAYLOAD:\n        default:\n        {\n        #ifdef WOLFMQTT_DEBUG_CLIENT\n            PRINTF(\"MqttClient_WaitType: Invalid state %d!\", *mms_stat);\n        #endif\n            rc = MQTT_CODE_ERROR_STAT;\n            break;\n        }\n    } /* switch (*mms_stat) */\n\n#ifdef WOLFMQTT_NONBLOCK\n    if (rc != MQTT_CODE_CONTINUE)\n#endif\n    {\n        /* reset state */\n        *mms_stat = MQTT_MSG_BEGIN;\n    }\n\n#ifdef WOLFMQTT_MULTITHREAD\n    if (readLocked) {\n        wm_SemUnlock(&client->lockRecv);\n    }\n#endif\n    if (rc < 0) {\n    #ifdef WOLFMQTT_DEBUG_CLIENT\n        PRINTF(\"MqttClient_WaitType: Failure: %s (%d)\",\n            MqttClient_ReturnCodeToString(rc), rc);\n    #endif\n        return rc;\n    }\n\n    if (!waitMatchFound) {\n        /* if we get here, then the we are still waiting for a packet */\n        goto wait_again;\n    }\n\n    return rc;\n}",
        "func_hash": 2988390772969394657723865827973366134,
        "file_name": "mqtt_client.c",
        "file_hash": 187905589318508952285873561463064501412,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2021-45936",
        "cve_desc": "wolfSSL wolfMQTT 1.9 has a heap-based buffer overflow in MqttDecode_Disconnect (called from MqttClient_DecodePacket and MqttClient_WaitType).",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-45936",
        "func_name": "MqttClient_WaitType",
        "diff": [
            "diff --git a/src/mqtt_client.c b/src/mqtt_client.c\nindex d06fac66a..d392cc5f0 100644\n--- a/src/mqtt_client.c\n+++ b/src/mqtt_client.c\n@@ -906,8 +906,9 @@ static int MqttClient_WaitType(MqttClient *client, void *packet_obj,\n             /* Determine if we received data for this request */\n             if ((wait_type == MQTT_PACKET_TYPE_ANY ||\n                  wait_type == packet_type ||\n-                 MqttIsPubRespPacket(packet_type) == MqttIsPubRespPacket(wait_type)) &&\n-               (wait_packet_id == 0 || wait_packet_id == packet_id))\n+                 (MqttIsPubRespPacket(packet_type) &&\n+                  MqttIsPubRespPacket(wait_type))) &&\n+                (wait_packet_id == 0 || wait_packet_id == packet_id))\n             {\n                 use_packet_obj = packet_obj;\n                 waitMatchFound = 1;\n"
        ],
        "func_after": []
    },
    {
        "idx": 197593,
        "project": "njs",
        "commit_id": "ad48705bf1f04b4221a5f5b07715ac48b3160d53",
        "project_url": "https://github.com/nginx/njs",
        "commit_url": "https://github.com/nginx/njs/commit/ad48705bf1f04b4221a5f5b07715ac48b3160d53",
        "commit_message": "Fixed frame allocation from an awaited frame.\n\nnjs_function_frame_save() is used to save the awaited frame when \"await\"\ninstruction is encountered. The saving was done as a memcpy() of\nexisting runtime frame.\n\nnjs_function_frame_alloc() is used to alloc a new function frame, this\nfunction tries to use a spare preallocated memory from the previous\nframe first.  Previously, this function might result in \"use-after-free\"\nwhen invoked from a restored frame saved with njs_function_frame_save().\nBecause njs_function_frame_save() left pointers to the spare memory of\nthe original frame which may be already free when saved frame is\nrestored.\n\nThe fix is to erase fields for the spare memory from the saved frame.\n\nThis closes #469 issue on Github.",
        "target": 1,
        "irrelevant": 1,
        "func_before": "njs_function_frame_save(njs_vm_t *vm, njs_frame_t *frame, u_char *pc)\n{\n    size_t              value_count, n;\n    njs_value_t         *start, *end, *p, **new, *value, **local;\n    njs_function_t      *function;\n    njs_native_frame_t  *active, *native;\n\n    *frame = *vm->active_frame;\n    frame->previous_active_frame = NULL;\n\n    native = &frame->native;\n\n    active = &vm->active_frame->native;\n    value_count = njs_function_frame_value_count(active);\n\n    function = active->function;\n\n    new = (njs_value_t **) ((u_char *) native + NJS_FRAME_SIZE);\n    value = (njs_value_t *) (new + value_count\n                             + function->u.lambda->temp);\n\n\n    native->arguments = value;\n    native->arguments_offset = value + (function->args_offset - 1);\n    native->local = new + njs_function_frame_args_count(active);\n    native->temp = new + value_count;\n    native->pc = pc;\n\n    start = njs_function_frame_values(active, &end);\n    p = native->arguments;\n\n    while (start < end) {\n        *p = *start++;\n        *new++ = p++;\n    }\n\n    /* Move all arguments. */\n\n    p = native->arguments;\n    local = native->local + function->args_offset;\n\n    for (n = 0; n < function->args_count; n++) {\n        if (!njs_is_valid(p)) {\n            njs_set_undefined(p);\n        }\n\n        *local++ = p++;\n    }\n\n    return NJS_OK;\n}",
        "func_hash": 163196677430813133926152837345587363595,
        "file_name": "njs_function.c",
        "file_hash": 84952023387586829721392975850477495397,
        "cwe": [
            "CWE-416"
        ],
        "cve": "CVE-2022-27007",
        "cve_desc": "nginx njs 0.7.2 is affected suffers from Use-after-free in njs_function_frame_alloc() when it try to invoke from a restored frame saved with njs_function_frame_save().",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-27007",
        "func_name": "njs_function_frame_save",
        "diff": [
            "diff --git a/src/njs_function.c b/src/njs_function.c\nindex c9d4d9732..78857e01e 100644\n--- a/src/njs_function.c\n+++ b/src/njs_function.c\n@@ -811,9 +811,13 @@ njs_function_frame_save(njs_vm_t *vm, njs_frame_t *frame, u_char *pc)\n     njs_native_frame_t  *active, *native;\n \n     *frame = *vm->active_frame;\n+\n     frame->previous_active_frame = NULL;\n \n     native = &frame->native;\n+    native->size = 0;\n+    native->free = NULL;\n+    native->free_size = 0;\n \n     active = &vm->active_frame->native;\n     value_count = njs_function_frame_value_count(active);\ndiff --git a/test/js/async_recursive_large.t.js b/test/js/async_recursive_large.t.js\nnew file mode 100644\nindex 000000000..423e8d01e\n--- /dev/null\n+++ b/test/js/async_recursive_large.t.js\n@@ -0,0 +1,26 @@\n+/*---\n+includes: [compareArray.js]\n+flags: [async]\n+---*/\n+\n+let stages = [];\n+\n+async function f(v) {\n+    if (v == 1000) {\n+        return;\n+    }\n+\n+    stages.push(`f>${v}`);\n+\n+    await \"X\";\n+\n+    await f(v + 1);\n+\n+    stages.push(`f<${v}`);\n+}\n+\n+f(0)\n+.then(v => {\n+    assert.sameValue(stages.length, 2000);\n+})\n+.then($DONE, $DONE);\ndiff --git a/test/js/async_recursive_mid.t.js b/test/js/async_recursive_mid.t.js\nindex 4d3a9fd19..6b6779629 100644\n--- a/test/js/async_recursive_mid.t.js\n+++ b/test/js/async_recursive_mid.t.js\n@@ -6,7 +6,7 @@ flags: [async]\n let stages = [];\n \n async function f(v) {\n-    if (v == 3) {\n+    if (v == 1000) {\n         return;\n     }\n \n"
        ],
        "func_after": []
    },
    {
        "idx": 197615,
        "project": "tensorflow",
        "commit_id": "abcced051cb1bd8fb05046ac3b6023a7ebcc4578",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/abcced051cb1bd8fb05046ac3b6023a7ebcc4578",
        "commit_message": "Prevent crashes when loading tensor slices with unsupported types.\n\nAlso fix the `Tensor(const TensorShape&)` constructor swapping the LOG(FATAL)\nmessages for the unset and unsupported types.\n\nPiperOrigin-RevId: 392695027\nChange-Id: I4beda7db950db951d273e3259a7c8534ece49354",
        "target": 1,
        "irrelevant": 0,
        "func_before": "Status TensorSliceReader::GetTensor(\n    const string& name, std::unique_ptr<tensorflow::Tensor>* out_tensor) const {\n  DataType type;\n  TensorShape shape;\n  TensorSlice slice;\n  {\n    mutex_lock l(mu_);\n    const TensorSliceSet* tss = gtl::FindPtrOrNull(tensors_, name);\n    if (tss == nullptr) {\n      return errors::NotFound(name, \" not found in checkpoint file\");\n    }\n\n    if (tss->Slices().size() > 1) {\n      // TODO(sherrym): Support multi-slice checkpoints.\n      return errors::Unimplemented(\"Sliced checkpoints are not supported\");\n    }\n\n    type = tss->type();\n    shape = tss->shape();\n    slice = tss->Slices().begin()->second.slice;\n  }\n\n  std::unique_ptr<tensorflow::Tensor> t(new tensorflow::Tensor(type, shape));\n  bool success = false;\n\n#define READER_COPY(dt)                                                  \\\n  case dt:                                                               \\\n    success = CopySliceData(name, slice,                                 \\\n                            t->flat<EnumToDataType<dt>::Type>().data()); \\\n    break;\n\n  switch (type) {\n    READER_COPY(DT_FLOAT);\n    READER_COPY(DT_DOUBLE);\n    READER_COPY(DT_INT32);\n    READER_COPY(DT_UINT8);\n    READER_COPY(DT_INT16);\n    READER_COPY(DT_INT8);\n    READER_COPY(DT_INT64);\n    READER_COPY(DT_STRING);\n    default:\n      return errors::Unimplemented(\"Data type not supported\");\n  }\n#undef READER_COPY\n\n  if (!success) {\n    return errors::NotFound(name, \" not found in checkpoint file\");\n  }\n  std::swap(*out_tensor, t);\n\n  return Status::OK();\n}",
        "func_hash": 280007427282291482813273164813512992579,
        "file_name": "tensor_slice_reader.cc",
        "file_hash": 18697630540874284571835582575505228006,
        "cwe": [
            "CWE-345"
        ],
        "cve": "CVE-2021-41203",
        "cve_desc": "TensorFlow is an open source platform for machine learning. In affected versions an attacker can trigger undefined behavior, integer overflows, segfaults and `CHECK`-fail crashes if they can change saved checkpoints from outside of TensorFlow. This is because the checkpoints loading infrastructure is missing validation for invalid file formats. The fixes will be included in TensorFlow 2.7.0. We will also cherrypick these commits on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-41203",
        "func_name": "TensorSliceReader::GetTensor",
        "diff": [
            "diff --git a/tensorflow/core/framework/BUILD b/tensorflow/core/framework/BUILD\nindex 88550b3205ff58..11fe921173ae40 100644\n--- a/tensorflow/core/framework/BUILD\n+++ b/tensorflow/core/framework/BUILD\n@@ -835,6 +835,7 @@ tf_cuda_library(\n         \"//tensorflow/core/lib/strings:str_util\",\n         \"//tensorflow/core/lib/strings:strcat\",\n         \"//tensorflow/core/platform:abi\",\n+        \"//tensorflow/core/platform:errors\",\n         \"//tensorflow/core/platform:logging\",\n         \"//tensorflow/core/platform:macros\",\n         \"//tensorflow/core/platform:platform_port\",\ndiff --git a/tensorflow/core/framework/tensor.cc b/tensorflow/core/framework/tensor.cc\nindex 2abd8fce1c4276..5e26bf05c03ca9 100644\n--- a/tensorflow/core/framework/tensor.cc\n+++ b/tensorflow/core/framework/tensor.cc\n@@ -52,6 +52,7 @@ limitations under the License.\n #include \"tensorflow/core/lib/gtl/inlined_vector.h\"\n #include \"tensorflow/core/lib/strings/str_util.h\"\n #include \"tensorflow/core/lib/strings/strcat.h\"\n+#include \"tensorflow/core/platform/errors.h\"\n #include \"tensorflow/core/platform/logging.h\"\n #include \"tensorflow/core/platform/macros.h\"\n #include \"tensorflow/core/platform/protobuf.h\"\n@@ -723,11 +724,11 @@ bool Tensor::RefCountIsOne() const {\n // The macro CASES() expands to a switch statement conditioned on\n // TYPE_ENUM. Each case expands the STMTS after a typedef for T.\n #define SINGLE_ARG(...) __VA_ARGS__\n-#define CASE(TYPE, STMTS)             \\\n-  case DataTypeToEnum<TYPE>::value: { \\\n-    typedef TYPE T;                   \\\n-    STMTS;                            \\\n-    break;                            \\\n+#define CASE(TYPE, STMTS)               \\\n+  case DataTypeToEnum<TYPE>::value: {   \\\n+    typedef TF_ATTRIBUTE_UNUSED TYPE T; \\\n+    STMTS;                              \\\n+    break;                              \\\n   }\n #define CASES_WITH_DEFAULT(TYPE_ENUM, STMTS, INVALID, DEFAULT) \\\n   switch (TYPE_ENUM) {                                         \\\n@@ -763,9 +764,8 @@ bool Tensor::RefCountIsOne() const {\n   }\n \n #define CASES(TYPE_ENUM, STMTS)                                      \\\n-  CASES_WITH_DEFAULT(TYPE_ENUM, STMTS,                               \\\n-                     LOG(FATAL) << \"Unexpected type: \" << TYPE_ENUM; \\\n-                     , LOG(FATAL) << \"Type not set\";)\n+  CASES_WITH_DEFAULT(TYPE_ENUM, STMTS, LOG(FATAL) << \"Type not set\"; \\\n+                     , LOG(FATAL) << \"Unexpected type: \" << TYPE_ENUM;)\n \n Tensor::Tensor(Allocator* a, DataType type, const TensorShape& shape)\n     : shape_(shape), buf_(nullptr) {\n@@ -795,6 +795,16 @@ Tensor::Tensor(Allocator* a, DataType type, const TensorShape& shape,\n   }\n }\n \n+Status Tensor::BuildTensor(DataType type, const TensorShape& shape,\n+                           Tensor* out_tensor) {\n+  // Avoid crashes due to invalid or unsupported types.\n+  CASES_WITH_DEFAULT(\n+      type, {}, return errors::InvalidArgument(\"Type not set\"),\n+      return errors::InvalidArgument(\"Unexpected type: \", DataType_Name(type)));\n+  *out_tensor = Tensor(type, shape);\n+  return Status::OK();\n+}\n+\n // NOTE(mrry): The default allocator for a Tensor (when none is specified) is\n // the default CPU allocator for NUMA zone 0. Accessing that currently involves\n // acquiring a lock, which guards initialization of the per-NUMA zone\ndiff --git a/tensorflow/core/framework/tensor.h b/tensorflow/core/framework/tensor.h\nindex dd66f995ecbcd7..d4ffb1106e40c1 100644\n--- a/tensorflow/core/framework/tensor.h\n+++ b/tensorflow/core/framework/tensor.h\n@@ -170,6 +170,15 @@ class Tensor {\n   /// for details.\n   explicit Tensor(DataType type);\n \n+  /// \\brief Initializes a tensor with the input `type` and `shape`, or returns\n+  /// an error and leaves `out_tensor` unmodified. This factory method should be\n+  /// used instead of the corresponding constructor if calling code cannot\n+  /// validate that the `DataType` is valid and supported.\n+  ///\n+  /// The underlying buffer is allocated using a `CPUAllocator`.\n+  static Status BuildTensor(DataType type, const TensorShape& shape,\n+                            Tensor* out_tensor);\n+\n  private:\n   // A tag type for selecting the `Tensor` constructor overload that creates a\n   // scalar tensor in host memory.\ndiff --git a/tensorflow/core/util/tensor_slice_reader.cc b/tensorflow/core/util/tensor_slice_reader.cc\nindex 58c4c22ce7a9e2..00911b13f34914 100644\n--- a/tensorflow/core/util/tensor_slice_reader.cc\n+++ b/tensorflow/core/util/tensor_slice_reader.cc\n@@ -248,7 +248,9 @@ Status TensorSliceReader::GetTensor(\n     slice = tss->Slices().begin()->second.slice;\n   }\n \n-  std::unique_ptr<tensorflow::Tensor> t(new tensorflow::Tensor(type, shape));\n+  std::unique_ptr<tensorflow::Tensor> t(new tensorflow::Tensor);\n+  Status s = tensorflow::Tensor::BuildTensor(type, shape, t.get());\n+  if (!s.ok()) return s;\n   bool success = false;\n \n #define READER_COPY(dt)                                                  \\\ndiff --git a/tensorflow/core/util/tensor_slice_reader_test.cc b/tensorflow/core/util/tensor_slice_reader_test.cc\nindex e6e65fc2e6c96d..9bd3063d4ebec3 100644\n--- a/tensorflow/core/util/tensor_slice_reader_test.cc\n+++ b/tensorflow/core/util/tensor_slice_reader_test.cc\n@@ -13,15 +13,19 @@ See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*/\n \n-#include <utility>\n-\n #include \"tensorflow/core/util/tensor_slice_reader.h\"\n \n+#include <utility>\n+#include <vector>\n+\n #include \"tensorflow/core/framework/types.h\"\n #include \"tensorflow/core/framework/versions.pb.h\"\n #include \"tensorflow/core/lib/core/status_test_util.h\"\n #include \"tensorflow/core/lib/core/stringpiece.h\"\n+#include \"tensorflow/core/lib/io/iterator.h\"\n #include \"tensorflow/core/lib/io/path.h\"\n+#include \"tensorflow/core/lib/io/table.h\"\n+#include \"tensorflow/core/lib/io/table_builder.h\"\n #include \"tensorflow/core/lib/strings/str_util.h\"\n #include \"tensorflow/core/lib/strings/strcat.h\"\n #include \"tensorflow/core/platform/env.h\"\n@@ -30,6 +34,7 @@ limitations under the License.\n #include \"tensorflow/core/platform/test.h\"\n #include \"tensorflow/core/platform/types.h\"\n #include \"tensorflow/core/public/version.h\"\n+#include \"tensorflow/core/util/saved_tensor_slice.pb.h\"\n #include \"tensorflow/core/util/saved_tensor_slice_util.h\"\n #include \"tensorflow/core/util/tensor_slice_reader_cache.h\"\n #include \"tensorflow/core/util/tensor_slice_writer.h\"\n@@ -309,6 +314,102 @@ TEST_SIMPLE_INT(int16, int32)\n TEST_SIMPLE_INT(int8, int32)\n TEST_SIMPLE_INT(uint8, int32)\n \n+// Modifies the SavedTensorSlices messages in a checkpoint to allow creating\n+// malformed or unsupported checkpoints.\n+void MutateSavedTensorSlices(\n+    const std::string& fname,\n+    const std::function<std::string(SavedTensorSlices)>& mutator) {\n+  table::Options options;\n+  options.compression = table::kNoCompression;\n+\n+  // Read all entres from the table.\n+  std::vector<std::pair<std::string, std::string>> entries;\n+  {\n+    std::unique_ptr<RandomAccessFile> file;\n+    TF_CHECK_OK(Env::Default()->NewRandomAccessFile(fname, &file));\n+    uint64 file_size;\n+    TF_CHECK_OK(Env::Default()->GetFileSize(fname, &file_size));\n+    table::Table* t;\n+    TF_CHECK_OK(table::Table::Open(options, file.get(), file_size, &t));\n+    std::unique_ptr<table::Table> table(t);\n+    std::unique_ptr<table::Iterator> it(table->NewIterator());\n+    for (it->Seek(\"\"); it->Valid(); it->Next()) {\n+      entries.emplace_back(it->key(), it->value());\n+    }\n+    TF_CHECK_OK(it->status());\n+  }\n+\n+  // Rewrite the table, mutating each value.\n+  {\n+    std::unique_ptr<WritableFile> file;\n+    TF_CHECK_OK(Env::Default()->NewWritableFile(fname, &file));\n+    table::TableBuilder builder(options, file.get());\n+    for (const auto& entry : entries) {\n+      SavedTensorSlices sts;\n+      CHECK(sts.ParseFromString(entry.second));\n+      builder.Add(entry.first, mutator(std::move(sts)));\n+    }\n+    TF_CHECK_OK(builder.Finish());\n+    TF_CHECK_OK(file->Close());\n+  }\n+}\n+\n+TEST(TensorSliceReaderTest, MissingTensorType) {\n+  const string fname = io::JoinPath(testing::TmpDir(), \"invalid_checkpoint\");\n+  TensorSliceWriter writer(fname, CreateTableTensorSliceBuilder);\n+  const int32 data[] = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9};\n+  TensorShape shape({4, 5});\n+  TensorSlice slice = TensorSlice::ParseOrDie(\"0,2:-\");\n+  TF_CHECK_OK(writer.Add(\"test\", shape, slice, data));\n+  TF_CHECK_OK(writer.Finish());\n+\n+  MutateSavedTensorSlices(fname, [](SavedTensorSlices sts) {\n+    if (sts.has_meta()) {\n+      for (auto& tensor : *sts.mutable_meta()->mutable_tensor()) {\n+        tensor.clear_type();\n+      }\n+    }\n+    return sts.SerializeAsString();\n+  });\n+\n+  TensorSliceReader reader(fname, OpenTableTensorSliceReader);\n+  TF_CHECK_OK(reader.status());\n+\n+  // The tensor should be present, but loading it should fail due to the\n+  // unset (invalid) type.\n+  EXPECT_TRUE(reader.HasTensor(\"test\", nullptr, nullptr));\n+  std::unique_ptr<Tensor> tensor;\n+  EXPECT_FALSE(reader.GetTensor(\"test\", &tensor).ok());\n+}\n+\n+TEST(TensorSliceReaderTest, UnsupportedTensorType) {\n+  const string fname = io::JoinPath(testing::TmpDir(), \"int32_ref_checkpoint\");\n+  TensorSliceWriter writer(fname, CreateTableTensorSliceBuilder);\n+  const int32 data[] = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9};\n+  TensorShape shape({4, 5});\n+  TensorSlice slice = TensorSlice::ParseOrDie(\"0,2:-\");\n+  TF_CHECK_OK(writer.Add(\"test\", shape, slice, data));\n+  TF_CHECK_OK(writer.Finish());\n+\n+  MutateSavedTensorSlices(fname, [](SavedTensorSlices sts) {\n+    if (sts.has_meta()) {\n+      for (auto& tensor : *sts.mutable_meta()->mutable_tensor()) {\n+        tensor.set_type(DT_INT32_REF);\n+      }\n+    }\n+    return sts.SerializeAsString();\n+  });\n+\n+  TensorSliceReader reader(fname, OpenTableTensorSliceReader);\n+  TF_CHECK_OK(reader.status());\n+\n+  // The tensor should be present, but loading it should fail due to the\n+  // unsupported type.\n+  EXPECT_TRUE(reader.HasTensor(\"test\", nullptr, nullptr));\n+  std::unique_ptr<Tensor> tensor;\n+  EXPECT_FALSE(reader.GetTensor(\"test\", &tensor).ok());\n+}\n+\n void CachedTensorSliceReaderTesterHelper(\n     const TensorSliceWriter::CreateBuilderFunction& create_function,\n     const TensorSliceReader::OpenTableFunction& open_function) {\n"
        ],
        "func_after": []
    },
    {
        "idx": 197621,
        "project": "tensorflow",
        "commit_id": "e84c975313e8e8e38bb2ea118196369c45c51378",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/e84c975313e8e8e38bb2ea118196369c45c51378",
        "commit_message": "In tf.raw_ops.BoostedTreesSparseCalculateBestFeatureSplit, limit stat_dim in stats_summary_indices to under stats_dims in stats_summary_shape\n\nPiperOrigin-RevId: 387171191\nChange-Id: I83ca8a75b22aa78c037e8b98779da6cced16bfaa",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext* const context) override {\n    // node_id_range\n    const Tensor* node_id_range_t;\n    OP_REQUIRES_OK(context, context->input(\"node_id_range\", &node_id_range_t));\n    const auto node_id_range = node_id_range_t->vec<int32>();\n    const int32_t node_id_first = node_id_range(0);  // inclusive\n    const int32_t node_id_last = node_id_range(1);   // exclusive\n\n    const Tensor* stats_summary_indices_t;\n    OP_REQUIRES_OK(context, context->input(\"stats_summary_indices\",\n                                           &stats_summary_indices_t));\n    const auto stats_summary_indices = stats_summary_indices_t->matrix<int32>();\n    const int32_t num_sparse_entries = stats_summary_indices_t->dim_size(0);\n\n    const Tensor* stats_summary_values_t;\n    OP_REQUIRES_OK(context, context->input(\"stats_summary_values\",\n                                           &stats_summary_values_t));\n    const auto stats_summary_values = stats_summary_values_t->vec<float>();\n\n    const Tensor* stats_summary_shape_t;\n    OP_REQUIRES_OK(\n        context, context->input(\"stats_summary_shape\", &stats_summary_shape_t));\n    const auto stats_summary_shape = stats_summary_shape_t->vec<int32>();\n    const int32_t num_buckets = stats_summary_shape(2) - 1;\n    const int32_t stats_dims = stats_summary_shape(3);\n\n    const Tensor* l1_t;\n    OP_REQUIRES_OK(context, context->input(\"l1\", &l1_t));\n    const auto l1 = l1_t->scalar<float>()();\n\n    const Tensor* l2_t;\n    OP_REQUIRES_OK(context, context->input(\"l2\", &l2_t));\n    const auto l2 = l2_t->scalar<float>()();\n\n    const Tensor* tree_complexity_t;\n    OP_REQUIRES_OK(context,\n                   context->input(\"tree_complexity\", &tree_complexity_t));\n    const auto tree_complexity = tree_complexity_t->scalar<float>()();\n\n    const Tensor* min_node_weight_t;\n    OP_REQUIRES_OK(context,\n                   context->input(\"min_node_weight\", &min_node_weight_t));\n    const auto min_node_weight = min_node_weight_t->scalar<float>()();\n\n    std::vector<int32> output_node_ids;\n    std::vector<float> output_gains;\n    std::vector<int32> output_feature_dimensions;\n    std::vector<int32> output_thresholds;\n    std::vector<float> output_left_node_contribs;\n    std::vector<float> output_right_node_contribs;\n    std::vector<string> output_split_types;\n\n    FeatureMap f_map;\n\n    int32_t previous_node_id = -1;\n    for (int idx = 0; idx < num_sparse_entries; ++idx) {\n      int32_t node_id = stats_summary_indices(idx, 0);\n      if (node_id != previous_node_id) {\n        process_node(f_map, &output_node_ids, &output_gains,\n                     &output_feature_dimensions, &output_thresholds,\n                     &output_left_node_contribs, &output_right_node_contribs,\n                     &output_split_types, previous_node_id, min_node_weight, l1,\n                     l2, num_buckets);\n        f_map.clear();\n      }\n      previous_node_id = node_id;\n      DCHECK_LE(node_id_first, node_id);\n      DCHECK_LT(node_id, node_id_last);\n      const int32_t feature_dim = stats_summary_indices(idx, 1);\n      const int32_t bucket_id = stats_summary_indices(idx, 2);\n      const int32_t stat_dim = stats_summary_indices(idx, 3);\n      std::pair<FeatureMapIterator, bool> const& f_insert_result = f_map.insert(\n          FeatureMapIterator::value_type(feature_dim, BucketMap()));\n      auto& b_map = f_insert_result.first->second;\n      std::pair<BucketMapIterator, bool> const& b_insert_result =\n          b_map.insert(BucketMapIterator::value_type(\n              bucket_id, std::vector<float>(stats_dims)));\n      auto& stats = b_insert_result.first->second;\n      stats[stat_dim] = stats_summary_values(idx);\n    }  // for node_id\n    // process the last node id\n    process_node(f_map, &output_node_ids, &output_gains,\n                 &output_feature_dimensions, &output_thresholds,\n                 &output_left_node_contribs, &output_right_node_contribs,\n                 &output_split_types, previous_node_id, min_node_weight, l1, l2,\n                 num_buckets);\n\n    const int num_nodes = output_node_ids.size();\n    // output_node_ids\n    Tensor* output_node_ids_t = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(\"node_ids\", {num_nodes},\n                                                     &output_node_ids_t));\n    auto output_node_ids_vec = output_node_ids_t->vec<int32>();\n\n    // output_gains\n    Tensor* output_gains_t;\n    OP_REQUIRES_OK(context, context->allocate_output(\"gains\", {num_nodes},\n                                                     &output_gains_t));\n    auto output_gains_vec = output_gains_t->vec<float>();\n\n    // output_feature_dimensions\n    Tensor* output_feature_dimension_t;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(\"feature_dimensions\", {num_nodes},\n                                            &output_feature_dimension_t));\n    auto output_feature_dimensions_vec =\n        output_feature_dimension_t->vec<int32>();\n\n    // output_thresholds\n    Tensor* output_thresholds_t;\n    OP_REQUIRES_OK(context, context->allocate_output(\"thresholds\", {num_nodes},\n                                                     &output_thresholds_t));\n    auto output_thresholds_vec = output_thresholds_t->vec<int32>();\n\n    // output_left_node_contribs\n    Tensor* output_left_node_contribs_t;\n    OP_REQUIRES_OK(\n        context, context->allocate_output(\"left_node_contribs\", {num_nodes, 1},\n                                          &output_left_node_contribs_t));\n    auto output_left_node_contribs_matrix =\n        output_left_node_contribs_t->matrix<float>();\n\n    // output_right_node_contribs\n    Tensor* output_right_node_contribs_t;\n    OP_REQUIRES_OK(\n        context, context->allocate_output(\"right_node_contribs\", {num_nodes, 1},\n                                          &output_right_node_contribs_t));\n    auto output_right_node_contribs_matrix =\n        output_right_node_contribs_t->matrix<float>();\n\n    // split type\n    Tensor* output_split_types_t;\n    OP_REQUIRES_OK(\n        context, context->allocate_output(\"split_with_default_directions\",\n                                          {num_nodes}, &output_split_types_t));\n    auto output_split_types_vec = output_split_types_t->vec<tstring>();\n\n    // Sets output tensors from vectors.\n    for (int i = 0; i < num_nodes; ++i) {\n      output_node_ids_vec(i) = output_node_ids[i];\n      // Adjust the gains to penalize by tree complexity.\n      output_gains_vec(i) = output_gains[i] - tree_complexity;\n      output_feature_dimensions_vec(i) = output_feature_dimensions[i];\n      output_thresholds_vec(i) = output_thresholds[i];\n      // TODO(crawles): change this for multi-class.\n      output_left_node_contribs_matrix(i, 0) = output_left_node_contribs[i];\n      output_right_node_contribs_matrix(i, 0) = output_right_node_contribs[i];\n      output_split_types_vec(i) = output_split_types[i];\n    }\n  }",
        "func_hash": 69206211534814304835270711364278354354,
        "file_name": "stats_ops.cc",
        "file_hash": 316049476660529142907096006231459788339,
        "cwe": [
            "CWE-369"
        ],
        "cve": "CVE-2021-37664",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions an attacker can read from outside of bounds of heap allocated data by sending specially crafted illegal arguments to `BoostedTreesSparseCalculateBestFeatureSplit`. The [implementation](https://github.com/tensorflow/tensorflow/blob/84d053187cb80d975ef2b9684d4b61981bca0c41/tensorflow/core/kernels/boosted_trees/stats_ops.cc) needs to validate that each value in `stats_summary_indices` is in range. We have patched the issue in GitHub commit e84c975313e8e8e38bb2ea118196369c45c51378. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37664",
        "func_name": "Compute",
        "diff": [
            "diff --git a/tensorflow/core/kernels/boosted_trees/stats_ops.cc b/tensorflow/core/kernels/boosted_trees/stats_ops.cc\nindex 014c2ec22c9cf6..2636909855a386 100644\n--- a/tensorflow/core/kernels/boosted_trees/stats_ops.cc\n+++ b/tensorflow/core/kernels/boosted_trees/stats_ops.cc\n@@ -1050,6 +1050,13 @@ class BoostedTreesSparseCalculateBestFeatureSplitOp : public OpKernel {\n       const int32_t feature_dim = stats_summary_indices(idx, 1);\n       const int32_t bucket_id = stats_summary_indices(idx, 2);\n       const int32_t stat_dim = stats_summary_indices(idx, 3);\n+      OP_REQUIRES(context, stat_dim < stats_dims,\n+                  errors::InvalidArgument(\n+                      \"Stat dim, the sum of logits dim and hessian dim in \"\n+                      \"stats_summary_indices, cannot be greater than stats \"\n+                      \"dims, the last value in stats_summary_shape, which was \",\n+                      stats_dims, \". At index (\", idx,\n+                      \", 4), stats_summary_indices contains value \", stat_dim));\n       std::pair<FeatureMapIterator, bool> const& f_insert_result = f_map.insert(\n           FeatureMapIterator::value_type(feature_dim, BucketMap()));\n       auto& b_map = f_insert_result.first->second;\n"
        ],
        "func_after": []
    },
    {
        "idx": 197632,
        "project": "njs",
        "commit_id": "6a40a85ff239497c6458c7dbef18f6a2736fe992",
        "project_url": "https://github.com/nginx/njs",
        "commit_url": "https://github.com/nginx/njs/commit/6a40a85ff239497c6458c7dbef18f6a2736fe992",
        "commit_message": "Fixed type confusion bug while resolving promises.\n\nPreviously, the internal function njs_promise_perform_then() which\nimplements PerformPromiseThen() expects its first argument to always be\na promise instance.  This assertion might be invalid because the\nfunctions corresponding to Promise.prototype.then() and\nPromise.resolve() incorrectly verified their arguments.\n\nSpecifically, the functions recognized their first argument as promise\nif it was an object which was an Promise or had Promise object in its\nprototype chain.  The later condition is not correct because internal\nslots are not inherited according to the spec.\n\nThis closes #447 issue in Github.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "njs_promise_perform_then(njs_vm_t *vm, njs_value_t *value,\n    njs_value_t *fulfilled, njs_value_t *rejected,\n    njs_promise_capability_t *capability)\n{\n    njs_int_t               ret;\n    njs_value_t             arguments[2];\n    njs_promise_t           *promise;\n    njs_function_t          *function;\n    njs_promise_data_t      *data;\n    njs_promise_reaction_t  *fulfilled_reaction, *rejected_reaction;\n\n    if (!njs_is_function(fulfilled)) {\n        fulfilled = njs_value_arg(&njs_value_undefined);\n    }\n\n    if (!njs_is_function(rejected)) {\n        rejected = njs_value_arg(&njs_value_undefined);\n    }\n\n    promise = njs_promise(value);\n    data = njs_data(&promise->value);\n\n    fulfilled_reaction = njs_mp_alloc(vm->mem_pool,\n                                      sizeof(njs_promise_reaction_t));\n    if (njs_slow_path(fulfilled_reaction == NULL)) {\n        njs_memory_error(vm);\n        return NJS_ERROR;\n    }\n\n    fulfilled_reaction->capability = capability;\n    fulfilled_reaction->handler = *fulfilled;\n    fulfilled_reaction->type = NJS_PROMISE_FULFILL;\n\n    rejected_reaction = njs_mp_alloc(vm->mem_pool,\n                                     sizeof(njs_promise_reaction_t));\n    if (njs_slow_path(rejected_reaction == NULL)) {\n        njs_memory_error(vm);\n        return NJS_ERROR;\n    }\n\n    rejected_reaction->capability = capability;\n    rejected_reaction->handler = *rejected;\n    rejected_reaction->type = NJS_PROMISE_REJECTED;\n\n    if (data->state == NJS_PROMISE_PENDING) {\n        njs_queue_insert_tail(&data->fulfill_queue, &fulfilled_reaction->link);\n        njs_queue_insert_tail(&data->reject_queue, &rejected_reaction->link);\n\n    } else {\n        function = njs_promise_create_function(vm,\n                                               sizeof(njs_promise_context_t));\n        function->u.native = njs_promise_reaction_job;\n\n        if (data->state == NJS_PROMISE_REJECTED) {\n            njs_set_data(&arguments[0], rejected_reaction, 0);\n\n            ret = njs_promise_host_rejection_tracker(vm, promise,\n                                                     NJS_PROMISE_HANDLE);\n            if (njs_slow_path(ret != NJS_OK)) {\n                return ret;\n            }\n\n        } else {\n            njs_set_data(&arguments[0], fulfilled_reaction, 0);\n        }\n\n        arguments[1] = data->result;\n\n        ret = njs_promise_add_event(vm, function, arguments, 2);\n        if (njs_slow_path(ret != NJS_OK)) {\n            return ret;\n        }\n    }\n\n    data->is_handled = 1;\n\n    if (capability == NULL) {\n        njs_vm_retval_set(vm, &njs_value_undefined);\n\n    } else {\n        njs_vm_retval_set(vm, &capability->promise);\n    }\n\n    return NJS_OK;\n}",
        "func_hash": 181580372713190612781917074071493405711,
        "file_name": "njs_promise.c",
        "file_hash": 261469139723432841860734117510139062920,
        "cwe": [
            "CWE-269"
        ],
        "cve": "CVE-2021-46463",
        "cve_desc": "njs through 0.7.1, used in NGINX, was discovered to contain a control flow hijack caused by a Type Confusion vulnerability in njs_promise_perform_then().",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-46463",
        "func_name": "njs_promise_perform_then",
        "diff": [
            "diff --git a/src/njs_promise.c b/src/njs_promise.c\nindex 45ea4921c..52ae5b570 100644\n--- a/src/njs_promise.c\n+++ b/src/njs_promise.c\n@@ -771,25 +771,19 @@ njs_promise_resolve(njs_vm_t *vm, njs_value_t *constructor, njs_value_t *x)\n {\n     njs_int_t                 ret;\n     njs_value_t               value;\n-    njs_object_t              *object;\n     njs_promise_capability_t  *capability;\n \n     static const njs_value_t  string_constructor = njs_string(\"constructor\");\n \n-    if (njs_is_object(x)) {\n-        object = njs_object_proto_lookup(njs_object(x), NJS_PROMISE,\n-                                         njs_object_t);\n-\n-        if (object != NULL) {\n-            ret = njs_value_property(vm, x, njs_value_arg(&string_constructor),\n-                                     &value);\n-            if (njs_slow_path(ret == NJS_ERROR)) {\n-                return NULL;\n-            }\n+    if (njs_is_promise(x)) {\n+        ret = njs_value_property(vm, x, njs_value_arg(&string_constructor),\n+                                 &value);\n+        if (njs_slow_path(ret == NJS_ERROR)) {\n+            return NULL;\n+        }\n \n-            if (njs_values_same(&value, constructor)) {\n-                return njs_promise(x);\n-            }\n+        if (njs_values_same(&value, constructor)) {\n+            return njs_promise(x);\n         }\n     }\n \n@@ -875,19 +869,12 @@ njs_promise_prototype_then(njs_vm_t *vm, njs_value_t *args, njs_uint_t nargs,\n {\n     njs_int_t                 ret;\n     njs_value_t               *promise, *fulfilled, *rejected, constructor;\n-    njs_object_t              *object;\n     njs_function_t            *function;\n     njs_promise_capability_t  *capability;\n \n     promise = njs_argument(args, 0);\n \n-    if (njs_slow_path(!njs_is_object(promise))) {\n-        goto failed;\n-    }\n-\n-    object = njs_object_proto_lookup(njs_object(promise), NJS_PROMISE,\n-                                     njs_object_t);\n-    if (njs_slow_path(object == NULL)) {\n+    if (njs_slow_path(!njs_is_promise(promise))) {\n         goto failed;\n     }\n \n@@ -933,6 +920,8 @@ njs_promise_perform_then(njs_vm_t *vm, njs_value_t *value,\n     njs_promise_data_t      *data;\n     njs_promise_reaction_t  *fulfilled_reaction, *rejected_reaction;\n \n+    njs_assert(njs_is_promise(value));\n+\n     if (!njs_is_function(fulfilled)) {\n         fulfilled = njs_value_arg(&njs_value_undefined);\n     }\ndiff --git a/src/njs_vmcode.c b/src/njs_vmcode.c\nindex 759112550..b371c3748 100644\n--- a/src/njs_vmcode.c\n+++ b/src/njs_vmcode.c\n@@ -1895,7 +1895,7 @@ njs_vmcode_await(njs_vm_t *vm, njs_vmcode_await_t *await)\n     rejected->args_count = 1;\n     rejected->u.native = njs_await_rejected;\n \n-    njs_set_object(&val, &promise->object);\n+    njs_set_promise(&val, promise);\n     njs_set_function(&on_fulfilled, fulfilled);\n     njs_set_function(&on_rejected, rejected);\n \ndiff --git a/test/js/promise_prototype_reject_type_confusion.t.js b/test/js/promise_prototype_reject_type_confusion.t.js\nnew file mode 100644\nindex 000000000..0201f29c0\n--- /dev/null\n+++ b/test/js/promise_prototype_reject_type_confusion.t.js\n@@ -0,0 +1,11 @@\n+/*---\n+includes: []\n+flags: [async]\n+---*/\n+\n+Symbol.__proto__ = new Promise(()=>{});\n+\n+Promise.reject(Symbol)\n+.then(v => $DONOTEVALUATE())\n+.catch(err => assert.sameValue(err.name, 'Symbol'))\n+.then($DONE, $DONE);\ndiff --git a/test/js/promise_prototype_then_type_confusion.t.js b/test/js/promise_prototype_then_type_confusion.t.js\nnew file mode 100644\nindex 000000000..72b687cf3\n--- /dev/null\n+++ b/test/js/promise_prototype_then_type_confusion.t.js\n@@ -0,0 +1,11 @@\n+/*---\n+includes: []\n+flags: [async]\n+---*/\n+\n+Symbol.__proto__ = new Promise(()=>{});\n+\n+Promise.resolve(Symbol)\n+.then(v => $DONOTEVALUATE())\n+.catch(err => assert.sameValue(err.name, 'TypeError'))\n+.then($DONE, $DONE);\n"
        ],
        "func_after": []
    },
    {
        "idx": 197666,
        "project": "njs",
        "commit_id": "eafe4c7a326b163612f10861392622b5da5b1792",
        "project_url": "https://github.com/nginx/njs",
        "commit_url": "https://github.com/nginx/njs/commit/eafe4c7a326b163612f10861392622b5da5b1792",
        "commit_message": "Fixed Array.prototype.lastIndexOf() with unicode string as \"this\".\n\nPreviously, when lastIndexOf() was called with unicode string as \"this\"\nargument and a negative \"fromIndex\" argument null-pointer dererence\nmight occur because njs_string_offset() was called with invalid index\nvalue whereas njs_string_offset() should always be called with valid\nindex argument.\n\nThe fix is to verify that from index is valid.\n\nThis closes #482 issue on Github.",
        "target": 1,
        "irrelevant": 1,
        "func_before": "njs_object_iterate_reverse(njs_vm_t *vm, njs_iterator_args_t *args,\n    njs_iterator_handler_t handler)\n{\n    double              idx;\n    int64_t             i, from, to, length;\n    njs_int_t           ret;\n    njs_array_t         *array, *keys;\n    njs_value_t         *entry, *value, prop, character, string_obj;\n    const u_char        *p, *end, *pos;\n    njs_string_prop_t   string_prop;\n    njs_object_value_t  *object;\n\n    value = args->value;\n    from = args->from;\n    to = args->to;\n\n    if (njs_is_array(value)) {\n        array = njs_array(value);\n\n        from += 1;\n\n        while (from-- > to) {\n            if (njs_slow_path(!array->object.fast_array)) {\n                goto process_object;\n            }\n\n            if (njs_fast_path(from < array->length\n                              && njs_is_valid(&array->start[from])))\n            {\n                ret = handler(vm, args, &array->start[from], from);\n\n            } else {\n                entry = njs_value_arg(&njs_value_invalid);\n                ret = njs_value_property_i64(vm, value, from, &prop);\n                if (njs_slow_path(ret != NJS_DECLINED)) {\n                    if (ret == NJS_ERROR) {\n                        return NJS_ERROR;\n                    }\n\n                    entry = &prop;\n                }\n\n                ret = handler(vm, args, entry, from);\n            }\n\n            if (njs_slow_path(ret != NJS_OK)) {\n                if (ret == NJS_DONE) {\n                    return NJS_DONE;\n                }\n\n                return NJS_ERROR;\n            }\n        }\n\n        return NJS_OK;\n    }\n\n    if (njs_is_string(value) || njs_is_object_string(value)) {\n\n        if (njs_is_string(value)) {\n            object = njs_object_value_alloc(vm, NJS_OBJ_TYPE_STRING, 0, value);\n            if (njs_slow_path(object == NULL)) {\n                return NJS_ERROR;\n            }\n\n            njs_set_object_value(&string_obj, object);\n\n            args->value = &string_obj;\n        }\n        else {\n            value = njs_object_value(value);\n        }\n\n        length = njs_string_prop(&string_prop, value);\n        end = string_prop.start + string_prop.size;\n\n        if ((size_t) length == string_prop.size) {\n            /* Byte or ASCII string. */\n\n            p = string_prop.start + from;\n\n            i = from + 1;\n\n            while (i-- > to) {\n                /* This cannot fail. */\n                (void) njs_string_new(vm, &character, p, 1, 1);\n\n                ret = handler(vm, args, &character, i);\n                if (njs_slow_path(ret != NJS_OK)) {\n                    if (ret == NJS_DONE) {\n                        return NJS_DONE;\n                    }\n\n                    return NJS_ERROR;\n                }\n\n                p--;\n            }\n\n        } else {\n            /* UTF-8 string. */\n\n            p = njs_string_offset(string_prop.start, end, from);\n            p = njs_utf8_next(p, end);\n\n            i = from + 1;\n\n            while (i-- > to) {\n                pos = njs_utf8_prev(p);\n\n                /* This cannot fail. */\n                (void) njs_string_new(vm, &character, pos, p - pos , 1);\n\n                ret = handler(vm, args, &character, i);\n                if (njs_slow_path(ret != NJS_OK)) {\n                    if (ret == NJS_DONE) {\n                        return NJS_DONE;\n                    }\n\n                    return NJS_ERROR;\n                }\n\n                p = pos;\n            }\n        }\n\n        return NJS_OK;\n    }\n\n    if (!njs_is_object(value)) {\n        return NJS_OK;\n    }\n\nprocess_object:\n\n    if (!njs_fast_object(from - to)) {\n        keys = njs_array_indices(vm, value);\n        if (njs_slow_path(keys == NULL)) {\n            return NJS_ERROR;\n        }\n\n        i = keys->length;\n\n        while (i > 0) {\n            idx = njs_string_to_index(&keys->start[--i]);\n\n            if (idx < to || idx > from) {\n                continue;\n            }\n\n            ret = njs_iterator_object_handler(vm, handler, args,\n                                              &keys->start[i], idx);\n            if (njs_slow_path(ret != NJS_OK)) {\n                njs_array_destroy(vm, keys);\n                return ret;\n            }\n        }\n\n        njs_array_destroy(vm, keys);\n\n        return NJS_OK;\n    }\n\n    i = from + 1;\n\n    while (i-- > to) {\n        ret = njs_iterator_object_handler(vm, handler, args, NULL, i);\n        if (njs_slow_path(ret != NJS_OK)) {\n            return ret;\n        }\n    }\n\n    return NJS_OK;\n}",
        "func_hash": 204015889704330628062672866949061415790,
        "file_name": "njs_iterator.c",
        "file_hash": 335799250908607269245401986160656951958,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2022-31307",
        "cve_desc": "Nginx NJS v0.7.2 was discovered to contain a segmentation violation in the function njs_string_offset at src/njs_string.c.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-31307",
        "func_name": "njs_object_iterate_reverse",
        "diff": [
            "diff --git a/src/njs_iterator.c b/src/njs_iterator.c\nindex 90c3046fb..043e4483c 100644\n--- a/src/njs_iterator.c\n+++ b/src/njs_iterator.c\n@@ -560,11 +560,14 @@ njs_object_iterate_reverse(njs_vm_t *vm, njs_iterator_args_t *args,\n         } else {\n             /* UTF-8 string. */\n \n-            p = njs_string_offset(string_prop.start, end, from);\n-            p = njs_utf8_next(p, end);\n-\n+            p = NULL;\n             i = from + 1;\n \n+            if (i > to) {\n+                p = njs_string_offset(string_prop.start, end, from);\n+                p = njs_utf8_next(p, end);\n+            }\n+\n             while (i-- > to) {\n                 pos = njs_utf8_prev(p);\n \ndiff --git a/src/test/njs_unit_test.c b/src/test/njs_unit_test.c\nindex def152aa8..0b73c77b3 100644\n--- a/src/test/njs_unit_test.c\n+++ b/src/test/njs_unit_test.c\n@@ -5103,6 +5103,9 @@ static njs_unit_test_t  njs_test[] =\n     { njs_str(\"Array.prototype.lastIndexOf.call({0:'undefined', length:0}, 'undefined')\"),\n       njs_str(\"-1\") },\n \n+    { njs_str(\"[1,0,-1,-2].map(v => Array.prototype.lastIndexOf.call('\u0424', '\u0424', v))\"),\n+      njs_str(\"0,0,0,-1\") },\n+\n     { njs_str(\"[''].lastIndexOf.call('00000000000000000000000000000\u043000')\"),\n       njs_str(\"-1\") },\n \n"
        ],
        "func_after": []
    },
    {
        "idx": 197719,
        "project": "tensorflow",
        "commit_id": "be7a4de6adfbd303ce08be4332554dff70362612",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/be7a4de6adfbd303ce08be4332554dff70362612",
        "commit_message": "Ensure non-empty rt_nested_splits in tf.raw_ops.RaggedTensorToVariant\n\nPiperOrigin-RevId: 387664237\nChange-Id: Ia1700c34b5610873d63561abc86e23b46ead93b3",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext* context) override {\n    // Read ragged_splits inputs.\n    OpInputList ragged_nested_splits_in;\n    OP_REQUIRES_OK(context, context->input_list(\"rt_nested_splits\",\n                                                &ragged_nested_splits_in));\n    const int ragged_nested_splits_len = ragged_nested_splits_in.size();\n    RaggedTensorVariant batched_ragged_input;\n    // Read ragged_values input.\n    batched_ragged_input.set_values(context->input(ragged_nested_splits_len));\n    batched_ragged_input.mutable_nested_splits()->reserve(\n        ragged_nested_splits_len);\n    for (int i = 0; i < ragged_nested_splits_len; i++) {\n      batched_ragged_input.append_splits(ragged_nested_splits_in[i]);\n    }\n\n    if (!batched_input_) {\n      // Encode as a Scalar Variant Tensor.\n      Tensor* encoded_scalar;\n      OP_REQUIRES_OK(context, context->allocate_output(0, TensorShape({}),\n                                                       &encoded_scalar));\n      encoded_scalar->scalar<Variant>()() = std::move(batched_ragged_input);\n      return;\n    }\n\n    // Unbatch the Ragged Tensor and encode the components.\n    std::vector<RaggedTensorVariant> unbatched_ragged_input;\n    auto batched_splits_top_vec =\n        batched_ragged_input.splits(0).vec<SPLIT_TYPE>();\n    int num_components = batched_splits_top_vec.size() - 1;\n    OP_REQUIRES(context, num_components >= 0,\n                errors::Internal(\"Invalid split argument.\"));\n    OP_REQUIRES_OK(context, UnbatchRaggedZerothDim<VALUE_TYPE, SPLIT_TYPE>(\n                                batched_ragged_input, &unbatched_ragged_input));\n\n    // Bundle the encoded scalar Variant Tensors into a rank-1 Variant Tensor.\n    Tensor* encoded_vector;\n    int output_size = unbatched_ragged_input.size();\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(0, TensorShape({output_size}),\n                                            &encoded_vector));\n    auto encoded_vector_t = encoded_vector->vec<Variant>();\n    for (int i = 0; i < output_size; i++) {\n      encoded_vector_t(i) = unbatched_ragged_input[i];\n    }\n  }",
        "func_hash": 87089111367695740407726211981017748791,
        "file_name": "ragged_tensor_to_variant_op.cc",
        "file_hash": 103790733078302023163492154550355279185,
        "cwe": [
            "CWE-125"
        ],
        "cve": "CVE-2021-37666",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions an attacker can cause undefined behavior via binding a reference to null pointer in `tf.raw_ops.RaggedTensorToVariant`. The [implementation](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/core/kernels/ragged_tensor_to_variant_op.cc#L129) has an incomplete validation of the splits values, missing the case when the argument would be empty. We have patched the issue in GitHub commit be7a4de6adfbd303ce08be4332554dff70362612. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37666",
        "func_name": "Compute",
        "diff": [
            "diff --git a/tensorflow/core/kernels/ragged_tensor_to_variant_op.cc b/tensorflow/core/kernels/ragged_tensor_to_variant_op.cc\nindex 687289cd38077a..ab86863e3a987f 100644\n--- a/tensorflow/core/kernels/ragged_tensor_to_variant_op.cc\n+++ b/tensorflow/core/kernels/ragged_tensor_to_variant_op.cc\n@@ -157,6 +157,12 @@ class RaggedTensorToVariantOp : public OpKernel {\n       return;\n     }\n \n+    // Checked here instead of at input in case batched_input_ is false\n+    OP_REQUIRES(context, ragged_nested_splits_len > 0,\n+                errors::InvalidArgument(\n+                    \"rt_nested_splits must be a list of one or more, but \"\n+                    \"received rt_nested_splits of length 0.\"));\n+\n     // Unbatch the Ragged Tensor and encode the components.\n     std::vector<RaggedTensorVariant> unbatched_ragged_input;\n     auto batched_splits_top_vec =\n"
        ],
        "func_after": []
    },
    {
        "idx": 197748,
        "project": "tensorflow",
        "commit_id": "c79ba87153ee343401dbe9d1954d7f79e521eb14",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/c79ba87153ee343401dbe9d1954d7f79e521eb14",
        "commit_message": "Make Transpose's shape inference function validate that negative `perm` values are within the tensor's rank.\n\nPiperOrigin-RevId: 403252853\nChange-Id: Ia6b31b45b237312668bb31c2c3b3c7bbce2d2610",
        "target": 1,
        "irrelevant": 1,
        "func_before": "Status TransposeShapeFn(InferenceContext* c) {\n  ShapeHandle input = c->input(0);\n  ShapeHandle perm_shape = c->input(1);\n  const Tensor* perm = c->input_tensor(1);\n  DimensionHandle perm_elems = c->NumElements(perm_shape);\n  // If we don't have rank information on the input or value information on\n  // perm we can't return any shape information, otherwise we have enough\n  // information to at least find the rank of the output.\n  if (!c->RankKnown(input) && !c->ValueKnown(perm_elems) && perm == nullptr) {\n    c->set_output(0, c->UnknownShape());\n    return Status::OK();\n  }\n\n  // Find our value of the rank.\n  int64_t rank;\n  if (c->RankKnown(input)) {\n    rank = c->Rank(input);\n  } else if (c->ValueKnown(perm_elems)) {\n    rank = c->Value(perm_elems);\n  } else {\n    rank = perm->NumElements();\n  }\n  if (!c->RankKnown(input) && rank < 2) {\n    // A permutation array containing a single element is ambiguous. It could\n    // indicate either a scalar or a 1-dimensional array, both of which the\n    // transpose op returns unchanged.\n    c->set_output(0, input);\n    return Status::OK();\n  }\n\n  std::vector<DimensionHandle> dims;\n  dims.resize(rank);\n  TF_RETURN_IF_ERROR(c->WithRank(input, rank, &input));\n  // Ensure that perm is a vector and has rank elements.\n  TF_RETURN_IF_ERROR(c->WithRank(perm_shape, 1, &perm_shape));\n  TF_RETURN_IF_ERROR(c->WithValue(perm_elems, rank, &perm_elems));\n\n  // If we know the rank of the input and the value of perm, we can return\n  // all shape information, otherwise we can only return rank information,\n  // but no information for the dimensions.\n  if (perm != nullptr) {\n    std::vector<int64_t> data;\n    if (perm->dtype() == DT_INT32) {\n      data = AsInt64<int32>(perm, rank);\n    } else {\n      data = AsInt64<int64_t>(perm, rank);\n    }\n\n    for (int32_t i = 0; i < rank; ++i) {\n      int64_t in_idx = data[i];\n      if (in_idx >= rank) {\n        return errors::InvalidArgument(\"perm dim \", in_idx,\n                                       \" is out of range of input rank \", rank);\n      }\n      dims[i] = c->Dim(input, in_idx);\n    }\n  } else {\n    for (int i = 0; i < rank; ++i) {\n      dims[i] = c->UnknownDim();\n    }\n  }\n\n  c->set_output(0, c->MakeShape(dims));\n  return Status::OK();\n}",
        "func_hash": 264434210200699405161022303469799474263,
        "file_name": "array_ops.cc",
        "file_hash": 212731692545100279573003636737252061446,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2021-41216",
        "cve_desc": "TensorFlow is an open source platform for machine learning. In affected versions the shape inference function for `Transpose` is vulnerable to a heap buffer overflow. This occurs whenever `perm` contains negative elements. The shape inference function does not validate that the indices in `perm` are all valid. The fix will be included in TensorFlow 2.7.0. We will also cherrypick this commit on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-41216",
        "func_name": "TransposeShapeFn",
        "diff": [
            "diff --git a/tensorflow/core/ops/array_ops.cc b/tensorflow/core/ops/array_ops.cc\nindex 64bd4f38478542..14c9efae1ddd3b 100644\n--- a/tensorflow/core/ops/array_ops.cc\n+++ b/tensorflow/core/ops/array_ops.cc\n@@ -168,7 +168,7 @@ Status TransposeShapeFn(InferenceContext* c) {\n \n     for (int32_t i = 0; i < rank; ++i) {\n       int64_t in_idx = data[i];\n-      if (in_idx >= rank) {\n+      if (in_idx >= rank || in_idx <= -rank) {\n         return errors::InvalidArgument(\"perm dim \", in_idx,\n                                        \" is out of range of input rank \", rank);\n       }\n"
        ],
        "func_after": []
    },
    {
        "idx": 197760,
        "project": "tensorflow",
        "commit_id": "bb6a0383ed553c286f87ca88c207f6774d5c4a8f",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/bb6a0383ed553c286f87ca88c207f6774d5c4a8f",
        "commit_message": "Prevent heap OOB read in TFLite's `gather_nd.cc`.\n\nPassing negative indices is illegal but there was a missing check so that resulted in OOB accesses.\n\nPiperOrigin-RevId: 387208551\nChange-Id: I6b7a8a62d3e7c13a16d81619e5bc23ae2cdbc7fd",
        "target": 1,
        "irrelevant": 1,
        "func_before": "TfLiteStatus EvalGatherNd(TfLiteContext* context, const TfLiteTensor* params,\n                          const TfLiteTensor* indices, TfLiteTensor* output) {\n  switch (params->type) {\n    case kTfLiteFloat32:\n      return GatherNd<float, IndicesT>(params, indices, output);\n    case kTfLiteUInt8:\n      return GatherNd<uint8_t, IndicesT>(params, indices, output);\n    case kTfLiteInt8:\n      return GatherNd<int8_t, IndicesT>(params, indices, output);\n    case kTfLiteInt16:\n      return GatherNd<int16_t, IndicesT>(params, indices, output);\n    case kTfLiteInt32:\n      return GatherNd<int32_t, IndicesT>(params, indices, output);\n    case kTfLiteInt64:\n      return GatherNd<int64_t, IndicesT>(params, indices, output);\n    case kTfLiteString:\n      return GatherNdString<IndicesT>(params, indices, output);\n    default:\n      context->ReportError(context,\n                           \"Params type '%s' are not supported by gather_nd.\",\n                           TfLiteTypeGetName(params->type));\n      return kTfLiteError;\n  }\n}",
        "func_hash": 33385980683805390111226215596644506391,
        "file_name": "gather_nd.cc",
        "file_hash": 316439389085787575038399494263818469682,
        "cwe": [
            "CWE-125"
        ],
        "cve": "CVE-2021-37687",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions TFLite's [`GatherNd` implementation](https://github.com/tensorflow/tensorflow/blob/149562d49faa709ea80df1d99fc41d005b81082a/tensorflow/lite/kernels/gather_nd.cc#L124) does not support negative indices but there are no checks for this situation. Hence, an attacker can read arbitrary data from the heap by carefully crafting a model with negative values in `indices`. Similar issue exists in [`Gather` implementation](https://github.com/tensorflow/tensorflow/blob/149562d49faa709ea80df1d99fc41d005b81082a/tensorflow/lite/kernels/gather.cc). We have patched the issue in GitHub commits bb6a0383ed553c286f87ca88c207f6774d5c4a8f and eb921122119a6b6e470ee98b89e65d721663179d. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37687",
        "func_name": "EvalGatherNd",
        "diff": [
            "diff --git a/tensorflow/lite/kernels/gather_nd.cc b/tensorflow/lite/kernels/gather_nd.cc\nindex 3ded771382569e..c39917b478505f 100644\n--- a/tensorflow/lite/kernels/gather_nd.cc\n+++ b/tensorflow/lite/kernels/gather_nd.cc\n@@ -123,6 +123,17 @@ TfLiteStatus GatherNdString(const TfLiteTensor* params,\n template <typename IndicesT>\n TfLiteStatus EvalGatherNd(TfLiteContext* context, const TfLiteTensor* params,\n                           const TfLiteTensor* indices, TfLiteTensor* output) {\n+  bool indices_has_only_positive_elements = true;\n+  const auto* indices_values = GetTensorData<IndicesT>(indices);\n+  const size_t num_indices = indices->bytes / sizeof(IndicesT);\n+  for (size_t i = 0; i < num_indices; i++) {\n+    if (indices_values[i] < 0) {\n+      indices_has_only_positive_elements = false;\n+      break;\n+    }\n+  }\n+  TF_LITE_ENSURE(context, indices_has_only_positive_elements);\n+\n   switch (params->type) {\n     case kTfLiteFloat32:\n       return GatherNd<float, IndicesT>(params, indices, output);\n"
        ],
        "func_after": []
    },
    {
        "idx": 197796,
        "project": "qemu",
        "commit_id": "f9a70e79391f6d7c2a912d785239ee8effc1922d",
        "project_url": "https://github.com/bonzini/qemu",
        "commit_url": "https://github.com/qemu/qemu/commit/f9a70e79391f6d7c2a912d785239ee8effc1922d",
        "commit_message": "ui/vnc: limit client_cut_text msg payload size\n\ncurrently a malicious client could define a payload\nsize of 2^32 - 1 bytes and send up to that size of\ndata to the vnc server. The server would allocated\nthat amount of memory which could easily create an\nout of memory condition.\n\nThis patch limits the payload size to 1MB max.\n\nPlease note that client_cut_text messages are currently\nsilently ignored.\n\nSigned-off-by: Peter Lieven <pl@kamp.de>\nSigned-off-by: Gerd Hoffmann <kraxel@redhat.com>",
        "target": 1,
        "irrelevant": 1,
        "func_before": "static int protocol_client_msg(VncState *vs, uint8_t *data, size_t len)\n{\n    int i;\n    uint16_t limit;\n    VncDisplay *vd = vs->vd;\n\n    if (data[0] > 3) {\n        update_displaychangelistener(&vd->dcl, VNC_REFRESH_INTERVAL_BASE);\n    }\n\n    switch (data[0]) {\n    case VNC_MSG_CLIENT_SET_PIXEL_FORMAT:\n        if (len == 1)\n            return 20;\n\n        set_pixel_format(vs, read_u8(data, 4), read_u8(data, 5),\n                         read_u8(data, 6), read_u8(data, 7),\n                         read_u16(data, 8), read_u16(data, 10),\n                         read_u16(data, 12), read_u8(data, 14),\n                         read_u8(data, 15), read_u8(data, 16));\n        break;\n    case VNC_MSG_CLIENT_SET_ENCODINGS:\n        if (len == 1)\n            return 4;\n\n        if (len == 4) {\n            limit = read_u16(data, 2);\n            if (limit > 0)\n                return 4 + (limit * 4);\n        } else\n            limit = read_u16(data, 2);\n\n        for (i = 0; i < limit; i++) {\n            int32_t val = read_s32(data, 4 + (i * 4));\n            memcpy(data + 4 + (i * 4), &val, sizeof(val));\n        }\n\n        set_encodings(vs, (int32_t *)(data + 4), limit);\n        break;\n    case VNC_MSG_CLIENT_FRAMEBUFFER_UPDATE_REQUEST:\n        if (len == 1)\n            return 10;\n\n        framebuffer_update_request(vs,\n                                   read_u8(data, 1), read_u16(data, 2), read_u16(data, 4),\n                                   read_u16(data, 6), read_u16(data, 8));\n        break;\n    case VNC_MSG_CLIENT_KEY_EVENT:\n        if (len == 1)\n            return 8;\n\n        key_event(vs, read_u8(data, 1), read_u32(data, 4));\n        break;\n    case VNC_MSG_CLIENT_POINTER_EVENT:\n        if (len == 1)\n            return 6;\n\n        pointer_event(vs, read_u8(data, 1), read_u16(data, 2), read_u16(data, 4));\n        break;\n    case VNC_MSG_CLIENT_CUT_TEXT:\n        if (len == 1)\n            return 8;\n\n        if (len == 8) {\n            uint32_t dlen = read_u32(data, 4);\n            if (dlen > 0)\n                return 8 + dlen;\n        }\n\n        client_cut_text(vs, read_u32(data, 4), data + 8);\n        break;\n    case VNC_MSG_CLIENT_QEMU:\n        if (len == 1)\n            return 2;\n\n        switch (read_u8(data, 1)) {\n        case VNC_MSG_CLIENT_QEMU_EXT_KEY_EVENT:\n            if (len == 2)\n                return 12;\n\n            ext_key_event(vs, read_u16(data, 2),\n                          read_u32(data, 4), read_u32(data, 8));\n            break;\n        case VNC_MSG_CLIENT_QEMU_AUDIO:\n            if (len == 2)\n                return 4;\n\n            switch (read_u16 (data, 2)) {\n            case VNC_MSG_CLIENT_QEMU_AUDIO_ENABLE:\n                audio_add(vs);\n                break;\n            case VNC_MSG_CLIENT_QEMU_AUDIO_DISABLE:\n                audio_del(vs);\n                break;\n            case VNC_MSG_CLIENT_QEMU_AUDIO_SET_FORMAT:\n                if (len == 4)\n                    return 10;\n                switch (read_u8(data, 4)) {\n                case 0: vs->as.fmt = AUD_FMT_U8; break;\n                case 1: vs->as.fmt = AUD_FMT_S8; break;\n                case 2: vs->as.fmt = AUD_FMT_U16; break;\n                case 3: vs->as.fmt = AUD_FMT_S16; break;\n                case 4: vs->as.fmt = AUD_FMT_U32; break;\n                case 5: vs->as.fmt = AUD_FMT_S32; break;\n                default:\n                    printf(\"Invalid audio format %d\\n\", read_u8(data, 4));\n                    vnc_client_error(vs);\n                    break;\n                }\n                vs->as.nchannels = read_u8(data, 5);\n                if (vs->as.nchannels != 1 && vs->as.nchannels != 2) {\n                    printf(\"Invalid audio channel coount %d\\n\",\n                           read_u8(data, 5));\n                    vnc_client_error(vs);\n                    break;\n                }\n                vs->as.freq = read_u32(data, 6);\n                break;\n            default:\n                printf (\"Invalid audio message %d\\n\", read_u8(data, 4));\n                vnc_client_error(vs);\n                break;\n            }\n            break;\n\n        default:\n            printf(\"Msg: %d\\n\", read_u16(data, 0));\n            vnc_client_error(vs);\n            break;\n        }\n        break;\n    default:\n        printf(\"Msg: %d\\n\", data[0]);\n        vnc_client_error(vs);\n        break;\n    }\n\n    vnc_read_when(vs, protocol_client_msg, 1);\n    return 0;\n}",
        "func_hash": 26933609972946502173706391662270420555,
        "file_name": "vnc.c",
        "file_hash": 161585493204485691727376098595593068159,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2015-5239",
        "cve_desc": "Integer overflow in the VNC display driver in QEMU before 2.1.0 allows attachers to cause a denial of service (process crash) via a CLIENT_CUT_TEXT message, which triggers an infinite loop.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2015-5239",
        "func_name": "protocol_client_msg",
        "diff": [
            "diff --git a/ui/vnc.c b/ui/vnc.c\nindex 14a86c36ce66..19ce988f5509 100644\n--- a/ui/vnc.c\n+++ b/ui/vnc.c\n@@ -2165,13 +2165,20 @@ static int protocol_client_msg(VncState *vs, uint8_t *data, size_t len)\n         pointer_event(vs, read_u8(data, 1), read_u16(data, 2), read_u16(data, 4));\n         break;\n     case VNC_MSG_CLIENT_CUT_TEXT:\n-        if (len == 1)\n+        if (len == 1) {\n             return 8;\n-\n+        }\n         if (len == 8) {\n             uint32_t dlen = read_u32(data, 4);\n-            if (dlen > 0)\n+            if (dlen > (1 << 20)) {\n+                error_report(\"vnc: client_cut_text msg payload has %u bytes\"\n+                             \" which exceeds our limit of 1MB.\", dlen);\n+                vnc_client_error(vs);\n+                break;\n+            }\n+            if (dlen > 0) {\n                 return 8 + dlen;\n+            }\n         }\n \n         client_cut_text(vs, read_u32(data, 4), data + 8);\n"
        ],
        "func_after": []
    },
    {
        "idx": 197801,
        "project": "tensorflow",
        "commit_id": "368af875869a204b4ac552b9ddda59f6a46a56ec",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/368af875869a204b4ac552b9ddda59f6a46a56ec",
        "commit_message": "Avoid buffer overflow when loading tensors with insufficient data from checkpoints.\n\n`CopyDataFromTensorSliceToTensorSlice` does not (and cannot conveniently)\nprovide any bounds checking on its own, so the size is instead checked prior\nto passing unvalidated data to that function.\n\nPiperOrigin-RevId: 392971286\nChange-Id: If2073b36d4d5eedd386329f56729395fd7effee1",
        "target": 1,
        "irrelevant": 1,
        "func_before": "bool TensorSliceReader::CopySliceData(const string& name,\n                                      const TensorSlice& slice, T* data) const {\n  std::vector<std::pair<TensorSlice, string>> details;\n  const TensorSliceSet* tss;\n  {\n    mutex_lock l(mu_);\n    tss = FindTensorSlice(name, slice, &details);\n    if (!tss && !all_shards_loaded_) {\n      VLOG(1) << \"Did not find slice in preferred shard, loading all shards.\"\n              << name << \": \" << slice.DebugString();\n      LoadAllShards();\n      tss = FindTensorSlice(name, slice, &details);\n    }\n    if (!tss) {\n      // No such tensor\n      return false;\n    }\n  }\n  // We have the data -- copy it over.\n  string value;\n  for (const auto& x : details) {\n    const TensorSlice& slice_s = x.first;\n    const string& fname = x.second;\n    int idx = gtl::FindWithDefault(fname_to_index_, fname, -1);\n    CHECK_GE(idx, 0) << \"Failed to find the index for filename \" << fname;\n    // We read a record in the corresponding sstable\n    const string key = EncodeTensorNameSlice(name, slice_s);\n    if (!sss_[idx]->Get(key, &value)) {\n      VLOG(1) << \"Failed to seek to the record for tensor \" << name\n              << \", slice \" << slice_s.DebugString()\n              << \": computed key = \" << key;\n      return false;\n    }\n    SavedTensorSlices sts;\n    if (!ParseProtoUnlimited(&sts, value)) {\n      VLOG(1) << \"Failed to parse the record for tensor \" << name << \", slice \"\n              << slice_s.DebugString() << \": computed key = \" << key;\n      return false;\n    }\n    CopyDataFromTensorSliceToTensorSlice(\n        tss->shape(), slice_s, slice,\n        checkpoint::TensorProtoData<T>(sts.data().data()), data);\n  }\n  return true;\n}",
        "func_hash": 253938811692403617918500480067513726895,
        "file_name": "tensor_slice_reader.h",
        "file_hash": 240433137636754905402215095789731366712,
        "cwe": [
            "CWE-345"
        ],
        "cve": "CVE-2021-41203",
        "cve_desc": "TensorFlow is an open source platform for machine learning. In affected versions an attacker can trigger undefined behavior, integer overflows, segfaults and `CHECK`-fail crashes if they can change saved checkpoints from outside of TensorFlow. This is because the checkpoints loading infrastructure is missing validation for invalid file formats. The fixes will be included in TensorFlow 2.7.0. We will also cherrypick these commits on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-41203",
        "func_name": "TensorSliceReader::CopySliceData",
        "diff": [
            "diff --git a/tensorflow/core/util/saved_tensor_slice_util.h b/tensorflow/core/util/saved_tensor_slice_util.h\nindex d0b08b3c294e06..b992061a15df93 100644\n--- a/tensorflow/core/util/saved_tensor_slice_util.h\n+++ b/tensorflow/core/util/saved_tensor_slice_util.h\n@@ -59,6 +59,9 @@ Status ParseShapeAndSlice(const string& shape_and_slice, TensorShape* shape,\n template <typename T>\n struct SaveTypeTraits;\n \n+template <typename T>\n+int TensorProtoDataSize(const TensorProto& t);\n+\n template <typename T>\n const typename SaveTypeTraits<T>::SavedType* TensorProtoData(\n     const TensorProto& t);\n@@ -95,6 +98,10 @@ void Fill(T* data, size_t n, TensorProto* t);\n #define TENSOR_PROTO_EXTRACT_TYPE(TYPE, FIELD, FTYPE)             \\\n   TENSOR_PROTO_EXTRACT_TYPE_HELPER(TYPE, FIELD, FTYPE, FTYPE)     \\\n   template <>                                                     \\\n+  inline int TensorProtoDataSize<TYPE>(const TensorProto& t) {    \\\n+    return t.FIELD##_val_size();                                  \\\n+  }                                                               \\\n+  template <>                                                     \\\n   inline void Fill(const TYPE* data, size_t n, TensorProto* t) {  \\\n     typename protobuf::RepeatedField<FTYPE> copy(data, data + n); \\\n     t->mutable_##FIELD##_val()->Swap(&copy);                      \\\n@@ -104,6 +111,10 @@ void Fill(T* data, size_t n, TensorProto* t);\n #define TENSOR_PROTO_EXTRACT_TYPE_COMPLEX(TYPE, FIELD, FTYPE)       \\\n   TENSOR_PROTO_EXTRACT_TYPE_HELPER(TYPE, FIELD, FTYPE, TYPE)        \\\n   template <>                                                       \\\n+  inline int TensorProtoDataSize<TYPE>(const TensorProto& t) {      \\\n+    return t.FIELD##_val_size() / 2;                                \\\n+  }                                                                 \\\n+  template <>                                                       \\\n   inline void Fill(const TYPE* data, size_t n, TensorProto* t) {    \\\n     const FTYPE* sub = reinterpret_cast<const FTYPE*>(data);        \\\n     typename protobuf::RepeatedField<FTYPE> copy(sub, sub + 2 * n); \\\n@@ -136,6 +147,11 @@ TENSOR_PROTO_EXTRACT_TYPE(quint16, int, int32);\n template <>\n struct SaveTypeTraits<qint32> : SaveTypeTraits<int32> {};\n \n+template <>\n+inline int TensorProtoDataSize<qint32>(const TensorProto& t) {\n+  return t.int_val_size();\n+}\n+\n template <>\n inline const int32* TensorProtoData<qint32>(const TensorProto& t) {\n   static_assert(SaveTypeTraits<qint32>::supported,\n@@ -158,6 +174,11 @@ struct SaveTypeTraits<Eigen::half> {\n   typedef protobuf::RepeatedField<int32> RepeatedField;\n };\n \n+template <>\n+inline int TensorProtoDataSize<Eigen::half>(const TensorProto& t) {\n+  return t.half_val_size();\n+}\n+\n template <>\n inline const int* TensorProtoData<Eigen::half>(const TensorProto& t) {\n   return t.half_val().data();\n@@ -187,6 +208,11 @@ struct SaveTypeTraits<tstring> {\n   typedef protobuf::RepeatedPtrField<string> RepeatedField;\n };\n \n+template <>\n+inline int TensorProtoDataSize<tstring>(const TensorProto& t) {\n+  return t.string_val_size();\n+}\n+\n template <>\n inline const string* const* TensorProtoData<tstring>(const TensorProto& t) {\n   static_assert(SaveTypeTraits<tstring>::supported,\ndiff --git a/tensorflow/core/util/tensor_slice_reader.h b/tensorflow/core/util/tensor_slice_reader.h\nindex 0fb2e11bf8dd08..bc0a91523fe36c 100644\n--- a/tensorflow/core/util/tensor_slice_reader.h\n+++ b/tensorflow/core/util/tensor_slice_reader.h\n@@ -181,6 +181,22 @@ bool TensorSliceReader::CopySliceData(const string& name,\n               << slice_s.DebugString() << \": computed key = \" << key;\n       return false;\n     }\n+    // Ensure the TensorSlice contains the expected amount of data.\n+    TensorShape shp_s;\n+    Status s = slice_s.SliceTensorShape(tss->shape(), &shp_s);\n+    if (!s.ok()) {\n+      VLOG(1) << \"Failed to slice tensor \" << name << \", slice \"\n+              << slice_s.DebugString() << \": \" << s;\n+      return false;\n+    }\n+    if (checkpoint::TensorProtoDataSize<T>(sts.data().data()) !=\n+        shp_s.num_elements()) {\n+      VLOG(1) << \"Tensor \" << name << \", slice \" << slice_s.DebugString()\n+              << \" had an unexpected amount of data: expected = \"\n+              << shp_s.num_elements() << \", got = \"\n+              << checkpoint::TensorProtoDataSize<T>(sts.data().data());\n+      return false;\n+    }\n     CopyDataFromTensorSliceToTensorSlice(\n         tss->shape(), slice_s, slice,\n         checkpoint::TensorProtoData<T>(sts.data().data()), data);\ndiff --git a/tensorflow/core/util/tensor_slice_reader_test.cc b/tensorflow/core/util/tensor_slice_reader_test.cc\nindex 53993862385e3e..efb2d9d9748fd5 100644\n--- a/tensorflow/core/util/tensor_slice_reader_test.cc\n+++ b/tensorflow/core/util/tensor_slice_reader_test.cc\n@@ -459,6 +459,33 @@ TEST(TensorSliceReaderTest, InvalidTensorSlice) {\n   EXPECT_FALSE(reader.status().ok());\n }\n \n+TEST(TensorSliceReaderTest, MissingTensorData) {\n+  const string fname =\n+      io::JoinPath(testing::TmpDir(), \"missing_data_checkpoint\");\n+  TensorSliceWriter writer(fname, CreateTableTensorSliceBuilder);\n+  const int32 data[] = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9};\n+  TF_ASSERT_OK(writer.Add(\"test\", TensorShape({4, 5}),\n+                          TensorSlice::ParseOrDie(\"0,2:-\"), data));\n+  TF_ASSERT_OK(writer.Finish());\n+\n+  MutateSavedTensorSlices(fname, [&](SavedTensorSlices sts) {\n+    if (sts.has_data()) {\n+      // Replace the data with only 4 elements.\n+      Fill(data, 4, sts.mutable_data()->mutable_data());\n+    }\n+    return sts.SerializeAsString();\n+  });\n+\n+  TensorSliceReader reader(fname, OpenTableTensorSliceReader);\n+  TF_ASSERT_OK(reader.status());\n+\n+  // The tensor should be present, but loading it should fail due to the missing\n+  // data.\n+  EXPECT_TRUE(reader.HasTensor(\"test\", nullptr, nullptr));\n+  std::unique_ptr<Tensor> tensor;\n+  EXPECT_FALSE(reader.GetTensor(\"test\", &tensor).ok());\n+}\n+\n void CachedTensorSliceReaderTesterHelper(\n     const TensorSliceWriter::CreateBuilderFunction& create_function,\n     const TensorSliceReader::OpenTableFunction& open_function) {\n"
        ],
        "func_after": []
    },
    {
        "idx": 196587,
        "project": "tensorflow",
        "commit_id": "4aacb30888638da75023e6601149415b39763d76",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/4aacb30888638da75023e6601149415b39763d76",
        "commit_message": "Disallow division by zero FPE in `tf.raw_ops.ResourceScatterDiv`\n\nHad to update a test that was broken.\n\nPiperOrigin-RevId: 388516976\nChange-Id: Ic358e6bf0559e011539974d453fc7aa18b427e9c",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void DoCompute(OpKernelContext* c) {\n    core::RefCountPtr<Var> v;\n    OP_REQUIRES_OK(c, LookupResource(c, HandleFromInput(c, 0), &v));\n    Tensor* params = v->tensor();\n    const Tensor& indices = c->input(1);\n    const Tensor& updates = c->input(2);\n\n    // Check that rank(updates.shape) = rank(indices.shape + params.shape[1:])\n    OP_REQUIRES(c,\n                updates.dims() == 0 ||\n                    updates.dims() == indices.dims() + params->dims() - 1,\n                errors::InvalidArgument(\n                    \"Must have updates.shape = indices.shape + \"\n                    \"params.shape[1:] or updates.shape = [], got \",\n                    \"updates.shape \", updates.shape().DebugString(),\n                    \", indices.shape \", indices.shape().DebugString(),\n                    \", params.shape \", params->shape().DebugString()));\n\n    // Check that we have enough index space\n    const int64_t N_big = indices.NumElements();\n    OP_REQUIRES(\n        c, N_big <= std::numeric_limits<Index>::max(),\n        errors::InvalidArgument(\"indices has too many elements for \",\n                                DataTypeString(DataTypeToEnum<Index>::v()),\n                                \" indexing: \", N_big, \" > \",\n                                std::numeric_limits<Index>::max()));\n    const Index N = static_cast<Index>(N_big);\n    OP_REQUIRES(\n        c, params->dim_size(0) <= std::numeric_limits<Index>::max(),\n        errors::InvalidArgument(\"params.shape[0] too large for \",\n                                DataTypeString(DataTypeToEnum<Index>::v()),\n                                \" indexing: \", params->dim_size(0), \" > \",\n                                std::numeric_limits<Index>::max()));\n\n    if (N > 0) {\n      auto indices_flat = indices.flat<Index>();\n      auto params_flat = params->flat_outer_dims<T>();\n      if (TensorShapeUtils::IsScalar(updates.shape())) {\n        const auto update = updates.scalar<T>();\n\n        functor::ScatterScalarFunctor<Device, T, Index, op> functor;\n        const Index bad_i = functor(c, c->template eigen_device<Device>(),\n                                    params_flat, update, indices_flat);\n        OP_REQUIRES(c, bad_i < 0,\n                    errors::InvalidArgument(\n                        \"indices\", SliceDebugString(indices.shape(), bad_i),\n                        \" = \", indices_flat(bad_i), \" is not in [0, \",\n                        params->dim_size(0), \")\"));\n      } else {\n        int64_t num_updates = updates.NumElements();\n        OP_REQUIRES(\n            c, TensorShapeUtils::StartsWith(updates.shape(), indices.shape()),\n            errors::InvalidArgument(\n                \"The shape of indices (\", indices.shape().DebugString(),\n                \") must be a prefix of the shape of updates (\",\n                updates.shape().DebugString(), \")\"));\n        auto updates_flat = updates.shaped<T, 2>({N, num_updates / N});\n\n        functor::ScatterFunctor<Device, T, Index, op> functor;\n        const Index bad_i = functor(c, c->template eigen_device<Device>(),\n                                    params_flat, updates_flat, indices_flat);\n        OP_REQUIRES(c, bad_i < 0,\n                    errors::InvalidArgument(\n                        \"indices\", SliceDebugString(indices.shape(), bad_i),\n                        \" = \", indices_flat(bad_i), \" is not in [0, \",\n                        params->dim_size(0), \")\"));\n      }\n    }\n  }",
        "func_hash": 322924980951140877428129021875471736973,
        "file_name": "resource_variable_ops.cc",
        "file_hash": 290989719174845979221072798512679804902,
        "cwe": [
            "CWE-369"
        ],
        "cve": "CVE-2021-37642",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions the implementation of `tf.raw_ops.ResourceScatterDiv` is vulnerable to a division by 0 error. The [implementation](https://github.com/tensorflow/tensorflow/blob/8d72537c6abf5a44103b57b9c2e22c14f5f49698/tensorflow/core/kernels/resource_variable_ops.cc#L865) uses a common class for all binary operations but fails to treat the division by 0 case separately. We have patched the issue in GitHub commit 4aacb30888638da75023e6601149415b39763d76. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37642",
        "func_name": "DoCompute",
        "diff": [
            "diff --git a/tensorflow/core/kernels/resource_variable_ops.cc b/tensorflow/core/kernels/resource_variable_ops.cc\nindex b81a7a517ea6d2..1a74774785f946 100644\n--- a/tensorflow/core/kernels/resource_variable_ops.cc\n+++ b/tensorflow/core/kernels/resource_variable_ops.cc\n@@ -873,6 +873,35 @@ TF_CALL_GPU_NUMBER_TYPES(REGISTER_GATHER_ND_GPU);\n #undef REGISTER_GATHER_ND_ALL_INDICES\n #undef REGISTER_GATHER_ND_FULL\n \n+namespace {\n+\n+template <typename Device>\n+bool isCPUDevice() {\n+  return false;\n+}\n+\n+template <>\n+bool isCPUDevice<CPUDevice>() {\n+  return true;\n+}\n+\n+template <typename T>\n+bool ValidateInput(const Tensor& updates) {\n+  const auto updates_flat = updates.flat<T>();\n+  const T zero(0);\n+  for (int i = 0; i < updates.NumElements(); i++) {\n+    if (updates_flat(i) == zero) return false;\n+  }\n+  return true;\n+}\n+\n+template <>\n+bool ValidateInput<Variant>(const Tensor& updates) {\n+  return true;\n+}\n+\n+}  // namespace\n+\n template <typename Device, typename T, typename Index, scatter_op::UpdateOp op>\n class ResourceScatterUpdateOp : public OpKernel {\n  public:\n@@ -939,6 +968,12 @@ class ResourceScatterUpdateOp : public OpKernel {\n                                 \" indexing: \", params->dim_size(0), \" > \",\n                                 std::numeric_limits<Index>::max()));\n \n+    // Prevent division by 0\n+    if (isCPUDevice<Device>() && op == tensorflow::scatter_op::UpdateOp::DIV) {\n+      OP_REQUIRES(c, ValidateInput<T>(updates),\n+                  errors::InvalidArgument(\"updates must not contain 0\"));\n+    }\n+\n     if (N > 0) {\n       auto indices_flat = indices.flat<Index>();\n       auto params_flat = params->flat_outer_dims<T>();\ndiff --git a/tensorflow/python/distribute/sharded_variable_test.py b/tensorflow/python/distribute/sharded_variable_test.py\nindex 9e1a32dc70286c..cb61cd5715aca1 100644\n--- a/tensorflow/python/distribute/sharded_variable_test.py\n+++ b/tensorflow/python/distribute/sharded_variable_test.py\n@@ -175,8 +175,9 @@ def func():\n                             'scatter_update')\n   def test_scatter_ops_even_partition(self, op):\n     v = variables_lib.Variable(array_ops.zeros((30, 1)))\n+    # Make sure values does not contain 0 due to testing `scatter_div`!\n     sparse_delta = ops.IndexedSlices(\n-        values=constant_op.constant([[0.], [1.], [2.], [3.], [4.]]),\n+        values=constant_op.constant([[1.], [2.], [3.], [4.], [5.]]),\n         indices=constant_op.constant([0, 10, 12, 21, 22]))\n \n     v0 = variables_lib.Variable(array_ops.zeros((10, 1)))\n"
        ],
        "func_after": []
    },
    {
        "idx": 196611,
        "project": "booth",
        "commit_id": "35bf0b7b048d715f671eb68974fb6b4af6528c67",
        "project_url": "https://github.com/ClusterLabs/booth",
        "commit_url": "https://github.com/ClusterLabs/booth/commit/35bf0b7b048d715f671eb68974fb6b4af6528c67",
        "commit_message": "Revert \"Refactor: main: substitute is_auth_req macro\"\n\nThis reverts commit da79b8ba28ad4837a0fee13e5f8fb6f89fe0e24c.\n\nauthfile != authkey\n\nSigned-off-by: Jan Friesse <jfriesse@redhat.com>",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static int setup_config(int type)\n{\n\tint rv;\n\n\trv = read_config(cl.configfile, type);\n\tif (rv < 0)\n\t\tgoto out;\n\n\tif (is_auth_req()) {\n\t\trv = read_authkey();\n\t\tif (rv < 0)\n\t\t\tgoto out;\n#if HAVE_LIBGCRYPT\n\t\tif (!gcry_check_version(NULL)) {\n\t\t\tlog_error(\"gcry_check_version\");\n\t\t\trv = -ENOENT;\n\t\t\tgoto out;\n\t\t}\n\t\tgcry_control(GCRYCTL_DISABLE_SECMEM, 0);\n\t\tgcry_control(GCRYCTL_INITIALIZATION_FINISHED, 0);\n#endif\n\t}\n\n\t/* Set \"local\" pointer, ignoring errors. */\n\tif (cl.type == DAEMON && cl.site[0]) {\n\t\tif (!find_site_by_name(cl.site, &local, 1)) {\n\t\t\tlog_error(\"Cannot find \\\"%s\\\" in the configuration.\",\n\t\t\t\t\tcl.site);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tlocal->local = 1;\n\t} else\n\t\tfind_myself(NULL, type == CLIENT || type == GEOSTORE);\n\n\n\trv = check_config(type);\n\tif (rv < 0)\n\t\tgoto out;\n\n\n\t/* Per default the PID file name is derived from the\n\t * configuration name. */\n\tif (!cl.lockfile[0]) {\n\t\tsnprintf(cl.lockfile, sizeof(cl.lockfile)-1,\n\t\t\t\t\"%s/%s.pid\", BOOTH_RUN_DIR, booth_conf->name);\n\t}\n\nout:\n\treturn rv;\n}",
        "func_hash": 170997267947585139967201027163993257008,
        "file_name": "main.c",
        "file_hash": 4814718832295442874488153140310945385,
        "cwe": [
            "CWE-284"
        ],
        "cve": "CVE-2022-2553",
        "cve_desc": "The authfile directive in the booth config file is ignored, preventing use of authentication in communications from node to node. As a result, nodes that do not have the correct authentication key are not prevented from communicating with other nodes in the cluster.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-2553",
        "func_name": "setup_config",
        "diff": [
            "diff --git a/src/main.c b/src/main.c\nindex b50a8834..b4a174f4 100644\n--- a/src/main.c\n+++ b/src/main.c\n@@ -364,7 +364,7 @@ static int setup_config(int type)\n \tif (rv < 0)\n \t\tgoto out;\n \n-\tif (is_auth_req()) {\n+\tif (booth_conf->authfile[0] != '\\0') {\n \t\trv = read_authkey();\n \t\tif (rv < 0)\n \t\t\tgoto out;\n"
        ],
        "func_after": []
    },
    {
        "idx": 196620,
        "project": "tensorflow",
        "commit_id": "20cb18724b0bf6c09071a3f53434c4eec53cc147",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/20cb18724b0bf6c09071a3f53434c4eec53cc147",
        "commit_message": "Allow 0 for number of segments in `unsorted_segment_join_op.cc`\n\nRelated to the fix for #55305\n\nPiperOrigin-RevId: 443157549",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext* context) override {\n    const Tensor& input = context->input(0);\n    const TensorShape& input_shape = input.shape();\n    const int32_t input_dims = input_shape.dims();\n\n    const Tensor& segment_id = context->input(1);\n    const TensorShape& segment_id_shape = segment_id.shape();\n    const int32_t segment_dims = segment_id_shape.dims();\n\n    const Tensor& num_segments_tensor = context->input(2);\n    OP_REQUIRES(context, num_segments_tensor.NumElements() != 0,\n                errors::InvalidArgument(\"Number of segments cannot be empty.\"));\n    auto num_segments = num_segments_tensor.scalar<NUM_SEGMENTS_TYPE>()();\n\n    OP_REQUIRES(context, num_segments > 0,\n                errors::InvalidArgument(\"Number of segments must be positive\"));\n    OP_REQUIRES(context, segment_dims != 0,\n                errors::InvalidArgument(\"Segment_id cannot have rank 0\"));\n\n    OP_REQUIRES(\n        context, segment_dims <= input_dims,\n        errors::OutOfRange(\"Invalid segment_id rank \", segment_dims,\n                           \" for input with \", input_dims, \" dimension(s)\"));\n    for (auto i = 0; i < segment_dims; i++) {\n      OP_REQUIRES(\n          context, segment_id_shape.dim_size(i) == input_shape.dim_size(i),\n          errors::InvalidArgument(\n              \"Segment dimension is \", segment_id_shape.dim_size(i),\n              \" while input dimension is \", input_dims, \" in rank \", i));\n    }\n\n    // Making output tensor.\n    Tensor* output_tensor = nullptr;\n    TensorShape output_shape =\n        GetOutputShape(input_shape, segment_id_shape, num_segments);\n    OP_REQUIRES_OK(context, context->allocate_output(\"output\", output_shape,\n                                                     &output_tensor));\n\n    // Preparating flat tensors.\n    auto output_flat = output_tensor->flat<tstring>();\n    auto flat_segment_id = segment_id.flat<INDICES_TYPE>();\n    auto flat_input = input.flat<tstring>();\n\n    for (int i = 0; i < flat_segment_id.size(); i++) {\n      OP_REQUIRES(\n          context,\n          ((flat_segment_id(i) < num_segments) && (flat_segment_id(i) >= 0)),\n          errors::InvalidArgument(\n              \"segment_ids are not allowed to exceed num_segments or\"\n              \" to have negative values.\"));\n    }\n\n    int64_t big_stride;\n    int64_t small_stride;\n    std::tie(big_stride, small_stride) =\n        GetStrides<INDICES_TYPE>(input_shape, segment_id_shape);\n    auto relative_offset_set =\n        GetFlattenedRelativeOffsets<INDICES_TYPE>(small_stride, big_stride);\n    for (auto start_offset = 0; start_offset < big_stride; start_offset++) {\n      for (auto i = 0; i < relative_offset_set.size(); i++) {\n        auto output_index = start_offset + flat_segment_id(i) * big_stride;\n        auto offset = start_offset + relative_offset_set[i];\n        if (output_flat(output_index).length() != 0)\n          output_flat(output_index).append(separator_.c_str());\n        output_flat(output_index).append(flat_input(offset));\n      }\n    }\n  }",
        "func_hash": 251373873884125985828265662891142387006,
        "file_name": "unsorted_segment_join_op.cc",
        "file_hash": 311353858985009725519986545827875705855,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2022-29204",
        "cve_desc": "TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, the implementation of `tf.raw_ops.UnsortedSegmentJoin` does not fully validate the input arguments. This results in a `CHECK`-failure which can be used to trigger a denial of service attack. The code assumes `num_segments` is a positive scalar but there is no validation. Since this value is used to allocate the output tensor, a negative value would result in a `CHECK`-failure (assertion failure), as per TFSA-2021-198. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-29204",
        "func_name": "Compute",
        "diff": [
            "diff --git a/tensorflow/core/kernels/unsorted_segment_join_op.cc b/tensorflow/core/kernels/unsorted_segment_join_op.cc\nindex 860cec8010042c..c8445ca4c4c596 100644\n--- a/tensorflow/core/kernels/unsorted_segment_join_op.cc\n+++ b/tensorflow/core/kernels/unsorted_segment_join_op.cc\n@@ -94,8 +94,10 @@ class UnsortedSegmentJoinOp : public OpKernel {\n                 errors::InvalidArgument(\"Number of segments cannot be empty.\"));\n     auto num_segments = num_segments_tensor.scalar<NUM_SEGMENTS_TYPE>()();\n \n-    OP_REQUIRES(context, num_segments > 0,\n-                errors::InvalidArgument(\"Number of segments must be positive\"));\n+    OP_REQUIRES(\n+        context, num_segments >= 0,\n+        errors::InvalidArgument(\n+            \"Number of segments must be non-negative but got \", num_segments));\n     OP_REQUIRES(context, segment_dims != 0,\n                 errors::InvalidArgument(\"Segment_id cannot have rank 0\"));\n \n"
        ],
        "func_after": []
    },
    {
        "idx": 196621,
        "project": "mruby",
        "commit_id": "b1d0296a937fe278239bdfac840a3fd0e93b3ee9",
        "project_url": "https://github.com/mruby/mruby",
        "commit_url": "https://github.com/mruby/mruby/commit/b1d0296a937fe278239bdfac840a3fd0e93b3ee9",
        "commit_message": "class.c: clear method cache after `remove_method`.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "mrb_remove_method(mrb_state *mrb, struct RClass *c, mrb_sym mid)\n{\n  mt_tbl *h;\n\n  MRB_CLASS_ORIGIN(c);\n  h = c->mt;\n\n  if (h && mt_del(mrb, h, mid)) return;\n  mrb_name_error(mrb, mid, \"method '%n' not defined in %C\", mid, c);\n}",
        "func_hash": 310092184444521797404238692578019888834,
        "file_name": "class.c",
        "file_hash": null,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2022-1286",
        "cve_desc": "heap-buffer-overflow in mrb_vm_exec in mruby/mruby in GitHub repository mruby/mruby prior to 3.2. Possible arbitrary code execution if being exploited.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-1286",
        "func_name": "mrb_remove_method",
        "diff": [
            "diff --git a/src/class.c b/src/class.c\nindex 37fc4e68a4..68a0ff0843 100644\n--- a/src/class.c\n+++ b/src/class.c\n@@ -2361,7 +2361,10 @@ mrb_remove_method(mrb_state *mrb, struct RClass *c, mrb_sym mid)\n   MRB_CLASS_ORIGIN(c);\n   h = c->mt;\n \n-  if (h && mt_del(mrb, h, mid)) return;\n+  if (h && mt_del(mrb, h, mid)) {\n+    mrb_mc_clear_by_class(mrb, c);\n+    return;\n+  }\n   mrb_name_error(mrb, mid, \"method '%n' not defined in %C\", mid, c);\n }\n \n"
        ],
        "func_after": []
    },
    {
        "idx": 196629,
        "project": "tensorflow",
        "commit_id": "579261dcd446385831fe4f7457d802a59685121d",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/579261dcd446385831fe4f7457d802a59685121d",
        "commit_message": "Fix crash in MatrixSolve when inputs have different batch dimensions.\n\nBefore, the process would crash or certain elements would be silently ignored. Now an InvalidArgument is raised.\n\nPiperOrigin-RevId: 384844020\nChange-Id: Iba44417e383bdd0e1abc4012bfca83b2377dd335",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void ComputeAsync(OpKernelContext* context, DoneCallback done) final {\n    const Tensor& input = context->input(0);\n    const Tensor& rhs = context->input(1);\n    const int ndims = input.dims();\n    const int64 n = input.dim_size(ndims - 1);\n    const int64 nrhs = rhs.dim_size(ndims - 1);\n    // Validate inputs.\n    OP_REQUIRES_ASYNC(\n        context, ndims >= 2,\n        errors::InvalidArgument(\"Input must have rank >= 2, got \", ndims),\n        done);\n    OP_REQUIRES_ASYNC(context, rhs.dims() == ndims,\n                      errors::InvalidArgument(\n                          \"Input and right-hand side must have same rank, got \",\n                          ndims, \" != \", rhs.dims()),\n                      done);\n    OP_REQUIRES_ASYNC(\n        context, input.dim_size(ndims - 2) == n,\n        errors::InvalidArgument(\"Input matrices must be squares, got\",\n                                input.dim_size(ndims - 2), \" != \", n),\n        done);\n    OP_REQUIRES_ASYNC(context, rhs.dim_size(ndims - 2) == n,\n                      errors::InvalidArgument(\n                          \"Input matrix and right-hand side must have the \"\n                          \"same number of rows, got\",\n                          n, \" != \", rhs.dim_size(ndims - 2)),\n                      done);\n\n    // Allocate output.\n    Tensor* output;\n    OP_REQUIRES_OK_ASYNC(\n        context,\n        context->forward_input_or_allocate_output({1}, 0, rhs.shape(), &output),\n        done);\n\n    // To be consistent with the MatrixInverse op, we define the solution for\n    // an empty set of equations as the empty matrix.\n    if (input.NumElements() == 0 || rhs.NumElements() == 0) {\n      done();\n      return;\n    }\n\n    // TODO(rmlarsen): Convert to std::make_unique when available.\n    std::unique_ptr<CudaSolver> solver(new CudaSolver(context));\n\n    // Make a copy of the input for the factorization step, or, if adjoint_ is\n    // false, try to reuse the input buffer if this op owns it exclusively.\n    Tensor input_copy;\n    const GPUDevice& device = context->eigen_device<GPUDevice>();\n    if (adjoint_) {\n      // For the adjoint case, it is simpler to always make a transposed copy up\n      // front.\n      OP_REQUIRES_OK_ASYNC(\n          context,\n          solver->allocate_scoped_tensor(DataTypeToEnum<Scalar>::value,\n                                         input.shape(), &input_copy),\n          done);\n      OP_REQUIRES_OK_ASYNC(context,\n                           DoMatrixTranspose(device, input, &input_copy), done);\n    } else {\n      OP_REQUIRES_OK_ASYNC(\n          context,\n          solver->forward_input_or_allocate_scoped_tensor(\n              {0}, DataTypeToEnum<Scalar>::value, input.shape(), &input_copy),\n          done);\n      if (!input.SharesBufferWith(input_copy)) {\n        device.memcpy(input_copy.flat<Scalar>().data(),\n                      input.flat<Scalar>().data(),\n                      input.NumElements() * sizeof(Scalar));\n      }\n    }\n    auto input_copy_reshaped = input_copy.template flat_inner_dims<Scalar, 3>();\n    const int64 batch_size = input_copy_reshaped.dimension(0);\n\n    // Allocate pivots on the device.\n    Tensor pivots;\n    OP_REQUIRES_OK_ASYNC(\n        context,\n        solver->allocate_scoped_tensor(DataTypeToEnum<int>::value,\n                                       TensorShape{batch_size, n}, &pivots),\n        done);\n    auto pivots_mat = pivots.template matrix<int>();\n\n    // 1. Compute the partially pivoted LU factorization(s) of the\n    // matrix/matrices.\n    std::vector<DeviceLapackInfo> dev_info;\n    auto input_copy_ptrs = solver->GetScratchSpace<uint8>(\n        sizeof(Scalar*) * batch_size, \"input_copt_ptrs\",\n        /* on_host */ true);\n    const int kMaxMatrixSizeToBatchSizeRatio = 128;\n    const bool use_batched_solver =\n        n <= kMaxMatrixSizeToBatchSizeRatio * batch_size;\n    if (use_batched_solver) {\n      // For small matrices or large batch sizes, we use the batched interface\n      // from cuBlas.\n      const Scalar** input_copy_ptrs_base =\n          reinterpret_cast<const Scalar**>(input_copy_ptrs.mutable_data());\n      for (int batch = 0; batch < batch_size; ++batch) {\n        input_copy_ptrs_base[batch] = &input_copy_reshaped(batch, 0, 0);\n      }\n      dev_info.push_back(\n          solver->GetDeviceLapackInfo(batch_size, \"getrfBatched\"));\n      OP_REQUIRES_OK_ASYNC(\n          context,\n          solver->GetrfBatched(n, input_copy_ptrs_base, n, pivots_mat.data(),\n                               &dev_info.back(), batch_size),\n          done);\n    } else {\n      // For small batch sizes or large matrices, we use the non-batched\n      // interface from cuSolver, which is much faster for large matrices.\n      dev_info.push_back(solver->GetDeviceLapackInfo(batch_size, \"getrf\"));\n      for (int batch = 0; batch < batch_size; ++batch) {\n        OP_REQUIRES_OK_ASYNC(\n            context,\n            solver->Getrf(n, n, &input_copy_reshaped(batch, 0, 0), n,\n                          &pivots_mat(batch, 0), &dev_info.back()(batch)),\n            done);\n      }\n    }\n\n    // 2. Make a transposed copy of the right-hand sides. This is necessary\n    // because cuBLAS assumes column-major storage while TensorFlow TF uses\n    // row-major.\n    TensorShape transposed_rhs_shape(rhs.shape());\n    transposed_rhs_shape.RemoveLastDims(2);\n    transposed_rhs_shape.AddDim(nrhs);\n    transposed_rhs_shape.AddDim(n);\n    Tensor transposed_rhs;\n    OP_REQUIRES_OK_ASYNC(\n        context,\n        solver->allocate_scoped_tensor(DataTypeToEnum<Scalar>::value,\n                                       transposed_rhs_shape, &transposed_rhs),\n        done);\n    if (nrhs > 1) {\n      OP_REQUIRES_OK_ASYNC(\n          context, DoMatrixTranspose(device, rhs, &transposed_rhs), done);\n    } else {\n      device.memcpy(transposed_rhs.flat<Scalar>().data(),\n                    rhs.flat<Scalar>().data(),\n                    rhs.NumElements() * sizeof(Scalar));\n    }\n\n    // 3. Solve op(A) X = B (in column major form).\n    // We use a trick here: If adjoint_ is true, we converted A to column major\n    // form above. If adjoint is false then I leave A in row-major form and use\n    // trans_a = CUBLAS_OP_T to effectively transform it to column-major on the\n    // fly. (This means that we actually use the LU-factorization of A^T in that\n    // case, but that is equally good for solving AX=B). This way we save an\n    // explicit transpose in the more common case of adjoint_ == false.\n    auto input_copy_ptr_array = solver->GetScratchSpace<uint8>(\n        sizeof(Scalar*) * batch_size, \"input_copy_ptr_array\",\n        /* on_host */ true);\n    auto transposed_rhs_ptr_array = solver->GetScratchSpace<uint8>(\n        sizeof(Scalar*) * batch_size, \"transposed_rhs_ptr_array\",\n        /* on_host */ true);\n    auto transposed_rhs_reshaped =\n        transposed_rhs.template flat_inner_dims<Scalar, 3>();\n    if (use_batched_solver) {\n      const Scalar** input_copy_ptrs_base =\n          reinterpret_cast<const Scalar**>(input_copy_ptr_array.mutable_data());\n      const Scalar** transposed_rhs_ptrs_base =\n          reinterpret_cast<const Scalar**>(\n              transposed_rhs_ptr_array.mutable_data());\n      for (int batch = 0; batch < batch_size; ++batch) {\n        input_copy_ptrs_base[batch] = &input_copy_reshaped(batch, 0, 0);\n        transposed_rhs_ptrs_base[batch] = &transposed_rhs_reshaped(batch, 0, 0);\n      }\n      int host_info = 0;\n      OP_REQUIRES_OK_ASYNC(\n          context,\n          solver->GetrsBatched(adjoint_ ? CUBLAS_OP_C : CUBLAS_OP_T, n, nrhs,\n                               input_copy_ptrs_base, n, pivots_mat.data(),\n                               transposed_rhs_ptrs_base, n, &host_info,\n                               batch_size),\n          done);\n      OP_REQUIRES_ASYNC(\n          context, host_info == 0,\n          errors::InvalidArgument(\"The \", -host_info,\n                                  \"'th argument to cublas*getrsBatched had \"\n                                  \"an illegal value.\"),\n          done);\n    } else {\n      dev_info.push_back(solver->GetDeviceLapackInfo(batch_size, \"getrs\"));\n      for (int batch = 0; batch < batch_size; ++batch) {\n        OP_REQUIRES_OK_ASYNC(\n            context,\n            solver->Getrs(adjoint_ ? CUBLAS_OP_C : CUBLAS_OP_T, n, nrhs,\n                          &input_copy_reshaped(batch, 0, 0), n,\n                          &pivots_mat(batch, 0),\n                          &transposed_rhs_reshaped(batch, 0, 0), n,\n                          &dev_info.back()(batch)),\n            done);\n      }\n    }\n\n    // 4. Transpose X to get the final result in row-major form.\n    if (nrhs > 1) {\n      OP_REQUIRES_OK_ASYNC(\n          context, DoMatrixTranspose(device, transposed_rhs, output), done);\n    } else {\n      device.memcpy(output->flat<Scalar>().data(),\n                    transposed_rhs.flat<Scalar>().data(),\n                    transposed_rhs.NumElements() * sizeof(Scalar));\n    }\n\n    // Callback for checking info after kernels finish. Also capture the\n    // temporary Tensors/ScratchSpace so they don't get deallocated before the\n    // kernels run. TODO(rmlarsen): Use move capture once C++14 becomes\n    // available.\n    auto info_checker = [context, done, dev_info](\n                            const Status& status,\n                            const std::vector<HostLapackInfo>& host_infos) {\n      if (!status.ok() && errors::IsInvalidArgument(status) &&\n          !host_infos.empty()) {\n        for (int i = 0; i < host_infos[0].size(); ++i) {\n          // Match the CPU error message for singular matrices. Otherwise\n          // just print the original error message from the status below.\n          OP_REQUIRES_ASYNC(context, host_infos[0].data()[i] <= 0,\n                            errors::InvalidArgument(kErrMsg), done);\n        }\n      }\n      OP_REQUIRES_OK_ASYNC(context, status, done);\n      done();\n    };\n    CudaSolver::CheckLapackInfoAndDeleteSolverAsync(std::move(solver), dev_info,\n                                                    std::move(info_checker));\n  }",
        "func_hash": 232512673394609281083836207268567643755,
        "file_name": "matrix_solve_op.cc",
        "file_hash": 18056043033202767652193305242094140715,
        "cwe": [
            "CWE-354"
        ],
        "cve": "CVE-2021-41206",
        "cve_desc": "TensorFlow is an open source platform for machine learning. In affected versions several TensorFlow operations are missing validation for the shapes of the tensor arguments involved in the call. Depending on the API, this can result in undefined behavior and segfault or `CHECK`-fail related crashes but in some scenarios writes and reads from heap populated arrays are also possible. We have discovered these issues internally via tooling while working on improving/testing GPU op determinism. As such, we don't have reproducers and there will be multiple fixes for these issues. These fixes will be included in TensorFlow 2.7.0. We will also cherrypick these commits on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-41206",
        "func_name": "ComputeAsync",
        "diff": [
            "diff --git a/tensorflow/core/kernels/linalg/matrix_solve_op.cc b/tensorflow/core/kernels/linalg/matrix_solve_op.cc\nindex 70f02bddf9b785..aeb0203b4a337d 100644\n--- a/tensorflow/core/kernels/linalg/matrix_solve_op.cc\n+++ b/tensorflow/core/kernels/linalg/matrix_solve_op.cc\n@@ -143,15 +143,22 @@ class MatrixSolveOpGpu : public AsyncOpKernel {\n                       done);\n     OP_REQUIRES_ASYNC(\n         context, input.dim_size(ndims - 2) == n,\n-        errors::InvalidArgument(\"Input matrices must be squares, got\",\n+        errors::InvalidArgument(\"Input matrices must be squares, got \",\n                                 input.dim_size(ndims - 2), \" != \", n),\n         done);\n     OP_REQUIRES_ASYNC(context, rhs.dim_size(ndims - 2) == n,\n                       errors::InvalidArgument(\n                           \"Input matrix and right-hand side must have the \"\n-                          \"same number of rows, got\",\n+                          \"same number of rows, got \",\n                           n, \" != \", rhs.dim_size(ndims - 2)),\n                       done);\n+    for (int dim = 0; dim < ndims - 2; dim++) {\n+      OP_REQUIRES_ASYNC(\n+          context, input.dim_size(dim) == rhs.dim_size(dim),\n+          errors::InvalidArgument(\n+              \"All input tensors must have the same outer dimensions.\"),\n+          done);\n+    }\n \n     // Allocate output.\n     Tensor* output;\ndiff --git a/tensorflow/python/kernel_tests/matrix_solve_op_test.py b/tensorflow/python/kernel_tests/matrix_solve_op_test.py\nindex 0d149de2acb5e5..1739b2272be810 100644\n--- a/tensorflow/python/kernel_tests/matrix_solve_op_test.py\n+++ b/tensorflow/python/kernel_tests/matrix_solve_op_test.py\n@@ -112,6 +112,12 @@ def testWrongDimensions(self):\n     with self.assertRaises((ValueError, errors_impl.InvalidArgumentError)):\n       self.evaluate(linalg_ops.matrix_solve(matrix, rhs))\n \n+    # The matrix and right-hand side should have the same batch dimensions\n+    matrix = np.random.normal(size=(2, 6, 2, 2))\n+    rhs = np.random.normal(size=(2, 3, 2, 2))\n+    with self.assertRaises((ValueError, errors_impl.InvalidArgumentError)):\n+      self.evaluate(linalg_ops.matrix_solve(matrix, rhs))\n+\n   def testNotInvertible(self):\n     # The input should be invertible.\n     with self.assertRaisesOpError(\"Input matrix is not invertible.\"):\n"
        ],
        "func_after": []
    },
    {
        "idx": 196689,
        "project": "tensorflow",
        "commit_id": "cebe3c45d76357d201c65bdbbf0dbe6e8a63bbdb",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/cebe3c45d76357d201c65bdbbf0dbe6e8a63bbdb",
        "commit_message": "Fix tf.raw_ops.StagePeek vulnerability with invalid `index`.\n\nCheck that input is actually a scalar before treating it as such.\n\nPiperOrigin-RevId: 445524908",
        "target": 1,
        "irrelevant": 1,
        "func_before": "  void Compute(OpKernelContext* ctx) override {\n    Buffer* buf = nullptr;\n    OP_REQUIRES_OK(ctx, GetBuffer(ctx, def(), &buf));\n    core::ScopedUnref scope(buf);\n    Buffer::Tuple tuple;\n\n    std::size_t index = ctx->input(0).scalar<int>()();\n\n    OP_REQUIRES_OK(ctx, buf->Peek(index, &tuple));\n\n    OP_REQUIRES(\n        ctx, tuple.size() == (size_t)ctx->num_outputs(),\n        errors::InvalidArgument(\"Mismatch stage/unstage: \", tuple.size(),\n                                \" vs. \", ctx->num_outputs()));\n\n    for (size_t i = 0; i < tuple.size(); ++i) {\n      ctx->set_output(i, tuple[i]);\n    }\n  }",
        "func_hash": 321476459442808105718031824942985787186,
        "file_name": "stage_op.cc",
        "file_hash": 203338145673187111221975146552959312769,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2022-29195",
        "cve_desc": "TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, the implementation of `tf.raw_ops.StagePeek` does not fully validate the input arguments. This results in a `CHECK`-failure which can be used to trigger a denial of service attack. The code assumes `index` is a scalar but there is no validation for this before accessing its value. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-29195",
        "func_name": "Compute",
        "diff": [
            "diff --git a/tensorflow/core/kernels/stage_op.cc b/tensorflow/core/kernels/stage_op.cc\nindex 55c9db22ddf527..f7bb42f9c52b7d 100644\n--- a/tensorflow/core/kernels/stage_op.cc\n+++ b/tensorflow/core/kernels/stage_op.cc\n@@ -258,6 +258,8 @@ class StagePeekOp : public OpKernel {\n     core::ScopedUnref scope(buf);\n     Buffer::Tuple tuple;\n \n+    OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(ctx->input(0).shape()),\n+                errors::InvalidArgument(\"index must be scalar\"));\n     std::size_t index = ctx->input(0).scalar<int>()();\n \n     OP_REQUIRES_OK(ctx, buf->Peek(index, &tuple));\ndiff --git a/tensorflow/python/kernel_tests/data_structures/stage_op_test.py b/tensorflow/python/kernel_tests/data_structures/stage_op_test.py\nindex c720155f3b6c90..d12624f1065928 100644\n--- a/tensorflow/python/kernel_tests/data_structures/stage_op_test.py\n+++ b/tensorflow/python/kernel_tests/data_structures/stage_op_test.py\n@@ -13,6 +13,7 @@\n # limitations under the License.\n # ==============================================================================\n from tensorflow.python.framework import dtypes\n+from tensorflow.python.framework import errors\n from tensorflow.python.framework import ops\n from tensorflow.python.framework import test_util\n from tensorflow.python.ops import array_ops\n@@ -134,6 +135,16 @@ def testPeek(self):\n       for i in range(10):\n         self.assertTrue(sess.run(peek, feed_dict={p: i}) == [i])\n \n+  def testPeekBadIndex(self):\n+    stager = data_flow_ops.StagingArea([\n+        dtypes.int32,\n+    ], shapes=[[10]])\n+    stager.put([array_ops.zeros([10], dtype=dtypes.int32)])\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                'must be scalar'):\n+      self.evaluate(stager.peek([]))\n+\n   @test_util.run_deprecated_v1\n   def testSizeAndClear(self):\n     with ops.Graph().as_default() as G:\ndiff --git a/tensorflow/python/ops/data_flow_ops.py b/tensorflow/python/ops/data_flow_ops.py\nindex 0076e54833de6c..42fd28c8cc1e60 100644\n--- a/tensorflow/python/ops/data_flow_ops.py\n+++ b/tensorflow/python/ops/data_flow_ops.py\n@@ -1737,7 +1737,7 @@ def _check_put_dtypes(self, vals, indices=None):\n \n     # Sanity check number of values\n     if not len(vals) <= len(self._dtypes):\n-      raise ValueError(f\"Unexpected number of inputs {len(vals)} vs\"\n+      raise ValueError(f\"Unexpected number of inputs {len(vals)} vs \"\n                        f\"{len(self._dtypes)}\")\n \n     tensors = []\n"
        ],
        "func_after": []
    },
    {
        "idx": 196691,
        "project": "gpac",
        "commit_id": "71460d72ec07df766dab0a4d52687529f3efcf0a",
        "project_url": "https://github.com/gpac/gpac",
        "commit_url": "https://github.com/gpac/gpac/commit/71460d72ec07df766dab0a4d52687529f3efcf0a",
        "commit_message": "fixed #1876",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static GF_Err isoffin_process(GF_Filter *filter)\n{\n\tISOMReader *read = gf_filter_get_udta(filter);\n\tu32 i, count = gf_list_count(read->channels);\n\tBool is_active = GF_FALSE;\n\tBool in_is_eos = GF_FALSE;\n\tBool check_forced_end = GF_FALSE;\n\tBool has_new_data = GF_FALSE;\n\tu64 min_offset_plus_one = 0;\n\tu32 nb_forced_end=0;\n\tif (read->in_error)\n\t\treturn read->in_error;\n\n\tif (read->pid) {\n\t\tBool fetch_input = GF_TRUE;\n\n\t\t//we failed at loading the init segment during a dash switch, retry\n\t\tif (!read->is_partial_download && !read->mem_load_mode && (read->moov_not_loaded==2) ) {\n\t\t\tisoffin_configure_pid(filter, read->pid, GF_FALSE);\n\t\t\tif (read->moov_not_loaded) return GF_OK;\n\t\t}\n\t\tif (read->mem_load_mode==2) {\n\t\t\tif (!read->force_fetch && read->mem_blob.size > read->mstore_size) {\n\t\t\t\tfetch_input = GF_FALSE;\n\t\t\t}\n\t\t\tread->force_fetch = GF_FALSE;\n\t\t}\n\t\twhile (fetch_input) {\n\t\t\tGF_FilterPacket *pck = gf_filter_pid_get_packet(read->pid);\n\t\t\tif (!pck) {\n\t\t\t\t//we issued a seek, wait for the first packet to be received before fetching channels\n\t\t\t\t//otherwise we could end up reading from the wrong cache\n\t\t\t\tif (read->wait_for_source) {\n\t\t\t\t\t//something went wrong during the seek request\n\t\t\t\t\tif (gf_filter_pid_is_eos(read->pid))\n\t\t\t\t\t\treturn GF_EOS;\n\t\t\t\t\treturn GF_OK;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tread->wait_for_source = GF_FALSE;\n\n\t\t\tif (read->mem_load_mode) {\n\t\t\t\tu32 data_size;\n\t\t\t\tconst u8 *pck_data = gf_filter_pck_get_data(pck, &data_size);\n\t\t\t\tisoffin_push_buffer(filter, read, pck_data, data_size);\n\t\t\t}\n\t\t\t//we just had a switch but init seg is not completely done: input packet is only a part of the init, drop it\n\t\t\telse if (read->moov_not_loaded==2) {\n\t\t\t\tgf_filter_pid_drop_packet(read->pid);\n\t\t\t\treturn GF_OK;\n\t\t\t}\n\t\t\tgf_filter_pid_drop_packet(read->pid);\n\t\t\thas_new_data = GF_TRUE;\n\t\t\tif (read->in_error)\n\t\t\t\treturn read->in_error;\n\t\t}\n\t\tif (gf_filter_pid_is_eos(read->pid)) {\n\t\t\tread->input_loaded = GF_TRUE;\n\t\t\tin_is_eos = GF_TRUE;\n\t\t}\n\t\tif (read->input_is_stop) {\n\t\t\tread->input_loaded = GF_TRUE;\n\t\t\tin_is_eos = GF_TRUE;\n\t\t\tread->input_is_stop = GF_FALSE;\n\t\t}\n\t\tif (!read->frag_type && read->input_loaded) {\n\t\t\tin_is_eos = GF_TRUE;\n\t\t}\n        //segment is invalid, wait for eos on input an send eos on all channels\n        if (read->invalid_segment) {\n            if (!in_is_eos) return GF_OK;\n            read->invalid_segment = GF_FALSE;\n\n            for (i=0; i<count; i++) {\n                ISOMChannel *ch = gf_list_get(read->channels, i);\n                if (!ch->playing) {\n                    continue;\n                }\n                if (!ch->eos_sent) {\n                    ch->eos_sent = GF_TRUE;\n                    gf_filter_pid_set_eos(ch->pid);\n                }\n            }\n            read->eos_signaled = GF_TRUE;\n            return GF_EOS;\n        }\n\t} else if (read->extern_mov) {\n\t\tin_is_eos = GF_TRUE;\n\t\tread->input_loaded = GF_TRUE;\n\t}\n\tif (read->moov_not_loaded==1) {\n\t\tif (read->mem_load_mode)\n\t\t\treturn GF_OK;\n\t\tread->moov_not_loaded = GF_FALSE;\n\t\treturn isoffin_setup(filter, read);\n\t}\n\n\tif (read->refresh_fragmented) {\n\t\tconst GF_PropertyValue *prop;\n\n\t\tif (in_is_eos) {\n\t\t\tread->refresh_fragmented = GF_FALSE;\n\t\t} else {\n\t\t\tprop = gf_filter_pid_get_property(read->pid, GF_PROP_PID_FILE_CACHED);\n\t\t\tif (prop && prop->value.boolean)\n\t\t\t\tread->refresh_fragmented = GF_FALSE;\n\t\t}\n\n\t\tif (has_new_data) {\n\t\t\tu64 bytesMissing=0;\n\t\t\tGF_Err e;\n\t\t\tconst char *new_url = NULL;\n\t\t\tprop = gf_filter_pid_get_property(read->pid, GF_PROP_PID_FILEPATH);\n\t\t\tif (prop) new_url = prop->value.string;\n\n\t\t\te = gf_isom_refresh_fragmented(read->mov, &bytesMissing, new_url);\n\n\t\t\tif (e && (e!= GF_ISOM_INCOMPLETE_FILE)) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_DASH, (\"[IsoMedia] Failed to refresh current segment: %s\\n\", gf_error_to_string(e) ));\n\t\t\t\tread->refresh_fragmented = GF_FALSE;\n\t\t\t} else {\n\t\t\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_DASH, (\"[IsoMedia] Refreshing current segment at UTC \"LLU\" - \"LLU\" bytes still missing - input is EOS %d\\n\", gf_net_get_utc(), bytesMissing, in_is_eos));\n\t\t\t}\n\n\t\t\tif (!read->refresh_fragmented && (e==GF_ISOM_INCOMPLETE_FILE)) {\n\t\t\t\tGF_LOG(GF_LOG_WARNING, GF_LOG_DASH, (\"[IsoMedia] Incomplete Segment received - \"LLU\" bytes missing but EOF found\\n\", bytesMissing ));\n\t\t\t}\n\n#ifndef GPAC_DISABLE_LOG\n\t\t\tif (gf_log_tool_level_on(GF_LOG_DASH, GF_LOG_DEBUG)) {\n\t\t\t\tfor (i=0; i<count; i++) {\n\t\t\t\t\tISOMChannel *ch = gf_list_get(read->channels, i);\n\t\t\t\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_DASH, (\"[IsoMedia] refresh track %d fragment - cur sample %d - new sample count %d\\n\", ch->track, ch->sample_num, gf_isom_get_sample_count(ch->owner->mov, ch->track) ));\n\t\t\t\t}\n\t\t\t}\n#endif\n\t\t\tisor_check_producer_ref_time(read);\n\t\t\tif (!read->frag_type)\n\t\t\t\tread->refresh_fragmented = GF_FALSE;\n\t\t}\n\t}\n\n\tfor (i=0; i<count; i++) {\n\t\tu8 *data;\n\t\tu32 nb_pck=50;\n\t\tISOMChannel *ch;\n\t\tch = gf_list_get(read->channels, i);\n\t\tif (!ch->playing) {\n\t\t\tnb_forced_end++;\n\t\t\tcontinue;\n\t\t}\n\t\t//eos not sent on this channel, we are active\n\t\tif (!ch->eos_sent)\n\t\t\tis_active = GF_TRUE;\n\n\t\twhile (nb_pck) {\n\t\t\tch->sample_data_offset = 0;\n\t\t\tif (!read->full_segment_flush && gf_filter_pid_would_block(ch->pid) )\n\t\t\t\tbreak;\n\n\t\t\tif (ch->item_id) {\n\t\t\t\tisor_reader_get_sample_from_item(ch);\n\t\t\t} else {\n\t\t\t\tisor_reader_get_sample(ch);\n\t\t\t}\n\n\t\t\tif (read->stsd && (ch->last_sample_desc_index != read->stsd) && ch->sample) {\n\t\t\t\tisor_reader_release_sample(ch);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (ch->sample) {\n\t\t\t\tu32 sample_dur;\n\t\t\t\tu8 dep_flags;\n\t\t\t\tu8 *subs_buf;\n\t\t\t\tu32 subs_buf_size;\n\t\t\t\tGF_FilterPacket *pck;\n\t\t\t\tif (ch->needs_pid_reconfig) {\n\t\t\t\t\tisor_update_channel_config(ch);\n\t\t\t\t\tch->needs_pid_reconfig = GF_FALSE;\n\t\t\t\t}\n\n\t\t\t\t//we have at least two samples, update GF_PROP_PID_HAS_SYNC if needed\n\t\t\t\tif (ch->check_has_rap && (gf_isom_get_sample_count(ch->owner->mov, ch->track)>1) && (gf_isom_has_sync_points(ch->owner->mov, ch->track)==1)) {\n\t\t\t\t\tch->check_has_rap = GF_FALSE;\n\t\t\t\t\tch->has_rap = GF_TRUE;\n\t\t\t\t\tgf_filter_pid_set_property(ch->pid, GF_PROP_PID_HAS_SYNC, &PROP_BOOL(ch->has_rap) );\n\t\t\t\t}\n\n\t\t\t\t//strip param sets from payload, trigger reconfig if needed\n\t\t\t\tisor_reader_check_config(ch);\n\n\t\t\t\tif (read->nodata) {\n\t\t\t\t\tpck = gf_filter_pck_new_shared(ch->pid, NULL, ch->sample->dataLength, NULL);\n\t\t\t\t\tif (!pck) return GF_OUT_OF_MEM;\n\t\t\t\t} else {\n\t\t\t\t\tpck = gf_filter_pck_new_alloc(ch->pid, ch->sample->dataLength, &data);\n\t\t\t\t\tif (!pck) return GF_OUT_OF_MEM;\n\n\t\t\t\t\tmemcpy(data, ch->sample->data, ch->sample->dataLength);\n\t\t\t\t}\n\t\t\t\tgf_filter_pck_set_dts(pck, ch->dts);\n\t\t\t\tgf_filter_pck_set_cts(pck, ch->cts);\n\t\t\t\tif (ch->sample->IsRAP==-1) {\n\t\t\t\t\tgf_filter_pck_set_sap(pck, GF_FILTER_SAP_1);\n\t\t\t\t\tch->redundant = 1;\n\t\t\t\t} else {\n\t\t\t\t\tgf_filter_pck_set_sap(pck, (GF_FilterSAPType) ch->sample->IsRAP);\n\t\t\t\t}\n\n\t\t\t\tif (ch->sap_3)\n\t\t\t\t\tgf_filter_pck_set_sap(pck, GF_FILTER_SAP_3);\n\t\t\t\telse if (ch->sap_4_type) {\n\t\t\t\t\tgf_filter_pck_set_sap(pck, (ch->sap_4_type==GF_ISOM_SAMPLE_PREROLL) ? GF_FILTER_SAP_4_PROL : GF_FILTER_SAP_4);\n\t\t\t\t\tgf_filter_pck_set_roll_info(pck, ch->roll);\n\t\t\t\t}\n\n\t\t\t\tsample_dur = ch->au_duration;\n\t\t\t\tif (ch->sample->nb_pack)\n\t\t\t\t\tsample_dur *= ch->sample->nb_pack;\n\t\t\t\tgf_filter_pck_set_duration(pck, sample_dur);\n\t\t\t\tgf_filter_pck_set_seek_flag(pck, ch->seek_flag);\n\n\t\t\t\t//for now we only signal xPS mask for non-sap\n\t\t\t\tif (ch->xps_mask && !gf_filter_pck_get_sap(pck) ) {\n\t\t\t\t\tgf_filter_pck_set_property(pck, GF_PROP_PCK_XPS_MASK, &PROP_UINT(ch->xps_mask) );\n\t\t\t\t}\n\n\t\t\t\tdep_flags = ch->isLeading;\n\t\t\t\tdep_flags <<= 2;\n\t\t\t\tdep_flags |= ch->dependsOn;\n\t\t\t\tdep_flags <<= 2;\n\t\t\t\tdep_flags |= ch->dependedOn;\n\t\t\t\tdep_flags <<= 2;\n\t\t\t\tdep_flags |= ch->redundant;\n\n\t\t\t\tif (dep_flags)\n\t\t\t\t\tgf_filter_pck_set_dependency_flags(pck, dep_flags);\n\n\t\t\t\tgf_filter_pck_set_crypt_flags(pck, ch->pck_encrypted ? GF_FILTER_PCK_CRYPT : 0);\n\t\t\t\tgf_filter_pck_set_seq_num(pck, ch->sample_num);\n\n\n\t\t\t\tsubs_buf = gf_isom_sample_get_subsamples_buffer(read->mov, ch->track, ch->sample_num, &subs_buf_size);\n\t\t\t\tif (subs_buf) {\n\t\t\t\t\tgf_filter_pck_set_property(pck, GF_PROP_PCK_SUBS, &PROP_DATA_NO_COPY(subs_buf, subs_buf_size) );\n\t\t\t\t}\n\n\t\t\t\tif (ch->sai_buffer && ch->pck_encrypted) {\n\t\t\t\t\tassert(ch->sai_buffer_size);\n\t\t\t\t\tgf_filter_pck_set_property(pck, GF_PROP_PCK_CENC_SAI, &PROP_DATA(ch->sai_buffer, ch->sai_buffer_size) );\n\t\t\t\t}\n\n\t\t\t\tif (read->sigfrag) {\n\t\t\t\t\tGF_ISOFragmentBoundaryInfo finfo;\n\t\t\t\t\tif (gf_isom_sample_is_fragment_start(read->mov, ch->track, ch->sample_num, &finfo) ) {\n\t\t\t\t\t\tu64 start=0;\n\t\t\t\t\t\tu32 traf_start = finfo.seg_start_plus_one ? 2 : 1;\n\n\t\t\t\t\t\tif (finfo.seg_start_plus_one)\n\t\t\t\t\t\t\tgf_filter_pck_set_property(pck, GF_PROP_PCK_CUE_START, &PROP_BOOL(GF_TRUE));\n\n\t\t\t\t\t\tgf_filter_pck_set_property(pck, GF_PROP_PCK_FRAG_START, &PROP_UINT(traf_start));\n\n\t\t\t\t\t\tstart = finfo.frag_start;\n\t\t\t\t\t\tif (finfo.seg_start_plus_one) start = finfo.seg_start_plus_one-1;\n\t\t\t\t\t\tgf_filter_pck_set_property(pck, GF_PROP_PCK_FRAG_RANGE, &PROP_FRAC64_INT(start, finfo.mdat_end));\n\t\t\t\t\t\tif (finfo.moof_template) {\n\t\t\t\t\t\t\tgf_filter_pck_set_property(pck, GF_PROP_PCK_MOOF_TEMPLATE, &PROP_DATA((u8 *)finfo.moof_template, finfo.moof_template_size));\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (finfo.sidx_end) {\n\t\t\t\t\t\t\tgf_filter_pck_set_property(pck, GF_PROP_PCK_SIDX_RANGE, &PROP_FRAC64_INT(finfo.sidx_start , finfo.sidx_end));\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tif (read->seg_name_changed) {\n\t\t\t\t\t\t\tconst GF_PropertyValue *p = gf_filter_pid_get_property(read->pid, GF_PROP_PID_URL);\n\t\t\t\t\t\t\tread->seg_name_changed = GF_FALSE;\n\t\t\t\t\t\t\tif (p && p->value.string) {\n\t\t\t\t\t\t\t\tgf_filter_pck_set_property(pck, GF_PROP_PID_URL, &PROP_STRING(p->value.string));\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (ch->sender_ntp) {\n\t\t\t\t\tgf_filter_pck_set_property(pck, GF_PROP_PCK_SENDER_NTP, &PROP_LONGUINT(ch->sender_ntp));\n\t\t\t\t\tif (ch->ntp_at_server_ntp) {\n\t\t\t\t\t\tgf_filter_pck_set_property(pck, GF_PROP_PCK_RECEIVER_NTP, &PROP_LONGUINT(ch->ntp_at_server_ntp));\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tch->eos_sent = GF_FALSE;\n\n\t\t\t\t//this might not be the true end of stream\n\t\t\t\tif ((ch->streamType==GF_STREAM_AUDIO) && (ch->sample_num == gf_isom_get_sample_count(read->mov, ch->track))) {\n\t\t\t\t\tgf_filter_pck_set_property(pck, GF_PROP_PCK_END_RANGE, &PROP_BOOL(GF_TRUE));\n\t\t\t\t}\n\n\t\t\t\tgf_filter_pck_send(pck);\n\t\t\t\tisor_reader_release_sample(ch);\n\n\t\t\t\tch->last_valid_sample_data_offset = ch->sample_data_offset;\n\t\t\t\tnb_pck--;\n\t\t\t} else if (ch->last_state==GF_EOS) {\n\t\t\t\tif (ch->playing == 2) {\n\t\t\t\t\tif (in_is_eos) {\n\t\t\t\t\t\tch->playing = GF_FALSE;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tnb_forced_end++;\n\t\t\t\t\t\tcheck_forced_end = GF_TRUE;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (in_is_eos && !ch->eos_sent) {\n\t\t\t\t\tvoid *tfrf;\n\t\t\t\t\tconst void *gf_isom_get_tfrf(GF_ISOFile *movie, u32 trackNumber);\n\n\t\t\t\t\tch->eos_sent = GF_TRUE;\n\t\t\t\t\tread->eos_signaled = GF_TRUE;\n\n\t\t\t\t\ttfrf = (void *) gf_isom_get_tfrf(read->mov, ch->track);\n\t\t\t\t\tif (tfrf) {\n\t\t\t\t\t\tgf_filter_pid_set_info_str(ch->pid, \"smooth_tfrf\", &PROP_POINTER(tfrf) );\n\t\t\t\t\t\tch->last_has_tfrf = GF_TRUE;\n\t\t\t\t\t} else if (ch->last_has_tfrf) {\n\t\t\t\t\t\tgf_filter_pid_set_info_str(ch->pid, \"smooth_tfrf\", NULL);\n\t\t\t\t\t\tch->last_has_tfrf = GF_FALSE;\n\t\t\t\t\t}\n\n\t\t\t\t\tgf_filter_pid_set_eos(ch->pid);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t} else {\n\t\t\t\tread->force_fetch = GF_TRUE;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (!min_offset_plus_one || (min_offset_plus_one - 1 > ch->last_valid_sample_data_offset))\n\t\t\tmin_offset_plus_one = 1 + ch->last_valid_sample_data_offset;\n\t}\n\tif (read->mem_load_mode && min_offset_plus_one) {\n\t\tisoffin_purge_mem(read, min_offset_plus_one-1);\n\t}\n\n\t//we reached end of playback due to play range request, we must send eos - however for safety reason with DASH, we first need to cancel the input\n\tif (read->pid && check_forced_end && (nb_forced_end==count)) {\n\t\t//abort input\n\t\tGF_FilterEvent evt;\n\t\tGF_FEVT_INIT(evt, GF_FEVT_STOP, read->pid);\n\t\tgf_filter_pid_send_event(read->pid, &evt);\n\t}\n\n\n\tif (!is_active) {\n\t\treturn GF_EOS;\n\t}\n\t//if (in_is_eos)\n//\tgf_filter_ask_rt_reschedule(filter, 1);\n\treturn GF_OK;\n\n}",
        "func_hash": 245491994913846374509516795584789756192,
        "file_name": "isoffin_read.c",
        "file_hash": 80320074166992838039801529564251755054,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2021-40592",
        "cve_desc": "GPAC version before commit 71460d72ec07df766dab0a4d52687529f3efcf0a (version v1.0.1 onwards) contains loop with unreachable exit condition ('infinite loop') vulnerability in ISOBMFF reader filter, isoffin_read.c. Function isoffin_process() can result in DoS by infinite loop. To exploit, the victim must open a specially crafted mp4 file.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-40592",
        "func_name": "isoffin_process",
        "diff": [
            "diff --git a/src/filters/isoffin_read.c b/src/filters/isoffin_read.c\nindex 899d3508a5..1f0d3742b5 100644\n--- a/src/filters/isoffin_read.c\n+++ b/src/filters/isoffin_read.c\n@@ -1453,6 +1453,13 @@ static GF_Err isoffin_process(GF_Filter *filter)\n \t\t\t\t\tgf_filter_pid_set_eos(ch->pid);\n \t\t\t\t}\n \t\t\t\tbreak;\n+\t\t\t} else if (ch->last_state==GF_ISOM_INVALID_FILE) {\n+\t\t\t\tif (!ch->eos_sent) {\n+\t\t\t\t\tch->eos_sent = GF_TRUE;\n+\t\t\t\t\tread->eos_signaled = GF_TRUE;\n+\t\t\t\t\tgf_filter_pid_set_eos(ch->pid);\n+\t\t\t\t}\n+\t\t\t\treturn ch->last_state;\n \t\t\t} else {\n \t\t\t\tread->force_fetch = GF_TRUE;\n \t\t\t\tbreak;\ndiff --git a/src/filters/isoffin_read_ch.c b/src/filters/isoffin_read_ch.c\nindex c9bde63876..90f5972eb1 100644\n--- a/src/filters/isoffin_read_ch.c\n+++ b/src/filters/isoffin_read_ch.c\n@@ -479,6 +479,10 @@ void isor_reader_get_sample(ISOMChannel *ch)\n \t\t\t\tif (!ch->has_edit_list && ch->sample_num)\n \t\t\t\t\tch->sample_num--;\n \t\t\t} else {\n+\t\t\t\tif (ch->to_init && ch->sample_num) {\n+\t\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[IsoMedia] Failed to fetch initial sample %d for track %d\\n\"));\n+\t\t\t\t\tch->last_state = GF_ISOM_INVALID_FILE;\n+\t\t\t\t}\n \t\t\t\tif (ch->sample_num >= gf_isom_get_sample_count(ch->owner->mov, ch->track)) {\n \t\t\t\t\tch->last_state = GF_EOS;\n \t\t\t\t}\n"
        ],
        "func_after": []
    },
    {
        "idx": 196698,
        "project": "tensorflow",
        "commit_id": "67bfd9feeecfb3c61d80f0e46d89c170fbee682b",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/67bfd9feeecfb3c61d80f0e46d89c170fbee682b",
        "commit_message": "Make SparseFillEmptyRows validate that the length of `values` must be equal to the number of index tuples.\n\nPiperOrigin-RevId: 399969549\nChange-Id: I3c2f2ca1c1d2cc88bb5951c6958b38c16e9436c8",
        "target": 1,
        "irrelevant": 0,
        "func_before": "void SparseFillEmptyRowsOpImpl(OpKernelContext* context,\n                               AsyncOpKernel::DoneCallback done = nullptr) {\n  // Note that setting this empty lambda as the default parameter value directly\n  // can cause strange compiler/linker errors, so we do it like this instead.\n  if (!done) {\n    done = [] {};\n  }\n\n  const int kIndicesInput = 0;\n  const int kValuesInput = 1;\n  const int kDenseShapeInput = 2;\n  const int kDefaultValueInput = 3;\n\n  const Tensor& indices_t = context->input(kIndicesInput);\n  const Tensor& values_t = context->input(kValuesInput);\n  const Tensor& dense_shape_t = context->input(kDenseShapeInput);\n  const Tensor& default_value_t = context->input(kDefaultValueInput);\n\n  OP_REQUIRES_ASYNC(\n      context, TensorShapeUtils::IsVector(dense_shape_t.shape()),\n      errors::InvalidArgument(\"dense_shape must be a vector, saw: \",\n                              dense_shape_t.shape().DebugString()),\n      done);\n  OP_REQUIRES_ASYNC(context, TensorShapeUtils::IsMatrix(indices_t.shape()),\n                    errors::InvalidArgument(\"indices must be a matrix, saw: \",\n                                            indices_t.shape().DebugString()),\n                    done);\n  OP_REQUIRES_ASYNC(context, TensorShapeUtils::IsVector(values_t.shape()),\n                    errors::InvalidArgument(\"values must be a vector, saw: \",\n                                            values_t.shape().DebugString()),\n                    done);\n  OP_REQUIRES_ASYNC(\n      context, TensorShapeUtils::IsScalar(default_value_t.shape()),\n      errors::InvalidArgument(\"default_value must be a scalar, saw: \",\n                              default_value_t.shape().DebugString()),\n      done);\n  // TODO(ebrevdo): add shape checks between values, indices,\n  // Also add check that dense rank > 0.\n  OP_REQUIRES_ASYNC(context, dense_shape_t.NumElements() != 0,\n                    errors::InvalidArgument(\"Dense shape cannot be empty.\"),\n                    done);\n\n  using FunctorType = functor::SparseFillEmptyRows<Device, T, Tindex>;\n  OP_REQUIRES_OK_ASYNC(context,\n                       FunctorType()(context, default_value_t, indices_t,\n                                     values_t, dense_shape_t, done),\n                       done);\n}",
        "func_hash": 163337242627579814226114932816582213259,
        "file_name": "sparse_fill_empty_rows_op.cc",
        "file_hash": 115550743256362209093747086328381163455,
        "cwe": [
            "CWE-125"
        ],
        "cve": "CVE-2021-41224",
        "cve_desc": "TensorFlow is an open source platform for machine learning. In affected versions the implementation of `SparseFillEmptyRows` can be made to trigger a heap OOB access. This occurs whenever the size of `indices` does not match the size of `values`. The fix will be included in TensorFlow 2.7.0. We will also cherrypick this commit on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-41224",
        "func_name": "SparseFillEmptyRowsOpImpl",
        "diff": [
            "diff --git a/tensorflow/core/kernels/sparse_fill_empty_rows_op.cc b/tensorflow/core/kernels/sparse_fill_empty_rows_op.cc\nindex e0c7e18090b66d..59eb6076ed528b 100644\n--- a/tensorflow/core/kernels/sparse_fill_empty_rows_op.cc\n+++ b/tensorflow/core/kernels/sparse_fill_empty_rows_op.cc\n@@ -24,11 +24,13 @@ limitations under the License.\n #include <vector>\n \n #include \"tensorflow/core/framework/op_kernel.h\"\n+#include \"tensorflow/core/framework/op_requires.h\"\n #include \"tensorflow/core/framework/register_types.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n #include \"tensorflow/core/framework/tensor_util.h\"\n #include \"tensorflow/core/framework/types.h\"\n #include \"tensorflow/core/lib/gtl/inlined_vector.h\"\n+#include \"tensorflow/core/platform/errors.h\"\n #include \"tensorflow/core/util/sparse/sparse_tensor.h\"\n \n namespace tensorflow {\n@@ -222,6 +224,12 @@ void SparseFillEmptyRowsOpImpl(OpKernelContext* context,\n                     errors::InvalidArgument(\"values must be a vector, saw: \",\n                                             values_t.shape().DebugString()),\n                     done);\n+  OP_REQUIRES_ASYNC(\n+      context, indices_t.dim_size(0) == values_t.dim_size(0),\n+      errors::InvalidArgument(\"The length of `values` (\", values_t.dim_size(0),\n+                              \") must match the first dimension of `indices` (\",\n+                              indices_t.dim_size(0), \").\"),\n+      done);\n   OP_REQUIRES_ASYNC(\n       context, TensorShapeUtils::IsScalar(default_value_t.shape()),\n       errors::InvalidArgument(\"default_value must be a scalar, saw: \",\n"
        ],
        "func_after": []
    },
    {
        "idx": 196705,
        "project": "tensorflow",
        "commit_id": "11ced8467eccad9c7cb94867708be8fa5c66c730",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/11ced8467eccad9c7cb94867708be8fa5c66c730",
        "commit_message": "Fix UB in SparseTensorDenseAdd\n\nAdded more input validation to avoid nullptr dereferencing and array index\nout of bounds issues.\n\nPiperOrigin-RevId: 446192704",
        "target": 1,
        "irrelevant": 0,
        "func_before": "Status ValidateInputs(const Tensor *a_indices, const Tensor *a_values,\n                      const Tensor *a_shape, const Tensor *b) {\n  if (!TensorShapeUtils::IsMatrix(a_indices->shape())) {\n    return errors::InvalidArgument(\n        \"Input a_indices should be a matrix but received shape: \",\n        a_indices->shape().DebugString());\n  }\n  if (!TensorShapeUtils::IsVector(a_values->shape()) ||\n      !TensorShapeUtils::IsVector(a_shape->shape())) {\n    return errors::InvalidArgument(\n        \"Inputs a_values and a_shape should be vectors \"\n        \"but received shapes: \",\n        a_values->shape().DebugString(), \" and \",\n        a_shape->shape().DebugString());\n  }\n  if (a_shape->NumElements() != b->dims()) {\n    return errors::InvalidArgument(\n        \"Two operands have different ranks; received: \", a_shape->NumElements(),\n        \" and \", b->dims());\n  }\n  const auto a_shape_flat = a_shape->flat<Index>();\n  for (int i = 0; i < b->dims(); ++i) {\n    if (a_shape_flat(i) != b->dim_size(i)) {\n      return errors::InvalidArgument(\n          \"Dimension \", i,\n          \" does not equal (no broadcasting is supported): sparse side \",\n          a_shape_flat(i), \" vs dense side \", b->dim_size(i));\n    }\n  }\n  return Status::OK();\n}",
        "func_hash": 308425823880781073775676879611190785715,
        "file_name": "sparse_tensor_dense_add_op.cc",
        "file_hash": 91198918327439956509177796541242214319,
        "cwe": [
            "CWE-20"
        ],
        "cve": "CVE-2022-29206",
        "cve_desc": "TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, the implementation of `tf.raw_ops.SparseTensorDenseAdd` does not fully validate the input arguments. In this case, a reference gets bound to a `nullptr` during kernel execution. This is undefined behavior. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-29206",
        "func_name": "ValidateInputs",
        "diff": [
            "diff --git a/tensorflow/core/kernels/sparse_tensor_dense_add_op.cc b/tensorflow/core/kernels/sparse_tensor_dense_add_op.cc\nindex 48803e4b939800..6d6b05bf70f30a 100644\n--- a/tensorflow/core/kernels/sparse_tensor_dense_add_op.cc\n+++ b/tensorflow/core/kernels/sparse_tensor_dense_add_op.cc\n@@ -18,6 +18,7 @@ limitations under the License.\n #include \"tensorflow/core/kernels/sparse_tensor_dense_add_op.h\"\n \n #include \"tensorflow/core/framework/op_kernel.h\"\n+#include \"tensorflow/core/framework/op_requires.h\"\n #include \"tensorflow/core/framework/register_types.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n #include \"tensorflow/core/framework/tensor_util.h\"\n@@ -47,6 +48,17 @@ Status ValidateInputs(const Tensor *a_indices, const Tensor *a_values,\n         a_values->shape().DebugString(), \" and \",\n         a_shape->shape().DebugString());\n   }\n+  int64_t nnz = a_indices->dim_size(0);\n+  int64_t ndims = a_indices->dim_size(1);\n+  if (a_values->dim_size(0) != nnz) {\n+    return errors::InvalidArgument(\"Dimensions \", nnz, \" and \",\n+                                   a_values->dim_size(0),\n+                                   \" are not compatible\");\n+  }\n+  if (a_shape->dim_size(0) != ndims) {\n+    return errors::InvalidArgument(\"Dimensions \", ndims, \" and \",\n+                                   a_shape->dim_size(0), \" are not compatible\");\n+  }\n   if (a_shape->NumElements() != b->dims()) {\n     return errors::InvalidArgument(\n         \"Two operands have different ranks; received: \", a_shape->NumElements(),\n@@ -61,6 +73,24 @@ Status ValidateInputs(const Tensor *a_indices, const Tensor *a_values,\n           a_shape_flat(i), \" vs dense side \", b->dim_size(i));\n     }\n   }\n+\n+  // Check for invalid indices.\n+  const auto a_indices_mat = a_indices->flat_inner_dims<Index>();\n+\n+  for (int64_t zidx = 0; zidx < nnz; ++zidx) {\n+    for (int64_t didx = 0; didx < ndims; ++didx) {\n+      const Index idx = a_indices_mat(zidx, didx);\n+      if (idx < 0 || idx >= a_shape_flat(didx)) {\n+        return errors::InvalidArgument(\n+            \"Sparse tensor has an invalid index on dimension \", didx,\n+            \": \"\n+            \"a_indices(\",\n+            zidx, \",\", didx, \") = \", idx,\n+            \", dense tensor shape: \", a_shape_flat);\n+      }\n+    }\n+  }\n+\n   return Status::OK();\n }\n \ndiff --git a/tensorflow/python/kernel_tests/sparse_ops/sparse_add_op_test.py b/tensorflow/python/kernel_tests/sparse_ops/sparse_add_op_test.py\nindex 61ad45fb5e273e..821184af5b5699 100644\n--- a/tensorflow/python/kernel_tests/sparse_ops/sparse_add_op_test.py\n+++ b/tensorflow/python/kernel_tests/sparse_ops/sparse_add_op_test.py\n@@ -189,7 +189,6 @@ def testSparseTensorDenseAddGradients(self):\n                                                     [(nnz,), (n, m)], s, (n, m))\n       self.assertLess(err, 1e-3)\n \n-  @test_util.run_deprecated_v1\n   def testInvalidSparseTensor(self):\n     with test_util.force_cpu():\n       shape = [2, 2]\n@@ -201,12 +200,49 @@ def testInvalidSparseTensor(self):\n           [[1, 3]],  # ...so is 3.\n       ]:\n         sparse = sparse_tensor.SparseTensorValue(bad_idx, val, shape)\n-        s = sparse_ops.sparse_add(sparse, dense)\n-\n-        with self.assertRaisesRegex(errors_impl.InvalidArgumentError,\n-                                    \"invalid index\"):\n+        with self.assertRaisesRegex(\n+            (ValueError, errors_impl.InvalidArgumentError), \"invalid index\"):\n+          s = sparse_ops.sparse_add(sparse, dense)\n           self.evaluate(s)\n \n+  def _testSparseDenseInvalidInputs(self,\n+                                    a_indices,\n+                                    a_values,\n+                                    a_shape,\n+                                    b,\n+                                    expected_error=\"\"):\n+    # Public API call to sparse-dense add.\n+    with self.assertRaisesRegex((ValueError, errors_impl.InvalidArgumentError),\n+                                expected_error):\n+      a = sparse_tensor.SparseTensor(a_indices, a_values, a_shape)\n+      self.evaluate(sparse_ops.sparse_add(a, b))\n+    # Directly call generated kernel, by-passing SparseTensor validation.\n+    with self.assertRaisesRegex((ValueError, errors_impl.InvalidArgumentError),\n+                                expected_error):\n+      self.evaluate(\n+          sparse_ops.gen_sparse_ops.sparse_tensor_dense_add(\n+              a_indices, a_values, a_shape, b))\n+\n+  def testSparseDenseInvalidInputs(self):\n+    self._testSparseDenseInvalidInputs(\n+        a_indices=constant_op.constant(0, shape=[17, 2], dtype=dtypes.int64),\n+        a_values=constant_op.constant(0, shape=[5], dtype=dtypes.float32),\n+        a_shape=constant_op.constant([3, 4], dtype=dtypes.int64),\n+        b=constant_op.constant(1, shape=[3, 4], dtype=dtypes.float32),\n+        expected_error=\"Dimensions 17 and 5 are not compatible\")\n+    self._testSparseDenseInvalidInputs(\n+        a_indices=constant_op.constant(0, shape=[17, 4], dtype=dtypes.int64),\n+        a_values=constant_op.constant(0, shape=[17], dtype=dtypes.float32),\n+        a_shape=constant_op.constant([3, 4], dtype=dtypes.int64),\n+        b=constant_op.constant(1, shape=[3, 4], dtype=dtypes.float32),\n+        expected_error=\"Dimensions 4 and 2 are not compatible\")\n+    self._testSparseDenseInvalidInputs(\n+        a_indices=constant_op.constant(7, shape=[17, 2], dtype=dtypes.int64),\n+        a_values=constant_op.constant(0, shape=[17], dtype=dtypes.float32),\n+        a_shape=constant_op.constant([3, 4], dtype=dtypes.int64),\n+        b=constant_op.constant(1, shape=[3, 4], dtype=dtypes.float32),\n+        expected_error=\"invalid index\")\n+\n ######################## Benchmarking code\n \n \ndiff --git a/tensorflow/python/kernel_tests/sparse_ops/sparse_ops_test.py b/tensorflow/python/kernel_tests/sparse_ops/sparse_ops_test.py\nindex 4972d1d25f08f1..684d1f98432b53 100644\n--- a/tensorflow/python/kernel_tests/sparse_ops/sparse_ops_test.py\n+++ b/tensorflow/python/kernel_tests/sparse_ops/sparse_ops_test.py\n@@ -665,7 +665,7 @@ def testInvalidIndices(self):\n class SparseAddTest(test_util.TensorFlowTestCase):\n \n   def testValuesInVariable(self):\n-    indices = constant_op.constant([[1]], dtype=dtypes.int64)\n+    indices = constant_op.constant([[0]], dtype=dtypes.int64)\n     values = variables.Variable([1], trainable=False, dtype=dtypes.float32)\n     shape = constant_op.constant([1], dtype=dtypes.int64)\n \n"
        ],
        "func_after": []
    },
    {
        "idx": 196726,
        "project": "njs",
        "commit_id": "8b39afdad9a0761e0a5d4af1a762bd9a6daef572",
        "project_url": "https://github.com/nginx/njs",
        "commit_url": "https://github.com/nginx/njs/commit/8b39afdad9a0761e0a5d4af1a762bd9a6daef572",
        "commit_message": "Fixed Array.prototype.sort() when arr size is changed in a comparator.\n\nThis fixed #468 issue on Github.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "njs_array_prototype_sort(njs_vm_t *vm, njs_value_t *args, njs_uint_t nargs,\n    njs_index_t unused)\n{\n    int64_t                i, und, len, nlen, length;\n    njs_int_t              ret, fast_path;\n    njs_array_t            *array;\n    njs_value_t            *this, *comparefn, *start, *strings;\n    njs_array_sort_ctx_t   ctx;\n    njs_array_sort_slot_t  *p, *end, *slots, *nslots;\n\n    comparefn = njs_arg(args, nargs, 1);\n\n    if (njs_is_defined(comparefn)) {\n        if (njs_slow_path(!njs_is_function(comparefn))) {\n            njs_type_error(vm, \"comparefn must be callable or undefined\");\n            return NJS_ERROR;\n        }\n\n        ctx.function = njs_function(comparefn);\n\n    } else {\n        ctx.function = NULL;\n    }\n\n    this = njs_argument(args, 0);\n\n    ret = njs_value_to_object(vm, this);\n    if (njs_slow_path(ret != NJS_OK)) {\n        return ret;\n    }\n\n    ret = njs_value_length(vm, this, &length);\n    if (njs_slow_path(ret != NJS_OK)) {\n        return ret;\n    }\n\n    if (njs_slow_path(length < 2)) {\n        vm->retval = *this;\n        return NJS_OK;\n    }\n\n    slots = NULL;\n    ctx.vm = vm;\n    ctx.strings.separate = 0;\n    ctx.strings.pointer = 0;\n    ctx.exception = 0;\n\n    fast_path = njs_is_fast_array(this);\n\n    if (njs_fast_path(fast_path)) {\n        array = njs_array(this);\n        start = array->start;\n\n        slots = njs_mp_alloc(vm->mem_pool,\n                             sizeof(njs_array_sort_slot_t) * length);\n        if (njs_slow_path(slots == NULL)) {\n                return NJS_ERROR;\n        }\n\n        und = 0;\n        p = slots;\n\n        for (i = 0; i < length; i++) {\n            if (njs_slow_path(!njs_is_valid(&start[i]))) {\n                fast_path = 0;\n                njs_mp_free(vm->mem_pool, slots);\n                slots = NULL;\n                goto slow_path;\n            }\n\n            if (njs_slow_path(njs_is_undefined(&start[i]))) {\n                und++;\n                continue;\n            }\n\n            p->value = start[i];\n            p->pos = i;\n            p->str = NULL;\n            p++;\n        }\n\n        len = p - slots;\n\n    } else {\n\nslow_path:\n\n        und = 0;\n        p = NULL;\n        end = NULL;\n\n        for (i = 0; i < length; i++) {\n            if (p >= end) {\n                nlen = njs_min(njs_max((p - slots) * 2, 8), length);\n                nslots = njs_mp_alloc(vm->mem_pool,\n                                      sizeof(njs_array_sort_slot_t) * nlen);\n                if (njs_slow_path(nslots == NULL)) {\n                    njs_memory_error(vm);\n                    return NJS_ERROR;\n                }\n\n                if (slots != NULL) {\n                    p = (void *) njs_cpymem(nslots, slots,\n                                  sizeof(njs_array_sort_slot_t) * (p - slots));\n                    njs_mp_free(vm->mem_pool, slots);\n\n                } else {\n                    p = nslots;\n                }\n\n                slots = nslots;\n                end = slots + nlen;\n            }\n\n            ret = njs_value_property_i64(vm, this, i, &p->value);\n            if (njs_slow_path(ret == NJS_ERROR)) {\n                ret = NJS_ERROR;\n                goto exception;\n            }\n\n            if (ret == NJS_DECLINED) {\n                continue;\n            }\n\n            if (njs_is_undefined(&p->value)) {\n                und++;\n                continue;\n            }\n\n            p->pos = i;\n            p->str = NULL;\n            p++;\n        }\n\n        len = p - slots;\n    }\n\n    strings = njs_arr_init(vm->mem_pool, &ctx.strings, NULL, len + 1,\n                           sizeof(njs_value_t));\n    if (njs_slow_path(strings == NULL)) {\n        ret = NJS_ERROR;\n        goto exception;\n    }\n\n    njs_qsort(slots, len, sizeof(njs_array_sort_slot_t), njs_array_compare,\n              &ctx);\n\n    if (ctx.exception) {\n        ret = NJS_ERROR;\n        goto exception;\n    }\n\n    if (njs_fast_path(fast_path)) {\n        array = njs_array(this);\n        start = array->start;\n\n        for (i = 0; i < len; i++) {\n            start[i] = slots[i].value;\n        }\n\n        for (i = len; und-- > 0; i++) {\n            start[i] = njs_value_undefined;\n        }\n\n    } else {\n        for (i = 0; i < len; i++) {\n            if (slots[i].pos != i) {\n                ret = njs_value_property_i64_set(vm, this, i, &slots[i].value);\n                if (njs_slow_path(ret == NJS_ERROR)) {\n                    goto exception;\n                }\n            }\n        }\n\n        for (i = len; und-- > 0; i++) {\n            ret = njs_value_property_i64_set(vm, this, i,\n                                          njs_value_arg(&njs_value_undefined));\n            if (njs_slow_path(ret == NJS_ERROR)) {\n                goto exception;\n            }\n        }\n\n        for (; i < length; i++) {\n            ret = njs_value_property_i64_delete(vm, this, i, NULL);\n            if (njs_slow_path(ret == NJS_ERROR)) {\n                goto exception;\n            }\n        }\n    }\n\n    vm->retval = *this;\n\n    ret = NJS_OK;\n\nexception:\n\n    if (slots != NULL) {\n        njs_mp_free(vm->mem_pool, slots);\n    }\n\n    njs_arr_destroy(&ctx.strings);\n\n    return ret;\n}",
        "func_hash": 315762575953614180704363033015743212537,
        "file_name": "njs_array.c",
        "file_hash": 304271490911532501655096631912999183260,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2022-29780",
        "cve_desc": "Nginx NJS v0.7.2 was discovered to contain a segmentation violation in the function njs_array_prototype_sort at src/njs_array.c.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-29780",
        "func_name": "njs_array_prototype_sort",
        "diff": [
            "diff --git a/src/njs_array.c b/src/njs_array.c\nindex 81a7c1555..0b8c7b919 100644\n--- a/src/njs_array.c\n+++ b/src/njs_array.c\n@@ -2696,7 +2696,7 @@ njs_array_prototype_sort(njs_vm_t *vm, njs_value_t *args, njs_uint_t nargs,\n         goto exception;\n     }\n \n-    if (njs_fast_path(fast_path)) {\n+    if (njs_fast_path(fast_path && njs_is_fast_array(this))) {\n         array = njs_array(this);\n         start = array->start;\n \ndiff --git a/src/test/njs_unit_test.c b/src/test/njs_unit_test.c\nindex 186defa1a..25e066c32 100644\n--- a/src/test/njs_unit_test.c\n+++ b/src/test/njs_unit_test.c\n@@ -6989,6 +6989,9 @@ static njs_unit_test_t  njs_test[] =\n     { njs_str(\"[1,2].sort(1)\"),\n       njs_str(\"TypeError: comparefn must be callable or undefined\") },\n \n+    { njs_str(\"var a = [1,2]; a.sort(() => {a.length = 65535}); a.length\"),\n+      njs_str(\"65535\") },\n+\n     /*\n       Array.prototype.keys()\n       Array.prototype.values()\n"
        ],
        "func_after": []
    },
    {
        "idx": 196790,
        "project": "tensorflow",
        "commit_id": "a4e138660270e7599793fa438cd7b2fc2ce215a6",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/a4e138660270e7599793fa438cd7b2fc2ce215a6",
        "commit_message": "Add remaining validation to `sdca_internal.cc`\n\nPiperOrigin-RevId: 387738010\nChange-Id: I28eedcfd87a53aaf34deb075acea1f8c95470808",
        "target": 1,
        "irrelevant": 0,
        "func_before": "Status Examples::Initialize(OpKernelContext* const context,\n                            const ModelWeights& weights,\n                            const int num_sparse_features,\n                            const int num_sparse_features_with_values,\n                            const int num_dense_features) {\n  num_features_ = num_sparse_features + num_dense_features;\n\n  OpInputList sparse_example_indices_inputs;\n  TF_RETURN_IF_ERROR(context->input_list(\"sparse_example_indices\",\n                                         &sparse_example_indices_inputs));\n  if (sparse_example_indices_inputs.size() != num_sparse_features)\n    return errors::InvalidArgument(\n        \"Expected \", num_sparse_features,\n        \" tensors in sparse_example_indices but got \",\n        sparse_example_indices_inputs.size());\n  OpInputList sparse_feature_indices_inputs;\n  TF_RETURN_IF_ERROR(context->input_list(\"sparse_feature_indices\",\n                                         &sparse_feature_indices_inputs));\n  if (sparse_feature_indices_inputs.size() != num_sparse_features)\n    return errors::InvalidArgument(\n        \"Expected \", num_sparse_features,\n        \" tensors in sparse_feature_indices but got \",\n        sparse_feature_indices_inputs.size());\n  OpInputList sparse_feature_values_inputs;\n  if (num_sparse_features_with_values > 0) {\n    TF_RETURN_IF_ERROR(context->input_list(\"sparse_feature_values\",\n                                           &sparse_feature_values_inputs));\n    if (sparse_feature_values_inputs.size() != num_sparse_features_with_values)\n      return errors::InvalidArgument(\n          \"Expected \", num_sparse_features_with_values,\n          \" tensors in sparse_feature_values but got \",\n          sparse_feature_values_inputs.size());\n  }\n\n  const Tensor* example_weights_t;\n  TF_RETURN_IF_ERROR(context->input(\"example_weights\", &example_weights_t));\n  auto example_weights = example_weights_t->flat<float>();\n\n  if (example_weights.size() >= std::numeric_limits<int>::max()) {\n    return errors::InvalidArgument(strings::Printf(\n        \"Too many examples in a mini-batch: %zu > %d\", example_weights.size(),\n        std::numeric_limits<int>::max()));\n  }\n\n  // The static_cast here is safe since num_examples can be at max an int.\n  const int num_examples = static_cast<int>(example_weights.size());\n  const Tensor* example_labels_t;\n  TF_RETURN_IF_ERROR(context->input(\"example_labels\", &example_labels_t));\n  auto example_labels = example_labels_t->flat<float>();\n\n  OpInputList dense_features_inputs;\n  TF_RETURN_IF_ERROR(\n      context->input_list(\"dense_features\", &dense_features_inputs));\n\n  examples_.clear();\n  examples_.resize(num_examples);\n  probabilities_.resize(num_examples);\n  sampled_index_.resize(num_examples);\n  sampled_count_.resize(num_examples);\n  for (int example_id = 0; example_id < num_examples; ++example_id) {\n    Example* const example = &examples_[example_id];\n    example->sparse_features_.resize(num_sparse_features);\n    example->dense_vectors_.resize(num_dense_features);\n    example->example_weight_ = example_weights(example_id);\n    example->example_label_ = example_labels(example_id);\n  }\n  const DeviceBase::CpuWorkerThreads& worker_threads =\n      *context->device()->tensorflow_cpu_worker_threads();\n  TF_RETURN_IF_ERROR(CreateSparseFeatureRepresentation(\n      worker_threads, num_examples, num_sparse_features, weights,\n      sparse_example_indices_inputs, sparse_feature_indices_inputs,\n      sparse_feature_values_inputs, &examples_));\n  TF_RETURN_IF_ERROR(CreateDenseFeatureRepresentation(\n      worker_threads, num_examples, num_dense_features, weights,\n      dense_features_inputs, &examples_));\n  TF_RETURN_IF_ERROR(ComputeSquaredNormPerExample(\n      worker_threads, num_examples, num_sparse_features, num_dense_features,\n      &examples_));\n  return Status::OK();\n}",
        "func_hash": 183156860369052380668778554351089179754,
        "file_name": "sdca_internal.cc",
        "file_hash": 189786435377355636606855329054946360663,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2021-37672",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions an attacker can read from outside of bounds of heap allocated data by sending specially crafted illegal arguments to `tf.raw_ops.SdcaOptimizerV2`. The [implementation](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/core/kernels/sdca_internal.cc#L320-L353) does not check that the length of `example_labels` is the same as the number of examples. We have patched the issue in GitHub commit a4e138660270e7599793fa438cd7b2fc2ce215a6. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37672",
        "func_name": "Examples::Initialize",
        "diff": [
            "diff --git a/tensorflow/core/kernels/sdca_internal.cc b/tensorflow/core/kernels/sdca_internal.cc\nindex 6c4a63b270c25b..164f9382724cac 100644\n--- a/tensorflow/core/kernels/sdca_internal.cc\n+++ b/tensorflow/core/kernels/sdca_internal.cc\n@@ -380,6 +380,11 @@ Status Examples::Initialize(OpKernelContext* const context,\n   const Tensor* example_labels_t;\n   TF_RETURN_IF_ERROR(context->input(\"example_labels\", &example_labels_t));\n   auto example_labels = example_labels_t->flat<float>();\n+  if (example_labels.size() != num_examples) {\n+    return errors::InvalidArgument(\"Expected \", num_examples,\n+                                   \" example labels but got \",\n+                                   example_labels.size());\n+  }\n \n   OpInputList dense_features_inputs;\n   TF_RETURN_IF_ERROR(\n"
        ],
        "func_after": []
    },
    {
        "idx": 196801,
        "project": "gpac",
        "commit_id": "f5a038e6893019ee471b6a57490cf7a495673816",
        "project_url": "https://github.com/gpac/gpac",
        "commit_url": "https://github.com/gpac/gpac/commit/f5a038e6893019ee471b6a57490cf7a495673816",
        "commit_message": "fixed #1885",
        "target": 1,
        "irrelevant": 0,
        "func_before": "GF_Err gf_hinter_finalize(GF_ISOFile *file, GF_SDP_IODProfile IOD_Profile, u32 bandwidth)\n{\n\tu32 i, sceneT, odT, descIndex, size, size64;\n\tGF_InitialObjectDescriptor *iod;\n\tGF_SLConfig slc;\n\tGF_ISOSample *samp;\n\tBool remove_ocr;\n\tu8 *buffer;\n\tchar buf64[5000], sdpLine[5100];\n\n\n\tgf_isom_sdp_clean(file);\n\n\tif (bandwidth) {\n\t\tsprintf(buf64, \"b=AS:%d\", bandwidth);\n\t\tgf_isom_sdp_add_line(file, buf64);\n\t}\n    //xtended attribute for copyright\n    if (gf_sys_is_test_mode()) {\n        sprintf(buf64, \"a=x-copyright: %s\", \"MP4/3GP File hinted with GPAC - (c) Telecom ParisTech (http://gpac.io)\");\n    } else {\n        sprintf(buf64, \"a=x-copyright: MP4/3GP File hinted with GPAC %s - %s\", gf_gpac_version(), gf_gpac_copyright() );\n    }\n\tgf_isom_sdp_add_line(file, buf64);\n\n\tif (IOD_Profile == GF_SDP_IOD_NONE) return GF_OK;\n\n\todT = sceneT = 0;\n\tfor (i=0; i<gf_isom_get_track_count(file); i++) {\n\t\tif (!gf_isom_is_track_in_root_od(file, i+1)) continue;\n\t\tswitch (gf_isom_get_media_type(file,i+1)) {\n\t\tcase GF_ISOM_MEDIA_OD:\n\t\t\todT = i+1;\n\t\t\tbreak;\n\t\tcase GF_ISOM_MEDIA_SCENE:\n\t\t\tsceneT = i+1;\n\t\t\tbreak;\n\t\t}\n\t}\n\tremove_ocr = 0;\n\tif (IOD_Profile == GF_SDP_IOD_ISMA_STRICT) {\n\t\tIOD_Profile = GF_SDP_IOD_ISMA;\n\t\tremove_ocr = 1;\n\t}\n\n\t/*if we want ISMA like iods, we need at least BIFS */\n\tif ( (IOD_Profile == GF_SDP_IOD_ISMA) && !sceneT ) return GF_BAD_PARAM;\n\n\t/*do NOT change PLs, we assume they are correct*/\n\tiod = (GF_InitialObjectDescriptor *) gf_isom_get_root_od(file);\n\tif (!iod) return GF_NOT_SUPPORTED;\n\n\t/*rewrite an IOD with good SL config - embbed data if possible*/\n\tif (IOD_Profile == GF_SDP_IOD_ISMA) {\n\t\tGF_ESD *esd;\n\t\tBool is_ok = 1;\n\t\twhile (gf_list_count(iod->ESDescriptors)) {\n\t\t\tesd = (GF_ESD*)gf_list_get(iod->ESDescriptors, 0);\n\t\t\tgf_odf_desc_del((GF_Descriptor *) esd);\n\t\t\tgf_list_rem(iod->ESDescriptors, 0);\n\t\t}\n\n\n\t\t/*get OD esd, and embbed stream data if possible*/\n\t\tif (odT) {\n\t\t\tesd = gf_isom_get_esd(file, odT, 1);\n\t\t\tif (gf_isom_get_sample_count(file, odT)==1) {\n\t\t\t\tsamp = gf_isom_get_sample(file, odT, 1, &descIndex);\n\t\t\t\tif (samp && gf_hinter_can_embbed_data(samp->data, samp->dataLength, GF_STREAM_OD)) {\n\t\t\t\t\tInitSL_NULL(&slc);\n\t\t\t\t\tslc.predefined = 0;\n\t\t\t\t\tslc.hasRandomAccessUnitsOnlyFlag = 1;\n\t\t\t\t\tslc.timeScale = slc.timestampResolution = gf_isom_get_media_timescale(file, odT);\n\t\t\t\t\tslc.OCRResolution = 1000;\n\t\t\t\t\tslc.startCTS = samp->DTS+samp->CTS_Offset;\n\t\t\t\t\tslc.startDTS = samp->DTS;\n\t\t\t\t\t//set the SL for future extraction\n\t\t\t\t\tgf_isom_set_extraction_slc(file, odT, 1, &slc);\n\n\t\t\t\t\tsize64 = gf_base64_encode(samp->data, samp->dataLength, buf64, 2000);\n\t\t\t\t\tbuf64[size64] = 0;\n\t\t\t\t\tsprintf(sdpLine, \"data:application/mpeg4-od-au;base64,%s\", buf64);\n\n\t\t\t\t\tif (esd->decoderConfig) {\n\t\t\t\t\t\tesd->decoderConfig->avgBitrate = 0;\n\t\t\t\t\t\tesd->decoderConfig->bufferSizeDB = samp->dataLength;\n\t\t\t\t\t\tesd->decoderConfig->maxBitrate = 0;\n\t\t\t\t\t}\n\t\t\t\t\tsize64 = (u32) strlen(sdpLine)+1;\n\t\t\t\t\tesd->URLString = (char*)gf_malloc(sizeof(char) * size64);\n\t\t\t\t\tstrcpy(esd->URLString, sdpLine);\n\t\t\t\t} else {\n\t\t\t\t\tGF_LOG(GF_LOG_WARNING, GF_LOG_RTP, (\"[rtp hinter] OD sample too large to be embedded in IOD - ISMA disabled\\n\"));\n\t\t\t\t\tis_ok = 0;\n\t\t\t\t}\n\t\t\t\tgf_isom_sample_del(&samp);\n\t\t\t}\n\t\t\tif (remove_ocr) esd->OCRESID = 0;\n\t\t\telse if (esd->OCRESID == esd->ESID) esd->OCRESID = 0;\n\n\t\t\t//OK, add this to our IOD\n\t\t\tgf_list_add(iod->ESDescriptors, esd);\n\t\t}\n\n\t\tesd = gf_isom_get_esd(file, sceneT, 1);\n\t\tif (gf_isom_get_sample_count(file, sceneT)==1) {\n\t\t\tsamp = gf_isom_get_sample(file, sceneT, 1, &descIndex);\n\t\t\tif (samp && gf_hinter_can_embbed_data(samp->data, samp->dataLength, GF_STREAM_SCENE)) {\n\n\t\t\t\tslc.timeScale = slc.timestampResolution = gf_isom_get_media_timescale(file, sceneT);\n\t\t\t\tslc.OCRResolution = 1000;\n\t\t\t\tslc.startCTS = samp->DTS+samp->CTS_Offset;\n\t\t\t\tslc.startDTS = samp->DTS;\n\t\t\t\t//set the SL for future extraction\n\t\t\t\tgf_isom_set_extraction_slc(file, sceneT, 1, &slc);\n\t\t\t\t//encode in Base64 the sample\n\t\t\t\tsize64 = gf_base64_encode(samp->data, samp->dataLength, buf64, 2000);\n\t\t\t\tbuf64[size64] = 0;\n\t\t\t\tsprintf(sdpLine, \"data:application/mpeg4-bifs-au;base64,%s\", buf64);\n\n\t\t\t\tif (esd->decoderConfig) {\n\t\t\t\t\tesd->decoderConfig->avgBitrate = 0;\n\t\t\t\t\tesd->decoderConfig->bufferSizeDB = samp->dataLength;\n\t\t\t\t\tesd->decoderConfig->maxBitrate = 0;\n\t\t\t\t}\n\t\t\t\tesd->URLString = (char*)gf_malloc(sizeof(char) * (strlen(sdpLine)+1));\n\t\t\t\tstrcpy(esd->URLString, sdpLine);\n\t\t\t} else {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_RTP, (\"[rtp hinter] Scene description sample too large to be embedded in IOD - ISMA disabled\\n\"));\n\t\t\t\tis_ok = 0;\n\t\t\t}\n\t\t\tgf_isom_sample_del(&samp);\n\t\t}\n\t\tif (remove_ocr) esd->OCRESID = 0;\n\t\telse if (esd->OCRESID == esd->ESID) esd->OCRESID = 0;\n\n\t\tgf_list_add(iod->ESDescriptors, esd);\n\n\t\tif (is_ok) {\n\t\t\tu32 has_a, has_v, has_i_a, has_i_v;\n\t\t\thas_a = has_v = has_i_a = has_i_v = 0;\n\t\t\tfor (i=0; i<gf_isom_get_track_count(file); i++) {\n\t\t\t\tesd = gf_isom_get_esd(file, i+1, 1);\n\t\t\t\tif (!esd) continue;\n\t\t\t\tif (esd->decoderConfig) {\n\t\t\t\t\tif (esd->decoderConfig->streamType==GF_STREAM_VISUAL) {\n\t\t\t\t\t\tif (esd->decoderConfig->objectTypeIndication==GF_CODECID_MPEG4_PART2) has_i_v ++;\n\t\t\t\t\t\telse has_v++;\n\t\t\t\t\t} else if (esd->decoderConfig->streamType==GF_STREAM_AUDIO) {\n\t\t\t\t\t\tif (esd->decoderConfig->objectTypeIndication==GF_CODECID_AAC_MPEG4) has_i_a ++;\n\t\t\t\t\t\telse has_a++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tgf_odf_desc_del((GF_Descriptor *)esd);\n\t\t\t}\n\t\t\t/*only 1 MPEG-4 visual max and 1 MPEG-4 audio max for ISMA compliancy*/\n\t\t\tif (!has_v && !has_a && (has_i_v<=1) && (has_i_a<=1)) {\n\t\t\t\tsprintf(sdpLine, \"a=isma-compliance:1,1.0,1\");\n\t\t\t\tgf_isom_sdp_add_line(file, sdpLine);\n\t\t\t}\n\t\t}\n\t}\n\n\t//encode the IOD\n\tbuffer = NULL;\n\tsize = 0;\n\tgf_odf_desc_write((GF_Descriptor *) iod, &buffer, &size);\n\tgf_odf_desc_del((GF_Descriptor *)iod);\n\n\t//encode in Base64 the iod\n\tsize64 = gf_base64_encode(buffer, size, buf64, 2000);\n\tbuf64[size64] = 0;\n\tgf_free(buffer);\n\n\tsprintf(sdpLine, \"a=mpeg4-iod:\\\"data:application/mpeg4-iod;base64,%s\\\"\", buf64);\n\tgf_isom_sdp_add_line(file, sdpLine);\n\n\treturn GF_OK;\n}",
        "func_hash": 123828913884454942556959015680908121097,
        "file_name": "isom_hinter.c",
        "file_hash": 94306079889139284150664165649647698827,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2021-40567",
        "cve_desc": "Segmentation fault vulnerability exists in Gpac through 1.0.1 via the gf_odf_size_descriptor function in desc_private.c when using mp4box, which causes a denial of service.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-40567",
        "func_name": "gf_hinter_finalize",
        "diff": [
            "diff --git a/src/media_tools/isom_hinter.c b/src/media_tools/isom_hinter.c\nindex eacef641fe..6d823b1484 100644\n--- a/src/media_tools/isom_hinter.c\n+++ b/src/media_tools/isom_hinter.c\n@@ -1241,7 +1241,7 @@ GF_Err gf_hinter_finalize(GF_ISOFile *file, GF_SDP_IODProfile IOD_Profile, u32 b\n \t\tif (gf_isom_get_sample_count(file, sceneT)==1) {\n \t\t\tsamp = gf_isom_get_sample(file, sceneT, 1, &descIndex);\n \t\t\tif (samp && gf_hinter_can_embbed_data(samp->data, samp->dataLength, GF_STREAM_SCENE)) {\n-\n+\t\t\t\tInitSL_NULL(&slc);\n \t\t\t\tslc.timeScale = slc.timestampResolution = gf_isom_get_media_timescale(file, sceneT);\n \t\t\t\tslc.OCRResolution = 1000;\n \t\t\t\tslc.startCTS = samp->DTS+samp->CTS_Offset;\n"
        ],
        "func_after": []
    },
    {
        "idx": 196805,
        "project": "mruby",
        "commit_id": "aaa28a508903041dd7399d4159a8ace9766b022f",
        "project_url": "https://github.com/mruby/mruby",
        "commit_url": "https://github.com/mruby/mruby/commit/aaa28a508903041dd7399d4159a8ace9766b022f",
        "commit_message": "vm.c: stack may be reallocated in functions calls.\n\nProbably due to recursive VM calls via `mrb_funcall()`.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "mrb_vm_exec(mrb_state *mrb, const struct RProc *proc, const mrb_code *pc)\n{\n  /* mrb_assert(MRB_PROC_CFUNC_P(proc)) */\n  const mrb_irep *irep = proc->body.irep;\n  const mrb_pool_value *pool = irep->pool;\n  const mrb_sym *syms = irep->syms;\n  mrb_code insn;\n  int ai = mrb_gc_arena_save(mrb);\n  struct mrb_jmpbuf *prev_jmp = mrb->jmp;\n  struct mrb_jmpbuf c_jmp;\n  uint32_t a;\n  uint16_t b;\n  uint16_t c;\n  mrb_sym mid;\n  const struct mrb_irep_catch_handler *ch;\n\n#ifdef DIRECT_THREADED\n  static const void * const optable[] = {\n#define OPCODE(x,_) &&L_OP_ ## x,\n#include \"mruby/ops.h\"\n#undef OPCODE\n  };\n#endif\n\n  mrb_bool exc_catched = FALSE;\nRETRY_TRY_BLOCK:\n\n  MRB_TRY(&c_jmp) {\n\n  if (exc_catched) {\n    exc_catched = FALSE;\n    mrb_gc_arena_restore(mrb, ai);\n    if (mrb->exc && mrb->exc->tt == MRB_TT_BREAK)\n      goto L_BREAK;\n    goto L_RAISE;\n  }\n  mrb->jmp = &c_jmp;\n  mrb_vm_ci_proc_set(mrb->c->ci, proc);\n\n#define regs (mrb->c->ci->stack)\n  INIT_DISPATCH {\n    CASE(OP_NOP, Z) {\n      /* do nothing */\n      NEXT;\n    }\n\n    CASE(OP_MOVE, BB) {\n      regs[a] = regs[b];\n      NEXT;\n    }\n\n    CASE(OP_LOADL, BB) {\n      switch (pool[b].tt) {   /* number */\n      case IREP_TT_INT32:\n        regs[a] = mrb_int_value(mrb, (mrb_int)pool[b].u.i32);\n        break;\n      case IREP_TT_INT64:\n#if defined(MRB_INT64)\n        regs[a] = mrb_int_value(mrb, (mrb_int)pool[b].u.i64);\n        break;\n#else\n#if defined(MRB_64BIT)\n        if (INT32_MIN <= pool[b].u.i64 && pool[b].u.i64 <= INT32_MAX) {\n          regs[a] = mrb_int_value(mrb, (mrb_int)pool[b].u.i64);\n          break;\n        }\n#endif\n        goto L_INT_OVERFLOW;\n#endif\n      case IREP_TT_BIGINT:\n        goto L_INT_OVERFLOW;\n#ifndef MRB_NO_FLOAT\n      case IREP_TT_FLOAT:\n        regs[a] = mrb_float_value(mrb, pool[b].u.f);\n        break;\n#endif\n      default:\n        /* should not happen (tt:string) */\n        regs[a] = mrb_nil_value();\n        break;\n      }\n      NEXT;\n    }\n\n    CASE(OP_LOADI, BB) {\n      SET_FIXNUM_VALUE(regs[a], b);\n      NEXT;\n    }\n\n    CASE(OP_LOADINEG, BB) {\n      SET_FIXNUM_VALUE(regs[a], -b);\n      NEXT;\n    }\n\n    CASE(OP_LOADI__1,B) goto L_LOADI;\n    CASE(OP_LOADI_0,B) goto L_LOADI;\n    CASE(OP_LOADI_1,B) goto L_LOADI;\n    CASE(OP_LOADI_2,B) goto L_LOADI;\n    CASE(OP_LOADI_3,B) goto L_LOADI;\n    CASE(OP_LOADI_4,B) goto L_LOADI;\n    CASE(OP_LOADI_5,B) goto L_LOADI;\n    CASE(OP_LOADI_6,B) goto L_LOADI;\n    CASE(OP_LOADI_7, B) {\n    L_LOADI:\n      SET_FIXNUM_VALUE(regs[a], (mrb_int)insn - (mrb_int)OP_LOADI_0);\n      NEXT;\n    }\n\n    CASE(OP_LOADI16, BS) {\n      SET_FIXNUM_VALUE(regs[a], (mrb_int)(int16_t)b);\n      NEXT;\n    }\n\n    CASE(OP_LOADI32, BSS) {\n      SET_INT_VALUE(mrb, regs[a], (int32_t)(((uint32_t)b<<16)+c));\n      NEXT;\n    }\n\n    CASE(OP_LOADSYM, BB) {\n      SET_SYM_VALUE(regs[a], syms[b]);\n      NEXT;\n    }\n\n    CASE(OP_LOADNIL, B) {\n      SET_NIL_VALUE(regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_LOADSELF, B) {\n      regs[a] = regs[0];\n      NEXT;\n    }\n\n    CASE(OP_LOADT, B) {\n      SET_TRUE_VALUE(regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_LOADF, B) {\n      SET_FALSE_VALUE(regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETGV, BB) {\n      mrb_value val = mrb_gv_get(mrb, syms[b]);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETGV, BB) {\n      mrb_gv_set(mrb, syms[b], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETSV, BB) {\n      mrb_value val = mrb_vm_special_get(mrb, syms[b]);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETSV, BB) {\n      mrb_vm_special_set(mrb, syms[b], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETIV, BB) {\n      regs[a] = mrb_iv_get(mrb, regs[0], syms[b]);\n      NEXT;\n    }\n\n    CASE(OP_SETIV, BB) {\n      mrb_iv_set(mrb, regs[0], syms[b], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETCV, BB) {\n      mrb_value val;\n      val = mrb_vm_cv_get(mrb, syms[b]);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETCV, BB) {\n      mrb_vm_cv_set(mrb, syms[b], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETIDX, B) {\n      mrb_value va = regs[a], vb = regs[a+1];\n      switch (mrb_type(va)) {\n      case MRB_TT_ARRAY:\n        if (!mrb_integer_p(vb)) goto getidx_fallback;\n        regs[a] = mrb_ary_entry(va, mrb_integer(vb));\n        break;\n      case MRB_TT_HASH:\n        regs[a] = mrb_hash_get(mrb, va, vb);\n        break;\n      case MRB_TT_STRING:\n        switch (mrb_type(vb)) {\n        case MRB_TT_INTEGER:\n        case MRB_TT_STRING:\n        case MRB_TT_RANGE:\n          regs[a] = mrb_str_aref(mrb, va, vb, mrb_undef_value());\n          break;\n        default:\n          goto getidx_fallback;\n        }\n        break;\n      default:\n      getidx_fallback:\n        mid = MRB_OPSYM(aref);\n        goto L_SEND_SYM;\n      }\n      NEXT;\n    }\n\n    CASE(OP_SETIDX, B) {\n      c = 2;\n      mid = MRB_OPSYM(aset);\n      SET_NIL_VALUE(regs[a+3]);\n      goto L_SENDB_SYM;\n    }\n\n    CASE(OP_GETCONST, BB) {\n      regs[a] = mrb_vm_const_get(mrb, syms[b]);\n      NEXT;\n    }\n\n    CASE(OP_SETCONST, BB) {\n      mrb_vm_const_set(mrb, syms[b], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETMCNST, BB) {\n      regs[a] = mrb_const_get(mrb, regs[a], syms[b]);\n      NEXT;\n    }\n\n    CASE(OP_SETMCNST, BB) {\n      mrb_const_set(mrb, regs[a+1], syms[b], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETUPVAR, BBB) {\n      mrb_value *regs_a = regs + a;\n      struct REnv *e = uvenv(mrb, c);\n\n      if (e && b < MRB_ENV_LEN(e)) {\n        *regs_a = e->stack[b];\n      }\n      else {\n        *regs_a = mrb_nil_value();\n      }\n      NEXT;\n    }\n\n    CASE(OP_SETUPVAR, BBB) {\n      struct REnv *e = uvenv(mrb, c);\n\n      if (e) {\n        mrb_value *regs_a = regs + a;\n\n        if (b < MRB_ENV_LEN(e)) {\n          e->stack[b] = *regs_a;\n          mrb_write_barrier(mrb, (struct RBasic*)e);\n        }\n      }\n      NEXT;\n    }\n\n    CASE(OP_JMP, S) {\n      pc += (int16_t)a;\n      JUMP;\n    }\n    CASE(OP_JMPIF, BS) {\n      if (mrb_test(regs[a])) {\n        pc += (int16_t)b;\n        JUMP;\n      }\n      NEXT;\n    }\n    CASE(OP_JMPNOT, BS) {\n      if (!mrb_test(regs[a])) {\n        pc += (int16_t)b;\n        JUMP;\n      }\n      NEXT;\n    }\n    CASE(OP_JMPNIL, BS) {\n      if (mrb_nil_p(regs[a])) {\n        pc += (int16_t)b;\n        JUMP;\n      }\n      NEXT;\n    }\n\n    CASE(OP_JMPUW, S) {\n      a = (uint32_t)((pc - irep->iseq) + (int16_t)a);\n      CHECKPOINT_RESTORE(RBREAK_TAG_JUMP) {\n        struct RBreak *brk = (struct RBreak*)mrb->exc;\n        mrb_value target = mrb_break_value_get(brk);\n        mrb_assert(mrb_integer_p(target));\n        a = (uint32_t)mrb_integer(target);\n        mrb_assert(a >= 0 && a < irep->ilen);\n      }\n      CHECKPOINT_MAIN(RBREAK_TAG_JUMP) {\n        ch = catch_handler_find(mrb, mrb->c->ci, pc, MRB_CATCH_FILTER_ENSURE);\n        if (ch) {\n          /* avoiding a jump from a catch handler into the same handler */\n          if (a < mrb_irep_catch_handler_unpack(ch->begin) || a >= mrb_irep_catch_handler_unpack(ch->end)) {\n            THROW_TAGGED_BREAK(mrb, RBREAK_TAG_JUMP, proc, mrb_fixnum_value(a));\n          }\n        }\n      }\n      CHECKPOINT_END(RBREAK_TAG_JUMP);\n\n      mrb->exc = NULL; /* clear break object */\n      pc = irep->iseq + a;\n      JUMP;\n    }\n\n    CASE(OP_EXCEPT, B) {\n      mrb_value exc;\n\n      if (mrb->exc == NULL) {\n        exc = mrb_nil_value();\n      }\n      else {\n        switch (mrb->exc->tt) {\n        case MRB_TT_BREAK:\n        case MRB_TT_EXCEPTION:\n          exc = mrb_obj_value(mrb->exc);\n          break;\n        default:\n          mrb_assert(!\"bad mrb_type\");\n          exc = mrb_nil_value();\n          break;\n        }\n        mrb->exc = NULL;\n      }\n      regs[a] = exc;\n      NEXT;\n    }\n    CASE(OP_RESCUE, BB) {\n      mrb_value exc = regs[a];  /* exc on stack */\n      mrb_value e = regs[b];\n      struct RClass *ec;\n\n      switch (mrb_type(e)) {\n      case MRB_TT_CLASS:\n      case MRB_TT_MODULE:\n        break;\n      default:\n        {\n          mrb_value exc;\n\n          exc = mrb_exc_new_lit(mrb, E_TYPE_ERROR,\n                                    \"class or module required for rescue clause\");\n          mrb_exc_set(mrb, exc);\n          goto L_RAISE;\n        }\n      }\n      ec = mrb_class_ptr(e);\n      regs[b] = mrb_bool_value(mrb_obj_is_kind_of(mrb, exc, ec));\n      NEXT;\n    }\n\n    CASE(OP_RAISEIF, B) {\n      mrb_value exc = regs[a];\n      if (mrb_break_p(exc)) {\n        mrb->exc = mrb_obj_ptr(exc);\n        goto L_BREAK;\n      }\n      mrb_exc_set(mrb, exc);\n      if (mrb->exc) {\n        goto L_RAISE;\n      }\n      NEXT;\n    }\n\n    CASE(OP_SSEND, BBB) {\n      regs[a] = regs[0];\n      insn = OP_SEND;\n    }\n    goto L_SENDB;\n\n    CASE(OP_SSENDB, BBB) {\n      regs[a] = regs[0];\n    }\n    goto L_SENDB;\n\n    CASE(OP_SEND, BBB)\n    goto L_SENDB;\n\n    L_SEND_SYM:\n    c = 1;\n    /* push nil after arguments */\n    SET_NIL_VALUE(regs[a+2]);\n    goto L_SENDB_SYM;\n\n    CASE(OP_SENDB, BBB)\n    L_SENDB:\n    mid = syms[b];\n    L_SENDB_SYM:\n    {\n      mrb_callinfo *ci = mrb->c->ci;\n      mrb_method_t m;\n      struct RClass *cls;\n      mrb_value recv, blk;\n\n      ARGUMENT_NORMALIZE(a, &c, insn);\n\n      recv = regs[a];\n      cls = mrb_class(mrb, recv);\n      m = mrb_method_search_vm(mrb, &cls, mid);\n      if (MRB_METHOD_UNDEF_P(m)) {\n        m = prepare_missing(mrb, recv, mid, &cls, a, &c, blk, 0);\n        mid = MRB_SYM(method_missing);\n      }\n\n      /* push callinfo */\n      ci = cipush(mrb, a, 0, cls, NULL, mid, c);\n\n      if (MRB_METHOD_CFUNC_P(m)) {\n        if (MRB_METHOD_PROC_P(m)) {\n          struct RProc *p = MRB_METHOD_PROC(m);\n\n          mrb_vm_ci_proc_set(ci, p);\n          recv = p->body.func(mrb, recv);\n        }\n        else {\n          if (MRB_METHOD_NOARG_P(m)) {\n            check_method_noarg(mrb, ci);\n          }\n          recv = MRB_METHOD_FUNC(m)(mrb, recv);\n        }\n        mrb_gc_arena_shrink(mrb, ai);\n        if (mrb->exc) goto L_RAISE;\n        ci = mrb->c->ci;\n        if (mrb_proc_p(blk)) {\n          struct RProc *p = mrb_proc_ptr(blk);\n          if (p && !MRB_PROC_STRICT_P(p) && MRB_PROC_ENV(p) == mrb_vm_ci_env(&ci[-1])) {\n            p->flags |= MRB_PROC_ORPHAN;\n          }\n        }\n        if (!ci->u.target_class) { /* return from context modifying method (resume/yield) */\n          if (ci->cci == CINFO_RESUMED) {\n            mrb->jmp = prev_jmp;\n            return recv;\n          }\n          else {\n            mrb_assert(!MRB_PROC_CFUNC_P(ci[-1].proc));\n            proc = ci[-1].proc;\n            irep = proc->body.irep;\n            pool = irep->pool;\n            syms = irep->syms;\n          }\n        }\n        ci->stack[0] = recv;\n        /* pop stackpos */\n        ci = cipop(mrb);\n        pc = ci->pc;\n      }\n      else {\n        /* setup environment for calling method */\n        mrb_vm_ci_proc_set(ci, (proc = MRB_METHOD_PROC(m)));\n        irep = proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n        mrb_stack_extend(mrb, (irep->nregs < 4) ? 4 : irep->nregs);\n        pc = irep->iseq;\n      }\n    }\n    JUMP;\n\n    CASE(OP_CALL, Z) {\n      mrb_callinfo *ci = mrb->c->ci;\n      mrb_value recv = ci->stack[0];\n      struct RProc *m = mrb_proc_ptr(recv);\n\n      /* replace callinfo */\n      ci->u.target_class = MRB_PROC_TARGET_CLASS(m);\n      mrb_vm_ci_proc_set(ci, m);\n      if (MRB_PROC_ENV_P(m)) {\n        ci->mid = MRB_PROC_ENV(m)->mid;\n      }\n\n      /* prepare stack */\n      if (MRB_PROC_CFUNC_P(m)) {\n        recv = MRB_PROC_CFUNC(m)(mrb, recv);\n        mrb_gc_arena_shrink(mrb, ai);\n        if (mrb->exc) goto L_RAISE;\n        /* pop stackpos */\n        ci = cipop(mrb);\n        pc = ci->pc;\n        ci[1].stack[0] = recv;\n        irep = mrb->c->ci->proc->body.irep;\n      }\n      else {\n        /* setup environment for calling method */\n        proc = m;\n        irep = m->body.irep;\n        if (!irep) {\n          mrb->c->ci->stack[0] = mrb_nil_value();\n          a = 0;\n          c = OP_R_NORMAL;\n          goto L_OP_RETURN_BODY;\n        }\n        mrb_int nargs = mrb_ci_bidx(ci)+1;\n        if (nargs < irep->nregs) {\n          mrb_stack_extend(mrb, irep->nregs);\n          stack_clear(regs+nargs, irep->nregs-nargs);\n        }\n        if (MRB_PROC_ENV_P(m)) {\n          regs[0] = MRB_PROC_ENV(m)->stack[0];\n        }\n        pc = irep->iseq;\n      }\n      pool = irep->pool;\n      syms = irep->syms;\n      JUMP;\n    }\n\n    CASE(OP_SUPER, BB) {\n      mrb_method_t m;\n      struct RClass *cls;\n      mrb_callinfo *ci = mrb->c->ci;\n      mrb_value recv, blk;\n      const struct RProc *p = ci->proc;\n      mrb_sym mid = ci->mid;\n      struct RClass* target_class = MRB_PROC_TARGET_CLASS(p);\n\n      if (MRB_PROC_ENV_P(p) && p->e.env->mid && p->e.env->mid != mid) { /* alias support */\n        mid = p->e.env->mid;    /* restore old mid */\n      }\n\n      if (mid == 0 || !target_class) {\n        mrb_value exc = mrb_exc_new_lit(mrb, E_NOMETHOD_ERROR, \"super called outside of method\");\n        mrb_exc_set(mrb, exc);\n        goto L_RAISE;\n      }\n      if (target_class->flags & MRB_FL_CLASS_IS_PREPENDED) {\n        target_class = mrb_vm_ci_target_class(ci);\n      }\n      else if (target_class->tt == MRB_TT_MODULE) {\n        target_class = mrb_vm_ci_target_class(ci);\n        if (target_class->tt != MRB_TT_ICLASS) {\n          goto super_typeerror;\n        }\n      }\n      recv = regs[0];\n      if (!mrb_obj_is_kind_of(mrb, recv, target_class)) {\n      super_typeerror: ;\n        mrb_value exc = mrb_exc_new_lit(mrb, E_TYPE_ERROR,\n                                            \"self has wrong type to call super in this context\");\n        mrb_exc_set(mrb, exc);\n        goto L_RAISE;\n      }\n\n      ARGUMENT_NORMALIZE(a, &b, OP_SUPER);\n\n      cls = target_class->super;\n      m = mrb_method_search_vm(mrb, &cls, mid);\n      if (MRB_METHOD_UNDEF_P(m)) {\n        m = prepare_missing(mrb, recv, mid, &cls, a, &b, blk, 1);\n        mid = MRB_SYM(method_missing);\n      }\n\n      /* push callinfo */\n      ci = cipush(mrb, a, 0, cls, NULL, mid, b);\n\n      /* prepare stack */\n      ci->stack[0] = recv;\n\n      if (MRB_METHOD_CFUNC_P(m)) {\n        mrb_value v;\n\n        if (MRB_METHOD_PROC_P(m)) {\n          mrb_vm_ci_proc_set(ci, MRB_METHOD_PROC(m));\n        }\n        v = MRB_METHOD_CFUNC(m)(mrb, recv);\n        mrb_gc_arena_restore(mrb, ai);\n        if (mrb->exc) goto L_RAISE;\n        ci = mrb->c->ci;\n        mrb_assert(!mrb_break_p(v));\n        if (!mrb_vm_ci_target_class(ci)) { /* return from context modifying method (resume/yield) */\n          if (ci->cci == CINFO_RESUMED) {\n            mrb->jmp = prev_jmp;\n            return v;\n          }\n          else {\n            mrb_assert(!MRB_PROC_CFUNC_P(ci[-1].proc));\n            proc = ci[-1].proc;\n            irep = proc->body.irep;\n            pool = irep->pool;\n            syms = irep->syms;\n          }\n        }\n        mrb->c->ci->stack[0] = v;\n        ci = cipop(mrb);\n        pc = ci->pc;\n      }\n      else {\n        /* setup environment for calling method */\n        mrb_vm_ci_proc_set(ci, (proc = MRB_METHOD_PROC(m)));\n        irep = proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n        mrb_stack_extend(mrb, (irep->nregs < 4) ? 4 : irep->nregs);\n        pc = irep->iseq;\n      }\n      JUMP;\n    }\n\n    CASE(OP_ARGARY, BS) {\n      mrb_int m1 = (b>>11)&0x3f;\n      mrb_int r  = (b>>10)&0x1;\n      mrb_int m2 = (b>>5)&0x1f;\n      mrb_int kd = (b>>4)&0x1;\n      mrb_int lv = (b>>0)&0xf;\n      mrb_value *stack;\n\n      if (mrb->c->ci->mid == 0 || mrb_vm_ci_target_class(mrb->c->ci) == NULL) {\n        mrb_value exc;\n\n      L_NOSUPER:\n        exc = mrb_exc_new_lit(mrb, E_NOMETHOD_ERROR, \"super called outside of method\");\n        mrb_exc_set(mrb, exc);\n        goto L_RAISE;\n      }\n      if (lv == 0) stack = regs + 1;\n      else {\n        struct REnv *e = uvenv(mrb, lv-1);\n        if (!e) goto L_NOSUPER;\n        if (MRB_ENV_LEN(e) <= m1+r+m2+1)\n          goto L_NOSUPER;\n        stack = e->stack + 1;\n      }\n      if (r == 0) {\n        regs[a] = mrb_ary_new_from_values(mrb, m1+m2, stack);\n      }\n      else {\n        mrb_value *pp = NULL;\n        struct RArray *rest;\n        mrb_int len = 0;\n\n        if (mrb_array_p(stack[m1])) {\n          struct RArray *ary = mrb_ary_ptr(stack[m1]);\n\n          pp = ARY_PTR(ary);\n          len = ARY_LEN(ary);\n        }\n        regs[a] = mrb_ary_new_capa(mrb, m1+len+m2);\n        rest = mrb_ary_ptr(regs[a]);\n        if (m1 > 0) {\n          stack_copy(ARY_PTR(rest), stack, m1);\n        }\n        if (len > 0) {\n          stack_copy(ARY_PTR(rest)+m1, pp, len);\n        }\n        if (m2 > 0) {\n          stack_copy(ARY_PTR(rest)+m1+len, stack+m1+1, m2);\n        }\n        ARY_SET_LEN(rest, m1+len+m2);\n      }\n      if (kd) {\n        regs[a+1] = stack[m1+r+m2];\n        regs[a+2] = stack[m1+r+m2+1];\n      }\n      else {\n        regs[a+1] = stack[m1+r+m2];\n      }\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_ENTER, W) {\n      mrb_int m1 = MRB_ASPEC_REQ(a);\n      mrb_int o  = MRB_ASPEC_OPT(a);\n      mrb_int r  = MRB_ASPEC_REST(a);\n      mrb_int m2 = MRB_ASPEC_POST(a);\n      mrb_int kd = (MRB_ASPEC_KEY(a) > 0 || MRB_ASPEC_KDICT(a))? 1 : 0;\n      /* unused\n      int b  = MRB_ASPEC_BLOCK(a);\n      */\n      mrb_int const len = m1 + o + r + m2;\n\n      mrb_callinfo *ci = mrb->c->ci;\n      mrb_int argc = ci->n;\n      mrb_value *argv = regs+1;\n      mrb_value * const argv0 = argv;\n      mrb_int const kw_pos = len + kd;    /* where kwhash should be */\n      mrb_int const blk_pos = kw_pos + 1; /* where block should be */\n      mrb_value blk = regs[mrb_ci_bidx(ci)];\n      mrb_value kdict = mrb_nil_value();\n\n      /* keyword arguments */\n      if (ci->nk > 0) {\n        mrb_int kidx = mrb_ci_kidx(ci);\n        kdict = regs[kidx];\n        if (!mrb_hash_p(kdict) || mrb_hash_size(mrb, kdict) == 0) {\n          kdict = mrb_nil_value();\n          ci->nk = 0;\n        }\n      }\n      if (!kd && !mrb_nil_p(kdict)) {\n        if (argc < 14) {\n          ci->n++;\n          argc++;    /* include kdict in normal arguments */\n        }\n        else if (argc == 14) {\n          /* pack arguments and kdict */\n          regs[1] = mrb_ary_new_from_values(mrb, argc+1, &regs[1]);\n          argc = ci->n = 15;\n        }\n        else {/* argc == 15 */\n          /* push kdict to packed arguments */\n          mrb_ary_push(mrb, regs[1], regs[2]);\n        }\n        ci->nk = 0;\n      }\n      if (kd && MRB_ASPEC_KEY(a) > 0 && mrb_hash_p(kdict)) {\n        kdict = mrb_hash_dup(mrb, kdict);\n      }\n\n      /* arguments is passed with Array */\n      if (argc == 15) {\n        struct RArray *ary = mrb_ary_ptr(regs[1]);\n        argv = ARY_PTR(ary);\n        argc = (int)ARY_LEN(ary);\n        mrb_gc_protect(mrb, regs[1]);\n      }\n\n      /* strict argument check */\n      if (ci->proc && MRB_PROC_STRICT_P(ci->proc)) {\n        if (argc < m1 + m2 || (r == 0 && argc > len)) {\n          argnum_error(mrb, m1+m2);\n          goto L_RAISE;\n        }\n      }\n      /* extract first argument array to arguments */\n      else if (len > 1 && argc == 1 && mrb_array_p(argv[0])) {\n        mrb_gc_protect(mrb, argv[0]);\n        argc = (int)RARRAY_LEN(argv[0]);\n        argv = RARRAY_PTR(argv[0]);\n      }\n\n      /* rest arguments */\n      mrb_value rest = mrb_nil_value();\n      if (argc < len) {\n        mrb_int mlen = m2;\n        if (argc < m1+m2) {\n          mlen = m1 < argc ? argc - m1 : 0;\n        }\n\n        /* copy mandatory and optional arguments */\n        if (argv0 != argv && argv) {\n          value_move(&regs[1], argv, argc-mlen); /* m1 + o */\n        }\n        if (argc < m1) {\n          stack_clear(&regs[argc+1], m1-argc);\n        }\n        /* copy post mandatory arguments */\n        if (mlen) {\n          value_move(&regs[len-m2+1], &argv[argc-mlen], mlen);\n        }\n        if (mlen < m2) {\n          stack_clear(&regs[len-m2+mlen+1], m2-mlen);\n        }\n        /* initialize rest arguments with empty Array */\n        if (r) {\n          rest = mrb_ary_new_capa(mrb, 0);\n          regs[m1+o+1] = rest;\n        }\n        /* skip initializer of passed arguments */\n        if (o > 0 && argc > m1+m2)\n          pc += (argc - m1 - m2)*3;\n      }\n      else {\n        mrb_int rnum = 0;\n        if (argv0 != argv) {\n          value_move(&regs[1], argv, m1+o);\n        }\n        if (r) {\n          rnum = argc-m1-o-m2;\n          rest = mrb_ary_new_from_values(mrb, rnum, argv+m1+o);\n          regs[m1+o+1] = rest;\n        }\n        if (m2 > 0 && argc-m2 > m1) {\n          value_move(&regs[m1+o+r+1], &argv[m1+o+rnum], m2);\n        }\n        pc += o*3;\n      }\n\n      /* need to be update blk first to protect blk from GC */\n      regs[blk_pos] = blk;              /* move block */\n      if (kd) {\n        if (mrb_nil_p(kdict))\n          kdict = mrb_hash_new_capa(mrb, 0);\n        regs[kw_pos] = kdict;           /* set kwhash */\n      }\n\n      /* format arguments for generated code */\n      mrb->c->ci->n = len;\n\n      /* clear local (but non-argument) variables */\n      if (irep->nlocals-blk_pos-1 > 0) {\n        stack_clear(&regs[blk_pos+1], irep->nlocals-blk_pos-1);\n      }\n      JUMP;\n    }\n\n    CASE(OP_KARG, BB) {\n      mrb_value k = mrb_symbol_value(syms[b]);\n      mrb_int kidx = mrb_ci_kidx(mrb->c->ci);\n      mrb_value kdict;\n\n      if (kidx < 0 || !mrb_hash_p(kdict=regs[kidx]) || !mrb_hash_key_p(mrb, kdict, k)) {\n        mrb_value str = mrb_format(mrb, \"missing keyword: %v\", k);\n        mrb_exc_set(mrb, mrb_exc_new_str(mrb, E_ARGUMENT_ERROR, str));\n        goto L_RAISE;\n      }\n      regs[a] = mrb_hash_get(mrb, kdict, k);\n      mrb_hash_delete_key(mrb, kdict, k);\n      NEXT;\n    }\n\n    CASE(OP_KEY_P, BB) {\n      mrb_value k = mrb_symbol_value(syms[b]);\n      mrb_int kidx = mrb_ci_kidx(mrb->c->ci);\n      mrb_value kdict;\n      mrb_bool key_p = FALSE;\n\n      if (kidx >= 0 && mrb_hash_p(kdict=regs[kidx])) {\n        key_p = mrb_hash_key_p(mrb, kdict, k);\n      }\n      regs[a] = mrb_bool_value(key_p);\n      NEXT;\n    }\n\n    CASE(OP_KEYEND, Z) {\n      mrb_int kidx = mrb_ci_kidx(mrb->c->ci);\n      mrb_value kdict;\n\n      if (kidx >= 0 && mrb_hash_p(kdict=regs[kidx]) && !mrb_hash_empty_p(mrb, kdict)) {\n        mrb_value keys = mrb_hash_keys(mrb, kdict);\n        mrb_value key1 = RARRAY_PTR(keys)[0];\n        mrb_value str = mrb_format(mrb, \"unknown keyword: %v\", key1);\n        mrb_exc_set(mrb, mrb_exc_new_str(mrb, E_ARGUMENT_ERROR, str));\n        goto L_RAISE;\n      }\n      NEXT;\n    }\n\n    CASE(OP_BREAK, B) {\n      c = OP_R_BREAK;\n      goto L_RETURN;\n    }\n    CASE(OP_RETURN_BLK, B) {\n      c = OP_R_RETURN;\n      goto L_RETURN;\n    }\n    CASE(OP_RETURN, B)\n    c = OP_R_NORMAL;\n    L_RETURN:\n    {\n      mrb_callinfo *ci;\n\n      ci = mrb->c->ci;\n      if (ci->mid) {\n        mrb_value blk = regs[mrb_ci_bidx(ci)];\n\n        if (mrb_proc_p(blk)) {\n          struct RProc *p = mrb_proc_ptr(blk);\n\n          if (!MRB_PROC_STRICT_P(p) &&\n              ci > mrb->c->cibase && MRB_PROC_ENV(p) == mrb_vm_ci_env(&ci[-1])) {\n            p->flags |= MRB_PROC_ORPHAN;\n          }\n        }\n      }\n\n      if (mrb->exc) {\n      L_RAISE:\n        ci = mrb->c->ci;\n        if (ci == mrb->c->cibase) {\n          ch = catch_handler_find(mrb, ci, pc, MRB_CATCH_FILTER_ALL);\n          if (ch == NULL) goto L_FTOP;\n          goto L_CATCH;\n        }\n        while ((ch = catch_handler_find(mrb, ci, pc, MRB_CATCH_FILTER_ALL)) == NULL) {\n          ci = cipop(mrb);\n          if (ci[1].cci == CINFO_SKIP && prev_jmp) {\n            mrb->jmp = prev_jmp;\n            MRB_THROW(prev_jmp);\n          }\n          pc = ci[0].pc;\n          if (ci == mrb->c->cibase) {\n            ch = catch_handler_find(mrb, ci, pc, MRB_CATCH_FILTER_ALL);\n            if (ch == NULL) {\n            L_FTOP:             /* fiber top */\n              if (mrb->c == mrb->root_c) {\n                mrb->c->ci->stack = mrb->c->stbase;\n                goto L_STOP;\n              }\n              else {\n                struct mrb_context *c = mrb->c;\n\n                c->status = MRB_FIBER_TERMINATED;\n                mrb->c = c->prev;\n                c->prev = NULL;\n                goto L_RAISE;\n              }\n            }\n            break;\n          }\n        }\n      L_CATCH:\n        if (ch == NULL) goto L_STOP;\n        if (FALSE) {\n        L_CATCH_TAGGED_BREAK: /* from THROW_TAGGED_BREAK() or UNWIND_ENSURE() */\n          ci = mrb->c->ci;\n        }\n        proc = ci->proc;\n        irep = proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n        mrb_stack_extend(mrb, irep->nregs);\n        pc = irep->iseq + mrb_irep_catch_handler_unpack(ch->target);\n      }\n      else {\n        mrb_int acc;\n        mrb_value v;\n\n        ci = mrb->c->ci;\n        v = regs[a];\n        mrb_gc_protect(mrb, v);\n        switch (c) {\n        case OP_R_RETURN:\n          /* Fall through to OP_R_NORMAL otherwise */\n          if (ci->cci == CINFO_NONE && MRB_PROC_ENV_P(proc) && !MRB_PROC_STRICT_P(proc)) {\n            const struct RProc *dst;\n            mrb_callinfo *cibase;\n            cibase = mrb->c->cibase;\n            dst = top_proc(mrb, proc);\n\n            if (MRB_PROC_ENV_P(dst)) {\n              struct REnv *e = MRB_PROC_ENV(dst);\n\n              if (!MRB_ENV_ONSTACK_P(e) || (e->cxt && e->cxt != mrb->c)) {\n                localjump_error(mrb, LOCALJUMP_ERROR_RETURN);\n                goto L_RAISE;\n              }\n            }\n            /* check jump destination */\n            while (cibase <= ci && ci->proc != dst) {\n              if (ci->cci > CINFO_NONE) { /* jump cross C boundary */\n                localjump_error(mrb, LOCALJUMP_ERROR_RETURN);\n                goto L_RAISE;\n              }\n              ci--;\n            }\n            if (ci <= cibase) { /* no jump destination */\n              localjump_error(mrb, LOCALJUMP_ERROR_RETURN);\n              goto L_RAISE;\n            }\n            ci = mrb->c->ci;\n            while (cibase <= ci && ci->proc != dst) {\n              CHECKPOINT_RESTORE(RBREAK_TAG_RETURN_BLOCK) {\n                cibase = mrb->c->cibase;\n                dst = top_proc(mrb, proc);\n              }\n              CHECKPOINT_MAIN(RBREAK_TAG_RETURN_BLOCK) {\n                UNWIND_ENSURE(mrb, ci, pc, RBREAK_TAG_RETURN_BLOCK, proc, v);\n              }\n              CHECKPOINT_END(RBREAK_TAG_RETURN_BLOCK);\n              ci = cipop(mrb);\n              pc = ci->pc;\n            }\n            proc = ci->proc;\n            mrb->exc = NULL; /* clear break object */\n            break;\n          }\n          /* fallthrough */\n        case OP_R_NORMAL:\n        NORMAL_RETURN:\n          if (ci == mrb->c->cibase) {\n            struct mrb_context *c;\n            c = mrb->c;\n\n            if (!c->prev) { /* toplevel return */\n              regs[irep->nlocals] = v;\n              goto CHECKPOINT_LABEL_MAKE(RBREAK_TAG_STOP);\n            }\n            if (!c->vmexec && c->prev->ci == c->prev->cibase) {\n              mrb_value exc = mrb_exc_new_lit(mrb, E_FIBER_ERROR, \"double resume\");\n              mrb_exc_set(mrb, exc);\n              goto L_RAISE;\n            }\n            CHECKPOINT_RESTORE(RBREAK_TAG_RETURN_TOPLEVEL) {\n              c = mrb->c;\n            }\n            CHECKPOINT_MAIN(RBREAK_TAG_RETURN_TOPLEVEL) {\n              UNWIND_ENSURE(mrb, ci, pc, RBREAK_TAG_RETURN_TOPLEVEL, proc, v);\n            }\n            CHECKPOINT_END(RBREAK_TAG_RETURN_TOPLEVEL);\n            /* automatic yield at the end */\n            c->status = MRB_FIBER_TERMINATED;\n            mrb->c = c->prev;\n            mrb->c->status = MRB_FIBER_RUNNING;\n            c->prev = NULL;\n            if (c->vmexec) {\n              mrb_gc_arena_restore(mrb, ai);\n              c->vmexec = FALSE;\n              mrb->jmp = prev_jmp;\n              return v;\n            }\n            ci = mrb->c->ci;\n          }\n          CHECKPOINT_RESTORE(RBREAK_TAG_RETURN) {\n            /* do nothing */\n          }\n          CHECKPOINT_MAIN(RBREAK_TAG_RETURN) {\n            UNWIND_ENSURE(mrb, ci, pc, RBREAK_TAG_RETURN, proc, v);\n          }\n          CHECKPOINT_END(RBREAK_TAG_RETURN);\n          mrb->exc = NULL; /* clear break object */\n          break;\n        case OP_R_BREAK:\n          if (MRB_PROC_STRICT_P(proc)) goto NORMAL_RETURN;\n          if (MRB_PROC_ORPHAN_P(proc)) {\n            mrb_value exc;\n\n          L_BREAK_ERROR:\n            exc = mrb_exc_new_lit(mrb, E_LOCALJUMP_ERROR,\n                                      \"break from proc-closure\");\n            mrb_exc_set(mrb, exc);\n            goto L_RAISE;\n          }\n          if (!MRB_PROC_ENV_P(proc) || !MRB_ENV_ONSTACK_P(MRB_PROC_ENV(proc))) {\n            goto L_BREAK_ERROR;\n          }\n          else {\n            struct REnv *e = MRB_PROC_ENV(proc);\n\n            if (e->cxt != mrb->c) {\n              goto L_BREAK_ERROR;\n            }\n          }\n          CHECKPOINT_RESTORE(RBREAK_TAG_BREAK) {\n            /* do nothing */\n          }\n          CHECKPOINT_MAIN(RBREAK_TAG_BREAK) {\n            UNWIND_ENSURE(mrb, ci, pc, RBREAK_TAG_BREAK, proc, v);\n          }\n          CHECKPOINT_END(RBREAK_TAG_BREAK);\n          /* break from fiber block */\n          if (ci == mrb->c->cibase && ci->pc) {\n            struct mrb_context *c = mrb->c;\n\n            mrb->c = c->prev;\n            c->prev = NULL;\n            ci = mrb->c->ci;\n          }\n          if (ci->cci > CINFO_NONE) {\n            ci = cipop(mrb);\n            mrb_gc_arena_restore(mrb, ai);\n            mrb->c->vmexec = FALSE;\n            mrb->exc = (struct RObject*)break_new(mrb, RBREAK_TAG_BREAK, proc, v);\n            mrb->jmp = prev_jmp;\n            MRB_THROW(prev_jmp);\n          }\n          if (FALSE) {\n            struct RBreak *brk;\n\n          L_BREAK:\n            brk = (struct RBreak*)mrb->exc;\n            proc = mrb_break_proc_get(brk);\n            v = mrb_break_value_get(brk);\n            ci = mrb->c->ci;\n\n            switch (mrb_break_tag_get(brk)) {\n#define DISPATCH_CHECKPOINTS(n, i) case n: goto CHECKPOINT_LABEL_MAKE(n);\n              RBREAK_TAG_FOREACH(DISPATCH_CHECKPOINTS)\n#undef DISPATCH_CHECKPOINTS\n              default:\n                mrb_assert(!\"wrong break tag\");\n            }\n          }\n          while (mrb->c->cibase < ci && ci[-1].proc != proc->upper) {\n            if (ci[-1].cci == CINFO_SKIP) {\n              goto L_BREAK_ERROR;\n            }\n            CHECKPOINT_RESTORE(RBREAK_TAG_BREAK_UPPER) {\n              /* do nothing */\n            }\n            CHECKPOINT_MAIN(RBREAK_TAG_BREAK_UPPER) {\n              UNWIND_ENSURE(mrb, ci, pc, RBREAK_TAG_BREAK_UPPER, proc, v);\n            }\n            CHECKPOINT_END(RBREAK_TAG_BREAK_UPPER);\n            ci = cipop(mrb);\n            pc = ci->pc;\n          }\n          CHECKPOINT_RESTORE(RBREAK_TAG_BREAK_INTARGET) {\n            /* do nothing */\n          }\n          CHECKPOINT_MAIN(RBREAK_TAG_BREAK_INTARGET) {\n            UNWIND_ENSURE(mrb, ci, pc, RBREAK_TAG_BREAK_INTARGET, proc, v);\n          }\n          CHECKPOINT_END(RBREAK_TAG_BREAK_INTARGET);\n          if (ci == mrb->c->cibase) {\n            goto L_BREAK_ERROR;\n          }\n          mrb->exc = NULL; /* clear break object */\n          break;\n        default:\n          /* cannot happen */\n          break;\n        }\n        mrb_assert(ci == mrb->c->ci);\n        mrb_assert(mrb->exc == NULL);\n\n        if (mrb->c->vmexec && !mrb_vm_ci_target_class(ci)) {\n          mrb_gc_arena_restore(mrb, ai);\n          mrb->c->vmexec = FALSE;\n          mrb->jmp = prev_jmp;\n          return v;\n        }\n        acc = ci->cci;\n        ci = cipop(mrb);\n        if (acc == CINFO_SKIP || acc == CINFO_DIRECT) {\n          mrb_gc_arena_restore(mrb, ai);\n          mrb->jmp = prev_jmp;\n          return v;\n        }\n        pc = ci->pc;\n        DEBUG(fprintf(stderr, \"from :%s\\n\", mrb_sym_name(mrb, ci->mid)));\n        proc = ci->proc;\n        irep = proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n\n        ci[1].stack[0] = v;\n        mrb_gc_arena_restore(mrb, ai);\n      }\n      JUMP;\n    }\n\n    CASE(OP_BLKPUSH, BS) {\n      int m1 = (b>>11)&0x3f;\n      int r  = (b>>10)&0x1;\n      int m2 = (b>>5)&0x1f;\n      int kd = (b>>4)&0x1;\n      int lv = (b>>0)&0xf;\n      mrb_value *stack;\n\n      if (lv == 0) stack = regs + 1;\n      else {\n        struct REnv *e = uvenv(mrb, lv-1);\n        if (!e || (!MRB_ENV_ONSTACK_P(e) && e->mid == 0) ||\n            MRB_ENV_LEN(e) <= m1+r+m2+1) {\n          localjump_error(mrb, LOCALJUMP_ERROR_YIELD);\n          goto L_RAISE;\n        }\n        stack = e->stack + 1;\n      }\n      if (mrb_nil_p(stack[m1+r+m2+kd])) {\n        localjump_error(mrb, LOCALJUMP_ERROR_YIELD);\n        goto L_RAISE;\n      }\n      regs[a] = stack[m1+r+m2+kd];\n      NEXT;\n    }\n\n  L_INT_OVERFLOW:\n    {\n      mrb_value exc = mrb_exc_new_lit(mrb, E_RANGE_ERROR, \"integer overflow\");\n      mrb_exc_set(mrb, exc);\n    }\n    goto L_RAISE;\n\n#define TYPES2(a,b) ((((uint16_t)(a))<<8)|(((uint16_t)(b))&0xff))\n#define OP_MATH(op_name)                                                    \\\n  /* need to check if op is overridden */                                   \\\n  switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {                  \\\n    OP_MATH_CASE_INTEGER(op_name);                                          \\\n    OP_MATH_CASE_FLOAT(op_name, integer, float);                            \\\n    OP_MATH_CASE_FLOAT(op_name, float,  integer);                           \\\n    OP_MATH_CASE_FLOAT(op_name, float,  float);                             \\\n    OP_MATH_CASE_STRING_##op_name();                                        \\\n    default:                                                                \\\n      mid = MRB_OPSYM(op_name);                                             \\\n      goto L_SEND_SYM;                                                      \\\n  }                                                                         \\\n  NEXT;\n#define OP_MATH_CASE_INTEGER(op_name)                                       \\\n  case TYPES2(MRB_TT_INTEGER, MRB_TT_INTEGER):                              \\\n    {                                                                       \\\n      mrb_int x = mrb_integer(regs[a]), y = mrb_integer(regs[a+1]), z;      \\\n      if (mrb_int_##op_name##_overflow(x, y, &z))                           \\\n        OP_MATH_OVERFLOW_INT();                                             \\\n      else                                                                  \\\n        SET_INT_VALUE(mrb,regs[a], z);                                      \\\n    }                                                                       \\\n    break\n#ifdef MRB_NO_FLOAT\n#define OP_MATH_CASE_FLOAT(op_name, t1, t2) (void)0\n#else\n#define OP_MATH_CASE_FLOAT(op_name, t1, t2)                                     \\\n  case TYPES2(OP_MATH_TT_##t1, OP_MATH_TT_##t2):                                \\\n    {                                                                           \\\n      mrb_float z = mrb_##t1(regs[a]) OP_MATH_OP_##op_name mrb_##t2(regs[a+1]); \\\n      SET_FLOAT_VALUE(mrb, regs[a], z);                                         \\\n    }                                                                           \\\n    break\n#endif\n#define OP_MATH_OVERFLOW_INT() goto L_INT_OVERFLOW\n#define OP_MATH_CASE_STRING_add()                                           \\\n  case TYPES2(MRB_TT_STRING, MRB_TT_STRING):                                \\\n    regs[a] = mrb_str_plus(mrb, regs[a], regs[a+1]);                        \\\n    mrb_gc_arena_restore(mrb, ai);                                          \\\n    break\n#define OP_MATH_CASE_STRING_sub() (void)0\n#define OP_MATH_CASE_STRING_mul() (void)0\n#define OP_MATH_OP_add +\n#define OP_MATH_OP_sub -\n#define OP_MATH_OP_mul *\n#define OP_MATH_TT_integer MRB_TT_INTEGER\n#define OP_MATH_TT_float   MRB_TT_FLOAT\n\n    CASE(OP_ADD, B) {\n      OP_MATH(add);\n    }\n\n    CASE(OP_SUB, B) {\n      OP_MATH(sub);\n    }\n\n    CASE(OP_MUL, B) {\n      OP_MATH(mul);\n    }\n\n    CASE(OP_DIV, B) {\n#ifndef MRB_NO_FLOAT\n      mrb_float x, y, f;\n#endif\n\n      /* need to check if op is overridden */\n      switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\n      case TYPES2(MRB_TT_INTEGER,MRB_TT_INTEGER):\n        {\n          mrb_int x = mrb_integer(regs[a]);\n          mrb_int y = mrb_integer(regs[a+1]);\n          mrb_int div = mrb_div_int(mrb, x, y);\n          SET_INT_VALUE(mrb, regs[a], div);\n        }\n        NEXT;\n#ifndef MRB_NO_FLOAT\n      case TYPES2(MRB_TT_INTEGER,MRB_TT_FLOAT):\n        x = (mrb_float)mrb_integer(regs[a]);\n        y = mrb_float(regs[a+1]);\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_INTEGER):\n        x = mrb_float(regs[a]);\n        y = (mrb_float)mrb_integer(regs[a+1]);\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_FLOAT):\n        x = mrb_float(regs[a]);\n        y = mrb_float(regs[a+1]);\n        break;\n#endif\n      default:\n        mid = MRB_OPSYM(div);\n        goto L_SEND_SYM;\n      }\n\n#ifndef MRB_NO_FLOAT\n      f = mrb_div_float(x, y);\n      SET_FLOAT_VALUE(mrb, regs[a], f);\n#endif\n      NEXT;\n    }\n\n#define OP_MATHI(op_name)                                                   \\\n  /* need to check if op is overridden */                                   \\\n  switch (mrb_type(regs[a])) {                                              \\\n    OP_MATHI_CASE_INTEGER(op_name);                                         \\\n    OP_MATHI_CASE_FLOAT(op_name);                                           \\\n    default:                                                                \\\n      SET_INT_VALUE(mrb,regs[a+1], b);                                      \\\n      mid = MRB_OPSYM(op_name);                                             \\\n      goto L_SEND_SYM;                                                      \\\n  }                                                                         \\\n  NEXT;\n#define OP_MATHI_CASE_INTEGER(op_name)                                      \\\n  case MRB_TT_INTEGER:                                                      \\\n    {                                                                       \\\n      mrb_int x = mrb_integer(regs[a]), y = (mrb_int)b, z;                  \\\n      if (mrb_int_##op_name##_overflow(x, y, &z))                           \\\n        OP_MATH_OVERFLOW_INT();                                             \\\n      else                                                                  \\\n        SET_INT_VALUE(mrb,regs[a], z);                                      \\\n    }                                                                       \\\n    break\n#ifdef MRB_NO_FLOAT\n#define OP_MATHI_CASE_FLOAT(op_name) (void)0\n#else\n#define OP_MATHI_CASE_FLOAT(op_name)                                        \\\n  case MRB_TT_FLOAT:                                                        \\\n    {                                                                       \\\n      mrb_float z = mrb_float(regs[a]) OP_MATH_OP_##op_name b;              \\\n      SET_FLOAT_VALUE(mrb, regs[a], z);                                     \\\n    }                                                                       \\\n    break\n#endif\n\n    CASE(OP_ADDI, BB) {\n      OP_MATHI(add);\n    }\n\n    CASE(OP_SUBI, BB) {\n      OP_MATHI(sub);\n    }\n\n#define OP_CMP_BODY(op,v1,v2) (v1(regs[a]) op v2(regs[a+1]))\n\n#ifdef MRB_NO_FLOAT\n#define OP_CMP(op,sym) do {\\\n  int result;\\\n  /* need to check if - is overridden */\\\n  switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\\\n  case TYPES2(MRB_TT_INTEGER,MRB_TT_INTEGER):\\\n    result = OP_CMP_BODY(op,mrb_fixnum,mrb_fixnum);\\\n    break;\\\n  default:\\\n    mid = MRB_OPSYM(sym);\\\n    goto L_SEND_SYM;\\\n  }\\\n  if (result) {\\\n    SET_TRUE_VALUE(regs[a]);\\\n  }\\\n  else {\\\n    SET_FALSE_VALUE(regs[a]);\\\n  }\\\n} while(0)\n#else\n#define OP_CMP(op, sym) do {\\\n  int result;\\\n  /* need to check if - is overridden */\\\n  switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\\\n  case TYPES2(MRB_TT_INTEGER,MRB_TT_INTEGER):\\\n    result = OP_CMP_BODY(op,mrb_fixnum,mrb_fixnum);\\\n    break;\\\n  case TYPES2(MRB_TT_INTEGER,MRB_TT_FLOAT):\\\n    result = OP_CMP_BODY(op,mrb_fixnum,mrb_float);\\\n    break;\\\n  case TYPES2(MRB_TT_FLOAT,MRB_TT_INTEGER):\\\n    result = OP_CMP_BODY(op,mrb_float,mrb_fixnum);\\\n    break;\\\n  case TYPES2(MRB_TT_FLOAT,MRB_TT_FLOAT):\\\n    result = OP_CMP_BODY(op,mrb_float,mrb_float);\\\n    break;\\\n  default:\\\n    mid = MRB_OPSYM(sym);\\\n    goto L_SEND_SYM;\\\n  }\\\n  if (result) {\\\n    SET_TRUE_VALUE(regs[a]);\\\n  }\\\n  else {\\\n    SET_FALSE_VALUE(regs[a]);\\\n  }\\\n} while(0)\n#endif\n\n    CASE(OP_EQ, B) {\n      if (mrb_obj_eq(mrb, regs[a], regs[a+1])) {\n        SET_TRUE_VALUE(regs[a]);\n      }\n      else {\n        OP_CMP(==,eq);\n      }\n      NEXT;\n    }\n\n    CASE(OP_LT, B) {\n      OP_CMP(<,lt);\n      NEXT;\n    }\n\n    CASE(OP_LE, B) {\n      OP_CMP(<=,le);\n      NEXT;\n    }\n\n    CASE(OP_GT, B) {\n      OP_CMP(>,gt);\n      NEXT;\n    }\n\n    CASE(OP_GE, B) {\n      OP_CMP(>=,ge);\n      NEXT;\n    }\n\n    CASE(OP_ARRAY, BB) {\n      regs[a] = mrb_ary_new_from_values(mrb, b, &regs[a]);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n    CASE(OP_ARRAY2, BBB) {\n      regs[a] = mrb_ary_new_from_values(mrb, c, &regs[b]);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_ARYCAT, B) {\n      mrb_value splat = mrb_ary_splat(mrb, regs[a+1]);\n      if (mrb_nil_p(regs[a])) {\n        regs[a] = splat;\n      }\n      else {\n        mrb_assert(mrb_array_p(regs[a]));\n        mrb_ary_concat(mrb, regs[a], splat);\n      }\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_ARYPUSH, BB) {\n      mrb_assert(mrb_array_p(regs[a]));\n      for (mrb_int i=0; i<b; i++) {\n        mrb_ary_push(mrb, regs[a], regs[a+i+1]);\n      }\n      NEXT;\n    }\n\n    CASE(OP_ARYDUP, B) {\n      mrb_value ary = regs[a];\n      if (mrb_array_p(ary)) {\n        ary = mrb_ary_new_from_values(mrb, RARRAY_LEN(ary), RARRAY_PTR(ary));\n      }\n      else {\n        ary = mrb_ary_new_from_values(mrb, 1, &ary);\n      }\n      regs[a] = ary;\n      NEXT;\n    }\n\n    CASE(OP_AREF, BBB) {\n      mrb_value v = regs[b];\n\n      if (!mrb_array_p(v)) {\n        if (c == 0) {\n          regs[a] = v;\n        }\n        else {\n          SET_NIL_VALUE(regs[a]);\n        }\n      }\n      else {\n        v = mrb_ary_ref(mrb, v, c);\n        regs[a] = v;\n      }\n      NEXT;\n    }\n\n    CASE(OP_ASET, BBB) {\n      mrb_assert(mrb_array_p(regs[a]));\n      mrb_ary_set(mrb, regs[b], c, regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_APOST, BBB) {\n      mrb_value v = regs[a];\n      int pre  = b;\n      int post = c;\n      struct RArray *ary;\n      int len, idx;\n\n      if (!mrb_array_p(v)) {\n        v = mrb_ary_new_from_values(mrb, 1, &regs[a]);\n      }\n      ary = mrb_ary_ptr(v);\n      len = (int)ARY_LEN(ary);\n      if (len > pre + post) {\n        v = mrb_ary_new_from_values(mrb, len - pre - post, ARY_PTR(ary)+pre);\n        regs[a++] = v;\n        while (post--) {\n          regs[a++] = ARY_PTR(ary)[len-post-1];\n        }\n      }\n      else {\n        v = mrb_ary_new_capa(mrb, 0);\n        regs[a++] = v;\n        for (idx=0; idx+pre<len; idx++) {\n          regs[a+idx] = ARY_PTR(ary)[pre+idx];\n        }\n        while (idx < post) {\n          SET_NIL_VALUE(regs[a+idx]);\n          idx++;\n        }\n      }\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_INTERN, B) {\n      mrb_assert(mrb_string_p(regs[a]));\n      mrb_sym sym = mrb_intern_str(mrb, regs[a]);\n      regs[a] = mrb_symbol_value(sym);\n      NEXT;\n    }\n\n    CASE(OP_SYMBOL, BB) {\n      size_t len;\n      mrb_sym sym;\n\n      mrb_assert((pool[b].tt&IREP_TT_NFLAG)==0);\n      len = pool[b].tt >> 2;\n      if (pool[b].tt & IREP_TT_SFLAG) {\n        sym = mrb_intern_static(mrb, pool[b].u.str, len);\n      }\n      else {\n        sym  = mrb_intern(mrb, pool[b].u.str, len);\n      }\n      regs[a] = mrb_symbol_value(sym);\n      NEXT;\n    }\n\n    CASE(OP_STRING, BB) {\n      mrb_int len;\n\n      mrb_assert((pool[b].tt&IREP_TT_NFLAG)==0);\n      len = pool[b].tt >> 2;\n      if (pool[b].tt & IREP_TT_SFLAG) {\n        regs[a] = mrb_str_new_static(mrb, pool[b].u.str, len);\n      }\n      else {\n        regs[a] = mrb_str_new(mrb, pool[b].u.str, len);\n      }\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_STRCAT, B) {\n      mrb_assert(mrb_string_p(regs[a]));\n      mrb_str_concat(mrb, regs[a], regs[a+1]);\n      NEXT;\n    }\n\n    CASE(OP_HASH, BB) {\n      mrb_value hash = mrb_hash_new_capa(mrb, b);\n      int i;\n      int lim = a+b*2;\n\n      for (i=a; i<lim; i+=2) {\n        mrb_hash_set(mrb, hash, regs[i], regs[i+1]);\n      }\n      regs[a] = hash;\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_HASHADD, BB) {\n      mrb_value hash;\n      int i;\n      int lim = a+b*2+1;\n\n      hash = regs[a];\n      mrb_ensure_hash_type(mrb, hash);\n      for (i=a+1; i<lim; i+=2) {\n        mrb_hash_set(mrb, hash, regs[i], regs[i+1]);\n      }\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n    CASE(OP_HASHCAT, B) {\n      mrb_value hash = regs[a];\n\n      mrb_assert(mrb_hash_p(hash));\n      mrb_hash_merge(mrb, hash, regs[a+1]);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_LAMBDA, BB)\n    c = OP_L_LAMBDA;\n    L_MAKE_LAMBDA:\n    {\n      struct RProc *p;\n      const mrb_irep *nirep = irep->reps[b];\n\n      if (c & OP_L_CAPTURE) {\n        p = mrb_closure_new(mrb, nirep);\n      }\n      else {\n        p = mrb_proc_new(mrb, nirep);\n        p->flags |= MRB_PROC_SCOPE;\n      }\n      if (c & OP_L_STRICT) p->flags |= MRB_PROC_STRICT;\n      regs[a] = mrb_obj_value(p);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n    CASE(OP_BLOCK, BB) {\n      c = OP_L_BLOCK;\n      goto L_MAKE_LAMBDA;\n    }\n    CASE(OP_METHOD, BB) {\n      c = OP_L_METHOD;\n      goto L_MAKE_LAMBDA;\n    }\n\n    CASE(OP_RANGE_INC, B) {\n      regs[a] = mrb_range_new(mrb, regs[a], regs[a+1], FALSE);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_RANGE_EXC, B) {\n      regs[a] = mrb_range_new(mrb, regs[a], regs[a+1], TRUE);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_OCLASS, B) {\n      regs[a] = mrb_obj_value(mrb->object_class);\n      NEXT;\n    }\n\n    CASE(OP_CLASS, BB) {\n      struct RClass *c = 0, *baseclass;\n      mrb_value base, super;\n      mrb_sym id = syms[b];\n\n      base = regs[a];\n      super = regs[a+1];\n      if (mrb_nil_p(base)) {\n        baseclass = MRB_PROC_TARGET_CLASS(mrb->c->ci->proc);\n        if (!baseclass) baseclass = mrb->object_class;\n        base = mrb_obj_value(baseclass);\n      }\n      c = mrb_vm_define_class(mrb, base, super, id);\n      regs[a] = mrb_obj_value(c);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_MODULE, BB) {\n      struct RClass *cls = 0, *baseclass;\n      mrb_value base;\n      mrb_sym id = syms[b];\n\n      base = regs[a];\n      if (mrb_nil_p(base)) {\n        baseclass = MRB_PROC_TARGET_CLASS(mrb->c->ci->proc);\n        if (!baseclass) baseclass = mrb->object_class;\n        base = mrb_obj_value(baseclass);\n      }\n      cls = mrb_vm_define_module(mrb, base, id);\n      regs[a] = mrb_obj_value(cls);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_EXEC, BB)\n    {\n      mrb_value recv = regs[a];\n      struct RProc *p;\n      const mrb_irep *nirep = irep->reps[b];\n\n      /* prepare closure */\n      p = mrb_proc_new(mrb, nirep);\n      p->c = NULL;\n      mrb_field_write_barrier(mrb, (struct RBasic*)p, (struct RBasic*)proc);\n      MRB_PROC_SET_TARGET_CLASS(p, mrb_class_ptr(recv));\n      p->flags |= MRB_PROC_SCOPE;\n\n      /* prepare call stack */\n      cipush(mrb, a, 0, mrb_class_ptr(recv), p, 0, 0);\n\n      irep = p->body.irep;\n      pool = irep->pool;\n      syms = irep->syms;\n      mrb_stack_extend(mrb, irep->nregs);\n      stack_clear(regs+1, irep->nregs-1);\n      pc = irep->iseq;\n      JUMP;\n    }\n\n    CASE(OP_DEF, BB) {\n      struct RClass *target = mrb_class_ptr(regs[a]);\n      struct RProc *p = mrb_proc_ptr(regs[a+1]);\n      mrb_method_t m;\n      mrb_sym mid = syms[b];\n\n      MRB_METHOD_FROM_PROC(m, p);\n      mrb_define_method_raw(mrb, target, mid, m);\n      mrb_method_added(mrb, target, mid);\n      mrb_gc_arena_restore(mrb, ai);\n      regs[a] = mrb_symbol_value(mid);\n      NEXT;\n    }\n\n    CASE(OP_SCLASS, B) {\n      regs[a] = mrb_singleton_class(mrb, regs[a]);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_TCLASS, B) {\n      struct RClass *target = check_target_class(mrb);\n      if (!target) goto L_RAISE;\n      regs[a] = mrb_obj_value(target);\n      NEXT;\n    }\n\n    CASE(OP_ALIAS, BB) {\n      struct RClass *target = check_target_class(mrb);\n\n      if (!target) goto L_RAISE;\n      mrb_alias_method(mrb, target, syms[a], syms[b]);\n      mrb_method_added(mrb, target, syms[a]);\n      NEXT;\n    }\n    CASE(OP_UNDEF, B) {\n      struct RClass *target = check_target_class(mrb);\n\n      if (!target) goto L_RAISE;\n      mrb_undef_method_id(mrb, target, syms[a]);\n      NEXT;\n    }\n\n    CASE(OP_DEBUG, Z) {\n      FETCH_BBB();\n#ifdef MRB_USE_DEBUG_HOOK\n      mrb->debug_op_hook(mrb, irep, pc, regs);\n#else\n#ifndef MRB_NO_STDIO\n      printf(\"OP_DEBUG %d %d %d\\n\", a, b, c);\n#else\n      abort();\n#endif\n#endif\n      NEXT;\n    }\n\n    CASE(OP_ERR, B) {\n      size_t len = pool[a].tt >> 2;\n      mrb_value exc;\n\n      mrb_assert((pool[a].tt&IREP_TT_NFLAG)==0);\n      exc = mrb_exc_new(mrb, E_LOCALJUMP_ERROR, pool[a].u.str, len);\n      mrb_exc_set(mrb, exc);\n      goto L_RAISE;\n    }\n\n    CASE(OP_EXT1, Z) {\n      insn = READ_B();\n      switch (insn) {\n#define OPCODE(insn,ops) case OP_ ## insn: FETCH_ ## ops ## _1(); mrb->c->ci->pc = pc; goto L_OP_ ## insn ## _BODY;\n#include \"mruby/ops.h\"\n#undef OPCODE\n      }\n      pc--;\n      NEXT;\n    }\n    CASE(OP_EXT2, Z) {\n      insn = READ_B();\n      switch (insn) {\n#define OPCODE(insn,ops) case OP_ ## insn: FETCH_ ## ops ## _2(); mrb->c->ci->pc = pc; goto L_OP_ ## insn ## _BODY;\n#include \"mruby/ops.h\"\n#undef OPCODE\n      }\n      pc--;\n      NEXT;\n    }\n    CASE(OP_EXT3, Z) {\n      uint8_t insn = READ_B();\n      switch (insn) {\n#define OPCODE(insn,ops) case OP_ ## insn: FETCH_ ## ops ## _3(); mrb->c->ci->pc = pc; goto L_OP_ ## insn ## _BODY;\n#include \"mruby/ops.h\"\n#undef OPCODE\n      }\n      pc--;\n      NEXT;\n    }\n\n    CASE(OP_STOP, Z) {\n      /*        stop VM */\n      CHECKPOINT_RESTORE(RBREAK_TAG_STOP) {\n        /* do nothing */\n      }\n      CHECKPOINT_MAIN(RBREAK_TAG_STOP) {\n        UNWIND_ENSURE(mrb, mrb->c->ci, pc, RBREAK_TAG_STOP, proc, mrb_nil_value());\n      }\n      CHECKPOINT_END(RBREAK_TAG_STOP);\n    L_STOP:\n      mrb->jmp = prev_jmp;\n      if (mrb->exc) {\n        mrb_assert(mrb->exc->tt == MRB_TT_EXCEPTION);\n        return mrb_obj_value(mrb->exc);\n      }\n      return regs[irep->nlocals];\n    }\n  }\n  END_DISPATCH;\n#undef regs\n  }\n  MRB_CATCH(&c_jmp) {\n    mrb_callinfo *ci = mrb->c->ci;\n    while (ci > mrb->c->cibase && ci->cci == CINFO_DIRECT) {\n      ci = cipop(mrb);\n    }\n    exc_catched = TRUE;\n    pc = ci->pc;\n    goto RETRY_TRY_BLOCK;\n  }\n  MRB_END_EXC(&c_jmp);\n}",
        "func_hash": 48104799339109897868762377500628330824,
        "file_name": "vm.c",
        "file_hash": 254712077563543563381285441661557243082,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2022-1071",
        "cve_desc": "User after free in mrb_vm_exec in GitHub repository mruby/mruby prior to 3.2.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-1071",
        "func_name": "mrb_vm_exec",
        "diff": [
            "diff --git a/src/vm.c b/src/vm.c\nindex 8b81031a37..fd17e90cc4 100644\n--- a/src/vm.c\n+++ b/src/vm.c\n@@ -1394,14 +1394,16 @@ mrb_vm_exec(mrb_state *mrb, const struct RProc *proc, const mrb_code *pc)\n         regs[a] = mrb_ary_entry(va, mrb_integer(vb));\n         break;\n       case MRB_TT_HASH:\n-        regs[a] = mrb_hash_get(mrb, va, vb);\n+        va = mrb_hash_get(mrb, va, vb);\n+        regs[a] = va;\n         break;\n       case MRB_TT_STRING:\n         switch (mrb_type(vb)) {\n         case MRB_TT_INTEGER:\n         case MRB_TT_STRING:\n         case MRB_TT_RANGE:\n-          regs[a] = mrb_str_aref(mrb, va, vb, mrb_undef_value());\n+          va = mrb_str_aref(mrb, va, vb, mrb_undef_value());\n+          regs[a] = va;\n           break;\n         default:\n           goto getidx_fallback;\n@@ -1423,7 +1425,8 @@ mrb_vm_exec(mrb_state *mrb, const struct RProc *proc, const mrb_code *pc)\n     }\n \n     CASE(OP_GETCONST, BB) {\n-      regs[a] = mrb_vm_const_get(mrb, syms[b]);\n+      mrb_value v = mrb_vm_const_get(mrb, syms[b]);\n+      regs[a] = v;\n       NEXT;\n     }\n \n@@ -1433,7 +1436,8 @@ mrb_vm_exec(mrb_state *mrb, const struct RProc *proc, const mrb_code *pc)\n     }\n \n     CASE(OP_GETMCNST, BB) {\n-      regs[a] = mrb_const_get(mrb, regs[a], syms[b]);\n+      mrb_value v = mrb_const_get(mrb, regs[a], syms[b]);\n+      regs[a] = v;\n       NEXT;\n     }\n \n@@ -2014,14 +2018,15 @@ mrb_vm_exec(mrb_state *mrb, const struct RProc *proc, const mrb_code *pc)\n     CASE(OP_KARG, BB) {\n       mrb_value k = mrb_symbol_value(syms[b]);\n       mrb_int kidx = mrb_ci_kidx(mrb->c->ci);\n-      mrb_value kdict;\n+      mrb_value kdict, v;\n \n       if (kidx < 0 || !mrb_hash_p(kdict=regs[kidx]) || !mrb_hash_key_p(mrb, kdict, k)) {\n         mrb_value str = mrb_format(mrb, \"missing keyword: %v\", k);\n         mrb_exc_set(mrb, mrb_exc_new_str(mrb, E_ARGUMENT_ERROR, str));\n         goto L_RAISE;\n       }\n-      regs[a] = mrb_hash_get(mrb, kdict, k);\n+      v = mrb_hash_get(mrb, kdict, k);\n+      regs[a] = v;\n       mrb_hash_delete_key(mrb, kdict, k);\n       NEXT;\n     }\n"
        ],
        "func_after": []
    },
    {
        "idx": 196817,
        "project": "njs",
        "commit_id": "81af26364c21c196dd21fb5e14c7fa9ce7debd17",
        "project_url": "https://github.com/nginx/njs",
        "commit_url": "https://github.com/nginx/njs/commit/81af26364c21c196dd21fb5e14c7fa9ce7debd17",
        "commit_message": "Fixed Object.defineProperty() when a recursive descriptor is provided.\n\nThis closes #481 issue on Github.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "njs_array_convert_to_slow_array(njs_vm_t *vm, njs_array_t *array)\n{\n    uint32_t           i, length;\n    njs_value_t        index, value;\n    njs_object_prop_t  *prop;\n\n    njs_set_array(&value, array);\n    array->object.fast_array = 0;\n\n    length = array->length;\n\n    for (i = 0; i < length; i++) {\n        if (njs_is_valid(&array->start[i])) {\n            njs_uint32_to_string(&index, i);\n            prop = njs_object_property_add(vm, &value, &index, 0);\n            if (njs_slow_path(prop == NULL)) {\n                return NJS_ERROR;\n            }\n\n            prop->value = array->start[i];\n        }\n    }\n\n    /* GC: release value. */\n\n    njs_mp_free(vm->mem_pool, array->start);\n    array->start = NULL;\n\n    return NJS_OK;\n}",
        "func_hash": 135038301213614089320274160983601202248,
        "file_name": "njs_array.c",
        "file_hash": 27861953644579332654826088207600556930,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2022-31306",
        "cve_desc": "Nginx NJS v0.7.2 was discovered to contain a segmentation violation in the function njs_array_convert_to_slow_array at src/njs_array.c.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-31306",
        "func_name": "njs_array_convert_to_slow_array",
        "diff": [
            "diff --git a/src/njs_array.c b/src/njs_array.c\nindex ec3a5da93..2367420dc 100644\n--- a/src/njs_array.c\n+++ b/src/njs_array.c\n@@ -142,6 +142,10 @@ njs_array_convert_to_slow_array(njs_vm_t *vm, njs_array_t *array)\n     njs_value_t        index, value;\n     njs_object_prop_t  *prop;\n \n+    if (njs_slow_path(!array->object.fast_array)) {\n+        return NJS_OK;\n+    }\n+\n     njs_set_array(&value, array);\n     array->object.fast_array = 0;\n \ndiff --git a/src/test/njs_unit_test.c b/src/test/njs_unit_test.c\nindex 87d8d46c0..77ec044e1 100644\n--- a/src/test/njs_unit_test.c\n+++ b/src/test/njs_unit_test.c\n@@ -13837,6 +13837,16 @@ static njs_unit_test_t  njs_test[] =\n               \"d.enumerable && d.writable && d.configurable\"),\n       njs_str(\"true\") },\n \n+    { njs_str(\"const arr = [1,2];\"\n+              \"function f(arg) {\"\n+              \"        const desc = {get: arg};\"\n+              \"        Object.defineProperty(desc, 'set', desc);\"\n+              \"        Object.defineProperty(arr, 1, desc);\"\n+              \"}\"\n+              \"f(f);\"\n+              \"njs.dump(arr)\"),\n+      njs_str(\"[1,'[Getter]']\") },\n+\n     { njs_str(\"Object.defineProperties()\"),\n       njs_str(\"TypeError: Object.defineProperties is called on non-object\") },\n \n"
        ],
        "func_after": []
    },
    {
        "idx": 196829,
        "project": "tensorflow",
        "commit_id": "9a133d73ae4b4664d22bd1aa6d654fec13c52ee1",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/9a133d73ae4b4664d22bd1aa6d654fec13c52ee1",
        "commit_message": "Prevent segfault in `GetSessionHandle{,V2}`.\n\nIn eager mode, session state is null.\n\nPiperOrigin-RevId: 332548597\nChange-Id: If094812c2e094044220b9ba28f7d7601be042f38",
        "target": 1,
        "irrelevant": 1,
        "func_before": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor& val = ctx->input(0);\n    int64 id = ctx->session_state()->GetNewId();\n    TensorStore::TensorAndKey tk{val, id, requested_device()};\n    OP_REQUIRES_OK(ctx, ctx->tensor_store()->AddTensor(name(), tk));\n\n    Tensor* handle = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, TensorShape({}), &handle));\n    if (ctx->expected_output_dtype(0) == DT_RESOURCE) {\n      ResourceHandle resource_handle = MakeResourceHandle<Tensor>(\n          ctx, SessionState::kTensorHandleResourceTypeName,\n          tk.GetHandle(name()));\n      resource_handle.set_maybe_type_name(\n          SessionState::kTensorHandleResourceTypeName);\n      handle->scalar<ResourceHandle>()() = resource_handle;\n    } else {\n      // Legacy behavior in V1.\n      handle->flat<tstring>().setConstant(tk.GetHandle(name()));\n    }\n  }",
        "func_hash": 265136132776865637405047291994320353020,
        "file_name": "session_ops.cc",
        "file_hash": 301236181949638816884177571060128580318,
        "cwe": [
            "CWE-476"
        ],
        "cve": "CVE-2020-15204",
        "cve_desc": "In eager mode, TensorFlow before versions 1.15.4, 2.0.3, 2.1.2, 2.2.1 and 2.3.1 does not set the session state. Hence, calling `tf.raw_ops.GetSessionHandle` or `tf.raw_ops.GetSessionHandleV2` results in a null pointer dereference In linked snippet, in eager mode, `ctx->session_state()` returns `nullptr`. Since code immediately dereferences this, we get a segmentation fault. The issue is patched in commit 9a133d73ae4b4664d22bd1aa6d654fec13c52ee1, and is released in TensorFlow versions 1.15.4, 2.0.3, 2.1.2, 2.2.1, or 2.3.1.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2020-15204",
        "func_name": "Compute",
        "diff": [
            "diff --git a/tensorflow/core/kernels/session_ops.cc b/tensorflow/core/kernels/session_ops.cc\nindex 9e67fec3c20a53..ee81ad27632622 100644\n--- a/tensorflow/core/kernels/session_ops.cc\n+++ b/tensorflow/core/kernels/session_ops.cc\n@@ -16,6 +16,7 @@ limitations under the License.\n // See docs in ../ops/data_flow_ops.cc.\n \n #include <limits.h>\n+\n #include <vector>\n \n #include \"tensorflow/core/common_runtime/device.h\"\n@@ -27,6 +28,7 @@ limitations under the License.\n #include \"tensorflow/core/framework/types.h\"\n #include \"tensorflow/core/lib/core/errors.h\"\n #include \"tensorflow/core/lib/gtl/map_util.h\"\n+#include \"tensorflow/core/platform/errors.h\"\n #include \"tensorflow/core/platform/logging.h\"\n #include \"tensorflow/core/platform/macros.h\"\n #include \"tensorflow/core/platform/mutex.h\"\n@@ -42,7 +44,11 @@ class GetSessionHandleOp : public OpKernel {\n \n   void Compute(OpKernelContext* ctx) override {\n     const Tensor& val = ctx->input(0);\n-    int64 id = ctx->session_state()->GetNewId();\n+    auto session_state = ctx->session_state();\n+    OP_REQUIRES(ctx, session_state != nullptr,\n+                errors::FailedPrecondition(\n+                    \"GetSessionHandle called on null session state\"));\n+    int64 id = session_state->GetNewId();\n     TensorStore::TensorAndKey tk{val, id, requested_device()};\n     OP_REQUIRES_OK(ctx, ctx->tensor_store()->AddTensor(name(), tk));\n \ndiff --git a/tensorflow/python/ops/raw_ops_test.py b/tensorflow/python/ops/raw_ops_test.py\nindex ee20d58d2f0fdd..6706ef194b221a 100644\n--- a/tensorflow/python/ops/raw_ops_test.py\n+++ b/tensorflow/python/ops/raw_ops_test.py\n@@ -25,6 +25,7 @@\n from tensorflow.python.framework import errors\n from tensorflow.python.framework import ops\n from tensorflow.python.framework import test_util\n+from tensorflow.python.ops import gen_data_flow_ops\n from tensorflow.python.ops import gen_math_ops\n from tensorflow.python.ops import gen_string_ops\n from tensorflow.python.platform import test\n@@ -79,6 +80,13 @@ def testStringNGramsBadDataSplits(self, splits):\n               pad_width=0,\n               preserve_short_sequences=False))\n \n+  def testGetSessionHandle(self):\n+    if context.executing_eagerly():\n+      with self.assertRaisesRegex(\n+          errors.FailedPreconditionError,\n+          \"GetSessionHandle called on null session state\"):\n+        gen_data_flow_ops.GetSessionHandle(value=[1])\n+\n \n if __name__ == \"__main__\":\n   ops.enable_eager_execution()\n"
        ],
        "func_after": []
    },
    {
        "idx": 196834,
        "project": "tensorflow",
        "commit_id": "701cfaca222a82afbeeb17496bd718baa65a67d2",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/701cfaca222a82afbeeb17496bd718baa65a67d2",
        "commit_message": "Fix heap out of bounds error in tf.raw_ops.SparseCountSparseOutput shape inference when it is called with invalid inputs, and add a test for it.\n\nPiperOrigin-RevId: 405766415\nChange-Id: I77d244ef35f351ef7b6f821efd959cac2c66db24",
        "target": 1,
        "irrelevant": 0,
        "func_before": "Status SparseCountSparseOutputShapeFn(InferenceContext *c) {\n  auto rank = c->Dim(c->input(0), 1);\n  auto nvals = c->UnknownDim();\n  c->set_output(0, c->Matrix(nvals, rank));  // out.indices\n  c->set_output(1, c->Vector(nvals));        // out.values\n  c->set_output(2, c->Vector(rank));         // out.dense_shape\n  return Status::OK();\n}",
        "func_hash": 288638774639466658606082764141579193752,
        "file_name": "count_ops.cc",
        "file_hash": 285251304555239344227100279342018211632,
        "cwe": [
            "CWE-125"
        ],
        "cve": "CVE-2021-41210",
        "cve_desc": "TensorFlow is an open source platform for machine learning. In affected versions the shape inference functions for `SparseCountSparseOutput` can trigger a read outside of bounds of heap allocated array. The fix will be included in TensorFlow 2.7.0. We will also cherrypick this commit on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-41210",
        "func_name": "SparseCountSparseOutputShapeFn",
        "diff": [
            "diff --git a/tensorflow/core/ops/count_ops.cc b/tensorflow/core/ops/count_ops.cc\nindex 4f9631310df924..aa6c0437337af2 100644\n--- a/tensorflow/core/ops/count_ops.cc\n+++ b/tensorflow/core/ops/count_ops.cc\n@@ -41,6 +41,8 @@ Status DenseCountSparseOutputShapeFn(InferenceContext *c) {\n }\n \n Status SparseCountSparseOutputShapeFn(InferenceContext *c) {\n+  ShapeHandle unused;\n+  TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 2, &unused));\n   auto rank = c->Dim(c->input(0), 1);\n   auto nvals = c->UnknownDim();\n   c->set_output(0, c->Matrix(nvals, rank));  // out.indices\ndiff --git a/tensorflow/python/ops/bincount_ops_test.py b/tensorflow/python/ops/bincount_ops_test.py\nindex 3c7a2a5da9daf6..de7d1423870d76 100644\n--- a/tensorflow/python/ops/bincount_ops_test.py\n+++ b/tensorflow/python/ops/bincount_ops_test.py\n@@ -831,6 +831,25 @@ def test_ragged_input_different_shape_fails(self):\n       self.evaluate(bincount_ops.sparse_bincount(x, weights=weights, axis=-1))\n \n \n+class RawOpsHeapOobTest(test.TestCase, parameterized.TestCase):\n+\n+  @test_util.run_v1_only(\"Test security error\")\n+  def testSparseCountSparseOutputBadIndicesShapeTooSmall(self):\n+    indices = [1]\n+    values = [[1]]\n+    weights = []\n+    dense_shape = [10]\n+    with self.assertRaisesRegex(ValueError,\n+                                \"Shape must be rank 2 but is rank 1 for\"):\n+      self.evaluate(\n+          gen_count_ops.SparseCountSparseOutput(\n+              indices=indices,\n+              values=values,\n+              dense_shape=dense_shape,\n+              weights=weights,\n+              binary_output=True))\n+\n+\n @test_util.run_all_in_graph_and_eager_modes\n @test_util.disable_tfrt\n class RawOpsTest(test.TestCase, parameterized.TestCase):\n"
        ],
        "func_after": []
    },
    {
        "idx": 196841,
        "project": "furnace",
        "commit_id": "0eb02422d5161767e9983bdaa5c429762d3477ce",
        "project_url": "https://github.com/tildearrow/furnace",
        "commit_url": "https://github.com/tildearrow/furnace/commit/0eb02422d5161767e9983bdaa5c429762d3477ce",
        "commit_message": "fix possible pattern crash\n\nissue #325",
        "target": 1,
        "irrelevant": 0,
        "func_before": "inline void FurnaceGUI::patternRow(int i, bool isPlaying, float lineHeight, int chans, int ord, const DivPattern** patCache) {\n  static char id[32];\n  bool selectedRow=(i>=sel1.y && i<=sel2.y);\n  ImGui::TableNextRow(0,lineHeight);\n  ImGui::TableNextColumn();\n  float cursorPosY=ImGui::GetCursorPos().y-ImGui::GetScrollY();\n  // check if the row is visible\n  if (cursorPosY<-lineHeight || cursorPosY>ImGui::GetWindowSize().y) {\n    return;\n  }\n  // check if we are in range\n  if (ord<0 || ord>=e->song.ordersLen) {\n    return;\n  }\n  if (i<0 || i>=e->song.patLen) {\n    return;\n  }\n  bool isPushing=false;\n  ImVec4 activeColor=uiColors[GUI_COLOR_PATTERN_ACTIVE];\n  ImVec4 inactiveColor=uiColors[GUI_COLOR_PATTERN_INACTIVE];\n  ImVec4 rowIndexColor=uiColors[GUI_COLOR_PATTERN_ROW_INDEX];\n  if (e->song.hilightB>0 && !(i%e->song.hilightB)) {\n    activeColor=uiColors[GUI_COLOR_PATTERN_ACTIVE_HI2];\n    inactiveColor=uiColors[GUI_COLOR_PATTERN_INACTIVE_HI2];\n    rowIndexColor=uiColors[GUI_COLOR_PATTERN_ROW_INDEX_HI2];\n  } else if (e->song.hilightA>0 && !(i%e->song.hilightA)) {\n    activeColor=uiColors[GUI_COLOR_PATTERN_ACTIVE_HI1];\n    inactiveColor=uiColors[GUI_COLOR_PATTERN_INACTIVE_HI1];\n    rowIndexColor=uiColors[GUI_COLOR_PATTERN_ROW_INDEX_HI1];\n  }\n  // check overflow highlight\n  if (settings.overflowHighlight) {\n    if (edit && cursor.y==i) {\n      ImGui::TableSetBgColor(ImGuiTableBgTarget_RowBg0,ImGui::GetColorU32(uiColors[GUI_COLOR_EDITING]));\n    } else if (isPlaying && oldRow==i) {\n      ImGui::TableSetBgColor(ImGuiTableBgTarget_RowBg0,ImGui::GetColorU32(uiColors[GUI_COLOR_PATTERN_PLAY_HEAD]));\n    } else if (e->song.hilightB>0 && !(i%e->song.hilightB)) {\n      ImGui::TableSetBgColor(ImGuiTableBgTarget_RowBg0,ImGui::GetColorU32(uiColors[GUI_COLOR_PATTERN_HI_2]));\n    } else if (e->song.hilightA>0 && !(i%e->song.hilightA)) {\n      ImGui::TableSetBgColor(ImGuiTableBgTarget_RowBg0,ImGui::GetColorU32(uiColors[GUI_COLOR_PATTERN_HI_1]));\n    }\n  } else {\n    isPushing=true;\n    if (edit && cursor.y==i) {\n      ImGui::PushStyleColor(ImGuiCol_Header,ImGui::GetColorU32(uiColors[GUI_COLOR_EDITING]));\n    } else if (isPlaying && oldRow==i) {\n      ImGui::PushStyleColor(ImGuiCol_Header,ImGui::GetColorU32(uiColors[GUI_COLOR_PATTERN_PLAY_HEAD]));\n    } else if (e->song.hilightB>0 && !(i%e->song.hilightB)) {\n      ImGui::PushStyleColor(ImGuiCol_Header,ImGui::GetColorU32(uiColors[GUI_COLOR_PATTERN_HI_2]));\n    } else if (e->song.hilightA>0 && !(i%e->song.hilightA)) {\n      ImGui::PushStyleColor(ImGuiCol_Header,ImGui::GetColorU32(uiColors[GUI_COLOR_PATTERN_HI_1]));\n    } else {\n      isPushing=false;\n    }\n  }\n  // row number\n  if (settings.patRowsBase==1) {\n    ImGui::TextColored(rowIndexColor,\" %.2X \",i);\n  } else {\n    ImGui::TextColored(rowIndexColor,\"%3d \",i);\n  }\n  // for each column\n  for (int j=0; j<chans; j++) {\n    // check if channel is not hidden\n    if (!e->song.chanShow[j]) {\n      patChanX[j]=ImGui::GetCursorPosX();\n      continue;\n    }\n    int chanVolMax=e->getMaxVolumeChan(j);\n    if (chanVolMax<1) chanVolMax=1;\n    const DivPattern* pat=patCache[j];\n    ImGui::TableNextColumn();\n    patChanX[j]=ImGui::GetCursorPosX();\n\n    // selection highlight flags\n    int sel1XSum=sel1.xCoarse*32+sel1.xFine;\n    int sel2XSum=sel2.xCoarse*32+sel2.xFine;\n    int j32=j*32;\n    bool selectedNote=selectedRow && (j32>=sel1XSum && j32<=sel2XSum);\n    bool selectedIns=selectedRow && (j32+1>=sel1XSum && j32+1<=sel2XSum);\n    bool selectedVol=selectedRow && (j32+2>=sel1XSum && j32+2<=sel2XSum);\n    bool cursorNote=(cursor.y==i && cursor.xCoarse==j && cursor.xFine==0);\n    bool cursorIns=(cursor.y==i && cursor.xCoarse==j && cursor.xFine==1);\n    bool cursorVol=(cursor.y==i && cursor.xCoarse==j && cursor.xFine==2);\n\n    // note\n    sprintf(id,\"%s##PN_%d_%d\",noteName(pat->data[i][0],pat->data[i][1]),i,j);\n    if (pat->data[i][0]==0 && pat->data[i][1]==0) {\n      ImGui::PushStyleColor(ImGuiCol_Text,inactiveColor);\n    } else {\n      ImGui::PushStyleColor(ImGuiCol_Text,activeColor);\n    }\n    if (cursorNote) {\n      ImGui::PushStyleColor(ImGuiCol_Header,uiColors[GUI_COLOR_PATTERN_CURSOR]);\n      ImGui::PushStyleColor(ImGuiCol_HeaderActive,uiColors[GUI_COLOR_PATTERN_CURSOR_ACTIVE]);\n      ImGui::PushStyleColor(ImGuiCol_HeaderHovered,uiColors[GUI_COLOR_PATTERN_CURSOR_HOVER]);\n      ImGui::Selectable(id,true,ImGuiSelectableFlags_NoPadWithHalfSpacing,threeChars);\n      demandX=ImGui::GetCursorPosX();\n      ImGui::PopStyleColor(3);\n    } else {\n      if (selectedNote) ImGui::PushStyleColor(ImGuiCol_Header,uiColors[GUI_COLOR_PATTERN_SELECTION]);\n      ImGui::Selectable(id,isPushing || selectedNote,ImGuiSelectableFlags_NoPadWithHalfSpacing,threeChars);\n      if (selectedNote) ImGui::PopStyleColor();\n    }\n    if (ImGui::IsItemClicked()) {\n      startSelection(j,0,i);\n    }\n    if (ImGui::IsItemHovered(ImGuiHoveredFlags_AllowWhenBlockedByActiveItem)) {\n      updateSelection(j,0,i);\n    }\n    ImGui::PopStyleColor();\n\n    // the following is only visible when the channel is not collapsed\n    if (!e->song.chanCollapse[j]) {\n      // instrument\n      if (pat->data[i][2]==-1) {\n        ImGui::PushStyleColor(ImGuiCol_Text,inactiveColor);\n        sprintf(id,\"..##PI_%d_%d\",i,j);\n      } else {\n        if (pat->data[i][2]<0 || pat->data[i][2]>=e->song.insLen) {\n          ImGui::PushStyleColor(ImGuiCol_Text,uiColors[GUI_COLOR_PATTERN_INS_ERROR]);\n        } else {\n          DivInstrumentType t=e->song.ins[pat->data[i][2]]->type;\n          if (t!=DIV_INS_AMIGA && t!=e->getPreferInsType(j)) {\n            ImGui::PushStyleColor(ImGuiCol_Text,uiColors[GUI_COLOR_PATTERN_INS_WARN]);\n          } else {\n            ImGui::PushStyleColor(ImGuiCol_Text,uiColors[GUI_COLOR_PATTERN_INS]);\n          }\n        }\n        sprintf(id,\"%.2X##PI_%d_%d\",pat->data[i][2],i,j);\n      }\n      ImGui::SameLine(0.0f,0.0f);\n      if (cursorIns) {\n        ImGui::PushStyleColor(ImGuiCol_Header,uiColors[GUI_COLOR_PATTERN_CURSOR]);\n        ImGui::PushStyleColor(ImGuiCol_HeaderActive,uiColors[GUI_COLOR_PATTERN_CURSOR_ACTIVE]);\n        ImGui::PushStyleColor(ImGuiCol_HeaderHovered,uiColors[GUI_COLOR_PATTERN_CURSOR_HOVER]);\n        ImGui::Selectable(id,true,ImGuiSelectableFlags_NoPadWithHalfSpacing,twoChars);\n        demandX=ImGui::GetCursorPosX();\n        ImGui::PopStyleColor(3);\n      } else {\n        if (selectedIns) ImGui::PushStyleColor(ImGuiCol_Header,uiColors[GUI_COLOR_PATTERN_SELECTION]);\n        ImGui::Selectable(id,isPushing || selectedIns,ImGuiSelectableFlags_NoPadWithHalfSpacing,twoChars);\n        if (selectedIns) ImGui::PopStyleColor();\n      }\n      if (ImGui::IsItemClicked()) {\n        startSelection(j,1,i);\n      }\n      if (ImGui::IsItemHovered(ImGuiHoveredFlags_AllowWhenBlockedByActiveItem)) {\n        updateSelection(j,1,i);\n      }\n      ImGui::PopStyleColor();\n\n      // volume\n      if (pat->data[i][3]==-1) {\n        sprintf(id,\"..##PV_%d_%d\",i,j);\n        ImGui::PushStyleColor(ImGuiCol_Text,inactiveColor);\n      } else {\n        int volColor=(pat->data[i][3]*127)/chanVolMax;\n        if (volColor>127) volColor=127;\n        if (volColor<0) volColor=0;\n        sprintf(id,\"%.2X##PV_%d_%d\",pat->data[i][3],i,j);\n        ImGui::PushStyleColor(ImGuiCol_Text,volColors[volColor]);\n      }\n      ImGui::SameLine(0.0f,0.0f);\n      if (cursorVol) {\n        ImGui::PushStyleColor(ImGuiCol_Header,uiColors[GUI_COLOR_PATTERN_CURSOR]);\n        ImGui::PushStyleColor(ImGuiCol_HeaderActive,uiColors[GUI_COLOR_PATTERN_CURSOR_ACTIVE]);\n        ImGui::PushStyleColor(ImGuiCol_HeaderHovered,uiColors[GUI_COLOR_PATTERN_CURSOR_HOVER]);\n        ImGui::Selectable(id,true,ImGuiSelectableFlags_NoPadWithHalfSpacing,twoChars);\n        demandX=ImGui::GetCursorPosX();\n        ImGui::PopStyleColor(3);\n      } else {\n        if (selectedVol) ImGui::PushStyleColor(ImGuiCol_Header,uiColors[GUI_COLOR_PATTERN_SELECTION]);\n        ImGui::Selectable(id,isPushing || selectedVol,ImGuiSelectableFlags_NoPadWithHalfSpacing,twoChars);\n        if (selectedVol) ImGui::PopStyleColor();\n      }\n      if (ImGui::IsItemClicked()) {\n        startSelection(j,2,i);\n      }\n      if (ImGui::IsItemHovered(ImGuiHoveredFlags_AllowWhenBlockedByActiveItem)) {\n        updateSelection(j,2,i);\n      }\n      ImGui::PopStyleColor();\n\n      // effects\n      for (int k=0; k<e->song.pat[j].effectRows; k++) {\n        int index=4+(k<<1);\n        bool selectedEffect=selectedRow && (j32+index-1>=sel1XSum && j32+index-1<=sel2XSum);\n        bool selectedEffectVal=selectedRow && (j32+index>=sel1XSum && j32+index<=sel2XSum);\n        bool cursorEffect=(cursor.y==i && cursor.xCoarse==j && cursor.xFine==index-1);\n        bool cursorEffectVal=(cursor.y==i && cursor.xCoarse==j && cursor.xFine==index);\n        \n        // effect\n        if (pat->data[i][index]==-1) {\n          sprintf(id,\"..##PE%d_%d_%d\",k,i,j);\n          ImGui::PushStyleColor(ImGuiCol_Text,inactiveColor);\n        } else {\n          sprintf(id,\"%.2X##PE%d_%d_%d\",pat->data[i][index],k,i,j);\n          if (pat->data[i][index]<0x10) {\n            ImGui::PushStyleColor(ImGuiCol_Text,uiColors[fxColors[pat->data[i][index]]]);\n          } else if (pat->data[i][index]<0x20) {\n            ImGui::PushStyleColor(ImGuiCol_Text,uiColors[GUI_COLOR_PATTERN_EFFECT_SYS_PRIMARY]);\n          } else if (pat->data[i][index]<0x30) {\n            ImGui::PushStyleColor(ImGuiCol_Text,uiColors[GUI_COLOR_PATTERN_EFFECT_SYS_SECONDARY]);\n          } else if (pat->data[i][index]<0x48) {\n            ImGui::PushStyleColor(ImGuiCol_Text,uiColors[GUI_COLOR_PATTERN_EFFECT_SYS_PRIMARY]);\n          } else if (pat->data[i][index]<0x90) {\n            ImGui::PushStyleColor(ImGuiCol_Text,uiColors[GUI_COLOR_PATTERN_EFFECT_INVALID]);\n          } else if (pat->data[i][index]<0xa0) {\n            ImGui::PushStyleColor(ImGuiCol_Text,uiColors[GUI_COLOR_PATTERN_EFFECT_MISC]);\n          } else if (pat->data[i][index]<0xc0) {\n            ImGui::PushStyleColor(ImGuiCol_Text,uiColors[GUI_COLOR_PATTERN_EFFECT_INVALID]);\n          } else if (pat->data[i][index]<0xd0) {\n            ImGui::PushStyleColor(ImGuiCol_Text,uiColors[GUI_COLOR_PATTERN_EFFECT_SPEED]);\n          } else if (pat->data[i][index]<0xe0) {\n            ImGui::PushStyleColor(ImGuiCol_Text,uiColors[GUI_COLOR_PATTERN_EFFECT_INVALID]);\n          } else {\n            ImGui::PushStyleColor(ImGuiCol_Text,uiColors[extFxColors[pat->data[i][index]-0xe0]]);\n          }\n        }\n        ImGui::SameLine(0.0f,0.0f);\n        if (cursorEffect) {\n          ImGui::PushStyleColor(ImGuiCol_Header,uiColors[GUI_COLOR_PATTERN_CURSOR]);  \n          ImGui::PushStyleColor(ImGuiCol_HeaderActive,uiColors[GUI_COLOR_PATTERN_CURSOR_ACTIVE]);\n          ImGui::PushStyleColor(ImGuiCol_HeaderHovered,uiColors[GUI_COLOR_PATTERN_CURSOR_HOVER]);\n          ImGui::Selectable(id,true,ImGuiSelectableFlags_NoPadWithHalfSpacing,twoChars);\n          demandX=ImGui::GetCursorPosX();\n          ImGui::PopStyleColor(3);\n        } else {\n          if (selectedEffect) ImGui::PushStyleColor(ImGuiCol_Header,uiColors[GUI_COLOR_PATTERN_SELECTION]);\n          ImGui::Selectable(id,isPushing || selectedEffect,ImGuiSelectableFlags_NoPadWithHalfSpacing,twoChars);\n          if (selectedEffect) ImGui::PopStyleColor();\n        }\n        if (ImGui::IsItemClicked()) {\n          startSelection(j,index-1,i);\n        }\n        if (ImGui::IsItemHovered(ImGuiHoveredFlags_AllowWhenBlockedByActiveItem)) {\n          updateSelection(j,index-1,i);\n        }\n\n        // effect value\n        if (pat->data[i][index+1]==-1) {\n          sprintf(id,\"..##PF%d_%d_%d\",k,i,j);\n        } else {\n          sprintf(id,\"%.2X##PF%d_%d_%d\",pat->data[i][index+1],k,i,j);\n        }\n        ImGui::SameLine(0.0f,0.0f);\n        if (cursorEffectVal) {\n          ImGui::PushStyleColor(ImGuiCol_Header,uiColors[GUI_COLOR_PATTERN_CURSOR]);  \n          ImGui::PushStyleColor(ImGuiCol_HeaderActive,uiColors[GUI_COLOR_PATTERN_CURSOR_ACTIVE]);\n          ImGui::PushStyleColor(ImGuiCol_HeaderHovered,uiColors[GUI_COLOR_PATTERN_CURSOR_HOVER]);\n          ImGui::Selectable(id,true,ImGuiSelectableFlags_NoPadWithHalfSpacing,twoChars);\n          demandX=ImGui::GetCursorPosX();\n          ImGui::PopStyleColor(3);\n        } else {\n          if (selectedEffectVal) ImGui::PushStyleColor(ImGuiCol_Header,uiColors[GUI_COLOR_PATTERN_SELECTION]);\n          ImGui::Selectable(id,isPushing || selectedEffectVal,ImGuiSelectableFlags_NoPadWithHalfSpacing,twoChars);\n          if (selectedEffectVal) ImGui::PopStyleColor();\n        }\n        if (ImGui::IsItemClicked()) {\n          startSelection(j,index,i);\n        }\n        if (ImGui::IsItemHovered(ImGuiHoveredFlags_AllowWhenBlockedByActiveItem)) {\n          updateSelection(j,index,i);\n        }\n        ImGui::PopStyleColor();\n      }\n    }\n  }\n  if (isPushing) {\n    ImGui::PopStyleColor();\n  }\n  ImGui::TableNextColumn();\n  patChanX[chans]=ImGui::GetCursorPosX();\n}",
        "func_hash": 17036366544095628794236625993100848883,
        "file_name": "pattern.cpp",
        "file_hash": 65197606135408680585944772278654686188,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2022-1289",
        "cve_desc": "A denial of service vulnerability was found in tildearrow Furnace. It has been classified as problematic. This is due to an incomplete fix of CVE-2022-1211. It is possible to initiate the attack remotely but it requires user interaction. The issue got fixed with the patch 0eb02422d5161767e9983bdaa5c429762d3477ce.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-1289",
        "func_name": "FurnaceGUI::patternRow",
        "diff": [
            "diff --git a/src/gui/pattern.cpp b/src/gui/pattern.cpp\nindex d6b6fce70d..d56196d6c8 100644\n--- a/src/gui/pattern.cpp\n+++ b/src/gui/pattern.cpp\n@@ -282,27 +282,33 @@ inline void FurnaceGUI::patternRow(int i, bool isPlaying, float lineHeight, int\n           sprintf(id,\"..##PE%d_%d_%d\",k,i,j);\n           ImGui::PushStyleColor(ImGuiCol_Text,inactiveColor);\n         } else {\n-          sprintf(id,\"%.2X##PE%d_%d_%d\",pat->data[i][index],k,i,j);\n-          if (pat->data[i][index]<0x10) {\n-            ImGui::PushStyleColor(ImGuiCol_Text,uiColors[fxColors[pat->data[i][index]]]);\n-          } else if (pat->data[i][index]<0x20) {\n-            ImGui::PushStyleColor(ImGuiCol_Text,uiColors[GUI_COLOR_PATTERN_EFFECT_SYS_PRIMARY]);\n-          } else if (pat->data[i][index]<0x30) {\n-            ImGui::PushStyleColor(ImGuiCol_Text,uiColors[GUI_COLOR_PATTERN_EFFECT_SYS_SECONDARY]);\n-          } else if (pat->data[i][index]<0x48) {\n-            ImGui::PushStyleColor(ImGuiCol_Text,uiColors[GUI_COLOR_PATTERN_EFFECT_SYS_PRIMARY]);\n-          } else if (pat->data[i][index]<0x90) {\n-            ImGui::PushStyleColor(ImGuiCol_Text,uiColors[GUI_COLOR_PATTERN_EFFECT_INVALID]);\n-          } else if (pat->data[i][index]<0xa0) {\n-            ImGui::PushStyleColor(ImGuiCol_Text,uiColors[GUI_COLOR_PATTERN_EFFECT_MISC]);\n-          } else if (pat->data[i][index]<0xc0) {\n-            ImGui::PushStyleColor(ImGuiCol_Text,uiColors[GUI_COLOR_PATTERN_EFFECT_INVALID]);\n-          } else if (pat->data[i][index]<0xd0) {\n-            ImGui::PushStyleColor(ImGuiCol_Text,uiColors[GUI_COLOR_PATTERN_EFFECT_SPEED]);\n-          } else if (pat->data[i][index]<0xe0) {\n+          if (pat->data[i][index]>0xff) {\n+            sprintf(id,\"??##PE%d_%d_%d\",k,i,j);\n             ImGui::PushStyleColor(ImGuiCol_Text,uiColors[GUI_COLOR_PATTERN_EFFECT_INVALID]);\n           } else {\n-            ImGui::PushStyleColor(ImGuiCol_Text,uiColors[extFxColors[pat->data[i][index]-0xe0]]);\n+            const unsigned char data=pat->data[i][index];\n+            sprintf(id,\"%.2X##PE%d_%d_%d\",data,k,i,j);\n+            if (data<0x10) {\n+              ImGui::PushStyleColor(ImGuiCol_Text,uiColors[fxColors[data]]);\n+            } else if (data<0x20) {\n+              ImGui::PushStyleColor(ImGuiCol_Text,uiColors[GUI_COLOR_PATTERN_EFFECT_SYS_PRIMARY]);\n+            } else if (data<0x30) {\n+              ImGui::PushStyleColor(ImGuiCol_Text,uiColors[GUI_COLOR_PATTERN_EFFECT_SYS_SECONDARY]);\n+            } else if (data<0x48) {\n+              ImGui::PushStyleColor(ImGuiCol_Text,uiColors[GUI_COLOR_PATTERN_EFFECT_SYS_PRIMARY]);\n+            } else if (data<0x90) {\n+              ImGui::PushStyleColor(ImGuiCol_Text,uiColors[GUI_COLOR_PATTERN_EFFECT_INVALID]);\n+            } else if (data<0xa0) {\n+              ImGui::PushStyleColor(ImGuiCol_Text,uiColors[GUI_COLOR_PATTERN_EFFECT_MISC]);\n+            } else if (data<0xc0) {\n+              ImGui::PushStyleColor(ImGuiCol_Text,uiColors[GUI_COLOR_PATTERN_EFFECT_INVALID]);\n+            } else if (data<0xd0) {\n+              ImGui::PushStyleColor(ImGuiCol_Text,uiColors[GUI_COLOR_PATTERN_EFFECT_SPEED]);\n+            } else if (data<0xe0) {\n+              ImGui::PushStyleColor(ImGuiCol_Text,uiColors[GUI_COLOR_PATTERN_EFFECT_INVALID]);\n+            } else {\n+              ImGui::PushStyleColor(ImGuiCol_Text,uiColors[extFxColors[data-0xe0]]);\n+            }\n           }\n         }\n         ImGui::SameLine(0.0f,0.0f);\n"
        ],
        "func_after": []
    },
    {
        "idx": 196846,
        "project": "tensorflow",
        "commit_id": "1e206baedf8bef0334cca3eb92bab134ef525a28",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/1e206baedf8bef0334cca3eb92bab134ef525a28",
        "commit_message": "Prevent a division by 0 in division ops.\n\nPiperOrigin-RevId: 385223169\nChange-Id: Ia4228960b5d2aa44480385f74bdd70d21a3613c3",
        "target": 1,
        "irrelevant": 0,
        "func_before": "TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n  auto* params = reinterpret_cast<TfLiteDivParams*>(node->builtin_data);\n  OpData* data = reinterpret_cast<OpData*>(node->user_data);\n\n  const TfLiteTensor* input1;\n  TF_LITE_ENSURE_OK(context,\n                    GetInputSafe(context, node, kInputTensor1, &input1));\n  const TfLiteTensor* input2;\n  TF_LITE_ENSURE_OK(context,\n                    GetInputSafe(context, node, kInputTensor2, &input2));\n  TfLiteTensor* output;\n  TF_LITE_ENSURE_OK(context,\n                    GetOutputSafe(context, node, kOutputTensor, &output));\n\n  if (output->type == kTfLiteFloat32 || output->type == kTfLiteInt32) {\n    EvalDiv<kernel_type>(context, node, params, data, input1, input2, output);\n  } else if (output->type == kTfLiteUInt8) {\n    TF_LITE_ENSURE_OK(\n        context, EvalQuantized<kernel_type>(context, node, params, data, input1,\n                                            input2, output));\n  } else {\n    context->ReportError(\n        context,\n        \"Div only supports FLOAT32, INT32 and quantized UINT8 now, got %d.\",\n        output->type);\n    return kTfLiteError;\n  }\n\n  return kTfLiteOk;\n}",
        "func_hash": 74793210691338682931219587955813295204,
        "file_name": "div.cc",
        "file_hash": 136615346340517059112870142252291864399,
        "cwe": [
            "CWE-369"
        ],
        "cve": "CVE-2021-37683",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions the implementation of division in TFLite is [vulnerable to a division by 0 error](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/lite/kernels/div.cc). There is no check that the divisor tensor does not contain zero elements. We have patched the issue in GitHub commit 1e206baedf8bef0334cca3eb92bab134ef525a28. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37683",
        "func_name": "Eval",
        "diff": [
            "diff --git a/tensorflow/lite/kernels/div.cc b/tensorflow/lite/kernels/div.cc\nindex f744b4ba1b7f63..51623a969d1b11 100644\n--- a/tensorflow/lite/kernels/div.cc\n+++ b/tensorflow/lite/kernels/div.cc\n@@ -216,9 +216,23 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_OK(context,\n                     GetOutputSafe(context, node, kOutputTensor, &output));\n \n-  if (output->type == kTfLiteFloat32 || output->type == kTfLiteInt32) {\n+  // TODO(b/193904910): This can written with C++ templates\n+#define TF_LITE_CHECK_DIV_NON_ZERO(data_type)                       \\\n+  const auto* input2_data = GetTensorData<data_type>(input2);       \\\n+  const size_t input2_elements = input2->bytes / sizeof(data_type); \\\n+  for (size_t i = 0; i < input2_elements; i++) {                    \\\n+    TF_LITE_ENSURE(context, input2_data[i] != 0);                   \\\n+  }\n+\n+  if (output->type == kTfLiteFloat32) {\n+    // Div by zero seems ok in this case, just like in TF case infinities are\n+    // returned. So we don't do a check at this point.\n+    EvalDiv<kernel_type>(context, node, params, data, input1, input2, output);\n+  } else if (output->type == kTfLiteInt32) {\n+    TF_LITE_CHECK_DIV_NON_ZERO(int32_t);\n     EvalDiv<kernel_type>(context, node, params, data, input1, input2, output);\n   } else if (output->type == kTfLiteUInt8) {\n+    TF_LITE_CHECK_DIV_NON_ZERO(uint8_t);\n     TF_LITE_ENSURE_OK(\n         context, EvalQuantized<kernel_type>(context, node, params, data, input1,\n                                             input2, output));\n@@ -229,6 +243,7 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n         output->type);\n     return kTfLiteError;\n   }\n+#undef TF_LITE_CHECK_DIV_NON_ZERO\n \n   return kTfLiteOk;\n }\n"
        ],
        "func_after": []
    },
    {
        "idx": 196860,
        "project": "gpac",
        "commit_id": "a51f951b878c2b73c1d8e2f1518c7cdc5fb82c3f",
        "project_url": "https://github.com/gpac/gpac",
        "commit_url": "https://github.com/gpac/gpac/commit/a51f951b878c2b73c1d8e2f1518c7cdc5fb82c3f",
        "commit_message": "fixed #1782 (fuzz)",
        "target": 1,
        "irrelevant": 0,
        "func_before": "GF_Err afra_box_read(GF_Box *s, GF_BitStream *bs)\n{\n\tunsigned int i;\n\tGF_AdobeFragRandomAccessBox *ptr = (GF_AdobeFragRandomAccessBox *)s;\n\n\tISOM_DECREASE_SIZE(ptr, 9)\n\tptr->long_ids = gf_bs_read_int(bs, 1);\n\tptr->long_offsets = gf_bs_read_int(bs, 1);\n\tptr->global_entries = gf_bs_read_int(bs, 1);\n\tptr->reserved = gf_bs_read_int(bs, 5);\n\tptr->time_scale = gf_bs_read_u32(bs);\n\n\tptr->entry_count = gf_bs_read_u32(bs);\n\tif (ptr->size / ( (ptr->long_offsets ? 16 : 12) ) < ptr->entry_count)\n\t\treturn GF_ISOM_INVALID_FILE;\n\n\tfor (i=0; i<ptr->entry_count; i++) {\n\t\tGF_AfraEntry *ae = gf_malloc(sizeof(GF_AfraEntry));\n\t\tif (!ae) return GF_OUT_OF_MEM;\n\n\t\tISOM_DECREASE_SIZE(ptr, 8)\n\t\tae->time = gf_bs_read_u64(bs);\n\t\tif (ptr->long_offsets) {\n\t\t\tISOM_DECREASE_SIZE(ptr, 8)\n\t\t\tae->offset = gf_bs_read_u64(bs);\n\t\t} else {\n\t\t\tISOM_DECREASE_SIZE(ptr, 4)\n\t\t\tae->offset = gf_bs_read_u32(bs);\n\t\t}\n\n\t\tgf_list_insert(ptr->local_access_entries, ae, i);\n\t}\n\n\tif (ptr->global_entries) {\n\t\tISOM_DECREASE_SIZE(ptr, 4)\n\t\tptr->global_entry_count = gf_bs_read_u32(bs);\n\t\tfor (i=0; i<ptr->global_entry_count; i++) {\n\t\t\tGF_GlobalAfraEntry *ae = gf_malloc(sizeof(GF_GlobalAfraEntry));\n\t\t\tif (!ae) return GF_OUT_OF_MEM;\n\t\t\tISOM_DECREASE_SIZE(ptr, 8)\n\t\t\tae->time = gf_bs_read_u64(bs);\n\t\t\tif (ptr->long_ids) {\n\t\t\t\tISOM_DECREASE_SIZE(ptr, 8)\n\t\t\t\tae->segment = gf_bs_read_u32(bs);\n\t\t\t\tae->fragment = gf_bs_read_u32(bs);\n\t\t\t} else {\n\t\t\t\tISOM_DECREASE_SIZE(ptr, 4)\n\t\t\t\tae->segment = gf_bs_read_u16(bs);\n\t\t\t\tae->fragment = gf_bs_read_u16(bs);\n\t\t\t}\n\t\t\tif (ptr->long_offsets) {\n\t\t\t\tISOM_DECREASE_SIZE(ptr, 16)\n\t\t\t\tae->afra_offset = gf_bs_read_u64(bs);\n\t\t\t\tae->offset_from_afra = gf_bs_read_u64(bs);\n\t\t\t} else {\n\t\t\t\tISOM_DECREASE_SIZE(ptr, 8)\n\t\t\t\tae->afra_offset = gf_bs_read_u32(bs);\n\t\t\t\tae->offset_from_afra = gf_bs_read_u32(bs);\n\t\t\t}\n\n\t\t\tgf_list_insert(ptr->global_access_entries, ae, i);\n\t\t}\n\t}\n\n\treturn GF_OK;\n}",
        "func_hash": 312927211426500504617752335989791880756,
        "file_name": "box_code_adobe.c",
        "file_hash": null,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2021-33361",
        "cve_desc": "Memory leak in the afra_box_read function in MP4Box in GPAC 1.0.1 allows attackers to read memory via a crafted file.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-33361",
        "func_name": "afra_box_read",
        "diff": [
            "diff --git a/applications/mp4box/main.c b/applications/mp4box/main.c\nindex e0215f77ed..db6c067796 100644\n--- a/applications/mp4box/main.c\n+++ b/applications/mp4box/main.c\n@@ -5439,6 +5439,14 @@ static u32 mp4box_cleanup(u32 ret_code) {\n \t}\n \tif (logfile) gf_fclose(logfile);\n \tgf_sys_close();\n+\n+#ifdef GPAC_MEMORY_TRACKING\n+\tif (mem_track && (gf_memory_size() || gf_file_handles_count() )) {\n+\t\tgf_log_set_tool_level(GF_LOG_MEMORY, GF_LOG_INFO);\n+\t\tgf_memory_print();\n+\t}\n+#endif\n+\n \treturn ret_code;\n }\n \ndiff --git a/src/isomedia/box_code_adobe.c b/src/isomedia/box_code_adobe.c\nindex fe46191915..bb80f3ce89 100644\n--- a/src/isomedia/box_code_adobe.c\n+++ b/src/isomedia/box_code_adobe.c\n@@ -408,6 +408,7 @@ GF_Err afra_box_read(GF_Box *s, GF_BitStream *bs)\n \tfor (i=0; i<ptr->entry_count; i++) {\n \t\tGF_AfraEntry *ae = gf_malloc(sizeof(GF_AfraEntry));\n \t\tif (!ae) return GF_OUT_OF_MEM;\n+\t\tgf_list_insert(ptr->local_access_entries, ae, i);\n \n \t\tISOM_DECREASE_SIZE(ptr, 8)\n \t\tae->time = gf_bs_read_u64(bs);\n@@ -418,8 +419,6 @@ GF_Err afra_box_read(GF_Box *s, GF_BitStream *bs)\n \t\t\tISOM_DECREASE_SIZE(ptr, 4)\n \t\t\tae->offset = gf_bs_read_u32(bs);\n \t\t}\n-\n-\t\tgf_list_insert(ptr->local_access_entries, ae, i);\n \t}\n \n \tif (ptr->global_entries) {\n@@ -428,6 +427,8 @@ GF_Err afra_box_read(GF_Box *s, GF_BitStream *bs)\n \t\tfor (i=0; i<ptr->global_entry_count; i++) {\n \t\t\tGF_GlobalAfraEntry *ae = gf_malloc(sizeof(GF_GlobalAfraEntry));\n \t\t\tif (!ae) return GF_OUT_OF_MEM;\n+\t\t\tgf_list_insert(ptr->global_access_entries, ae, i);\n+\n \t\t\tISOM_DECREASE_SIZE(ptr, 8)\n \t\t\tae->time = gf_bs_read_u64(bs);\n \t\t\tif (ptr->long_ids) {\n@@ -448,8 +449,6 @@ GF_Err afra_box_read(GF_Box *s, GF_BitStream *bs)\n \t\t\t\tae->afra_offset = gf_bs_read_u32(bs);\n \t\t\t\tae->offset_from_afra = gf_bs_read_u32(bs);\n \t\t\t}\n-\n-\t\t\tgf_list_insert(ptr->global_access_entries, ae, i);\n \t\t}\n \t}\n \n"
        ],
        "func_after": []
    },
    {
        "idx": 196885,
        "project": "tensorflow",
        "commit_id": "9e62869465573cb2d9b5053f1fa02a81fce21d69",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/9e62869465573cb2d9b5053f1fa02a81fce21d69",
        "commit_message": "Add more validation to `RequantizationRangePerChannel`.\n\nPiperOrigin-RevId: 387693946\nChange-Id: Ife8dcbdb021bec4787eef6a4361dd08f17c14bd6",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor& input = ctx->input(kInputTensorIndex);\n    const Tensor& input_min = ctx->input(kInputMinIndex);\n    const Tensor& input_max = ctx->input(kInputMaxIndex);\n\n    const size_t depth = input_max.NumElements();\n    OP_REQUIRES(\n        ctx, input_min.dim_size(0) == depth,\n        errors::InvalidArgument(\"input_min has incorrect size, expected \",\n                                depth, \" was \", input_min.dim_size(0)));\n    OP_REQUIRES(\n        ctx, input_max.dim_size(0) == depth,\n        errors::InvalidArgument(\"input_max has incorrect size, expected \",\n                                depth, \" was \", input_max.dim_size(0)));\n\n    const float* input_min_data = input_min.flat<float>().data();\n    const float* input_max_data = input_max.flat<float>().data();\n    std::vector<float> ranges(depth);\n    bool is_non_negative = true;\n    Eigen::array<int, 2> shuffling({1, 0});\n    auto input_matrix = input.flat_inner_dims<qint32>();\n\n    // TODO: verify performance of not transposing and finding the min max\n    // directly from input_matrix vs the one presented below of transposing and\n    // using the transposed matrix as the transposing operation in itself might\n    // be more costly.\n    // Note that this operation is a calibration step for quantization and will\n    // cease to exist in the final inference graph(will exist as a const node).\n    auto transposed_input = input_matrix.shuffle(shuffling);\n\n    // Find the ranges of each channel in parallel.\n    float out_min_max = std::numeric_limits<float>::min();\n\n#ifdef ENABLE_ONEDNN_OPENMP\n#ifdef _MSC_VER\n#pragma omp parallel for\n#else\n#pragma omp parallel for reduction(max : out_min_max)\n#endif\n#endif  // ENABLE_ONEDNN_OPENMP\n    // TODO: Add eigen parallel_for\n    for (int64_t i = 0; i < depth; ++i) {\n      Eigen::Tensor<qint32, 0, Eigen::RowMajor> min =\n          transposed_input.chip<0>(i).minimum();\n      Eigen::Tensor<qint32, 0, Eigen::RowMajor> max =\n          transposed_input.chip<0>(i).maximum();\n      const int32_t min_per_channel = min();\n      const int32_t max_per_channel = max();\n      const int32_t abs_max =\n          std::max(std::abs(min_per_channel), std::abs(max_per_channel));\n      float scale =\n          std::max(std::abs(input_min_data[i]), std::abs(input_max_data[i]));\n      ranges[i] =\n          scale * static_cast<float>(abs_max) / static_cast<float>(1L << 31);\n      if (min_per_channel < 0) is_non_negative = false;\n\n      // Thread-local out_min_max.\n      out_min_max = std::max(out_min_max, ranges[i]);\n    }\n\n    // All local out_min_max gets max-reduced into one global out_min_max at\n    // the end of the loop by specifying reduction(max:out_min_max) along with\n    // omp parallel for.\n\n    // Fixing max to clip_value_max_ (example 6.0 to support relu6)\n    if (out_min_max > clip_value_max_) out_min_max = clip_value_max_;\n\n    Tensor* output_min = nullptr;\n    Tensor* output_max = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->allocate_output(kOutputMinIndex, {}, &output_min));\n    OP_REQUIRES_OK(ctx, ctx->allocate_output(kOutputMaxIndex, {}, &output_max));\n    output_min->flat<float>()(0) = is_non_negative ? 0.0f : -out_min_max;\n    output_max->flat<float>()(0) = out_min_max;\n  }",
        "func_hash": 260350269729869693096839937488434150493,
        "file_name": "mkl_requantization_range_per_channel_op.cc",
        "file_hash": 184757242449876370761844438653930390458,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2021-37665",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions due to incomplete validation in MKL implementation of requantization, an attacker can trigger undefined behavior via binding a reference to a null pointer or can access data outside the bounds of heap allocated arrays. The [implementation](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/core/kernels/mkl/mkl_requantization_range_per_channel_op.cc) does not validate the dimensions of the `input` tensor. A similar issue occurs in `MklRequantizePerChannelOp`. The [implementation](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/core/kernels/mkl/mkl_requantize_per_channel_op.cc) does not perform full validation for all the input arguments. We have patched the issue in GitHub commit 9e62869465573cb2d9b5053f1fa02a81fce21d69 and in the Github commit 203214568f5bc237603dbab6e1fd389f1572f5c9. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37665",
        "func_name": "Compute",
        "diff": [
            "diff --git a/tensorflow/core/kernels/mkl/mkl_requantization_range_per_channel_op.cc b/tensorflow/core/kernels/mkl/mkl_requantization_range_per_channel_op.cc\nindex 24dabb07ca067a..a38df2450d1942 100644\n--- a/tensorflow/core/kernels/mkl/mkl_requantization_range_per_channel_op.cc\n+++ b/tensorflow/core/kernels/mkl/mkl_requantization_range_per_channel_op.cc\n@@ -57,6 +57,20 @@ class MklRequantizationRangePerChannelOp : public OpKernel {\n         ctx, input_max.dim_size(0) == depth,\n         errors::InvalidArgument(\"input_max has incorrect size, expected \",\n                                 depth, \" was \", input_max.dim_size(0)));\n+    OP_REQUIRES(\n+        ctx, input_min.NumElements() == depth,\n+        errors::InvalidArgument(\"input_min must have the same number of \"\n+                                \"elements as input_max, got \",\n+                                input_min.NumElements(), \" and \", depth));\n+    OP_REQUIRES(ctx, input.NumElements() > 0,\n+                errors::InvalidArgument(\"input must not be empty\"));\n+    OP_REQUIRES(ctx, input.dims() == 4,\n+                errors::InvalidArgument(\"input must be in NHWC format\"));\n+    OP_REQUIRES(\n+        ctx, input.dim_size(3) == depth,\n+        errors::InvalidArgument(\n+            \"input must have same number of channels as length of input_min: \",\n+            input.dim_size(3), \" vs \", depth));\n \n     const float* input_min_data = input_min.flat<float>().data();\n     const float* input_max_data = input_max.flat<float>().data();\n"
        ],
        "func_after": []
    },
    {
        "idx": 195691,
        "project": "mruby",
        "commit_id": "a4d97934d51cb88954cc49161dc1d151f64afb6b",
        "project_url": "https://github.com/mruby/mruby",
        "commit_url": "https://github.com/mruby/mruby/commit/a4d97934d51cb88954cc49161dc1d151f64afb6b",
        "commit_message": "vm.c: check if target_class is NULL (when prepended).",
        "target": 1,
        "irrelevant": 0,
        "func_before": "mrb_vm_exec(mrb_state *mrb, const struct RProc *proc, const mrb_code *pc)\n{\n  /* mrb_assert(MRB_PROC_CFUNC_P(proc)) */\n  const mrb_irep *irep = proc->body.irep;\n  const mrb_pool_value *pool = irep->pool;\n  const mrb_sym *syms = irep->syms;\n  mrb_code insn;\n  int ai = mrb_gc_arena_save(mrb);\n  struct mrb_jmpbuf *prev_jmp = mrb->jmp;\n  struct mrb_jmpbuf c_jmp;\n  uint32_t a;\n  uint16_t b;\n  uint16_t c;\n  mrb_sym mid;\n  const struct mrb_irep_catch_handler *ch;\n\n#ifdef DIRECT_THREADED\n  static const void * const optable[] = {\n#define OPCODE(x,_) &&L_OP_ ## x,\n#include \"mruby/ops.h\"\n#undef OPCODE\n  };\n#endif\n\n  mrb_bool exc_catched = FALSE;\nRETRY_TRY_BLOCK:\n\n  MRB_TRY(&c_jmp) {\n\n  if (exc_catched) {\n    exc_catched = FALSE;\n    mrb_gc_arena_restore(mrb, ai);\n    if (mrb->exc && mrb->exc->tt == MRB_TT_BREAK)\n      goto L_BREAK;\n    goto L_RAISE;\n  }\n  mrb->jmp = &c_jmp;\n  mrb_vm_ci_proc_set(mrb->c->ci, proc);\n\n#define regs (mrb->c->ci->stack)\n  INIT_DISPATCH {\n    CASE(OP_NOP, Z) {\n      /* do nothing */\n      NEXT;\n    }\n\n    CASE(OP_MOVE, BB) {\n      regs[a] = regs[b];\n      NEXT;\n    }\n\n    CASE(OP_LOADL, BB) {\n      switch (pool[b].tt) {   /* number */\n      case IREP_TT_INT32:\n        regs[a] = mrb_int_value(mrb, (mrb_int)pool[b].u.i32);\n        break;\n      case IREP_TT_INT64:\n#if defined(MRB_INT64)\n        regs[a] = mrb_int_value(mrb, (mrb_int)pool[b].u.i64);\n        break;\n#else\n#if defined(MRB_64BIT)\n        if (INT32_MIN <= pool[b].u.i64 && pool[b].u.i64 <= INT32_MAX) {\n          regs[a] = mrb_int_value(mrb, (mrb_int)pool[b].u.i64);\n          break;\n        }\n#endif\n        goto L_INT_OVERFLOW;\n#endif\n      case IREP_TT_BIGINT:\n#ifdef MRB_USE_BIGINT\n        {\n          const char *s = pool[b].u.str;\n          regs[a] = mrb_bint_new_str(mrb, s+2, (mrb_int)s[0], (mrb_int)s[1]);\n        }\n        break;\n#else\n        goto L_INT_OVERFLOW;\n#endif\n#ifndef MRB_NO_FLOAT\n      case IREP_TT_FLOAT:\n        regs[a] = mrb_float_value(mrb, pool[b].u.f);\n        break;\n#endif\n      default:\n        /* should not happen (tt:string) */\n        regs[a] = mrb_nil_value();\n        break;\n      }\n      NEXT;\n    }\n\n    CASE(OP_LOADI, BB) {\n      SET_FIXNUM_VALUE(regs[a], b);\n      NEXT;\n    }\n\n    CASE(OP_LOADINEG, BB) {\n      SET_FIXNUM_VALUE(regs[a], -b);\n      NEXT;\n    }\n\n    CASE(OP_LOADI__1,B) goto L_LOADI;\n    CASE(OP_LOADI_0,B) goto L_LOADI;\n    CASE(OP_LOADI_1,B) goto L_LOADI;\n    CASE(OP_LOADI_2,B) goto L_LOADI;\n    CASE(OP_LOADI_3,B) goto L_LOADI;\n    CASE(OP_LOADI_4,B) goto L_LOADI;\n    CASE(OP_LOADI_5,B) goto L_LOADI;\n    CASE(OP_LOADI_6,B) goto L_LOADI;\n    CASE(OP_LOADI_7, B) {\n    L_LOADI:\n      SET_FIXNUM_VALUE(regs[a], (mrb_int)insn - (mrb_int)OP_LOADI_0);\n      NEXT;\n    }\n\n    CASE(OP_LOADI16, BS) {\n      SET_FIXNUM_VALUE(regs[a], (mrb_int)(int16_t)b);\n      NEXT;\n    }\n\n    CASE(OP_LOADI32, BSS) {\n      SET_INT_VALUE(mrb, regs[a], (int32_t)(((uint32_t)b<<16)+c));\n      NEXT;\n    }\n\n    CASE(OP_LOADSYM, BB) {\n      SET_SYM_VALUE(regs[a], syms[b]);\n      NEXT;\n    }\n\n    CASE(OP_LOADNIL, B) {\n      SET_NIL_VALUE(regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_LOADSELF, B) {\n      regs[a] = regs[0];\n      NEXT;\n    }\n\n    CASE(OP_LOADT, B) {\n      SET_TRUE_VALUE(regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_LOADF, B) {\n      SET_FALSE_VALUE(regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETGV, BB) {\n      mrb_value val = mrb_gv_get(mrb, syms[b]);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETGV, BB) {\n      mrb_gv_set(mrb, syms[b], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETSV, BB) {\n      mrb_value val = mrb_vm_special_get(mrb, syms[b]);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETSV, BB) {\n      mrb_vm_special_set(mrb, syms[b], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETIV, BB) {\n      regs[a] = mrb_iv_get(mrb, regs[0], syms[b]);\n      NEXT;\n    }\n\n    CASE(OP_SETIV, BB) {\n      mrb_iv_set(mrb, regs[0], syms[b], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETCV, BB) {\n      mrb_value val;\n      val = mrb_vm_cv_get(mrb, syms[b]);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETCV, BB) {\n      mrb_vm_cv_set(mrb, syms[b], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETIDX, B) {\n      mrb_value va = regs[a], vb = regs[a+1];\n      switch (mrb_type(va)) {\n      case MRB_TT_ARRAY:\n        if (!mrb_integer_p(vb)) goto getidx_fallback;\n        regs[a] = mrb_ary_entry(va, mrb_integer(vb));\n        break;\n      case MRB_TT_HASH:\n        va = mrb_hash_get(mrb, va, vb);\n        regs[a] = va;\n        break;\n      case MRB_TT_STRING:\n        switch (mrb_type(vb)) {\n        case MRB_TT_INTEGER:\n        case MRB_TT_STRING:\n        case MRB_TT_RANGE:\n          va = mrb_str_aref(mrb, va, vb, mrb_undef_value());\n          regs[a] = va;\n          break;\n        default:\n          goto getidx_fallback;\n        }\n        break;\n      default:\n      getidx_fallback:\n        mid = MRB_OPSYM(aref);\n        goto L_SEND_SYM;\n      }\n      NEXT;\n    }\n\n    CASE(OP_SETIDX, B) {\n      c = 2;\n      mid = MRB_OPSYM(aset);\n      SET_NIL_VALUE(regs[a+3]);\n      goto L_SENDB_SYM;\n    }\n\n    CASE(OP_GETCONST, BB) {\n      mrb_value v = mrb_vm_const_get(mrb, syms[b]);\n      regs[a] = v;\n      NEXT;\n    }\n\n    CASE(OP_SETCONST, BB) {\n      mrb_vm_const_set(mrb, syms[b], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETMCNST, BB) {\n      mrb_value v = mrb_const_get(mrb, regs[a], syms[b]);\n      regs[a] = v;\n      NEXT;\n    }\n\n    CASE(OP_SETMCNST, BB) {\n      mrb_const_set(mrb, regs[a+1], syms[b], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETUPVAR, BBB) {\n      mrb_value *regs_a = regs + a;\n      struct REnv *e = uvenv(mrb, c);\n\n      if (e && b < MRB_ENV_LEN(e)) {\n        *regs_a = e->stack[b];\n      }\n      else {\n        *regs_a = mrb_nil_value();\n      }\n      NEXT;\n    }\n\n    CASE(OP_SETUPVAR, BBB) {\n      struct REnv *e = uvenv(mrb, c);\n\n      if (e) {\n        mrb_value *regs_a = regs + a;\n\n        if (b < MRB_ENV_LEN(e)) {\n          e->stack[b] = *regs_a;\n          mrb_write_barrier(mrb, (struct RBasic*)e);\n        }\n      }\n      NEXT;\n    }\n\n    CASE(OP_JMP, S) {\n      pc += (int16_t)a;\n      JUMP;\n    }\n    CASE(OP_JMPIF, BS) {\n      if (mrb_test(regs[a])) {\n        pc += (int16_t)b;\n        JUMP;\n      }\n      NEXT;\n    }\n    CASE(OP_JMPNOT, BS) {\n      if (!mrb_test(regs[a])) {\n        pc += (int16_t)b;\n        JUMP;\n      }\n      NEXT;\n    }\n    CASE(OP_JMPNIL, BS) {\n      if (mrb_nil_p(regs[a])) {\n        pc += (int16_t)b;\n        JUMP;\n      }\n      NEXT;\n    }\n\n    CASE(OP_JMPUW, S) {\n      a = (uint32_t)((pc - irep->iseq) + (int16_t)a);\n      CHECKPOINT_RESTORE(RBREAK_TAG_JUMP) {\n        struct RBreak *brk = (struct RBreak*)mrb->exc;\n        mrb_value target = mrb_break_value_get(brk);\n        mrb_assert(mrb_integer_p(target));\n        a = (uint32_t)mrb_integer(target);\n        mrb_assert(a >= 0 && a < irep->ilen);\n      }\n      CHECKPOINT_MAIN(RBREAK_TAG_JUMP) {\n        ch = catch_handler_find(mrb, mrb->c->ci, pc, MRB_CATCH_FILTER_ENSURE);\n        if (ch) {\n          /* avoiding a jump from a catch handler into the same handler */\n          if (a < mrb_irep_catch_handler_unpack(ch->begin) || a >= mrb_irep_catch_handler_unpack(ch->end)) {\n            THROW_TAGGED_BREAK(mrb, RBREAK_TAG_JUMP, proc, mrb_fixnum_value(a));\n          }\n        }\n      }\n      CHECKPOINT_END(RBREAK_TAG_JUMP);\n\n      mrb->exc = NULL; /* clear break object */\n      pc = irep->iseq + a;\n      JUMP;\n    }\n\n    CASE(OP_EXCEPT, B) {\n      mrb_value exc;\n\n      if (mrb->exc == NULL) {\n        exc = mrb_nil_value();\n      }\n      else {\n        switch (mrb->exc->tt) {\n        case MRB_TT_BREAK:\n        case MRB_TT_EXCEPTION:\n          exc = mrb_obj_value(mrb->exc);\n          break;\n        default:\n          mrb_assert(!\"bad mrb_type\");\n          exc = mrb_nil_value();\n          break;\n        }\n        mrb->exc = NULL;\n      }\n      regs[a] = exc;\n      NEXT;\n    }\n    CASE(OP_RESCUE, BB) {\n      mrb_value exc = regs[a];  /* exc on stack */\n      mrb_value e = regs[b];\n      struct RClass *ec;\n\n      switch (mrb_type(e)) {\n      case MRB_TT_CLASS:\n      case MRB_TT_MODULE:\n        break;\n      default:\n        {\n          mrb_value exc;\n\n          exc = mrb_exc_new_lit(mrb, E_TYPE_ERROR,\n                                    \"class or module required for rescue clause\");\n          mrb_exc_set(mrb, exc);\n          goto L_RAISE;\n        }\n      }\n      ec = mrb_class_ptr(e);\n      regs[b] = mrb_bool_value(mrb_obj_is_kind_of(mrb, exc, ec));\n      NEXT;\n    }\n\n    CASE(OP_RAISEIF, B) {\n      mrb_value exc = regs[a];\n      if (mrb_break_p(exc)) {\n        mrb->exc = mrb_obj_ptr(exc);\n        goto L_BREAK;\n      }\n      mrb_exc_set(mrb, exc);\n      if (mrb->exc) {\n        goto L_RAISE;\n      }\n      NEXT;\n    }\n\n    CASE(OP_SSEND, BBB) {\n      regs[a] = regs[0];\n      insn = OP_SEND;\n    }\n    goto L_SENDB;\n\n    CASE(OP_SSENDB, BBB) {\n      regs[a] = regs[0];\n    }\n    goto L_SENDB;\n\n    CASE(OP_SEND, BBB)\n    goto L_SENDB;\n\n    L_SEND_SYM:\n    c = 1;\n    /* push nil after arguments */\n    SET_NIL_VALUE(regs[a+2]);\n    goto L_SENDB_SYM;\n\n    CASE(OP_SENDB, BBB)\n    L_SENDB:\n    mid = syms[b];\n    L_SENDB_SYM:\n    {\n      mrb_callinfo *ci = mrb->c->ci;\n      mrb_method_t m;\n      struct RClass *cls;\n      mrb_value recv, blk;\n\n      ARGUMENT_NORMALIZE(a, &c, insn);\n\n      recv = regs[a];\n      cls = mrb_class(mrb, recv);\n      m = mrb_method_search_vm(mrb, &cls, mid);\n      if (MRB_METHOD_UNDEF_P(m)) {\n        m = prepare_missing(mrb, recv, mid, &cls, a, &c, blk, 0);\n        mid = MRB_SYM(method_missing);\n      }\n\n      /* push callinfo */\n      ci = cipush(mrb, a, 0, cls, NULL, mid, c);\n\n      if (MRB_METHOD_CFUNC_P(m)) {\n        if (MRB_METHOD_PROC_P(m)) {\n          struct RProc *p = MRB_METHOD_PROC(m);\n\n          mrb_vm_ci_proc_set(ci, p);\n          recv = p->body.func(mrb, recv);\n        }\n        else {\n          if (MRB_METHOD_NOARG_P(m)) {\n            check_method_noarg(mrb, ci);\n          }\n          recv = MRB_METHOD_FUNC(m)(mrb, recv);\n        }\n        mrb_gc_arena_shrink(mrb, ai);\n        if (mrb->exc) goto L_RAISE;\n        ci = mrb->c->ci;\n        if (mrb_proc_p(blk)) {\n          struct RProc *p = mrb_proc_ptr(blk);\n          if (p && !MRB_PROC_STRICT_P(p) && MRB_PROC_ENV(p) == mrb_vm_ci_env(&ci[-1])) {\n            p->flags |= MRB_PROC_ORPHAN;\n          }\n        }\n        if (!ci->u.target_class) { /* return from context modifying method (resume/yield) */\n          if (ci->cci == CINFO_RESUMED) {\n            mrb->jmp = prev_jmp;\n            return recv;\n          }\n          else {\n            mrb_assert(!MRB_PROC_CFUNC_P(ci[-1].proc));\n            proc = ci[-1].proc;\n            irep = proc->body.irep;\n            pool = irep->pool;\n            syms = irep->syms;\n          }\n        }\n        ci->stack[0] = recv;\n        /* pop stackpos */\n        ci = cipop(mrb);\n        pc = ci->pc;\n      }\n      else {\n        /* setup environment for calling method */\n        mrb_vm_ci_proc_set(ci, (proc = MRB_METHOD_PROC(m)));\n        irep = proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n        mrb_stack_extend(mrb, (irep->nregs < 4) ? 4 : irep->nregs);\n        pc = irep->iseq;\n      }\n    }\n    JUMP;\n\n    CASE(OP_CALL, Z) {\n      mrb_callinfo *ci = mrb->c->ci;\n      mrb_value recv = ci->stack[0];\n      struct RProc *m = mrb_proc_ptr(recv);\n\n      /* replace callinfo */\n      ci->u.target_class = MRB_PROC_TARGET_CLASS(m);\n      mrb_vm_ci_proc_set(ci, m);\n      if (MRB_PROC_ENV_P(m)) {\n        ci->mid = MRB_PROC_ENV(m)->mid;\n      }\n\n      /* prepare stack */\n      if (MRB_PROC_CFUNC_P(m)) {\n        recv = MRB_PROC_CFUNC(m)(mrb, recv);\n        mrb_gc_arena_shrink(mrb, ai);\n        if (mrb->exc) goto L_RAISE;\n        /* pop stackpos */\n        ci = cipop(mrb);\n        pc = ci->pc;\n        ci[1].stack[0] = recv;\n        irep = mrb->c->ci->proc->body.irep;\n      }\n      else {\n        /* setup environment for calling method */\n        proc = m;\n        irep = m->body.irep;\n        if (!irep) {\n          mrb->c->ci->stack[0] = mrb_nil_value();\n          a = 0;\n          c = OP_R_NORMAL;\n          goto L_OP_RETURN_BODY;\n        }\n        mrb_int nargs = mrb_ci_bidx(ci)+1;\n        if (nargs < irep->nregs) {\n          mrb_stack_extend(mrb, irep->nregs);\n          stack_clear(regs+nargs, irep->nregs-nargs);\n        }\n        if (MRB_PROC_ENV_P(m)) {\n          regs[0] = MRB_PROC_ENV(m)->stack[0];\n        }\n        pc = irep->iseq;\n      }\n      pool = irep->pool;\n      syms = irep->syms;\n      JUMP;\n    }\n\n    CASE(OP_SUPER, BB) {\n      mrb_method_t m;\n      struct RClass *cls;\n      mrb_callinfo *ci = mrb->c->ci;\n      mrb_value recv, blk;\n      const struct RProc *p = ci->proc;\n      mrb_sym mid = ci->mid;\n      struct RClass* target_class = MRB_PROC_TARGET_CLASS(p);\n\n      if (MRB_PROC_ENV_P(p) && p->e.env->mid && p->e.env->mid != mid) { /* alias support */\n        mid = p->e.env->mid;    /* restore old mid */\n      }\n\n      if (mid == 0 || !target_class) {\n        mrb_value exc = mrb_exc_new_lit(mrb, E_NOMETHOD_ERROR, \"super called outside of method\");\n        mrb_exc_set(mrb, exc);\n        goto L_RAISE;\n      }\n      if (target_class->flags & MRB_FL_CLASS_IS_PREPENDED) {\n        target_class = mrb_vm_ci_target_class(ci);\n      }\n      else if (target_class->tt == MRB_TT_MODULE) {\n        target_class = mrb_vm_ci_target_class(ci);\n        if (!target_class || target_class->tt != MRB_TT_ICLASS) {\n          goto super_typeerror;\n        }\n      }\n      recv = regs[0];\n      if (!mrb_obj_is_kind_of(mrb, recv, target_class)) {\n      super_typeerror: ;\n        mrb_value exc = mrb_exc_new_lit(mrb, E_TYPE_ERROR,\n                                            \"self has wrong type to call super in this context\");\n        mrb_exc_set(mrb, exc);\n        goto L_RAISE;\n      }\n\n      ARGUMENT_NORMALIZE(a, &b, OP_SUPER);\n\n      cls = target_class->super;\n      m = mrb_method_search_vm(mrb, &cls, mid);\n      if (MRB_METHOD_UNDEF_P(m)) {\n        m = prepare_missing(mrb, recv, mid, &cls, a, &b, blk, 1);\n        mid = MRB_SYM(method_missing);\n      }\n\n      /* push callinfo */\n      ci = cipush(mrb, a, 0, cls, NULL, mid, b);\n\n      /* prepare stack */\n      ci->stack[0] = recv;\n\n      if (MRB_METHOD_CFUNC_P(m)) {\n        mrb_value v;\n\n        if (MRB_METHOD_PROC_P(m)) {\n          mrb_vm_ci_proc_set(ci, MRB_METHOD_PROC(m));\n        }\n        v = MRB_METHOD_CFUNC(m)(mrb, recv);\n        mrb_gc_arena_restore(mrb, ai);\n        if (mrb->exc) goto L_RAISE;\n        ci = mrb->c->ci;\n        mrb_assert(!mrb_break_p(v));\n        if (!mrb_vm_ci_target_class(ci)) { /* return from context modifying method (resume/yield) */\n          if (ci->cci == CINFO_RESUMED) {\n            mrb->jmp = prev_jmp;\n            return v;\n          }\n          else {\n            mrb_assert(!MRB_PROC_CFUNC_P(ci[-1].proc));\n            proc = ci[-1].proc;\n            irep = proc->body.irep;\n            pool = irep->pool;\n            syms = irep->syms;\n          }\n        }\n        mrb->c->ci->stack[0] = v;\n        ci = cipop(mrb);\n        pc = ci->pc;\n      }\n      else {\n        /* setup environment for calling method */\n        mrb_vm_ci_proc_set(ci, (proc = MRB_METHOD_PROC(m)));\n        irep = proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n        mrb_stack_extend(mrb, (irep->nregs < 4) ? 4 : irep->nregs);\n        pc = irep->iseq;\n      }\n      JUMP;\n    }\n\n    CASE(OP_ARGARY, BS) {\n      mrb_int m1 = (b>>11)&0x3f;\n      mrb_int r  = (b>>10)&0x1;\n      mrb_int m2 = (b>>5)&0x1f;\n      mrb_int kd = (b>>4)&0x1;\n      mrb_int lv = (b>>0)&0xf;\n      mrb_value *stack;\n\n      if (mrb->c->ci->mid == 0 || mrb_vm_ci_target_class(mrb->c->ci) == NULL) {\n        mrb_value exc;\n\n      L_NOSUPER:\n        exc = mrb_exc_new_lit(mrb, E_NOMETHOD_ERROR, \"super called outside of method\");\n        mrb_exc_set(mrb, exc);\n        goto L_RAISE;\n      }\n      if (lv == 0) stack = regs + 1;\n      else {\n        struct REnv *e = uvenv(mrb, lv-1);\n        if (!e) goto L_NOSUPER;\n        if (MRB_ENV_LEN(e) <= m1+r+m2+1)\n          goto L_NOSUPER;\n        stack = e->stack + 1;\n      }\n      if (r == 0) {\n        regs[a] = mrb_ary_new_from_values(mrb, m1+m2, stack);\n      }\n      else {\n        mrb_value *pp = NULL;\n        struct RArray *rest;\n        mrb_int len = 0;\n\n        if (mrb_array_p(stack[m1])) {\n          struct RArray *ary = mrb_ary_ptr(stack[m1]);\n\n          pp = ARY_PTR(ary);\n          len = ARY_LEN(ary);\n        }\n        regs[a] = mrb_ary_new_capa(mrb, m1+len+m2);\n        rest = mrb_ary_ptr(regs[a]);\n        if (m1 > 0) {\n          stack_copy(ARY_PTR(rest), stack, m1);\n        }\n        if (len > 0) {\n          stack_copy(ARY_PTR(rest)+m1, pp, len);\n        }\n        if (m2 > 0) {\n          stack_copy(ARY_PTR(rest)+m1+len, stack+m1+1, m2);\n        }\n        ARY_SET_LEN(rest, m1+len+m2);\n      }\n      if (kd) {\n        regs[a+1] = stack[m1+r+m2];\n        regs[a+2] = stack[m1+r+m2+1];\n      }\n      else {\n        regs[a+1] = stack[m1+r+m2];\n      }\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_ENTER, W) {\n      mrb_int m1 = MRB_ASPEC_REQ(a);\n      mrb_int o  = MRB_ASPEC_OPT(a);\n      mrb_int r  = MRB_ASPEC_REST(a);\n      mrb_int m2 = MRB_ASPEC_POST(a);\n      mrb_int kd = (MRB_ASPEC_KEY(a) > 0 || MRB_ASPEC_KDICT(a))? 1 : 0;\n      /* unused\n      int b  = MRB_ASPEC_BLOCK(a);\n      */\n      mrb_int const len = m1 + o + r + m2;\n\n      mrb_callinfo *ci = mrb->c->ci;\n      mrb_int argc = ci->n;\n      mrb_value *argv = regs+1;\n      mrb_value * const argv0 = argv;\n      mrb_int const kw_pos = len + kd;    /* where kwhash should be */\n      mrb_int const blk_pos = kw_pos + 1; /* where block should be */\n      mrb_value blk = regs[mrb_ci_bidx(ci)];\n      mrb_value kdict = mrb_nil_value();\n\n      /* keyword arguments */\n      if (ci->nk > 0) {\n        mrb_int kidx = mrb_ci_kidx(ci);\n        kdict = regs[kidx];\n        if (!mrb_hash_p(kdict) || mrb_hash_size(mrb, kdict) == 0) {\n          kdict = mrb_nil_value();\n          ci->nk = 0;\n        }\n      }\n      if (!kd && !mrb_nil_p(kdict)) {\n        if (argc < 14) {\n          ci->n++;\n          argc++;    /* include kdict in normal arguments */\n        }\n        else if (argc == 14) {\n          /* pack arguments and kdict */\n          regs[1] = mrb_ary_new_from_values(mrb, argc+1, &regs[1]);\n          argc = ci->n = 15;\n        }\n        else {/* argc == 15 */\n          /* push kdict to packed arguments */\n          mrb_ary_push(mrb, regs[1], regs[2]);\n        }\n        ci->nk = 0;\n      }\n      if (kd && MRB_ASPEC_KEY(a) > 0 && mrb_hash_p(kdict)) {\n        kdict = mrb_hash_dup(mrb, kdict);\n      }\n\n      /* arguments is passed with Array */\n      if (argc == 15) {\n        struct RArray *ary = mrb_ary_ptr(regs[1]);\n        argv = ARY_PTR(ary);\n        argc = (int)ARY_LEN(ary);\n        mrb_gc_protect(mrb, regs[1]);\n      }\n\n      /* strict argument check */\n      if (ci->proc && MRB_PROC_STRICT_P(ci->proc)) {\n        if (argc < m1 + m2 || (r == 0 && argc > len)) {\n          argnum_error(mrb, m1+m2);\n          goto L_RAISE;\n        }\n      }\n      /* extract first argument array to arguments */\n      else if (len > 1 && argc == 1 && mrb_array_p(argv[0])) {\n        mrb_gc_protect(mrb, argv[0]);\n        argc = (int)RARRAY_LEN(argv[0]);\n        argv = RARRAY_PTR(argv[0]);\n      }\n\n      /* rest arguments */\n      mrb_value rest = mrb_nil_value();\n      if (argc < len) {\n        mrb_int mlen = m2;\n        if (argc < m1+m2) {\n          mlen = m1 < argc ? argc - m1 : 0;\n        }\n\n        /* copy mandatory and optional arguments */\n        if (argv0 != argv && argv) {\n          value_move(&regs[1], argv, argc-mlen); /* m1 + o */\n        }\n        if (argc < m1) {\n          stack_clear(&regs[argc+1], m1-argc);\n        }\n        /* copy post mandatory arguments */\n        if (mlen) {\n          value_move(&regs[len-m2+1], &argv[argc-mlen], mlen);\n        }\n        if (mlen < m2) {\n          stack_clear(&regs[len-m2+mlen+1], m2-mlen);\n        }\n        /* initialize rest arguments with empty Array */\n        if (r) {\n          rest = mrb_ary_new_capa(mrb, 0);\n          regs[m1+o+1] = rest;\n        }\n        /* skip initializer of passed arguments */\n        if (o > 0 && argc > m1+m2)\n          pc += (argc - m1 - m2)*3;\n      }\n      else {\n        mrb_int rnum = 0;\n        if (argv0 != argv) {\n          value_move(&regs[1], argv, m1+o);\n        }\n        if (r) {\n          rnum = argc-m1-o-m2;\n          rest = mrb_ary_new_from_values(mrb, rnum, argv+m1+o);\n          regs[m1+o+1] = rest;\n        }\n        if (m2 > 0 && argc-m2 > m1) {\n          value_move(&regs[m1+o+r+1], &argv[m1+o+rnum], m2);\n        }\n        pc += o*3;\n      }\n\n      /* need to be update blk first to protect blk from GC */\n      regs[blk_pos] = blk;              /* move block */\n      if (kd) {\n        if (mrb_nil_p(kdict))\n          kdict = mrb_hash_new_capa(mrb, 0);\n        regs[kw_pos] = kdict;           /* set kwhash */\n      }\n\n      /* format arguments for generated code */\n      mrb->c->ci->n = (uint8_t)len;\n\n      /* clear local (but non-argument) variables */\n      if (irep->nlocals-blk_pos-1 > 0) {\n        stack_clear(&regs[blk_pos+1], irep->nlocals-blk_pos-1);\n      }\n      JUMP;\n    }\n\n    CASE(OP_KARG, BB) {\n      mrb_value k = mrb_symbol_value(syms[b]);\n      mrb_int kidx = mrb_ci_kidx(mrb->c->ci);\n      mrb_value kdict, v;\n\n      if (kidx < 0 || !mrb_hash_p(kdict=regs[kidx]) || !mrb_hash_key_p(mrb, kdict, k)) {\n        mrb_value str = mrb_format(mrb, \"missing keyword: %v\", k);\n        mrb_exc_set(mrb, mrb_exc_new_str(mrb, E_ARGUMENT_ERROR, str));\n        goto L_RAISE;\n      }\n      v = mrb_hash_get(mrb, kdict, k);\n      regs[a] = v;\n      mrb_hash_delete_key(mrb, kdict, k);\n      NEXT;\n    }\n\n    CASE(OP_KEY_P, BB) {\n      mrb_value k = mrb_symbol_value(syms[b]);\n      mrb_int kidx = mrb_ci_kidx(mrb->c->ci);\n      mrb_value kdict;\n      mrb_bool key_p = FALSE;\n\n      if (kidx >= 0 && mrb_hash_p(kdict=regs[kidx])) {\n        key_p = mrb_hash_key_p(mrb, kdict, k);\n      }\n      regs[a] = mrb_bool_value(key_p);\n      NEXT;\n    }\n\n    CASE(OP_KEYEND, Z) {\n      mrb_int kidx = mrb_ci_kidx(mrb->c->ci);\n      mrb_value kdict;\n\n      if (kidx >= 0 && mrb_hash_p(kdict=regs[kidx]) && !mrb_hash_empty_p(mrb, kdict)) {\n        mrb_value keys = mrb_hash_keys(mrb, kdict);\n        mrb_value key1 = RARRAY_PTR(keys)[0];\n        mrb_value str = mrb_format(mrb, \"unknown keyword: %v\", key1);\n        mrb_exc_set(mrb, mrb_exc_new_str(mrb, E_ARGUMENT_ERROR, str));\n        goto L_RAISE;\n      }\n      NEXT;\n    }\n\n    CASE(OP_BREAK, B) {\n      c = OP_R_BREAK;\n      goto L_RETURN;\n    }\n    CASE(OP_RETURN_BLK, B) {\n      c = OP_R_RETURN;\n      goto L_RETURN;\n    }\n    CASE(OP_RETURN, B)\n    c = OP_R_NORMAL;\n    L_RETURN:\n    {\n      mrb_callinfo *ci;\n\n      ci = mrb->c->ci;\n      if (ci->mid) {\n        mrb_value blk = regs[mrb_ci_bidx(ci)];\n\n        if (mrb_proc_p(blk)) {\n          struct RProc *p = mrb_proc_ptr(blk);\n\n          if (!MRB_PROC_STRICT_P(p) &&\n              ci > mrb->c->cibase && MRB_PROC_ENV(p) == mrb_vm_ci_env(&ci[-1])) {\n            p->flags |= MRB_PROC_ORPHAN;\n          }\n        }\n      }\n\n      if (mrb->exc) {\n      L_RAISE:\n        ci = mrb->c->ci;\n        if (ci == mrb->c->cibase) {\n          ch = catch_handler_find(mrb, ci, pc, MRB_CATCH_FILTER_ALL);\n          if (ch == NULL) goto L_FTOP;\n          goto L_CATCH;\n        }\n        while ((ch = catch_handler_find(mrb, ci, pc, MRB_CATCH_FILTER_ALL)) == NULL) {\n          ci = cipop(mrb);\n          if (ci[1].cci == CINFO_SKIP && prev_jmp) {\n            mrb->jmp = prev_jmp;\n            MRB_THROW(prev_jmp);\n          }\n          pc = ci[0].pc;\n          if (ci == mrb->c->cibase) {\n            ch = catch_handler_find(mrb, ci, pc, MRB_CATCH_FILTER_ALL);\n            if (ch == NULL) {\n            L_FTOP:             /* fiber top */\n              if (mrb->c == mrb->root_c) {\n                mrb->c->ci->stack = mrb->c->stbase;\n                goto L_STOP;\n              }\n              else {\n                struct mrb_context *c = mrb->c;\n\n                c->status = MRB_FIBER_TERMINATED;\n                mrb->c = c->prev;\n                c->prev = NULL;\n                goto L_RAISE;\n              }\n            }\n            break;\n          }\n        }\n      L_CATCH:\n        if (ch == NULL) goto L_STOP;\n        if (FALSE) {\n        L_CATCH_TAGGED_BREAK: /* from THROW_TAGGED_BREAK() or UNWIND_ENSURE() */\n          ci = mrb->c->ci;\n        }\n        proc = ci->proc;\n        irep = proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n        mrb_stack_extend(mrb, irep->nregs);\n        pc = irep->iseq + mrb_irep_catch_handler_unpack(ch->target);\n      }\n      else {\n        mrb_int acc;\n        mrb_value v;\n\n        ci = mrb->c->ci;\n        v = regs[a];\n        mrb_gc_protect(mrb, v);\n        switch (c) {\n        case OP_R_RETURN:\n          /* Fall through to OP_R_NORMAL otherwise */\n          if (ci->cci == CINFO_NONE && MRB_PROC_ENV_P(proc) && !MRB_PROC_STRICT_P(proc)) {\n            const struct RProc *dst;\n            mrb_callinfo *cibase;\n            cibase = mrb->c->cibase;\n            dst = top_proc(mrb, proc);\n\n            if (MRB_PROC_ENV_P(dst)) {\n              struct REnv *e = MRB_PROC_ENV(dst);\n\n              if (!MRB_ENV_ONSTACK_P(e) || (e->cxt && e->cxt != mrb->c)) {\n                localjump_error(mrb, LOCALJUMP_ERROR_RETURN);\n                goto L_RAISE;\n              }\n            }\n            /* check jump destination */\n            while (cibase <= ci && ci->proc != dst) {\n              if (ci->cci > CINFO_NONE) { /* jump cross C boundary */\n                localjump_error(mrb, LOCALJUMP_ERROR_RETURN);\n                goto L_RAISE;\n              }\n              ci--;\n            }\n            if (ci <= cibase) { /* no jump destination */\n              localjump_error(mrb, LOCALJUMP_ERROR_RETURN);\n              goto L_RAISE;\n            }\n            ci = mrb->c->ci;\n            while (cibase <= ci && ci->proc != dst) {\n              CHECKPOINT_RESTORE(RBREAK_TAG_RETURN_BLOCK) {\n                cibase = mrb->c->cibase;\n                dst = top_proc(mrb, proc);\n              }\n              CHECKPOINT_MAIN(RBREAK_TAG_RETURN_BLOCK) {\n                UNWIND_ENSURE(mrb, ci, pc, RBREAK_TAG_RETURN_BLOCK, proc, v);\n              }\n              CHECKPOINT_END(RBREAK_TAG_RETURN_BLOCK);\n              ci = cipop(mrb);\n              pc = ci->pc;\n            }\n            proc = ci->proc;\n            mrb->exc = NULL; /* clear break object */\n            break;\n          }\n          /* fallthrough */\n        case OP_R_NORMAL:\n        NORMAL_RETURN:\n          if (ci == mrb->c->cibase) {\n            struct mrb_context *c;\n            c = mrb->c;\n\n            if (!c->prev) { /* toplevel return */\n              regs[irep->nlocals] = v;\n              goto CHECKPOINT_LABEL_MAKE(RBREAK_TAG_STOP);\n            }\n            if (!c->vmexec && c->prev->ci == c->prev->cibase) {\n              mrb_value exc = mrb_exc_new_lit(mrb, E_FIBER_ERROR, \"double resume\");\n              mrb_exc_set(mrb, exc);\n              goto L_RAISE;\n            }\n            CHECKPOINT_RESTORE(RBREAK_TAG_RETURN_TOPLEVEL) {\n              c = mrb->c;\n            }\n            CHECKPOINT_MAIN(RBREAK_TAG_RETURN_TOPLEVEL) {\n              UNWIND_ENSURE(mrb, ci, pc, RBREAK_TAG_RETURN_TOPLEVEL, proc, v);\n            }\n            CHECKPOINT_END(RBREAK_TAG_RETURN_TOPLEVEL);\n            /* automatic yield at the end */\n            c->status = MRB_FIBER_TERMINATED;\n            mrb->c = c->prev;\n            mrb->c->status = MRB_FIBER_RUNNING;\n            c->prev = NULL;\n            if (c->vmexec) {\n              mrb_gc_arena_restore(mrb, ai);\n              c->vmexec = FALSE;\n              mrb->jmp = prev_jmp;\n              return v;\n            }\n            ci = mrb->c->ci;\n          }\n          CHECKPOINT_RESTORE(RBREAK_TAG_RETURN) {\n            /* do nothing */\n          }\n          CHECKPOINT_MAIN(RBREAK_TAG_RETURN) {\n            UNWIND_ENSURE(mrb, ci, pc, RBREAK_TAG_RETURN, proc, v);\n          }\n          CHECKPOINT_END(RBREAK_TAG_RETURN);\n          mrb->exc = NULL; /* clear break object */\n          break;\n        case OP_R_BREAK:\n          if (MRB_PROC_STRICT_P(proc)) goto NORMAL_RETURN;\n          if (MRB_PROC_ORPHAN_P(proc)) {\n            mrb_value exc;\n\n          L_BREAK_ERROR:\n            exc = mrb_exc_new_lit(mrb, E_LOCALJUMP_ERROR,\n                                      \"break from proc-closure\");\n            mrb_exc_set(mrb, exc);\n            goto L_RAISE;\n          }\n          if (!MRB_PROC_ENV_P(proc) || !MRB_ENV_ONSTACK_P(MRB_PROC_ENV(proc))) {\n            goto L_BREAK_ERROR;\n          }\n          else {\n            struct REnv *e = MRB_PROC_ENV(proc);\n\n            if (e->cxt != mrb->c) {\n              goto L_BREAK_ERROR;\n            }\n          }\n          CHECKPOINT_RESTORE(RBREAK_TAG_BREAK) {\n            /* do nothing */\n          }\n          CHECKPOINT_MAIN(RBREAK_TAG_BREAK) {\n            UNWIND_ENSURE(mrb, ci, pc, RBREAK_TAG_BREAK, proc, v);\n          }\n          CHECKPOINT_END(RBREAK_TAG_BREAK);\n          /* break from fiber block */\n          if (ci == mrb->c->cibase && ci->pc) {\n            struct mrb_context *c = mrb->c;\n\n            mrb->c = c->prev;\n            c->prev = NULL;\n            ci = mrb->c->ci;\n          }\n          if (ci->cci > CINFO_NONE) {\n            ci = cipop(mrb);\n            mrb->exc = (struct RObject*)break_new(mrb, RBREAK_TAG_BREAK, proc, v);\n            mrb_gc_arena_restore(mrb, ai);\n            mrb->c->vmexec = FALSE;\n            mrb->jmp = prev_jmp;\n            MRB_THROW(prev_jmp);\n          }\n          if (FALSE) {\n            struct RBreak *brk;\n\n          L_BREAK:\n            brk = (struct RBreak*)mrb->exc;\n            proc = mrb_break_proc_get(brk);\n            v = mrb_break_value_get(brk);\n            ci = mrb->c->ci;\n\n            switch (mrb_break_tag_get(brk)) {\n#define DISPATCH_CHECKPOINTS(n, i) case n: goto CHECKPOINT_LABEL_MAKE(n);\n              RBREAK_TAG_FOREACH(DISPATCH_CHECKPOINTS)\n#undef DISPATCH_CHECKPOINTS\n              default:\n                mrb_assert(!\"wrong break tag\");\n            }\n          }\n          while (mrb->c->cibase < ci && ci[-1].proc != proc->upper) {\n            if (ci[-1].cci == CINFO_SKIP) {\n              goto L_BREAK_ERROR;\n            }\n            CHECKPOINT_RESTORE(RBREAK_TAG_BREAK_UPPER) {\n              /* do nothing */\n            }\n            CHECKPOINT_MAIN(RBREAK_TAG_BREAK_UPPER) {\n              UNWIND_ENSURE(mrb, ci, pc, RBREAK_TAG_BREAK_UPPER, proc, v);\n            }\n            CHECKPOINT_END(RBREAK_TAG_BREAK_UPPER);\n            ci = cipop(mrb);\n            pc = ci->pc;\n          }\n          CHECKPOINT_RESTORE(RBREAK_TAG_BREAK_INTARGET) {\n            /* do nothing */\n          }\n          CHECKPOINT_MAIN(RBREAK_TAG_BREAK_INTARGET) {\n            UNWIND_ENSURE(mrb, ci, pc, RBREAK_TAG_BREAK_INTARGET, proc, v);\n          }\n          CHECKPOINT_END(RBREAK_TAG_BREAK_INTARGET);\n          if (ci == mrb->c->cibase) {\n            goto L_BREAK_ERROR;\n          }\n          mrb->exc = NULL; /* clear break object */\n          break;\n        default:\n          /* cannot happen */\n          break;\n        }\n        mrb_assert(ci == mrb->c->ci);\n        mrb_assert(mrb->exc == NULL);\n\n        if (mrb->c->vmexec && !mrb_vm_ci_target_class(ci)) {\n          mrb_gc_arena_restore(mrb, ai);\n          mrb->c->vmexec = FALSE;\n          mrb->jmp = prev_jmp;\n          return v;\n        }\n        acc = ci->cci;\n        ci = cipop(mrb);\n        if (acc == CINFO_SKIP || acc == CINFO_DIRECT) {\n          mrb_gc_arena_restore(mrb, ai);\n          mrb->jmp = prev_jmp;\n          return v;\n        }\n        pc = ci->pc;\n        DEBUG(fprintf(stderr, \"from :%s\\n\", mrb_sym_name(mrb, ci->mid)));\n        proc = ci->proc;\n        irep = proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n\n        ci[1].stack[0] = v;\n        mrb_gc_arena_restore(mrb, ai);\n      }\n      JUMP;\n    }\n\n    CASE(OP_BLKPUSH, BS) {\n      int m1 = (b>>11)&0x3f;\n      int r  = (b>>10)&0x1;\n      int m2 = (b>>5)&0x1f;\n      int kd = (b>>4)&0x1;\n      int lv = (b>>0)&0xf;\n      mrb_value *stack;\n\n      if (lv == 0) stack = regs + 1;\n      else {\n        struct REnv *e = uvenv(mrb, lv-1);\n        if (!e || (!MRB_ENV_ONSTACK_P(e) && e->mid == 0) ||\n            MRB_ENV_LEN(e) <= m1+r+m2+1) {\n          localjump_error(mrb, LOCALJUMP_ERROR_YIELD);\n          goto L_RAISE;\n        }\n        stack = e->stack + 1;\n      }\n      if (mrb_nil_p(stack[m1+r+m2+kd])) {\n        localjump_error(mrb, LOCALJUMP_ERROR_YIELD);\n        goto L_RAISE;\n      }\n      regs[a] = stack[m1+r+m2+kd];\n      NEXT;\n    }\n\n#if !defined(MRB_USE_BIGINT) || defined(MRB_INT32)\n  L_INT_OVERFLOW:\n    {\n      mrb_value exc = mrb_exc_new_lit(mrb, E_RANGE_ERROR, \"integer overflow\");\n      mrb_exc_set(mrb, exc);\n    }\n    goto L_RAISE;\n#endif\n\n#define TYPES2(a,b) ((((uint16_t)(a))<<8)|(((uint16_t)(b))&0xff))\n#define OP_MATH(op_name)                                                    \\\n  /* need to check if op is overridden */                                   \\\n  switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {                  \\\n    OP_MATH_CASE_INTEGER(op_name);                                          \\\n    OP_MATH_CASE_FLOAT(op_name, integer, float);                            \\\n    OP_MATH_CASE_FLOAT(op_name, float,  integer);                           \\\n    OP_MATH_CASE_FLOAT(op_name, float,  float);                             \\\n    OP_MATH_CASE_STRING_##op_name();                                        \\\n    default:                                                                \\\n      mid = MRB_OPSYM(op_name);                                             \\\n      goto L_SEND_SYM;                                                      \\\n  }                                                                         \\\n  NEXT;\n#define OP_MATH_CASE_INTEGER(op_name)                                       \\\n  case TYPES2(MRB_TT_INTEGER, MRB_TT_INTEGER):                              \\\n    {                                                                       \\\n      mrb_int x = mrb_integer(regs[a]), y = mrb_integer(regs[a+1]), z;      \\\n      if (mrb_int_##op_name##_overflow(x, y, &z)) {                         \\\n        OP_MATH_OVERFLOW_INT(op_name,x,y);                                  \\\n      }                                                                     \\\n      else                                                                  \\\n        SET_INT_VALUE(mrb,regs[a], z);                                      \\\n    }                                                                       \\\n    break\n#ifdef MRB_NO_FLOAT\n#define OP_MATH_CASE_FLOAT(op_name, t1, t2) (void)0\n#else\n#define OP_MATH_CASE_FLOAT(op_name, t1, t2)                                     \\\n  case TYPES2(OP_MATH_TT_##t1, OP_MATH_TT_##t2):                                \\\n    {                                                                           \\\n      mrb_float z = mrb_##t1(regs[a]) OP_MATH_OP_##op_name mrb_##t2(regs[a+1]); \\\n      SET_FLOAT_VALUE(mrb, regs[a], z);                                         \\\n    }                                                                           \\\n    break\n#endif\n#ifdef MRB_USE_BIGINT\n#define OP_MATH_OVERFLOW_INT(op,x,y) regs[a] = mrb_bint_##op##_ii(mrb,x,y)\n#else\n#define OP_MATH_OVERFLOW_INT(op,x,y) goto L_INT_OVERFLOW\n#endif\n#define OP_MATH_CASE_STRING_add()                                           \\\n  case TYPES2(MRB_TT_STRING, MRB_TT_STRING):                                \\\n    regs[a] = mrb_str_plus(mrb, regs[a], regs[a+1]);                        \\\n    mrb_gc_arena_restore(mrb, ai);                                          \\\n    break\n#define OP_MATH_CASE_STRING_sub() (void)0\n#define OP_MATH_CASE_STRING_mul() (void)0\n#define OP_MATH_OP_add +\n#define OP_MATH_OP_sub -\n#define OP_MATH_OP_mul *\n#define OP_MATH_TT_integer MRB_TT_INTEGER\n#define OP_MATH_TT_float   MRB_TT_FLOAT\n\n    CASE(OP_ADD, B) {\n      OP_MATH(add);\n    }\n\n    CASE(OP_SUB, B) {\n      OP_MATH(sub);\n    }\n\n    CASE(OP_MUL, B) {\n      OP_MATH(mul);\n    }\n\n    CASE(OP_DIV, B) {\n#ifndef MRB_NO_FLOAT\n      mrb_float x, y, f;\n#endif\n\n      /* need to check if op is overridden */\n      switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\n      case TYPES2(MRB_TT_INTEGER,MRB_TT_INTEGER):\n        {\n          mrb_int x = mrb_integer(regs[a]);\n          mrb_int y = mrb_integer(regs[a+1]);\n          mrb_int div = mrb_div_int(mrb, x, y);\n          SET_INT_VALUE(mrb, regs[a], div);\n        }\n        NEXT;\n#ifndef MRB_NO_FLOAT\n      case TYPES2(MRB_TT_INTEGER,MRB_TT_FLOAT):\n        x = (mrb_float)mrb_integer(regs[a]);\n        y = mrb_float(regs[a+1]);\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_INTEGER):\n        x = mrb_float(regs[a]);\n        y = (mrb_float)mrb_integer(regs[a+1]);\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_FLOAT):\n        x = mrb_float(regs[a]);\n        y = mrb_float(regs[a+1]);\n        break;\n#endif\n      default:\n        mid = MRB_OPSYM(div);\n        goto L_SEND_SYM;\n      }\n\n#ifndef MRB_NO_FLOAT\n      f = mrb_div_float(x, y);\n      SET_FLOAT_VALUE(mrb, regs[a], f);\n#endif\n      NEXT;\n    }\n\n#define OP_MATHI(op_name)                                                   \\\n  /* need to check if op is overridden */                                   \\\n  switch (mrb_type(regs[a])) {                                              \\\n    OP_MATHI_CASE_INTEGER(op_name);                                         \\\n    OP_MATHI_CASE_FLOAT(op_name);                                           \\\n    default:                                                                \\\n      SET_INT_VALUE(mrb,regs[a+1], b);                                      \\\n      mid = MRB_OPSYM(op_name);                                             \\\n      goto L_SEND_SYM;                                                      \\\n  }                                                                         \\\n  NEXT;\n#define OP_MATHI_CASE_INTEGER(op_name)                                      \\\n  case MRB_TT_INTEGER:                                                      \\\n    {                                                                       \\\n      mrb_int x = mrb_integer(regs[a]), y = (mrb_int)b, z;                  \\\n      if (mrb_int_##op_name##_overflow(x, y, &z)) {                         \\\n        OP_MATH_OVERFLOW_INT(op_name,x,y);                                  \\\n      }                                                                     \\\n      else                                                                  \\\n        SET_INT_VALUE(mrb,regs[a], z);                                      \\\n    }                                                                       \\\n    break\n#ifdef MRB_NO_FLOAT\n#define OP_MATHI_CASE_FLOAT(op_name) (void)0\n#else\n#define OP_MATHI_CASE_FLOAT(op_name)                                        \\\n  case MRB_TT_FLOAT:                                                        \\\n    {                                                                       \\\n      mrb_float z = mrb_float(regs[a]) OP_MATH_OP_##op_name b;              \\\n      SET_FLOAT_VALUE(mrb, regs[a], z);                                     \\\n    }                                                                       \\\n    break\n#endif\n\n    CASE(OP_ADDI, BB) {\n      OP_MATHI(add);\n    }\n\n    CASE(OP_SUBI, BB) {\n      OP_MATHI(sub);\n    }\n\n#define OP_CMP_BODY(op,v1,v2) (v1(regs[a]) op v2(regs[a+1]))\n\n#ifdef MRB_NO_FLOAT\n#define OP_CMP(op,sym) do {\\\n  int result;\\\n  /* need to check if - is overridden */\\\n  switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\\\n  case TYPES2(MRB_TT_INTEGER,MRB_TT_INTEGER):\\\n    result = OP_CMP_BODY(op,mrb_fixnum,mrb_fixnum);\\\n    break;\\\n  default:\\\n    mid = MRB_OPSYM(sym);\\\n    goto L_SEND_SYM;\\\n  }\\\n  if (result) {\\\n    SET_TRUE_VALUE(regs[a]);\\\n  }\\\n  else {\\\n    SET_FALSE_VALUE(regs[a]);\\\n  }\\\n} while(0)\n#else\n#define OP_CMP(op, sym) do {\\\n  int result;\\\n  /* need to check if - is overridden */\\\n  switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\\\n  case TYPES2(MRB_TT_INTEGER,MRB_TT_INTEGER):\\\n    result = OP_CMP_BODY(op,mrb_fixnum,mrb_fixnum);\\\n    break;\\\n  case TYPES2(MRB_TT_INTEGER,MRB_TT_FLOAT):\\\n    result = OP_CMP_BODY(op,mrb_fixnum,mrb_float);\\\n    break;\\\n  case TYPES2(MRB_TT_FLOAT,MRB_TT_INTEGER):\\\n    result = OP_CMP_BODY(op,mrb_float,mrb_fixnum);\\\n    break;\\\n  case TYPES2(MRB_TT_FLOAT,MRB_TT_FLOAT):\\\n    result = OP_CMP_BODY(op,mrb_float,mrb_float);\\\n    break;\\\n  default:\\\n    mid = MRB_OPSYM(sym);\\\n    goto L_SEND_SYM;\\\n  }\\\n  if (result) {\\\n    SET_TRUE_VALUE(regs[a]);\\\n  }\\\n  else {\\\n    SET_FALSE_VALUE(regs[a]);\\\n  }\\\n} while(0)\n#endif\n\n    CASE(OP_EQ, B) {\n      if (mrb_obj_eq(mrb, regs[a], regs[a+1])) {\n        SET_TRUE_VALUE(regs[a]);\n      }\n      else {\n        OP_CMP(==,eq);\n      }\n      NEXT;\n    }\n\n    CASE(OP_LT, B) {\n      OP_CMP(<,lt);\n      NEXT;\n    }\n\n    CASE(OP_LE, B) {\n      OP_CMP(<=,le);\n      NEXT;\n    }\n\n    CASE(OP_GT, B) {\n      OP_CMP(>,gt);\n      NEXT;\n    }\n\n    CASE(OP_GE, B) {\n      OP_CMP(>=,ge);\n      NEXT;\n    }\n\n    CASE(OP_ARRAY, BB) {\n      regs[a] = mrb_ary_new_from_values(mrb, b, &regs[a]);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n    CASE(OP_ARRAY2, BBB) {\n      regs[a] = mrb_ary_new_from_values(mrb, c, &regs[b]);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_ARYCAT, B) {\n      mrb_value splat = mrb_ary_splat(mrb, regs[a+1]);\n      if (mrb_nil_p(regs[a])) {\n        regs[a] = splat;\n      }\n      else {\n        mrb_assert(mrb_array_p(regs[a]));\n        mrb_ary_concat(mrb, regs[a], splat);\n      }\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_ARYPUSH, BB) {\n      mrb_assert(mrb_array_p(regs[a]));\n      for (mrb_int i=0; i<b; i++) {\n        mrb_ary_push(mrb, regs[a], regs[a+i+1]);\n      }\n      NEXT;\n    }\n\n    CASE(OP_ARYDUP, B) {\n      mrb_value ary = regs[a];\n      if (mrb_array_p(ary)) {\n        ary = mrb_ary_new_from_values(mrb, RARRAY_LEN(ary), RARRAY_PTR(ary));\n      }\n      else {\n        ary = mrb_ary_new_from_values(mrb, 1, &ary);\n      }\n      regs[a] = ary;\n      NEXT;\n    }\n\n    CASE(OP_AREF, BBB) {\n      mrb_value v = regs[b];\n\n      if (!mrb_array_p(v)) {\n        if (c == 0) {\n          regs[a] = v;\n        }\n        else {\n          SET_NIL_VALUE(regs[a]);\n        }\n      }\n      else {\n        v = mrb_ary_ref(mrb, v, c);\n        regs[a] = v;\n      }\n      NEXT;\n    }\n\n    CASE(OP_ASET, BBB) {\n      mrb_assert(mrb_array_p(regs[a]));\n      mrb_ary_set(mrb, regs[b], c, regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_APOST, BBB) {\n      mrb_value v = regs[a];\n      int pre  = b;\n      int post = c;\n      struct RArray *ary;\n      int len, idx;\n\n      if (!mrb_array_p(v)) {\n        v = mrb_ary_new_from_values(mrb, 1, &regs[a]);\n      }\n      ary = mrb_ary_ptr(v);\n      len = (int)ARY_LEN(ary);\n      if (len > pre + post) {\n        v = mrb_ary_new_from_values(mrb, len - pre - post, ARY_PTR(ary)+pre);\n        regs[a++] = v;\n        while (post--) {\n          regs[a++] = ARY_PTR(ary)[len-post-1];\n        }\n      }\n      else {\n        v = mrb_ary_new_capa(mrb, 0);\n        regs[a++] = v;\n        for (idx=0; idx+pre<len; idx++) {\n          regs[a+idx] = ARY_PTR(ary)[pre+idx];\n        }\n        while (idx < post) {\n          SET_NIL_VALUE(regs[a+idx]);\n          idx++;\n        }\n      }\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_INTERN, B) {\n      mrb_assert(mrb_string_p(regs[a]));\n      mrb_sym sym = mrb_intern_str(mrb, regs[a]);\n      regs[a] = mrb_symbol_value(sym);\n      NEXT;\n    }\n\n    CASE(OP_SYMBOL, BB) {\n      size_t len;\n      mrb_sym sym;\n\n      mrb_assert((pool[b].tt&IREP_TT_NFLAG)==0);\n      len = pool[b].tt >> 2;\n      if (pool[b].tt & IREP_TT_SFLAG) {\n        sym = mrb_intern_static(mrb, pool[b].u.str, len);\n      }\n      else {\n        sym  = mrb_intern(mrb, pool[b].u.str, len);\n      }\n      regs[a] = mrb_symbol_value(sym);\n      NEXT;\n    }\n\n    CASE(OP_STRING, BB) {\n      mrb_int len;\n\n      mrb_assert((pool[b].tt&IREP_TT_NFLAG)==0);\n      len = pool[b].tt >> 2;\n      if (pool[b].tt & IREP_TT_SFLAG) {\n        regs[a] = mrb_str_new_static(mrb, pool[b].u.str, len);\n      }\n      else {\n        regs[a] = mrb_str_new(mrb, pool[b].u.str, len);\n      }\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_STRCAT, B) {\n      mrb_assert(mrb_string_p(regs[a]));\n      mrb_str_concat(mrb, regs[a], regs[a+1]);\n      NEXT;\n    }\n\n    CASE(OP_HASH, BB) {\n      mrb_value hash = mrb_hash_new_capa(mrb, b);\n      int i;\n      int lim = a+b*2;\n\n      for (i=a; i<lim; i+=2) {\n        mrb_hash_set(mrb, hash, regs[i], regs[i+1]);\n      }\n      regs[a] = hash;\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_HASHADD, BB) {\n      mrb_value hash;\n      int i;\n      int lim = a+b*2+1;\n\n      hash = regs[a];\n      mrb_ensure_hash_type(mrb, hash);\n      for (i=a+1; i<lim; i+=2) {\n        mrb_hash_set(mrb, hash, regs[i], regs[i+1]);\n      }\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n    CASE(OP_HASHCAT, B) {\n      mrb_value hash = regs[a];\n\n      mrb_assert(mrb_hash_p(hash));\n      mrb_hash_merge(mrb, hash, regs[a+1]);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_LAMBDA, BB)\n    c = OP_L_LAMBDA;\n    L_MAKE_LAMBDA:\n    {\n      struct RProc *p;\n      const mrb_irep *nirep = irep->reps[b];\n\n      if (c & OP_L_CAPTURE) {\n        p = mrb_closure_new(mrb, nirep);\n      }\n      else {\n        p = mrb_proc_new(mrb, nirep);\n        p->flags |= MRB_PROC_SCOPE;\n      }\n      if (c & OP_L_STRICT) p->flags |= MRB_PROC_STRICT;\n      regs[a] = mrb_obj_value(p);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n    CASE(OP_BLOCK, BB) {\n      c = OP_L_BLOCK;\n      goto L_MAKE_LAMBDA;\n    }\n    CASE(OP_METHOD, BB) {\n      c = OP_L_METHOD;\n      goto L_MAKE_LAMBDA;\n    }\n\n    CASE(OP_RANGE_INC, B) {\n      mrb_value v = mrb_range_new(mrb, regs[a], regs[a+1], FALSE);\n      regs[a] = v;\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_RANGE_EXC, B) {\n      mrb_value v = mrb_range_new(mrb, regs[a], regs[a+1], TRUE);\n      regs[a] = v;\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_OCLASS, B) {\n      regs[a] = mrb_obj_value(mrb->object_class);\n      NEXT;\n    }\n\n    CASE(OP_CLASS, BB) {\n      struct RClass *c = 0, *baseclass;\n      mrb_value base, super;\n      mrb_sym id = syms[b];\n\n      base = regs[a];\n      super = regs[a+1];\n      if (mrb_nil_p(base)) {\n        baseclass = MRB_PROC_TARGET_CLASS(mrb->c->ci->proc);\n        if (!baseclass) baseclass = mrb->object_class;\n        base = mrb_obj_value(baseclass);\n      }\n      c = mrb_vm_define_class(mrb, base, super, id);\n      regs[a] = mrb_obj_value(c);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_MODULE, BB) {\n      struct RClass *cls = 0, *baseclass;\n      mrb_value base;\n      mrb_sym id = syms[b];\n\n      base = regs[a];\n      if (mrb_nil_p(base)) {\n        baseclass = MRB_PROC_TARGET_CLASS(mrb->c->ci->proc);\n        if (!baseclass) baseclass = mrb->object_class;\n        base = mrb_obj_value(baseclass);\n      }\n      cls = mrb_vm_define_module(mrb, base, id);\n      regs[a] = mrb_obj_value(cls);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_EXEC, BB)\n    {\n      mrb_value recv = regs[a];\n      struct RProc *p;\n      const mrb_irep *nirep = irep->reps[b];\n\n      /* prepare closure */\n      p = mrb_proc_new(mrb, nirep);\n      p->c = NULL;\n      mrb_field_write_barrier(mrb, (struct RBasic*)p, (struct RBasic*)proc);\n      MRB_PROC_SET_TARGET_CLASS(p, mrb_class_ptr(recv));\n      p->flags |= MRB_PROC_SCOPE;\n\n      /* prepare call stack */\n      cipush(mrb, a, 0, mrb_class_ptr(recv), p, 0, 0);\n\n      irep = p->body.irep;\n      pool = irep->pool;\n      syms = irep->syms;\n      mrb_stack_extend(mrb, irep->nregs);\n      stack_clear(regs+1, irep->nregs-1);\n      pc = irep->iseq;\n      JUMP;\n    }\n\n    CASE(OP_DEF, BB) {\n      struct RClass *target = mrb_class_ptr(regs[a]);\n      struct RProc *p = mrb_proc_ptr(regs[a+1]);\n      mrb_method_t m;\n      mrb_sym mid = syms[b];\n\n      MRB_METHOD_FROM_PROC(m, p);\n      mrb_define_method_raw(mrb, target, mid, m);\n      mrb_method_added(mrb, target, mid);\n      mrb_gc_arena_restore(mrb, ai);\n      regs[a] = mrb_symbol_value(mid);\n      NEXT;\n    }\n\n    CASE(OP_SCLASS, B) {\n      regs[a] = mrb_singleton_class(mrb, regs[a]);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_TCLASS, B) {\n      struct RClass *target = check_target_class(mrb);\n      if (!target) goto L_RAISE;\n      regs[a] = mrb_obj_value(target);\n      NEXT;\n    }\n\n    CASE(OP_ALIAS, BB) {\n      struct RClass *target = check_target_class(mrb);\n\n      if (!target) goto L_RAISE;\n      mrb_alias_method(mrb, target, syms[a], syms[b]);\n      mrb_method_added(mrb, target, syms[a]);\n      NEXT;\n    }\n    CASE(OP_UNDEF, B) {\n      struct RClass *target = check_target_class(mrb);\n\n      if (!target) goto L_RAISE;\n      mrb_undef_method_id(mrb, target, syms[a]);\n      NEXT;\n    }\n\n    CASE(OP_DEBUG, Z) {\n      FETCH_BBB();\n#ifdef MRB_USE_DEBUG_HOOK\n      mrb->debug_op_hook(mrb, irep, pc, regs);\n#else\n#ifndef MRB_NO_STDIO\n      printf(\"OP_DEBUG %d %d %d\\n\", a, b, c);\n#else\n      abort();\n#endif\n#endif\n      NEXT;\n    }\n\n    CASE(OP_ERR, B) {\n      size_t len = pool[a].tt >> 2;\n      mrb_value exc;\n\n      mrb_assert((pool[a].tt&IREP_TT_NFLAG)==0);\n      exc = mrb_exc_new(mrb, E_LOCALJUMP_ERROR, pool[a].u.str, len);\n      mrb_exc_set(mrb, exc);\n      goto L_RAISE;\n    }\n\n    CASE(OP_EXT1, Z) {\n      insn = READ_B();\n      switch (insn) {\n#define OPCODE(insn,ops) case OP_ ## insn: FETCH_ ## ops ## _1(); mrb->c->ci->pc = pc; goto L_OP_ ## insn ## _BODY;\n#include \"mruby/ops.h\"\n#undef OPCODE\n      }\n      pc--;\n      NEXT;\n    }\n    CASE(OP_EXT2, Z) {\n      insn = READ_B();\n      switch (insn) {\n#define OPCODE(insn,ops) case OP_ ## insn: FETCH_ ## ops ## _2(); mrb->c->ci->pc = pc; goto L_OP_ ## insn ## _BODY;\n#include \"mruby/ops.h\"\n#undef OPCODE\n      }\n      pc--;\n      NEXT;\n    }\n    CASE(OP_EXT3, Z) {\n      uint8_t insn = READ_B();\n      switch (insn) {\n#define OPCODE(insn,ops) case OP_ ## insn: FETCH_ ## ops ## _3(); mrb->c->ci->pc = pc; goto L_OP_ ## insn ## _BODY;\n#include \"mruby/ops.h\"\n#undef OPCODE\n      }\n      pc--;\n      NEXT;\n    }\n\n    CASE(OP_STOP, Z) {\n      /*        stop VM */\n      CHECKPOINT_RESTORE(RBREAK_TAG_STOP) {\n        /* do nothing */\n      }\n      CHECKPOINT_MAIN(RBREAK_TAG_STOP) {\n        UNWIND_ENSURE(mrb, mrb->c->ci, pc, RBREAK_TAG_STOP, proc, mrb_nil_value());\n      }\n      CHECKPOINT_END(RBREAK_TAG_STOP);\n    L_STOP:\n      mrb->jmp = prev_jmp;\n      if (mrb->exc) {\n        mrb_assert(mrb->exc->tt == MRB_TT_EXCEPTION);\n        return mrb_obj_value(mrb->exc);\n      }\n      return regs[irep->nlocals];\n    }\n  }\n  END_DISPATCH;\n#undef regs\n  }\n  MRB_CATCH(&c_jmp) {\n    mrb_callinfo *ci = mrb->c->ci;\n    while (ci > mrb->c->cibase && ci->cci == CINFO_DIRECT) {\n      ci = cipop(mrb);\n    }\n    exc_catched = TRUE;\n    pc = ci->pc;\n    goto RETRY_TRY_BLOCK;\n  }\n  MRB_END_EXC(&c_jmp);\n}",
        "func_hash": 44658455618798852770197569753613577766,
        "file_name": "vm.c",
        "file_hash": 164058079299968555060167307813659313262,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2022-1427",
        "cve_desc": "Out-of-bounds Read in mrb_obj_is_kind_of in in GitHub repository mruby/mruby prior to 3.2. # Impact: Possible arbitrary code execution if being exploited.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-1427",
        "func_name": "mrb_vm_exec",
        "diff": [
            "diff --git a/src/vm.c b/src/vm.c\nindex 5013c877d4..aa043b06ae 100644\n--- a/src/vm.c\n+++ b/src/vm.c\n@@ -1750,10 +1750,7 @@ mrb_vm_exec(mrb_state *mrb, const struct RProc *proc, const mrb_code *pc)\n         mrb_exc_set(mrb, exc);\n         goto L_RAISE;\n       }\n-      if (target_class->flags & MRB_FL_CLASS_IS_PREPENDED) {\n-        target_class = mrb_vm_ci_target_class(ci);\n-      }\n-      else if (target_class->tt == MRB_TT_MODULE) {\n+      if ((target_class->flags & MRB_FL_CLASS_IS_PREPENDED) || target_class->tt == MRB_TT_MODULE) {\n         target_class = mrb_vm_ci_target_class(ci);\n         if (!target_class || target_class->tt != MRB_TT_ICLASS) {\n           goto super_typeerror;\n"
        ],
        "func_after": []
    },
    {
        "idx": 195692,
        "project": "FreeRTOS-Kernel",
        "commit_id": "47338393f1f79558f6144213409f09f81d7c4837",
        "project_url": "https://github.com/FreeRTOS/FreeRTOS-Kernel",
        "commit_url": "https://github.com/FreeRTOS/FreeRTOS-Kernel/commit/47338393f1f79558f6144213409f09f81d7c4837",
        "commit_message": "add assert for addition overflow on queue creation (#225)",
        "target": 1,
        "irrelevant": 1,
        "func_before": "    QueueHandle_t xQueueGenericCreate( const UBaseType_t uxQueueLength,\r\n                                       const UBaseType_t uxItemSize,\r\n                                       const uint8_t ucQueueType )\r\n    {\r\n        Queue_t * pxNewQueue;\r\n        size_t xQueueSizeInBytes;\r\n        uint8_t * pucQueueStorage;\r\n\r\n        configASSERT( uxQueueLength > ( UBaseType_t ) 0 );\r\n\r\n        /* Allocate enough space to hold the maximum number of items that\r\n         * can be in the queue at any time.  It is valid for uxItemSize to be\r\n         * zero in the case the queue is used as a semaphore. */\r\n        xQueueSizeInBytes = ( size_t ) ( uxQueueLength * uxItemSize ); /*lint !e961 MISRA exception as the casts are only redundant for some ports. */\r\n\r\n        /* Check for multiplication overflow. */\r\n        configASSERT( ( uxItemSize == 0 ) || ( uxQueueLength == ( xQueueSizeInBytes / uxItemSize ) ) );\r\n\r\n        /* Allocate the queue and storage area.  Justification for MISRA\r\n         * deviation as follows:  pvPortMalloc() always ensures returned memory\r\n         * blocks are aligned per the requirements of the MCU stack.  In this case\r\n         * pvPortMalloc() must return a pointer that is guaranteed to meet the\r\n         * alignment requirements of the Queue_t structure - which in this case\r\n         * is an int8_t *.  Therefore, whenever the stack alignment requirements\r\n         * are greater than or equal to the pointer to char requirements the cast\r\n         * is safe.  In other cases alignment requirements are not strict (one or\r\n         * two bytes). */\r\n        pxNewQueue = ( Queue_t * ) pvPortMalloc( sizeof( Queue_t ) + xQueueSizeInBytes ); /*lint !e9087 !e9079 see comment above. */\r\n\r\n        if( pxNewQueue != NULL )\r\n        {\r\n            /* Jump past the queue structure to find the location of the queue\r\n             * storage area. */\r\n            pucQueueStorage = ( uint8_t * ) pxNewQueue;\r\n            pucQueueStorage += sizeof( Queue_t ); /*lint !e9016 Pointer arithmetic allowed on char types, especially when it assists conveying intent. */\r\n\r\n            #if ( configSUPPORT_STATIC_ALLOCATION == 1 )\r\n                {\r\n                    /* Queues can be created either statically or dynamically, so\r\n                     * note this task was created dynamically in case it is later\r\n                     * deleted. */\r\n                    pxNewQueue->ucStaticallyAllocated = pdFALSE;\r\n                }\r\n            #endif /* configSUPPORT_STATIC_ALLOCATION */\r\n\r\n            prvInitialiseNewQueue( uxQueueLength, uxItemSize, pucQueueStorage, ucQueueType, pxNewQueue );\r\n        }\r\n        else\r\n        {\r\n            traceQUEUE_CREATE_FAILED( ucQueueType );\r\n            mtCOVERAGE_TEST_MARKER();\r\n        }\r\n\r\n        return pxNewQueue;\r\n    }\r",
        "func_hash": 278728915886701481135388633284092658774,
        "file_name": "queue.c",
        "file_hash": 44156660200315650828929819637760261927,
        "cwe": [
            "CWE-200"
        ],
        "cve": "CVE-2021-31571",
        "cve_desc": "The kernel in Amazon Web Services FreeRTOS before 10.4.3 has an integer overflow in queue.c for queue creation.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-31571",
        "func_name": "xQueueGenericCreate",
        "diff": [
            "diff --git a/queue.c b/queue.c\nindex d2e27e55a52..b01dfd11ff1 100644\n--- a/queue.c\n+++ b/queue.c\n@@ -397,6 +397,9 @@ BaseType_t xQueueGenericReset( QueueHandle_t xQueue,\n         /* Check for multiplication overflow. */\r\n         configASSERT( ( uxItemSize == 0 ) || ( uxQueueLength == ( xQueueSizeInBytes / uxItemSize ) ) );\r\n \r\n+        /* Check for addition overflow. */\r\n+        configASSERT( ( sizeof( Queue_t ) + xQueueSizeInBytes ) >  xQueueSizeInBytes );\r\n+\r\n         /* Allocate the queue and storage area.  Justification for MISRA\r\n          * deviation as follows:  pvPortMalloc() always ensures returned memory\r\n          * blocks are aligned per the requirements of the MCU stack.  In this case\r\n"
        ],
        "func_after": []
    },
    {
        "idx": 195720,
        "project": "mvfst",
        "commit_id": "a67083ff4b8dcbb7ee2839da6338032030d712b0",
        "project_url": "https://github.com/facebookincubator/mvfst",
        "commit_url": "https://github.com/facebookincubator/mvfst/commit/a67083ff4b8dcbb7ee2839da6338032030d712b0",
        "commit_message": "Close connection if we derive an extra 1-rtt write cipher\n\nSummary: Fixes CVE-2021-24029\n\nReviewed By: mjoras, lnicco\n\nDifferential Revision: D26613890\n\nfbshipit-source-id: 19bb2be2c731808144e1a074ece313fba11f1945",
        "target": 1,
        "irrelevant": 0,
        "func_before": "void updateHandshakeState(QuicServerConnectionState& conn) {\n  // Zero RTT read cipher is available after chlo is processed with the\n  // condition that early data attempt is accepted.\n  auto handshakeLayer = conn.serverHandshakeLayer;\n  auto zeroRttReadCipher = handshakeLayer->getZeroRttReadCipher();\n  auto zeroRttHeaderCipher = handshakeLayer->getZeroRttReadHeaderCipher();\n  // One RTT write cipher is available at Fizz layer after chlo is processed.\n  // However, the cipher is only exported to QUIC if early data attempt is\n  // accepted. Otherwise, the cipher will be available after cfin is\n  // processed.\n  auto oneRttWriteCipher = handshakeLayer->getOneRttWriteCipher();\n  // One RTT read cipher is available after cfin is processed.\n  auto oneRttReadCipher = handshakeLayer->getOneRttReadCipher();\n\n  auto oneRttWriteHeaderCipher = handshakeLayer->getOneRttWriteHeaderCipher();\n  auto oneRttReadHeaderCipher = handshakeLayer->getOneRttReadHeaderCipher();\n\n  if (zeroRttReadCipher) {\n    if (conn.qLogger) {\n      conn.qLogger->addTransportStateUpdate(kDerivedZeroRttReadCipher);\n    }\n    QUIC_TRACE(fst_trace, conn, \"derived 0-rtt read cipher\");\n    conn.readCodec->setZeroRttReadCipher(std::move(zeroRttReadCipher));\n  }\n  if (zeroRttHeaderCipher) {\n    conn.readCodec->setZeroRttHeaderCipher(std::move(zeroRttHeaderCipher));\n  }\n  if (oneRttWriteHeaderCipher) {\n    conn.oneRttWriteHeaderCipher = std::move(oneRttWriteHeaderCipher);\n  }\n  if (oneRttReadHeaderCipher) {\n    conn.readCodec->setOneRttHeaderCipher(std::move(oneRttReadHeaderCipher));\n  }\n\n  if (oneRttWriteCipher) {\n    if (conn.qLogger) {\n      conn.qLogger->addTransportStateUpdate(kDerivedOneRttWriteCipher);\n    }\n    QUIC_TRACE(fst_trace, conn, \"derived 1-rtt write cipher\");\n    CHECK(!conn.oneRttWriteCipher.get());\n    conn.oneRttWriteCipher = std::move(oneRttWriteCipher);\n\n    updatePacingOnKeyEstablished(conn);\n\n    // We negotiate the transport parameters whenever we have the 1-RTT write\n    // keys available.\n    auto clientParams = handshakeLayer->getClientTransportParams();\n    if (!clientParams) {\n      throw QuicTransportException(\n          \"No client transport params\",\n          TransportErrorCode::TRANSPORT_PARAMETER_ERROR);\n    }\n    processClientInitialParams(conn, std::move(*clientParams));\n  }\n  if (oneRttReadCipher) {\n    if (conn.qLogger) {\n      conn.qLogger->addTransportStateUpdate(kDerivedOneRttReadCipher);\n    }\n    QUIC_TRACE(fst_trace, conn, \"derived 1-rtt read cipher\");\n    // Clear limit because CFIN is received at this point\n    conn.writableBytesLimit = folly::none;\n    conn.readCodec->setOneRttReadCipher(std::move(oneRttReadCipher));\n  }\n  auto handshakeReadCipher = handshakeLayer->getHandshakeReadCipher();\n  auto handshakeReadHeaderCipher =\n      handshakeLayer->getHandshakeReadHeaderCipher();\n  if (handshakeReadCipher) {\n    CHECK(handshakeReadHeaderCipher);\n    conn.readCodec->setHandshakeReadCipher(std::move(handshakeReadCipher));\n    conn.readCodec->setHandshakeHeaderCipher(\n        std::move(handshakeReadHeaderCipher));\n  }\n  if (handshakeLayer->isHandshakeDone()) {\n    CHECK(conn.oneRttWriteCipher);\n    if (conn.version != QuicVersion::MVFST_D24 && !conn.sentHandshakeDone) {\n      sendSimpleFrame(conn, HandshakeDoneFrame());\n      conn.sentHandshakeDone = true;\n    }\n  }\n}",
        "func_hash": 43735419078414129480912957086830640484,
        "file_name": "ServerStateMachine.cpp",
        "file_hash": 9223824505720776904271246874049398430,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2021-24029",
        "cve_desc": "A packet of death scenario is possible in mvfst via a specially crafted message during a QUIC session, which causes a crash via a failed assertion. Per QUIC specification, this particular message should be treated as a connection error. This issue affects mvfst versions prior to commit a67083ff4b8dcbb7ee2839da6338032030d712b0 and proxygen versions prior to v2021.03.15.00.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-24029",
        "func_name": "updateHandshakeState",
        "diff": [
            "diff --git a/quic/server/state/ServerStateMachine.cpp b/quic/server/state/ServerStateMachine.cpp\nindex a5f42f8ef..eaa609e56 100644\n--- a/quic/server/state/ServerStateMachine.cpp\n+++ b/quic/server/state/ServerStateMachine.cpp\n@@ -311,7 +311,10 @@ void updateHandshakeState(QuicServerConnectionState& conn) {\n       conn.qLogger->addTransportStateUpdate(kDerivedOneRttWriteCipher);\n     }\n     QUIC_TRACE(fst_trace, conn, \"derived 1-rtt write cipher\");\n-    CHECK(!conn.oneRttWriteCipher.get());\n+    if (conn.oneRttWriteCipher) {\n+      throw QuicTransportException(\n+          \"Duplicate 1-rtt write cipher\", TransportErrorCode::CRYPTO_ERROR);\n+    }\n     conn.oneRttWriteCipher = std::move(oneRttWriteCipher);\n \n     updatePacingOnKeyEstablished(conn);\ndiff --git a/quic/server/test/QuicServerTransportTest.cpp b/quic/server/test/QuicServerTransportTest.cpp\nindex 07e22bcf9..404a78b80 100644\n--- a/quic/server/test/QuicServerTransportTest.cpp\n+++ b/quic/server/test/QuicServerTransportTest.cpp\n@@ -4265,6 +4265,21 @@ TEST_P(QuicServerTransportHandshakeTest, TestD6DStartCallback) {\n   server->removeObserver(mockObserver.get());\n }\n \n+TEST_F(QuicUnencryptedServerTransportTest, DuplicateOneRttWriteCipher) {\n+  setupClientReadCodec();\n+  recvClientHello();\n+  recvClientFinished();\n+  loopForWrites();\n+  try {\n+    recvClientHello();\n+    recvClientFinished();\n+    FAIL();\n+  } catch (const std::runtime_error& ex) {\n+    EXPECT_THAT(ex.what(), HasSubstr(\"Crypto error\"));\n+  }\n+  EXPECT_TRUE(server->isClosed());\n+}\n+\n TEST_F(QuicServerTransportTest, TestRegisterAndHandleTransportKnobParams) {\n   int flag = 0;\n   server->registerKnobParamHandler(\n"
        ],
        "func_after": []
    },
    {
        "idx": 195740,
        "project": "libjpeg",
        "commit_id": "4746b577931e926a49e50de9720a4946de3069a7",
        "project_url": "https://github.com/thorfdbg/libjpeg",
        "commit_url": "https://github.com/thorfdbg/libjpeg/commit/4746b577931e926a49e50de9720a4946de3069a7",
        "commit_message": "Fixed handling of empty JPEG-LS scans.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "bool SampleInterleavedLSScan::ParseMCU(void)\n{\n#if ACCUSOFT_CODE\n  int lines             = m_ulRemaining[0]; // total number of MCU lines processed.\n  UBYTE preshift        = m_ucLowBit + FractionalColorBitsOf();\n  struct Line *line[4];\n  UBYTE cx;\n\n  //\n  // If a DNL marker is present, the number of remaining lines is zero. Fix it.\n  if (m_pFrame->HeightOf() == 0) {\n    assert(lines == 0);\n    lines = 8;\n  }\n  //\n  // A \"MCU\" in respect to the code organization is eight lines.\n  if (lines > 8) {\n    lines = 8;\n  }\n  if (m_pFrame->HeightOf() > 0)\n    m_ulRemaining[0] -= lines;\n  assert(lines > 0);\n  assert(m_ucCount < 4);\n\n  //\n  // Fill the line pointers.\n  for(cx = 0;cx < m_ucCount;cx++) {\n    line[cx] = CurrentLine(cx);\n  }\n\n  // Loop over lines and columns\n  do {\n    LONG length = m_ulWidth[0];\n    LONG *lp[4];\n\n    // Get the line pointers and initialize the internal backup lines.\n    for(cx = 0;cx < m_ucCount;cx++) {\n      lp[cx] = line[cx]->m_pData;\n      StartLine(cx);\n    }\n\n    if (BeginReadMCU(m_Stream.ByteStreamOf())) { \n      // No error handling strategy. No RST in scans. Bummer!\n      do {\n        LONG a[4],b[4],c[4],d[4]; // neighbouring values.\n        LONG d1[4],d2[4],d3[4];   // local gradients.\n        bool isrun = true;\n      \n        for(cx = 0;cx < m_ucCount;cx++) {\n          GetContext(cx,a[cx],b[cx],c[cx],d[cx]);\n\n          d1[cx]  = d[cx] - b[cx];    // compute local gradients\n          d2[cx]  = b[cx] - c[cx];\n          d3[cx]  = c[cx] - a[cx];\n\n          //\n          // Run mode only if the run condition is met for all components\n          if (isrun && !isRunMode(d1[cx],d2[cx],d3[cx]))\n            isrun = false;\n        }\n        \n        if (isrun) {\n          LONG run = DecodeRun(length,m_lRunIndex[0]);\n          //\n          // Now fill the data.\n          while(run) {\n            // Update so that the next process gets the correct value.\n            // There is one sample per component.\n            for(cx = 0;cx < m_ucCount;cx++) {\n              UpdateContext(cx,a[cx]);\n              // And insert the value into the target line as well.\n              *lp[cx]++ = a[cx] << preshift;\n            }\n            run--,length--;\n            // As long as there are pixels on the line.\n          }\n          //\n          // More data on the line? I.e. the run did not cover the full m_lJ samples?\n          // Now decode the run interruption sample. The rtype is here always zero.\n          if (length) {\n            bool negative; // the sign variable\n            LONG errval;   // the prediction error\n            LONG merr;     // the mapped error (symbol)\n            LONG rx;       // the reconstructed value\n            UBYTE k;       // golomb parameter\n            //\n            // Decode the interrupting pixels.\n            for(cx = 0;cx < m_ucCount;cx++) {\n              // Get the neighbourhood.\n              GetContext(cx,a[cx],b[cx],c[cx],d[cx]);\n              // The prediction mode is always false, but the sign information\n              // is required.\n              negative = a[cx] > b[cx];\n              // Get the golomb parameter for run interruption coding.\n              k       = GolombParameter(false);\n              // Golomb-decode the error symbol. It is always using the common\n              // run index.\n              merr    = GolombDecode(k,m_lLimit - m_lJ[m_lRunIndex[0]] - 1);\n              // Inverse the error mapping procedure.\n              errval  = InverseErrorMapping(merr,ErrorMappingOffset(false,merr != 0,k));\n              // Compute the reconstructed value.\n              rx      = Reconstruct(negative,b[cx],errval);\n              // Update so that the next process gets the correct value.\n              UpdateContext(cx,rx);\n              // Fill in the value into the line\n              *lp[cx]++ = rx << preshift;\n              // Update the variables of the run mode.\n              UpdateState(false,errval);\n            }\n            // Update the run index now. This is not part of\n            // EncodeRun because the non-reduced run-index is\n            // required for the golomb coder length limit. \n            if (m_lRunIndex[0] > 0)\n              m_lRunIndex[0]--;\n          } else break; // end of line.\n        } else {\n          UWORD ctxt;\n          bool  negative; // the sign variable.\n          LONG  px;       // the predicted variable.\n          LONG  rx;       // the reconstructed value.\n          LONG  errval;   // the error value.\n          LONG  merr;     // the mapped error value.\n          UBYTE k;        // the Golomb parameter.\n          //\n          for(cx = 0;cx < m_ucCount;cx++) {\n            // Quantize the gradients.\n            d1[cx]  = QuantizedGradient(d1[cx]);\n            d2[cx]  = QuantizedGradient(d2[cx]);\n            d3[cx]  = QuantizedGradient(d3[cx]);\n            // Compute the context.\n            ctxt    = Context(negative,d1[cx],d2[cx],d3[cx]); \n            // Compute the predicted value.\n            px      = Predict(a[cx],b[cx],c[cx]);\n            // Correct the prediction.\n            px      = CorrectPrediction(ctxt,negative,px);\n            // Compute the golomb parameter k from the context.\n            k       = GolombParameter(ctxt);\n            // Decode the error symbol.\n            merr    = GolombDecode(k,m_lLimit);\n            // Inverse the error symbol into an error value.\n            errval  = InverseErrorMapping(merr,ErrorMappingOffset(ctxt,k));\n            // Update the variables.\n            UpdateState(ctxt,errval);\n            // Compute the reconstructed value.\n            rx      = Reconstruct(negative,px,errval);\n            // Update so that the next process gets the correct value.\n            UpdateContext(cx,rx);\n            // And insert the value into the target line as well.\n            *lp[cx]++ = rx << preshift;\n          }\n        }\n      } while(--length);\n    } // No error handling here.\n    //\n    // Advance the line pointers.\n    for(cx = 0;cx < m_ucCount;cx++) {\n      EndLine(cx);\n      line[cx] = line[cx]->m_pNext;\n    }\n    //\n  } while(--lines);\n  //\n  // If this is the last line, gobble up all the\n  // bits from bitstuffing the last byte may have left.\n  // As SkipStuffing is idempotent, we can also do that\n  // all the time.\n  m_Stream.SkipStuffing();\n#endif  \n  return false;\n}",
        "func_hash": 262161649015079801638874313151941212550,
        "file_name": "sampleinterleavedlsscan.cpp",
        "file_hash": null,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2022-32978",
        "cve_desc": "There is an assertion failure in SingleComponentLSScan::ParseMCU in singlecomponentlsscan.cpp in libjpeg before 1.64 via an empty JPEG-LS scan.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-32978",
        "func_name": "SampleInterleavedLSScan::ParseMCU",
        "diff": [
            "diff --git a/README b/README\nindex 124c958..3cff2da 100644\n--- a/README\n+++ b/README\n@@ -40,7 +40,7 @@ Standard JPEG compression, with 444 (aka \"no\") subsampling:\n \r\n $ jpeg -q <quality> infile.ppm outfile.jpg\r\n \r\n-Standard JPEG compression, with 422 subsampling:\r\n+Standard JPEG compression, with 420 subsampling:\r\n \r\n $ jpeg -q <quality> -s 1x1,2x2,2x2 infile.ppm outfile.jpg\r\n \r\ndiff --git a/codestream/sampleinterleavedlsscan.cpp b/codestream/sampleinterleavedlsscan.cpp\nindex e92c309..e3cfe47 100644\n--- a/codestream/sampleinterleavedlsscan.cpp\n+++ b/codestream/sampleinterleavedlsscan.cpp\n@@ -42,7 +42,7 @@\n ** A JPEG LS scan interleaving samples of several components,\n ** sample by sample.\n **\n-** $Id: sampleinterleavedlsscan.cpp,v 1.15 2014/11/14 15:41:32 thor Exp $\n+** $Id: sampleinterleavedlsscan.cpp,v 1.16 2022/06/08 10:54:55 thor Exp $\n **\n */\n \n@@ -112,9 +112,12 @@ bool SampleInterleavedLSScan::ParseMCU(void)\n   if (lines > 8) {\n     lines = 8;\n   }\n+\n+  if (lines == 0)\n+    return false;\n+  \n   if (m_pFrame->HeightOf() > 0)\n     m_ulRemaining[0] -= lines;\n-  assert(lines > 0);\n   assert(m_ucCount < 4);\n \n   //\ndiff --git a/codestream/singlecomponentlsscan.cpp b/codestream/singlecomponentlsscan.cpp\nindex 76310d6..cabc82c 100644\n--- a/codestream/singlecomponentlsscan.cpp\n+++ b/codestream/singlecomponentlsscan.cpp\n@@ -41,7 +41,7 @@\n /*\n ** A JPEG LS scan covering only a single component.\n **\n-** $Id: singlecomponentlsscan.cpp,v 1.18 2014/11/14 15:41:32 thor Exp $\n+** $Id: singlecomponentlsscan.cpp,v 1.19 2022/06/08 10:54:55 thor Exp $\n **\n */\n \n@@ -96,8 +96,9 @@ bool SingleComponentLSScan::ParseMCU(void)\n   }\n   if (m_pFrame->HeightOf() > 0)\n     m_ulRemaining[0] -= lines;\n-  \n-  assert(lines > 0);\n+\n+  if (lines == 0)\n+    return false;\n \n   // Loop over lines and columns\n   do {\n"
        ],
        "func_after": []
    },
    {
        "idx": 195741,
        "project": "libjpeg",
        "commit_id": "4746b577931e926a49e50de9720a4946de3069a7",
        "project_url": "https://github.com/thorfdbg/libjpeg",
        "commit_url": "https://github.com/thorfdbg/libjpeg/commit/4746b577931e926a49e50de9720a4946de3069a7",
        "commit_message": "Fixed handling of empty JPEG-LS scans.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "bool SingleComponentLSScan::ParseMCU(void)\n{ \n#if ACCUSOFT_CODE\n  int lines             = m_ulRemaining[0]; // total number of MCU lines processed.\n  UBYTE preshift        = m_ucLowBit + FractionalColorBitsOf();\n  struct Line *line     = CurrentLine(0);\n  \n  //\n  // If a DNL marker is present, the number of remaining lines is zero. Fix it.\n  if (m_pFrame->HeightOf() == 0) {\n    assert(lines == 0);\n    lines = 8;\n  }\n\n  assert(m_ucCount == 1);\n\n  //\n  // A \"MCU\" in respect to the code organization is eight lines.\n  if (lines > 8) {\n    lines = 8;\n  }\n  if (m_pFrame->HeightOf() > 0)\n    m_ulRemaining[0] -= lines;\n  \n  assert(lines > 0);\n\n  // Loop over lines and columns\n  do {\n    LONG length = m_ulWidth[0];\n    LONG *lp    = line->m_pData;\n\n#ifdef DEBUG_LS\n    int xpos    = 0;\n    static int linenumber = 0;\n    printf(\"\\n%4d : \",++linenumber);\n#endif\n     \n    StartLine(0);\n    if (BeginReadMCU(m_Stream.ByteStreamOf())) { // No error handling strategy. No RST in scans. Bummer!\n      do {\n        LONG a,b,c,d;   // neighbouring values.\n        LONG d1,d2,d3;  // local gradients.\n      \n        GetContext(0,a,b,c,d);\n        d1  = d - b;    // compute local gradients\n        d2  = b - c;\n        d3  = c - a;\n        \n        if (isRunMode(d1,d2,d3)) {\n          LONG run = DecodeRun(length,m_lRunIndex[0]);\n          //\n          // Now fill the data.\n          while(run) {\n            // Update so that the next process gets the correct value.\n            UpdateContext(0,a);\n            // And insert the value into the target line as well.\n            *lp++ = a << preshift;\n#ifdef DEBUG_LS\n            printf(\"%4d:<%2x> \",xpos++,a);\n#endif\n            run--,length--;\n            // As long as there are pixels on the line.\n          }\n          //\n          // More data on the line? I.e. the run did not cover the full m_lJ samples?\n          // Now decode the run interruption sample.\n          if (length) {\n            bool negative; // the sign variable\n            bool rtype;    // run interruption type\n            LONG errval;   // the prediction error\n            LONG merr;     // the mapped error (symbol)\n            LONG rx;       // the reconstructed value\n            UBYTE k;       // golomb parameter\n            // Get the neighbourhood.\n            GetContext(0,a,b,c,d);\n            // Get the prediction mode.\n            rtype  = InterruptedPredictionMode(negative,a,b);\n            // Get the golomb parameter for run interruption coding.\n            k      = GolombParameter(rtype);\n            // Golomb-decode the error symbol.\n            merr   = GolombDecode(k,m_lLimit - m_lJ[m_lRunIndex[0]] - 1);\n            // Inverse the error mapping procedure.\n            errval = InverseErrorMapping(merr + rtype,ErrorMappingOffset(rtype,rtype || merr,k));\n            // Compute the reconstructed value.\n            rx     = Reconstruct(negative,rtype?a:b,errval);\n            // Update so that the next process gets the correct value.\n            UpdateContext(0,rx);\n            // Fill in the value into the line\n            *lp    = rx << preshift;\n#ifdef DEBUG_LS\n            printf(\"%4d:<%2x> \",xpos++,*lp);\n#endif\n            // Update the variables of the run mode.\n            UpdateState(rtype,errval);\n            // Update the run index now. This is not part of\n            // EncodeRun because the non-reduced run-index is\n            // required for the golomb coder length limit. \n            if (m_lRunIndex[0] > 0)\n              m_lRunIndex[0]--;\n          } else break; // end of line.\n        } else {\n          UWORD ctxt;\n          bool  negative; // the sign variable.\n          LONG  px;       // the predicted variable.\n          LONG  rx;       // the reconstructed value.\n          LONG  errval;   // the error value.\n          LONG  merr;     // the mapped error value.\n          UBYTE k;        // the Golomb parameter.\n          // Quantize the gradients.\n          d1     = QuantizedGradient(d1);\n          d2     = QuantizedGradient(d2);\n          d3     = QuantizedGradient(d3);\n          // Compute the context.\n          ctxt   = Context(negative,d1,d2,d3); \n          // Compute the predicted value.\n          px     = Predict(a,b,c);\n          // Correct the prediction.\n          px     = CorrectPrediction(ctxt,negative,px);\n          // Compute the golomb parameter k from the context.\n          k      = GolombParameter(ctxt);\n          // Decode the error symbol.\n          merr   = GolombDecode(k,m_lLimit);\n          // Inverse the error symbol into an error value.\n          errval = InverseErrorMapping(merr,ErrorMappingOffset(ctxt,k));\n          // Update the variables.\n          UpdateState(ctxt,errval);\n          // Compute the reconstructed value.\n          rx     = Reconstruct(negative,px,errval);\n          // Update so that the next process gets the correct value.\n          UpdateContext(0,rx);\n          // And insert the value into the target line as well.\n          *lp    = rx << preshift;\n#ifdef DEBUG_LS\n          printf(\"%4d:<%2x> \",xpos++,*lp);\n#endif\n        }\n      } while(++lp,--length);\n    } // No error handling here.\n    EndLine(0);\n    line = line->m_pNext;\n  } while(--lines); \n  //\n  // If this is the last line, gobble up all the\n  // bits from bitstuffing the last byte may have left.\n  // As SkipStuffing is idempotent, we can also do that\n  // all the time.\n  m_Stream.SkipStuffing();\n#endif  \n  return false;\n}",
        "func_hash": 62606079555374024593923514521759457355,
        "file_name": "singlecomponentlsscan.cpp",
        "file_hash": null,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2022-32978",
        "cve_desc": "There is an assertion failure in SingleComponentLSScan::ParseMCU in singlecomponentlsscan.cpp in libjpeg before 1.64 via an empty JPEG-LS scan.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-32978",
        "func_name": "SingleComponentLSScan::ParseMCU",
        "diff": [
            "diff --git a/README b/README\nindex 124c958..3cff2da 100644\n--- a/README\n+++ b/README\n@@ -40,7 +40,7 @@ Standard JPEG compression, with 444 (aka \"no\") subsampling:\n \r\n $ jpeg -q <quality> infile.ppm outfile.jpg\r\n \r\n-Standard JPEG compression, with 422 subsampling:\r\n+Standard JPEG compression, with 420 subsampling:\r\n \r\n $ jpeg -q <quality> -s 1x1,2x2,2x2 infile.ppm outfile.jpg\r\n \r\ndiff --git a/codestream/sampleinterleavedlsscan.cpp b/codestream/sampleinterleavedlsscan.cpp\nindex e92c309..e3cfe47 100644\n--- a/codestream/sampleinterleavedlsscan.cpp\n+++ b/codestream/sampleinterleavedlsscan.cpp\n@@ -42,7 +42,7 @@\n ** A JPEG LS scan interleaving samples of several components,\n ** sample by sample.\n **\n-** $Id: sampleinterleavedlsscan.cpp,v 1.15 2014/11/14 15:41:32 thor Exp $\n+** $Id: sampleinterleavedlsscan.cpp,v 1.16 2022/06/08 10:54:55 thor Exp $\n **\n */\n \n@@ -112,9 +112,12 @@ bool SampleInterleavedLSScan::ParseMCU(void)\n   if (lines > 8) {\n     lines = 8;\n   }\n+\n+  if (lines == 0)\n+    return false;\n+  \n   if (m_pFrame->HeightOf() > 0)\n     m_ulRemaining[0] -= lines;\n-  assert(lines > 0);\n   assert(m_ucCount < 4);\n \n   //\ndiff --git a/codestream/singlecomponentlsscan.cpp b/codestream/singlecomponentlsscan.cpp\nindex 76310d6..cabc82c 100644\n--- a/codestream/singlecomponentlsscan.cpp\n+++ b/codestream/singlecomponentlsscan.cpp\n@@ -41,7 +41,7 @@\n /*\n ** A JPEG LS scan covering only a single component.\n **\n-** $Id: singlecomponentlsscan.cpp,v 1.18 2014/11/14 15:41:32 thor Exp $\n+** $Id: singlecomponentlsscan.cpp,v 1.19 2022/06/08 10:54:55 thor Exp $\n **\n */\n \n@@ -96,8 +96,9 @@ bool SingleComponentLSScan::ParseMCU(void)\n   }\n   if (m_pFrame->HeightOf() > 0)\n     m_ulRemaining[0] -= lines;\n-  \n-  assert(lines > 0);\n+\n+  if (lines == 0)\n+    return false;\n \n   // Loop over lines and columns\n   do {\n"
        ],
        "func_after": []
    },
    {
        "idx": 195742,
        "project": "gpac",
        "commit_id": "37592ad86c6ca934d34740012213e467acc4a3b0",
        "project_url": "https://github.com/gpac/gpac",
        "commit_url": "https://github.com/gpac/gpac/commit/37592ad86c6ca934d34740012213e467acc4a3b0",
        "commit_message": "fixed #2163",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static GF_Err gf_isom_parse_movie_boxes_internal(GF_ISOFile *mov, u32 *boxType, u64 *bytesMissing, Bool progressive_mode)\n{\n\tGF_Box *a;\n\tu64 totSize, mdat_end=0;\n\tGF_Err e = GF_OK;\n\n#ifndef\tGPAC_DISABLE_ISOM_FRAGMENTS\n\tif (mov->single_moof_mode && mov->single_moof_state == 2) {\n\t\treturn e;\n\t}\n\n\t/*restart from where we stopped last*/\n\ttotSize = mov->current_top_box_start;\n\tif (mov->bytes_removed) {\n\t\tassert(totSize >= mov->bytes_removed);\n\t\ttotSize -= mov->bytes_removed;\n\t}\n\tgf_bs_seek(mov->movieFileMap->bs, totSize);\n#endif\n\n\n\t/*while we have some data, parse our boxes*/\n\twhile (gf_bs_available(mov->movieFileMap->bs)) {\n\t\t*bytesMissing = 0;\n#ifndef\tGPAC_DISABLE_ISOM_FRAGMENTS\n\t\tmov->current_top_box_start = gf_bs_get_position(mov->movieFileMap->bs) + mov->bytes_removed;\n\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_CONTAINER, (\"[iso file] Parsing a top-level box at position %d\\n\", mov->current_top_box_start));\n#endif\n\n\t\te = gf_isom_parse_root_box(&a, mov->movieFileMap->bs, boxType, bytesMissing, progressive_mode);\n\n\t\tif (e >= 0) {\n\n\t\t} else if (e == GF_ISOM_INCOMPLETE_FILE) {\n\t\t\t/*our mdat is uncomplete, only valid for READ ONLY files...*/\n\t\t\tif (mov->openMode != GF_ISOM_OPEN_READ) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[iso file] Incomplete MDAT while file is not read-only\\n\"));\n\t\t\t\treturn GF_ISOM_INVALID_FILE;\n\t\t\t}\n\t\t\tif ((mov->openMode == GF_ISOM_OPEN_READ) && !progressive_mode) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[iso file] Incomplete file while reading for dump - aborting parsing\\n\"));\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\treturn e;\n\t\t} else {\n\t\t\treturn e;\n\t\t}\n\n\t\tswitch (a->type) {\n\t\t/*MOOV box*/\n\t\tcase GF_ISOM_BOX_TYPE_MOOV:\n\t\t\tif (mov->moov) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[iso file] Duplicate MOOV detected!\\n\"));\n\t\t\t\tgf_isom_box_del(a);\n\t\t\t\treturn GF_ISOM_INVALID_FILE;\n\t\t\t}\n\t\t\tmov->moov = (GF_MovieBox *)a;\n\t\t\tmov->original_moov_offset = mov->current_top_box_start;\n\t\t\t/*set our pointer to the movie*/\n\t\t\tmov->moov->mov = mov;\n#ifndef GPAC_DISABLE_ISOM_FRAGMENTS\n\t\t\tif (mov->moov->mvex) mov->moov->mvex->mov = mov;\n\n#ifdef GF_ENABLE_CTRN\n\t\t\tif (! (mov->FragmentsFlags & GF_ISOM_FRAG_READ_DEBUG)) {\n\t\t\t\tgf_isom_setup_traf_inheritance(mov);\n\t\t\t}\n#endif\n\n#endif\n\t\t\te = gf_list_add(mov->TopBoxes, a);\n\t\t\tif (e) return e;\n\n\t\t\ttotSize += a->size;\n\n            if (!mov->moov->mvhd) {\n                GF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[iso file] Missing MovieHeaderBox\\n\"));\n                return GF_ISOM_INVALID_FILE;\n            }\n\n            if (mov->meta) {\n\t\t\t\tgf_isom_meta_restore_items_ref(mov, mov->meta);\n\t\t\t}\n\n\t\t\t//dump senc info in dump mode\n\t\t\tif (mov->FragmentsFlags & GF_ISOM_FRAG_READ_DEBUG) {\n\t\t\t\tu32 k;\n\t\t\t\tfor (k=0; k<gf_list_count(mov->moov->trackList); k++) {\n\t\t\t\t\tGF_TrackBox *trak = (GF_TrackBox *)gf_list_get(mov->moov->trackList, k);\n\n\t\t\t\t\tif (trak->sample_encryption) {\n\t\t\t\t\t\te = senc_Parse(mov->movieFileMap->bs, trak, NULL, trak->sample_encryption);\n\t\t\t\t\t\tif (e) return e;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tu32 k;\n\t\t\t\tfor (k=0; k<gf_list_count(mov->moov->trackList); k++) {\n\t\t\t\t\tGF_TrackBox *trak = (GF_TrackBox *)gf_list_get(mov->moov->trackList, k);\n\t\t\t\t\tif (trak->Media->information->sampleTable->sampleGroups) {\n\t\t\t\t\t\tconvert_compact_sample_groups(trak->Media->information->sampleTable->child_boxes, trak->Media->information->sampleTable->sampleGroups);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n            if (mdat_end && mov->signal_frag_bounds && !(mov->FragmentsFlags & GF_ISOM_FRAG_READ_DEBUG) ) {\n                gf_isom_push_mdat_end(mov, mdat_end);\n                mdat_end=0;\n            }\n\t\t\tbreak;\n\n\t\t/*META box*/\n\t\tcase GF_ISOM_BOX_TYPE_META:\n\t\t\tif (mov->meta) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[iso file] Duplicate META detected!\\n\"));\n\t\t\t\tgf_isom_box_del(a);\n\t\t\t\treturn GF_ISOM_INVALID_FILE;\n\t\t\t}\n\t\t\tmov->meta = (GF_MetaBox *)a;\n\t\t\tmov->original_meta_offset = mov->current_top_box_start;\n\t\t\te = gf_list_add(mov->TopBoxes, a);\n\t\t\tif (e) {\n\t\t\t\treturn e;\n\t\t\t}\n\t\t\ttotSize += a->size;\n\t\t\tgf_isom_meta_restore_items_ref(mov, mov->meta);\n\t\t\tbreak;\n\n\t\t/*we only keep the MDAT in READ for dump purposes*/\n\t\tcase GF_ISOM_BOX_TYPE_MDAT:\n\t\t\tif (!mov->first_data_toplevel_offset) {\n\t\t\t\tmov->first_data_toplevel_offset = mov->current_top_box_start;\n\t\t\t\tmov->first_data_toplevel_size = a->size;\n\t\t\t}\n\t\t\ttotSize += a->size;\n\n#ifndef\tGPAC_DISABLE_ISOM_FRAGMENTS\n\t\t\tif (mov->emsgs) {\n\t\t\t\tgf_isom_box_array_del(mov->emsgs);\n\t\t\t\tmov->emsgs = NULL;\n\t\t\t}\n#endif\n\n\t\t\tif (mov->openMode == GF_ISOM_OPEN_READ) {\n\t\t\t\tif (!mov->mdat) {\n\t\t\t\t\tmov->mdat = (GF_MediaDataBox *) a;\n\t\t\t\t\te = gf_list_add(mov->TopBoxes, mov->mdat);\n\t\t\t\t\tif (e) {\n\t\t\t\t\t\treturn e;\n\t\t\t\t\t}\n\t\t\t\t}\n#ifndef\tGPAC_DISABLE_ISOM_FRAGMENTS\n\t\t\t\telse if (mov->FragmentsFlags & GF_ISOM_FRAG_READ_DEBUG) gf_list_add(mov->TopBoxes, a);\n#endif\n\t\t\t\telse gf_isom_box_del(a); //in other modes we don't care\n\n\n\t\t\t\tif (mov->signal_frag_bounds && !(mov->FragmentsFlags & GF_ISOM_FRAG_READ_DEBUG) ) {\n                    mdat_end = gf_bs_get_position(mov->movieFileMap->bs);\n                    if (mov->moov) {\n                        gf_isom_push_mdat_end(mov, mdat_end);\n                        mdat_end=0;\n                    }\n\t\t\t\t}\n\t\t\t}\n\t\t\t/*if we don't have any MDAT yet, create one (edit-write mode)\n\t\t\tWe only work with one mdat, but we're puting it at the place\n\t\t\tof the first mdat found when opening a file for editing*/\n\t\t\telse if (!mov->mdat && (mov->openMode != GF_ISOM_OPEN_READ) && (mov->openMode != GF_ISOM_OPEN_KEEP_FRAGMENTS)) {\n\t\t\t\tgf_isom_box_del(a);\n\t\t\t\tmov->mdat = (GF_MediaDataBox *) gf_isom_box_new(GF_ISOM_BOX_TYPE_MDAT);\n\t\t\t\tif (!mov->mdat) return GF_OUT_OF_MEM;\n\t\t\t\te = gf_list_add(mov->TopBoxes, mov->mdat);\n\t\t\t\tif (e) {\n\t\t\t\t\treturn e;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tgf_isom_box_del(a);\n\t\t\t}\n\t\t\tbreak;\n\t\tcase GF_ISOM_BOX_TYPE_FTYP:\n\t\t\t/*ONE AND ONLY ONE FTYP*/\n\t\t\tif (mov->brand) {\n\t\t\t\tgf_isom_box_del(a);\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[iso file] Duplicate 'ftyp' detected!\\n\"));\n\t\t\t\treturn GF_ISOM_INVALID_FILE;\n\t\t\t}\n\t\t\tmov->brand = (GF_FileTypeBox *)a;\n\t\t\ttotSize += a->size;\n\t\t\te = gf_list_add(mov->TopBoxes, a);\n\t\t\tif (e) return e;\n\t\t\tbreak;\n\n\t\tcase GF_ISOM_BOX_TYPE_OTYP:\n\t\t\t/*ONE AND ONLY ONE FTYP*/\n\t\t\tif (mov->otyp) {\n\t\t\t\tgf_isom_box_del(a);\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[iso file] Duplicate 'otyp' detected!\\n\"));\n\t\t\t\treturn GF_ISOM_INVALID_FILE;\n\t\t\t}\n\n\t\t\tif (mov->FragmentsFlags & GF_ISOM_FRAG_READ_DEBUG) {\n\t\t\t\tmov->otyp = (GF_Box *)a;\n\t\t\t\ttotSize += a->size;\n\t\t\t\te = gf_list_add(mov->TopBoxes, a);\n\t\t\t\tif (e) return e;\n\t\t\t} else {\n\t\t\t\tGF_FileTypeBox *brand = (GF_FileTypeBox *) gf_isom_box_find_child(a->child_boxes, GF_ISOM_BOX_TYPE_FTYP);\n\t\t\t\tif (brand) {\n\t\t\t\t\ts32 pos;\n\t\t\t\t\tgf_list_del_item(a->child_boxes, brand);\n\t\t\t\t\tpos = gf_list_del_item(mov->TopBoxes, mov->brand);\n\t\t\t\t\tgf_isom_box_del((GF_Box *) mov->brand);\n\t\t\t\t\tmov->brand = brand;\n\t\t\t\t\tif (pos<0) pos=0;\n\t\t\t\t\tgf_list_insert(mov->TopBoxes, brand, pos);\n\t\t\t\t}\n\t\t\t\tgf_isom_box_del(a);\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase GF_ISOM_BOX_TYPE_PDIN:\n\t\t\t/*ONE AND ONLY ONE PDIN*/\n\t\t\tif (mov->pdin) {\n\t\t\t\tgf_isom_box_del(a);\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[iso file] Duplicate 'pdin'' detected!\\n\"));\n\t\t\t\treturn GF_ISOM_INVALID_FILE;\n\t\t\t}\n\t\t\tmov->pdin = (GF_ProgressiveDownloadBox *) a;\n\t\t\ttotSize += a->size;\n\t\t\te = gf_list_add(mov->TopBoxes, a);\n\t\t\tif (e) return e;\n\t\t\tbreak;\n\n\n#ifndef\tGPAC_DISABLE_ISOM_FRAGMENTS\n\t\tcase GF_ISOM_BOX_TYPE_STYP:\n\t\t{\n\t\t\tu32 brand = ((GF_FileTypeBox *)a)->majorBrand;\n\t\t\tswitch (brand) {\n\t\t\tcase GF_ISOM_BRAND_SISX:\n\t\t\tcase GF_ISOM_BRAND_RISX:\n\t\t\tcase GF_ISOM_BRAND_SSSS:\n\t\t\t\tmov->is_index_segment = GF_TRUE;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\t/*fall-through*/\n\n\t\tcase GF_ISOM_BOX_TYPE_SIDX:\n\t\tcase GF_ISOM_BOX_TYPE_SSIX:\n\t\t\tif (mov->moov && !mov->first_data_toplevel_offset) {\n\t\t\t\tmov->first_data_toplevel_offset = mov->current_top_box_start;\n\t\t\t\tmov->first_data_toplevel_size = a->size;\n\t\t\t}\n\t\t\ttotSize += a->size;\n\t\t\tif (mov->FragmentsFlags & GF_ISOM_FRAG_READ_DEBUG) {\n\t\t\t\te = gf_list_add(mov->TopBoxes, a);\n\t\t\t\tif (e) return e;\n\t\t\t} else if (mov->signal_frag_bounds && !(mov->FragmentsFlags & GF_ISOM_FRAG_READ_DEBUG)  && (mov->openMode!=GF_ISOM_OPEN_KEEP_FRAGMENTS)\n\t\t\t) {\n\t\t\t\tif (a->type==GF_ISOM_BOX_TYPE_SIDX) {\n\t\t\t\t\tif (mov->root_sidx) gf_isom_box_del( (GF_Box *) mov->root_sidx);\n\t\t\t\t\tmov->root_sidx = (GF_SegmentIndexBox *) a;\n\t\t\t\t\tmov->sidx_start_offset = mov->current_top_box_start;\n\t\t\t\t\tmov->sidx_end_offset = gf_bs_get_position(mov->movieFileMap->bs);\n\n\t\t\t\t}\n\t\t\t\telse if (a->type==GF_ISOM_BOX_TYPE_STYP) {\n\t\t\t\t\tmov->styp_start_offset = mov->current_top_box_start;\n\n\t\t\t\t\tif (mov->seg_styp) gf_isom_box_del(mov->seg_styp);\n\t\t\t\t\tmov->seg_styp = a;\n\t\t\t\t} else if (a->type==GF_ISOM_BOX_TYPE_SSIX) {\n\t\t\t\t\tif (mov->seg_ssix) gf_isom_box_del(mov->seg_ssix);\n\t\t\t\t\tmov->seg_ssix = a;\n\t\t\t\t} else {\n\t\t\t\t\tgf_isom_box_del(a);\n\t\t\t\t}\n\t\t\t\tgf_isom_push_mdat_end(mov, mov->current_top_box_start);\n\t\t\t} else if (!mov->NextMoofNumber && (a->type==GF_ISOM_BOX_TYPE_SIDX)) {\n\t\t\t\tif (mov->main_sidx) gf_isom_box_del( (GF_Box *) mov->main_sidx);\n\t\t\t\tmov->main_sidx = (GF_SegmentIndexBox *) a;\n\t\t\t\tmov->main_sidx_end_pos = mov->current_top_box_start + a->size;\n\t\t\t} else {\n\t\t\t\tgf_isom_box_del(a);\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase GF_ISOM_BOX_TYPE_MOOF:\n\t\t\t//no support for inplace rewrite for fragmented files\n\t\t\tgf_isom_disable_inplace_rewrite(mov);\n\t\t\tif (!mov->moov) {\n\t\t\t\tGF_LOG(mov->moof ? GF_LOG_DEBUG : GF_LOG_WARNING, GF_LOG_CONTAINER, (\"[iso file] Movie fragment but no moov (yet) - possibly broken parsing!\\n\"));\n\t\t\t}\n\t\t\tif (mov->single_moof_mode) {\n\t\t\t\tmov->single_moof_state++;\n\t\t\t\tif (mov->single_moof_state > 1) {\n\t\t\t\t\tgf_isom_box_del(a);\n\t\t\t\t\treturn GF_OK;\n\t\t\t\t}\n\t\t\t}\n\t\t\t((GF_MovieFragmentBox *)a)->mov = mov;\n\n\t\t\ttotSize += a->size;\n\t\t\tmov->moof = (GF_MovieFragmentBox *) a;\n\n\t\t\t/*some smooth streaming streams contain a SDTP under the TRAF: this is incorrect, convert it*/\n\t\t\tFixTrackID(mov);\n\t\t\tif (! (mov->FragmentsFlags & GF_ISOM_FRAG_READ_DEBUG)) {\n\t\t\t\tFixSDTPInTRAF(mov->moof);\n\t\t\t} else {\n\t\t\t\tu32 k;\n\t\t\t\tfor (k=0; k<gf_list_count(mov->moof->TrackList); k++) {\n\t\t\t\t\tGF_TrackFragmentBox *traf = (GF_TrackFragmentBox *)gf_list_get(mov->moof->TrackList, k);\n\t\t\t\t\tif (traf->sampleGroups) {\n\t\t\t\t\t\tconvert_compact_sample_groups(traf->child_boxes, traf->sampleGroups);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t/*read & debug: store at root level*/\n\t\t\tif (mov->FragmentsFlags & GF_ISOM_FRAG_READ_DEBUG) {\n\t\t\t\tu32 k;\n\t\t\t\tgf_list_add(mov->TopBoxes, a);\n\t\t\t\t/*also update pointers to trex for debug*/\n\t\t\t\tif (mov->moov) {\n\t\t\t\t\tfor (k=0; k<gf_list_count(mov->moof->TrackList); k++) {\n\t\t\t\t\t\tGF_TrackFragmentBox *traf = gf_list_get(mov->moof->TrackList, k);\n\t\t\t\t\t\tif (traf->tfhd && mov->moov->mvex && mov->moov->mvex->TrackExList) {\n\t\t\t\t\t\t\tGF_TrackBox *trak = gf_isom_get_track_from_id(mov->moov, traf->tfhd->trackID);\n\t\t\t\t\t\t\tu32 j=0;\n\t\t\t\t\t\t\twhile ((traf->trex = (GF_TrackExtendsBox*)gf_list_enum(mov->moov->mvex->TrackExList, &j))) {\n\t\t\t\t\t\t\t\tif (traf->trex->trackID == traf->tfhd->trackID) {\n\t\t\t\t\t\t\t\t\tif (!traf->trex->track) traf->trex->track = trak;\n\t\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\ttraf->trex = NULL;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\t//we should only parse senc/psec when no saiz/saio is present, otherwise we fetch the info directly\n\t\t\t\t\t\tif (traf->trex && traf->tfhd && traf->trex->track && traf->sample_encryption) {\n\t\t\t\t\t\t\tGF_TrackBox *trak = GetTrackbyID(mov->moov, traf->tfhd->trackID);\n\t\t\t\t\t\t\tif (trak) {\n\t\t\t\t\t\t\t\ttrak->current_traf_stsd_idx = traf->tfhd->sample_desc_index ? traf->tfhd->sample_desc_index : traf->trex->def_sample_desc_index;\n\t\t\t\t\t\t\t\te = senc_Parse(mov->movieFileMap->bs, trak, traf, traf->sample_encryption);\n\t\t\t\t\t\t\t\tif (e) return e;\n\t\t\t\t\t\t\t\ttrak->current_traf_stsd_idx = 0;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tfor (k=0; k<gf_list_count(mov->moof->TrackList); k++) {\n\t\t\t\t\t\tGF_TrackFragmentBox *traf = gf_list_get(mov->moof->TrackList, k);\n\t\t\t\t\t\tif (traf->sample_encryption) {\n\t\t\t\t\t\t\te = senc_Parse(mov->movieFileMap->bs, NULL, traf, traf->sample_encryption);\n\t\t\t\t\t\t\tif (e) return e;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t}\n\t\t\t} else if (mov->openMode==GF_ISOM_OPEN_KEEP_FRAGMENTS) {\n\t\t\t\tmov->NextMoofNumber = mov->moof->mfhd->sequence_number+1;\n\t\t\t\tmov->moof = NULL;\n\t\t\t\tgf_isom_box_del(a);\n\t\t\t} else {\n\t\t\t\t/*merge all info*/\n\t\t\t\te = MergeFragment((GF_MovieFragmentBox *)a, mov);\n\t\t\t\tgf_isom_box_del(a);\n\t\t\t\tif (e) return e;\n\t\t\t}\n\n\t\t\t//done with moov\n\t\t\tif (mov->root_sidx) {\n\t\t\t\tgf_isom_box_del((GF_Box *) mov->root_sidx);\n\t\t\t\tmov->root_sidx = NULL;\n\t\t\t}\n\t\t\tif (mov->root_ssix) {\n\t\t\t\tgf_isom_box_del(mov->seg_ssix);\n\t\t\t\tmov->root_ssix = NULL;\n\t\t\t}\n\t\t\tif (mov->seg_styp) {\n\t\t\t\tgf_isom_box_del(mov->seg_styp);\n\t\t\t\tmov->seg_styp = NULL;\n\t\t\t}\n\t\t\tmov->sidx_start_offset = 0;\n\t\t\tmov->sidx_end_offset = 0;\n\t\t\tmov->styp_start_offset = 0;\n\t\t\tbreak;\n#endif\n\t\tcase GF_ISOM_BOX_TYPE_UNKNOWN:\n\t\t{\n\t\t\tGF_UnknownBox *box = (GF_UnknownBox*)a;\n\t\t\tif (box->original_4cc == GF_ISOM_BOX_TYPE_JP) {\n\t\t\t\tu8 *c = (u8 *) box->data;\n\t\t\t\tif ((box->dataSize==4) && (GF_4CC(c[0],c[1],c[2],c[3])==(u32)0x0D0A870A))\n\t\t\t\t\tmov->is_jp2 = 1;\n\t\t\t\tgf_isom_box_del(a);\n\t\t\t} else {\n\t\t\t\te = gf_list_add(mov->TopBoxes, a);\n\t\t\t\tif (e) return e;\n\t\t\t}\n\t\t}\n\t\tbreak;\n\n\t\tcase GF_ISOM_BOX_TYPE_PRFT:\n#ifndef GPAC_DISABLE_ISOM_FRAGMENTS\n\t\t\tif (!(mov->FragmentsFlags & GF_ISOM_FRAG_READ_DEBUG)) {\n\t\t\t\t//keep the last one read\n\t\t\t\tif (mov->last_producer_ref_time)\n\t\t\t\t\tgf_isom_box_del(a);\n\t\t\t\telse\n\t\t\t\t\tmov->last_producer_ref_time = (GF_ProducerReferenceTimeBox *)a;\n\t\t\t\tbreak;\n\t\t\t}\n#endif\n\t\t//fallthrough\n\t\tcase GF_ISOM_BOX_TYPE_EMSG:\n#ifndef GPAC_DISABLE_ISOM_FRAGMENTS\n\t\t\tif (! (mov->FragmentsFlags & GF_ISOM_FRAG_READ_DEBUG)) {\n\t\t\t\tif (!mov->emsgs) mov->emsgs = gf_list_new();\n\t\t\t\tgf_list_add(mov->emsgs, a);\n\t\t\t\tbreak;\n\t\t\t}\n#endif\n\t\tcase GF_ISOM_BOX_TYPE_MFRA:\n\t\tcase GF_ISOM_BOX_TYPE_MFRO:\n\t\t\t//only keep for dump mode, otherwise we ignore these boxes and we don't want to carry them over in non-fragmented file\n\t\t\tif (! (mov->FragmentsFlags & GF_ISOM_FRAG_READ_DEBUG)) {\n\t\t\t\ttotSize += a->size;\n\t\t\t\tgf_isom_box_del(a);\n\t\t\t\tbreak;\n\t\t\t}\n\t\tdefault:\n\t\t\ttotSize += a->size;\n\t\t\te = gf_list_add(mov->TopBoxes, a);\n\t\t\tif (e) return e;\n\t\t\tbreak;\n\t\t}\n\n#ifndef\tGPAC_DISABLE_ISOM_FRAGMENTS\n\t\t/*remember where we left, in case we append an entire number of movie fragments*/\n\t\tmov->current_top_box_start = gf_bs_get_position(mov->movieFileMap->bs) + mov->bytes_removed;\n#endif\n\t}\n\n\t/*we need at least moov or meta*/\n\tif (!mov->moov && !mov->meta\n#ifndef GPAC_DISABLE_ISOM_FRAGMENTS\n\t        && !mov->moof && !mov->is_index_segment\n#endif\n\t   ) {\n\t\treturn GF_ISOM_INCOMPLETE_FILE;\n\t}\n\t/*we MUST have movie header*/\n\tif (!gf_opts_get_bool(\"core\", \"no-check\")) {\n\t\tif (mov->moov && !mov->moov->mvhd) {\n\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[iso file] Missing MVHD in MOOV!\\n\"));\n\t\t\treturn GF_ISOM_INVALID_FILE;\n\t\t}\n\n\t\t/*we MUST have meta handler*/\n\t\tif (mov->meta && !mov->meta->handler) {\n\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[iso file] Missing handler in META!\\n\"));\n\t\t\treturn GF_ISOM_INVALID_FILE;\n\t\t}\n\t}\n\n#ifndef GPAC_DISABLE_ISOM_WRITE\n\n\tif (mov->moov) {\n\t\t/*set the default interleaving time*/\n\t\tmov->interleavingTime = mov->moov->mvhd->timeScale;\n\n#ifndef\tGPAC_DISABLE_ISOM_FRAGMENTS\n\t\t/*in edit mode with successfully loaded fragments, delete all fragment signaling since\n\t\tfile is no longer fragmented*/\n\t\tif ((mov->openMode > GF_ISOM_OPEN_READ) && (mov->openMode != GF_ISOM_OPEN_KEEP_FRAGMENTS) && mov->moov->mvex) {\n\t\t\tgf_isom_box_del_parent(&mov->moov->child_boxes, (GF_Box *)mov->moov->mvex);\n\t\t\tmov->moov->mvex = NULL;\n\t\t}\n#endif\n\n\t}\n\n\t//create a default mdat if none was found\n\tif (!mov->mdat && (mov->openMode != GF_ISOM_OPEN_READ) && (mov->openMode != GF_ISOM_OPEN_KEEP_FRAGMENTS)) {\n\t\tmov->mdat = (GF_MediaDataBox *) gf_isom_box_new(GF_ISOM_BOX_TYPE_MDAT);\n\t\tif (!mov->mdat) return GF_OUT_OF_MEM;\n\t\te = gf_list_add(mov->TopBoxes, mov->mdat);\n\t\tif (e) return e;\n\t}\n#endif /*GPAC_DISABLE_ISOM_WRITE*/\n\n\treturn GF_OK;\n}",
        "func_hash": 68912157747726016692935177449045975431,
        "file_name": "isom_intern.c",
        "file_hash": null,
        "cwe": [
            "CWE-476"
        ],
        "cve": "CVE-2022-29340",
        "cve_desc": "GPAC 2.1-DEV-rev87-g053aae8-master. has a Null Pointer Dereference vulnerability in gf_isom_parse_movie_boxes_internal due to improper return value handling of GF_SKIP_BOX, which causes a Denial of Service. This vulnerability was fixed in commit 37592ad.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-29340",
        "func_name": "gf_isom_parse_movie_boxes_internal",
        "diff": [
            "diff --git a/src/isomedia/box_funcs.c b/src/isomedia/box_funcs.c\nindex 310511db4e..7a79233fab 100644\n--- a/src/isomedia/box_funcs.c\n+++ b/src/isomedia/box_funcs.c\n@@ -310,8 +310,10 @@ GF_Err gf_isom_box_parse_ex(GF_Box **outBox, GF_BitStream *bs, u32 parent_type,\n \tif (e && (e != GF_ISOM_INCOMPLETE_FILE)) {\n \t\tgf_isom_box_del(newBox);\n \t\t*outBox = NULL;\n+\t\tif (is_root_box && (e==GF_SKIP_BOX))\n+\t\t\te = GF_ISOM_INVALID_FILE;\n \n-\t\tif (!skip_logs) {\n+\t\tif (!skip_logs && (e!=GF_SKIP_BOX)) {\n \t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[iso file] Read Box \\\"%s\\\" (start \"LLU\") failed (%s) - skipping\\n\", gf_4cc_to_str(type), start, gf_error_to_string(e)));\n \t\t}\n \t\t//we don't try to reparse known boxes that have been failing (too dangerous)\ndiff --git a/src/isomedia/isom_intern.c b/src/isomedia/isom_intern.c\nindex 09a720649a..242209c3fc 100644\n--- a/src/isomedia/isom_intern.c\n+++ b/src/isomedia/isom_intern.c\n@@ -373,7 +373,8 @@ static GF_Err gf_isom_parse_movie_boxes_internal(GF_ISOFile *mov, u32 *boxType,\n \t\te = gf_isom_parse_root_box(&a, mov->movieFileMap->bs, boxType, bytesMissing, progressive_mode);\n \n \t\tif (e >= 0) {\n-\n+\t\t\t//safety check, should never happen\n+\t\t\tif (!a) return GF_ISOM_INVALID_FILE;\n \t\t} else if (e == GF_ISOM_INCOMPLETE_FILE) {\n \t\t\t/*our mdat is uncomplete, only valid for READ ONLY files...*/\n \t\t\tif (mov->openMode != GF_ISOM_OPEN_READ) {\n"
        ],
        "func_after": []
    },
    {
        "idx": 195752,
        "project": "tensorflow",
        "commit_id": "02cc160e29d20631de3859c6653184e3f876b9d7",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/02cc160e29d20631de3859c6653184e3f876b9d7",
        "commit_message": "Prevent nullptr deref in SparseTensorSliceDataset\n\nThe arguments must determine a valid sparse tensor. This means that when indices are empty then the values must be empty too (and the reverse).\n\nAlso added test, by modifying existing test with empty sparse tensor to now run with an invalid sparse tensor input.\n\nPiperOrigin-RevId: 388562757\nChange-Id: Id8b54cd7c2316025b4f9a77292c8fb5344d17609",
        "target": 1,
        "irrelevant": 1,
        "func_before": "  void MakeDataset(OpKernelContext* ctx, DatasetBase** output) override {\n    // Create a new SparseTensorSliceDatasetOp::Dataset, insert it in\n    // the step container, and return it as the output.\n    const Tensor* indices;\n    OP_REQUIRES_OK(ctx, ctx->input(\"indices\", &indices));\n    const Tensor* values;\n    OP_REQUIRES_OK(ctx, ctx->input(\"values\", &values));\n    const Tensor* dense_shape;\n    OP_REQUIRES_OK(ctx, ctx->input(\"dense_shape\", &dense_shape));\n\n    OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(indices->shape()),\n                errors::InvalidArgument(\n                    \"Input indices should be a matrix but received shape \",\n                    indices->shape().DebugString()));\n    OP_REQUIRES(ctx, TensorShapeUtils::IsVector(values->shape()),\n                errors::InvalidArgument(\n                    \"Input values should be a vector but received shape \",\n                    indices->shape().DebugString()));\n    OP_REQUIRES(ctx, TensorShapeUtils::IsVector(dense_shape->shape()),\n                errors::InvalidArgument(\n                    \"Input shape should be a vector but received shape \",\n                    dense_shape->shape().DebugString()));\n\n    // We currently ensure that `sparse_tensor` is ordered in the\n    // batch dimension.\n    // TODO(mrry): Investigate ways to avoid this unconditional check\n    // if we can be sure that the sparse tensor was produced in an\n    // appropriate order (e.g. by `tf.parse_example()` or a Dataset\n    // that batches elements into rows of a SparseTensor).\n    int64_t previous_batch_index = -1;\n    for (int64_t i = 0; i < indices->dim_size(0); ++i) {\n      int64_t next_batch_index = indices->matrix<int64>()(i, 0);\n      OP_REQUIRES(\n          ctx, next_batch_index >= previous_batch_index,\n          errors::Unimplemented(\"The SparseTensor must be ordered in the batch \"\n                                \"dimension; handling arbitrarily ordered input \"\n                                \"is not currently supported.\"));\n      previous_batch_index = next_batch_index;\n    }\n    gtl::InlinedVector<int64, 8> std_order(dense_shape->NumElements(), 0);\n    sparse::SparseTensor tensor;\n    OP_REQUIRES_OK(\n        ctx, sparse::SparseTensor::Create(\n                 *indices, *values, TensorShape(dense_shape->vec<int64>()),\n                 std_order, &tensor));\n    *output = new Dataset<T>(ctx, std::move(tensor));\n  }",
        "func_hash": 111818826187244494245403789873500831419,
        "file_name": "sparse_tensor_slice_dataset_op.cc",
        "file_hash": 152047584060469134260687844063366554733,
        "cwe": [
            "CWE-476"
        ],
        "cve": "CVE-2021-37647",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. When a user does not supply arguments that determine a valid sparse tensor, `tf.raw_ops.SparseTensorSliceDataset` implementation can be made to dereference a null pointer. The [implementation](https://github.com/tensorflow/tensorflow/blob/8d72537c6abf5a44103b57b9c2e22c14f5f49698/tensorflow/core/kernels/data/sparse_tensor_slice_dataset_op.cc#L240-L251) has some argument validation but fails to consider the case when either `indices` or `values` are provided for an empty sparse tensor when the other is not. If `indices` is empty, then [code that performs validation](https://github.com/tensorflow/tensorflow/blob/8d72537c6abf5a44103b57b9c2e22c14f5f49698/tensorflow/core/kernels/data/sparse_tensor_slice_dataset_op.cc#L260-L261) (i.e., checking that the indices are monotonically increasing) results in a null pointer dereference. If `indices` as provided by the user is empty, then `indices` in the C++ code above is backed by an empty `std::vector`, hence calling `indices->dim_size(0)` results in null pointer dereferencing (same as calling `std::vector::at()` on an empty vector). We have patched the issue in GitHub commit 02cc160e29d20631de3859c6653184e3f876b9d7. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37647",
        "func_name": "MakeDataset",
        "diff": [
            "diff --git a/tensorflow/core/kernels/data/sparse_tensor_slice_dataset_op.cc b/tensorflow/core/kernels/data/sparse_tensor_slice_dataset_op.cc\nindex 00b71d41a7ca1e..58bb4b0b6d8065 100644\n--- a/tensorflow/core/kernels/data/sparse_tensor_slice_dataset_op.cc\n+++ b/tensorflow/core/kernels/data/sparse_tensor_slice_dataset_op.cc\n@@ -241,6 +241,17 @@ class SparseTensorSliceDatasetOp : public DatasetOpKernel {\n                 errors::InvalidArgument(\n                     \"Input indices should be a matrix but received shape \",\n                     indices->shape().DebugString()));\n+\n+    const auto num_indices = indices->NumElements();\n+    const auto num_values = values->NumElements();\n+    if (num_indices == 0 || num_values == 0) {\n+      OP_REQUIRES(ctx, num_indices == num_values,\n+                  errors::InvalidArgument(\n+                      \"If indices or values are empty, the other one must also \"\n+                      \"be. Got indices of shape \",\n+                      indices->shape().DebugString(), \" and values of shape \",\n+                      values->shape().DebugString()));\n+    }\n     OP_REQUIRES(ctx, TensorShapeUtils::IsVector(values->shape()),\n                 errors::InvalidArgument(\n                     \"Input values should be a vector but received shape \",\ndiff --git a/tensorflow/python/data/kernel_tests/from_sparse_tensor_slices_test.py b/tensorflow/python/data/kernel_tests/from_sparse_tensor_slices_test.py\nindex 25ecbf20680b3f..8f93530010caec 100644\n--- a/tensorflow/python/data/kernel_tests/from_sparse_tensor_slices_test.py\n+++ b/tensorflow/python/data/kernel_tests/from_sparse_tensor_slices_test.py\n@@ -118,6 +118,26 @@ def testEmptySparseTensorSlices(self):\n       with self.assertRaises(errors.OutOfRangeError):\n         sess.run(get_next)\n \n+  @combinations.generate(combinations.combine(tf_api_version=1, mode=[\"graph\"]))\n+  def testEmptySparseTensorSlicesInvalid(self):\n+    \"\"\"Test a dataset based on invalid `tf.sparse.SparseTensor`.\"\"\"\n+    st = array_ops.sparse_placeholder(dtypes.float64)\n+    iterator = dataset_ops.make_initializable_iterator(\n+        dataset_ops.Dataset.from_sparse_tensor_slices(st))\n+    init_op = iterator.initializer\n+\n+    with self.cached_session() as sess:\n+      # Test with an empty sparse tensor but with non empty values.\n+      empty_indices = np.empty((0, 4), dtype=np.int64)\n+      non_empty_values = [1, 2, 3, 4]\n+      empty_dense_shape = [0, 4, 37, 9]\n+      sparse_feed = sparse_tensor.SparseTensorValue(empty_indices,\n+                                                    non_empty_values,\n+                                                    empty_dense_shape)\n+      # Here, we expect the test to fail when running the feed.\n+      with self.assertRaises(errors.InvalidArgumentError):\n+        sess.run(init_op, feed_dict={st: sparse_feed})\n+\n   @combinations.generate(combinations.combine(tf_api_version=2, mode=[\"eager\"]))\n   def testFromSparseTensorSlicesError(self):\n     with self.assertRaises(AttributeError):\n"
        ],
        "func_after": []
    },
    {
        "idx": 195768,
        "project": "tensorflow",
        "commit_id": "8a84f7a2b5a2b27ecf88d25bad9ac777cd2f7992",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/8a84f7a2b5a2b27ecf88d25bad9ac777cd2f7992",
        "commit_message": "Ensure num_streams >= 0 in tf.raw_ops.BoostedTreesCreateQuantileStreamResource\n\nPiperOrigin-RevId: 387452765\nChange-Id: I9990c760e177fabca6a3b9b4612ceeaeeba51495",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext* context) override {\n    // Only create one, if one does not exist already. Report status for all\n    // other exceptions. If one already exists, it unrefs the new one.\n    // An epsilon value of zero could cause performance issues and is therefore,\n    // disallowed.\n    const Tensor* epsilon_t;\n    OP_REQUIRES_OK(context, context->input(kEpsilonName, &epsilon_t));\n    float epsilon = epsilon_t->scalar<float>()();\n    OP_REQUIRES(\n        context, epsilon > 0,\n        errors::InvalidArgument(\"An epsilon value of zero is not allowed.\"));\n\n    const Tensor* num_streams_t;\n    OP_REQUIRES_OK(context, context->input(kNumStreamsName, &num_streams_t));\n    int64_t num_streams = num_streams_t->scalar<int64>()();\n\n    auto result =\n        new QuantileStreamResource(epsilon, max_elements_, num_streams);\n    auto status = CreateResource(context, HandleFromInput(context, 0), result);\n    if (!status.ok() && status.code() != tensorflow::error::ALREADY_EXISTS) {\n      OP_REQUIRES(context, false, status);\n    }\n  }",
        "func_hash": 313445736659793184747687838118492710807,
        "file_name": "quantile_ops.cc",
        "file_hash": 107616464713850423069668018637690909159,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2021-37661",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions an attacker can cause a denial of service in `boosted_trees_create_quantile_stream_resource` by using negative arguments. The [implementation](https://github.com/tensorflow/tensorflow/blob/84d053187cb80d975ef2b9684d4b61981bca0c41/tensorflow/core/kernels/boosted_trees/quantile_ops.cc#L96) does not validate that `num_streams` only contains non-negative numbers. In turn, [this results in using this value to allocate memory](https://github.com/tensorflow/tensorflow/blob/84d053187cb80d975ef2b9684d4b61981bca0c41/tensorflow/core/kernels/boosted_trees/quantiles/quantile_stream_resource.h#L31-L40). However, `reserve` receives an unsigned integer so there is an implicit conversion from a negative value to a large positive unsigned. This results in a crash from the standard library. We have patched the issue in GitHub commit 8a84f7a2b5a2b27ecf88d25bad9ac777cd2f7992. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37661",
        "func_name": "Compute",
        "diff": [
            "diff --git a/tensorflow/core/kernels/boosted_trees/quantile_ops.cc b/tensorflow/core/kernels/boosted_trees/quantile_ops.cc\nindex c245b25aab0fbf..13a0056060e92a 100644\n--- a/tensorflow/core/kernels/boosted_trees/quantile_ops.cc\n+++ b/tensorflow/core/kernels/boosted_trees/quantile_ops.cc\n@@ -116,6 +116,9 @@ class BoostedTreesCreateQuantileStreamResourceOp : public OpKernel {\n     const Tensor* num_streams_t;\n     OP_REQUIRES_OK(context, context->input(kNumStreamsName, &num_streams_t));\n     int64_t num_streams = num_streams_t->scalar<int64>()();\n+    OP_REQUIRES(context, num_streams >= 0,\n+                errors::InvalidArgument(\n+                    \"Num_streams input cannot be a negative integer\"));\n \n     auto result =\n         new QuantileStreamResource(epsilon, max_elements_, num_streams);\n"
        ],
        "func_after": []
    },
    {
        "idx": 195800,
        "project": "deark",
        "commit_id": "62acb7753b0e3c0d3ab3c15057b0a65222313334",
        "project_url": "https://github.com/jsummers/deark",
        "commit_url": "https://github.com/jsummers/deark/commit/62acb7753b0e3c0d3ab3c15057b0a65222313334",
        "commit_message": "pict,macrsrc: Fixed a bug that could cause division by 0\n\nFound by F. \u00c7elik.",
        "target": 1,
        "irrelevant": 1,
        "func_before": "void fmtutil_macbitmap_read_pixmap_only_fields(deark *c, dbuf *f, struct fmtutil_macbitmap_info *bi,\n\ti64 pos)\n{\n\ti64 pixmap_version;\n\ti64 pack_size;\n\ti64 plane_bytes;\n\ti64 n;\n\n\tde_dbg(c, \"additional PixMap header fields, at %d\", (int)pos);\n\tde_dbg_indent(c, 1);\n\n\tpixmap_version = dbuf_getu16be(f, pos+0);\n\tde_dbg(c, \"pixmap version: %d\", (int)pixmap_version);\n\n\tbi->packing_type = dbuf_getu16be(f, pos+2);\n\tde_dbg(c, \"packing type: %d\", (int)bi->packing_type);\n\n\tpack_size = dbuf_getu32be(f, pos+4);\n\tde_dbg(c, \"pixel data length: %d\", (int)pack_size);\n\n\tbi->hdpi = pict_read_fixed(f, pos+8);\n\tbi->vdpi = pict_read_fixed(f, pos+12);\n\tde_dbg(c, \"dpi: %.2f\"DE_CHAR_TIMES\"%.2f\", bi->hdpi, bi->vdpi);\n\n\tbi->pixeltype = dbuf_getu16be(f, pos+16);\n\tbi->pixelsize = dbuf_getu16be(f, pos+18);\n\tbi->cmpcount = dbuf_getu16be(f, pos+20);\n\tbi->cmpsize = dbuf_getu16be(f, pos+22);\n\tde_dbg(c, \"pixel type=%d, bits/pixel=%d, components/pixel=%d, bits/comp=%d\",\n\t\t(int)bi->pixeltype, (int)bi->pixelsize, (int)bi->cmpcount, (int)bi->cmpsize);\n\n\tbi->pdwidth = (bi->rowbytes*8)/bi->pixelsize;\n\tif(bi->pdwidth < bi->npwidth) {\n\t\tbi->pdwidth = bi->npwidth;\n\t}\n\n\tplane_bytes = dbuf_getu32be(f, pos+24);\n\tde_dbg(c, \"plane bytes: %d\", (int)plane_bytes);\n\n\tbi->pmTable = (u32)dbuf_getu32be(f, pos+28);\n\tde_dbg(c, \"pmTable: 0x%08x\", (unsigned int)bi->pmTable);\n\n\tn = dbuf_getu32be(f, pos+32);\n\tde_dbg(c, \"pmReserved: 0x%08x\", (unsigned int)n);\n\n\tde_dbg_indent(c, -1);\n}",
        "func_hash": 203544519943268578056087775697493086183,
        "file_name": "fmtutil.c",
        "file_hash": 198892381443353894699781903058114971913,
        "cwe": [
            "CWE-369"
        ],
        "cve": "CVE-2021-28856",
        "cve_desc": "In Deark before v1.5.8, a specially crafted input file can cause a division by zero in (src/fmtutil.c) because of the value of pixelsize.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-28856",
        "func_name": "fmtutil_macbitmap_read_pixmap_only_fields",
        "diff": [
            "diff --git a/src/fmtutil.c b/src/fmtutil.c\nindex f7e9ac1b..ab728413 100644\n--- a/src/fmtutil.c\n+++ b/src/fmtutil.c\n@@ -1618,7 +1618,9 @@ void fmtutil_macbitmap_read_pixmap_only_fields(deark *c, dbuf *f, struct fmtutil\n \tde_dbg(c, \"pixel type=%d, bits/pixel=%d, components/pixel=%d, bits/comp=%d\",\n \t\t(int)bi->pixeltype, (int)bi->pixelsize, (int)bi->cmpcount, (int)bi->cmpsize);\n \n-\tbi->pdwidth = (bi->rowbytes*8)/bi->pixelsize;\n+\tif(bi->pixelsize>0) {\n+\t\tbi->pdwidth = (bi->rowbytes*8)/bi->pixelsize;\n+\t}\n \tif(bi->pdwidth < bi->npwidth) {\n \t\tbi->pdwidth = bi->npwidth;\n \t}\n"
        ],
        "func_after": []
    },
    {
        "idx": 195801,
        "project": "php-src",
        "commit_id": "0c8a2a2cd1056b7dc403eacb5d2c0eec6ce47c6f",
        "project_url": "https://github.com/php/php-src",
        "commit_url": "https://github.com/php/php-src/commit/0c8a2a2cd1056b7dc403eacb5d2c0eec6ce47c6f",
        "commit_message": "Fix for bug #72790 and bug #72799\n\n(cherry picked from commit a14fdb9746262549bbbb96abb87338bacd147e1b)\n\nConflicts:\n\text/wddx/wddx.c",
        "target": 1,
        "irrelevant": 0,
        "func_before": " */\nstatic void php_wddx_pop_element(void *user_data, const XML_Char *name)\n{\n\tst_entry \t\t\t*ent1, *ent2;\n\twddx_stack \t\t\t*stack = (wddx_stack *)user_data;\n\tHashTable \t\t\t*target_hash;\n\tzend_class_entry \t*pce;\n\tzval\t\t\t\tobj;\n\n/* OBJECTS_FIXME */\n\tif (stack->top == 0) {\n\t\treturn;\n\t}\n\n\tif (!strcmp((char *)name, EL_STRING) || !strcmp((char *)name, EL_NUMBER) ||\n\t\t!strcmp((char *)name, EL_BOOLEAN) || !strcmp((char *)name, EL_NULL) ||\n\t  \t!strcmp((char *)name, EL_ARRAY) || !strcmp((char *)name, EL_STRUCT) ||\n\t\t!strcmp((char *)name, EL_RECORDSET) || !strcmp((char *)name, EL_BINARY) ||\n\t\t!strcmp((char *)name, EL_DATETIME)) {\n\t\twddx_stack_top(stack, (void**)&ent1);\n\n\t\tif (Z_TYPE(ent1->data) == IS_UNDEF) {\n\t\t\tif (stack->top > 1) {\n\t\t\t\tstack->top--;\n\t\t\t} else {\n\t\t\t\tstack->done = 1;\n\t\t\t}\n\t\t\tefree(ent1);\n\t\t\treturn;\n\t\t}\n\n\t\tif (!strcmp((char *)name, EL_BINARY)) {\n\t\t\tzend_string *new_str = php_base64_decode(\n\t\t\t\t(unsigned char *)Z_STRVAL(ent1->data), Z_STRLEN(ent1->data));\n\t\t\tzval_ptr_dtor(&ent1->data);\n\t\t\tZVAL_STR(&ent1->data, new_str);\n\t\t}\n\n\t\t/* Call __wakeup() method on the object. */\n\t\tif (Z_TYPE(ent1->data) == IS_OBJECT) {\n\t\t\tzval fname, retval;\n\n\t\t\tZVAL_STRING(&fname, \"__wakeup\");\n\n\t\t\tcall_user_function_ex(NULL, &ent1->data, &fname, &retval, 0, 0, 0, NULL);\n\n\t\t\tzval_ptr_dtor(&fname);\n\t\t\tzval_ptr_dtor(&retval);\n\t\t}\n\n\t\tif (stack->top > 1) {\n\t\t\tstack->top--;\n\t\t\twddx_stack_top(stack, (void**)&ent2);\n\n\t\t\t/* if non-existent field */\n\t\t\tif (ent2->type == ST_FIELD && Z_ISUNDEF(ent2->data)) {\n\t\t\t\tzval_ptr_dtor(&ent1->data);\n\t\t\t\tefree(ent1);\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tif (Z_TYPE(ent2->data) == IS_ARRAY || Z_TYPE(ent2->data) == IS_OBJECT) {\n\t\t\t\ttarget_hash = HASH_OF(&ent2->data);\n\n\t\t\t\tif (ent1->varname) {\n\t\t\t\t\tif (!strcmp(ent1->varname, PHP_CLASS_NAME_VAR) &&\n\t\t\t\t\t\tZ_TYPE(ent1->data) == IS_STRING && Z_STRLEN(ent1->data) &&\n\t\t\t\t\t\tent2->type == ST_STRUCT && Z_TYPE(ent2->data) == IS_ARRAY) {\n\t\t\t\t\t\tzend_bool incomplete_class = 0;\n\n\t\t\t\t\t\tzend_str_tolower(Z_STRVAL(ent1->data), Z_STRLEN(ent1->data));\n\t\t\t\t\t\tzend_string_forget_hash_val(Z_STR(ent1->data));\n\t\t\t\t\t\tif ((pce = zend_hash_find_ptr(EG(class_table), Z_STR(ent1->data))) == NULL) {\n\t\t\t\t\t\t\tincomplete_class = 1;\n\t\t\t\t\t\t\tpce = PHP_IC_ENTRY;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t/* Initialize target object */\n\t\t\t\t\t\tobject_init_ex(&obj, pce);\n\n\t\t\t\t\t\t/* Merge current hashtable with object's default properties */\n\t\t\t\t\t\tzend_hash_merge(Z_OBJPROP(obj),\n\t\t\t\t\t\t\t\t\t\tZ_ARRVAL(ent2->data),\n\t\t\t\t\t\t\t\t\t\tzval_add_ref, 0);\n\n\t\t\t\t\t\tif (incomplete_class) {\n\t\t\t\t\t\t\tphp_store_class_name(&obj, Z_STRVAL(ent1->data), Z_STRLEN(ent1->data));\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t/* Clean up old array entry */\n\t\t\t\t\t\tzval_ptr_dtor(&ent2->data);\n\n\t\t\t\t\t\t/* Set stack entry to point to the newly created object */\n\t\t\t\t\t\tZVAL_COPY_VALUE(&ent2->data, &obj);\n\n\t\t\t\t\t\t/* Clean up class name var entry */\n\t\t\t\t\t\tzval_ptr_dtor(&ent1->data);\n\t\t\t\t\t} else if (Z_TYPE(ent2->data) == IS_OBJECT) {\n\t\t\t\t\t\tzend_class_entry *old_scope = EG(scope);\n\n\t\t\t\t\t\tEG(scope) = Z_OBJCE(ent2->data);\n\t\t\t\t\t\tadd_property_zval(&ent2->data, ent1->varname, &ent1->data);\n\t\t\t\t\t\tif Z_REFCOUNTED(ent1->data) Z_DELREF(ent1->data);\n\t\t\t\t\t\tEG(scope) = old_scope;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tzend_symtable_str_update(target_hash, ent1->varname, strlen(ent1->varname), &ent1->data);\n\t\t\t\t\t}\n\t\t\t\t\tefree(ent1->varname);\n\t\t\t\t} else\t{\n\t\t\t\t\tzend_hash_next_index_insert(target_hash, &ent1->data);\n\t\t\t\t}\n\t\t\t}\n\t\t\tefree(ent1);\n\t\t} else {\n\t\t\tstack->done = 1;\n\t\t}\n\t} else if (!strcmp((char *)name, EL_VAR) && stack->varname) {\n\t\tefree(stack->varname);\n\t\tstack->varname = NULL;\n\t} else if (!strcmp((char *)name, EL_FIELD)) {\n\t\tst_entry *ent;\n\t\twddx_stack_top(stack, (void **)&ent);\n\t\tefree(ent);\n\t\tstack->top--;\n\t}",
        "func_hash": 195456627139063255714886732829389598772,
        "file_name": "wddx.c",
        "file_hash": 202333767268853724294318351879930678985,
        "cwe": [
            "CWE-476"
        ],
        "cve": "CVE-2016-7132",
        "cve_desc": "ext/wddx/wddx.c in PHP before 5.6.25 and 7.x before 7.0.10 allows remote attackers to cause a denial of service (NULL pointer dereference and application crash) or possibly have unspecified other impact via an invalid wddxPacket XML document that is mishandled in a wddx_deserialize call, as demonstrated by a stray element inside a boolean element, leading to incorrect pop processing.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2016-7132",
        "func_name": "php_wddx_pop_element",
        "diff": [
            "diff --git a/ext/wddx/tests/bug72790.phpt b/ext/wddx/tests/bug72790.phpt\nnew file mode 100644\nindex 0000000000000..a60524bdaf19e\n--- /dev/null\n+++ b/ext/wddx/tests/bug72790.phpt\n@@ -0,0 +1,35 @@\n+--TEST--\n+Bug 72790: wddx_deserialize null dereference with invalid xml\n+--SKIPIF--\n+<?php\n+if (!extension_loaded('wddx')) {\n+    die('skip. wddx not available');\n+}\n+?>\n+--FILE--\n+<?php\n+\n+$xml = <<< XML\n+<?xml version='1.0' ?>\n+<!DOCTYPE wddxPacket SYSTEM 'wddx_0100.dtd'>\n+<wddxPacket version='1.0'>\n+        |array>\n+                <var name=\"XXXX\">\n+                        <boolean value=\"this\">\n+                        </boolean>\n+                </var>\n+                <var name=\"YYYY\">\n+                        <var name=\"UUUU\">\n+                                <var name=\"EZEZ\">\n+                                </var>\n+                        </var>\n+                </var>\n+        </array>\n+</wddxPacket>\n+XML;\n+\n+$array = wddx_deserialize($xml);\n+var_dump($array);\n+?>\n+--EXPECT--\n+NULL\n\\ No newline at end of file\ndiff --git a/ext/wddx/tests/bug72799.phpt b/ext/wddx/tests/bug72799.phpt\nnew file mode 100644\nindex 0000000000000..5861d5538f49f\n--- /dev/null\n+++ b/ext/wddx/tests/bug72799.phpt\n@@ -0,0 +1,28 @@\n+--TEST--\n+Bug #72799: wddx_deserialize null dereference in php_wddx_pop_element\n+--SKIPIF--\n+<?php\n+if (!extension_loaded('wddx')) {\n+    die('skip. wddx not available');\n+}\n+?>\n+--FILE--\n+<?php\n+\n+$xml = <<<XML\n+<?xml version='1.0'?>\n+<!DOCTYPE wddxPacket SYSTEM 'wddx_0100.dtd'>\n+<wddxPacket version=\"1.0\">\n+    <var name=\"XXXX\">\n+        <boolean value=\"1\">\n+            <dateTime>1998-06-12T04:32:12+00</dateTime>\n+        </boolean>\n+    </var>\n+</wddxPacket>\n+XML;\n+\n+$array = wddx_deserialize($xml);\n+var_dump($array);\n+?>\n+--EXPECT--\n+NULL\n\\ No newline at end of file\ndiff --git a/ext/wddx/wddx.c b/ext/wddx/wddx.c\nindex d28cb7a0acbef..11cf0be62e30c 100644\n--- a/ext/wddx/wddx.c\n+++ b/ext/wddx/wddx.c\n@@ -886,10 +886,10 @@ static void php_wddx_pop_element(void *user_data, const XML_Char *name)\n \t\tif (Z_TYPE(ent1->data) == IS_UNDEF) {\n \t\t\tif (stack->top > 1) {\n \t\t\t\tstack->top--;\n+\t\t\t\tefree(ent1);\n \t\t\t} else {\n \t\t\t\tstack->done = 1;\n \t\t\t}\n-\t\t\tefree(ent1);\n \t\t\treturn;\n \t\t}\n \n"
        ],
        "func_after": []
    },
    {
        "idx": 195908,
        "project": "linux",
        "commit_id": "e4571b8c5e9ffa1e85c0c671995bd4dcc5c75091",
        "project_url": "https://github.com/torvalds/linux",
        "commit_url": "https://github.com/torvalds/linux/commit/e4571b8c5e9ffa1e85c0c671995bd4dcc5c75091",
        "commit_message": "btrfs: fix NULL pointer dereference when deleting device by invalid id\n\n[BUG]\nIt's easy to trigger NULL pointer dereference, just by removing a\nnon-existing device id:\n\n # mkfs.btrfs -f -m single -d single /dev/test/scratch1 \\\n\t\t\t\t     /dev/test/scratch2\n # mount /dev/test/scratch1 /mnt/btrfs\n # btrfs device remove 3 /mnt/btrfs\n\nThen we have the following kernel NULL pointer dereference:\n\n BUG: kernel NULL pointer dereference, address: 0000000000000000\n #PF: supervisor read access in kernel mode\n #PF: error_code(0x0000) - not-present page\n PGD 0 P4D 0\n Oops: 0000 [#1] PREEMPT SMP NOPTI\n CPU: 9 PID: 649 Comm: btrfs Not tainted 5.14.0-rc3-custom+ #35\n Hardware name: QEMU Standard PC (Q35 + ICH9, 2009), BIOS 0.0.0 02/06/2015\n RIP: 0010:btrfs_rm_device+0x4de/0x6b0 [btrfs]\n  btrfs_ioctl+0x18bb/0x3190 [btrfs]\n  ? lock_is_held_type+0xa5/0x120\n  ? find_held_lock.constprop.0+0x2b/0x80\n  ? do_user_addr_fault+0x201/0x6a0\n  ? lock_release+0xd2/0x2d0\n  ? __x64_sys_ioctl+0x83/0xb0\n  __x64_sys_ioctl+0x83/0xb0\n  do_syscall_64+0x3b/0x90\n  entry_SYSCALL_64_after_hwframe+0x44/0xae\n\n[CAUSE]\nCommit a27a94c2b0c7 (\"btrfs: Make btrfs_find_device_by_devspec return\nbtrfs_device directly\") moves the \"missing\" device path check into\nbtrfs_rm_device().\n\nBut btrfs_rm_device() itself can have case where it only receives\n@devid, with NULL as @device_path.\n\nIn that case, calling strcmp() on NULL will trigger the NULL pointer\ndereference.\n\nBefore that commit, we handle the \"missing\" case inside\nbtrfs_find_device_by_devspec(), which will not check @device_path at all\nif @devid is provided, thus no way to trigger the bug.\n\n[FIX]\nBefore calling strcmp(), also make sure @device_path is not NULL.\n\nFixes: a27a94c2b0c7 (\"btrfs: Make btrfs_find_device_by_devspec return btrfs_device directly\")\nCC: stable@vger.kernel.org # 5.4+\nReported-by: butt3rflyh4ck <butterflyhuangxx@gmail.com>\nReviewed-by: Anand Jain <anand.jain@oracle.com>\nSigned-off-by: Qu Wenruo <wqu@suse.com>\nReviewed-by: David Sterba <dsterba@suse.com>\nSigned-off-by: David Sterba <dsterba@suse.com>",
        "target": 1,
        "irrelevant": 1,
        "func_before": "int btrfs_rm_device(struct btrfs_fs_info *fs_info, const char *device_path,\n\t\t    u64 devid)\n{\n\tstruct btrfs_device *device;\n\tstruct btrfs_fs_devices *cur_devices;\n\tstruct btrfs_fs_devices *fs_devices = fs_info->fs_devices;\n\tu64 num_devices;\n\tint ret = 0;\n\n\tmutex_lock(&uuid_mutex);\n\n\tnum_devices = btrfs_num_devices(fs_info);\n\n\tret = btrfs_check_raid_min_devices(fs_info, num_devices - 1);\n\tif (ret)\n\t\tgoto out;\n\n\tdevice = btrfs_find_device_by_devspec(fs_info, devid, device_path);\n\n\tif (IS_ERR(device)) {\n\t\tif (PTR_ERR(device) == -ENOENT &&\n\t\t    strcmp(device_path, \"missing\") == 0)\n\t\t\tret = BTRFS_ERROR_DEV_MISSING_NOT_FOUND;\n\t\telse\n\t\t\tret = PTR_ERR(device);\n\t\tgoto out;\n\t}\n\n\tif (btrfs_pinned_by_swapfile(fs_info, device)) {\n\t\tbtrfs_warn_in_rcu(fs_info,\n\t\t  \"cannot remove device %s (devid %llu) due to active swapfile\",\n\t\t\t\t  rcu_str_deref(device->name), device->devid);\n\t\tret = -ETXTBSY;\n\t\tgoto out;\n\t}\n\n\tif (test_bit(BTRFS_DEV_STATE_REPLACE_TGT, &device->dev_state)) {\n\t\tret = BTRFS_ERROR_DEV_TGT_REPLACE;\n\t\tgoto out;\n\t}\n\n\tif (test_bit(BTRFS_DEV_STATE_WRITEABLE, &device->dev_state) &&\n\t    fs_info->fs_devices->rw_devices == 1) {\n\t\tret = BTRFS_ERROR_DEV_ONLY_WRITABLE;\n\t\tgoto out;\n\t}\n\n\tif (test_bit(BTRFS_DEV_STATE_WRITEABLE, &device->dev_state)) {\n\t\tmutex_lock(&fs_info->chunk_mutex);\n\t\tlist_del_init(&device->dev_alloc_list);\n\t\tdevice->fs_devices->rw_devices--;\n\t\tmutex_unlock(&fs_info->chunk_mutex);\n\t}\n\n\tmutex_unlock(&uuid_mutex);\n\tret = btrfs_shrink_device(device, 0);\n\tif (!ret)\n\t\tbtrfs_reada_remove_dev(device);\n\tmutex_lock(&uuid_mutex);\n\tif (ret)\n\t\tgoto error_undo;\n\n\t/*\n\t * TODO: the superblock still includes this device in its num_devices\n\t * counter although write_all_supers() is not locked out. This\n\t * could give a filesystem state which requires a degraded mount.\n\t */\n\tret = btrfs_rm_dev_item(device);\n\tif (ret)\n\t\tgoto error_undo;\n\n\tclear_bit(BTRFS_DEV_STATE_IN_FS_METADATA, &device->dev_state);\n\tbtrfs_scrub_cancel_dev(device);\n\n\t/*\n\t * the device list mutex makes sure that we don't change\n\t * the device list while someone else is writing out all\n\t * the device supers. Whoever is writing all supers, should\n\t * lock the device list mutex before getting the number of\n\t * devices in the super block (super_copy). Conversely,\n\t * whoever updates the number of devices in the super block\n\t * (super_copy) should hold the device list mutex.\n\t */\n\n\t/*\n\t * In normal cases the cur_devices == fs_devices. But in case\n\t * of deleting a seed device, the cur_devices should point to\n\t * its own fs_devices listed under the fs_devices->seed.\n\t */\n\tcur_devices = device->fs_devices;\n\tmutex_lock(&fs_devices->device_list_mutex);\n\tlist_del_rcu(&device->dev_list);\n\n\tcur_devices->num_devices--;\n\tcur_devices->total_devices--;\n\t/* Update total_devices of the parent fs_devices if it's seed */\n\tif (cur_devices != fs_devices)\n\t\tfs_devices->total_devices--;\n\n\tif (test_bit(BTRFS_DEV_STATE_MISSING, &device->dev_state))\n\t\tcur_devices->missing_devices--;\n\n\tbtrfs_assign_next_active_device(device, NULL);\n\n\tif (device->bdev) {\n\t\tcur_devices->open_devices--;\n\t\t/* remove sysfs entry */\n\t\tbtrfs_sysfs_remove_device(device);\n\t}\n\n\tnum_devices = btrfs_super_num_devices(fs_info->super_copy) - 1;\n\tbtrfs_set_super_num_devices(fs_info->super_copy, num_devices);\n\tmutex_unlock(&fs_devices->device_list_mutex);\n\n\t/*\n\t * at this point, the device is zero sized and detached from\n\t * the devices list.  All that's left is to zero out the old\n\t * supers and free the device.\n\t */\n\tif (test_bit(BTRFS_DEV_STATE_WRITEABLE, &device->dev_state))\n\t\tbtrfs_scratch_superblocks(fs_info, device->bdev,\n\t\t\t\t\t  device->name->str);\n\n\tbtrfs_close_bdev(device);\n\tsynchronize_rcu();\n\tbtrfs_free_device(device);\n\n\tif (cur_devices->open_devices == 0) {\n\t\tlist_del_init(&cur_devices->seed_list);\n\t\tclose_fs_devices(cur_devices);\n\t\tfree_fs_devices(cur_devices);\n\t}\n\nout:\n\tmutex_unlock(&uuid_mutex);\n\treturn ret;\n\nerror_undo:\n\tbtrfs_reada_undo_remove_dev(device);\n\tif (test_bit(BTRFS_DEV_STATE_WRITEABLE, &device->dev_state)) {\n\t\tmutex_lock(&fs_info->chunk_mutex);\n\t\tlist_add(&device->dev_alloc_list,\n\t\t\t &fs_devices->alloc_list);\n\t\tdevice->fs_devices->rw_devices++;\n\t\tmutex_unlock(&fs_info->chunk_mutex);\n\t}\n\tgoto out;\n}",
        "func_hash": 109862119097507194285189243526662049352,
        "file_name": "volumes.c",
        "file_hash": 327977751785202812455417482244318484271,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2021-3739",
        "cve_desc": "A NULL pointer dereference flaw was found in the btrfs_rm_device function in fs/btrfs/volumes.c in the Linux Kernel, where triggering the bug requires \u2018CAP_SYS_ADMIN\u2019. This flaw allows a local attacker to crash the system or leak kernel internal information. The highest threat from this vulnerability is to system availability.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-3739",
        "func_name": "btrfs_rm_device",
        "diff": [
            "diff --git a/fs/btrfs/volumes.c b/fs/btrfs/volumes.c\nindex 536e60c6ade3cb..7fec0c68b744b9 100644\n--- a/fs/btrfs/volumes.c\n+++ b/fs/btrfs/volumes.c\n@@ -2074,7 +2074,7 @@ int btrfs_rm_device(struct btrfs_fs_info *fs_info, const char *device_path,\n \n \tif (IS_ERR(device)) {\n \t\tif (PTR_ERR(device) == -ENOENT &&\n-\t\t    strcmp(device_path, \"missing\") == 0)\n+\t\t    device_path && strcmp(device_path, \"missing\") == 0)\n \t\t\tret = BTRFS_ERROR_DEV_MISSING_NOT_FOUND;\n \t\telse\n \t\t\tret = PTR_ERR(device);\n"
        ],
        "func_after": []
    },
    {
        "idx": 195909,
        "project": "ImageMagick",
        "commit_id": "d072ed6aff835c174e856ce3a428163c0da9e8f4",
        "project_url": "https://github.com/ImageMagick/ImageMagick",
        "commit_url": "https://github.com/ImageMagick/ImageMagick/commit/d072ed6aff835c174e856ce3a428163c0da9e8f4",
        "commit_message": "Skip MNG CLIP chunk with out-of-range object IDs",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static Image *ReadOneMNGImage(MngInfo* mng_info, const ImageInfo *image_info,\n     ExceptionInfo *exception)\n{\n  char\n    page_geometry[MagickPathExtent];\n\n  Image\n    *image;\n\n  MagickBooleanType\n    logging;\n\n  volatile int\n    first_mng_object,\n    object_id,\n    term_chunk_found,\n    skip_to_iend;\n\n  volatile ssize_t\n    image_count=0;\n\n  MagickBooleanType\n    status;\n\n  MagickOffsetType\n    offset;\n\n  MngBox\n    default_fb,\n    fb,\n    previous_fb;\n\n#if defined(MNG_INSERT_LAYERS)\n  PixelInfo\n    mng_background_color;\n#endif\n\n  register unsigned char\n    *p;\n\n  register ssize_t\n    i;\n\n  size_t\n    count;\n\n  ssize_t\n    loop_level;\n\n  volatile short\n    skipping_loop;\n\n#if defined(MNG_INSERT_LAYERS)\n  unsigned int\n    mandatory_back=0;\n#endif\n\n  volatile unsigned int\n#ifdef MNG_OBJECT_BUFFERS\n    mng_background_object=0,\n#endif\n    mng_type=0;   /* 0: PNG or JNG; 1: MNG; 2: MNG-LC; 3: MNG-VLC */\n\n  size_t\n    default_frame_timeout,\n    frame_timeout,\n#if defined(MNG_INSERT_LAYERS)\n    image_height,\n    image_width,\n#endif\n    length;\n\n  /* These delays are all measured in image ticks_per_second,\n   * not in MNG ticks_per_second\n   */\n  volatile size_t\n    default_frame_delay,\n    final_delay,\n    final_image_delay,\n    frame_delay,\n#if defined(MNG_INSERT_LAYERS)\n    insert_layers,\n#endif\n    mng_iterations=1,\n    simplicity=0,\n    subframe_height=0,\n    subframe_width=0;\n\n  previous_fb.top=0;\n  previous_fb.bottom=0;\n  previous_fb.left=0;\n  previous_fb.right=0;\n  default_fb.top=0;\n  default_fb.bottom=0;\n  default_fb.left=0;\n  default_fb.right=0;\n\n  logging=LogMagickEvent(CoderEvent,GetMagickModule(),\n    \"  Enter ReadOneMNGImage()\");\n\n  image=mng_info->image;\n\n  if (LocaleCompare(image_info->magick,\"MNG\") == 0)\n    {\n      char\n        magic_number[MagickPathExtent];\n\n      /* Verify MNG signature.  */\n      count=(size_t) ReadBlob(image,8,(unsigned char *) magic_number);\n      if (memcmp(magic_number,\"\\212MNG\\r\\n\\032\\n\",8) != 0)\n        ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n\n      /* Initialize some nonzero members of the MngInfo structure.  */\n      for (i=0; i < MNG_MAX_OBJECTS; i++)\n      {\n        mng_info->object_clip[i].right=(ssize_t) PNG_UINT_31_MAX;\n        mng_info->object_clip[i].bottom=(ssize_t) PNG_UINT_31_MAX;\n      }\n      mng_info->exists[0]=MagickTrue;\n    }\n\n  skipping_loop=(-1);\n  first_mng_object=MagickTrue;\n  mng_type=0;\n#if defined(MNG_INSERT_LAYERS)\n  insert_layers=MagickFalse; /* should be False during convert or mogrify */\n#endif\n  default_frame_delay=0;\n  default_frame_timeout=0;\n  frame_delay=0;\n  final_delay=1;\n  mng_info->ticks_per_second=1UL*image->ticks_per_second;\n  object_id=0;\n  skip_to_iend=MagickFalse;\n  term_chunk_found=MagickFalse;\n  mng_info->framing_mode=1;\n#if defined(MNG_INSERT_LAYERS)\n  mandatory_back=MagickFalse;\n#endif\n#if defined(MNG_INSERT_LAYERS)\n  mng_background_color=image->background_color;\n#endif\n  default_fb=mng_info->frame;\n  previous_fb=mng_info->frame;\n  do\n  {\n    char\n      type[MagickPathExtent];\n\n    if (LocaleCompare(image_info->magick,\"MNG\") == 0)\n      {\n        unsigned char\n          *chunk;\n\n        /*\n          Read a new chunk.\n        */\n        type[0]='\\0';\n        (void) ConcatenateMagickString(type,\"errr\",MagickPathExtent);\n        length=ReadBlobMSBLong(image);\n        count=(size_t) ReadBlob(image,4,(unsigned char *) type);\n\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n           \"  Reading MNG chunk type %c%c%c%c, length: %.20g\",\n           type[0],type[1],type[2],type[3],(double) length);\n\n        if (length > PNG_UINT_31_MAX)\n          {\n            status=MagickFalse;\n            break;\n          }\n\n        if (count == 0)\n          ThrowReaderException(CorruptImageError,\"CorruptImage\");\n\n        p=NULL;\n        chunk=(unsigned char *) NULL;\n\n        if (length != 0)\n          {\n            if (length > GetBlobSize(image))\n              ThrowReaderException(CorruptImageError,\n                \"InsufficientImageDataInFile\");\n            chunk=(unsigned char *) AcquireQuantumMemory(length+\n             MagickPathExtent,sizeof(*chunk));\n\n            if (chunk == (unsigned char *) NULL)\n              ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n\n            for (i=0; i < (ssize_t) length; i++)\n            {\n              int\n                c;\n\n              c=ReadBlobByte(image);\n              if (c == EOF)\n                break;\n              chunk[i]=(unsigned char) c;\n            }\n\n            p=chunk;\n          }\n\n        (void) ReadBlobMSBLong(image);  /* read crc word */\n\n#if !defined(JNG_SUPPORTED)\n        if (memcmp(type,mng_JHDR,4) == 0)\n          {\n            skip_to_iend=MagickTrue;\n\n            if (mng_info->jhdr_warning == 0)\n              (void) ThrowMagickException(exception,GetMagickModule(),\n                CoderError,\"JNGCompressNotSupported\",\"`%s'\",image->filename);\n\n            mng_info->jhdr_warning++;\n          }\n#endif\n        if (memcmp(type,mng_DHDR,4) == 0)\n          {\n            skip_to_iend=MagickTrue;\n\n            if (mng_info->dhdr_warning == 0)\n              (void) ThrowMagickException(exception,GetMagickModule(),\n                CoderError,\"DeltaPNGNotSupported\",\"`%s'\",image->filename);\n\n            mng_info->dhdr_warning++;\n          }\n        if (memcmp(type,mng_MEND,4) == 0)\n          break;\n\n        if (skip_to_iend)\n          {\n            if (memcmp(type,mng_IEND,4) == 0)\n              skip_to_iend=MagickFalse;\n\n            if (length != 0)\n              chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  Skip to IEND.\");\n\n            continue;\n          }\n\n        if (memcmp(type,mng_MHDR,4) == 0)\n          {\n            if (length != 28)\n              {\n                chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n                ThrowReaderException(CorruptImageError,\"CorruptImage\");\n              }\n\n            mng_info->mng_width=(size_t) ((p[0] << 24) | (p[1] << 16) |\n                (p[2] << 8) | p[3]);\n\n            mng_info->mng_height=(size_t) ((p[4] << 24) | (p[5] << 16) |\n                (p[6] << 8) | p[7]);\n\n            if (logging != MagickFalse)\n              {\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"  MNG width: %.20g\",(double) mng_info->mng_width);\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"  MNG height: %.20g\",(double) mng_info->mng_height);\n              }\n\n            p+=8;\n            mng_info->ticks_per_second=(size_t) mng_get_long(p);\n\n            if (mng_info->ticks_per_second == 0)\n              default_frame_delay=0;\n\n            else\n              default_frame_delay=1UL*image->ticks_per_second/\n                mng_info->ticks_per_second;\n\n            frame_delay=default_frame_delay;\n            simplicity=0;\n\n            p+=16;\n            simplicity=(size_t) mng_get_long(p);\n\n            mng_type=1;    /* Full MNG */\n\n            if ((simplicity != 0) && ((simplicity | 11) == 11))\n              mng_type=2; /* LC */\n\n            if ((simplicity != 0) && ((simplicity | 9) == 9))\n              mng_type=3; /* VLC */\n\n#if defined(MNG_INSERT_LAYERS)\n            if (mng_type != 3)\n              insert_layers=MagickTrue;\n#endif\n            if (GetAuthenticPixelQueue(image) != (Quantum *) NULL)\n              {\n                /* Allocate next image structure.  */\n                AcquireNextImage(image_info,image,exception);\n\n                if (GetNextImageInList(image) == (Image *) NULL)\n                  return((Image *) NULL);\n\n                image=SyncNextImageInList(image);\n                mng_info->image=image;\n              }\n\n            if ((mng_info->mng_width > 65535L) ||\n                (mng_info->mng_height > 65535L))\n              {\n                chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n                ThrowReaderException(ImageError,\"WidthOrHeightExceedsLimit\");\n              }\n\n            (void) FormatLocaleString(page_geometry,MagickPathExtent,\n              \"%.20gx%.20g+0+0\",(double) mng_info->mng_width,(double)\n              mng_info->mng_height);\n\n            mng_info->frame.left=0;\n            mng_info->frame.right=(ssize_t) mng_info->mng_width;\n            mng_info->frame.top=0;\n            mng_info->frame.bottom=(ssize_t) mng_info->mng_height;\n            mng_info->clip=default_fb=previous_fb=mng_info->frame;\n\n            for (i=0; i < MNG_MAX_OBJECTS; i++)\n              mng_info->object_clip[i]=mng_info->frame;\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_TERM,4) == 0)\n          {\n            int\n              repeat=0;\n\n            if (length != 0)\n              repeat=p[0];\n\n            if (repeat == 3)\n              {\n                final_delay=(png_uint_32) mng_get_long(&p[2]);\n                mng_iterations=(png_uint_32) mng_get_long(&p[6]);\n\n                if (mng_iterations == PNG_UINT_31_MAX)\n                  mng_iterations=0;\n\n                image->iterations=mng_iterations;\n                term_chunk_found=MagickTrue;\n              }\n\n            if (logging != MagickFalse)\n              {\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"    repeat=%d,  final_delay=%.20g,  iterations=%.20g\",\n                  repeat,(double) final_delay, (double) image->iterations);\n              }\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n        if (memcmp(type,mng_DEFI,4) == 0)\n          {\n            if (mng_type == 3)\n              (void) ThrowMagickException(exception,GetMagickModule(),\n                CoderError,\"DEFI chunk found in MNG-VLC datastream\",\"`%s'\",\n                image->filename);\n\n            if (length < 2)\n              {\n                if (chunk)\n                  chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n                ThrowReaderException(CorruptImageError,\"CorruptImage\");\n              }\n\n            object_id=(p[0] << 8) | p[1];\n\n            if (mng_type == 2 && object_id != 0)\n              (void) ThrowMagickException(exception,GetMagickModule(),\n                CoderError,\"Nonzero object_id in MNG-LC datastream\",\"`%s'\",\n                image->filename);\n\n            if (object_id > MNG_MAX_OBJECTS)\n              {\n                /*\n                  Instead of using a warning we should allocate a larger\n                  MngInfo structure and continue.\n                */\n                (void) ThrowMagickException(exception,GetMagickModule(),\n                  CoderError,\"object id too large\",\"`%s'\",image->filename);\n                object_id=MNG_MAX_OBJECTS;\n              }\n\n            if (mng_info->exists[object_id])\n              if (mng_info->frozen[object_id])\n                {\n                  chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n                  (void) ThrowMagickException(exception,\n                    GetMagickModule(),CoderError,\n                    \"DEFI cannot redefine a frozen MNG object\",\"`%s'\",\n                    image->filename);\n                  continue;\n                }\n\n            mng_info->exists[object_id]=MagickTrue;\n\n            if (length > 2)\n              mng_info->invisible[object_id]=p[2];\n\n            /*\n              Extract object offset info.\n            */\n            if (length > 11)\n              {\n                mng_info->x_off[object_id]=(ssize_t) ((p[4] << 24) |\n                    (p[5] << 16) | (p[6] << 8) | p[7]);\n\n                mng_info->y_off[object_id]=(ssize_t) ((p[8] << 24) |\n                    (p[9] << 16) | (p[10] << 8) | p[11]);\n\n                if (logging != MagickFalse)\n                  {\n                    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                      \"  x_off[%d]: %.20g,  y_off[%d]: %.20g\",\n                      object_id,(double) mng_info->x_off[object_id],\n                      object_id,(double) mng_info->y_off[object_id]);\n                  }\n              }\n\n            /*\n              Extract object clipping info.\n            */\n            if (length > 27)\n              mng_info->object_clip[object_id]=mng_read_box(mng_info->frame,0,\n                &p[12]);\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n        if (memcmp(type,mng_bKGD,4) == 0)\n          {\n            mng_info->have_global_bkgd=MagickFalse;\n\n            if (length > 5)\n              {\n                mng_info->mng_global_bkgd.red=\n                  ScaleShortToQuantum((unsigned short) ((p[0] << 8) | p[1]));\n\n                mng_info->mng_global_bkgd.green=\n                  ScaleShortToQuantum((unsigned short) ((p[2] << 8) | p[3]));\n\n                mng_info->mng_global_bkgd.blue=\n                  ScaleShortToQuantum((unsigned short) ((p[4] << 8) | p[5]));\n\n                mng_info->have_global_bkgd=MagickTrue;\n              }\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n        if (memcmp(type,mng_BACK,4) == 0)\n          {\n#if defined(MNG_INSERT_LAYERS)\n            if (length > 6)\n              mandatory_back=p[6];\n\n            else\n              mandatory_back=0;\n\n            if (mandatory_back && length > 5)\n              {\n                mng_background_color.red=\n                    ScaleShortToQuantum((unsigned short) ((p[0] << 8) | p[1]));\n\n                mng_background_color.green=\n                    ScaleShortToQuantum((unsigned short) ((p[2] << 8) | p[3]));\n\n                mng_background_color.blue=\n                    ScaleShortToQuantum((unsigned short) ((p[4] << 8) | p[5]));\n\n                mng_background_color.alpha=OpaqueAlpha;\n              }\n\n#ifdef MNG_OBJECT_BUFFERS\n            if (length > 8)\n              mng_background_object=(p[7] << 8) | p[8];\n#endif\n#endif\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_PLTE,4) == 0)\n          {\n            /* Read global PLTE.  */\n\n            if (length && (length < 769))\n              {\n                if (mng_info->global_plte == (png_colorp) NULL)\n                  mng_info->global_plte=(png_colorp) AcquireQuantumMemory(256,\n                    sizeof(*mng_info->global_plte));\n\n                for (i=0; i < (ssize_t) (length/3); i++)\n                {\n                  mng_info->global_plte[i].red=p[3*i];\n                  mng_info->global_plte[i].green=p[3*i+1];\n                  mng_info->global_plte[i].blue=p[3*i+2];\n                }\n\n                mng_info->global_plte_length=(unsigned int) (length/3);\n              }\n#ifdef MNG_LOOSE\n            for ( ; i < 256; i++)\n            {\n              mng_info->global_plte[i].red=i;\n              mng_info->global_plte[i].green=i;\n              mng_info->global_plte[i].blue=i;\n            }\n\n            if (length != 0)\n              mng_info->global_plte_length=256;\n#endif\n            else\n              mng_info->global_plte_length=0;\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_tRNS,4) == 0)\n          {\n            /* read global tRNS */\n\n            if (length > 0 && length < 257)\n              for (i=0; i < (ssize_t) length; i++)\n                mng_info->global_trns[i]=p[i];\n\n#ifdef MNG_LOOSE\n            for ( ; i < 256; i++)\n              mng_info->global_trns[i]=255;\n#endif\n            mng_info->global_trns_length=(unsigned int) length;\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n        if (memcmp(type,mng_gAMA,4) == 0)\n          {\n            if (length == 4)\n              {\n                ssize_t\n                  igamma;\n\n                igamma=mng_get_long(p);\n                mng_info->global_gamma=((float) igamma)*0.00001;\n                mng_info->have_global_gama=MagickTrue;\n              }\n\n            else\n              mng_info->have_global_gama=MagickFalse;\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_cHRM,4) == 0)\n          {\n            /* Read global cHRM */\n\n            if (length == 32)\n              {\n                mng_info->global_chrm.white_point.x=0.00001*mng_get_long(p);\n                mng_info->global_chrm.white_point.y=0.00001*mng_get_long(&p[4]);\n                mng_info->global_chrm.red_primary.x=0.00001*mng_get_long(&p[8]);\n                mng_info->global_chrm.red_primary.y=0.00001*\n                  mng_get_long(&p[12]);\n                mng_info->global_chrm.green_primary.x=0.00001*\n                  mng_get_long(&p[16]);\n                mng_info->global_chrm.green_primary.y=0.00001*\n                  mng_get_long(&p[20]);\n                mng_info->global_chrm.blue_primary.x=0.00001*\n                  mng_get_long(&p[24]);\n                mng_info->global_chrm.blue_primary.y=0.00001*\n                  mng_get_long(&p[28]);\n                mng_info->have_global_chrm=MagickTrue;\n              }\n            else\n              mng_info->have_global_chrm=MagickFalse;\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_sRGB,4) == 0)\n          {\n            /*\n              Read global sRGB.\n            */\n            if (length != 0)\n              {\n                mng_info->global_srgb_intent=\n                  Magick_RenderingIntent_from_PNG_RenderingIntent(p[0]);\n                mng_info->have_global_srgb=MagickTrue;\n              }\n            else\n              mng_info->have_global_srgb=MagickFalse;\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_iCCP,4) == 0)\n          {\n            /* To do: */\n\n            /*\n              Read global iCCP.\n            */\n            if (length != 0)\n              chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n            continue;\n          }\n\n        if (memcmp(type,mng_FRAM,4) == 0)\n          {\n            if (mng_type == 3)\n              (void) ThrowMagickException(exception,GetMagickModule(),\n                CoderError,\"FRAM chunk found in MNG-VLC datastream\",\"`%s'\",\n                image->filename);\n\n            if ((mng_info->framing_mode == 2) || (mng_info->framing_mode == 4))\n              image->delay=frame_delay;\n\n            frame_delay=default_frame_delay;\n            frame_timeout=default_frame_timeout;\n            fb=default_fb;\n\n            if (length != 0)\n              if (p[0])\n                mng_info->framing_mode=p[0];\n\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"    Framing_mode=%d\",mng_info->framing_mode);\n\n            if (length > 6)\n              {\n                /* Note the delay and frame clipping boundaries.  */\n\n                p++; /* framing mode */\n\n                while (*p && ((p-chunk) < (ssize_t) length))\n                  p++;  /* frame name */\n\n                p++;  /* frame name terminator */\n\n                if ((p-chunk) < (ssize_t) (length-4))\n                  {\n                    int\n                      change_delay,\n                      change_timeout,\n                      change_clipping;\n\n                    change_delay=(*p++);\n                    change_timeout=(*p++);\n                    change_clipping=(*p++);\n                    p++; /* change_sync */\n\n                    if (change_delay)\n                      {\n                        frame_delay=1UL*image->ticks_per_second*\n                          mng_get_long(p);\n\n                        if (mng_info->ticks_per_second != 0)\n                          frame_delay/=mng_info->ticks_per_second;\n\n                        else\n                          frame_delay=PNG_UINT_31_MAX;\n\n                        if (change_delay == 2)\n                          default_frame_delay=frame_delay;\n\n                        p+=4;\n\n                        if (logging != MagickFalse)\n                          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                            \"    Framing_delay=%.20g\",(double) frame_delay);\n                      }\n\n                    if (change_timeout)\n                      {\n                        frame_timeout=1UL*image->ticks_per_second*\n                          mng_get_long(p);\n\n                        if (mng_info->ticks_per_second != 0)\n                          frame_timeout/=mng_info->ticks_per_second;\n\n                        else\n                          frame_timeout=PNG_UINT_31_MAX;\n\n                        if (change_timeout == 2)\n                          default_frame_timeout=frame_timeout;\n\n                        p+=4;\n\n                        if (logging != MagickFalse)\n                          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                            \"    Framing_timeout=%.20g\",(double) frame_timeout);\n                      }\n\n                    if (change_clipping)\n                      {\n                        fb=mng_read_box(previous_fb,(char) p[0],&p[1]);\n                        p+=17;\n                        previous_fb=fb;\n\n                        if (logging != MagickFalse)\n                          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                            \"    Frame_clip: L=%.20g R=%.20g T=%.20g B=%.20g\",\n                            (double) fb.left,(double) fb.right,(double) fb.top,\n                            (double) fb.bottom);\n\n                        if (change_clipping == 2)\n                          default_fb=fb;\n                      }\n                  }\n              }\n            mng_info->clip=fb;\n            mng_info->clip=mng_minimum_box(fb,mng_info->frame);\n\n            subframe_width=(size_t) (mng_info->clip.right\n               -mng_info->clip.left);\n\n            subframe_height=(size_t) (mng_info->clip.bottom\n               -mng_info->clip.top);\n            /*\n              Insert a background layer behind the frame if framing_mode is 4.\n            */\n#if defined(MNG_INSERT_LAYERS)\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"   subframe_width=%.20g, subframe_height=%.20g\",(double)\n                subframe_width,(double) subframe_height);\n\n            if (insert_layers && (mng_info->framing_mode == 4) &&\n                (subframe_width) && (subframe_height))\n              {\n                /* Allocate next image structure.  */\n                if (GetAuthenticPixelQueue(image) != (Quantum *) NULL)\n                  {\n                    AcquireNextImage(image_info,image,exception);\n\n                    if (GetNextImageInList(image) == (Image *) NULL)\n                      return(DestroyImageList(image));\n\n                    image=SyncNextImageInList(image);\n                  }\n\n                mng_info->image=image;\n\n                if (term_chunk_found)\n                  {\n                    image->start_loop=MagickTrue;\n                    image->iterations=mng_iterations;\n                    term_chunk_found=MagickFalse;\n                  }\n\n                else\n                    image->start_loop=MagickFalse;\n\n                image->columns=subframe_width;\n                image->rows=subframe_height;\n                image->page.width=subframe_width;\n                image->page.height=subframe_height;\n                image->page.x=mng_info->clip.left;\n                image->page.y=mng_info->clip.top;\n                image->background_color=mng_background_color;\n                image->alpha_trait=UndefinedPixelTrait;\n                image->delay=0;\n                (void) SetImageBackgroundColor(image,exception);\n\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"  Insert backgd layer, L=%.20g, R=%.20g T=%.20g, B=%.20g\",\n                    (double) mng_info->clip.left,\n                    (double) mng_info->clip.right,\n                    (double) mng_info->clip.top,\n                    (double) mng_info->clip.bottom);\n              }\n#endif\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_CLIP,4) == 0)\n          {\n            unsigned int\n              first_object,\n              last_object;\n\n            /*\n              Read CLIP.\n            */\n            if (length > 3)\n              {\n                first_object=(p[0] << 8) | p[1];\n                last_object=(p[2] << 8) | p[3];\n                p+=4;\n\n                for (i=(int) first_object; i <= (int) last_object; i++)\n                {\n                  if (mng_info->exists[i] && !mng_info->frozen[i])\n                    {\n                      MngBox\n                        box;\n\n                      box=mng_info->object_clip[i];\n                      if ((p-chunk) < (ssize_t) (length-17))\n                        mng_info->object_clip[i]=\n                           mng_read_box(box,(char) p[0],&p[1]);\n                    }\n                }\n\n              }\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_SAVE,4) == 0)\n          {\n            for (i=1; i < MNG_MAX_OBJECTS; i++)\n              if (mng_info->exists[i])\n                {\n                 mng_info->frozen[i]=MagickTrue;\n#ifdef MNG_OBJECT_BUFFERS\n                 if (mng_info->ob[i] != (MngBuffer *) NULL)\n                    mng_info->ob[i]->frozen=MagickTrue;\n#endif\n                }\n\n            if (length != 0)\n              chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n            continue;\n          }\n\n        if ((memcmp(type,mng_DISC,4) == 0) || (memcmp(type,mng_SEEK,4) == 0))\n          {\n            /* Read DISC or SEEK.  */\n\n            if ((length == 0) || !memcmp(type,mng_SEEK,4))\n              {\n                for (i=1; i < MNG_MAX_OBJECTS; i++)\n                  MngInfoDiscardObject(mng_info,i);\n              }\n\n            else\n              {\n                register ssize_t\n                  j;\n\n                for (j=1; j < (ssize_t) length; j+=2)\n                {\n                  i=p[j-1] << 8 | p[j];\n                  MngInfoDiscardObject(mng_info,i);\n                }\n              }\n\n            if (length != 0)\n              chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n            continue;\n          }\n\n        if (memcmp(type,mng_MOVE,4) == 0)\n          {\n            size_t\n              first_object,\n              last_object;\n\n            /* read MOVE */\n\n            if (length > 3)\n            {\n              first_object=(p[0] << 8) | p[1];\n              last_object=(p[2] << 8) | p[3];\n              p+=4;\n\n              for (i=(ssize_t) first_object; i <= (ssize_t) last_object; i++)\n              {\n                if ((i < 0) || (i >= MNG_MAX_OBJECTS))\n                  continue;\n\n                if (mng_info->exists[i] && !mng_info->frozen[i] &&\n                    (p-chunk) < (ssize_t) (length-8))\n                  {\n                    MngPair\n                      new_pair;\n\n                    MngPair\n                      old_pair;\n\n                    old_pair.a=mng_info->x_off[i];\n                    old_pair.b=mng_info->y_off[i];\n                    new_pair=mng_read_pair(old_pair,(int) p[0],&p[1]);\n                    mng_info->x_off[i]=new_pair.a;\n                    mng_info->y_off[i]=new_pair.b;\n                  }\n              }\n            }\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_LOOP,4) == 0)\n          {\n            ssize_t loop_iters=1;\n            if (length > 4)\n              {\n                loop_level=chunk[0];\n                mng_info->loop_active[loop_level]=1;  /* mark loop active */\n\n                /* Record starting point.  */\n                loop_iters=mng_get_long(&chunk[1]);\n\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"  LOOP level %.20g has %.20g iterations \",\n                    (double) loop_level, (double) loop_iters);\n\n                if (loop_iters == 0)\n                  skipping_loop=loop_level;\n\n                else\n                  {\n                    mng_info->loop_jump[loop_level]=TellBlob(image);\n                    mng_info->loop_count[loop_level]=loop_iters;\n                  }\n\n                mng_info->loop_iteration[loop_level]=0;\n              }\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_ENDL,4) == 0)\n          {\n            if (length > 0)\n              {\n                loop_level=chunk[0];\n\n                if (skipping_loop > 0)\n                  {\n                    if (skipping_loop == loop_level)\n                      {\n                        /*\n                          Found end of zero-iteration loop.\n                        */\n                        skipping_loop=(-1);\n                        mng_info->loop_active[loop_level]=0;\n                      }\n                  }\n\n                else\n                  {\n                    if (mng_info->loop_active[loop_level] == 1)\n                      {\n                        mng_info->loop_count[loop_level]--;\n                        mng_info->loop_iteration[loop_level]++;\n\n                        if (logging != MagickFalse)\n                          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                          \"  ENDL: LOOP level %.20g has %.20g remaining iters\",\n                            (double) loop_level,(double)\n                            mng_info->loop_count[loop_level]);\n\n                        if (mng_info->loop_count[loop_level] != 0)\n                          {\n                            offset=\n                              SeekBlob(image,mng_info->loop_jump[loop_level],\n                              SEEK_SET);\n\n                            if (offset < 0)\n                              {\n                                chunk=(unsigned char *) RelinquishMagickMemory(\n                                  chunk);\n                                ThrowReaderException(CorruptImageError,\n                                  \"ImproperImageHeader\");\n                              }\n                          }\n\n                        else\n                          {\n                            short\n                              last_level;\n\n                            /*\n                              Finished loop.\n                            */\n                            mng_info->loop_active[loop_level]=0;\n                            last_level=(-1);\n                            for (i=0; i < loop_level; i++)\n                              if (mng_info->loop_active[i] == 1)\n                                last_level=(short) i;\n                            loop_level=last_level;\n                          }\n                      }\n                  }\n              }\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_CLON,4) == 0)\n          {\n            if (mng_info->clon_warning == 0)\n              (void) ThrowMagickException(exception,GetMagickModule(),\n                CoderError,\"CLON is not implemented yet\",\"`%s'\",\n                image->filename);\n\n            mng_info->clon_warning++;\n          }\n\n        if (memcmp(type,mng_MAGN,4) == 0)\n          {\n            png_uint_16\n              magn_first,\n              magn_last,\n              magn_mb,\n              magn_ml,\n              magn_mr,\n              magn_mt,\n              magn_mx,\n              magn_my,\n              magn_methx,\n              magn_methy;\n\n            if (length > 1)\n              magn_first=(p[0] << 8) | p[1];\n\n            else\n              magn_first=0;\n\n            if (length > 3)\n              magn_last=(p[2] << 8) | p[3];\n\n            else\n              magn_last=magn_first;\n#ifndef MNG_OBJECT_BUFFERS\n            if (magn_first || magn_last)\n              if (mng_info->magn_warning == 0)\n                {\n                  (void) ThrowMagickException(exception,\n                     GetMagickModule(),CoderError,\n                     \"MAGN is not implemented yet for nonzero objects\",\n                     \"`%s'\",image->filename);\n\n                   mng_info->magn_warning++;\n                }\n#endif\n            if (length > 4)\n              magn_methx=p[4];\n\n            else\n              magn_methx=0;\n\n            if (length > 6)\n              magn_mx=(p[5] << 8) | p[6];\n\n            else\n              magn_mx=1;\n\n            if (magn_mx == 0)\n              magn_mx=1;\n\n            if (length > 8)\n              magn_my=(p[7] << 8) | p[8];\n\n            else\n              magn_my=magn_mx;\n\n            if (magn_my == 0)\n              magn_my=1;\n\n            if (length > 10)\n              magn_ml=(p[9] << 8) | p[10];\n\n            else\n              magn_ml=magn_mx;\n\n            if (magn_ml == 0)\n              magn_ml=1;\n\n            if (length > 12)\n              magn_mr=(p[11] << 8) | p[12];\n\n            else\n              magn_mr=magn_mx;\n\n            if (magn_mr == 0)\n              magn_mr=1;\n\n            if (length > 14)\n              magn_mt=(p[13] << 8) | p[14];\n\n            else\n              magn_mt=magn_my;\n\n            if (magn_mt == 0)\n              magn_mt=1;\n\n            if (length > 16)\n              magn_mb=(p[15] << 8) | p[16];\n\n            else\n              magn_mb=magn_my;\n\n            if (magn_mb == 0)\n              magn_mb=1;\n\n            if (length > 17)\n              magn_methy=p[17];\n\n            else\n              magn_methy=magn_methx;\n\n\n            if (magn_methx > 5 || magn_methy > 5)\n              if (mng_info->magn_warning == 0)\n                {\n                  (void) ThrowMagickException(exception,\n                     GetMagickModule(),CoderError,\n                     \"Unknown MAGN method in MNG datastream\",\"`%s'\",\n                     image->filename);\n\n                   mng_info->magn_warning++;\n                }\n#ifdef MNG_OBJECT_BUFFERS\n          /* Magnify existing objects in the range magn_first to magn_last */\n#endif\n            if (magn_first == 0 || magn_last == 0)\n              {\n                /* Save the magnification factors for object 0 */\n                mng_info->magn_mb=magn_mb;\n                mng_info->magn_ml=magn_ml;\n                mng_info->magn_mr=magn_mr;\n                mng_info->magn_mt=magn_mt;\n                mng_info->magn_mx=magn_mx;\n                mng_info->magn_my=magn_my;\n                mng_info->magn_methx=magn_methx;\n                mng_info->magn_methy=magn_methy;\n              }\n          }\n\n        if (memcmp(type,mng_PAST,4) == 0)\n          {\n            if (mng_info->past_warning == 0)\n              (void) ThrowMagickException(exception,GetMagickModule(),\n                CoderError,\"PAST is not implemented yet\",\"`%s'\",\n                image->filename);\n\n            mng_info->past_warning++;\n          }\n\n        if (memcmp(type,mng_SHOW,4) == 0)\n          {\n            if (mng_info->show_warning == 0)\n              (void) ThrowMagickException(exception,GetMagickModule(),\n                CoderError,\"SHOW is not implemented yet\",\"`%s'\",\n                image->filename);\n\n            mng_info->show_warning++;\n          }\n\n        if (memcmp(type,mng_sBIT,4) == 0)\n          {\n            if (length < 4)\n              mng_info->have_global_sbit=MagickFalse;\n\n            else\n              {\n                mng_info->global_sbit.gray=p[0];\n                mng_info->global_sbit.red=p[0];\n                mng_info->global_sbit.green=p[1];\n                mng_info->global_sbit.blue=p[2];\n                mng_info->global_sbit.alpha=p[3];\n                mng_info->have_global_sbit=MagickTrue;\n             }\n          }\n        if (memcmp(type,mng_pHYs,4) == 0)\n          {\n            if (length > 8)\n              {\n                mng_info->global_x_pixels_per_unit=\n                    (size_t) mng_get_long(p);\n                mng_info->global_y_pixels_per_unit=\n                    (size_t) mng_get_long(&p[4]);\n                mng_info->global_phys_unit_type=p[8];\n                mng_info->have_global_phys=MagickTrue;\n              }\n\n            else\n              mng_info->have_global_phys=MagickFalse;\n          }\n        if (memcmp(type,mng_pHYg,4) == 0)\n          {\n            if (mng_info->phyg_warning == 0)\n              (void) ThrowMagickException(exception,GetMagickModule(),\n                CoderError,\"pHYg is not implemented.\",\"`%s'\",image->filename);\n\n            mng_info->phyg_warning++;\n          }\n        if (memcmp(type,mng_BASI,4) == 0)\n          {\n            skip_to_iend=MagickTrue;\n\n            if (mng_info->basi_warning == 0)\n              (void) ThrowMagickException(exception,GetMagickModule(),\n                CoderError,\"BASI is not implemented yet\",\"`%s'\",\n                image->filename);\n\n            mng_info->basi_warning++;\n#ifdef MNG_BASI_SUPPORTED\n            basi_width=(size_t) ((p[0] << 24) | (p[1] << 16) |\n               (p[2] << 8) | p[3]);\n            basi_height=(size_t) ((p[4] << 24) | (p[5] << 16) |\n               (p[6] << 8) | p[7]);\n            basi_color_type=p[8];\n            basi_compression_method=p[9];\n            basi_filter_type=p[10];\n            basi_interlace_method=p[11];\n            if (length > 11)\n              basi_red=(p[12] << 8) & p[13];\n\n            else\n              basi_red=0;\n\n            if (length > 13)\n              basi_green=(p[14] << 8) & p[15];\n\n            else\n              basi_green=0;\n\n            if (length > 15)\n              basi_blue=(p[16] << 8) & p[17];\n\n            else\n              basi_blue=0;\n\n            if (length > 17)\n              basi_alpha=(p[18] << 8) & p[19];\n\n            else\n              {\n                if (basi_sample_depth == 16)\n                  basi_alpha=65535L;\n                else\n                  basi_alpha=255;\n              }\n\n            if (length > 19)\n              basi_viewable=p[20];\n\n            else\n              basi_viewable=0;\n\n#endif\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_IHDR,4)\n#if defined(JNG_SUPPORTED)\n            && memcmp(type,mng_JHDR,4)\n#endif\n            )\n          {\n            /* Not an IHDR or JHDR chunk */\n            if (length != 0)\n              chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n            continue;\n          }\n/* Process IHDR */\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  Processing %c%c%c%c chunk\",type[0],type[1],type[2],type[3]);\n\n        mng_info->exists[object_id]=MagickTrue;\n        mng_info->viewable[object_id]=MagickTrue;\n\n        if (mng_info->invisible[object_id])\n          {\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  Skipping invisible object\");\n\n            skip_to_iend=MagickTrue;\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n#if defined(MNG_INSERT_LAYERS)\n        if (length < 8)\n          {\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n          }\n\n        image_width=(size_t) mng_get_long(p);\n        image_height=(size_t) mng_get_long(&p[4]);\n#endif\n        chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n        /*\n          Insert a transparent background layer behind the entire animation\n          if it is not full screen.\n        */\n#if defined(MNG_INSERT_LAYERS)\n        if (insert_layers && mng_type && first_mng_object)\n          {\n            if ((mng_info->clip.left > 0) || (mng_info->clip.top > 0) ||\n                (image_width < mng_info->mng_width) ||\n                (mng_info->clip.right < (ssize_t) mng_info->mng_width) ||\n                (image_height < mng_info->mng_height) ||\n                (mng_info->clip.bottom < (ssize_t) mng_info->mng_height))\n              {\n                if (GetAuthenticPixelQueue(image) != (Quantum *) NULL)\n                  {\n                    /*\n                      Allocate next image structure.\n                    */\n                    AcquireNextImage(image_info,image,exception);\n\n                    if (GetNextImageInList(image) == (Image *) NULL)\n                      return(DestroyImageList(image));\n\n                    image=SyncNextImageInList(image);\n                  }\n                mng_info->image=image;\n\n                if (term_chunk_found)\n                  {\n                    image->start_loop=MagickTrue;\n                    image->iterations=mng_iterations;\n                    term_chunk_found=MagickFalse;\n                  }\n\n                else\n                    image->start_loop=MagickFalse;\n\n                /* Make a background rectangle.  */\n\n                image->delay=0;\n                image->columns=mng_info->mng_width;\n                image->rows=mng_info->mng_height;\n                image->page.width=mng_info->mng_width;\n                image->page.height=mng_info->mng_height;\n                image->page.x=0;\n                image->page.y=0;\n                image->background_color=mng_background_color;\n                (void) SetImageBackgroundColor(image,exception);\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"  Inserted transparent background layer, W=%.20g, H=%.20g\",\n                    (double) mng_info->mng_width,(double) mng_info->mng_height);\n              }\n          }\n        /*\n          Insert a background layer behind the upcoming image if\n          framing_mode is 3, and we haven't already inserted one.\n        */\n        if (insert_layers && (mng_info->framing_mode == 3) &&\n                (subframe_width) && (subframe_height) && (simplicity == 0 ||\n                (simplicity & 0x08)))\n          {\n            if (GetAuthenticPixelQueue(image) != (Quantum *) NULL)\n            {\n              /*\n                Allocate next image structure.\n              */\n              AcquireNextImage(image_info,image,exception);\n\n              if (GetNextImageInList(image) == (Image *) NULL)\n                return(DestroyImageList(image));\n\n              image=SyncNextImageInList(image);\n            }\n\n            mng_info->image=image;\n\n            if (term_chunk_found)\n              {\n                image->start_loop=MagickTrue;\n                image->iterations=mng_iterations;\n                term_chunk_found=MagickFalse;\n              }\n\n            else\n                image->start_loop=MagickFalse;\n\n            image->delay=0;\n            image->columns=subframe_width;\n            image->rows=subframe_height;\n            image->page.width=subframe_width;\n            image->page.height=subframe_height;\n            image->page.x=mng_info->clip.left;\n            image->page.y=mng_info->clip.top;\n            image->background_color=mng_background_color;\n            image->alpha_trait=UndefinedPixelTrait;\n            (void) SetImageBackgroundColor(image,exception);\n\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  Insert background layer, L=%.20g, R=%.20g T=%.20g, B=%.20g\",\n                (double) mng_info->clip.left,(double) mng_info->clip.right,\n                (double) mng_info->clip.top,(double) mng_info->clip.bottom);\n          }\n#endif /* MNG_INSERT_LAYERS */\n        first_mng_object=MagickFalse;\n\n        if (GetAuthenticPixelQueue(image) != (Quantum *) NULL)\n          {\n            /*\n              Allocate next image structure.\n            */\n            AcquireNextImage(image_info,image,exception);\n\n            if (GetNextImageInList(image) == (Image *) NULL)\n              return(DestroyImageList(image));\n\n            image=SyncNextImageInList(image);\n          }\n        mng_info->image=image;\n        status=SetImageProgress(image,LoadImagesTag,TellBlob(image),\n          GetBlobSize(image));\n\n        if (status == MagickFalse)\n          break;\n\n        if (term_chunk_found)\n          {\n            image->start_loop=MagickTrue;\n            term_chunk_found=MagickFalse;\n          }\n\n        else\n            image->start_loop=MagickFalse;\n\n        if (mng_info->framing_mode == 1 || mng_info->framing_mode == 3)\n          {\n            image->delay=frame_delay;\n            frame_delay=default_frame_delay;\n          }\n\n        else\n          image->delay=0;\n\n        image->page.width=mng_info->mng_width;\n        image->page.height=mng_info->mng_height;\n        image->page.x=mng_info->x_off[object_id];\n        image->page.y=mng_info->y_off[object_id];\n        image->iterations=mng_iterations;\n\n        /*\n          Seek back to the beginning of the IHDR or JHDR chunk's length field.\n        */\n\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  Seeking back to beginning of %c%c%c%c chunk\",type[0],type[1],\n            type[2],type[3]);\n\n        offset=SeekBlob(image,-((ssize_t) length+12),SEEK_CUR);\n\n        if (offset < 0)\n          ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n      }\n\n    mng_info->image=image;\n    mng_info->mng_type=mng_type;\n    mng_info->object_id=object_id;\n\n    if (memcmp(type,mng_IHDR,4) == 0)\n      image=ReadOnePNGImage(mng_info,image_info,exception);\n\n#if defined(JNG_SUPPORTED)\n    else\n      image=ReadOneJNGImage(mng_info,image_info,exception);\n#endif\n\n    if (image == (Image *) NULL)\n      {\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"exit ReadJNGImage() with error\");\n\n        return((Image *) NULL);\n      }\n\n    if (image->columns == 0 || image->rows == 0)\n      {\n        (void) CloseBlob(image);\n        return(DestroyImageList(image));\n      }\n\n    mng_info->image=image;\n\n    if (mng_type)\n      {\n        MngBox\n          crop_box;\n\n        if (mng_info->magn_methx || mng_info->magn_methy)\n          {\n            png_uint_32\n               magnified_height,\n               magnified_width;\n\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  Processing MNG MAGN chunk\");\n\n            if (mng_info->magn_methx == 1)\n              {\n                magnified_width=mng_info->magn_ml;\n\n                if (image->columns > 1)\n                   magnified_width += mng_info->magn_mr;\n\n                if (image->columns > 2)\n                   magnified_width += (png_uint_32)\n                      ((image->columns-2)*(mng_info->magn_mx));\n              }\n\n            else\n              {\n                magnified_width=(png_uint_32) image->columns;\n\n                if (image->columns > 1)\n                   magnified_width += mng_info->magn_ml-1;\n\n                if (image->columns > 2)\n                   magnified_width += mng_info->magn_mr-1;\n\n                if (image->columns > 3)\n                   magnified_width += (png_uint_32)\n                      ((image->columns-3)*(mng_info->magn_mx-1));\n              }\n\n            if (mng_info->magn_methy == 1)\n              {\n                magnified_height=mng_info->magn_mt;\n\n                if (image->rows > 1)\n                   magnified_height += mng_info->magn_mb;\n\n                if (image->rows > 2)\n                   magnified_height += (png_uint_32)\n                      ((image->rows-2)*(mng_info->magn_my));\n              }\n\n            else\n              {\n                magnified_height=(png_uint_32) image->rows;\n\n                if (image->rows > 1)\n                   magnified_height += mng_info->magn_mt-1;\n\n                if (image->rows > 2)\n                   magnified_height += mng_info->magn_mb-1;\n\n                if (image->rows > 3)\n                   magnified_height += (png_uint_32)\n                      ((image->rows-3)*(mng_info->magn_my-1));\n              }\n\n            if (magnified_height > image->rows ||\n                magnified_width > image->columns)\n              {\n                Image\n                  *large_image;\n\n                int\n                  yy;\n\n                Quantum\n                  *next,\n                  *prev;\n\n                png_uint_16\n                  magn_methx,\n                  magn_methy;\n\n                ssize_t\n                  m,\n                  y;\n\n                register Quantum\n                  *n,\n                  *q;\n\n                register ssize_t\n                  x;\n\n                /* Allocate next image structure.  */\n\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"    Allocate magnified image\");\n\n                AcquireNextImage(image_info,image,exception);\n\n                if (GetNextImageInList(image) == (Image *) NULL)\n                  return(DestroyImageList(image));\n\n                large_image=SyncNextImageInList(image);\n\n                large_image->columns=magnified_width;\n                large_image->rows=magnified_height;\n\n                magn_methx=mng_info->magn_methx;\n                magn_methy=mng_info->magn_methy;\n\n#if (MAGICKCORE_QUANTUM_DEPTH > 16)\n#define QM unsigned short\n                if (magn_methx != 1 || magn_methy != 1)\n                  {\n                  /*\n                     Scale pixels to unsigned shorts to prevent\n                     overflow of intermediate values of interpolations\n                  */\n                     for (y=0; y < (ssize_t) image->rows; y++)\n                     {\n                       q=GetAuthenticPixels(image,0,y,image->columns,1,\n                          exception);\n\n                       for (x=(ssize_t) image->columns-1; x >= 0; x--)\n                       {\n                          SetPixelRed(image,ScaleQuantumToShort(\n                            GetPixelRed(image,q)),q);\n                          SetPixelGreen(image,ScaleQuantumToShort(\n                            GetPixelGreen(image,q)),q);\n                          SetPixelBlue(image,ScaleQuantumToShort(\n                            GetPixelBlue(image,q)),q);\n                          SetPixelAlpha(image,ScaleQuantumToShort(\n                            GetPixelAlpha(image,q)),q);\n                          q+=GetPixelChannels(image);\n                       }\n\n                       if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                         break;\n                     }\n                  }\n#else\n#define QM Quantum\n#endif\n\n                if (image->alpha_trait != UndefinedPixelTrait)\n                   (void) SetImageBackgroundColor(large_image,exception);\n\n                else\n                  {\n                    large_image->background_color.alpha=OpaqueAlpha;\n                    (void) SetImageBackgroundColor(large_image,exception);\n\n                    if (magn_methx == 4)\n                      magn_methx=2;\n\n                    if (magn_methx == 5)\n                      magn_methx=3;\n\n                    if (magn_methy == 4)\n                      magn_methy=2;\n\n                    if (magn_methy == 5)\n                      magn_methy=3;\n                  }\n\n                /* magnify the rows into the right side of the large image */\n\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"    Magnify the rows to %.20g\",\n                    (double) large_image->rows);\n                m=(ssize_t) mng_info->magn_mt;\n                yy=0;\n                length=(size_t) GetPixelChannels(image)*image->columns;\n                next=(Quantum *) AcquireQuantumMemory(length,sizeof(*next));\n                prev=(Quantum *) AcquireQuantumMemory(length,sizeof(*prev));\n\n                if ((prev == (Quantum *) NULL) ||\n                    (next == (Quantum *) NULL))\n                  {\n                     image=DestroyImageList(image);\n                     ThrowReaderException(ResourceLimitError,\n                       \"MemoryAllocationFailed\");\n                  }\n\n                n=GetAuthenticPixels(image,0,0,image->columns,1,exception);\n                (void) CopyMagickMemory(next,n,length);\n\n                for (y=0; y < (ssize_t) image->rows; y++)\n                {\n                  if (y == 0)\n                    m=(ssize_t) mng_info->magn_mt;\n\n                  else if (magn_methy > 1 && y == (ssize_t) image->rows-2)\n                    m=(ssize_t) mng_info->magn_mb;\n\n                  else if (magn_methy <= 1 && y == (ssize_t) image->rows-1)\n                    m=(ssize_t) mng_info->magn_mb;\n\n                  else if (magn_methy > 1 && y == (ssize_t) image->rows-1)\n                    m=1;\n\n                  else\n                    m=(ssize_t) mng_info->magn_my;\n\n                  n=prev;\n                  prev=next;\n                  next=n;\n\n                  if (y < (ssize_t) image->rows-1)\n                    {\n                      n=GetAuthenticPixels(image,0,y+1,image->columns,1,\n                          exception);\n                      (void) CopyMagickMemory(next,n,length);\n                    }\n\n                  for (i=0; i < m; i++, yy++)\n                  {\n                    register Quantum\n                      *pixels;\n\n                    assert(yy < (ssize_t) large_image->rows);\n                    pixels=prev;\n                    n=next;\n                    q=GetAuthenticPixels(large_image,0,yy,large_image->columns,\n                      1,exception);\n                    q+=(large_image->columns-image->columns)*\n                      GetPixelChannels(large_image);\n\n                    for (x=(ssize_t) image->columns-1; x >= 0; x--)\n                    {\n                      /* To do: get color as function of indexes[x] */\n                      /*\n                      if (image->storage_class == PseudoClass)\n                        {\n                        }\n                      */\n\n                      if (magn_methy <= 1)\n                        {\n                          /* replicate previous */\n                          SetPixelRed(large_image,GetPixelRed(image,pixels),q);\n                          SetPixelGreen(large_image,GetPixelGreen(image,\n                             pixels),q);\n                          SetPixelBlue(large_image,GetPixelBlue(image,\n                             pixels),q);\n                          SetPixelAlpha(large_image,GetPixelAlpha(image,\n                             pixels),q);\n                        }\n\n                      else if (magn_methy == 2 || magn_methy == 4)\n                        {\n                          if (i == 0)\n                            {\n                              SetPixelRed(large_image,GetPixelRed(image,\n                                 pixels),q);\n                              SetPixelGreen(large_image,GetPixelGreen(image,\n                                 pixels),q);\n                              SetPixelBlue(large_image,GetPixelBlue(image,\n                                 pixels),q);\n                              SetPixelAlpha(large_image,GetPixelAlpha(image,\n                                 pixels),q);\n                            }\n\n                          else\n                            {\n                              /* Interpolate */\n                              SetPixelRed(large_image,((QM) (((ssize_t)\n                                 (2*i*(GetPixelRed(image,n)\n                                 -GetPixelRed(image,pixels)+m))/\n                                 ((ssize_t) (m*2))\n                                 +GetPixelRed(image,pixels)))),q);\n                              SetPixelGreen(large_image,((QM) (((ssize_t)\n                                 (2*i*(GetPixelGreen(image,n)\n                                 -GetPixelGreen(image,pixels)+m))/\n                                 ((ssize_t) (m*2))\n                                 +GetPixelGreen(image,pixels)))),q);\n                              SetPixelBlue(large_image,((QM) (((ssize_t)\n                                 (2*i*(GetPixelBlue(image,n)\n                                 -GetPixelBlue(image,pixels)+m))/\n                                 ((ssize_t) (m*2))\n                                 +GetPixelBlue(image,pixels)))),q);\n\n                              if (image->alpha_trait != UndefinedPixelTrait)\n                                 SetPixelAlpha(large_image, ((QM) (((ssize_t)\n                                    (2*i*(GetPixelAlpha(image,n)\n                                    -GetPixelAlpha(image,pixels)+m))\n                                    /((ssize_t) (m*2))+\n                                   GetPixelAlpha(image,pixels)))),q);\n                            }\n\n                          if (magn_methy == 4)\n                            {\n                              /* Replicate nearest */\n                              if (i <= ((m+1) << 1))\n                                 SetPixelAlpha(large_image,GetPixelAlpha(image,\n                                    pixels),q);\n                              else\n                                 SetPixelAlpha(large_image,GetPixelAlpha(image,\n                                    n),q);\n                            }\n                        }\n\n                      else /* if (magn_methy == 3 || magn_methy == 5) */\n                        {\n                          /* Replicate nearest */\n                          if (i <= ((m+1) << 1))\n                          {\n                             SetPixelRed(large_image,GetPixelRed(image,\n                                    pixels),q);\n                             SetPixelGreen(large_image,GetPixelGreen(image,\n                                    pixels),q);\n                             SetPixelBlue(large_image,GetPixelBlue(image,\n                                    pixels),q);\n                             SetPixelAlpha(large_image,GetPixelAlpha(image,\n                                    pixels),q);\n                          }\n\n                          else\n                          {\n                             SetPixelRed(large_image,GetPixelRed(image,n),q);\n                             SetPixelGreen(large_image,GetPixelGreen(image,n),\n                                    q);\n                             SetPixelBlue(large_image,GetPixelBlue(image,n),\n                                    q);\n                             SetPixelAlpha(large_image,GetPixelAlpha(image,n),\n                                    q);\n                          }\n\n                          if (magn_methy == 5)\n                            {\n                              SetPixelAlpha(large_image,(QM) (((ssize_t) (2*i*\n                                 (GetPixelAlpha(image,n)\n                                 -GetPixelAlpha(image,pixels))\n                                 +m))/((ssize_t) (m*2))\n                                 +GetPixelAlpha(image,pixels)),q);\n                            }\n                        }\n                      n+=GetPixelChannels(image);\n                      q+=GetPixelChannels(large_image);\n                      pixels+=GetPixelChannels(image);\n                    } /* x */\n\n                    if (SyncAuthenticPixels(large_image,exception) == 0)\n                      break;\n\n                  } /* i */\n                } /* y */\n\n                prev=(Quantum *) RelinquishMagickMemory(prev);\n                next=(Quantum *) RelinquishMagickMemory(next);\n\n                length=image->columns;\n\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"    Delete original image\");\n\n                DeleteImageFromList(&image);\n\n                image=large_image;\n\n                mng_info->image=image;\n\n                /* magnify the columns */\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"    Magnify the columns to %.20g\",\n                    (double) image->columns);\n\n                for (y=0; y < (ssize_t) image->rows; y++)\n                {\n                  register Quantum\n                    *pixels;\n\n                  q=GetAuthenticPixels(image,0,y,image->columns,1,exception);\n                  pixels=q+(image->columns-length)*GetPixelChannels(image);\n                  n=pixels+GetPixelChannels(image);\n\n                  for (x=(ssize_t) (image->columns-length);\n                    x < (ssize_t) image->columns; x++)\n                  {\n                    /* To do: Rewrite using Get/Set***PixelChannel() */\n\n                    if (x == (ssize_t) (image->columns-length))\n                      m=(ssize_t) mng_info->magn_ml;\n\n                    else if (magn_methx > 1 && x == (ssize_t) image->columns-2)\n                      m=(ssize_t) mng_info->magn_mr;\n\n                    else if (magn_methx <= 1 &&\n                        x == (ssize_t) image->columns-1)\n                      m=(ssize_t) mng_info->magn_mr;\n\n                    else if (magn_methx > 1 && x == (ssize_t) image->columns-1)\n                      m=1;\n\n                    else\n                      m=(ssize_t) mng_info->magn_mx;\n\n                    for (i=0; i < m; i++)\n                    {\n                      if (magn_methx <= 1)\n                        {\n                          /* replicate previous */\n                          SetPixelRed(image,GetPixelRed(image,pixels),q);\n                          SetPixelGreen(image,GetPixelGreen(image,pixels),q);\n                          SetPixelBlue(image,GetPixelBlue(image,pixels),q);\n                          SetPixelAlpha(image,GetPixelAlpha(image,pixels),q);\n                        }\n\n                      else if (magn_methx == 2 || magn_methx == 4)\n                        {\n                          if (i == 0)\n                          {\n                            SetPixelRed(image,GetPixelRed(image,pixels),q);\n                            SetPixelGreen(image,GetPixelGreen(image,pixels),q);\n                            SetPixelBlue(image,GetPixelBlue(image,pixels),q);\n                            SetPixelAlpha(image,GetPixelAlpha(image,pixels),q);\n                          }\n\n                          /* To do: Rewrite using Get/Set***PixelChannel() */\n                          else\n                            {\n                              /* Interpolate */\n                              SetPixelRed(image,(QM) ((2*i*(\n                                 GetPixelRed(image,n)\n                                 -GetPixelRed(image,pixels))+m)\n                                 /((ssize_t) (m*2))+\n                                 GetPixelRed(image,pixels)),q);\n\n                              SetPixelGreen(image,(QM) ((2*i*(\n                                 GetPixelGreen(image,n)\n                                 -GetPixelGreen(image,pixels))+m)\n                                 /((ssize_t) (m*2))+\n                                 GetPixelGreen(image,pixels)),q);\n\n                              SetPixelBlue(image,(QM) ((2*i*(\n                                 GetPixelBlue(image,n)\n                                 -GetPixelBlue(image,pixels))+m)\n                                 /((ssize_t) (m*2))+\n                                 GetPixelBlue(image,pixels)),q);\n                              if (image->alpha_trait != UndefinedPixelTrait)\n                                 SetPixelAlpha(image,(QM) ((2*i*(\n                                   GetPixelAlpha(image,n)\n                                   -GetPixelAlpha(image,pixels))+m)\n                                   /((ssize_t) (m*2))+\n                                   GetPixelAlpha(image,pixels)),q);\n                            }\n\n                          if (magn_methx == 4)\n                            {\n                              /* Replicate nearest */\n                              if (i <= ((m+1) << 1))\n                              {\n                                 SetPixelAlpha(image,\n                                   GetPixelAlpha(image,pixels)+0,q);\n                              }\n                              else\n                              {\n                                 SetPixelAlpha(image,\n                                   GetPixelAlpha(image,n)+0,q);\n                              }\n                            }\n                        }\n\n                      else /* if (magn_methx == 3 || magn_methx == 5) */\n                        {\n                          /* Replicate nearest */\n                          if (i <= ((m+1) << 1))\n                          {\n                             SetPixelRed(image,GetPixelRed(image,pixels),q);\n                             SetPixelGreen(image,GetPixelGreen(image,\n                                 pixels),q);\n                             SetPixelBlue(image,GetPixelBlue(image,pixels),q);\n                             SetPixelAlpha(image,GetPixelAlpha(image,\n                                 pixels),q);\n                          }\n\n                          else\n                          {\n                             SetPixelRed(image,GetPixelRed(image,n),q);\n                             SetPixelGreen(image,GetPixelGreen(image,n),q);\n                             SetPixelBlue(image,GetPixelBlue(image,n),q);\n                             SetPixelAlpha(image,GetPixelAlpha(image,n),q);\n                          }\n\n                          if (magn_methx == 5)\n                            {\n                              /* Interpolate */\n                              SetPixelAlpha(image,\n                                 (QM) ((2*i*( GetPixelAlpha(image,n)\n                                 -GetPixelAlpha(image,pixels))+m)/\n                                 ((ssize_t) (m*2))\n                                 +GetPixelAlpha(image,pixels)),q);\n                            }\n                        }\n                      q+=GetPixelChannels(image);\n                    }\n                    n+=GetPixelChannels(image);\n                  }\n\n                  if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                    break;\n                }\n#if (MAGICKCORE_QUANTUM_DEPTH > 16)\n              if (magn_methx != 1 || magn_methy != 1)\n                {\n                /*\n                   Rescale pixels to Quantum\n                */\n                   for (y=0; y < (ssize_t) image->rows; y++)\n                   {\n                     q=GetAuthenticPixels(image,0,y,image->columns,1,\n                       exception);\n\n                     for (x=(ssize_t) image->columns-1; x >= 0; x--)\n                     {\n                        SetPixelRed(image,ScaleShortToQuantum(\n                          GetPixelRed(image,q)),q);\n                        SetPixelGreen(image,ScaleShortToQuantum(\n                          GetPixelGreen(image,q)),q);\n                        SetPixelBlue(image,ScaleShortToQuantum(\n                          GetPixelBlue(image,q)),q);\n                        SetPixelAlpha(image,ScaleShortToQuantum(\n                          GetPixelAlpha(image,q)),q);\n                        q+=GetPixelChannels(image);\n                     }\n\n                     if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                       break;\n                   }\n                }\n#endif\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"  Finished MAGN processing\");\n              }\n          }\n\n        /*\n          Crop_box is with respect to the upper left corner of the MNG.\n        */\n        crop_box.left=mng_info->image_box.left+mng_info->x_off[object_id];\n        crop_box.right=mng_info->image_box.right+mng_info->x_off[object_id];\n        crop_box.top=mng_info->image_box.top+mng_info->y_off[object_id];\n        crop_box.bottom=mng_info->image_box.bottom+mng_info->y_off[object_id];\n        crop_box=mng_minimum_box(crop_box,mng_info->clip);\n        crop_box=mng_minimum_box(crop_box,mng_info->frame);\n        crop_box=mng_minimum_box(crop_box,mng_info->object_clip[object_id]);\n        if ((crop_box.left != (mng_info->image_box.left\n            +mng_info->x_off[object_id])) ||\n            (crop_box.right != (mng_info->image_box.right\n            +mng_info->x_off[object_id])) ||\n            (crop_box.top != (mng_info->image_box.top\n            +mng_info->y_off[object_id])) ||\n            (crop_box.bottom != (mng_info->image_box.bottom\n            +mng_info->y_off[object_id])))\n          {\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  Crop the PNG image\");\n\n            if ((crop_box.left < crop_box.right) &&\n                (crop_box.top < crop_box.bottom))\n              {\n                Image\n                  *im;\n\n                RectangleInfo\n                  crop_info;\n\n                /*\n                  Crop_info is with respect to the upper left corner of\n                  the image.\n                */\n                crop_info.x=(crop_box.left-mng_info->x_off[object_id]);\n                crop_info.y=(crop_box.top-mng_info->y_off[object_id]);\n                crop_info.width=(size_t) (crop_box.right-crop_box.left);\n                crop_info.height=(size_t) (crop_box.bottom-crop_box.top);\n                image->page.width=image->columns;\n                image->page.height=image->rows;\n                image->page.x=0;\n                image->page.y=0;\n                im=CropImage(image,&crop_info,exception);\n\n                if (im != (Image *) NULL)\n                  {\n                    image->columns=im->columns;\n                    image->rows=im->rows;\n                    im=DestroyImage(im);\n                    image->page.width=image->columns;\n                    image->page.height=image->rows;\n                    image->page.x=crop_box.left;\n                    image->page.y=crop_box.top;\n                  }\n              }\n\n            else\n              {\n                /*\n                  No pixels in crop area.  The MNG spec still requires\n                  a layer, though, so make a single transparent pixel in\n                  the top left corner.\n                */\n                image->columns=1;\n                image->rows=1;\n                image->colors=2;\n                (void) SetImageBackgroundColor(image,exception);\n                image->page.width=1;\n                image->page.height=1;\n                image->page.x=0;\n                image->page.y=0;\n              }\n          }\n#ifndef PNG_READ_EMPTY_PLTE_SUPPORTED\n        image=mng_info->image;\n#endif\n      }\n\n#if (MAGICKCORE_QUANTUM_DEPTH > 16)\n      /* PNG does not handle depths greater than 16 so reduce it even\n       * if lossy.\n       */\n      if (image->depth > 16)\n         image->depth=16;\n#endif\n\n#if (MAGICKCORE_QUANTUM_DEPTH > 8)\n      if (image->depth > 8)\n        {\n          /* To do: fill low byte properly */\n          image->depth=16;\n        }\n\n      if (LosslessReduceDepthOK(image,exception) != MagickFalse)\n         image->depth = 8;\n#endif\n\n      if (image_info->number_scenes != 0)\n        {\n          if (mng_info->scenes_found >\n             (ssize_t) (image_info->first_scene+image_info->number_scenes))\n            break;\n        }\n\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  Finished reading image datastream.\");\n\n  } while (LocaleCompare(image_info->magick,\"MNG\") == 0);\n\n  (void) CloseBlob(image);\n\n  if (logging != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"  Finished reading all image datastreams.\");\n\n#if defined(MNG_INSERT_LAYERS)\n  if (insert_layers && !mng_info->image_found && (mng_info->mng_width) &&\n       (mng_info->mng_height))\n    {\n      /*\n        Insert a background layer if nothing else was found.\n      */\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  No images found.  Inserting a background layer.\");\n\n      if (GetAuthenticPixelQueue(image) != (Quantum *) NULL)\n        {\n          /*\n            Allocate next image structure.\n          */\n          AcquireNextImage(image_info,image,exception);\n          if (GetNextImageInList(image) == (Image *) NULL)\n            {\n              if (logging != MagickFalse)\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"  Allocation failed, returning NULL.\");\n\n              return(DestroyImageList(image));;\n            }\n          image=SyncNextImageInList(image);\n        }\n      image->columns=mng_info->mng_width;\n      image->rows=mng_info->mng_height;\n      image->page.width=mng_info->mng_width;\n      image->page.height=mng_info->mng_height;\n      image->page.x=0;\n      image->page.y=0;\n      image->background_color=mng_background_color;\n      image->alpha_trait=UndefinedPixelTrait;\n\n      if (image_info->ping == MagickFalse)\n        (void) SetImageBackgroundColor(image,exception);\n\n      mng_info->image_found++;\n    }\n#endif\n  image->iterations=mng_iterations;\n\n  if (mng_iterations == 1)\n    image->start_loop=MagickTrue;\n\n  while (GetPreviousImageInList(image) != (Image *) NULL)\n  {\n    image_count++;\n    if (image_count > 10*mng_info->image_found)\n      {\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\"  No beginning\");\n\n        (void) ThrowMagickException(exception,GetMagickModule(),\n          CoderError,\"Linked list is corrupted, beginning of list not found\",\n          \"`%s'\",image_info->filename);\n\n        return(DestroyImageList(image));\n      }\n\n    image=GetPreviousImageInList(image);\n\n    if (GetNextImageInList(image) == (Image *) NULL)\n      {\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\"  Corrupt list\");\n\n        (void) ThrowMagickException(exception,GetMagickModule(),\n          CoderError,\"Linked list is corrupted; next_image is NULL\",\"`%s'\",\n          image_info->filename);\n      }\n  }\n\n  if (mng_info->ticks_per_second && mng_info->image_found > 1 &&\n             GetNextImageInList(image) ==\n     (Image *) NULL)\n    {\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  First image null\");\n\n      (void) ThrowMagickException(exception,GetMagickModule(),\n        CoderError,\"image->next for first image is NULL but shouldn't be.\",\n        \"`%s'\",image_info->filename);\n    }\n\n  if (mng_info->image_found == 0)\n    {\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  No visible images found.\");\n\n      (void) ThrowMagickException(exception,GetMagickModule(),\n        CoderError,\"No visible images in file\",\"`%s'\",image_info->filename);\n\n      return(DestroyImageList(image));\n    }\n\n  if (mng_info->ticks_per_second)\n    final_delay=1UL*MagickMax(image->ticks_per_second,1L)*\n            final_delay/mng_info->ticks_per_second;\n\n  else\n    image->start_loop=MagickTrue;\n\n  /* Find final nonzero image delay */\n  final_image_delay=0;\n\n  while (GetNextImageInList(image) != (Image *) NULL)\n    {\n      if (image->delay)\n        final_image_delay=image->delay;\n\n      image=GetNextImageInList(image);\n    }\n\n  if (final_delay < final_image_delay)\n    final_delay=final_image_delay;\n\n  image->delay=final_delay;\n\n  if (logging != MagickFalse)\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"  image->delay=%.20g, final_delay=%.20g\",(double) image->delay,\n        (double) final_delay);\n\n  if (logging != MagickFalse)\n    {\n      int\n        scene;\n\n      scene=0;\n      image=GetFirstImageInList(image);\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"  Before coalesce:\");\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"    scene 0 delay=%.20g\",(double) image->delay);\n\n      while (GetNextImageInList(image) != (Image *) NULL)\n      {\n        image=GetNextImageInList(image);\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"    scene %.20g delay=%.20g\",(double) scene++,\n          (double) image->delay);\n      }\n    }\n\n  image=GetFirstImageInList(image);\n#ifdef MNG_COALESCE_LAYERS\n  if (insert_layers)\n    {\n      Image\n        *next_image,\n        *next;\n\n      size_t\n        scene;\n\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  Coalesce Images\");\n\n      scene=image->scene;\n      next_image=CoalesceImages(image,exception);\n\n      if (next_image == (Image *) NULL)\n        ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n\n      image=DestroyImageList(image);\n      image=next_image;\n\n      for (next=image; next != (Image *) NULL; next=next_image)\n      {\n         next->page.width=mng_info->mng_width;\n         next->page.height=mng_info->mng_height;\n         next->page.x=0;\n         next->page.y=0;\n         next->scene=scene++;\n         next_image=GetNextImageInList(next);\n\n         if (next_image == (Image *) NULL)\n           break;\n\n         if (next->delay == 0)\n           {\n             scene--;\n             next_image->previous=GetPreviousImageInList(next);\n             if (GetPreviousImageInList(next) == (Image *) NULL)\n               image=next_image;\n             else\n               next->previous->next=next_image;\n             next=DestroyImage(next);\n           }\n      }\n    }\n#endif\n\n  while (GetNextImageInList(image) != (Image *) NULL)\n      image=GetNextImageInList(image);\n\n  image->dispose=BackgroundDispose;\n\n  if (logging != MagickFalse)\n    {\n      int\n        scene;\n\n      scene=0;\n      image=GetFirstImageInList(image);\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"  After coalesce:\");\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"    scene 0 delay=%.20g dispose=%.20g\",(double) image->delay,\n        (double) image->dispose);\n\n      while (GetNextImageInList(image) != (Image *) NULL)\n      {\n        image=GetNextImageInList(image);\n\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"    scene %.20g delay=%.20g dispose=%.20g\",(double) scene++,\n          (double) image->delay,(double) image->dispose);\n      }\n   }\n\n  if (logging != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"  exit ReadOneMNGImage();\");\n\n  return(image);\n}",
        "func_hash": 112335411773175147602521832461985951659,
        "file_name": "png.c",
        "file_hash": 320300249685897026258566713334395171716,
        "cwe": [
            "CWE-125"
        ],
        "cve": "CVE-2017-13139",
        "cve_desc": "In ImageMagick before 6.9.9-0 and 7.x before 7.0.6-1, the ReadOneMNGImage function in coders/png.c has an out-of-bounds read with the MNG CLIP chunk.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2017-13139",
        "func_name": "ReadOneMNGImage",
        "diff": [
            "diff --git a/coders/png.c b/coders/png.c\nindex d6d33ee3603..ea6dce6ab5f 100644\n--- a/coders/png.c\n+++ b/coders/png.c\n@@ -5899,6 +5899,9 @@ static Image *ReadOneMNGImage(MngInfo* mng_info, const ImageInfo *image_info,\n \n                 for (i=(int) first_object; i <= (int) last_object; i++)\n                 {\n+                  if ((i < 0) || (i >= MNG_MAX_OBJECTS))\n+                    continue;\n+\n                   if (mng_info->exists[i] && !mng_info->frozen[i])\n                     {\n                       MngBox\n"
        ],
        "func_after": []
    },
    {
        "idx": 195954,
        "project": "pjproject",
        "commit_id": "9fae8f43accef8ea65d4a8ae9cdf297c46cfe29a",
        "project_url": "https://github.com/pjsip/pjproject",
        "commit_url": "https://github.com/pjsip/pjproject/commit/9fae8f43accef8ea65d4a8ae9cdf297c46cfe29a",
        "commit_message": "Merge pull request from GHSA-p6g5-v97c-w5q4\n\n* Prevent heap buffer overflow when parsing DNS packets\n\n* Make sure packet parsing doesn't advance beyond max/end\n\n* Update checks\n\n* Remove  check\n\nCo-authored-by: sauwming <ming@teluu.com>",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static pj_status_t parse_query(pj_dns_parsed_query *q, pj_pool_t *pool,\n\t\t\t       const pj_uint8_t *pkt, const pj_uint8_t *start,\n\t\t\t       const pj_uint8_t *max, int *parsed_len)\n{\n    const pj_uint8_t *p = start;\n    int name_len, name_part_len;\n    pj_status_t status;\n\n    /* Get the length of the name */\n    status = get_name_len(0, pkt, start, max, &name_part_len, &name_len);\n    if (status != PJ_SUCCESS)\n\treturn status;\n\n    /* Allocate memory for the name */\n    q->name.ptr = (char*) pj_pool_alloc(pool, name_len+4);\n    q->name.slen = 0;\n\n    /* Get the name */\n    status = get_name(0, pkt, start, max, &q->name);\n    if (status != PJ_SUCCESS)\n\treturn status;\n\n    p = (start + name_part_len);\n\n    /* Get the type */\n    pj_memcpy(&q->type, p, 2);\n    q->type = pj_ntohs(q->type);\n    p += 2;\n\n    /* Get the class */\n    pj_memcpy(&q->dnsclass, p, 2);\n    q->dnsclass = pj_ntohs(q->dnsclass);\n    p += 2;\n\n    *parsed_len = (int)(p - start);\n\n    return PJ_SUCCESS;\n}",
        "func_hash": 135450072303259419822933820270333517166,
        "file_name": "dns.c",
        "file_hash": 253652259492393007596255371845847130395,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2022-24793",
        "cve_desc": "PJSIP is a free and open source multimedia communication library written in C. A buffer overflow vulnerability in versions 2.12 and prior affects applications that use PJSIP DNS resolution. It doesn't affect PJSIP users who utilize an external resolver. This vulnerability is related to CVE-2023-27585. The difference is that this issue is in parsing the query record `parse_rr()`, while the issue in CVE-2023-27585 is in `parse_query()`. A patch is available in the `master` branch of the `pjsip/pjproject` GitHub repository. A workaround is to disable DNS resolution in PJSIP config (by setting `nameserver_count` to zero) or use an external resolver instead.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-24793",
        "func_name": "parse_query",
        "diff": [
            "diff --git a/pjlib-util/src/pjlib-util/dns.c b/pjlib-util/src/pjlib-util/dns.c\nindex df47c83b9d..1f712eeced 100644\n--- a/pjlib-util/src/pjlib-util/dns.c\n+++ b/pjlib-util/src/pjlib-util/dns.c\n@@ -159,8 +159,13 @@ static pj_status_t get_name_len(int rec_counter, const pj_uint8_t *pkt,\n \t} else {\n \t    unsigned label_len = *p;\n \n-\t    /* Check that label length is valid */\n-\t    if (pkt+label_len > max)\n+\t    /* Check that label length is valid.\n+\t     * Each label consists of an octet length (of size 1) followed\n+\t     * by the octet of the specified length (label_len). Then it\n+\t     * must be followed by either another label's octet length or\n+\t     * a zero length octet (that terminates the sequence).\n+\t     */\n+\t    if (p+1+label_len+1 > max)\n \t\treturn PJLIB_UTIL_EDNSINNAMEPTR;\n \n \t    p += (label_len + 1);\n@@ -170,9 +175,6 @@ static pj_status_t get_name_len(int rec_counter, const pj_uint8_t *pkt,\n \t\t++label_len;\n \t    \n \t    *name_len += label_len;\n-\n-\t    if (p >= max)\n-\t\treturn PJLIB_UTIL_EDNSINSIZE;\n \t}\n     }\n     ++p;\n@@ -222,8 +224,13 @@ static pj_status_t get_name(int rec_counter, const pj_uint8_t *pkt,\n \t} else {\n \t    unsigned label_len = *p;\n \n-\t    /* Check that label length is valid */\n-\t    if (pkt+label_len > max)\n+\t    /* Check that label length is valid.\n+\t     * Each label consists of an octet length (of size 1) followed\n+\t     * by the octet of the specified length (label_len). Then it\n+\t     * must be followed by either another label's octet length or\n+\t     * a zero length octet (that terminates the sequence).\n+\t     */\n+\t    if (p+1+label_len+1 > max)\n \t\treturn PJLIB_UTIL_EDNSINNAMEPTR;\n \n \t    pj_memcpy(name->ptr + name->slen, p+1, label_len);\n@@ -234,9 +241,6 @@ static pj_status_t get_name(int rec_counter, const pj_uint8_t *pkt,\n \t\t*(name->ptr + name->slen) = '.';\n \t\t++name->slen;\n \t    }\n-\n-\t    if (p >= max)\n-\t\treturn PJLIB_UTIL_EDNSINSIZE;\n \t}\n     }\n \n@@ -269,6 +273,10 @@ static pj_status_t parse_query(pj_dns_parsed_query *q, pj_pool_t *pool,\n \n     p = (start + name_part_len);\n \n+    /* Check the size can accomodate next few fields. */\n+    if (p + 4 > max)\n+    \treturn PJLIB_UTIL_EDNSINSIZE;\n+\n     /* Get the type */\n     pj_memcpy(&q->type, p, 2);\n     q->type = pj_ntohs(q->type);\n"
        ],
        "func_after": []
    },
    {
        "idx": 195965,
        "project": "tensorflow",
        "commit_id": "30721cf564cb029d34535446d6a5a6357bebc8e7",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/30721cf564cb029d34535446d6a5a6357bebc8e7",
        "commit_message": "Fix tf.raw_ops.EditDistance vulnerability with negative indices.\n\nCheck that indices are non-negative. Fix several identical code sites.\nClean up grammar in error message.\n\nPiperOrigin-RevId: 445442017",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor* hypothesis_indices;\n    const Tensor* hypothesis_values;\n    const Tensor* hypothesis_shape;\n    const Tensor* truth_indices;\n    const Tensor* truth_values;\n    const Tensor* truth_shape;\n    OP_REQUIRES_OK(ctx, ctx->input(\"hypothesis_indices\", &hypothesis_indices));\n    OP_REQUIRES_OK(ctx, ctx->input(\"hypothesis_values\", &hypothesis_values));\n    OP_REQUIRES_OK(ctx, ctx->input(\"hypothesis_shape\", &hypothesis_shape));\n    OP_REQUIRES_OK(ctx, ctx->input(\"truth_indices\", &truth_indices));\n    OP_REQUIRES_OK(ctx, ctx->input(\"truth_values\", &truth_values));\n    OP_REQUIRES_OK(ctx, ctx->input(\"truth_shape\", &truth_shape));\n\n    OP_REQUIRES_OK(\n        ctx, ValidateShapes(ctx, *hypothesis_indices, *hypothesis_values,\n                            *hypothesis_shape, *truth_indices, *truth_values,\n                            *truth_shape));\n\n    TensorShape hypothesis_st_shape;\n    OP_REQUIRES_OK(ctx,\n                   TensorShapeUtils::MakeShape(\n                       hypothesis_shape->vec<int64_t>().data(),\n                       hypothesis_shape->NumElements(), &hypothesis_st_shape));\n    TensorShape truth_st_shape;\n    OP_REQUIRES_OK(ctx, TensorShapeUtils::MakeShape(\n                            truth_shape->vec<int64_t>().data(),\n                            truth_shape->NumElements(), &truth_st_shape));\n\n    // Assume indices are sorted in row-major order.\n    std::vector<int64_t> sorted_order(truth_st_shape.dims());\n    std::iota(sorted_order.begin(), sorted_order.end(), 0);\n\n    sparse::SparseTensor hypothesis;\n    OP_REQUIRES_OK(ctx, sparse::SparseTensor::Create(\n                            *hypothesis_indices, *hypothesis_values,\n                            hypothesis_st_shape, sorted_order, &hypothesis));\n\n    sparse::SparseTensor truth;\n    OP_REQUIRES_OK(ctx, sparse::SparseTensor::Create(\n                            *truth_indices, *truth_values, truth_st_shape,\n                            sorted_order, &truth));\n\n    // Group dims 0, 1, ..., RANK - 1.  The very last dim is assumed\n    // to store the variable length sequences.\n    std::vector<int64_t> group_dims(truth_st_shape.dims() - 1);\n    std::iota(group_dims.begin(), group_dims.end(), 0);\n\n    TensorShape output_shape;\n    for (int d = 0; d < static_cast<int>(group_dims.size()); ++d) {\n      output_shape.AddDim(std::max(hypothesis_st_shape.dim_size(d),\n                                   truth_st_shape.dim_size(d)));\n    }\n    const auto output_elements = output_shape.num_elements();\n    OP_REQUIRES(\n        ctx, output_elements > 0,\n        errors::InvalidArgument(\"Got output shape \", output_shape.DebugString(),\n                                \" which has 0 elements\"));\n\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->allocate_output(\"output\", output_shape, &output));\n    auto output_t = output->flat<float>();\n    output_t.setZero();\n\n    std::vector<int64_t> output_strides(output_shape.dims());\n    output_strides[output_shape.dims() - 1] = 1;\n    for (int d = output_shape.dims() - 2; d >= 0; --d) {\n      output_strides[d] = output_strides[d + 1] * output_shape.dim_size(d + 1);\n    }\n\n    auto hypothesis_grouper = hypothesis.group(group_dims);\n    auto truth_grouper = truth.group(group_dims);\n\n    auto hypothesis_iter = hypothesis_grouper.begin();\n    auto truth_iter = truth_grouper.begin();\n\n    auto cmp = std::equal_to<T>();\n\n    while (hypothesis_iter != hypothesis_grouper.end() &&\n           truth_iter != truth_grouper.end()) {\n      sparse::Group truth_i = *truth_iter;\n      sparse::Group hypothesis_j = *hypothesis_iter;\n      std::vector<int64_t> g_truth = truth_i.group();\n      std::vector<int64_t> g_hypothesis = hypothesis_j.group();\n      auto truth_seq = truth_i.values<T>();\n      auto hypothesis_seq = hypothesis_j.values<T>();\n\n      if (g_truth == g_hypothesis) {\n        auto loc = std::inner_product(g_truth.begin(), g_truth.end(),\n                                      output_strides.begin(), int64_t{0});\n        OP_REQUIRES(\n            ctx, loc < output_elements,\n            errors::Internal(\"Got an inner product \", loc,\n                             \" which would require in writing to outside of \"\n                             \"the buffer for the output tensor (max elements \",\n                             output_elements, \")\"));\n        output_t(loc) =\n            gtl::LevenshteinDistance<T>(truth_seq, hypothesis_seq, cmp);\n        if (normalize_) output_t(loc) /= truth_seq.size();\n\n        ++hypothesis_iter;\n        ++truth_iter;\n      } else if (g_truth > g_hypothesis) {  // zero-length truth\n        auto loc = std::inner_product(g_hypothesis.begin(), g_hypothesis.end(),\n                                      output_strides.begin(), int64_t{0});\n        OP_REQUIRES(\n            ctx, loc < output_elements,\n            errors::Internal(\"Got an inner product \", loc,\n                             \" which would require in writing to outside of \"\n                             \"the buffer for the output tensor (max elements \",\n                             output_elements, \")\"));\n        output_t(loc) = hypothesis_seq.size();\n        if (normalize_ && output_t(loc) != 0.0f) {\n          output_t(loc) = std::numeric_limits<float>::infinity();\n        }\n        ++hypothesis_iter;\n      } else {  // zero-length hypothesis\n        auto loc = std::inner_product(g_truth.begin(), g_truth.end(),\n                                      output_strides.begin(), int64_t{0});\n        OP_REQUIRES(\n            ctx, loc < output_elements,\n            errors::Internal(\"Got an inner product \", loc,\n                             \" which would require in writing to outside of \"\n                             \"the buffer for the output tensor (max elements \",\n                             output_elements, \")\"));\n        output_t(loc) = (normalize_) ? 1.0 : truth_seq.size();\n        ++truth_iter;\n      }\n    }\n    while (hypothesis_iter != hypothesis_grouper.end()) {  // zero-length truths\n      sparse::Group hypothesis_j = *hypothesis_iter;\n      std::vector<int64_t> g_hypothesis = hypothesis_j.group();\n      auto hypothesis_seq = hypothesis_j.values<T>();\n      auto loc = std::inner_product(g_hypothesis.begin(), g_hypothesis.end(),\n                                    output_strides.begin(), int64_t{0});\n      OP_REQUIRES(\n          ctx, loc < output_elements,\n          errors::Internal(\"Got an inner product \", loc,\n                           \" which would require in writing to outside of the \"\n                           \"buffer for the output tensor (max elements \",\n                           output_elements, \")\"));\n      output_t(loc) = hypothesis_seq.size();\n      if (normalize_ && output_t(loc) != 0.0f) {\n        output_t(loc) = std::numeric_limits<float>::infinity();\n      }\n      ++hypothesis_iter;\n    }\n    while (truth_iter != truth_grouper.end()) {  // missing hypotheses\n      sparse::Group truth_i = *truth_iter;\n      std::vector<int64_t> g_truth = truth_i.group();\n      auto truth_seq = truth_i.values<T>();\n      auto loc = std::inner_product(g_truth.begin(), g_truth.end(),\n                                    output_strides.begin(), int64_t{0});\n      OP_REQUIRES(\n          ctx, loc < output_elements,\n          errors::Internal(\"Got an inner product \", loc,\n                           \" which would require in writing to outside of the \"\n                           \"buffer for the output tensor (max elements \",\n                           output_elements, \")\"));\n      output_t(loc) = (normalize_) ? 1.0 : truth_seq.size();\n      ++truth_iter;\n    }\n  }",
        "func_hash": 330908344605810468129440704571471984591,
        "file_name": "edit_distance_op.cc",
        "file_hash": 218278977682570302037113861275408263141,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2022-29208",
        "cve_desc": "TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, the implementation of `tf.raw_ops.EditDistance` has incomplete validation. Users can pass negative values to cause a segmentation fault based denial of service. In multiple places throughout the code, one may compute an index for a write operation. However, the existing validation only checks against the upper bound of the array. Hence, it is possible to write before the array by massaging the input to generate negative values for `loc`. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-29208",
        "func_name": "Compute",
        "diff": [
            "diff --git a/tensorflow/core/kernels/edit_distance_op.cc b/tensorflow/core/kernels/edit_distance_op.cc\nindex 3ff290e92b6103..3ed0f012b83ceb 100644\n--- a/tensorflow/core/kernels/edit_distance_op.cc\n+++ b/tensorflow/core/kernels/edit_distance_op.cc\n@@ -203,9 +203,9 @@ class EditDistanceOp : public OpKernel {\n         auto loc = std::inner_product(g_truth.begin(), g_truth.end(),\n                                       output_strides.begin(), int64_t{0});\n         OP_REQUIRES(\n-            ctx, loc < output_elements,\n+            ctx, 0 <= loc && loc < output_elements,\n             errors::Internal(\"Got an inner product \", loc,\n-                             \" which would require in writing to outside of \"\n+                             \" which would require writing to outside of \"\n                              \"the buffer for the output tensor (max elements \",\n                              output_elements, \")\"));\n         output_t(loc) =\n@@ -218,9 +218,9 @@ class EditDistanceOp : public OpKernel {\n         auto loc = std::inner_product(g_hypothesis.begin(), g_hypothesis.end(),\n                                       output_strides.begin(), int64_t{0});\n         OP_REQUIRES(\n-            ctx, loc < output_elements,\n+            ctx, 0 <= loc && loc < output_elements,\n             errors::Internal(\"Got an inner product \", loc,\n-                             \" which would require in writing to outside of \"\n+                             \" which would require writing to outside of \"\n                              \"the buffer for the output tensor (max elements \",\n                              output_elements, \")\"));\n         output_t(loc) = hypothesis_seq.size();\n@@ -232,9 +232,9 @@ class EditDistanceOp : public OpKernel {\n         auto loc = std::inner_product(g_truth.begin(), g_truth.end(),\n                                       output_strides.begin(), int64_t{0});\n         OP_REQUIRES(\n-            ctx, loc < output_elements,\n+            ctx, 0 <= loc && loc < output_elements,\n             errors::Internal(\"Got an inner product \", loc,\n-                             \" which would require in writing to outside of \"\n+                             \" which would require writing to outside of \"\n                              \"the buffer for the output tensor (max elements \",\n                              output_elements, \")\"));\n         output_t(loc) = (normalize_) ? 1.0 : truth_seq.size();\n@@ -248,9 +248,9 @@ class EditDistanceOp : public OpKernel {\n       auto loc = std::inner_product(g_hypothesis.begin(), g_hypothesis.end(),\n                                     output_strides.begin(), int64_t{0});\n       OP_REQUIRES(\n-          ctx, loc < output_elements,\n+          ctx, 0 <= loc && loc < output_elements,\n           errors::Internal(\"Got an inner product \", loc,\n-                           \" which would require in writing to outside of the \"\n+                           \" which would require writing to outside of the \"\n                            \"buffer for the output tensor (max elements \",\n                            output_elements, \")\"));\n       output_t(loc) = hypothesis_seq.size();\n@@ -266,9 +266,9 @@ class EditDistanceOp : public OpKernel {\n       auto loc = std::inner_product(g_truth.begin(), g_truth.end(),\n                                     output_strides.begin(), int64_t{0});\n       OP_REQUIRES(\n-          ctx, loc < output_elements,\n+          ctx, 0 <= loc && loc < output_elements,\n           errors::Internal(\"Got an inner product \", loc,\n-                           \" which would require in writing to outside of the \"\n+                           \" which would require writing to outside of the \"\n                            \"buffer for the output tensor (max elements \",\n                            output_elements, \")\"));\n       output_t(loc) = (normalize_) ? 1.0 : truth_seq.size();\ndiff --git a/tensorflow/python/kernel_tests/array_ops/edit_distance_op_test.py b/tensorflow/python/kernel_tests/array_ops/edit_distance_op_test.py\nindex 9996a4f621e4bf..b74024aa60c8b6 100644\n--- a/tensorflow/python/kernel_tests/array_ops/edit_distance_op_test.py\n+++ b/tensorflow/python/kernel_tests/array_ops/edit_distance_op_test.py\n@@ -207,6 +207,24 @@ def testEditDistanceZeroLengthHypothesisAndTruth(self):\n         normalize=True,\n         expected_output=expected_output)\n \n+  def testEditDistanceBadIndices(self):\n+    hypothesis_indices = np.full((3, 3), -1250999896764, dtype=np.int64)\n+    hypothesis_values = np.empty(3, dtype=np.int64)\n+    hypothesis_shape = np.empty(3, dtype=np.int64)\n+    truth_indices = np.full((3, 3), -1250999896764, dtype=np.int64)\n+    truth_values = np.full([3], 2, dtype=np.int64)\n+    truth_shape = np.full([3], 2, dtype=np.int64)\n+    expected_output = []  # dummy; ignored\n+\n+    self._testEditDistance(\n+        hypothesis=(hypothesis_indices, hypothesis_values, hypothesis_shape),\n+        truth=(truth_indices, truth_values, truth_shape),\n+        normalize=False,\n+        expected_output=expected_output,\n+        expected_err_re=(r\"inner product -\\d+ which would require writing \"\n+                         \"to outside of the buffer for the output tensor\")\n+    )\n+\n \n if __name__ == \"__main__\":\n   test.main()\n"
        ],
        "func_after": []
    },
    {
        "idx": 195984,
        "project": "gpac",
        "commit_id": "3dbe11b37d65c8472faf0654410068e5500b3adb",
        "project_url": "https://github.com/gpac/gpac",
        "commit_url": "https://github.com/gpac/gpac/commit/3dbe11b37d65c8472faf0654410068e5500b3adb",
        "commit_message": "fixed #2175",
        "target": 1,
        "irrelevant": 1,
        "func_before": "GF_Err diST_box_read(GF_Box *s, GF_BitStream *bs)\n{\n\tu32 i;\n\tchar str[1024];\n\tGF_DIMSScriptTypesBox *p = (GF_DIMSScriptTypesBox *)s;\n\n\ti=0;\n\tstr[0]=0;\n\twhile (1) {\n\t\tstr[i] = gf_bs_read_u8(bs);\n\t\tif (!str[i]) break;\n\t\ti++;\n\t}\n\tISOM_DECREASE_SIZE(p, i);\n\n\tp->content_script_types = gf_strdup(str);\n\treturn GF_OK;\n}",
        "func_hash": 337508066102203205232219987774332438264,
        "file_name": "box_code_3gpp.c",
        "file_hash": 236995747067078276861335410375287788449,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2022-1441",
        "cve_desc": "MP4Box is a component of GPAC-2.0.0, which is a widely-used third-party package on RPM Fusion. When MP4Box tries to parse a MP4 file, it calls the function `diST_box_read()` to read from video. In this function, it allocates a buffer `str` with fixed length. However, content read from `bs` is controllable by user, so is the length, which causes a buffer overflow.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-1441",
        "func_name": "diST_box_read",
        "diff": [
            "diff --git a/src/isomedia/box_code_3gpp.c b/src/isomedia/box_code_3gpp.c\nindex 3f9ff05692..928a5575f2 100644\n--- a/src/isomedia/box_code_3gpp.c\n+++ b/src/isomedia/box_code_3gpp.c\n@@ -1128,20 +1128,12 @@ void diST_box_del(GF_Box *s)\n \n GF_Err diST_box_read(GF_Box *s, GF_BitStream *bs)\n {\n-\tu32 i;\n-\tchar str[1024];\n \tGF_DIMSScriptTypesBox *p = (GF_DIMSScriptTypesBox *)s;\n \n-\ti=0;\n-\tstr[0]=0;\n-\twhile (1) {\n-\t\tstr[i] = gf_bs_read_u8(bs);\n-\t\tif (!str[i]) break;\n-\t\ti++;\n-\t}\n-\tISOM_DECREASE_SIZE(p, i);\n-\n-\tp->content_script_types = gf_strdup(str);\n+\tp->content_script_types = gf_malloc(sizeof(char) * (s->size+1));\n+\tif (!p->content_script_types) return GF_OUT_OF_MEM;\n+\tgf_bs_read_data(bs, p->content_script_types, s->size);\n+\tp->content_script_types[s->size] = 0;\n \treturn GF_OK;\n }\n \n"
        ],
        "func_after": []
    },
    {
        "idx": 196231,
        "project": "tensorflow",
        "commit_id": "b619c6f865715ca3b15ef1842b5b95edbaa710ad",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/b619c6f865715ca3b15ef1842b5b95edbaa710ad",
        "commit_message": "Use BuildTensorShapeBase when parsing unverified TensorShapes during checkpoint loading.\n\nThis avoids crashing when the TensorShape has negative dimensions.\n\nPiperOrigin-RevId: 392769882\nChange-Id: Id1f7ae7fcf8142193556af47abfda81b13d3cce4",
        "target": 1,
        "irrelevant": 0,
        "func_before": "void TensorSliceReader::LoadShard(int shard) const {\n  CHECK_LT(shard, sss_.size());\n  if (sss_[shard] || !status_.ok()) {\n    return;  // Already loaded, or invalid.\n  }\n  string value;\n  SavedTensorSlices sts;\n  const string fname = fnames_[shard];\n  VLOG(1) << \"Reading meta data from file \" << fname << \"...\";\n  Table* table;\n  Status s = open_function_(fname, &table);\n  if (!s.ok()) {\n    status_ = errors::DataLoss(\"Unable to open table file \", fname, \": \",\n                               s.ToString());\n    return;\n  }\n  sss_[shard].reset(table);\n  if (!(table->Get(kSavedTensorSlicesKey, &value) &&\n        ParseProtoUnlimited(&sts, value))) {\n    status_ = errors::Internal(\n        \"Failed to find the saved tensor slices at the beginning of the \"\n        \"checkpoint file: \",\n        fname);\n    return;\n  }\n  status_ = CheckVersions(sts.meta().versions(), TF_CHECKPOINT_VERSION,\n                          TF_CHECKPOINT_VERSION_MIN_PRODUCER, \"Checkpoint\",\n                          \"checkpoint\");\n  if (!status_.ok()) return;\n  for (const SavedSliceMeta& ssm : sts.meta().tensor()) {\n    TensorShape ssm_shape(ssm.shape());\n    for (const TensorSliceProto& tsp : ssm.slice()) {\n      TensorSlice ss_slice(tsp);\n      status_ = RegisterTensorSlice(ssm.name(), ssm_shape, ssm.type(), fname,\n                                    ss_slice, &tensors_);\n      if (!status_.ok()) return;\n    }\n  }\n}",
        "func_hash": 142353236440749935149556768782118562464,
        "file_name": "tensor_slice_reader.cc",
        "file_hash": 273719145932163646554963802660605302118,
        "cwe": [
            "CWE-369"
        ],
        "cve": "CVE-2021-41203",
        "cve_desc": "TensorFlow is an open source platform for machine learning. In affected versions an attacker can trigger undefined behavior, integer overflows, segfaults and `CHECK`-fail crashes if they can change saved checkpoints from outside of TensorFlow. This is because the checkpoints loading infrastructure is missing validation for invalid file formats. The fixes will be included in TensorFlow 2.7.0. We will also cherrypick these commits on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-41203",
        "func_name": "TensorSliceReader::LoadShard",
        "diff": [
            "diff --git a/tensorflow/core/util/tensor_slice_reader.cc b/tensorflow/core/util/tensor_slice_reader.cc\nindex 00911b13f34914..da5ac17ee0eaef 100644\n--- a/tensorflow/core/util/tensor_slice_reader.cc\n+++ b/tensorflow/core/util/tensor_slice_reader.cc\n@@ -168,7 +168,9 @@ void TensorSliceReader::LoadShard(int shard) const {\n                           \"checkpoint\");\n   if (!status_.ok()) return;\n   for (const SavedSliceMeta& ssm : sts.meta().tensor()) {\n-    TensorShape ssm_shape(ssm.shape());\n+    TensorShape ssm_shape;\n+    status_ = TensorShape::BuildTensorShapeBase(ssm.shape(), &ssm_shape);\n+    if (!status_.ok()) return;\n     for (const TensorSliceProto& tsp : ssm.slice()) {\n       TensorSlice ss_slice(tsp);\n       status_ = RegisterTensorSlice(ssm.name(), ssm_shape, ssm.type(), fname,\ndiff --git a/tensorflow/core/util/tensor_slice_reader_test.cc b/tensorflow/core/util/tensor_slice_reader_test.cc\nindex 9bd3063d4ebec3..382e29ab321984 100644\n--- a/tensorflow/core/util/tensor_slice_reader_test.cc\n+++ b/tensorflow/core/util/tensor_slice_reader_test.cc\n@@ -18,6 +18,7 @@ limitations under the License.\n #include <utility>\n #include <vector>\n \n+#include \"tensorflow/core/framework/tensor_shape.pb.h\"\n #include \"tensorflow/core/framework/types.h\"\n #include \"tensorflow/core/framework/versions.pb.h\"\n #include \"tensorflow/core/lib/core/status_test_util.h\"\n@@ -410,6 +411,31 @@ TEST(TensorSliceReaderTest, UnsupportedTensorType) {\n   EXPECT_FALSE(reader.GetTensor(\"test\", &tensor).ok());\n }\n \n+TEST(TensorSliceReaderTest, NegativeTensorShapeDimension) {\n+  const string fname =\n+      io::JoinPath(testing::TmpDir(), \"negative_dim_checkpoint\");\n+  TensorSliceWriter writer(fname, CreateTableTensorSliceBuilder);\n+  const int32 data[] = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9};\n+  TF_CHECK_OK(writer.Add(\"test\", TensorShape({4, 5}),\n+                         TensorSlice::ParseOrDie(\"0,2:-\"), data));\n+  TF_CHECK_OK(writer.Finish());\n+\n+  MutateSavedTensorSlices(fname, [](SavedTensorSlices sts) {\n+    if (sts.has_meta()) {\n+      for (auto& tensor : *sts.mutable_meta()->mutable_tensor()) {\n+        for (auto& dim : *tensor.mutable_shape()->mutable_dim()) {\n+          dim.set_size(-dim.size());\n+        }\n+      }\n+    }\n+    return sts.SerializeAsString();\n+  });\n+\n+  TensorSliceReader reader(fname, OpenTableTensorSliceReader);\n+  // The negative dimension should cause loading to fail.\n+  EXPECT_FALSE(reader.status().ok());\n+}\n+\n void CachedTensorSliceReaderTesterHelper(\n     const TensorSliceWriter::CreateBuilderFunction& create_function,\n     const TensorSliceReader::OpenTableFunction& open_function) {\n"
        ],
        "func_after": []
    },
    {
        "idx": 196276,
        "project": "lsquic",
        "commit_id": "a74702c630e108125e71898398737baec8f02238",
        "project_url": "https://github.com/litespeedtech/lsquic",
        "commit_url": "https://github.com/litespeedtech/lsquic/commit/a74702c630e108125e71898398737baec8f02238",
        "commit_message": "Release 3.1.0",
        "target": 1,
        "irrelevant": 0,
        "func_before": "lsquic_qeh_settings (struct qpack_enc_hdl *qeh, unsigned max_table_size,\n             unsigned dyn_table_size, unsigned max_risked_streams, int server)\n{\n    enum lsqpack_enc_opts enc_opts;\n\n    assert(qeh->qeh_flags & QEH_INITIALIZED);\n\n    if (qeh->qeh_flags & QEH_HAVE_SETTINGS)\n    {\n        LSQ_WARN(\"settings already set\");\n        return -1;\n    }\n\n    enc_opts = LSQPACK_ENC_OPT_STAGE_2\n             | (server ? LSQPACK_ENC_OPT_SERVER : 0);\n    qeh->qeh_tsu_sz = sizeof(qeh->qeh_tsu_buf);\n    if (0 != lsqpack_enc_init(&qeh->qeh_encoder, (void *) qeh->qeh_conn,\n                max_table_size, dyn_table_size, max_risked_streams, enc_opts,\n                qeh->qeh_tsu_buf, &qeh->qeh_tsu_sz))\n    {\n        LSQ_INFO(\"could not initialize QPACK encoder\");\n        return -1;\n    }\n    LSQ_DEBUG(\"%zu-byte post-init TSU\", qeh->qeh_tsu_sz);\n    qeh->qeh_flags |= QEH_HAVE_SETTINGS;\n    qeh->qeh_max_prefix_size =\n                        lsqpack_enc_header_block_prefix_size(&qeh->qeh_encoder);\n    LSQ_DEBUG(\"have settings: max table size=%u; dyn table size=%u; max risked \"\n        \"streams=%u\", max_table_size, dyn_table_size, max_risked_streams);\n    if (qeh->qeh_enc_sm_out)\n        qeh_begin_out(qeh);\n    return 0;\n}",
        "func_hash": 304358665951404548699605657299704903588,
        "file_name": "lsquic_qenc_hdl.c",
        "file_hash": null,
        "cwe": [
            "CWE-269"
        ],
        "cve": "CVE-2022-30592",
        "cve_desc": "liblsquic/lsquic_qenc_hdl.c in LiteSpeed QUIC (aka LSQUIC) before 3.1.0 mishandles MAX_TABLE_CAPACITY.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-30592",
        "func_name": "lsquic_qeh_settings",
        "diff": [
            "diff --git a/APIs.txt b/APIs.txt\nindex 8186f88ef..16d5d0003 100644\n--- a/APIs.txt\n+++ b/APIs.txt\n@@ -1,4 +1,4 @@\n-# Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE.\n+# Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE.\n LSQUIC APIs\n ===========\n \ndiff --git a/CHANGELOG b/CHANGELOG\nindex 32cf6a03a..eec807dd6 100644\n--- a/CHANGELOG\n+++ b/CHANGELOG\n@@ -1,3 +1,14 @@\n+2022-05-06\n+    - 3.1.0\n+    - Better handling of transport parameter max_table_capcity < 32\n+    - Fix NULL pointer dereference in handshake\n+    - Fix 0-RTT transport parameter validation (issue #367)\n+    - Remove unnecessary debug log to avoid NULL pointer dereference\n+    - Tick connection on datagram write (pull #314)\n+    - Do not dispatch write event for FINISHED stream\n+    - Tweaks for CMake configuration (pull #354 #369 #370 #373 #374)\n+    - Update ls-qpack to 2.3.0\n+\n 2022-01-10\n     - 3.0.4\n     - Fix overly strict assert()\ndiff --git a/CMakeLists.txt b/CMakeLists.txt\nindex 5ddd90692..65c477689 100644\n--- a/CMakeLists.txt\n+++ b/CMakeLists.txt\n@@ -1,4 +1,4 @@\n-# Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE.\n+# Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE.\n cmake_minimum_required(VERSION 3.0...3.23)\n \n \n@@ -336,11 +336,3 @@ INSTALL(FILES\n     include/lsxpack_header.h\n     DESTINATION ${CMAKE_INSTALL_INCLUDEDIR}/lsquic\n )\n-\n-if(WIN32)\n-    # The other file in wincompat is not used in installed headers\n-    INSTALL(FILES\n-        wincompat/vc_compat.h\n-        DESTINATION ${CMAKE_INSTALL_INCLUDEDIR}/lsquic\n-    )\n-endif()\ndiff --git a/CONTRIBUTORS.txt b/CONTRIBUTORS.txt\nindex d5fd6a714..930337616 100644\n--- a/CONTRIBUTORS.txt\n+++ b/CONTRIBUTORS.txt\n@@ -1,4 +1,4 @@\n-# Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE.\n+# Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE.\n In addition to the LiteSpeed QUIC Team, the following people contributed\n to the LiteSpeed QUIC and HTTP/3 Library:\n \ndiff --git a/EXAMPLES.txt b/EXAMPLES.txt\nindex 612bb71e5..5bedbb7a4 100644\n--- a/EXAMPLES.txt\n+++ b/EXAMPLES.txt\n@@ -1,4 +1,4 @@\n-# Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE.\n+# Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE.\n LSQUIC Examples\n ===============\n \ndiff --git a/LICENSE b/LICENSE\nindex b825fe57b..8a83a86a5 100644\n--- a/LICENSE\n+++ b/LICENSE\n@@ -1,6 +1,6 @@\n MIT License\n \n-Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc\n+Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc\n \n Permission is hereby granted, free of charge, to any person obtaining a copy\n of this software and associated documentation files (the \"Software\"), to deal\ndiff --git a/bin/CMakeLists.txt b/bin/CMakeLists.txt\nindex 34f9cacf1..0872f115f 100644\n--- a/bin/CMakeLists.txt\n+++ b/bin/CMakeLists.txt\n@@ -1,4 +1,4 @@\n-# Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE.\n+# Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE.\n \n include_directories(${CMAKE_CURRENT_BINARY_DIR})\n LIST(APPEND LIBS ${EVENT_LIB})\ndiff --git a/bin/duck_client.c b/bin/duck_client.c\nindex 307c74870..30484e442 100644\n--- a/bin/duck_client.c\n+++ b/bin/duck_client.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * duck_client.c -- The siduck client.  See\n  *      https://tools.ietf.org/html/draft-pardue-quic-siduck-00\ndiff --git a/bin/duck_server.c b/bin/duck_server.c\nindex fae70a1b3..543b9f1aa 100644\n--- a/bin/duck_server.c\n+++ b/bin/duck_server.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * A duck quacks!  The server for the siduck protocol:\n  *      https://tools.ietf.org/html/draft-pardue-quic-siduck-00\ndiff --git a/bin/echo_client.c b/bin/echo_client.c\nindex d0c9b6851..a0e7fffe7 100644\n--- a/bin/echo_client.c\n+++ b/bin/echo_client.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * echo_client.c -- This is really a \"line client:\" it connects to QUIC server\n  * and sends it stuff, line by line.  It works in tandem with echo_server.\ndiff --git a/bin/echo_server.c b/bin/echo_server.c\nindex 3750d84d6..73e10fd65 100644\n--- a/bin/echo_server.c\n+++ b/bin/echo_server.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * echo_server.c -- QUIC server that echoes back input line by line\n  */\ndiff --git a/bin/http_client.c b/bin/http_client.c\nindex 134315383..33f638bce 100644\n--- a/bin/http_client.c\n+++ b/bin/http_client.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * http_client.c -- A simple HTTP/QUIC client\n  */\ndiff --git a/bin/http_server.c b/bin/http_server.c\nindex 3c2cc0776..c5b2caf80 100644\n--- a/bin/http_server.c\n+++ b/bin/http_server.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * http_server.c -- A simple HTTP/QUIC server\n  *\ndiff --git a/bin/md5_client.c b/bin/md5_client.c\nindex 64526626b..926b721e1 100644\n--- a/bin/md5_client.c\n+++ b/bin/md5_client.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * md5_client.c -- This client sends one or more files to MD5 QUIC server\n  *                 for MD5 sum calculation.\ndiff --git a/bin/md5_server.c b/bin/md5_server.c\nindex b36768eb9..c5acd3afa 100644\n--- a/bin/md5_server.c\n+++ b/bin/md5_server.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * md5_server.c -- Read one or more streams from the client and return\n  *                 MD5 sum of the payload.\ndiff --git a/bin/perf_client.c b/bin/perf_client.c\nindex 314ea8dc7..f9cf2913b 100644\n--- a/bin/perf_client.c\n+++ b/bin/perf_client.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * perf_client.c -- Implements the \"perf\" client, see\n  *      https://tools.ietf.org/html/draft-banks-quic-performance-00\ndiff --git a/bin/perf_server.c b/bin/perf_server.c\nindex 0ecebe101..d43cc6219 100644\n--- a/bin/perf_server.c\n+++ b/bin/perf_server.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * perf_server.c -- Implements the \"perf\" server, see\n  *      https://tools.ietf.org/html/draft-banks-quic-performance-00\ndiff --git a/bin/prog.c b/bin/prog.c\nindex 0affcb195..b779f92a9 100644\n--- a/bin/prog.c\n+++ b/bin/prog.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #ifndef WIN32\n #include <arpa/inet.h>\ndiff --git a/bin/prog.h b/bin/prog.h\nindex 804d05422..1638d2328 100644\n--- a/bin/prog.h\n+++ b/bin/prog.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * prog.h -- common setup and options for QUIC program\n  */\ndiff --git a/bin/test_cert.c b/bin/test_cert.c\nindex af1f8d0ed..e00bde8ec 100644\n--- a/bin/test_cert.c\n+++ b/bin/test_cert.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <errno.h>\n #include <stdio.h>\n #include <stdlib.h>\ndiff --git a/bin/test_cert.h b/bin/test_cert.h\nindex 25ed43bdb..4614b57c1 100644\n--- a/bin/test_cert.h\n+++ b/bin/test_cert.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef TEST_CERT_H\n #define TEST_CERT_H\n \ndiff --git a/bin/test_common.c b/bin/test_common.c\nindex 174fde748..685947d5f 100644\n--- a/bin/test_common.c\n+++ b/bin/test_common.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #if __GNUC__\n #define _GNU_SOURCE     /* For struct in6_pktinfo */\n #endif\ndiff --git a/bin/test_common.h b/bin/test_common.h\nindex 5bb291af3..4ad747295 100644\n--- a/bin/test_common.h\n+++ b/bin/test_common.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * Test client's and server's common components.\n  */\ndiff --git a/docs/conf.py b/docs/conf.py\nindex 028b6ddf1..1b6001470 100644\n--- a/docs/conf.py\n+++ b/docs/conf.py\n@@ -20,13 +20,13 @@\n # -- Project information -----------------------------------------------------\n \n project = u'lsquic'\n-copyright = u'2021, LiteSpeed Technologies'\n+copyright = u'2022, LiteSpeed Technologies'\n author = u'LiteSpeed Technologies'\n \n # The short X.Y version\n-version = u'3.0'\n+version = u'3.1'\n # The full version, including alpha/beta/rc tags\n-release = u'3.0.4'\n+release = u'3.1.0'\n \n \n # -- General configuration ---------------------------------------------------\ndiff --git a/include/lsquic.h b/include/lsquic.h\nindex 71c9e3c49..0cba9bb9e 100644\n--- a/include/lsquic.h\n+++ b/include/lsquic.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef __LSQUIC_H__\n #define __LSQUIC_H__\n \n@@ -24,8 +24,8 @@ extern \"C\" {\n #endif\n \n #define LSQUIC_MAJOR_VERSION 3\n-#define LSQUIC_MINOR_VERSION 0\n-#define LSQUIC_PATCH_VERSION 4\n+#define LSQUIC_MINOR_VERSION 1\n+#define LSQUIC_PATCH_VERSION 0\n \n /**\n  * Engine flags:\ndiff --git a/include/lsquic_types.h b/include/lsquic_types.h\nindex 92d752ba8..e76e4c98c 100644\n--- a/include/lsquic_types.h\n+++ b/include/lsquic_types.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef __LSQUIC_TYPES_H__\n #define __LSQUIC_TYPES_H__\n \ndiff --git a/include/lsxpack_header.h b/include/lsxpack_header.h\nindex e4719934b..9c05c7544 100644\n--- a/include/lsxpack_header.h\n+++ b/include/lsxpack_header.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef LSXPACK_HEADER_H_v206\n #define LSXPACK_HEADER_H_v206\n \ndiff --git a/src/CMakeLists.txt b/src/CMakeLists.txt\nindex 356322f3f..5494fea3b 100644\n--- a/src/CMakeLists.txt\n+++ b/src/CMakeLists.txt\n@@ -1,4 +1,4 @@\n-# Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE.\n+# Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE.\n cmake_minimum_required(VERSION 3.0...3.23)\n \n add_subdirectory(liblsquic)\ndiff --git a/src/liblsquic/CMakeLists.txt b/src/liblsquic/CMakeLists.txt\nindex e8cdde837..d462e7590 100644\n--- a/src/liblsquic/CMakeLists.txt\n+++ b/src/liblsquic/CMakeLists.txt\n@@ -1,4 +1,4 @@\n-# Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE.\n+# Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE.\n SET(lsquic_STAT_SRCS\n     ls-qpack/lsqpack.c\n     lsquic_adaptive_cc.c\n@@ -159,3 +159,4 @@ install(\n     DESTINATION share/lsquic\n     NAMESPACE lsquic::\n     FILE lsquic-targets.cmake)\n+\ndiff --git a/src/liblsquic/common_cert_set_2.c b/src/liblsquic/common_cert_set_2.c\nindex 4e41de0f0..fb0e06fa7 100644\n--- a/src/liblsquic/common_cert_set_2.c\n+++ b/src/liblsquic/common_cert_set_2.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /* Copyright (c) 2015 The Chromium Authors. All rights reserved.\n  * Use of this source code is governed by a BSD-style license that can be\n  * found in the LICENSE.chrome file.\ndiff --git a/src/liblsquic/common_cert_set_2a.inc b/src/liblsquic/common_cert_set_2a.inc\nindex 403417aeb..e9ea3cf3b 100644\n--- a/src/liblsquic/common_cert_set_2a.inc\n+++ b/src/liblsquic/common_cert_set_2a.inc\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /* Copyright (c) 2015 The Chromium Authors. All rights reserved.\n  * Use of this source code is governed by a BSD-style license that can be\n  * found in the LICENSE.chrome file.\ndiff --git a/src/liblsquic/common_cert_set_2b.inc b/src/liblsquic/common_cert_set_2b.inc\nindex 586af45b4..45f0e3171 100644\n--- a/src/liblsquic/common_cert_set_2b.inc\n+++ b/src/liblsquic/common_cert_set_2b.inc\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /* Copyright (c) 2015 The Chromium Authors. All rights reserved.\n  * Use of this source code is governed by a BSD-style license that can be\n  * found in the LICENSE.chrome file.\ndiff --git a/src/liblsquic/common_cert_set_3.c b/src/liblsquic/common_cert_set_3.c\nindex 1e6d40197..671054387 100644\n--- a/src/liblsquic/common_cert_set_3.c\n+++ b/src/liblsquic/common_cert_set_3.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /* Copyright (c) 2015 The Chromium Authors. All rights reserved.\n  * Use of this source code is governed by a BSD-style license that can be\n  * found in the LICENSE.chrome file.\ndiff --git a/src/liblsquic/common_cert_set_3a.inc b/src/liblsquic/common_cert_set_3a.inc\nindex de6677703..d12d4de1a 100644\n--- a/src/liblsquic/common_cert_set_3a.inc\n+++ b/src/liblsquic/common_cert_set_3a.inc\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /* Copyright (c) 2015 The Chromium Authors. All rights reserved.\n  * Use of this source code is governed by a BSD-style license that can be\n  * found in the LICENSE.chrome file.\ndiff --git a/src/liblsquic/common_cert_set_3b.inc b/src/liblsquic/common_cert_set_3b.inc\nindex 5f080b753..4ad584bb9 100644\n--- a/src/liblsquic/common_cert_set_3b.inc\n+++ b/src/liblsquic/common_cert_set_3b.inc\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /* Copyright (c) 2015 The Chromium Authors. All rights reserved.\n  * Use of this source code is governed by a BSD-style license that can be\n  * found in the LICENSE.chrome file.\ndiff --git a/src/liblsquic/fiu-local.h b/src/liblsquic/fiu-local.h\nindex 7c295ebea..a63f44b0d 100644\n--- a/src/liblsquic/fiu-local.h\n+++ b/src/liblsquic/fiu-local.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n \n /* libfiu - Fault Injection in Userspace\n  *\ndiff --git a/src/liblsquic/ls-sfparser.c b/src/liblsquic/ls-sfparser.c\nindex 03bcc4647..281670fd5 100644\n--- a/src/liblsquic/ls-sfparser.c\n+++ b/src/liblsquic/ls-sfparser.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #line 2 \"ls-sfparser.c\"\n #line 2 \"ls-sfparser.l\"\n /*\ndiff --git a/src/liblsquic/ls-sfparser.h b/src/liblsquic/ls-sfparser.h\nindex 152ba6881..571f73bd2 100644\n--- a/src/liblsquic/ls-sfparser.h\n+++ b/src/liblsquic/ls-sfparser.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n MIT License\n \ndiff --git a/src/liblsquic/lsquic_adaptive_cc.c b/src/liblsquic/lsquic_adaptive_cc.c\nindex a789476a7..cc1aefa5a 100644\n--- a/src/liblsquic/lsquic_adaptive_cc.c\n+++ b/src/liblsquic/lsquic_adaptive_cc.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /* lsquic_adaptive_cc.c -- adaptive congestion controller */\n \n #include <inttypes.h>\ndiff --git a/src/liblsquic/lsquic_adaptive_cc.h b/src/liblsquic/lsquic_adaptive_cc.h\nindex 8b8fe4953..36ea760b1 100644\n--- a/src/liblsquic/lsquic_adaptive_cc.h\n+++ b/src/liblsquic/lsquic_adaptive_cc.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_adaptive_cc.h -- Adaptive congestion controller\n  *\ndiff --git a/src/liblsquic/lsquic_alarmset.c b/src/liblsquic/lsquic_alarmset.c\nindex 0b98597e5..5a72ee356 100644\n--- a/src/liblsquic/lsquic_alarmset.c\n+++ b/src/liblsquic/lsquic_alarmset.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_alarmset.c -- A set of alarms\n  */\ndiff --git a/src/liblsquic/lsquic_alarmset.h b/src/liblsquic/lsquic_alarmset.h\nindex 6c1d4c1ac..fd6ea7d58 100644\n--- a/src/liblsquic/lsquic_alarmset.h\n+++ b/src/liblsquic/lsquic_alarmset.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_alarmset.h -- A set of alarms\n  */\ndiff --git a/src/liblsquic/lsquic_arr.c b/src/liblsquic/lsquic_arr.c\nindex f28c743f6..e3828c564 100644\n--- a/src/liblsquic/lsquic_arr.c\n+++ b/src/liblsquic/lsquic_arr.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_arr.c\n  */\ndiff --git a/src/liblsquic/lsquic_arr.h b/src/liblsquic/lsquic_arr.h\nindex 994eacf1e..881b771a7 100644\n--- a/src/liblsquic/lsquic_arr.h\n+++ b/src/liblsquic/lsquic_arr.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_arr.h -- Array\n  */\ndiff --git a/src/liblsquic/lsquic_attq.c b/src/liblsquic/lsquic_attq.c\nindex e00cb197b..4a3eb59fc 100644\n--- a/src/liblsquic/lsquic_attq.c\n+++ b/src/liblsquic/lsquic_attq.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_attq.c -- Advisory Tick Time Queue\n  *\ndiff --git a/src/liblsquic/lsquic_attq.h b/src/liblsquic/lsquic_attq.h\nindex bcc3a222d..c13c80de0 100644\n--- a/src/liblsquic/lsquic_attq.h\n+++ b/src/liblsquic/lsquic_attq.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_attq.h -- Advisory Tick Time Queue\n  */\ndiff --git a/src/liblsquic/lsquic_bbr.c b/src/liblsquic/lsquic_bbr.c\nindex 3d5f83592..5bd83a7fb 100644\n--- a/src/liblsquic/lsquic_bbr.c\n+++ b/src/liblsquic/lsquic_bbr.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n // Copyright 2016 The Chromium Authors. All rights reserved.\n // Use of this source code is governed by a BSD-style license that can be\n // found in the LICENSE.chrome file.\ndiff --git a/src/liblsquic/lsquic_bbr.h b/src/liblsquic/lsquic_bbr.h\nindex 699080903..89634c62a 100644\n--- a/src/liblsquic/lsquic_bbr.h\n+++ b/src/liblsquic/lsquic_bbr.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef LSQUIC_BBR_H\n #define LSQUIC_BBR_H\n \ndiff --git a/src/liblsquic/lsquic_bw_sampler.c b/src/liblsquic/lsquic_bw_sampler.c\nindex 3bf7be8b2..2d6541623 100644\n--- a/src/liblsquic/lsquic_bw_sampler.c\n+++ b/src/liblsquic/lsquic_bw_sampler.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <inttypes.h>\n #include <stddef.h>\ndiff --git a/src/liblsquic/lsquic_bw_sampler.h b/src/liblsquic/lsquic_bw_sampler.h\nindex 51ca3bfe0..ec2d8e83e 100644\n--- a/src/liblsquic/lsquic_bw_sampler.h\n+++ b/src/liblsquic/lsquic_bw_sampler.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef LSQUIC_BW_SAMPLER_H\n #define LSQUIC_BW_SAMPLER_H 1\n \ndiff --git a/src/liblsquic/lsquic_byteswap.h b/src/liblsquic/lsquic_byteswap.h\nindex bf23ace29..fdb9ab3a3 100644\n--- a/src/liblsquic/lsquic_byteswap.h\n+++ b/src/liblsquic/lsquic_byteswap.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef LSQUIC_BYTESWAP_H\n #define LSQUIC_BYTESWAP_H 1\n \ndiff --git a/src/liblsquic/lsquic_cfcw.c b/src/liblsquic/lsquic_cfcw.c\nindex c51067c68..d845aaa2b 100644\n--- a/src/liblsquic/lsquic_cfcw.c\n+++ b/src/liblsquic/lsquic_cfcw.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <inttypes.h>\n #include <stdint.h>\n #include <stdlib.h>\ndiff --git a/src/liblsquic/lsquic_chsk_stream.c b/src/liblsquic/lsquic_chsk_stream.c\nindex 307a5e696..6cc86b50b 100644\n--- a/src/liblsquic/lsquic_chsk_stream.c\n+++ b/src/liblsquic/lsquic_chsk_stream.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * Stream/crypto handshake adapter for the client side.\n  *\ndiff --git a/src/liblsquic/lsquic_chsk_stream.h b/src/liblsquic/lsquic_chsk_stream.h\nindex dada4a149..fe9db8d69 100644\n--- a/src/liblsquic/lsquic_chsk_stream.h\n+++ b/src/liblsquic/lsquic_chsk_stream.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * Stream/crypto handshake adapter for the client side.\n  */\ndiff --git a/src/liblsquic/lsquic_cong_ctl.h b/src/liblsquic/lsquic_cong_ctl.h\nindex bfcc1c7ed..31957d7a9 100644\n--- a/src/liblsquic/lsquic_cong_ctl.h\n+++ b/src/liblsquic/lsquic_cong_ctl.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_cong_ctl.h -- congestion control interface\n  */\ndiff --git a/src/liblsquic/lsquic_conn.c b/src/liblsquic/lsquic_conn.c\nindex 028b1d931..f76550dc2 100644\n--- a/src/liblsquic/lsquic_conn.c\n+++ b/src/liblsquic/lsquic_conn.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <inttypes.h>\n #include <string.h>\ndiff --git a/src/liblsquic/lsquic_conn.h b/src/liblsquic/lsquic_conn.h\nindex 4979240a9..200ba0f2c 100644\n--- a/src/liblsquic/lsquic_conn.h\n+++ b/src/liblsquic/lsquic_conn.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_conn.h -- Connection interface\n  *\ndiff --git a/src/liblsquic/lsquic_conn_flow.h b/src/liblsquic/lsquic_conn_flow.h\nindex 91b41aee5..8fa8587d4 100644\n--- a/src/liblsquic/lsquic_conn_flow.h\n+++ b/src/liblsquic/lsquic_conn_flow.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_conn_flow.h -- Connection flow control-related functions\n  */\ndiff --git a/src/liblsquic/lsquic_conn_public.h b/src/liblsquic/lsquic_conn_public.h\nindex 21e31f10b..c6bbb3afe 100644\n--- a/src/liblsquic/lsquic_conn_public.h\n+++ b/src/liblsquic/lsquic_conn_public.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_conn_public.h -- Connection's \"public interface\"\n  *\ndiff --git a/src/liblsquic/lsquic_crand.c b/src/liblsquic/lsquic_crand.c\nindex 58880f080..61b77a8c3 100644\n--- a/src/liblsquic/lsquic_crand.c\n+++ b/src/liblsquic/lsquic_crand.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <openssl/rand.h>\n #include <stdint.h>\n \ndiff --git a/src/liblsquic/lsquic_crand.h b/src/liblsquic/lsquic_crand.h\nindex 2333b571d..9e9d904b7 100644\n--- a/src/liblsquic/lsquic_crand.h\n+++ b/src/liblsquic/lsquic_crand.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_crand.h -- cached random bytes\n  *\ndiff --git a/src/liblsquic/lsquic_crt_compress.c b/src/liblsquic/lsquic_crt_compress.c\nindex 42539a20b..c6da73b51 100644\n--- a/src/liblsquic/lsquic_crt_compress.c\n+++ b/src/liblsquic/lsquic_crt_compress.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdbool.h>\n #include <string.h>\ndiff --git a/src/liblsquic/lsquic_crt_compress.h b/src/liblsquic/lsquic_crt_compress.h\nindex f9b708ef0..07a819de7 100644\n--- a/src/liblsquic/lsquic_crt_compress.h\n+++ b/src/liblsquic/lsquic_crt_compress.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef __LSQUIC_CRT_COMPRESS_H__\n #define __LSQUIC_CRT_COMPRESS_H__\n \ndiff --git a/src/liblsquic/lsquic_crypto.c b/src/liblsquic/lsquic_crypto.c\nindex b24c76d42..2dbf692e2 100644\n--- a/src/liblsquic/lsquic_crypto.c\n+++ b/src/liblsquic/lsquic_crypto.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <string.h>\n \ndiff --git a/src/liblsquic/lsquic_crypto.h b/src/liblsquic/lsquic_crypto.h\nindex 045580016..5a9d194ed 100644\n--- a/src/liblsquic/lsquic_crypto.h\n+++ b/src/liblsquic/lsquic_crypto.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n \n #ifndef __LSQUIC_CRYPTO_H__\n #define __LSQUIC_CRYPTO_H__\ndiff --git a/src/liblsquic/lsquic_cubic.c b/src/liblsquic/lsquic_cubic.c\nindex 0d2376374..a4efeacde 100644\n--- a/src/liblsquic/lsquic_cubic.c\n+++ b/src/liblsquic/lsquic_cubic.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_cubic.c -- LSQUIC CUBIC implementation.\n  */\ndiff --git a/src/liblsquic/lsquic_cubic.h b/src/liblsquic/lsquic_cubic.h\nindex 6f7b25090..8eef0967b 100644\n--- a/src/liblsquic/lsquic_cubic.h\n+++ b/src/liblsquic/lsquic_cubic.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_cubic.h -- CUBIC congestion control protocol.\n  */\ndiff --git a/src/liblsquic/lsquic_data_in_if.h b/src/liblsquic/lsquic_data_in_if.h\nindex 6deb8e006..b31161c50 100644\n--- a/src/liblsquic/lsquic_data_in_if.h\n+++ b/src/liblsquic/lsquic_data_in_if.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_data_in_if.h -- DATA in interface\n  */\ndiff --git a/src/liblsquic/lsquic_di_error.c b/src/liblsquic/lsquic_di_error.c\nindex 1bc901852..755eea139 100644\n--- a/src/liblsquic/lsquic_di_error.c\n+++ b/src/liblsquic/lsquic_di_error.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_di_error.c -- A placeholder when things go wrong\n  *\ndiff --git a/src/liblsquic/lsquic_di_hash.c b/src/liblsquic/lsquic_di_hash.c\nindex c889ffd38..900ab5817 100644\n--- a/src/liblsquic/lsquic_di_hash.c\n+++ b/src/liblsquic/lsquic_di_hash.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_di_hash.c -- Copy incoming data into a hash\n  *\ndiff --git a/src/liblsquic/lsquic_di_nocopy.c b/src/liblsquic/lsquic_di_nocopy.c\nindex 0fe8b4bb3..a9de76622 100644\n--- a/src/liblsquic/lsquic_di_nocopy.c\n+++ b/src/liblsquic/lsquic_di_nocopy.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_di_nocopy.c -- The \"no-copy\" data in stream.\n  *\ndiff --git a/src/liblsquic/lsquic_enc_sess.h b/src/liblsquic/lsquic_enc_sess.h\nindex 3e784e812..f45c15f7d 100644\n--- a/src/liblsquic/lsquic_enc_sess.h\n+++ b/src/liblsquic/lsquic_enc_sess.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef LSQUIC_ENC_SESS_H\n #define LSQUIC_ENC_SESS_H 1\n \ndiff --git a/src/liblsquic/lsquic_enc_sess_common.c b/src/liblsquic/lsquic_enc_sess_common.c\nindex 2270b49c3..69b2c443b 100644\n--- a/src/liblsquic/lsquic_enc_sess_common.c\n+++ b/src/liblsquic/lsquic_enc_sess_common.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <stddef.h>\n #include <stdint.h>\n #include <string.h>\ndiff --git a/src/liblsquic/lsquic_enc_sess_ietf.c b/src/liblsquic/lsquic_enc_sess_ietf.c\nindex 115cd9f0f..726f96c78 100644\n--- a/src/liblsquic/lsquic_enc_sess_ietf.c\n+++ b/src/liblsquic/lsquic_enc_sess_ietf.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_enc_sess_ietf.c -- Crypto session for IETF QUIC\n  */\ndiff --git a/src/liblsquic/lsquic_eng_hist.c b/src/liblsquic/lsquic_eng_hist.c\nindex 783bd9fd0..d8abf7f53 100644\n--- a/src/liblsquic/lsquic_eng_hist.c\n+++ b/src/liblsquic/lsquic_eng_hist.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <time.h>\n #ifdef WIN32\n #include <vc_compat.h>\ndiff --git a/src/liblsquic/lsquic_eng_hist.h b/src/liblsquic/lsquic_eng_hist.h\nindex 4bd6ddbbc..df14504e5 100644\n--- a/src/liblsquic/lsquic_eng_hist.h\n+++ b/src/liblsquic/lsquic_eng_hist.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_eng_hist.h - Engine history.\n  *\ndiff --git a/src/liblsquic/lsquic_engine.c b/src/liblsquic/lsquic_engine.c\nindex c3dcff5a1..0202e7455 100644\n--- a/src/liblsquic/lsquic_engine.c\n+++ b/src/liblsquic/lsquic_engine.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_engine.c - QUIC engine\n  */\ndiff --git a/src/liblsquic/lsquic_engine_public.h b/src/liblsquic/lsquic_engine_public.h\nindex ff5f2b495..88aa8432c 100644\n--- a/src/liblsquic/lsquic_engine_public.h\n+++ b/src/liblsquic/lsquic_engine_public.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_engine_public.h -- Engine's \"public interface\"\n  *\ndiff --git a/src/liblsquic/lsquic_ev_log.c b/src/liblsquic/lsquic_ev_log.c\nindex 69573ef2e..cd9e48d41 100644\n--- a/src/liblsquic/lsquic_ev_log.c\n+++ b/src/liblsquic/lsquic_ev_log.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef WIN32\n #include <arpa/inet.h>\n #else\ndiff --git a/src/liblsquic/lsquic_ev_log.h b/src/liblsquic/lsquic_ev_log.h\nindex c32bcd072..5e4a9f4e5 100644\n--- a/src/liblsquic/lsquic_ev_log.h\n+++ b/src/liblsquic/lsquic_ev_log.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_ev_log.h -- Event logger\n  */\ndiff --git a/src/liblsquic/lsquic_frab_list.c b/src/liblsquic/lsquic_frab_list.c\nindex 6da9cf12c..8083c3299 100644\n--- a/src/liblsquic/lsquic_frab_list.c\n+++ b/src/liblsquic/lsquic_frab_list.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_frab_list.c -- List of buffer for simple reading and writing\n  */\ndiff --git a/src/liblsquic/lsquic_frab_list.h b/src/liblsquic/lsquic_frab_list.h\nindex 2691c5f6f..23dc3cf8e 100644\n--- a/src/liblsquic/lsquic_frab_list.h\n+++ b/src/liblsquic/lsquic_frab_list.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_frab_list.h -- List of buffer for simple reading and writing\n  *\ndiff --git a/src/liblsquic/lsquic_frame_common.c b/src/liblsquic/lsquic_frame_common.c\nindex 01ba74ae4..26907b702 100644\n--- a/src/liblsquic/lsquic_frame_common.c\n+++ b/src/liblsquic/lsquic_frame_common.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <stdint.h>\n \n #include \"lsquic_frame_common.h\"\ndiff --git a/src/liblsquic/lsquic_frame_common.h b/src/liblsquic/lsquic_frame_common.h\nindex b3d10740a..a41bbf47e 100644\n--- a/src/liblsquic/lsquic_frame_common.h\n+++ b/src/liblsquic/lsquic_frame_common.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_frame_common.h\n  */\ndiff --git a/src/liblsquic/lsquic_frame_reader.c b/src/liblsquic/lsquic_frame_reader.c\nindex 15d3bf964..771f92264 100644\n--- a/src/liblsquic/lsquic_frame_reader.c\n+++ b/src/liblsquic/lsquic_frame_reader.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_frame_reader.c -- Read HTTP frames from stream\n  */\ndiff --git a/src/liblsquic/lsquic_frame_reader.h b/src/liblsquic/lsquic_frame_reader.h\nindex 0559ab989..1a55d043f 100644\n--- a/src/liblsquic/lsquic_frame_reader.h\n+++ b/src/liblsquic/lsquic_frame_reader.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_frame_reader.h -- Read HTTP frames from stream\n  */\ndiff --git a/src/liblsquic/lsquic_frame_writer.c b/src/liblsquic/lsquic_frame_writer.c\nindex 8332437bd..ae1919dd5 100644\n--- a/src/liblsquic/lsquic_frame_writer.c\n+++ b/src/liblsquic/lsquic_frame_writer.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_frame_writer.c -- write frames to HEADERS stream.\n  *\ndiff --git a/src/liblsquic/lsquic_frame_writer.h b/src/liblsquic/lsquic_frame_writer.h\nindex d087912be..ae7a3c298 100644\n--- a/src/liblsquic/lsquic_frame_writer.h\n+++ b/src/liblsquic/lsquic_frame_writer.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_frame_writer.h -- write frames to HEADERS stream.\n  */\ndiff --git a/src/liblsquic/lsquic_full_conn.c b/src/liblsquic/lsquic_full_conn.c\nindex 26b9ad89f..81632dd1a 100644\n--- a/src/liblsquic/lsquic_full_conn.c\n+++ b/src/liblsquic/lsquic_full_conn.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_full_conn.c -- A \"full\" connection object has full functionality\n  */\ndiff --git a/src/liblsquic/lsquic_full_conn.h b/src/liblsquic/lsquic_full_conn.h\nindex 78cd3d090..f2e514e98 100644\n--- a/src/liblsquic/lsquic_full_conn.h\n+++ b/src/liblsquic/lsquic_full_conn.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef LSQUIC_FULL_CONN_H\n #define LSQUIC_FULL_CONN_H\n \ndiff --git a/src/liblsquic/lsquic_full_conn_ietf.c b/src/liblsquic/lsquic_full_conn_ietf.c\nindex 15231b953..5af1642c6 100644\n--- a/src/liblsquic/lsquic_full_conn_ietf.c\n+++ b/src/liblsquic/lsquic_full_conn_ietf.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_full_conn_ietf.c -- IETF QUIC connection.\n  */\ndiff --git a/src/liblsquic/lsquic_global.c b/src/liblsquic/lsquic_global.c\nindex c16da90b9..9556842c2 100644\n--- a/src/liblsquic/lsquic_global.c\n+++ b/src/liblsquic/lsquic_global.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * Global state\n  */\ndiff --git a/src/liblsquic/lsquic_handshake.c b/src/liblsquic/lsquic_handshake.c\nindex 429814114..d292f72d0 100644\n--- a/src/liblsquic/lsquic_handshake.c\n+++ b/src/liblsquic/lsquic_handshake.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #define _GNU_SOURCE         /* for memmem */\n \n #include <assert.h>\ndiff --git a/src/liblsquic/lsquic_handshake.h b/src/liblsquic/lsquic_handshake.h\nindex d16fedac9..323c93945 100644\n--- a/src/liblsquic/lsquic_handshake.h\n+++ b/src/liblsquic/lsquic_handshake.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef LSQUIC_HANDSHAKE_H\n #define LSQUIC_HANDSHAKE_H 1\n \ndiff --git a/src/liblsquic/lsquic_hash.c b/src/liblsquic/lsquic_hash.c\nindex 7ac07b340..1ca16121d 100644\n--- a/src/liblsquic/lsquic_hash.c\n+++ b/src/liblsquic/lsquic_hash.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_hash.c\n  */\ndiff --git a/src/liblsquic/lsquic_hash.h b/src/liblsquic/lsquic_hash.h\nindex 9fb99e8b0..ccc7c1846 100644\n--- a/src/liblsquic/lsquic_hash.h\n+++ b/src/liblsquic/lsquic_hash.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_hash.c -- A generic hash\n  */\ndiff --git a/src/liblsquic/lsquic_hcsi_reader.c b/src/liblsquic/lsquic_hcsi_reader.c\nindex 8b365b636..f50ac675d 100644\n--- a/src/liblsquic/lsquic_hcsi_reader.c\n+++ b/src/liblsquic/lsquic_hcsi_reader.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <inttypes.h>\n #include <stddef.h>\ndiff --git a/src/liblsquic/lsquic_hcsi_reader.h b/src/liblsquic/lsquic_hcsi_reader.h\nindex 75a91ea5d..62609fb37 100644\n--- a/src/liblsquic/lsquic_hcsi_reader.h\n+++ b/src/liblsquic/lsquic_hcsi_reader.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_hcsi_reader.h -- HTTP Control Stream Incoming (HCSI) reader\n  */\ndiff --git a/src/liblsquic/lsquic_hcso_writer.c b/src/liblsquic/lsquic_hcso_writer.c\nindex efc968249..d1576714e 100644\n--- a/src/liblsquic/lsquic_hcso_writer.c\n+++ b/src/liblsquic/lsquic_hcso_writer.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_hcso_writer.c - write to outgoing HTTP Control Stream\n  */\ndiff --git a/src/liblsquic/lsquic_hcso_writer.h b/src/liblsquic/lsquic_hcso_writer.h\nindex 8809e4443..115e300eb 100644\n--- a/src/liblsquic/lsquic_hcso_writer.h\n+++ b/src/liblsquic/lsquic_hcso_writer.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_hcso_writer.h\n  */\ndiff --git a/src/liblsquic/lsquic_headers.h b/src/liblsquic/lsquic_headers.h\nindex a8fe33aa2..8a9d5a9fe 100644\n--- a/src/liblsquic/lsquic_headers.h\n+++ b/src/liblsquic/lsquic_headers.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef LSQUIC_HEADERS_H\n #define LSQUIC_HEADERS_H 1\n \ndiff --git a/src/liblsquic/lsquic_headers_stream.c b/src/liblsquic/lsquic_headers_stream.c\nindex c69feda76..dadd19793 100644\n--- a/src/liblsquic/lsquic_headers_stream.c\n+++ b/src/liblsquic/lsquic_headers_stream.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * HEADERS stream logic\n  */\ndiff --git a/src/liblsquic/lsquic_headers_stream.h b/src/liblsquic/lsquic_headers_stream.h\nindex fcf309a1f..b0895c527 100644\n--- a/src/liblsquic/lsquic_headers_stream.h\n+++ b/src/liblsquic/lsquic_headers_stream.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_headers_stream.h -- HEADERS stream interface\n  */\ndiff --git a/src/liblsquic/lsquic_hkdf.c b/src/liblsquic/lsquic_hkdf.c\nindex ba48d568a..0928bf30e 100644\n--- a/src/liblsquic/lsquic_hkdf.c\n+++ b/src/liblsquic/lsquic_hkdf.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stddef.h>\n #include <string.h>\ndiff --git a/src/liblsquic/lsquic_hkdf.h b/src/liblsquic/lsquic_hkdf.h\nindex 93b344b0a..97b0d36e2 100644\n--- a/src/liblsquic/lsquic_hkdf.h\n+++ b/src/liblsquic/lsquic_hkdf.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef LSQUIC_HKDF_H\n #define LSQUIC_HKDF_H 1\n \ndiff --git a/src/liblsquic/lsquic_hpi.c b/src/liblsquic/lsquic_hpi.c\nindex 1c78268e5..5ab96690e 100644\n--- a/src/liblsquic/lsquic_hpi.c\n+++ b/src/liblsquic/lsquic_hpi.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_hpi.c - implementation of (Extensible) HTTP Priority Iterator.\n  */\ndiff --git a/src/liblsquic/lsquic_hpi.h b/src/liblsquic/lsquic_hpi.h\nindex 45bc44b3a..d4a3fff7f 100644\n--- a/src/liblsquic/lsquic_hpi.h\n+++ b/src/liblsquic/lsquic_hpi.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_hpi.h - HPI: (Extensible) HTTP Priority Iterator\n  *\ndiff --git a/src/liblsquic/lsquic_hq.h b/src/liblsquic/lsquic_hq.h\nindex d972e780d..062dfa730 100644\n--- a/src/liblsquic/lsquic_hq.h\n+++ b/src/liblsquic/lsquic_hq.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_hq.h -- HTTP/3 (originally \"HTTP over QUIC\" or HQ) types\n  */\ndiff --git a/src/liblsquic/lsquic_hspack_valid.c b/src/liblsquic/lsquic_hspack_valid.c\nindex 30d7792a5..a30b3e666 100644\n--- a/src/liblsquic/lsquic_hspack_valid.c\n+++ b/src/liblsquic/lsquic_hspack_valid.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_hspack_valid.c -- Handshake packet validator.\n  *\ndiff --git a/src/liblsquic/lsquic_http.c b/src/liblsquic/lsquic_http.c\nindex af07512e2..dd2402adf 100644\n--- a/src/liblsquic/lsquic_http.c\n+++ b/src/liblsquic/lsquic_http.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /* Various HTTP-related functions. */\n \n #include <stddef.h>\ndiff --git a/src/liblsquic/lsquic_http1x_if.c b/src/liblsquic/lsquic_http1x_if.c\nindex b8fd90704..8710017a8 100644\n--- a/src/liblsquic/lsquic_http1x_if.c\n+++ b/src/liblsquic/lsquic_http1x_if.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <ctype.h>\n #include <stddef.h>\ndiff --git a/src/liblsquic/lsquic_http1x_if.h b/src/liblsquic/lsquic_http1x_if.h\nindex 5edd6fd31..1ba771b1d 100644\n--- a/src/liblsquic/lsquic_http1x_if.h\n+++ b/src/liblsquic/lsquic_http1x_if.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef LSQUIC_HTTP1X_IF_H\n #define LSQUIC_HTTP1X_IF_H 1\n \ndiff --git a/src/liblsquic/lsquic_ietf.h b/src/liblsquic/lsquic_ietf.h\nindex 0f7ed2f01..0c83061c6 100644\n--- a/src/liblsquic/lsquic_ietf.h\n+++ b/src/liblsquic/lsquic_ietf.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef LSQUIC_IETF_H\n #define LSQUIC_IETF_H 1\n \ndiff --git a/src/liblsquic/lsquic_int_types.h b/src/liblsquic/lsquic_int_types.h\nindex 9b48d1a3b..dd7d67b78 100644\n--- a/src/liblsquic/lsquic_int_types.h\n+++ b/src/liblsquic/lsquic_int_types.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef LSQUIC_INT_TYPES_H\n #define LSQUIC_INT_TYPES_H 1\n \ndiff --git a/src/liblsquic/lsquic_logger.c b/src/liblsquic/lsquic_logger.c\nindex 785bccdcf..07edb5ab9 100644\n--- a/src/liblsquic/lsquic_logger.c\n+++ b/src/liblsquic/lsquic_logger.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * LSQUIC Logger implementation.\n  */\ndiff --git a/src/liblsquic/lsquic_logger.h b/src/liblsquic/lsquic_logger.h\nindex 1d0d393b8..2d84eba89 100644\n--- a/src/liblsquic/lsquic_logger.h\n+++ b/src/liblsquic/lsquic_logger.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_logger.h -- logging functions and macros.\n  *\ndiff --git a/src/liblsquic/lsquic_malo.c b/src/liblsquic/lsquic_malo.c\nindex 45e72aacf..f14dbd525 100644\n--- a/src/liblsquic/lsquic_malo.c\n+++ b/src/liblsquic/lsquic_malo.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_malo.c -- malo allocator implementation.\n  *\ndiff --git a/src/liblsquic/lsquic_malo.h b/src/liblsquic/lsquic_malo.h\nindex 270bca383..9f701d368 100644\n--- a/src/liblsquic/lsquic_malo.h\n+++ b/src/liblsquic/lsquic_malo.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_malo.h -- Fast allocator for fixed-sized objects.\n  */\ndiff --git a/src/liblsquic/lsquic_min_heap.c b/src/liblsquic/lsquic_min_heap.c\nindex 4935756d5..818f1cb88 100644\n--- a/src/liblsquic/lsquic_min_heap.c\n+++ b/src/liblsquic/lsquic_min_heap.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_min_heap.c\n  */\ndiff --git a/src/liblsquic/lsquic_min_heap.h b/src/liblsquic/lsquic_min_heap.h\nindex 35ada4a87..b45fca02a 100644\n--- a/src/liblsquic/lsquic_min_heap.h\n+++ b/src/liblsquic/lsquic_min_heap.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_min_heap.h -- Min-heap for pointers\n  */\ndiff --git a/src/liblsquic/lsquic_mini_conn.c b/src/liblsquic/lsquic_mini_conn.c\nindex 94cda81eb..d7aa161f7 100644\n--- a/src/liblsquic/lsquic_mini_conn.c\n+++ b/src/liblsquic/lsquic_mini_conn.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_mini_conn.c -- Mini connection.\n  *\ndiff --git a/src/liblsquic/lsquic_mini_conn.h b/src/liblsquic/lsquic_mini_conn.h\nindex ddff7755f..80334add1 100644\n--- a/src/liblsquic/lsquic_mini_conn.h\n+++ b/src/liblsquic/lsquic_mini_conn.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_mini_conn.h -- Mini-connection\n  *\ndiff --git a/src/liblsquic/lsquic_mini_conn_ietf.c b/src/liblsquic/lsquic_mini_conn_ietf.c\nindex 5e6c26c79..f2ed267ab 100644\n--- a/src/liblsquic/lsquic_mini_conn_ietf.c\n+++ b/src/liblsquic/lsquic_mini_conn_ietf.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_mini_conn_ietf.c -- Mini connection used by the IETF QUIC\n  */\ndiff --git a/src/liblsquic/lsquic_mini_conn_ietf.h b/src/liblsquic/lsquic_mini_conn_ietf.h\nindex 2347bf363..9d0eec406 100644\n--- a/src/liblsquic/lsquic_mini_conn_ietf.h\n+++ b/src/liblsquic/lsquic_mini_conn_ietf.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_mini_conn_ietf.h -- Mini connection used by the IETF QUIC\n  */\ndiff --git a/src/liblsquic/lsquic_minmax.c b/src/liblsquic/lsquic_minmax.c\nindex 4eb5f0f9f..d6a184974 100644\n--- a/src/liblsquic/lsquic_minmax.c\n+++ b/src/liblsquic/lsquic_minmax.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * Based on Google code released under BSD license here:\n  *  https://groups.google.com/forum/#!topic/bbr-dev/3RTgkzi5ZD8\ndiff --git a/src/liblsquic/lsquic_minmax.h b/src/liblsquic/lsquic_minmax.h\nindex cf1420fe0..ad1ed9151 100644\n--- a/src/liblsquic/lsquic_minmax.h\n+++ b/src/liblsquic/lsquic_minmax.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef LSQUIC_MINMAX_H\n #define LSQUIC_MINMAX_H\n \ndiff --git a/src/liblsquic/lsquic_mm.c b/src/liblsquic/lsquic_mm.c\nindex 3e2141e6f..3315ebb0a 100644\n--- a/src/liblsquic/lsquic_mm.c\n+++ b/src/liblsquic/lsquic_mm.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_mm.c -- Memory manager.\n  */\ndiff --git a/src/liblsquic/lsquic_mm.h b/src/liblsquic/lsquic_mm.h\nindex 9575998d3..01c1fbb0d 100644\n--- a/src/liblsquic/lsquic_mm.h\n+++ b/src/liblsquic/lsquic_mm.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_mm.h -- Memory manager.\n  *\ndiff --git a/src/liblsquic/lsquic_pacer.c b/src/liblsquic/lsquic_pacer.c\nindex af188caa6..22842c56e 100644\n--- a/src/liblsquic/lsquic_pacer.c\n+++ b/src/liblsquic/lsquic_pacer.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <inttypes.h>\n #include <stdint.h>\ndiff --git a/src/liblsquic/lsquic_pacer.h b/src/liblsquic/lsquic_pacer.h\nindex 131d94db6..883c2a697 100644\n--- a/src/liblsquic/lsquic_pacer.h\n+++ b/src/liblsquic/lsquic_pacer.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef LSQUIC_PACER_H\n #define LSQUIC_PACER_H 1\n \ndiff --git a/src/liblsquic/lsquic_packet_common.c b/src/liblsquic/lsquic_packet_common.c\nindex ae959ba58..de55ead69 100644\n--- a/src/liblsquic/lsquic_packet_common.c\n+++ b/src/liblsquic/lsquic_packet_common.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_packet_common.c -- some common packet-related routines\n  */\ndiff --git a/src/liblsquic/lsquic_packet_common.h b/src/liblsquic/lsquic_packet_common.h\nindex 886ef467f..e4f0e85ee 100644\n--- a/src/liblsquic/lsquic_packet_common.h\n+++ b/src/liblsquic/lsquic_packet_common.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef LSQUIC_PACKET_COMMON_H\n #define LSQUIC_PACKET_COMMON_H 1\n \ndiff --git a/src/liblsquic/lsquic_packet_gquic.c b/src/liblsquic/lsquic_packet_gquic.c\nindex 016170727..21a9c4b7e 100644\n--- a/src/liblsquic/lsquic_packet_gquic.c\n+++ b/src/liblsquic/lsquic_packet_gquic.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <stdint.h>\n #include <stdlib.h>\n \ndiff --git a/src/liblsquic/lsquic_packet_gquic.h b/src/liblsquic/lsquic_packet_gquic.h\nindex e430b9935..5628c3487 100644\n--- a/src/liblsquic/lsquic_packet_gquic.h\n+++ b/src/liblsquic/lsquic_packet_gquic.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef LSQUIC_PACKET_GQUIC_H\n #define LSQUIC_PACKET_GQUIC_H 1\n \ndiff --git a/src/liblsquic/lsquic_packet_ietf.h b/src/liblsquic/lsquic_packet_ietf.h\nindex 35c4a601d..d8014cc6d 100644\n--- a/src/liblsquic/lsquic_packet_ietf.h\n+++ b/src/liblsquic/lsquic_packet_ietf.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef LSQUIC_PACKET_IETF_H\n #define LSQUIC_PACKET_IETF_H 1\n \ndiff --git a/src/liblsquic/lsquic_packet_in.c b/src/liblsquic/lsquic_packet_in.c\nindex 83d9731c7..3bc73a62c 100644\n--- a/src/liblsquic/lsquic_packet_in.c\n+++ b/src/liblsquic/lsquic_packet_in.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdint.h>\n #include <string.h>\ndiff --git a/src/liblsquic/lsquic_packet_in.h b/src/liblsquic/lsquic_packet_in.h\nindex 1efc91828..4974497e6 100644\n--- a/src/liblsquic/lsquic_packet_in.h\n+++ b/src/liblsquic/lsquic_packet_in.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_packet_in.h\n  */\ndiff --git a/src/liblsquic/lsquic_packet_out.c b/src/liblsquic/lsquic_packet_out.c\nindex 271e3c8ec..241c7a271 100644\n--- a/src/liblsquic/lsquic_packet_out.c\n+++ b/src/liblsquic/lsquic_packet_out.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_packet_out.c\n  */\ndiff --git a/src/liblsquic/lsquic_packet_out.h b/src/liblsquic/lsquic_packet_out.h\nindex 5d8820f53..29c59dd1a 100644\n--- a/src/liblsquic/lsquic_packet_out.h\n+++ b/src/liblsquic/lsquic_packet_out.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_packet_out.h -- Structure and routines dealing with packet_out\n  */\ndiff --git a/src/liblsquic/lsquic_packet_resize.c b/src/liblsquic/lsquic_packet_resize.c\nindex 92d73880b..58ff02720 100644\n--- a/src/liblsquic/lsquic_packet_resize.c\n+++ b/src/liblsquic/lsquic_packet_resize.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /* Functions to resize packets */\n \n #include <assert.h>\ndiff --git a/src/liblsquic/lsquic_packet_resize.h b/src/liblsquic/lsquic_packet_resize.h\nindex 5510c8e22..bfb4c482a 100644\n--- a/src/liblsquic/lsquic_packet_resize.h\n+++ b/src/liblsquic/lsquic_packet_resize.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_packet_resize.h -- functions to resize packets\n  */\ndiff --git a/src/liblsquic/lsquic_parse.h b/src/liblsquic/lsquic_parse.h\nindex 0ddb7598d..4b7594d88 100644\n--- a/src/liblsquic/lsquic_parse.h\n+++ b/src/liblsquic/lsquic_parse.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef LSQUIC_PARSE_H\n #define LSQUIC_PARSE_H 1\n \ndiff --git a/src/liblsquic/lsquic_parse_Q046.c b/src/liblsquic/lsquic_parse_Q046.c\nindex ecb062dc0..c6fc7b801 100644\n--- a/src/liblsquic/lsquic_parse_Q046.c\n+++ b/src/liblsquic/lsquic_parse_Q046.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_parse_Q046.c -- Parsing functions specific to GQUIC Q046\n  */\ndiff --git a/src/liblsquic/lsquic_parse_Q050.c b/src/liblsquic/lsquic_parse_Q050.c\nindex 029a1f4a0..f61fb1680 100644\n--- a/src/liblsquic/lsquic_parse_Q050.c\n+++ b/src/liblsquic/lsquic_parse_Q050.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_parse_Q050.c -- Parsing functions specific to GQUIC Q050\n  */\ndiff --git a/src/liblsquic/lsquic_parse_common.c b/src/liblsquic/lsquic_parse_common.c\nindex ee7bcc5cb..ffb9282c6 100644\n--- a/src/liblsquic/lsquic_parse_common.c\n+++ b/src/liblsquic/lsquic_parse_common.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <string.h>\n #include <sys/queue.h>\ndiff --git a/src/liblsquic/lsquic_parse_common.h b/src/liblsquic/lsquic_parse_common.h\nindex f1d051d9c..ca9b08d2a 100644\n--- a/src/liblsquic/lsquic_parse_common.h\n+++ b/src/liblsquic/lsquic_parse_common.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_parse_common.h\n  */\ndiff --git a/src/liblsquic/lsquic_parse_gquic_be.c b/src/liblsquic/lsquic_parse_gquic_be.c\nindex f5f2f405b..dd4d3c143 100644\n--- a/src/liblsquic/lsquic_parse_gquic_be.c\n+++ b/src/liblsquic/lsquic_parse_gquic_be.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_parse_gquic_be.c -- Parsing functions specific to big-endian\n  *                              (now only Q043) GQUIC.\ndiff --git a/src/liblsquic/lsquic_parse_gquic_be.h b/src/liblsquic/lsquic_parse_gquic_be.h\nindex 4f8f0bd8c..5d3935958 100644\n--- a/src/liblsquic/lsquic_parse_gquic_be.h\n+++ b/src/liblsquic/lsquic_parse_gquic_be.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef LSQUIC_PARSE_GQUIC_BE_H\n #define LSQUIC_PARSE_GQUIC_BE_H\n \ndiff --git a/src/liblsquic/lsquic_parse_gquic_common.c b/src/liblsquic/lsquic_parse_gquic_common.c\nindex cfaecc88f..18bc46e8d 100644\n--- a/src/liblsquic/lsquic_parse_gquic_common.c\n+++ b/src/liblsquic/lsquic_parse_gquic_common.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_parse_gquic_common.c -- Parsing functions common to GQUIC\n  */\ndiff --git a/src/liblsquic/lsquic_parse_ietf.h b/src/liblsquic/lsquic_parse_ietf.h\nindex 6ec1664f2..91f855eda 100644\n--- a/src/liblsquic/lsquic_parse_ietf.h\n+++ b/src/liblsquic/lsquic_parse_ietf.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef LSQUIC_PARSE_IETF_H\n #define LSQUIC_PARSE_IETF_H 1\n \ndiff --git a/src/liblsquic/lsquic_parse_ietf_v1.c b/src/liblsquic/lsquic_parse_ietf_v1.c\nindex 7638028f7..d73502e3e 100644\n--- a/src/liblsquic/lsquic_parse_ietf_v1.c\n+++ b/src/liblsquic/lsquic_parse_ietf_v1.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_parse_ietf_v1.c -- Parsing functions specific to IETF QUIC v1\n  */\ndiff --git a/src/liblsquic/lsquic_parse_iquic_common.c b/src/liblsquic/lsquic_parse_iquic_common.c\nindex d4c1a6464..f5b6b3816 100644\n--- a/src/liblsquic/lsquic_parse_iquic_common.c\n+++ b/src/liblsquic/lsquic_parse_iquic_common.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * Parsing routines shared by all IETF QUIC versions.\n  */\ndiff --git a/src/liblsquic/lsquic_pr_queue.c b/src/liblsquic/lsquic_pr_queue.c\nindex e605c6774..82fb5b5b6 100644\n--- a/src/liblsquic/lsquic_pr_queue.c\n+++ b/src/liblsquic/lsquic_pr_queue.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_pr_queue.c -- packet request queue.\n  */\ndiff --git a/src/liblsquic/lsquic_pr_queue.h b/src/liblsquic/lsquic_pr_queue.h\nindex 439f4bd8a..e528fe99b 100644\n--- a/src/liblsquic/lsquic_pr_queue.h\n+++ b/src/liblsquic/lsquic_pr_queue.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_pr_queue.h -- a queue of packet requests\n  *\ndiff --git a/src/liblsquic/lsquic_purga.c b/src/liblsquic/lsquic_purga.c\nindex 817e354ca..e4007d2e9 100644\n--- a/src/liblsquic/lsquic_purga.c\n+++ b/src/liblsquic/lsquic_purga.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <errno.h>\n #include <inttypes.h>\n #include <stddef.h>\ndiff --git a/src/liblsquic/lsquic_purga.h b/src/liblsquic/lsquic_purga.h\nindex c28e06a29..152465d3a 100644\n--- a/src/liblsquic/lsquic_purga.h\n+++ b/src/liblsquic/lsquic_purga.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_purga.h -- Purgatory for CIDs\n  *\ndiff --git a/src/liblsquic/lsquic_push_promise.h b/src/liblsquic/lsquic_push_promise.h\nindex cf936d083..a6abdfa3a 100644\n--- a/src/liblsquic/lsquic_push_promise.h\n+++ b/src/liblsquic/lsquic_push_promise.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef LSQUIC_PUSH_PROMISE_H\n #define LSQUIC_PUSH_PROMISE_H 1\n \ndiff --git a/src/liblsquic/lsquic_qdec_hdl.c b/src/liblsquic/lsquic_qdec_hdl.c\nindex 73381a515..4a6c3abc7 100644\n--- a/src/liblsquic/lsquic_qdec_hdl.c\n+++ b/src/liblsquic/lsquic_qdec_hdl.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_qdec_hdl.c -- QPACK decoder streams handler\n  */\ndiff --git a/src/liblsquic/lsquic_qdec_hdl.h b/src/liblsquic/lsquic_qdec_hdl.h\nindex 8c349c6b8..f2c67297a 100644\n--- a/src/liblsquic/lsquic_qdec_hdl.h\n+++ b/src/liblsquic/lsquic_qdec_hdl.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_qdec_hdl.h -- QPACK decoder streams handler\n  *\ndiff --git a/src/liblsquic/lsquic_qenc_hdl.c b/src/liblsquic/lsquic_qenc_hdl.c\nindex 42a667533..8251ea8d5 100644\n--- a/src/liblsquic/lsquic_qenc_hdl.c\n+++ b/src/liblsquic/lsquic_qenc_hdl.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_qenc_hdl.c -- QPACK encoder streams handler\n  */\n@@ -34,6 +34,7 @@\n #define LSQUIC_LOG_CONN_ID lsquic_conn_log_cid(qeh->qeh_conn)\n #include \"lsquic_logger.h\"\n \n+#define QENC_MIN_DYN_TABLE_SIZE 32u\n \n static int\n qeh_write_type (struct qpack_enc_hdl *qeh)\n@@ -123,6 +124,8 @@ lsquic_qeh_settings (struct qpack_enc_hdl *qeh, unsigned max_table_size,\n     enc_opts = LSQPACK_ENC_OPT_STAGE_2\n              | (server ? LSQPACK_ENC_OPT_SERVER : 0);\n     qeh->qeh_tsu_sz = sizeof(qeh->qeh_tsu_buf);\n+    if (QENC_MIN_DYN_TABLE_SIZE > dyn_table_size)\n+        dyn_table_size = 0;\n     if (0 != lsqpack_enc_init(&qeh->qeh_encoder, (void *) qeh->qeh_conn,\n                 max_table_size, dyn_table_size, max_risked_streams, enc_opts,\n                 qeh->qeh_tsu_buf, &qeh->qeh_tsu_sz))\ndiff --git a/src/liblsquic/lsquic_qenc_hdl.h b/src/liblsquic/lsquic_qenc_hdl.h\nindex 37736dd87..8e0bba2a6 100644\n--- a/src/liblsquic/lsquic_qenc_hdl.h\n+++ b/src/liblsquic/lsquic_qenc_hdl.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_qenc_hdl.h -- QPACK encoder streams handler\n  *\ndiff --git a/src/liblsquic/lsquic_qlog.c b/src/liblsquic/lsquic_qlog.c\nindex 469aa516e..cde7b5309 100644\n--- a/src/liblsquic/lsquic_qlog.c\n+++ b/src/liblsquic/lsquic_qlog.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <stdlib.h>\n #include <stdio.h>\n #include <errno.h>\ndiff --git a/src/liblsquic/lsquic_qlog.h b/src/liblsquic/lsquic_qlog.h\nindex 61d2f71d2..60aacd43b 100644\n--- a/src/liblsquic/lsquic_qlog.h\n+++ b/src/liblsquic/lsquic_qlog.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_qlog.h -- QLOG Event logger\n  */\ndiff --git a/src/liblsquic/lsquic_qpack_dec_logger.h b/src/liblsquic/lsquic_qpack_dec_logger.h\nindex c9739d3eb..0add551fc 100644\n--- a/src/liblsquic/lsquic_qpack_dec_logger.h\n+++ b/src/liblsquic/lsquic_qpack_dec_logger.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /* This header file is included into lsqpack.c */\n \n #include \"lsquic.h\"\ndiff --git a/src/liblsquic/lsquic_qpack_enc_logger.h b/src/liblsquic/lsquic_qpack_enc_logger.h\nindex 9dbf85858..ff4d48eb2 100644\n--- a/src/liblsquic/lsquic_qpack_enc_logger.h\n+++ b/src/liblsquic/lsquic_qpack_enc_logger.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /* This header file is included into lsqpack.c */\n \n #include \"lsquic.h\"\ndiff --git a/src/liblsquic/lsquic_qpack_exp.c b/src/liblsquic/lsquic_qpack_exp.c\nindex f25dc71cd..fae37cc74 100644\n--- a/src/liblsquic/lsquic_qpack_exp.c\n+++ b/src/liblsquic/lsquic_qpack_exp.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <inttypes.h>\n #include <stdio.h>\n #include <stdlib.h>\ndiff --git a/src/liblsquic/lsquic_qpack_exp.h b/src/liblsquic/lsquic_qpack_exp.h\nindex 7f39708b5..235b61574 100644\n--- a/src/liblsquic/lsquic_qpack_exp.h\n+++ b/src/liblsquic/lsquic_qpack_exp.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /* QPACK Experiment record */\n \n #ifndef LSQUIC_QPACK_EXP_H\ndiff --git a/src/liblsquic/lsquic_qtags.h b/src/liblsquic/lsquic_qtags.h\nindex beade102b..9d3e02c40 100644\n--- a/src/liblsquic/lsquic_qtags.h\n+++ b/src/liblsquic/lsquic_qtags.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef LSQUIC_QTAGS_H\n #define LSQUIC_QTAGS_H 1\n \ndiff --git a/src/liblsquic/lsquic_rechist.c b/src/liblsquic/lsquic_rechist.c\nindex 98350efc4..3ec413011 100644\n--- a/src/liblsquic/lsquic_rechist.c\n+++ b/src/liblsquic/lsquic_rechist.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_rechist.c -- History of received packets.\n  */\ndiff --git a/src/liblsquic/lsquic_rechist.h b/src/liblsquic/lsquic_rechist.h\nindex 0f7894b98..8c4ea2821 100644\n--- a/src/liblsquic/lsquic_rechist.h\n+++ b/src/liblsquic/lsquic_rechist.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_rechist.h -- History of received packets.\n  *\ndiff --git a/src/liblsquic/lsquic_rtt.c b/src/liblsquic/lsquic_rtt.c\nindex 90edf2139..6cbba5bee 100644\n--- a/src/liblsquic/lsquic_rtt.c\n+++ b/src/liblsquic/lsquic_rtt.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_rtt.c -- RTT calculation\n  */\ndiff --git a/src/liblsquic/lsquic_rtt.h b/src/liblsquic/lsquic_rtt.h\nindex e31331d05..f9a3cd924 100644\n--- a/src/liblsquic/lsquic_rtt.h\n+++ b/src/liblsquic/lsquic_rtt.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_rtt.h -- RTT calculation\n  */\ndiff --git a/src/liblsquic/lsquic_send_ctl.c b/src/liblsquic/lsquic_send_ctl.c\nindex 1574ca495..70a291e14 100644\n--- a/src/liblsquic/lsquic_send_ctl.c\n+++ b/src/liblsquic/lsquic_send_ctl.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_send_ctl.c -- Logic for sending and sent packets\n  */\ndiff --git a/src/liblsquic/lsquic_send_ctl.h b/src/liblsquic/lsquic_send_ctl.h\nindex 565fd11b6..01156371b 100644\n--- a/src/liblsquic/lsquic_send_ctl.h\n+++ b/src/liblsquic/lsquic_send_ctl.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef LSQUIC_SEND_CTL_H\n #define LSQUIC_SEND_CTL_H 1\n \ndiff --git a/src/liblsquic/lsquic_senhist.c b/src/liblsquic/lsquic_senhist.c\nindex ca123af38..d63c2a4ce 100644\n--- a/src/liblsquic/lsquic_senhist.c\n+++ b/src/liblsquic/lsquic_senhist.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_senhist.c -- Sent history implementation\n  */\ndiff --git a/src/liblsquic/lsquic_senhist.h b/src/liblsquic/lsquic_senhist.h\nindex 8120c8c90..5d451d1f9 100644\n--- a/src/liblsquic/lsquic_senhist.h\n+++ b/src/liblsquic/lsquic_senhist.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_senhist.h -- History sent packets.\n  *\ndiff --git a/src/liblsquic/lsquic_set.c b/src/liblsquic/lsquic_set.c\nindex 66d97d3f6..143332444 100644\n--- a/src/liblsquic/lsquic_set.c\n+++ b/src/liblsquic/lsquic_set.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_set.c -- A set implementation.\n  *\ndiff --git a/src/liblsquic/lsquic_set.h b/src/liblsquic/lsquic_set.h\nindex 09e6989fb..f910bbadc 100644\n--- a/src/liblsquic/lsquic_set.h\n+++ b/src/liblsquic/lsquic_set.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_set.h -- A set implementation.\n  *\ndiff --git a/src/liblsquic/lsquic_sfcw.c b/src/liblsquic/lsquic_sfcw.c\nindex 1b14be3b2..d8e88166c 100644\n--- a/src/liblsquic/lsquic_sfcw.c\n+++ b/src/liblsquic/lsquic_sfcw.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <inttypes.h>\n #include <stdint.h>\n #include <stdlib.h>\ndiff --git a/src/liblsquic/lsquic_sfcw.h b/src/liblsquic/lsquic_sfcw.h\nindex a20691035..795cdc380 100644\n--- a/src/liblsquic/lsquic_sfcw.h\n+++ b/src/liblsquic/lsquic_sfcw.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_sfcw.h -- Stream flow control window functions\n  */\ndiff --git a/src/liblsquic/lsquic_shsk_stream.c b/src/liblsquic/lsquic_shsk_stream.c\nindex b71709769..f87001f7d 100644\n--- a/src/liblsquic/lsquic_shsk_stream.c\n+++ b/src/liblsquic/lsquic_shsk_stream.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * Stream/crypto handshake adapter for the server side.  Since on the server\n  * side, the handshake logic is handled in mini conn, this adapter does not\ndiff --git a/src/liblsquic/lsquic_shsk_stream.h b/src/liblsquic/lsquic_shsk_stream.h\nindex edc230c4f..86d0a021a 100644\n--- a/src/liblsquic/lsquic_shsk_stream.h\n+++ b/src/liblsquic/lsquic_shsk_stream.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * Stream/crypto handshake adapter for the server side.  See implementation\n  * for more comments and explanation.\ndiff --git a/src/liblsquic/lsquic_sizes.h b/src/liblsquic/lsquic_sizes.h\nindex 2d92ad422..2e4313e9c 100644\n--- a/src/liblsquic/lsquic_sizes.h\n+++ b/src/liblsquic/lsquic_sizes.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef LSQUIC_SIZES_H\n #define LSQUIC_SIZES_H 1\n \ndiff --git a/src/liblsquic/lsquic_spi.c b/src/liblsquic/lsquic_spi.c\nindex 47e81a908..b8dfde431 100644\n--- a/src/liblsquic/lsquic_spi.c\n+++ b/src/liblsquic/lsquic_spi.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_spi.c - implementation of Stream Priority Iterator.\n  */\ndiff --git a/src/liblsquic/lsquic_spi.h b/src/liblsquic/lsquic_spi.h\nindex e1ff6f5eb..450e1a278 100644\n--- a/src/liblsquic/lsquic_spi.h\n+++ b/src/liblsquic/lsquic_spi.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_spi.h - SPI: Stream Priority Iterator\n  *\ndiff --git a/src/liblsquic/lsquic_stock_shi.c b/src/liblsquic/lsquic_stock_shi.c\nindex 5a45582dd..eca31f5aa 100644\n--- a/src/liblsquic/lsquic_stock_shi.c\n+++ b/src/liblsquic/lsquic_stock_shi.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_stock_shi.c\n  */\ndiff --git a/src/liblsquic/lsquic_stock_shi.h b/src/liblsquic/lsquic_stock_shi.h\nindex 4f62e4248..49d240bb3 100644\n--- a/src/liblsquic/lsquic_stock_shi.h\n+++ b/src/liblsquic/lsquic_stock_shi.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_stock_shi.h - Stock shared hash interface implementation.\n  */\ndiff --git a/src/liblsquic/lsquic_str.c b/src/liblsquic/lsquic_str.c\nindex e0f3ea052..371c37789 100644\n--- a/src/liblsquic/lsquic_str.c\n+++ b/src/liblsquic/lsquic_str.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_str.c\n  *\ndiff --git a/src/liblsquic/lsquic_str.h b/src/liblsquic/lsquic_str.h\nindex 1eb7e2bbc..eb0f0cc4a 100644\n--- a/src/liblsquic/lsquic_str.h\n+++ b/src/liblsquic/lsquic_str.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_str.h -- Some string routines.\n  */\ndiff --git a/src/liblsquic/lsquic_stream.c b/src/liblsquic/lsquic_stream.c\nindex 906497d57..accb30473 100644\n--- a/src/liblsquic/lsquic_stream.c\n+++ b/src/liblsquic/lsquic_stream.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_stream.c -- stream processing\n  */\ndiff --git a/src/liblsquic/lsquic_stream.h b/src/liblsquic/lsquic_stream.h\nindex cbbc0d4f3..5058ea9cc 100644\n--- a/src/liblsquic/lsquic_stream.h\n+++ b/src/liblsquic/lsquic_stream.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef LSQUIC_STREAM_H\n #define LSQUIC_STREAM_H\n \ndiff --git a/src/liblsquic/lsquic_tokgen.c b/src/liblsquic/lsquic_tokgen.c\nindex 01fee268d..28dc214b8 100644\n--- a/src/liblsquic/lsquic_tokgen.c\n+++ b/src/liblsquic/lsquic_tokgen.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stddef.h>\n #include <stdlib.h>\ndiff --git a/src/liblsquic/lsquic_tokgen.h b/src/liblsquic/lsquic_tokgen.h\nindex c7501206e..b405a49f8 100644\n--- a/src/liblsquic/lsquic_tokgen.h\n+++ b/src/liblsquic/lsquic_tokgen.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef LSQUIC_TOKEN_H\n #define LSQUIC_TOKEN_H 1\n \ndiff --git a/src/liblsquic/lsquic_trans_params.c b/src/liblsquic/lsquic_trans_params.c\nindex bf6b468d8..188d54c1d 100644\n--- a/src/liblsquic/lsquic_trans_params.c\n+++ b/src/liblsquic/lsquic_trans_params.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_trans_params.c\n  */\ndiff --git a/src/liblsquic/lsquic_trans_params.h b/src/liblsquic/lsquic_trans_params.h\nindex 22d101b67..edf2df4a1 100644\n--- a/src/liblsquic/lsquic_trans_params.h\n+++ b/src/liblsquic/lsquic_trans_params.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_trans_params.h -- Transport parameters types and functions.\n  */\ndiff --git a/src/liblsquic/lsquic_trechist.c b/src/liblsquic/lsquic_trechist.c\nindex c7cefe37c..bb6d4adba 100644\n--- a/src/liblsquic/lsquic_trechist.c\n+++ b/src/liblsquic/lsquic_trechist.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <limits.h>\n #include <stddef.h>\ndiff --git a/src/liblsquic/lsquic_trechist.h b/src/liblsquic/lsquic_trechist.h\nindex 5c3bcd3bf..6b69e0efd 100644\n--- a/src/liblsquic/lsquic_trechist.h\n+++ b/src/liblsquic/lsquic_trechist.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * Tiny receive history.  It is used in IETF mini connection, where we want\n  * to use as little memory as possible.  This data structure is an array of\ndiff --git a/src/liblsquic/lsquic_util.c b/src/liblsquic/lsquic_util.c\nindex 7b2ba211b..e377cc8f9 100644\n--- a/src/liblsquic/lsquic_util.c\n+++ b/src/liblsquic/lsquic_util.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * Utility functions\n  */\ndiff --git a/src/liblsquic/lsquic_util.h b/src/liblsquic/lsquic_util.h\nindex e2c22a113..8989f9f84 100644\n--- a/src/liblsquic/lsquic_util.h\n+++ b/src/liblsquic/lsquic_util.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_util.h -- Utility functions\n  */\ndiff --git a/src/liblsquic/lsquic_varint.c b/src/liblsquic/lsquic_varint.c\nindex 237ad3e32..fd9c1ca01 100644\n--- a/src/liblsquic/lsquic_varint.c\n+++ b/src/liblsquic/lsquic_varint.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_varint.c -- routines dealing with IETF QUIC varint.\n  */\ndiff --git a/src/liblsquic/lsquic_varint.h b/src/liblsquic/lsquic_varint.h\nindex 50a7bd3f1..e7f44bdb1 100644\n--- a/src/liblsquic/lsquic_varint.h\n+++ b/src/liblsquic/lsquic_varint.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef LSQUIC_VARINT_H\n #define LSQUIC_VARINT_H 1\n \ndiff --git a/src/liblsquic/lsquic_ver_neg.h b/src/liblsquic/lsquic_ver_neg.h\nindex a52c09859..63fafb46d 100644\n--- a/src/liblsquic/lsquic_ver_neg.h\n+++ b/src/liblsquic/lsquic_ver_neg.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef LSQUIC_VER_NEG_H\n #define LSQUIC_VER_NEG_H\n \ndiff --git a/src/liblsquic/lsquic_version.c b/src/liblsquic/lsquic_version.c\nindex ac2bb1acf..25d477e24 100644\n--- a/src/liblsquic/lsquic_version.c\n+++ b/src/liblsquic/lsquic_version.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <string.h>\n \n #include \"lsquic.h\"\ndiff --git a/src/liblsquic/lsquic_version.h b/src/liblsquic/lsquic_version.h\nindex 46cf26085..2c047a5a9 100644\n--- a/src/liblsquic/lsquic_version.h\n+++ b/src/liblsquic/lsquic_version.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_version.h -- version manipulation routines\n  */\ndiff --git a/src/liblsquic/lsquic_xxhash.c b/src/liblsquic/lsquic_xxhash.c\nindex fc50769b9..38568821b 100644\n--- a/src/liblsquic/lsquic_xxhash.c\n+++ b/src/liblsquic/lsquic_xxhash.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n xxHash - Fast Hash algorithm\n Copyright (C) 2012-2014, Yann Collet.\ndiff --git a/src/liblsquic/lsquic_xxhash.h b/src/liblsquic/lsquic_xxhash.h\nindex 4a92f415f..d89bf4d7c 100644\n--- a/src/liblsquic/lsquic_xxhash.h\n+++ b/src/liblsquic/lsquic_xxhash.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n    xxHash - Extremely Fast Hash algorithm\n    Header File\ndiff --git a/tests/CMakeLists.txt b/tests/CMakeLists.txt\nindex 7aee69b62..fab22d334 100644\n--- a/tests/CMakeLists.txt\n+++ b/tests/CMakeLists.txt\n@@ -1,4 +1,4 @@\n-# Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE.\n+# Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE.\n INCLUDE_DIRECTORIES(../src/liblsquic)\n \n ENABLE_TESTING()\ndiff --git a/tests/graph_cubic.c b/tests/graph_cubic.c\nindex bf56da43d..f91ce6954 100644\n--- a/tests/graph_cubic.c\n+++ b/tests/graph_cubic.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * This is not really a test: this program prints out cwnd histogram\n  * for visual inspection.\ndiff --git a/tests/mini_parse.c b/tests/mini_parse.c\nindex e05e2299f..108f91f94 100644\n--- a/tests/mini_parse.c\n+++ b/tests/mini_parse.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * Convert from our hexdump format to binary:\n  *\ndiff --git a/tests/test_ack.c b/tests/test_ack.c\nindex ed866cba0..dbe856a7f 100644\n--- a/tests/test_ack.c\n+++ b/tests/test_ack.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /* Test both generation and parsing of IETF ACK frames */\n \n #include <assert.h>\ndiff --git a/tests/test_ack_merge.c b/tests/test_ack_merge.c\nindex e84fecd95..da3654efb 100644\n--- a/tests/test_ack_merge.c\n+++ b/tests/test_ack_merge.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /* Test ACK merge */\n \n #include <assert.h>\ndiff --git a/tests/test_ackgen_gquic_be.c b/tests/test_ackgen_gquic_be.c\nindex 2ddf21815..2247288a8 100644\n--- a/tests/test_ackgen_gquic_be.c\n+++ b/tests/test_ackgen_gquic_be.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * Test how ACK frame is encoded.  Receive history module is tested by a\n  * separate unit test.\ndiff --git a/tests/test_ackparse_gquic_be.c b/tests/test_ackparse_gquic_be.c\nindex 2b783e83e..1b8c9debd 100644\n--- a/tests/test_ackparse_gquic_be.c\n+++ b/tests/test_ackparse_gquic_be.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdio.h>\n #include <stdlib.h>\ndiff --git a/tests/test_ackparse_ietf.c b/tests/test_ackparse_ietf.c\nindex 0af1f08c0..78708c651 100644\n--- a/tests/test_ackparse_ietf.c\n+++ b/tests/test_ackparse_ietf.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdio.h>\n #include <stdlib.h>\ndiff --git a/tests/test_alarmset.c b/tests/test_alarmset.c\nindex 301a021de..faf7f6e82 100644\n--- a/tests/test_alarmset.c\n+++ b/tests/test_alarmset.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdio.h>\n #include <stdlib.h>\ndiff --git a/tests/test_alt_svc_ver.c b/tests/test_alt_svc_ver.c\nindex b8d13d53f..e3c5184d4 100644\n--- a/tests/test_alt_svc_ver.c\n+++ b/tests/test_alt_svc_ver.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <string.h>\n \ndiff --git a/tests/test_arr.c b/tests/test_arr.c\nindex e27069bda..0a4e36662 100644\n--- a/tests/test_arr.c\n+++ b/tests/test_arr.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n \n #include \"lsquic_arr.h\"\ndiff --git a/tests/test_attq.c b/tests/test_attq.c\nindex 36849f2de..8901972e5 100644\n--- a/tests/test_attq.c\n+++ b/tests/test_attq.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdlib.h>\n #include <sys/queue.h>\ndiff --git a/tests/test_blocked_gquic_be.c b/tests/test_blocked_gquic_be.c\nindex e198e60cb..2ab947cf0 100644\n--- a/tests/test_blocked_gquic_be.c\n+++ b/tests/test_blocked_gquic_be.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdio.h>\n #include <stdlib.h>\ndiff --git a/tests/test_bw_sampler.c b/tests/test_bw_sampler.c\nindex 3011126c1..07796e290 100644\n--- a/tests/test_bw_sampler.c\n+++ b/tests/test_bw_sampler.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /* Test adapted from Chromium bandwidth_sampler_test.cc */\n // Copyright 2016 The Chromium Authors. All rights reserved.\n \ndiff --git a/tests/test_chlo_gen.c b/tests/test_chlo_gen.c\nindex 4c3d5a500..b40a77cb8 100644\n--- a/tests/test_chlo_gen.c\n+++ b/tests/test_chlo_gen.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * test_chlo_gen.c -- Test Client Hello generation.\n  */\ndiff --git a/tests/test_clear_aead.c b/tests/test_clear_aead.c\nindex 939ad3c3b..e0538370c 100644\n--- a/tests/test_clear_aead.c\n+++ b/tests/test_clear_aead.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * See\n  *  https://github.com/quicwg/base-drafts/wiki/Test-Vector-for-the-Clear-Text-AEAD-key-derivation\ndiff --git a/tests/test_conn_close_gquic_be.c b/tests/test_conn_close_gquic_be.c\nindex 085078646..c0608ba2b 100644\n--- a/tests/test_conn_close_gquic_be.c\n+++ b/tests/test_conn_close_gquic_be.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdio.h>\n #include <stdlib.h>\ndiff --git a/tests/test_conn_hash.c b/tests/test_conn_hash.c\nindex 5d1870c14..590672b00 100644\n--- a/tests/test_conn_hash.c\n+++ b/tests/test_conn_hash.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdint.h>\n #include <stdio.h>\ndiff --git a/tests/test_crypto_gen.c b/tests/test_crypto_gen.c\nindex 77589cd7d..7e6ac98fd 100644\n--- a/tests/test_crypto_gen.c\n+++ b/tests/test_crypto_gen.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdio.h>\n #include <stdlib.h>\ndiff --git a/tests/test_cubic.c b/tests/test_cubic.c\nindex b8f0b0d8b..295c1e3d9 100644\n--- a/tests/test_cubic.c\n+++ b/tests/test_cubic.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdio.h>\n #include <stdlib.h>\ndiff --git a/tests/test_dec.c b/tests/test_dec.c\nindex 3836bade6..b48bd5b11 100644\n--- a/tests/test_dec.c\n+++ b/tests/test_dec.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * test_dec.c -- Benchmark decryption using aligned and non-aligned buffers.\n  */\ndiff --git a/tests/test_di_nocopy.c b/tests/test_di_nocopy.c\nindex d90489e1e..441cbed2b 100644\n--- a/tests/test_di_nocopy.c\n+++ b/tests/test_di_nocopy.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * Test the \"nocopy\" data in stream\n  */\ndiff --git a/tests/test_elision.c b/tests/test_elision.c\nindex 13f4685c2..e6bef80a3 100644\n--- a/tests/test_elision.c\n+++ b/tests/test_elision.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <errno.h>\n #include <stdio.h>\ndiff --git a/tests/test_engine_ctor.c b/tests/test_engine_ctor.c\nindex 39e83ace1..5e9f67712 100644\n--- a/tests/test_engine_ctor.c\n+++ b/tests/test_engine_ctor.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdlib.h>\n #include <string.h>\ndiff --git a/tests/test_export_key.c b/tests/test_export_key.c\nindex b674cf72e..7e0de9c4a 100644\n--- a/tests/test_export_key.c\n+++ b/tests/test_export_key.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdlib.h>\n #include <string.h>\ndiff --git a/tests/test_frame_chop.c b/tests/test_frame_chop.c\nindex 6d906f1ef..518b849bf 100644\n--- a/tests/test_frame_chop.c\n+++ b/tests/test_frame_chop.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * Write several things to HEADERS stream and check the results.  What\n  * varies is the amount of bytes that are written to stream every time.\ndiff --git a/tests/test_frame_reader.c b/tests/test_frame_reader.c\nindex 0028e8e53..0d71a940a 100644\n--- a/tests/test_frame_reader.c\n+++ b/tests/test_frame_reader.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <errno.h>\n #include <stdio.h>\ndiff --git a/tests/test_frame_rw.c b/tests/test_frame_rw.c\nindex 7d13876ab..f4b7dbbf0 100644\n--- a/tests/test_frame_rw.c\n+++ b/tests/test_frame_rw.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * Generate a few thousand headers, frame them using frame writer, read them\n  * using frame reader, parse them, and compare with the original list: the\ndiff --git a/tests/test_frame_writer.c b/tests/test_frame_writer.c\nindex 7f5825481..12b5b1dc9 100644\n--- a/tests/test_frame_writer.c\n+++ b/tests/test_frame_writer.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <errno.h>\n #include <stdio.h>\ndiff --git a/tests/test_goaway_gquic_be.c b/tests/test_goaway_gquic_be.c\nindex b4a14801e..a3db7f9bd 100644\n--- a/tests/test_goaway_gquic_be.c\n+++ b/tests/test_goaway_gquic_be.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdio.h>\n #include <stdlib.h>\ndiff --git a/tests/test_h3_framing.c b/tests/test_h3_framing.c\nindex 9e4c951ef..cf6d25237 100644\n--- a/tests/test_h3_framing.c\n+++ b/tests/test_h3_framing.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * test_h3_framing.c -- test generation of H3 frames\n  */\ndiff --git a/tests/test_hcsi_reader.c b/tests/test_hcsi_reader.c\nindex 74432c8c1..8e688e64e 100644\n--- a/tests/test_hcsi_reader.c\n+++ b/tests/test_hcsi_reader.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <inttypes.h>\n #include <stdlib.h>\ndiff --git a/tests/test_hkdf.c b/tests/test_hkdf.c\nindex d699ae54a..a29ab4e70 100644\n--- a/tests/test_hkdf.c\n+++ b/tests/test_hkdf.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <string.h>\n #include <openssl/ssl.h>\ndiff --git a/tests/test_hpi.c b/tests/test_hpi.c\nindex a601b28f3..d08e3d11a 100644\n--- a/tests/test_hpi.c\n+++ b/tests/test_hpi.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <errno.h>\n #include <stdio.h>\ndiff --git a/tests/test_lsquic_hash.c b/tests/test_lsquic_hash.c\nindex 36fb625bf..f56390195 100644\n--- a/tests/test_lsquic_hash.c\n+++ b/tests/test_lsquic_hash.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdint.h>\n #include <stdio.h>\ndiff --git a/tests/test_malo.c b/tests/test_malo.c\nindex f7e67f2ff..4f6615ed0 100644\n--- a/tests/test_malo.c\n+++ b/tests/test_malo.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdint.h>\n #include <stdio.h>\ndiff --git a/tests/test_min_heap.c b/tests/test_min_heap.c\nindex 80100c930..cdd56d267 100644\n--- a/tests/test_min_heap.c\n+++ b/tests/test_min_heap.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /* Test min heap or benchmark heap creation */\n \n /* Floyd mechanism has been removed.  It's not faster. */\ndiff --git a/tests/test_minmax.c b/tests/test_minmax.c\nindex 6bebe86e8..60e071ec6 100644\n--- a/tests/test_minmax.c\n+++ b/tests/test_minmax.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /* Tests adopted from Chromium windowed_filter_test.cc */\n // Copyright (c) 2016 The Chromium Authors. All rights reserved.\n \ndiff --git a/tests/test_packet_out.c b/tests/test_packet_out.c\nindex 2b7441080..35478edf0 100644\n--- a/tests/test_packet_out.c\n+++ b/tests/test_packet_out.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <errno.h>\n #include <stdio.h>\ndiff --git a/tests/test_packet_resize.c b/tests/test_packet_resize.c\nindex 360f668b5..bc121bb38 100644\n--- a/tests/test_packet_resize.c\n+++ b/tests/test_packet_resize.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /* Test packet resizing */\n \n #include <assert.h>\ndiff --git a/tests/test_packno_len.c b/tests/test_packno_len.c\nindex 6cca758cf..9292ba35f 100644\n--- a/tests/test_packno_len.c\n+++ b/tests/test_packno_len.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdio.h>\n #include <stdlib.h>\ndiff --git a/tests/test_parse_packet_in.c b/tests/test_parse_packet_in.c\nindex 648725596..66ab19828 100644\n--- a/tests/test_parse_packet_in.c\n+++ b/tests/test_parse_packet_in.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdint.h>\n #include <stdlib.h>\ndiff --git a/tests/test_purga.c b/tests/test_purga.c\nindex a79e3ec24..28e7ac3f7 100644\n--- a/tests/test_purga.c\n+++ b/tests/test_purga.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdlib.h>\n #include <string.h>\ndiff --git a/tests/test_qlog.c b/tests/test_qlog.c\nindex 9d916e75b..fc8f40f9a 100644\n--- a/tests/test_qlog.c\n+++ b/tests/test_qlog.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdio.h>\n #include <stdlib.h>\ndiff --git a/tests/test_quic_be_floats.c b/tests/test_quic_be_floats.c\nindex e1f21d7f4..209b20517 100644\n--- a/tests/test_quic_be_floats.c\n+++ b/tests/test_quic_be_floats.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdio.h>\n #include <stdlib.h>\ndiff --git a/tests/test_rechist.c b/tests/test_rechist.c\nindex cc46ffd10..a41323fc5 100644\n--- a/tests/test_rechist.c\n+++ b/tests/test_rechist.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <inttypes.h>\n #include <stdio.h>\ndiff --git a/tests/test_reg_pkt_headergen.c b/tests/test_reg_pkt_headergen.c\nindex 481379c38..dbf400ded 100644\n--- a/tests/test_reg_pkt_headergen.c\n+++ b/tests/test_reg_pkt_headergen.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdio.h>\n #include <stdlib.h>\ndiff --git a/tests/test_rst_stream_gquic_be.c b/tests/test_rst_stream_gquic_be.c\nindex 26126b827..49971634b 100644\n--- a/tests/test_rst_stream_gquic_be.c\n+++ b/tests/test_rst_stream_gquic_be.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdio.h>\n #include <stdlib.h>\ndiff --git a/tests/test_rst_stream_ietf.c b/tests/test_rst_stream_ietf.c\nindex 5c912fa07..c43be944f 100644\n--- a/tests/test_rst_stream_ietf.c\n+++ b/tests/test_rst_stream_ietf.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdio.h>\n #include <stdlib.h>\ndiff --git a/tests/test_rtt.c b/tests/test_rtt.c\nindex 63c10112b..430046e6a 100644\n--- a/tests/test_rtt.c\n+++ b/tests/test_rtt.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdio.h>\n #include <stdlib.h>\ndiff --git a/tests/test_send_headers.c b/tests/test_send_headers.c\nindex daa0d5dd6..5e709793b 100644\n--- a/tests/test_send_headers.c\n+++ b/tests/test_send_headers.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * test_send_headers.c -- Test what happens when lsquic_stream_send_headers()\n  * is called.\ndiff --git a/tests/test_senhist.c b/tests/test_senhist.c\nindex 35a151099..4804bef29 100644\n--- a/tests/test_senhist.c\n+++ b/tests/test_senhist.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdio.h>\n #include <stdlib.h>\ndiff --git a/tests/test_set.c b/tests/test_set.c\nindex dd3280e63..28ce4a3d0 100644\n--- a/tests/test_set.c\n+++ b/tests/test_set.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdio.h>\n #include <stdlib.h>\ndiff --git a/tests/test_sfcw.c b/tests/test_sfcw.c\nindex 7905c0c23..67c659883 100644\n--- a/tests/test_sfcw.c\n+++ b/tests/test_sfcw.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdio.h>\n #include <stdint.h>\ndiff --git a/tests/test_shi.c b/tests/test_shi.c\nindex 24bf756e7..138c7f7e6 100644\n--- a/tests/test_shi.c\n+++ b/tests/test_shi.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdlib.h>\n #include <string.h>\ndiff --git a/tests/test_some_packets.c b/tests/test_some_packets.c\nindex 79dce845d..88766b45e 100644\n--- a/tests/test_some_packets.c\n+++ b/tests/test_some_packets.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /* Tests in this file have been migrated out of maintest.c */\n /* TODO: fix warnings */\n \ndiff --git a/tests/test_spi.c b/tests/test_spi.c\nindex 2f1a6001f..b603a4cd7 100644\n--- a/tests/test_spi.c\n+++ b/tests/test_spi.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <errno.h>\n #include <stdio.h>\ndiff --git a/tests/test_stop_waiting_gquic_be.c b/tests/test_stop_waiting_gquic_be.c\nindex 87b996d4c..d1195c2f7 100644\n--- a/tests/test_stop_waiting_gquic_be.c\n+++ b/tests/test_stop_waiting_gquic_be.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdio.h>\n #include <stdlib.h>\ndiff --git a/tests/test_stream.c b/tests/test_stream.c\nindex 860136923..8597530b3 100644\n--- a/tests/test_stream.c\n+++ b/tests/test_stream.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <errno.h>\n #include <stdio.h>\ndiff --git a/tests/test_streamgen.c b/tests/test_streamgen.c\nindex a4b13c58a..a46340d79 100644\n--- a/tests/test_streamgen.c\n+++ b/tests/test_streamgen.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdio.h>\n #include <stdlib.h>\ndiff --git a/tests/test_streamparse.c b/tests/test_streamparse.c\nindex 8013cf4b5..e776f654e 100644\n--- a/tests/test_streamparse.c\n+++ b/tests/test_streamparse.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdio.h>\n #include <stdlib.h>\ndiff --git a/tests/test_tokgen.c b/tests/test_tokgen.c\nindex 9650e20c0..0bc8e63fa 100644\n--- a/tests/test_tokgen.c\n+++ b/tests/test_tokgen.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdio.h>\n #include <string.h>\ndiff --git a/tests/test_trapa.c b/tests/test_trapa.c\nindex f3c4ed604..a0e7e89d7 100644\n--- a/tests/test_trapa.c\n+++ b/tests/test_trapa.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * test_trapa.c -- Test transport parameters.\n  */\ndiff --git a/tests/test_trechist.c b/tests/test_trechist.c\nindex f0040c220..163bfca1a 100644\n--- a/tests/test_trechist.c\n+++ b/tests/test_trechist.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /* Tests based on rechist tests */\n \n #include <assert.h>\ndiff --git a/tests/test_varint.c b/tests/test_varint.c\nindex 3f98c4386..b6779b727 100644\n--- a/tests/test_varint.c\n+++ b/tests/test_varint.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stddef.h>\n #include <stdint.h>\ndiff --git a/tests/test_ver_nego.c b/tests/test_ver_nego.c\nindex 9a0217fe3..e753d0a99 100644\n--- a/tests/test_ver_nego.c\n+++ b/tests/test_ver_nego.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdio.h>\n #include <stdlib.h>\ndiff --git a/tests/test_wuf_gquic_be.c b/tests/test_wuf_gquic_be.c\nindex 00fc868e3..992c78bc1 100644\n--- a/tests/test_wuf_gquic_be.c\n+++ b/tests/test_wuf_gquic_be.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdio.h>\n #include <stdlib.h>\ndiff --git a/wincompat/README.txt b/wincompat/README.txt\nindex 18f7680b3..a5ced1f76 100644\n--- a/wincompat/README.txt\n+++ b/wincompat/README.txt\n@@ -1,4 +1,4 @@\n-# Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE.\n+# Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE.\n - only debug and release are expected in the Cmakelists.txt. If you need a different config, please follow the model in that file to add it.\n \n - vcpkg does not have boringssl, so you'll have to build it yourself. Follow the instructions at the boringssl repository.\ndiff --git a/wincompat/sys/queue.h b/wincompat/sys/queue.h\nindex 4bc39ab23..e15d61af2 100644\n--- a/wincompat/sys/queue.h\n+++ b/wincompat/sys/queue.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*-\n  * SPDX-License-Identifier: BSD-3-Clause\n  *\ndiff --git a/wincompat/vc_compat.h b/wincompat/vc_compat.h\nindex 251e971f2..f5369a7d7 100644\n--- a/wincompat/vc_compat.h\n+++ b/wincompat/vc_compat.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #pragma once\n #include <Windows.h>\n #include <winsock2.h>\n"
        ],
        "func_after": []
    },
    {
        "idx": 196316,
        "project": "barebox",
        "commit_id": "0a9f9a7410681e55362f8311537ebc7be9ad0fbe",
        "project_url": "https://github.com/saschahauer/barebox",
        "commit_url": "https://github.com/saschahauer/barebox/commit/0a9f9a7410681e55362f8311537ebc7be9ad0fbe",
        "commit_message": "crypto: digest: use crypto_memneq()\n\nWhen verifying a digest it is important not to leak timing information\nthrough memcmp(). Use crypto_memneq() instead.\n\nSigned-off-by: Sascha Hauer <s.hauer@pengutronix.de>",
        "target": 1,
        "irrelevant": 1,
        "func_before": "int digest_generic_verify(struct digest *d, const unsigned char *md)\n{\n\tint ret;\n\tint len = digest_length(d);\n\tunsigned char *tmp;\n\n\ttmp = xmalloc(len);\n\n\tret = digest_final(d, tmp);\n\tif (ret)\n\t\tgoto end;\n\n\tret = memcmp(md, tmp, len);\n\tret = ret ? -EINVAL : 0;\nend:\n\tfree(tmp);\n\treturn ret;\n}",
        "func_hash": 71480685616976545176363965575731858659,
        "file_name": "digest.c",
        "file_hash": 309636649404648894565051311749383985179,
        "cwe": [
            "CWE-200"
        ],
        "cve": "CVE-2021-37847",
        "cve_desc": "crypto/digest.c in Pengutronix barebox through 2021.07.0 leaks timing information because memcmp is used during digest verification.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37847",
        "func_name": "digest_generic_verify",
        "diff": [
            "diff --git a/crypto/digest.c b/crypto/digest.c\nindex d23245e15f..621d384168 100644\n--- a/crypto/digest.c\n+++ b/crypto/digest.c\n@@ -22,6 +22,7 @@\n #include <errno.h>\n #include <module.h>\n #include <linux/err.h>\n+#include <crypto.h>\n #include <crypto/internal.h>\n \n static LIST_HEAD(digests);\n@@ -47,8 +48,10 @@ int digest_generic_verify(struct digest *d, const unsigned char *md)\n \tif (ret)\n \t\tgoto end;\n \n-\tret = memcmp(md, tmp, len);\n-\tret = ret ? -EINVAL : 0;\n+\tif (crypto_memneq(md, tmp, len))\n+\t\tret = -EINVAL;\n+\telse\n+\t\tret = 0;\n end:\n \tfree(tmp);\n \treturn ret;\n"
        ],
        "func_after": []
    },
    {
        "idx": 196328,
        "project": "vim",
        "commit_id": "409510c588b1eec1ae33511ae97a21eb8e110895",
        "project_url": "https://github.com/vim/vim",
        "commit_url": "https://github.com/vim/vim/commit/409510c588b1eec1ae33511ae97a21eb8e110895",
        "commit_message": "patch 8.2.5050: using freed memory when searching for pattern in path\n\nProblem:    Using freed memory when searching for pattern in path.\nSolution:   Make a copy of the line.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "find_pattern_in_path(\n    char_u\t*ptr,\t\t// pointer to search pattern\n    int\t\tdir UNUSED,\t// direction of expansion\n    int\t\tlen,\t\t// length of search pattern\n    int\t\twhole,\t\t// match whole words only\n    int\t\tskip_comments,\t// don't match inside comments\n    int\t\ttype,\t\t// Type of search; are we looking for a type?\n\t\t\t\t// a macro?\n    long\tcount,\n    int\t\taction,\t\t// What to do when we find it\n    linenr_T\tstart_lnum,\t// first line to start searching\n    linenr_T\tend_lnum)\t// last line for searching\n{\n    SearchedFile *files;\t\t// Stack of included files\n    SearchedFile *bigger;\t\t// When we need more space\n    int\t\tmax_path_depth = 50;\n    long\tmatch_count = 1;\n\n    char_u\t*pat;\n    char_u\t*new_fname;\n    char_u\t*curr_fname = curbuf->b_fname;\n    char_u\t*prev_fname = NULL;\n    linenr_T\tlnum;\n    int\t\tdepth;\n    int\t\tdepth_displayed;\t// For type==CHECK_PATH\n    int\t\told_files;\n    int\t\talready_searched;\n    char_u\t*file_line;\n    char_u\t*line;\n    char_u\t*p;\n    char_u\tsave_char;\n    int\t\tdefine_matched;\n    regmatch_T\tregmatch;\n    regmatch_T\tincl_regmatch;\n    regmatch_T\tdef_regmatch;\n    int\t\tmatched = FALSE;\n    int\t\tdid_show = FALSE;\n    int\t\tfound = FALSE;\n    int\t\ti;\n    char_u\t*already = NULL;\n    char_u\t*startp = NULL;\n    char_u\t*inc_opt = NULL;\n#if defined(FEAT_QUICKFIX)\n    win_T\t*curwin_save = NULL;\n#endif\n\n    regmatch.regprog = NULL;\n    incl_regmatch.regprog = NULL;\n    def_regmatch.regprog = NULL;\n\n    file_line = alloc(LSIZE);\n    if (file_line == NULL)\n\treturn;\n\n    if (type != CHECK_PATH && type != FIND_DEFINE\n\t    // when CONT_SOL is set compare \"ptr\" with the beginning of the\n\t    // line is faster than quote_meta/regcomp/regexec \"ptr\" -- Acevedo\n\t    && !compl_status_sol())\n    {\n\tpat = alloc(len + 5);\n\tif (pat == NULL)\n\t    goto fpip_end;\n\tsprintf((char *)pat, whole ? \"\\\\<%.*s\\\\>\" : \"%.*s\", len, ptr);\n\t// ignore case according to p_ic, p_scs and pat\n\tregmatch.rm_ic = ignorecase(pat);\n\tregmatch.regprog = vim_regcomp(pat, magic_isset() ? RE_MAGIC : 0);\n\tvim_free(pat);\n\tif (regmatch.regprog == NULL)\n\t    goto fpip_end;\n    }\n    inc_opt = (*curbuf->b_p_inc == NUL) ? p_inc : curbuf->b_p_inc;\n    if (*inc_opt != NUL)\n    {\n\tincl_regmatch.regprog = vim_regcomp(inc_opt,\n\t\t\t\t\t\t magic_isset() ? RE_MAGIC : 0);\n\tif (incl_regmatch.regprog == NULL)\n\t    goto fpip_end;\n\tincl_regmatch.rm_ic = FALSE;\t// don't ignore case in incl. pat.\n    }\n    if (type == FIND_DEFINE && (*curbuf->b_p_def != NUL || *p_def != NUL))\n    {\n\tdef_regmatch.regprog = vim_regcomp(*curbuf->b_p_def == NUL\n\t\t\t   ? p_def : curbuf->b_p_def,\n\t\t\t\t\t\t magic_isset() ? RE_MAGIC : 0);\n\tif (def_regmatch.regprog == NULL)\n\t    goto fpip_end;\n\tdef_regmatch.rm_ic = FALSE;\t// don't ignore case in define pat.\n    }\n    files = lalloc_clear(max_path_depth * sizeof(SearchedFile), TRUE);\n    if (files == NULL)\n\tgoto fpip_end;\n    old_files = max_path_depth;\n    depth = depth_displayed = -1;\n\n    lnum = start_lnum;\n    if (end_lnum > curbuf->b_ml.ml_line_count)\n\tend_lnum = curbuf->b_ml.ml_line_count;\n    if (lnum > end_lnum)\t\t// do at least one line\n\tlnum = end_lnum;\n    line = ml_get(lnum);\n\n    for (;;)\n    {\n\tif (incl_regmatch.regprog != NULL\n\t\t&& vim_regexec(&incl_regmatch, line, (colnr_T)0))\n\t{\n\t    char_u *p_fname = (curr_fname == curbuf->b_fname)\n\t\t\t\t\t      ? curbuf->b_ffname : curr_fname;\n\n\t    if (inc_opt != NULL && strstr((char *)inc_opt, \"\\\\zs\") != NULL)\n\t\t// Use text from '\\zs' to '\\ze' (or end) of 'include'.\n\t\tnew_fname = find_file_name_in_path(incl_regmatch.startp[0],\n\t\t       (int)(incl_regmatch.endp[0] - incl_regmatch.startp[0]),\n\t\t\t\t FNAME_EXP|FNAME_INCL|FNAME_REL, 1L, p_fname);\n\t    else\n\t\t// Use text after match with 'include'.\n\t\tnew_fname = file_name_in_line(incl_regmatch.endp[0], 0,\n\t\t\t     FNAME_EXP|FNAME_INCL|FNAME_REL, 1L, p_fname, NULL);\n\t    already_searched = FALSE;\n\t    if (new_fname != NULL)\n\t    {\n\t\t// Check whether we have already searched in this file\n\t\tfor (i = 0;; i++)\n\t\t{\n\t\t    if (i == depth + 1)\n\t\t\ti = old_files;\n\t\t    if (i == max_path_depth)\n\t\t\tbreak;\n\t\t    if (fullpathcmp(new_fname, files[i].name, TRUE, TRUE)\n\t\t\t\t\t\t\t\t    & FPC_SAME)\n\t\t    {\n\t\t\tif (type != CHECK_PATH\n\t\t\t\t&& action == ACTION_SHOW_ALL\n\t\t\t\t&& files[i].matched)\n\t\t\t{\n\t\t\t    msg_putchar('\\n');\t    // cursor below last one\n\t\t\t    if (!got_int)\t    // don't display if 'q'\n\t\t\t\t\t\t    // typed at \"--more--\"\n\t\t\t\t\t\t    // message\n\t\t\t    {\n\t\t\t\tmsg_home_replace_hl(new_fname);\n\t\t\t\tmsg_puts(_(\" (includes previously listed match)\"));\n\t\t\t\tprev_fname = NULL;\n\t\t\t    }\n\t\t\t}\n\t\t\tVIM_CLEAR(new_fname);\n\t\t\talready_searched = TRUE;\n\t\t\tbreak;\n\t\t    }\n\t\t}\n\t    }\n\n\t    if (type == CHECK_PATH && (action == ACTION_SHOW_ALL\n\t\t\t\t || (new_fname == NULL && !already_searched)))\n\t    {\n\t\tif (did_show)\n\t\t    msg_putchar('\\n');\t    // cursor below last one\n\t\telse\n\t\t{\n\t\t    gotocmdline(TRUE);\t    // cursor at status line\n\t\t    msg_puts_title(_(\"--- Included files \"));\n\t\t    if (action != ACTION_SHOW_ALL)\n\t\t\tmsg_puts_title(_(\"not found \"));\n\t\t    msg_puts_title(_(\"in path ---\\n\"));\n\t\t}\n\t\tdid_show = TRUE;\n\t\twhile (depth_displayed < depth && !got_int)\n\t\t{\n\t\t    ++depth_displayed;\n\t\t    for (i = 0; i < depth_displayed; i++)\n\t\t\tmsg_puts(\"  \");\n\t\t    msg_home_replace(files[depth_displayed].name);\n\t\t    msg_puts(\" -->\\n\");\n\t\t}\n\t\tif (!got_int)\t\t    // don't display if 'q' typed\n\t\t\t\t\t    // for \"--more--\" message\n\t\t{\n\t\t    for (i = 0; i <= depth_displayed; i++)\n\t\t\tmsg_puts(\"  \");\n\t\t    if (new_fname != NULL)\n\t\t    {\n\t\t\t// using \"new_fname\" is more reliable, e.g., when\n\t\t\t// 'includeexpr' is set.\n\t\t\tmsg_outtrans_attr(new_fname, HL_ATTR(HLF_D));\n\t\t    }\n\t\t    else\n\t\t    {\n\t\t\t/*\n\t\t\t * Isolate the file name.\n\t\t\t * Include the surrounding \"\" or <> if present.\n\t\t\t */\n\t\t\tif (inc_opt != NULL\n\t\t\t\t   && strstr((char *)inc_opt, \"\\\\zs\") != NULL)\n\t\t\t{\n\t\t\t    // pattern contains \\zs, use the match\n\t\t\t    p = incl_regmatch.startp[0];\n\t\t\t    i = (int)(incl_regmatch.endp[0]\n\t\t\t\t\t\t   - incl_regmatch.startp[0]);\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t    // find the file name after the end of the match\n\t\t\t    for (p = incl_regmatch.endp[0];\n\t\t\t\t\t\t  *p && !vim_isfilec(*p); p++)\n\t\t\t\t;\n\t\t\t    for (i = 0; vim_isfilec(p[i]); i++)\n\t\t\t\t;\n\t\t\t}\n\n\t\t\tif (i == 0)\n\t\t\t{\n\t\t\t    // Nothing found, use the rest of the line.\n\t\t\t    p = incl_regmatch.endp[0];\n\t\t\t    i = (int)STRLEN(p);\n\t\t\t}\n\t\t\t// Avoid checking before the start of the line, can\n\t\t\t// happen if \\zs appears in the regexp.\n\t\t\telse if (p > line)\n\t\t\t{\n\t\t\t    if (p[-1] == '\"' || p[-1] == '<')\n\t\t\t    {\n\t\t\t\t--p;\n\t\t\t\t++i;\n\t\t\t    }\n\t\t\t    if (p[i] == '\"' || p[i] == '>')\n\t\t\t\t++i;\n\t\t\t}\n\t\t\tsave_char = p[i];\n\t\t\tp[i] = NUL;\n\t\t\tmsg_outtrans_attr(p, HL_ATTR(HLF_D));\n\t\t\tp[i] = save_char;\n\t\t    }\n\n\t\t    if (new_fname == NULL && action == ACTION_SHOW_ALL)\n\t\t    {\n\t\t\tif (already_searched)\n\t\t\t    msg_puts(_(\"  (Already listed)\"));\n\t\t\telse\n\t\t\t    msg_puts(_(\"  NOT FOUND\"));\n\t\t    }\n\t\t}\n\t\tout_flush();\t    // output each line directly\n\t    }\n\n\t    if (new_fname != NULL)\n\t    {\n\t\t// Push the new file onto the file stack\n\t\tif (depth + 1 == old_files)\n\t\t{\n\t\t    bigger = ALLOC_MULT(SearchedFile, max_path_depth * 2);\n\t\t    if (bigger != NULL)\n\t\t    {\n\t\t\tfor (i = 0; i <= depth; i++)\n\t\t\t    bigger[i] = files[i];\n\t\t\tfor (i = depth + 1; i < old_files + max_path_depth; i++)\n\t\t\t{\n\t\t\t    bigger[i].fp = NULL;\n\t\t\t    bigger[i].name = NULL;\n\t\t\t    bigger[i].lnum = 0;\n\t\t\t    bigger[i].matched = FALSE;\n\t\t\t}\n\t\t\tfor (i = old_files; i < max_path_depth; i++)\n\t\t\t    bigger[i + max_path_depth] = files[i];\n\t\t\told_files += max_path_depth;\n\t\t\tmax_path_depth *= 2;\n\t\t\tvim_free(files);\n\t\t\tfiles = bigger;\n\t\t    }\n\t\t}\n\t\tif ((files[depth + 1].fp = mch_fopen((char *)new_fname, \"r\"))\n\t\t\t\t\t\t\t\t    == NULL)\n\t\t    vim_free(new_fname);\n\t\telse\n\t\t{\n\t\t    if (++depth == old_files)\n\t\t    {\n\t\t\t/*\n\t\t\t * lalloc() for 'bigger' must have failed above.  We\n\t\t\t * will forget one of our already visited files now.\n\t\t\t */\n\t\t\tvim_free(files[old_files].name);\n\t\t\t++old_files;\n\t\t    }\n\t\t    files[depth].name = curr_fname = new_fname;\n\t\t    files[depth].lnum = 0;\n\t\t    files[depth].matched = FALSE;\n\t\t    if (action == ACTION_EXPAND)\n\t\t    {\n\t\t\tmsg_hist_off = TRUE;\t// reset in msg_trunc_attr()\n\t\t\tvim_snprintf((char*)IObuff, IOSIZE,\n\t\t\t\t_(\"Scanning included file: %s\"),\n\t\t\t\t(char *)new_fname);\n\t\t\tmsg_trunc_attr((char *)IObuff, TRUE, HL_ATTR(HLF_R));\n\t\t    }\n\t\t    else if (p_verbose >= 5)\n\t\t    {\n\t\t\tverbose_enter();\n\t\t\tsmsg(_(\"Searching included file %s\"),\n\t\t\t\t\t\t\t   (char *)new_fname);\n\t\t\tverbose_leave();\n\t\t    }\n\n\t\t}\n\t    }\n\t}\n\telse\n\t{\n\t    /*\n\t     * Check if the line is a define (type == FIND_DEFINE)\n\t     */\n\t    p = line;\nsearch_line:\n\t    define_matched = FALSE;\n\t    if (def_regmatch.regprog != NULL\n\t\t\t      && vim_regexec(&def_regmatch, line, (colnr_T)0))\n\t    {\n\t\t/*\n\t\t * Pattern must be first identifier after 'define', so skip\n\t\t * to that position before checking for match of pattern.  Also\n\t\t * don't let it match beyond the end of this identifier.\n\t\t */\n\t\tp = def_regmatch.endp[0];\n\t\twhile (*p && !vim_iswordc(*p))\n\t\t    p++;\n\t\tdefine_matched = TRUE;\n\t    }\n\n\t    /*\n\t     * Look for a match.  Don't do this if we are looking for a\n\t     * define and this line didn't match define_prog above.\n\t     */\n\t    if (def_regmatch.regprog == NULL || define_matched)\n\t    {\n\t\tif (define_matched || compl_status_sol())\n\t\t{\n\t\t    // compare the first \"len\" chars from \"ptr\"\n\t\t    startp = skipwhite(p);\n\t\t    if (p_ic)\n\t\t\tmatched = !MB_STRNICMP(startp, ptr, len);\n\t\t    else\n\t\t\tmatched = !STRNCMP(startp, ptr, len);\n\t\t    if (matched && define_matched && whole\n\t\t\t\t\t\t  && vim_iswordc(startp[len]))\n\t\t\tmatched = FALSE;\n\t\t}\n\t\telse if (regmatch.regprog != NULL\n\t\t\t && vim_regexec(&regmatch, line, (colnr_T)(p - line)))\n\t\t{\n\t\t    matched = TRUE;\n\t\t    startp = regmatch.startp[0];\n\t\t    /*\n\t\t     * Check if the line is not a comment line (unless we are\n\t\t     * looking for a define).  A line starting with \"# define\"\n\t\t     * is not considered to be a comment line.\n\t\t     */\n\t\t    if (!define_matched && skip_comments)\n\t\t    {\n\t\t\tif ((*line != '#' ||\n\t\t\t\tSTRNCMP(skipwhite(line + 1), \"define\", 6) != 0)\n\t\t\t\t&& get_leader_len(line, NULL, FALSE, TRUE))\n\t\t\t    matched = FALSE;\n\n\t\t\t/*\n\t\t\t * Also check for a \"/ *\" or \"/ /\" before the match.\n\t\t\t * Skips lines like \"int backwards;  / * normal index\n\t\t\t * * /\" when looking for \"normal\".\n\t\t\t * Note: Doesn't skip \"/ *\" in comments.\n\t\t\t */\n\t\t\tp = skipwhite(line);\n\t\t\tif (matched\n\t\t\t\t|| (p[0] == '/' && p[1] == '*') || p[0] == '*')\n\t\t\t    for (p = line; *p && p < startp; ++p)\n\t\t\t    {\n\t\t\t\tif (matched\n\t\t\t\t\t&& p[0] == '/'\n\t\t\t\t\t&& (p[1] == '*' || p[1] == '/'))\n\t\t\t\t{\n\t\t\t\t    matched = FALSE;\n\t\t\t\t    // After \"//\" all text is comment\n\t\t\t\t    if (p[1] == '/')\n\t\t\t\t\tbreak;\n\t\t\t\t    ++p;\n\t\t\t\t}\n\t\t\t\telse if (!matched && p[0] == '*' && p[1] == '/')\n\t\t\t\t{\n\t\t\t\t    // Can find match after \"* /\".\n\t\t\t\t    matched = TRUE;\n\t\t\t\t    ++p;\n\t\t\t\t}\n\t\t\t    }\n\t\t    }\n\t\t}\n\t    }\n\t}\n\tif (matched)\n\t{\n\t    if (action == ACTION_EXPAND)\n\t    {\n\t\tint\tcont_s_ipos = FALSE;\n\t\tint\tadd_r;\n\t\tchar_u\t*aux;\n\n\t\tif (depth == -1 && lnum == curwin->w_cursor.lnum)\n\t\t    break;\n\t\tfound = TRUE;\n\t\taux = p = startp;\n\t\tif (compl_status_adding())\n\t\t{\n\t\t    p += ins_compl_len();\n\t\t    if (vim_iswordp(p))\n\t\t\tgoto exit_matched;\n\t\t    p = find_word_start(p);\n\t\t}\n\t\tp = find_word_end(p);\n\t\ti = (int)(p - aux);\n\n\t\tif (compl_status_adding() && i == ins_compl_len())\n\t\t{\n\t\t    // IOSIZE > compl_length, so the STRNCPY works\n\t\t    STRNCPY(IObuff, aux, i);\n\n\t\t    // Get the next line: when \"depth\" < 0  from the current\n\t\t    // buffer, otherwise from the included file.  Jump to\n\t\t    // exit_matched when past the last line.\n\t\t    if (depth < 0)\n\t\t    {\n\t\t\tif (lnum >= end_lnum)\n\t\t\t    goto exit_matched;\n\t\t\tline = ml_get(++lnum);\n\t\t    }\n\t\t    else if (vim_fgets(line = file_line,\n\t\t\t\t\t\t      LSIZE, files[depth].fp))\n\t\t\tgoto exit_matched;\n\n\t\t    // we read a line, set \"already\" to check this \"line\" later\n\t\t    // if depth >= 0 we'll increase files[depth].lnum far\n\t\t    // below  -- Acevedo\n\t\t    already = aux = p = skipwhite(line);\n\t\t    p = find_word_start(p);\n\t\t    p = find_word_end(p);\n\t\t    if (p > aux)\n\t\t    {\n\t\t\tif (*aux != ')' && IObuff[i-1] != TAB)\n\t\t\t{\n\t\t\t    if (IObuff[i-1] != ' ')\n\t\t\t\tIObuff[i++] = ' ';\n\t\t\t    // IObuf =~ \"\\(\\k\\|\\i\\).* \", thus i >= 2\n\t\t\t    if (p_js\n\t\t\t\t&& (IObuff[i-2] == '.'\n\t\t\t\t    || (vim_strchr(p_cpo, CPO_JOINSP) == NULL\n\t\t\t\t\t&& (IObuff[i-2] == '?'\n\t\t\t\t\t    || IObuff[i-2] == '!'))))\n\t\t\t\tIObuff[i++] = ' ';\n\t\t\t}\n\t\t\t// copy as much as possible of the new word\n\t\t\tif (p - aux >= IOSIZE - i)\n\t\t\t    p = aux + IOSIZE - i - 1;\n\t\t\tSTRNCPY(IObuff + i, aux, p - aux);\n\t\t\ti += (int)(p - aux);\n\t\t\tcont_s_ipos = TRUE;\n\t\t    }\n\t\t    IObuff[i] = NUL;\n\t\t    aux = IObuff;\n\n\t\t    if (i == ins_compl_len())\n\t\t\tgoto exit_matched;\n\t\t}\n\n\t\tadd_r = ins_compl_add_infercase(aux, i, p_ic,\n\t\t\tcurr_fname == curbuf->b_fname ? NULL : curr_fname,\n\t\t\tdir, cont_s_ipos);\n\t\tif (add_r == OK)\n\t\t    // if dir was BACKWARD then honor it just once\n\t\t    dir = FORWARD;\n\t\telse if (add_r == FAIL)\n\t\t    break;\n\t    }\n\t    else if (action == ACTION_SHOW_ALL)\n\t    {\n\t\tfound = TRUE;\n\t\tif (!did_show)\n\t\t    gotocmdline(TRUE);\t\t// cursor at status line\n\t\tif (curr_fname != prev_fname)\n\t\t{\n\t\t    if (did_show)\n\t\t\tmsg_putchar('\\n');\t// cursor below last one\n\t\t    if (!got_int)\t\t// don't display if 'q' typed\n\t\t\t\t\t\t// at \"--more--\" message\n\t\t\tmsg_home_replace_hl(curr_fname);\n\t\t    prev_fname = curr_fname;\n\t\t}\n\t\tdid_show = TRUE;\n\t\tif (!got_int)\n\t\t    show_pat_in_path(line, type, TRUE, action,\n\t\t\t    (depth == -1) ? NULL : files[depth].fp,\n\t\t\t    (depth == -1) ? &lnum : &files[depth].lnum,\n\t\t\t    match_count++);\n\n\t\t// Set matched flag for this file and all the ones that\n\t\t// include it\n\t\tfor (i = 0; i <= depth; ++i)\n\t\t    files[i].matched = TRUE;\n\t    }\n\t    else if (--count <= 0)\n\t    {\n\t\tfound = TRUE;\n\t\tif (depth == -1 && lnum == curwin->w_cursor.lnum\n#if defined(FEAT_QUICKFIX)\n\t\t\t\t\t\t      && g_do_tagpreview == 0\n#endif\n\t\t\t\t\t\t      )\n\t\t    emsg(_(e_match_is_on_current_line));\n\t\telse if (action == ACTION_SHOW)\n\t\t{\n\t\t    show_pat_in_path(line, type, did_show, action,\n\t\t\t(depth == -1) ? NULL : files[depth].fp,\n\t\t\t(depth == -1) ? &lnum : &files[depth].lnum, 1L);\n\t\t    did_show = TRUE;\n\t\t}\n\t\telse\n\t\t{\n#ifdef FEAT_GUI\n\t\t    need_mouse_correct = TRUE;\n#endif\n#if defined(FEAT_QUICKFIX)\n\t\t    // \":psearch\" uses the preview window\n\t\t    if (g_do_tagpreview != 0)\n\t\t    {\n\t\t\tcurwin_save = curwin;\n\t\t\tprepare_tagpreview(TRUE, TRUE, FALSE);\n\t\t    }\n#endif\n\t\t    if (action == ACTION_SPLIT)\n\t\t    {\n\t\t\tif (win_split(0, 0) == FAIL)\n\t\t\t    break;\n\t\t\tRESET_BINDING(curwin);\n\t\t    }\n\t\t    if (depth == -1)\n\t\t    {\n\t\t\t// match in current file\n#if defined(FEAT_QUICKFIX)\n\t\t\tif (g_do_tagpreview != 0)\n\t\t\t{\n\t\t\t    if (!win_valid(curwin_save))\n\t\t\t\tbreak;\n\t\t\t    if (!GETFILE_SUCCESS(getfile(\n\t\t\t\t\t   curwin_save->w_buffer->b_fnum, NULL,\n\t\t\t\t\t\t     NULL, TRUE, lnum, FALSE)))\n\t\t\t\tbreak;\t// failed to jump to file\n\t\t\t}\n\t\t\telse\n#endif\n\t\t\t    setpcmark();\n\t\t\tcurwin->w_cursor.lnum = lnum;\n\t\t\tcheck_cursor();\n\t\t    }\n\t\t    else\n\t\t    {\n\t\t\tif (!GETFILE_SUCCESS(getfile(\n\t\t\t\t\t0, files[depth].name, NULL, TRUE,\n\t\t\t\t\t\t    files[depth].lnum, FALSE)))\n\t\t\t    break;\t// failed to jump to file\n\t\t\t// autocommands may have changed the lnum, we don't\n\t\t\t// want that here\n\t\t\tcurwin->w_cursor.lnum = files[depth].lnum;\n\t\t    }\n\t\t}\n\t\tif (action != ACTION_SHOW)\n\t\t{\n\t\t    curwin->w_cursor.col = (colnr_T)(startp - line);\n\t\t    curwin->w_set_curswant = TRUE;\n\t\t}\n\n#if defined(FEAT_QUICKFIX)\n\t\tif (g_do_tagpreview != 0\n\t\t\t   && curwin != curwin_save && win_valid(curwin_save))\n\t\t{\n\t\t    // Return cursor to where we were\n\t\t    validate_cursor();\n\t\t    redraw_later(VALID);\n\t\t    win_enter(curwin_save, TRUE);\n\t\t}\n# ifdef FEAT_PROP_POPUP\n\t\telse if (WIN_IS_POPUP(curwin))\n\t\t    // can't keep focus in popup window\n\t\t    win_enter(firstwin, TRUE);\n# endif\n#endif\n\t\tbreak;\n\t    }\nexit_matched:\n\t    matched = FALSE;\n\t    // look for other matches in the rest of the line if we\n\t    // are not at the end of it already\n\t    if (def_regmatch.regprog == NULL\n\t\t    && action == ACTION_EXPAND\n\t\t    && !compl_status_sol()\n\t\t    && *startp != NUL\n\t\t    && *(p = startp + mb_ptr2len(startp)) != NUL)\n\t\tgoto search_line;\n\t}\n\tline_breakcheck();\n\tif (action == ACTION_EXPAND)\n\t    ins_compl_check_keys(30, FALSE);\n\tif (got_int || ins_compl_interrupted())\n\t    break;\n\n\t/*\n\t * Read the next line.  When reading an included file and encountering\n\t * end-of-file, close the file and continue in the file that included\n\t * it.\n\t */\n\twhile (depth >= 0 && !already\n\t\t&& vim_fgets(line = file_line, LSIZE, files[depth].fp))\n\t{\n\t    fclose(files[depth].fp);\n\t    --old_files;\n\t    files[old_files].name = files[depth].name;\n\t    files[old_files].matched = files[depth].matched;\n\t    --depth;\n\t    curr_fname = (depth == -1) ? curbuf->b_fname\n\t\t\t\t       : files[depth].name;\n\t    if (depth < depth_displayed)\n\t\tdepth_displayed = depth;\n\t}\n\tif (depth >= 0)\t\t// we could read the line\n\t{\n\t    files[depth].lnum++;\n\t    // Remove any CR and LF from the line.\n\t    i = (int)STRLEN(line);\n\t    if (i > 0 && line[i - 1] == '\\n')\n\t\tline[--i] = NUL;\n\t    if (i > 0 && line[i - 1] == '\\r')\n\t\tline[--i] = NUL;\n\t}\n\telse if (!already)\n\t{\n\t    if (++lnum > end_lnum)\n\t\tbreak;\n\t    line = ml_get(lnum);\n\t}\n\talready = NULL;\n    }\n    // End of big for (;;) loop.\n\n    // Close any files that are still open.\n    for (i = 0; i <= depth; i++)\n    {\n\tfclose(files[i].fp);\n\tvim_free(files[i].name);\n    }\n    for (i = old_files; i < max_path_depth; i++)\n\tvim_free(files[i].name);\n    vim_free(files);\n\n    if (type == CHECK_PATH)\n    {\n\tif (!did_show)\n\t{\n\t    if (action != ACTION_SHOW_ALL)\n\t\tmsg(_(\"All included files were found\"));\n\t    else\n\t\tmsg(_(\"No included files\"));\n\t}\n    }\n    else if (!found && action != ACTION_EXPAND)\n    {\n\tif (got_int || ins_compl_interrupted())\n\t    emsg(_(e_interrupted));\n\telse if (type == FIND_DEFINE)\n\t    emsg(_(e_couldnt_find_definition));\n\telse\n\t    emsg(_(e_couldnt_find_pattern));\n    }\n    if (action == ACTION_SHOW || action == ACTION_SHOW_ALL)\n\tmsg_end();\n\nfpip_end:\n    vim_free(file_line);\n    vim_regfree(regmatch.regprog);\n    vim_regfree(incl_regmatch.regprog);\n    vim_regfree(def_regmatch.regprog);\n}",
        "func_hash": 123923862521809134964983633516065480238,
        "file_name": "search.c",
        "file_hash": 229512534202460810065416633781657256150,
        "cwe": [
            "CWE-416"
        ],
        "cve": "CVE-2022-1968",
        "cve_desc": "Use After Free in GitHub repository vim/vim prior to 8.2.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-1968",
        "func_name": "find_pattern_in_path",
        "diff": [
            "diff --git a/src/search.c b/src/search.c\nindex ea72ec7fb9d786..35dc89b8fe4acb 100644\n--- a/src/search.c\n+++ b/src/search.c\n@@ -3305,6 +3305,21 @@ update_search_stat(\n }\n \n #if defined(FEAT_FIND_ID) || defined(PROTO)\n+\n+/*\n+ * Get line \"lnum\" and copy it into \"buf[LSIZE]\".\n+ * The copy is made because the regexp may make the line invalid when using a\n+ * mark.\n+ */\n+    static char_u *\n+get_line_and_copy(linenr_T lnum, char_u *buf)\n+{\n+    char_u *line = ml_get(lnum);\n+\n+    vim_strncpy(buf, line, LSIZE - 1);\n+    return buf;\n+}\n+\n /*\n  * Find identifiers or defines in included files.\n  * If p_ic && compl_status_sol() then ptr must be in lowercase.\n@@ -3409,7 +3424,7 @@ find_pattern_in_path(\n \tend_lnum = curbuf->b_ml.ml_line_count;\n     if (lnum > end_lnum)\t\t// do at least one line\n \tlnum = end_lnum;\n-    line = ml_get(lnum);\n+    line = get_line_and_copy(lnum, file_line);\n \n     for (;;)\n     {\n@@ -3738,7 +3753,7 @@ find_pattern_in_path(\n \t\t    {\n \t\t\tif (lnum >= end_lnum)\n \t\t\t    goto exit_matched;\n-\t\t\tline = ml_get(++lnum);\n+\t\t\tline = get_line_and_copy(++lnum, file_line);\n \t\t    }\n \t\t    else if (vim_fgets(line = file_line,\n \t\t\t\t\t\t      LSIZE, files[depth].fp))\n@@ -3950,7 +3965,7 @@ find_pattern_in_path(\n \t{\n \t    if (++lnum > end_lnum)\n \t\tbreak;\n-\t    line = ml_get(lnum);\n+\t    line = get_line_and_copy(lnum, file_line);\n \t}\n \talready = NULL;\n     }\ndiff --git a/src/testdir/test_tagjump.vim b/src/testdir/test_tagjump.vim\nindex aacfb9baeb56fc..060cc3b188c8e4 100644\n--- a/src/testdir/test_tagjump.vim\n+++ b/src/testdir/test_tagjump.vim\n@@ -1290,6 +1290,17 @@ func Test_inc_search()\n   close!\n endfunc\n \n+\" this was using a line from ml_get() freed by the regexp\n+func Test_isearch_copy_line()\n+  new\n+  norm o\n+  norm \u00160\n+  0norm o\n+  sil! norm bc0\n+  sil! isearch \\%')\n+  bwipe!\n+endfunc\n+\n \" Test for :dsearch, :dlist, :djump and :dsplit commands\n \" Test for [d, ]d, [D, ]D, [ CTRL-D, ] CTRL-D and CTRL-W d commands\n func Test_macro_search()\ndiff --git a/src/version.c b/src/version.c\nindex 97ca8ce5cb40af..ba8688bc55c961 100644\n--- a/src/version.c\n+++ b/src/version.c\n@@ -734,6 +734,8 @@ static char *(features[]) =\n \n static int included_patches[] =\n {   /* Add new patch number below this line */\n+/**/\n+    5050,\n /**/\n     5049,\n /**/\n"
        ],
        "func_after": []
    },
    {
        "idx": 196578,
        "project": "vim",
        "commit_id": "44db8213d38c39877d2148eff6a72f4beccfb94e",
        "project_url": "https://github.com/vim/vim",
        "commit_url": "https://github.com/vim/vim/commit/44db8213d38c39877d2148eff6a72f4beccfb94e",
        "commit_message": "patch 8.2.4219: reading before the start of the line\n\nProblem:    Reading before the start of the line.\nSolution:   Check boundary before trying to read the character.",
        "target": 1,
        "irrelevant": 1,
        "func_before": "yank_copy_line(struct block_def *bd, long y_idx, int exclude_trailing_space)\n{\n    char_u\t*pnew;\n\n    if (exclude_trailing_space)\n\tbd->endspaces = 0;\n    if ((pnew = alloc(bd->startspaces + bd->endspaces + bd->textlen + 1))\n\t\t\t\t\t\t\t\t      == NULL)\n\treturn FAIL;\n    y_current->y_array[y_idx] = pnew;\n    vim_memset(pnew, ' ', (size_t)bd->startspaces);\n    pnew += bd->startspaces;\n    mch_memmove(pnew, bd->textstart, (size_t)bd->textlen);\n    pnew += bd->textlen;\n    vim_memset(pnew, ' ', (size_t)bd->endspaces);\n    pnew += bd->endspaces;\n    if (exclude_trailing_space)\n    {\n\tint s = bd->textlen + bd->endspaces;\n\n\twhile (VIM_ISWHITE(*(bd->textstart + s - 1)) && s > 0)\n\t{\n\t    s = s - (*mb_head_off)(bd->textstart, bd->textstart + s - 1) - 1;\n\t    pnew--;\n\t}\n    }\n    *pnew = NUL;\n    return OK;\n}",
        "func_hash": 329046653104270093704788517563971777510,
        "file_name": "register.c",
        "file_hash": 197045442768005159362544298682780980387,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2022-0407",
        "cve_desc": "Heap-based Buffer Overflow in GitHub repository vim/vim prior to 8.2.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-0407",
        "func_name": "yank_copy_line",
        "diff": [
            "diff --git a/src/register.c b/src/register.c\nindex d604bae6b0debf..03f7f4ec9604ce 100644\n--- a/src/register.c\n+++ b/src/register.c\n@@ -1474,7 +1474,7 @@ yank_copy_line(struct block_def *bd, long y_idx, int exclude_trailing_space)\n     {\n \tint s = bd->textlen + bd->endspaces;\n \n-\twhile (VIM_ISWHITE(*(bd->textstart + s - 1)) && s > 0)\n+\twhile (s > 0 && VIM_ISWHITE(*(bd->textstart + s - 1)))\n \t{\n \t    s = s - (*mb_head_off)(bd->textstart, bd->textstart + s - 1) - 1;\n \t    pnew--;\ndiff --git a/src/testdir/test_visual.vim b/src/testdir/test_visual.vim\nindex b2beda08d0aa84..af54615c48a104 100644\n--- a/src/testdir/test_visual.vim\n+++ b/src/testdir/test_visual.vim\n@@ -1247,6 +1247,13 @@ func Test_visual_put_blockedit_zy_and_zp()\n   bw!\n endfunc\n \n+func Test_visual_block_yank_zy()\n+  new\n+  \" this was reading before the start of the line\n+  exe \"norm o\\<C-T>\\<Esc>\\<C-V>zy\"\n+  bwipe!\n+endfunc\n+\n func Test_visual_block_with_virtualedit()\n   CheckScreendump\n \ndiff --git a/src/version.c b/src/version.c\nindex 9dcf34928f8def..a3efb046bdf583 100644\n--- a/src/version.c\n+++ b/src/version.c\n@@ -750,6 +750,8 @@ static char *(features[]) =\n \n static int included_patches[] =\n {   /* Add new patch number below this line */\n+/**/\n+    4219,\n /**/\n     4218,\n /**/\n"
        ],
        "func_after": []
    },
    {
        "idx": 197808,
        "project": "mruby",
        "commit_id": "47068ae07a5fa3aa9a1879cdfe98a9ce0f339299",
        "project_url": "https://github.com/mruby/mruby",
        "commit_url": "https://github.com/mruby/mruby/commit/47068ae07a5fa3aa9a1879cdfe98a9ce0f339299",
        "commit_message": "vm.c: packed arguments length may be zero for `send` method.",
        "target": 1,
        "irrelevant": 1,
        "func_before": "mrb_f_send(mrb_state *mrb, mrb_value self)\n{\n  mrb_sym name;\n  mrb_value block, *regs;\n  mrb_method_t m;\n  struct RClass *c;\n  mrb_callinfo *ci = mrb->c->ci;\n  int n = ci->n;\n\n  if (ci->cci > CINFO_NONE) {\n  funcall:;\n    const mrb_value *argv;\n    mrb_int argc;\n    mrb_get_args(mrb, \"n*&\", &name, &argv, &argc, &block);\n    return mrb_funcall_with_block(mrb, self, name, argc, argv, block);\n  }\n\n  regs = mrb->c->ci->stack+1;\n\n  if (n == 0) {\n    mrb_argnum_error(mrb, 0, 1, -1);\n  }\n  else if (n == 15) {\n    name = mrb_obj_to_sym(mrb, RARRAY_PTR(regs[0])[0]);\n  }\n  else {\n    name = mrb_obj_to_sym(mrb, regs[0]);\n  }\n\n  c = mrb_class(mrb, self);\n  m = mrb_method_search_vm(mrb, &c, name);\n  if (MRB_METHOD_UNDEF_P(m)) {            /* call method_mising */\n    goto funcall;\n  }\n\n  ci->mid = name;\n  ci->u.target_class = c;\n  /* remove first symbol from arguments */\n  if (n == 15) {     /* variable length arguments */\n    regs[0] = mrb_ary_subseq(mrb, regs[0], 1, RARRAY_LEN(regs[0]) - 1);\n  }\n  else { /* n > 0 */\n    for (int i=0; i<n; i++) {\n      regs[i] = regs[i+1];\n    }\n    regs[n] = regs[n+1];        /* copy kdict or block */\n    if (ci->nk > 0) {\n      regs[n+1] = regs[n+2];    /* copy block */\n    }\n    ci->n--;\n  }\n\n  if (MRB_METHOD_CFUNC_P(m)) {\n    if (MRB_METHOD_NOARG_P(m)) {\n      check_method_noarg(mrb, ci);\n    }\n\n    if (MRB_METHOD_PROC_P(m)) {\n      mrb_vm_ci_proc_set(ci, MRB_METHOD_PROC(m));\n    }\n    return MRB_METHOD_CFUNC(m)(mrb, self);\n  }\n  return exec_irep(mrb, self, MRB_METHOD_PROC(m));\n}",
        "func_hash": 242172053441945825561730661416191930474,
        "file_name": "vm.c",
        "file_hash": 295571119031657653721791727608298010275,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2022-0631",
        "cve_desc": "Heap-based Buffer Overflow in Homebrew mruby prior to 3.2.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-0631",
        "func_name": "mrb_f_send",
        "diff": [
            "diff --git a/src/vm.c b/src/vm.c\nindex 9cb50847f2..aa5569503e 100644\n--- a/src/vm.c\n+++ b/src/vm.c\n@@ -689,9 +689,11 @@ mrb_f_send(mrb_state *mrb, mrb_value self)\n   regs = mrb->c->ci->stack+1;\n \n   if (n == 0) {\n+  argnum_error:\n     mrb_argnum_error(mrb, 0, 1, -1);\n   }\n   else if (n == 15) {\n+    if (RARRAY_LEN(regs[0]) == 0) goto argnum_error;\n     name = mrb_obj_to_sym(mrb, RARRAY_PTR(regs[0])[0]);\n   }\n   else {\n"
        ],
        "func_after": []
    },
    {
        "idx": 197824,
        "project": "gpac",
        "commit_id": "c535bad50d5812d27ee5b22b54371bddec411514",
        "project_url": "https://github.com/gpac/gpac",
        "commit_url": "https://github.com/gpac/gpac/commit/c535bad50d5812d27ee5b22b54371bddec411514",
        "commit_message": "fixed #2194",
        "target": 1,
        "irrelevant": 1,
        "func_before": "static GF_Err BM_ParseGlobalQuantizer(GF_BifsDecoder *codec, GF_BitStream *bs, GF_List *com_list)\n{\n\tGF_Node *node;\n\tGF_Command *com;\n\tGF_CommandField *inf;\n\tnode = gf_bifs_dec_node(codec, bs, NDT_SFWorldNode);\n\tif (!node) return GF_NON_COMPLIANT_BITSTREAM;\n\n\t/*reset global QP*/\n\tif (codec->scenegraph->global_qp) {\n\t\tgf_node_unregister(codec->scenegraph->global_qp, NULL);\n\t}\n\tcodec->ActiveQP = NULL;\n\tcodec->scenegraph->global_qp = NULL;\n\n\tif (gf_node_get_tag(node) != TAG_MPEG4_QuantizationParameter) {\n\t\tgf_node_unregister(node, NULL);\n\t\treturn GF_NON_COMPLIANT_BITSTREAM;\n\t}\n\n\t/*register global QP*/\n\tcodec->ActiveQP = (M_QuantizationParameter *) node;\n\tcodec->ActiveQP->isLocal = 0;\n\tcodec->scenegraph->global_qp = node;\n\n\t/*register TWICE: once for the command, and for the scenegraph globalQP*/\n\tnode->sgprivate->num_instances = 2;\n\n\tcom = gf_sg_command_new(codec->current_graph, GF_SG_GLOBAL_QUANTIZER);\n\tinf = gf_sg_command_field_new(com);\n\tinf->new_node = node;\n\tinf->field_ptr = &inf->new_node;\n\tinf->fieldType = GF_SG_VRML_SFNODE;\n\tgf_list_add(com_list, com);\n\treturn GF_OK;\n}",
        "func_hash": 227330749119032349040137878791232526501,
        "file_name": "memory_decoder.c",
        "file_hash": 144617483436873036933597599292760665537,
        "cwe": [
            "CWE-416"
        ],
        "cve": "CVE-2022-1795",
        "cve_desc": "Use After Free in GitHub repository gpac/gpac prior to v2.1.0-DEV.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-1795",
        "func_name": "BM_ParseGlobalQuantizer",
        "diff": [
            "diff --git a/src/bifs/memory_decoder.c b/src/bifs/memory_decoder.c\nindex 74d635750d..1fc8c99638 100644\n--- a/src/bifs/memory_decoder.c\n+++ b/src/bifs/memory_decoder.c\n@@ -178,7 +178,12 @@ static GF_Err BM_ParseGlobalQuantizer(GF_BifsDecoder *codec, GF_BitStream *bs, G\n \tcodec->scenegraph->global_qp = NULL;\n \n \tif (gf_node_get_tag(node) != TAG_MPEG4_QuantizationParameter) {\n-\t\tgf_node_unregister(node, NULL);\n+\t\t//if node was just created (num_instances == 0), unregister\n+\t\t//otherwise (USE node) don't do anything\n+\t\tif (!node->sgprivate->num_instances) {\n+\t\t\tnode->sgprivate->num_instances = 1;\n+\t\t\tgf_node_unregister(node, NULL);\n+\t\t}\n \t\treturn GF_NON_COMPLIANT_BITSTREAM;\n \t}\n \n@@ -188,7 +193,8 @@ static GF_Err BM_ParseGlobalQuantizer(GF_BifsDecoder *codec, GF_BitStream *bs, G\n \tcodec->scenegraph->global_qp = node;\n \n \t/*register TWICE: once for the command, and for the scenegraph globalQP*/\n-\tnode->sgprivate->num_instances = 2;\n+\tgf_node_unregister(node, NULL);\n+\tgf_node_unregister(node, NULL);\n \n \tcom = gf_sg_command_new(codec->current_graph, GF_SG_GLOBAL_QUANTIZER);\n \tinf = gf_sg_command_field_new(com);\n"
        ],
        "func_after": []
    },
    {
        "idx": 197826,
        "project": "tensorflow",
        "commit_id": "7731e8dfbe4a56773be5dc94d631611211156659",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/7731e8dfbe4a56773be5dc94d631611211156659",
        "commit_message": "Don't constant-fold DT_RESOURCE constants.\n\nPiperOrigin-RevId: 391803952\nChange-Id: I0ea3ec31d3e7dfda0f03b4027a237f08d00a3091",
        "target": 1,
        "irrelevant": 0,
        "func_before": "bool IsConstantFoldable(\n    const Node* n,\n    const std::unordered_map<string, std::vector<PartialTensorShape>>*\n        shape_map,\n    const std::function<bool(const Node*)>& consider,\n    int64_t max_constant_size_in_bytes,\n    std::unordered_map<const Node*, std::vector<Tensor>>*\n        shape_replacement_map) {\n  if (n->IsConstant()) {\n    return true;\n  }\n  if (MaybeReplaceShapeOp(n, shape_map, shape_replacement_map)) {\n    return true;\n  }\n  if (n->op_def().is_stateful()) {\n    return false;\n  }\n  if (consider && !consider(n)) {\n    return false;\n  }\n  if (shape_map != nullptr) {\n    // We can skip the node if an output is known to be oversized.\n    auto shape_it = shape_map->find(n->name());\n    if (shape_it != shape_map->end()) {\n      for (int64_t i = 0; i < shape_it->second.size(); ++i) {\n        const auto& out_shape = shape_it->second[i];\n        if (out_shape.IsFullyDefined() &&\n            out_shape.num_elements() * DataTypeSize(n->output_type(i)) >\n                max_constant_size_in_bytes) {\n          return false;\n        }\n      }\n    }\n  }\n  if (n->IsControlFlow() || n->IsSend() || n->IsRecv()) {\n    return false;\n  }\n  // TODO(yuanbyu): For now disable these session handle operations.\n  if (n->IsGetSessionHandle() || n->IsGetSessionTensor() ||\n      n->IsDeleteSessionTensor()) {\n    return false;\n  }\n  if (n->IsSource()) {\n    return false;\n  }\n  if (n->IsSink()) {\n    return false;\n  }\n  if (n->IsFakeParam()) {\n    return false;\n  }\n  // Since constant-folding runs on the CPU, do not attempt to constant-fold\n  // operators that have no CPU kernel. Also implies that we will not\n  // constant-fold functions.\n  // TODO(phawkins): allow constant-folding for functions; functions may\n  // be arbitrarily expensive to execute.\n  if (!KernelDefAvailable(DeviceType(DEVICE_CPU), n->def())) {\n    return false;\n  }\n  // Do not constant fold nodes which will be allocated by ScopedAllocator.\n  // This is because the constant-folding graph will not contain the\n  // `_ScopedAllocator` node, and that is necessary to be able to run a node\n  // that will use this allocator.\n  if (n->attrs().Find(kScopedAllocatorAttrName) != nullptr) {\n    VLOG(2) << \"Skip node [\" << n->DebugString()\n            << \"] for constant folding due to scoped allocator\";\n    return false;\n  }\n  return true;\n}",
        "func_hash": 116289485656616917830363077368123441202,
        "file_name": "constant_folding.cc",
        "file_hash": 46768745532828534791253050765124097339,
        "cwe": [
            "CWE-824"
        ],
        "cve": "CVE-2021-41204",
        "cve_desc": "TensorFlow is an open source platform for machine learning. In affected versions during TensorFlow's Grappler optimizer phase, constant folding might attempt to deep copy a resource tensor. This results in a segfault, as these tensors are supposed to not change. The fix will be included in TensorFlow 2.7.0. We will also cherrypick this commit on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-41204",
        "func_name": "IsConstantFoldable",
        "diff": [
            "diff --git a/tensorflow/core/common_runtime/constant_folding.cc b/tensorflow/core/common_runtime/constant_folding.cc\nindex 8367e5ff6aff34..ca75dc9f19160a 100644\n--- a/tensorflow/core/common_runtime/constant_folding.cc\n+++ b/tensorflow/core/common_runtime/constant_folding.cc\n@@ -30,6 +30,7 @@ limitations under the License.\n #include \"tensorflow/core/framework/log_memory.h\"\n #include \"tensorflow/core/framework/op_kernel.h\"\n #include \"tensorflow/core/framework/types.h\"\n+#include \"tensorflow/core/framework/types.pb.h\"\n #include \"tensorflow/core/graph/algorithm.h\"\n #include \"tensorflow/core/graph/node_builder.h\"\n #include \"tensorflow/core/graph/subgraph.h\"\n@@ -223,7 +224,8 @@ bool IsConstantFoldable(\n     std::unordered_map<const Node*, std::vector<Tensor>>*\n         shape_replacement_map) {\n   if (n->IsConstant()) {\n-    return true;\n+    // Skip constant folding resources as they cannot be deep copied.\n+    return n->output_type(0) != DT_RESOURCE;\n   }\n   if (MaybeReplaceShapeOp(n, shape_map, shape_replacement_map)) {\n     return true;\n"
        ],
        "func_after": []
    },
    {
        "idx": 197893,
        "project": "tensorflow",
        "commit_id": "eb921122119a6b6e470ee98b89e65d721663179d",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/eb921122119a6b6e470ee98b89e65d721663179d",
        "commit_message": "Prevent heap OOB read in TFLite's `gather.cc`.\n\nPassing negative indices is illegal but there was a missing check so that resulted in OOB accesses.\n\nPiperOrigin-RevId: 387231300\nChange-Id: I3111b54b2f232638d795be17efc46abe4ede6bf8",
        "target": 1,
        "irrelevant": 1,
        "func_before": "TfLiteStatus Gather(const TfLiteGatherParams& params, const TfLiteTensor* input,\n                    const TfLiteTensor* positions, TfLiteTensor* output) {\n  tflite::GatherParams op_params;\n  op_params.axis = params.axis;\n  op_params.batch_dims = params.batch_dims;\n  optimized_ops::Gather(op_params, GetTensorShape(input),\n                        GetTensorData<InputT>(input), GetTensorShape(positions),\n                        GetTensorData<PositionsT>(positions),\n                        GetTensorShape(output), GetTensorData<InputT>(output));\n  return kTfLiteOk;\n}",
        "func_hash": 291153190876322119376469189416083053275,
        "file_name": "gather.cc",
        "file_hash": 109151045550446368977897795663338855851,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2021-37687",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions TFLite's [`GatherNd` implementation](https://github.com/tensorflow/tensorflow/blob/149562d49faa709ea80df1d99fc41d005b81082a/tensorflow/lite/kernels/gather_nd.cc#L124) does not support negative indices but there are no checks for this situation. Hence, an attacker can read arbitrary data from the heap by carefully crafting a model with negative values in `indices`. Similar issue exists in [`Gather` implementation](https://github.com/tensorflow/tensorflow/blob/149562d49faa709ea80df1d99fc41d005b81082a/tensorflow/lite/kernels/gather.cc). We have patched the issue in GitHub commits bb6a0383ed553c286f87ca88c207f6774d5c4a8f and eb921122119a6b6e470ee98b89e65d721663179d. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37687",
        "func_name": "Gather",
        "diff": [
            "diff --git a/tensorflow/lite/kernels/gather.cc b/tensorflow/lite/kernels/gather.cc\nindex 9fe94821230c00..bdc2139d0fe7a5 100644\n--- a/tensorflow/lite/kernels/gather.cc\n+++ b/tensorflow/lite/kernels/gather.cc\n@@ -117,8 +117,20 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n }\n \n template <typename InputT, typename PositionsT>\n-TfLiteStatus Gather(const TfLiteGatherParams& params, const TfLiteTensor* input,\n-                    const TfLiteTensor* positions, TfLiteTensor* output) {\n+TfLiteStatus Gather(TfLiteContext* context, const TfLiteGatherParams& params,\n+                    const TfLiteTensor* input, const TfLiteTensor* positions,\n+                    TfLiteTensor* output) {\n+  const PositionsT* indexes = GetTensorData<PositionsT>(positions);\n+  bool indices_has_only_positive_elements = true;\n+  const size_t num_indices = positions->bytes / sizeof(PositionsT);\n+  for (size_t i = 0; i < num_indices; i++) {\n+    if (indexes[i] < 0) {\n+      indices_has_only_positive_elements = false;\n+      break;\n+    }\n+  }\n+  TF_LITE_ENSURE(context, indices_has_only_positive_elements);\n+\n   tflite::GatherParams op_params;\n   op_params.axis = params.axis;\n   op_params.batch_dims = params.batch_dims;\n@@ -134,7 +146,18 @@ TfLiteStatus GatherStrings(TfLiteContext* context, const TfLiteTensor* input,\n                            const TfLiteTensor* positions,\n                            TfLiteTensor* output) {\n   DynamicBuffer buffer;\n+\n   const PositionT* indexes = GetTensorData<PositionT>(positions);\n+  bool indices_has_only_positive_elements = true;\n+  const size_t num_indices = positions->bytes / sizeof(PositionT);\n+  for (size_t i = 0; i < num_indices; i++) {\n+    if (indexes[i] < 0) {\n+      indices_has_only_positive_elements = false;\n+      break;\n+    }\n+  }\n+  TF_LITE_ENSURE(context, indices_has_only_positive_elements);\n+\n   const PositionT num_strings = GetStringCount(input);\n   const int num_indexes = NumElements(positions);\n \n@@ -163,19 +186,26 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   if (positions->type == kTfLiteInt32) {\n     switch (input->type) {\n       case kTfLiteFloat32:\n-        return Gather<float, int32_t>(*params, input, positions, output);\n+        return Gather<float, int32_t>(context, *params, input, positions,\n+                                      output);\n       case kTfLiteUInt8:\n-        return Gather<uint8_t, int32_t>(*params, input, positions, output);\n+        return Gather<uint8_t, int32_t>(context, *params, input, positions,\n+                                        output);\n       case kTfLiteInt8:\n-        return Gather<int8_t, int32_t>(*params, input, positions, output);\n+        return Gather<int8_t, int32_t>(context, *params, input, positions,\n+                                       output);\n       case kTfLiteInt16:\n-        return Gather<int16_t, int32_t>(*params, input, positions, output);\n+        return Gather<int16_t, int32_t>(context, *params, input, positions,\n+                                        output);\n       case kTfLiteInt32:\n-        return Gather<int32_t, int32_t>(*params, input, positions, output);\n+        return Gather<int32_t, int32_t>(context, *params, input, positions,\n+                                        output);\n       case kTfLiteInt64:\n-        return Gather<int64_t, int32_t>(*params, input, positions, output);\n+        return Gather<int64_t, int32_t>(context, *params, input, positions,\n+                                        output);\n       case kTfLiteBool:\n-        return Gather<bool, int32_t>(*params, input, positions, output);\n+        return Gather<bool, int32_t>(context, *params, input, positions,\n+                                     output);\n       case kTfLiteString:\n         return GatherStrings<int32_t>(context, input, positions, output);\n       default:\n@@ -187,19 +217,26 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   if (positions->type == kTfLiteInt64) {\n     switch (input->type) {\n       case kTfLiteFloat32:\n-        return Gather<float, int64_t>(*params, input, positions, output);\n+        return Gather<float, int64_t>(context, *params, input, positions,\n+                                      output);\n       case kTfLiteUInt8:\n-        return Gather<uint8_t, int64_t>(*params, input, positions, output);\n+        return Gather<uint8_t, int64_t>(context, *params, input, positions,\n+                                        output);\n       case kTfLiteInt8:\n-        return Gather<int8_t, int64_t>(*params, input, positions, output);\n+        return Gather<int8_t, int64_t>(context, *params, input, positions,\n+                                       output);\n       case kTfLiteInt16:\n-        return Gather<int16_t, int64_t>(*params, input, positions, output);\n+        return Gather<int16_t, int64_t>(context, *params, input, positions,\n+                                        output);\n       case kTfLiteInt32:\n-        return Gather<int32_t, int64_t>(*params, input, positions, output);\n+        return Gather<int32_t, int64_t>(context, *params, input, positions,\n+                                        output);\n       case kTfLiteInt64:\n-        return Gather<int64_t, int64_t>(*params, input, positions, output);\n+        return Gather<int64_t, int64_t>(context, *params, input, positions,\n+                                        output);\n       case kTfLiteBool:\n-        return Gather<bool, int64_t>(*params, input, positions, output);\n+        return Gather<bool, int64_t>(context, *params, input, positions,\n+                                     output);\n       case kTfLiteString:\n         return GatherStrings<int64_t>(context, input, positions, output);\n       default:\n"
        ],
        "func_after": []
    },
    {
        "idx": 197898,
        "project": "tensorflow",
        "commit_id": "96f364a1ca3009f98980021c4b32be5fdcca33a1",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/96f364a1ca3009f98980021c4b32be5fdcca33a1",
        "commit_message": "Validate axis input in tf.raw_ops.QuantizeAndDequantizeV4Grad\n\nPiperOrigin-RevId: 388291385\nChange-Id: I3bab68dc61d935afa96c0da021a7b722c6dc8dc8",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor& gradient = ctx->input(0);\n    const Tensor& input = ctx->input(1);\n    Tensor* input_backprop = nullptr;\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_output(0, input.shape(), &input_backprop));\n\n    OP_REQUIRES(\n        ctx, input.IsSameSize(gradient),\n        errors::InvalidArgument(\"gradient and input must be the same size\"));\n    const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);\n    const Tensor& input_min_tensor = ctx->input(2);\n    OP_REQUIRES(ctx,\n                input_min_tensor.dims() == 0 || input_min_tensor.dims() == 1,\n                errors::InvalidArgument(\n                    \"Input min tensor must have dimension 1. Recieved \",\n                    input_min_tensor.dims(), \".\"));\n    const Tensor& input_max_tensor = ctx->input(3);\n    OP_REQUIRES(ctx,\n                input_max_tensor.dims() == 0 || input_max_tensor.dims() == 1,\n                errors::InvalidArgument(\n                    \"Input max tensor must have dimension 1. Recieved \",\n                    input_max_tensor.dims(), \".\"));\n    if (axis_ != -1) {\n      OP_REQUIRES(\n          ctx, input_min_tensor.dim_size(0) == depth,\n          errors::InvalidArgument(\"min has incorrect size, expected \", depth,\n                                  \" was \", input_min_tensor.dim_size(0)));\n      OP_REQUIRES(\n          ctx, input_max_tensor.dim_size(0) == depth,\n          errors::InvalidArgument(\"max has incorrect size, expected \", depth,\n                                  \" was \", input_max_tensor.dim_size(0)));\n    }\n\n    TensorShape min_max_shape(input_min_tensor.shape());\n    Tensor* input_min_backprop;\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_output(1, min_max_shape, &input_min_backprop));\n\n    Tensor* input_max_backprop;\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_output(2, min_max_shape, &input_max_backprop));\n\n    if (axis_ == -1) {\n      functor::QuantizeAndDequantizeOneScaleGradientFunctor<Device, T> f;\n      f(ctx->eigen_device<Device>(), gradient.template flat<T>(),\n        input.template flat<T>(), input_min_tensor.scalar<T>(),\n        input_max_tensor.scalar<T>(), input_backprop->template flat<T>(),\n        input_min_backprop->template scalar<T>(),\n        input_max_backprop->template scalar<T>());\n    } else {\n      functor::QuantizeAndDequantizePerChannelGradientFunctor<Device, T> f;\n      f(ctx->eigen_device<Device>(),\n        gradient.template flat_inner_outer_dims<T, 3>(axis_ - 1),\n        input.template flat_inner_outer_dims<T, 3>(axis_ - 1),\n        &input_min_tensor, &input_max_tensor,\n        input_backprop->template flat_inner_outer_dims<T, 3>(axis_ - 1),\n        input_min_backprop->template flat<T>(),\n        input_max_backprop->template flat<T>());\n    }\n  }",
        "func_hash": 29737241678039524897017482046018335676,
        "file_name": "quantize_and_dequantize_op.cc",
        "file_hash": 111820661822757211423774352328292852595,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2021-37645",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions the implementation of `tf.raw_ops.QuantizeAndDequantizeV4Grad` is vulnerable to an integer overflow issue caused by converting a signed integer value to an unsigned one and then allocating memory based on this value. The [implementation](https://github.com/tensorflow/tensorflow/blob/8d72537c6abf5a44103b57b9c2e22c14f5f49698/tensorflow/core/kernels/quantize_and_dequantize_op.cc#L126) uses the `axis` value as the size argument to `absl::InlinedVector` constructor. But, the constructor uses an unsigned type for the argument, so the implicit conversion transforms the negative value to a large integer. We have patched the issue in GitHub commit 96f364a1ca3009f98980021c4b32be5fdcca33a1. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, and TensorFlow 2.4.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37645",
        "func_name": "Compute",
        "diff": [
            "diff --git a/tensorflow/core/kernels/quantize_and_dequantize_op.cc b/tensorflow/core/kernels/quantize_and_dequantize_op.cc\nindex 540d900f9f8696..d63a49a04be621 100644\n--- a/tensorflow/core/kernels/quantize_and_dequantize_op.cc\n+++ b/tensorflow/core/kernels/quantize_and_dequantize_op.cc\n@@ -158,6 +158,13 @@ class QuantizeAndDequantizeV4GradientOp : public OpKernel {\n     Tensor* input_backprop = nullptr;\n     OP_REQUIRES_OK(ctx,\n                    ctx->allocate_output(0, input.shape(), &input_backprop));\n+    OP_REQUIRES(\n+        ctx, axis_ >= -1,\n+        errors::InvalidArgument(\"Axis must be at least -1. Found \", axis_));\n+    OP_REQUIRES(ctx, (axis_ == -1 || axis_ < input.shape().dims()),\n+                errors::InvalidArgument(\n+                    \"Axis should be -1 or 0 or a positive value less than \",\n+                    input.shape().dims(), \"but given axis value was \", axis_));\n \n     OP_REQUIRES(\n         ctx, input.IsSameSize(gradient),\n"
        ],
        "func_after": []
    },
    {
        "idx": 197973,
        "project": "crun",
        "commit_id": "1aeeed2e4fdeffb4875c0d0b439915894594c8c6",
        "project_url": "https://github.com/containers/crun",
        "commit_url": "https://github.com/containers/crun/commit/1aeeed2e4fdeffb4875c0d0b439915894594c8c6",
        "commit_message": "exec: --cap do not set inheritable capabilities\n\nCloses: CVE-2022-27650\n\nSigned-off-by: Giuseppe Scrivano <gscrivan@redhat.com>",
        "target": 1,
        "irrelevant": 0,
        "func_before": "crun_command_exec (struct crun_global_arguments *global_args, int argc, char **argv, libcrun_error_t *err)\n{\n  int first_arg = 0, ret = 0;\n  libcrun_context_t crun_context = {\n    0,\n  };\n  cleanup_process_schema runtime_spec_schema_config_schema_process *process = NULL;\n  struct libcrun_container_exec_options_s exec_opts;\n\n  memset (&exec_opts, 0, sizeof (exec_opts));\n  exec_opts.struct_size = sizeof (exec_opts);\n\n  crun_context.preserve_fds = 0;\n  crun_context.listen_fds = 0;\n\n  argp_parse (&run_argp, argc, argv, ARGP_IN_ORDER, &first_arg, &exec_options);\n  crun_assert_n_args (argc - first_arg, exec_options.process ? 1 : 2, -1);\n\n  ret = init_libcrun_context (&crun_context, argv[first_arg], global_args, err);\n  if (UNLIKELY (ret < 0))\n    return ret;\n\n  crun_context.detach = exec_options.detach;\n  crun_context.console_socket = exec_options.console_socket;\n  crun_context.pid_file = exec_options.pid_file;\n  crun_context.preserve_fds = exec_options.preserve_fds;\n\n  if (getenv (\"LISTEN_FDS\"))\n    {\n      crun_context.listen_fds = strtoll (getenv (\"LISTEN_FDS\"), NULL, 10);\n      crun_context.preserve_fds += crun_context.listen_fds;\n    }\n\n  if (exec_options.process)\n    exec_opts.path = exec_options.process;\n  else\n    {\n      process = xmalloc0 (sizeof (*process));\n      int i;\n\n      process->args_len = argc;\n      process->args = xmalloc0 ((argc + 1) * sizeof (*process->args));\n      for (i = 0; i < argc - first_arg; i++)\n        process->args[i] = xstrdup (argv[first_arg + i + 1]);\n      process->args[i] = NULL;\n      if (exec_options.cwd)\n        process->cwd = exec_options.cwd;\n      process->terminal = exec_options.tty;\n      process->env = exec_options.env;\n      process->env_len = exec_options.env_size;\n      process->user = make_oci_process_user (exec_options.user);\n\n      if (exec_options.process_label != NULL)\n        process->selinux_label = exec_options.process_label;\n\n      if (exec_options.apparmor != NULL)\n        process->apparmor_profile = exec_options.apparmor;\n\n      if (exec_options.cap_size > 0)\n        {\n          runtime_spec_schema_config_schema_process_capabilities *capabilities\n              = xmalloc (sizeof (runtime_spec_schema_config_schema_process_capabilities));\n\n          capabilities->effective = exec_options.cap;\n          capabilities->effective_len = exec_options.cap_size;\n\n          capabilities->inheritable = dup_array (exec_options.cap, exec_options.cap_size);\n          capabilities->inheritable_len = exec_options.cap_size;\n\n          capabilities->bounding = dup_array (exec_options.cap, exec_options.cap_size);\n          capabilities->bounding_len = exec_options.cap_size;\n\n          capabilities->ambient = dup_array (exec_options.cap, exec_options.cap_size);\n          capabilities->ambient_len = exec_options.cap_size;\n\n          capabilities->permitted = dup_array (exec_options.cap, exec_options.cap_size);\n          capabilities->permitted_len = exec_options.cap_size;\n\n          process->capabilities = capabilities;\n        }\n\n      // noNewPriviledges will remain `false` if basespec has `false` unless specified\n      // Default is always `true` in generated basespec config\n      if (exec_options.no_new_privs)\n        process->no_new_privileges = 1;\n\n      exec_opts.process = process;\n    }\n\n  exec_opts.cgroup = exec_options.cgroup;\n\n  return libcrun_container_exec_with_options (&crun_context, argv[first_arg], &exec_opts, err);\n}",
        "func_hash": 202081994104919800529457023385761628896,
        "file_name": "exec.c",
        "file_hash": 10128723194506737000766570571290960247,
        "cwe": [
            "CWE-276"
        ],
        "cve": "CVE-2022-27650",
        "cve_desc": "A flaw was found in crun where containers were incorrectly started with non-empty default permissions. A vulnerability was found in Moby (Docker Engine) where containers were started incorrectly with non-empty inheritable Linux process capabilities. This flaw allows an attacker with access to programs with inheritable file capabilities to elevate those capabilities to the permitted set when execve(2) runs.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-27650",
        "func_name": "crun_command_exec",
        "diff": [
            "diff --git a/src/exec.c b/src/exec.c\nindex 7a8931e5ce..c876ecd180 100644\n--- a/src/exec.c\n+++ b/src/exec.c\n@@ -304,8 +304,8 @@ crun_command_exec (struct crun_global_arguments *global_args, int argc, char **a\n           capabilities->effective = exec_options.cap;\n           capabilities->effective_len = exec_options.cap_size;\n \n-          capabilities->inheritable = dup_array (exec_options.cap, exec_options.cap_size);\n-          capabilities->inheritable_len = exec_options.cap_size;\n+          capabilities->inheritable = NULL;\n+          capabilities->inheritable_len = 0;\n \n           capabilities->bounding = dup_array (exec_options.cap, exec_options.cap_size);\n           capabilities->bounding_len = exec_options.cap_size;\n"
        ],
        "func_after": []
    },
    {
        "idx": 197998,
        "project": "tensorflow",
        "commit_id": "704866eabe03a9aeda044ec91a8d0c83fc1ebdbe",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/704866eabe03a9aeda044ec91a8d0c83fc1ebdbe",
        "commit_message": "Fix overflow CHECK issue with `tf.raw_ops.UnsortedSegmentJoin`.\n\nPiperOrigin-RevId: 370766155\nChange-Id: I33e7c6626224e1060a8a4ab51ad5d861c6d4c63e",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext* context) override {\n    const Tensor& input = context->input(0);\n    const TensorShape& input_shape = input.shape();\n    const int32 input_dims = input_shape.dims();\n\n    const Tensor& segment_id = context->input(1);\n    const TensorShape& segment_id_shape = segment_id.shape();\n    const int32 segment_dims = segment_id_shape.dims();\n\n    const Tensor& num_segments_tensor = context->input(2);\n    auto num_segments = num_segments_tensor.scalar<NUM_SEGMENTS_TYPE>()();\n\n    OP_REQUIRES(context, segment_dims != 0,\n                errors::InvalidArgument(\"Segment_id cannot have rank 0\"));\n\n    OP_REQUIRES(\n        context, segment_dims <= input_dims,\n        errors::OutOfRange(\"Invalid segment_id rank \", segment_dims,\n                           \" for input with \", input_dims, \" dimension(s)\"));\n    for (auto i = 0; i < segment_dims; i++) {\n      OP_REQUIRES(\n          context, segment_id_shape.dim_size(i) == input_shape.dim_size(i),\n          errors::InvalidArgument(\n              \"Segment dimension is \", segment_id_shape.dim_size(i),\n              \" while input dimension is \", input_dims, \" in rank \", i));\n    }\n\n    // Making output tensor.\n    Tensor* output_tensor = nullptr;\n    TensorShape output_shape =\n        GetOutputShape(input_shape, segment_id_shape, num_segments);\n    OP_REQUIRES_OK(context, context->allocate_output(\"output\", output_shape,\n                                                     &output_tensor));\n\n    // Preparating flat tensors.\n    auto output_flat = output_tensor->flat<tstring>();\n    auto flat_segment_id = segment_id.flat<INDICES_TYPE>();\n    auto flat_input = input.flat<tstring>();\n\n    for (int i = 0; i < flat_segment_id.size(); i++) {\n      OP_REQUIRES(\n          context,\n          ((flat_segment_id(i) < num_segments) && (flat_segment_id(i) >= 0)),\n          errors::InvalidArgument(\n              \"segment_ids are not allowed to exceed num_segments or\"\n              \" to have negative values.\"));\n    }\n\n    int64 big_stride;\n    int64 small_stride;\n    std::tie(big_stride, small_stride) =\n        GetStrides<INDICES_TYPE>(input_shape, segment_id_shape);\n    auto relative_offset_set =\n        GetFlattenedRelativeOffsets<INDICES_TYPE>(small_stride, big_stride);\n    for (auto start_offset = 0; start_offset < big_stride; start_offset++) {\n      for (auto i = 0; i < relative_offset_set.size(); i++) {\n        auto output_index = start_offset + flat_segment_id(i) * big_stride;\n        auto offset = start_offset + relative_offset_set[i];\n        if (output_flat(output_index).length() != 0)\n          output_flat(output_index).append(separator_.c_str());\n        output_flat(output_index).append(flat_input(offset));\n      }\n    }\n  }",
        "func_hash": 25791049116451232925309470165962173994,
        "file_name": "unsorted_segment_join_op.cc",
        "file_hash": 172265001795447375510451213673230640731,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2021-29552",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. An attacker can cause a denial of service by controlling the values of `num_segments` tensor argument for `UnsortedSegmentJoin`. This is because the implementation(https://github.com/tensorflow/tensorflow/blob/a2a607db15c7cd01d754d37e5448d72a13491bdb/tensorflow/core/kernels/unsorted_segment_join_op.cc#L92-L93) assumes that the `num_segments` tensor is a valid scalar. Since the tensor is empty the `CHECK` involved in `.scalar<T>()()` that checks that the number of elements is exactly 1 will be invalidated and this would result in process termination. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-29552",
        "func_name": "Compute",
        "diff": [
            "diff --git a/tensorflow/core/kernels/unsorted_segment_join_op.cc b/tensorflow/core/kernels/unsorted_segment_join_op.cc\nindex 7464e165e46c8b..9acfe7fb1e4952 100644\n--- a/tensorflow/core/kernels/unsorted_segment_join_op.cc\n+++ b/tensorflow/core/kernels/unsorted_segment_join_op.cc\n@@ -90,6 +90,8 @@ class UnsortedSegmentJoinOp : public OpKernel {\n     const int32 segment_dims = segment_id_shape.dims();\n \n     const Tensor& num_segments_tensor = context->input(2);\n+    OP_REQUIRES(context, num_segments_tensor.NumElements() != 0,\n+                errors::InvalidArgument(\"Number of segments cannot be empty.\"));\n     auto num_segments = num_segments_tensor.scalar<NUM_SEGMENTS_TYPE>()();\n \n     OP_REQUIRES(context, segment_dims != 0,\n"
        ],
        "func_after": []
    },
    {
        "idx": 198003,
        "project": "tensorflow",
        "commit_id": "e86605c0a336c088b638da02135ea6f9f6753618",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/e86605c0a336c088b638da02135ea6f9f6753618",
        "commit_message": "Fix FPE in inpace update ops.\n\nPiperOrigin-RevId: 388303197\nChange-Id: Ib48309b6213ffe53eba81004b00e889d653e4b83",
        "target": 1,
        "irrelevant": 1,
        "func_before": "  void Compute(OpKernelContext* ctx) override {\n    auto x = ctx->input(0);\n    auto i = ctx->input(1);\n    auto v = ctx->input(2);\n\n    OP_REQUIRES(ctx, TensorShapeUtils::IsVector(i.shape()),\n                errors::InvalidArgument(\"i must be a vector. \",\n                                        i.shape().DebugString()));\n    OP_REQUIRES(ctx, x.dims() == v.dims(),\n                errors::InvalidArgument(\n                    \"x and v shape doesn't match (ranks differ): \",\n                    x.shape().DebugString(), \" vs. \", v.shape().DebugString()));\n    for (int i = 1; i < x.dims(); ++i) {\n      OP_REQUIRES(\n          ctx, x.dim_size(i) == v.dim_size(i),\n          errors::InvalidArgument(\"x and v shape doesn't match at index \", i,\n                                  \" : \", x.shape().DebugString(), \" vs. \",\n                                  v.shape().DebugString()));\n    }\n    OP_REQUIRES(ctx, i.dim_size(0) == v.dim_size(0),\n                errors::InvalidArgument(\n                    \"i and x shape doesn't match at index 0: \",\n                    i.shape().DebugString(), \" vs. \", v.shape().DebugString()));\n\n    Tensor y = x;  // This creates an alias intentionally.\n    // Skip processing if tensors are empty.\n    if (x.NumElements() > 0 || v.NumElements() > 0) {\n      OP_REQUIRES_OK(ctx, DoCompute(ctx, i, v, &y));\n    }\n    ctx->set_output(0, y);\n  }",
        "func_hash": 239122710109603573986035577656659080255,
        "file_name": "inplace_ops.cc",
        "file_hash": 227256482225018419801828296351506660662,
        "cwe": [
            "CWE-369"
        ],
        "cve": "CVE-2021-37660",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions an attacker can cause a floating point exception by calling inplace operations with crafted arguments that would result in a division by 0. The [implementation](https://github.com/tensorflow/tensorflow/blob/84d053187cb80d975ef2b9684d4b61981bca0c41/tensorflow/core/kernels/inplace_ops.cc#L283) has a logic error: it should skip processing if `x` and `v` are empty but the code uses `||` instead of `&&`. We have patched the issue in GitHub commit e86605c0a336c088b638da02135ea6f9f6753618. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37660",
        "func_name": "Compute",
        "diff": [
            "diff --git a/tensorflow/core/kernels/inplace_ops.cc b/tensorflow/core/kernels/inplace_ops.cc\nindex 2c0b201af3dd81..81027c7e17ee1a 100644\n--- a/tensorflow/core/kernels/inplace_ops.cc\n+++ b/tensorflow/core/kernels/inplace_ops.cc\n@@ -225,7 +225,7 @@ class InplaceOpBase : public OpKernel {\n \n     Tensor y = x;  // This creates an alias intentionally.\n     // Skip processing if tensors are empty.\n-    if (x.NumElements() > 0 || v.NumElements() > 0) {\n+    if (x.NumElements() > 0 && v.NumElements() > 0) {\n       OP_REQUIRES_OK(ctx, DoCompute(ctx, i, v, &y));\n     }\n     ctx->set_output(0, y);\n"
        ],
        "func_after": []
    },
    {
        "idx": 198004,
        "project": "tensorflow",
        "commit_id": "b5cdbf12ffcaaffecf98f22a6be5a64bb96e4f58",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/b5cdbf12ffcaaffecf98f22a6be5a64bb96e4f58",
        "commit_message": "Prevent overflow due to integer conversion to unsigned.\n\nPiperOrigin-RevId: 387738045\nChange-Id: Id7e95bc07e02df1c66b72bd09f389608c87bdebe",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext* context) override {\n    // boxes: [batch_size, num_anchors, q, 4]\n    const Tensor& boxes = context->input(0);\n    // scores: [batch_size, num_anchors, num_classes]\n    const Tensor& scores = context->input(1);\n    OP_REQUIRES(\n        context, (boxes.dim_size(0) == scores.dim_size(0)),\n        errors::InvalidArgument(\"boxes and scores must have same batch size\"));\n\n    // max_output_size: scalar\n    const Tensor& max_output_size = context->input(2);\n    OP_REQUIRES(\n        context, TensorShapeUtils::IsScalar(max_output_size.shape()),\n        errors::InvalidArgument(\"max_size_per_class must be 0-D, got shape \",\n                                max_output_size.shape().DebugString()));\n    const int max_size_per_class = max_output_size.scalar<int>()();\n    // max_total_size: scalar\n    const Tensor& max_total_size = context->input(3);\n    OP_REQUIRES(\n        context, TensorShapeUtils::IsScalar(max_total_size.shape()),\n        errors::InvalidArgument(\"max_total_size must be 0-D, got shape \",\n                                max_total_size.shape().DebugString()));\n    const int max_total_size_per_batch = max_total_size.scalar<int>()();\n    OP_REQUIRES(context, max_total_size_per_batch > 0,\n                errors::InvalidArgument(\"max_total_size must be > 0\"));\n    // Throw warning when `max_total_size` is too large as it may cause OOM.\n    if (max_total_size_per_batch > pow(10, 6)) {\n      LOG(WARNING) << \"Detected a large value for `max_total_size`. This may \"\n                   << \"cause OOM error. (max_total_size: \"\n                   << max_total_size.scalar<int>()() << \")\";\n    }\n    // iou_threshold: scalar\n    const Tensor& iou_threshold = context->input(4);\n    OP_REQUIRES(context, TensorShapeUtils::IsScalar(iou_threshold.shape()),\n                errors::InvalidArgument(\"iou_threshold must be 0-D, got shape \",\n                                        iou_threshold.shape().DebugString()));\n    const float iou_threshold_val = iou_threshold.scalar<float>()();\n\n    // score_threshold: scalar\n    const Tensor& score_threshold = context->input(5);\n    OP_REQUIRES(\n        context, TensorShapeUtils::IsScalar(score_threshold.shape()),\n        errors::InvalidArgument(\"score_threshold must be 0-D, got shape \",\n                                score_threshold.shape().DebugString()));\n    const float score_threshold_val = score_threshold.scalar<float>()();\n\n    OP_REQUIRES(context, iou_threshold_val >= 0 && iou_threshold_val <= 1,\n                errors::InvalidArgument(\"iou_threshold must be in [0, 1]\"));\n    int num_boxes = 0;\n    const int num_classes = scores.dim_size(2);\n    ParseAndCheckCombinedNMSBoxSizes(context, boxes, &num_boxes, num_classes);\n    CheckCombinedNMSScoreSizes(context, num_boxes, scores);\n\n    if (!context->status().ok()) {\n      return;\n    }\n    BatchedNonMaxSuppressionOp(context, boxes, scores, num_boxes,\n                               max_size_per_class, max_total_size_per_batch,\n                               score_threshold_val, iou_threshold_val,\n                               pad_per_class_, clip_boxes_);\n  }",
        "func_hash": 210673426581575547249707641301751491612,
        "file_name": "non_max_suppression_op.cc",
        "file_hash": 139290447269713266938093065325537015681,
        "cwe": [
            "CWE-369"
        ],
        "cve": "CVE-2021-37669",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions an attacker can cause denial of service in applications serving models using `tf.raw_ops.NonMaxSuppressionV5` by triggering a division by 0. The [implementation](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/core/kernels/image/non_max_suppression_op.cc#L170-L271) uses a user controlled argument to resize a `std::vector`. However, as `std::vector::resize` takes the size argument as a `size_t` and `output_size` is an `int`, there is an implicit conversion to unsigned. If the attacker supplies a negative value, this conversion results in a crash. A similar issue occurs in `CombinedNonMaxSuppression`. We have patched the issue in GitHub commit 3a7362750d5c372420aa8f0caf7bf5b5c3d0f52d and commit [b5cdbf12ffcaaffecf98f22a6be5a64bb96e4f58. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37669",
        "func_name": "Compute",
        "diff": [
            "diff --git a/tensorflow/core/kernels/image/non_max_suppression_op.cc b/tensorflow/core/kernels/image/non_max_suppression_op.cc\nindex 5cb721ed7105fa..69b05cc9d84f83 100644\n--- a/tensorflow/core/kernels/image/non_max_suppression_op.cc\n+++ b/tensorflow/core/kernels/image/non_max_suppression_op.cc\n@@ -930,6 +930,8 @@ class CombinedNonMaxSuppressionOp : public OpKernel {\n         errors::InvalidArgument(\"max_size_per_class must be 0-D, got shape \",\n                                 max_output_size.shape().DebugString()));\n     const int max_size_per_class = max_output_size.scalar<int>()();\n+    OP_REQUIRES(context, max_size_per_class > 0,\n+                errors::InvalidArgument(\"max_size_per_class must be positive\"));\n     // max_total_size: scalar\n     const Tensor& max_total_size = context->input(3);\n     OP_REQUIRES(\n"
        ],
        "func_after": []
    },
    {
        "idx": 198010,
        "project": "radare2",
        "commit_id": "193f4fe01d7f626e2ea937450f2e0c4604420e9d",
        "project_url": "https://github.com/radare/radare2",
        "commit_url": "https://github.com/radareorg/radare2/commit/193f4fe01d7f626e2ea937450f2e0c4604420e9d",
        "commit_message": "Fix integer overflow in string search causing oobread ##crash\n\n* Reported by @greatergoodest via huntrdev\n* BountyID: 8a3dc5cb-08b3-4807-82b2-77f08c137a04\n* Reproducer bfileovf",
        "target": 1,
        "irrelevant": 1,
        "func_before": "static int string_scan_range(RList *list, RBinFile *bf, int min,\n\t\t\t      const ut64 from, const ut64 to, int type, int raw, RBinSection *section) {\n\tRBin *bin = bf->rbin;\n\tut8 tmp[R_STRING_SCAN_BUFFER_SIZE];\n\tut64 str_start, needle = from;\n\tint count = 0, i, rc, runes;\n\tint str_type = R_STRING_TYPE_DETECT;\n\n\t// if list is null it means its gonna dump\n\tr_return_val_if_fail (bf, -1);\n\n\tif (type == -1) {\n\t\ttype = R_STRING_TYPE_DETECT;\n\t}\n\tif (from == to) {\n\t\treturn 0;\n\t}\n\tif (from > to) {\n\t\teprintf (\"Invalid range to find strings 0x%\"PFMT64x\" .. 0x%\"PFMT64x\"\\n\", from, to);\n\t\treturn -1;\n\t}\n\tst64 len = (st64)(to - from);\n\tif (len < 1 || len > ST32_MAX) {\n\t\teprintf (\"String scan range is invalid (%\"PFMT64d\" bytes)\\n\", len);\n\t\treturn -1;\n\t}\n\tut8 *buf = calloc (len, 1);\n\tif (!buf || !min) {\n\t\tfree (buf);\n\t\treturn -1;\n\t}\n\tst64 vdelta = 0, pdelta = 0;\n\tRBinSection *s = NULL;\n\tbool ascii_only = false;\n\tPJ *pj = NULL;\n\tif (bf->strmode == R_MODE_JSON && !list) {\n\t\tpj = pj_new ();\n\t\tif (pj) {\n\t\t\tpj_a (pj);\n\t\t}\n\t}\n\tr_buf_read_at (bf->buf, from, buf, len);\n\tchar *charset = r_sys_getenv (\"RABIN2_CHARSET\");\n\tif (!R_STR_ISEMPTY (charset)) {\n\t\tRCharset *ch = r_charset_new ();\n\t\tif (r_charset_use (ch, charset)) {\n\t\t\tint outlen = len * 4;\n\t\t\tut8 *out = calloc (len, 4);\n\t\t\tif (out) {\n\t\t\t\tint res = r_charset_encode_str (ch, out, outlen, buf, len);\n\t\t\t\tint i;\n\t\t\t\t// TODO unknown chars should be translated to null bytes\n\t\t\t\tfor (i = 0; i < res; i++) {\n\t\t\t\t\tif (out[i] == '?') {\n\t\t\t\t\t\tout[i] = 0;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tlen = res;\n\t\t\t\tfree (buf);\n\t\t\t\tbuf = out;\n\t\t\t} else {\n\t\t\t\teprintf (\"Cannot allocate\\n\");\n\t\t\t}\n\t\t} else {\n\t\t\teprintf (\"Invalid value for RABIN2_CHARSET.\\n\");\n\t\t}\n\t\tr_charset_free (ch);\n\t}\n\tfree (charset);\n\tRConsIsBreaked is_breaked = (bin && bin->consb.is_breaked)? bin->consb.is_breaked: NULL;\n\t// may oobread\n\twhile (needle < to) {\n\t\tif (is_breaked && is_breaked ()) {\n\t\t\tbreak;\n\t\t}\n\t\t// smol optimization\n\t\tif (needle + 4 < to) {\n\t\t\tut32 n1 = r_read_le32 (buf + needle - from);\n\t\t\tif (!n1) {\n\t\t\t\tneedle += 4;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t}\n\t\trc = r_utf8_decode (buf + needle - from, to - needle, NULL);\n\t\tif (!rc) {\n\t\t\tneedle++;\n\t\t\tcontinue;\n\t\t}\n\t\tbool addr_aligned = !(needle % 4);\n\n\t\tif (type == R_STRING_TYPE_DETECT) {\n\t\t\tchar *w = (char *)buf + needle + rc - from;\n\t\t\tif (((to - needle) > 8 + rc)) {\n\t\t\t\t// TODO: support le and be\n\t\t\t\tbool is_wide32le = (needle + rc + 2 < to) && (!w[0] && !w[1] && !w[2] && w[3] && !w[4]);\n\t\t\t\t// reduce false positives\n\t\t\t\tif (is_wide32le) {\n\t\t\t\t\tif (!w[5] && !w[6] && w[7] && w[8]) {\n\t\t\t\t\t\tis_wide32le = false;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (!addr_aligned) {\n\t\t\t\t\tis_wide32le = false;\n\t\t\t\t}\n\t\t\t\t///is_wide32be &= (n1 < 0xff && n11 < 0xff); // false; // n11 < 0xff;\n\t\t\t\tif (is_wide32le  && addr_aligned) {\n\t\t\t\t\tstr_type = R_STRING_TYPE_WIDE32; // asume big endian,is there little endian w32?\n\t\t\t\t} else {\n\t\t\t\t\t// bool is_wide = (n1 && n2 && n1 < 0xff && (!n2 || n2 < 0xff));\n\t\t\t\t\tbool is_wide = needle + rc + 4 < to && !w[0] && w[1] && !w[2] && w[3] && !w[4];\n\t\t\t\t\tstr_type = is_wide? R_STRING_TYPE_WIDE: R_STRING_TYPE_ASCII;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (rc > 1) {\n\t\t\t\t\tstr_type = R_STRING_TYPE_UTF8; // could be charset if set :?\n\t\t\t\t} else {\n\t\t\t\t\tstr_type = R_STRING_TYPE_ASCII;\n\t\t\t\t}\n\t\t\t}\n\t\t} else if (type == R_STRING_TYPE_UTF8) {\n\t\t\tstr_type = R_STRING_TYPE_ASCII; // initial assumption\n\t\t} else {\n\t\t\tstr_type = type;\n\t\t}\n\t\trunes = 0;\n\t\tstr_start = needle;\n\n\t\t/* Eat a whole C string */\n\t\tfor (i = 0; i < sizeof (tmp) - 4 && needle < to; i += rc) {\n\t\t\tRRune r = {0};\n\t\t\tif (str_type == R_STRING_TYPE_WIDE32) {\n\t\t\t\trc = r_utf32le_decode (buf + needle - from, to - needle, &r);\n\t\t\t\tif (rc) {\n\t\t\t\t\trc = 4;\n\t\t\t\t}\n\t\t\t} else if (str_type == R_STRING_TYPE_WIDE) {\n\t\t\t\trc = r_utf16le_decode (buf + needle - from, to - needle, &r);\n\t\t\t\tif (rc == 1) {\n\t\t\t\t\trc = 2;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\trc = r_utf8_decode (buf + needle - from, to - needle, &r);\n\t\t\t\tif (rc > 1) {\n\t\t\t\t\tstr_type = R_STRING_TYPE_UTF8;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t/* Invalid sequence detected */\n\t\t\tif (!rc || (ascii_only && r > 0x7f)) {\n\t\t\t\tneedle++;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tneedle += rc;\n\n\t\t\tif (r_isprint (r) && r != '\\\\') {\n\t\t\t\tif (str_type == R_STRING_TYPE_WIDE32) {\n\t\t\t\t\tif (r == 0xff) {\n\t\t\t\t\t\tr = 0;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\trc = r_utf8_encode (tmp + i, r);\n\t\t\t\trunes++;\n\t\t\t\t/* Print the escape code */\n\t\t\t} else if (r && r < 0x100 && strchr (\"\\b\\v\\f\\n\\r\\t\\a\\033\\\\\", (char)r)) {\n\t\t\t\tif ((i + 32) < sizeof (tmp) && r < 93) {\n\t\t\t\t\ttmp[i + 0] = '\\\\';\n\t\t\t\t\ttmp[i + 1] = \"       abtnvfr             e  \"\n\t\t\t\t\t             \"                              \"\n\t\t\t\t\t             \"                              \"\n\t\t\t\t\t             \"  \\\\\"[r];\n\t\t\t\t} else {\n\t\t\t\t\t// string too long\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\trc = 2;\n\t\t\t\trunes++;\n\t\t\t} else {\n\t\t\t\t/* \\0 marks the end of C-strings */\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\ttmp[i++] = '\\0';\n\n\t\tif (runes < min && runes >= 2 && str_type == R_STRING_TYPE_ASCII && needle < to) {\n\t\t\t// back up past the \\0 to the last char just in case it starts a wide string\n\t\t\tneedle -= 2;\n\t\t}\n\t\tif (runes >= min) {\n\t\t\t// reduce false positives\n\t\t\tint j, num_blocks, *block_list;\n\t\t\tint *freq_list = NULL, expected_ascii, actual_ascii, num_chars;\n\t\t\tif (str_type == R_STRING_TYPE_ASCII) {\n\t\t\t\tfor (j = 0; j < i; j++) {\n\t\t\t\t\tchar ch = tmp[j];\n\t\t\t\t\tif (ch != '\\n' && ch != '\\r' && ch != '\\t') {\n\t\t\t\t\t\tif (!IS_PRINTABLE (tmp[j])) {\n\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tswitch (str_type) {\n\t\t\tcase R_STRING_TYPE_UTF8:\n\t\t\tcase R_STRING_TYPE_WIDE:\n\t\t\tcase R_STRING_TYPE_WIDE32:\n\t\t\t\tnum_blocks = 0;\n\t\t\t\tblock_list = r_utf_block_list ((const ut8*)tmp, i - 1,\n\t\t\t\t\t\tstr_type == R_STRING_TYPE_WIDE? &freq_list: NULL);\n\t\t\t\tif (block_list) {\n\t\t\t\t\tfor (j = 0; block_list[j] != -1; j++) {\n\t\t\t\t\t\tnum_blocks++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (freq_list) {\n\t\t\t\t\tnum_chars = 0;\n\t\t\t\t\tactual_ascii = 0;\n\t\t\t\t\tfor (j = 0; freq_list[j] != -1; j++) {\n\t\t\t\t\t\tnum_chars += freq_list[j];\n\t\t\t\t\t\tif (!block_list[j]) { // ASCII\n\t\t\t\t\t\t\tactual_ascii = freq_list[j];\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tfree (freq_list);\n\t\t\t\t\texpected_ascii = num_blocks ? num_chars / num_blocks : 0;\n\t\t\t\t\tif (actual_ascii > expected_ascii) {\n\t\t\t\t\t\tascii_only = true;\n\t\t\t\t\t\tneedle = str_start;\n\t\t\t\t\t\tfree (block_list);\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfree (block_list);\n\t\t\t\tif (num_blocks > R_STRING_MAX_UNI_BLOCKS) {\n\t\t\t\t\tneedle++;\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t}\n\t\t\tRBinString *bs = R_NEW0 (RBinString);\n\t\t\tif (!bs) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbs->type = str_type;\n\t\t\tbs->length = runes;\n\t\t\tbs->size = needle - str_start;\n\t\t\tbs->ordinal = count++;\n\t\t\t// TODO: move into adjust_offset\n\t\t\tswitch (str_type) {\n\t\t\tcase R_STRING_TYPE_WIDE:\n\t\t\t\tif (str_start - from > 1) {\n\t\t\t\t\tconst ut8 *p = buf + str_start - 2 - from;\n\t\t\t\t\tif (p[0] == 0xff && p[1] == 0xfe) {\n\t\t\t\t\t\tstr_start -= 2; // \\xff\\xfe\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase R_STRING_TYPE_WIDE32:\n\t\t\t\tif (str_start - from > 3) {\n\t\t\t\t\tconst ut8 *p = buf + str_start - 4 - from;\n\t\t\t\t\tif (p[0] == 0xff && p[1] == 0xfe) {\n\t\t\t\t\t\tstr_start -= 4; // \\xff\\xfe\\x00\\x00\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (!s) {\n\t\t\t\tif (section) {\n\t\t\t\t\ts = section;\n\t\t\t\t} else if (bf->o) {\n\t\t\t\t\ts = r_bin_get_section_at (bf->o, str_start, false);\n\t\t\t\t}\n\t\t\t\tif (s) {\n\t\t\t\t\tvdelta = s->vaddr;\n\t\t\t\t\tpdelta = s->paddr;\n\t\t\t\t}\n\t\t\t}\n\t\t\tut64 baddr = bf->loadaddr && bf->o? bf->o->baddr: bf->loadaddr;\n\t\t\tbs->paddr = str_start + baddr;\n\t\t\tbs->vaddr = str_start - pdelta + vdelta + baddr;\n\t\t\tbs->string = r_str_ndup ((const char *)tmp, i);\n\t\t\tif (list) {\n\t\t\t\tr_list_append (list, bs);\n\t\t\t\tif (bf->o) {\n\t\t\t\t\tht_up_insert (bf->o->strings_db, bs->vaddr, bs);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tprint_string (bf, bs, raw, pj);\n\t\t\t\tr_bin_string_free (bs);\n\t\t\t}\n\t\t\tif (from == 0 && to == bf->size) {\n\t\t\t\t/* force lookup section at the next one */\n\t\t\t\ts = NULL;\n\t\t\t}\n\t\t}\n\t\tascii_only = false;\n\t}\n\tfree (buf);\n\tif (pj) {\n\t\tpj_end (pj);\n\t\tif (bin) {\n\t\t\tRIO *io = bin->iob.io;\n\t\t\tif (io) {\n\t\t\t\tio->cb_printf (\"%s\", pj_string (pj));\n\t\t\t}\n\t\t}\n\t\tpj_free (pj);\n\t}\n\treturn count;\n}",
        "func_hash": 327958810043229005935201535284879314576,
        "file_name": "bfile.c",
        "file_hash": 285505404053025817812791776020239027950,
        "cwe": [
            "CWE-125"
        ],
        "cve": "CVE-2022-1899",
        "cve_desc": "Out-of-bounds Read in GitHub repository radareorg/radare2 prior to 5.7.0.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-1899",
        "func_name": "string_scan_range",
        "diff": [
            "diff --git a/libr/bin/bfile.c b/libr/bin/bfile.c\nindex 3216e5b7618d9..bb9663fff17d4 100644\n--- a/libr/bin/bfile.c\n+++ b/libr/bin/bfile.c\n@@ -178,19 +178,19 @@ static int string_scan_range(RList *list, RBinFile *bf, int min,\n \tfree (charset);\n \tRConsIsBreaked is_breaked = (bin && bin->consb.is_breaked)? bin->consb.is_breaked: NULL;\n \t// may oobread\n-\twhile (needle < to) {\n+\twhile (needle < to && needle < UT64_MAX - 4) {\n \t\tif (is_breaked && is_breaked ()) {\n \t\t\tbreak;\n \t\t}\n \t\t// smol optimization\n-\t\tif (needle + 4 < to) {\n-\t\t\tut32 n1 = r_read_le32 (buf + needle - from);\n+\t\tif (needle < to - 4) {\n+\t\t\tut32 n1 = r_read_le32 (buf + (needle - from));\n \t\t\tif (!n1) {\n \t\t\t\tneedle += 4;\n \t\t\t\tcontinue;\n \t\t\t}\n \t\t}\n-\t\trc = r_utf8_decode (buf + needle - from, to - needle, NULL);\n+\t\trc = r_utf8_decode (buf + (needle - from), to - needle, NULL);\n \t\tif (!rc) {\n \t\t\tneedle++;\n \t\t\tcontinue;\n@@ -198,7 +198,7 @@ static int string_scan_range(RList *list, RBinFile *bf, int min,\n \t\tbool addr_aligned = !(needle % 4);\n \n \t\tif (type == R_STRING_TYPE_DETECT) {\n-\t\t\tchar *w = (char *)buf + needle + rc - from;\n+\t\t\tchar *w = (char *)buf + (needle + rc - from);\n \t\t\tif (((to - needle) > 8 + rc)) {\n \t\t\t\t// TODO: support le and be\n \t\t\t\tbool is_wide32le = (needle + rc + 2 < to) && (!w[0] && !w[1] && !w[2] && w[3] && !w[4]);\n@@ -248,7 +248,7 @@ static int string_scan_range(RList *list, RBinFile *bf, int min,\n \t\t\t\t\trc = 2;\n \t\t\t\t}\n \t\t\t} else {\n-\t\t\t\trc = r_utf8_decode (buf + needle - from, to - needle, &r);\n+\t\t\t\trc = r_utf8_decode (buf + (needle - from), to - needle, &r);\n \t\t\t\tif (rc > 1) {\n \t\t\t\t\tstr_type = R_STRING_TYPE_UTF8;\n \t\t\t\t}\n"
        ],
        "func_after": []
    },
    {
        "idx": 198013,
        "project": "tensorflow",
        "commit_id": "3150642acbbe254e3c3c5d2232143fa591855ac9",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/3150642acbbe254e3c3c5d2232143fa591855ac9",
        "commit_message": "Fix tf.raw_ops.LoadAndRemapMatrix vulnerability with invalid `row_remapping`.\n\nCheck that `row_remapping` has the correct dims().\n\nPiperOrigin-RevId: 445522800",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext* context) override {\n    // Checks what we're remapping and inverts the relevant remapping Tensors to\n    // be maps with key = old ID, value = new ID.\n    std::unordered_map<int64_t, int64_t> old_row_to_new_row_map;\n    std::vector<bool> row_id_present;\n    const Tensor* row_remapping_t;\n    OP_REQUIRES_OK(context, context->input(\"row_remapping\", &row_remapping_t));\n    const auto row_remapping = row_remapping_t->vec<int64_t>();\n    OP_REQUIRES(context, row_remapping.size() == num_rows_,\n                errors::InvalidArgument(strings::StrCat(\n                    \"Size of row_remapping is \", row_remapping.size(),\n                    \" instead of being equal to num_rows=\", num_rows_)));\n    OP_REQUIRES_OK(context, RemapVectorToMap(row_remapping, &row_id_present,\n                                             &old_row_to_new_row_map));\n\n    // Calculates the min/max old row ID that we need to read, to save us from\n    // reading some unnecessary slices of the old tensor.\n    int64_t min_old_row = -1;\n    int64_t max_old_row = -1;\n    for (int i = 0; i < row_remapping.size(); ++i) {\n      if (min_old_row < 0 ||\n          (row_remapping(i) >= 0 && row_remapping(i) < min_old_row)) {\n        min_old_row = row_remapping(i);\n      }\n      if (max_old_row < 0 ||\n          (row_remapping(i) >= 0 && row_remapping(i) > max_old_row)) {\n        max_old_row = row_remapping(i);\n      }\n    }\n\n    // Processes the remapping for columns.\n    std::unordered_map<int64_t, int64_t> old_col_to_new_col_map;\n    std::vector<bool> col_id_present;\n    const Tensor* col_remapping_t;\n    OP_REQUIRES_OK(context, context->input(\"col_remapping\", &col_remapping_t));\n    const auto col_remapping = col_remapping_t->vec<int64_t>();\n    // Note that we always \"remap rows\", even when the row vocabulary does\n    // not change, because partitioning requires a mapping from partitioned\n    // Variables to the full checkpoints we load.\n    const bool remap_cols = col_remapping.size() > 0;\n    if (remap_cols) {\n      OP_REQUIRES(\n          context, col_remapping.size() == num_cols_,\n          errors::InvalidArgument(strings::StrCat(\n              \"Provided col_remapping, but its size is \", col_remapping.size(),\n              \" instead of being equal to num_cols=\", num_cols_)));\n      OP_REQUIRES_OK(context, RemapVectorToMap(col_remapping, &col_id_present,\n                                               &old_col_to_new_col_map));\n    } else {\n      col_id_present.clear();\n      col_id_present.resize(num_cols_, true);\n    }\n\n    // Processes the checkpoint source and the provided Tensor name.\n    const Tensor* ckpt_path_t;\n    OP_REQUIRES_OK(context, context->input(\"ckpt_path\", &ckpt_path_t));\n    OP_REQUIRES(\n        context, ckpt_path_t->NumElements() == 1,\n        errors::InvalidArgument(\"The `ckpt_path` tensor must have exactly one \"\n                                \"element, got tensor of shape \",\n                                ckpt_path_t->shape().DebugString()));\n    const string& ckpt_path = ckpt_path_t->scalar<tstring>()();\n    const Tensor* old_tensor_name_t;\n    OP_REQUIRES_OK(context,\n                   context->input(\"old_tensor_name\", &old_tensor_name_t));\n    const string& old_tensor_name = old_tensor_name_t->scalar<tstring>()();\n\n    LOG(INFO) << \"Processing checkpoint : \" << ckpt_path;\n    BundleReader reader(context->env(), ckpt_path);\n    OP_REQUIRES_OK(context, reader.status());\n\n    DataType tensor_type;\n    TensorShape tensor_shape;\n    OP_REQUIRES_OK(context, reader.LookupDtypeAndShape(\n                                old_tensor_name, &tensor_type, &tensor_shape));\n    OP_REQUIRES(context, tensor_type == DT_FLOAT,\n                errors::InvalidArgument(strings::StrCat(\n                    \"Tensor \", old_tensor_name, \" has invalid type \",\n                    DataTypeString(tensor_type), \" instead of expected type \",\n                    DataTypeString(DT_FLOAT))));\n    // This op is limited to loading Tensors of rank 2 (matrices).\n    OP_REQUIRES(\n        context, tensor_shape.dims() == 2,\n        errors::InvalidArgument(strings::StrCat(\n            \"Tensor \", old_tensor_name, \" has shape \",\n            tensor_shape.DebugString(), \" of invalid rank \",\n            tensor_shape.dims(), \" instead of expected shape of rank 2.\")));\n\n    if (!remap_cols) {\n      // TODO(weiho): Consider relaxing this restriction to allow partial column\n      // loading (even when no column remapping is specified) if there turns out\n      // to be a use case for it.\n      OP_REQUIRES(context, num_cols_ == tensor_shape.dim_size(1),\n                  errors::InvalidArgument(strings::StrCat(\n                      \"Tensor \", old_tensor_name, \" has shape \",\n                      tensor_shape.DebugString(),\n                      \", where the size of its 2nd dimension is \",\n                      tensor_shape.dim_size(1),\n                      \" instead of being equal to num_cols=\", num_cols_)));\n    }\n\n    // Uses TensorSlice to potentially load the old tensor in chunks in case\n    // memory usage is a concern.\n    std::vector<TensorSlice> tensor_slices;\n    TensorSlice slice(tensor_shape.dims());\n    if (min_old_row >= 0 && max_old_row >= 0) {\n      int64_t row_start = min_old_row;\n      // TODO(weiho): Given the list of old row IDs of interest (the keys of\n      // old_row_to_new_row_map), we could also try something smarter to\n      // find some minimal set of covering ranges for the list of old row IDs\n      // such that the size of each range is less than max_rows_in_memory_.\n      while (row_start <= max_old_row) {\n        const int64_t slice_length =\n            max_rows_in_memory_ <= 0\n                // If max_rows_in_memory_ <= 0, we just load the entire chunk.\n                ? max_old_row - row_start + 1\n                : std::min(max_rows_in_memory_, max_old_row - row_start + 1);\n        slice.set_start(0, row_start);\n        slice.set_length(0, slice_length);\n        tensor_slices.push_back(slice);\n        row_start += slice_length;\n      }\n    }\n\n    // Allocates the output matrix.\n    Tensor* output_matrix_t = nullptr;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(\"output_matrix\",\n                                            TensorShape({num_rows_, num_cols_}),\n                                            &output_matrix_t));\n    auto output_matrix = output_matrix_t->matrix<float>();\n\n    // Iterates through tensor slices and copies over values from the old tensor\n    // to the output matrix.\n    int64_t row_index = min_old_row;\n    int64_t rows_copied = 0;\n    Tensor loaded_tensor_t;\n    for (const TensorSlice& tensor_slice : tensor_slices) {\n      LOG(INFO) << \"Loading slice \" << tensor_slice.DebugString();\n      TensorShape slice_shape;\n      OP_REQUIRES_OK(context,\n                     tensor_slice.SliceTensorShape(tensor_shape, &slice_shape));\n      // Potentially re-allocates the tensor buffer since the last slice may\n      // have fewer rows than the other slices.\n      if (loaded_tensor_t.shape() != slice_shape) {\n        loaded_tensor_t = Tensor(DT_FLOAT, slice_shape);\n      }\n      OP_REQUIRES_OK(context, reader.LookupSlice(old_tensor_name, tensor_slice,\n                                                 &loaded_tensor_t));\n\n      // Iterates through the old loaded tensor slice row-by-row.\n      for (int row = 0; row < loaded_tensor_t.dim_size(0); ++row, ++row_index) {\n        if (row_index % 500000 == min_old_row) {\n          LOG(INFO) << \"Processing old row \" << row_index;\n        }\n\n        // If the old row ID is not found in old_row_to_new_row_map, continue\n        // to the next row; otherwise, copy it to the output matrix.\n        const int64_t* new_row_ptr =\n            gtl::FindOrNull(old_row_to_new_row_map, row_index);\n        if (new_row_ptr == nullptr) {\n          continue;\n        }\n        ++rows_copied;\n        const int64_t new_row = *new_row_ptr;\n\n        // Copies over the row element-by-element, in case remapping is needed\n        // along the column axis.\n        const auto& loaded_tensor = loaded_tensor_t.matrix<float>();\n        for (int old_col = 0; old_col < loaded_tensor_t.dim_size(1);\n             ++old_col) {\n          int64_t new_col = old_col;\n          if (remap_cols) {\n            const int64_t* new_col_ptr =\n                gtl::FindOrNull(old_col_to_new_col_map, old_col);\n            if (new_col_ptr == nullptr) {\n              // Column remapping is specified, but this column is not found in\n              // old_col_to_new_col_map, so we leave it uninitialized, to be\n              // filled in with initializing_values later.\n              continue;\n            }\n            new_col = *new_col_ptr;\n          }\n\n          OP_REQUIRES(context,\n                      new_row < num_rows_ && new_col < num_cols_ &&\n                          new_row >= 0 && new_col >= 0,\n                      errors::Internal(strings::StrCat(\n                          \"new_row=\", new_row, \" and new_col=\", new_col,\n                          \" should have been less than num_rows_=\", num_rows_,\n                          \" and num_cols_=\", num_cols_,\n                          \" and non-negative. This should never have happened \"\n                          \"if the code were correct. Please file a bug.\")));\n          output_matrix(new_row, new_col) = loaded_tensor(row, old_col);\n        }\n      }\n    }\n    LOG(INFO) << \"Copied \" << rows_copied << \" rows from old matrix (with \"\n              << tensor_shape.dim_size(0) << \" rows) to new matrix (with \"\n              << num_rows_ << \" rows).\";\n\n    // At this point, there are potentially whole rows/columns uninitialized\n    // (corresponding to the indices where row_id_present/col_id_present are\n    // false). We fill this in cell-by-cell using row_id_present and\n    // col_id_present while dequeuing from the initializing_values vector.\n    const Tensor* initializing_values_t;\n    OP_REQUIRES_OK(\n        context, context->input(\"initializing_values\", &initializing_values_t));\n    const auto initializing_values = initializing_values_t->flat<float>();\n    int64_t initializing_values_index = 0;\n    for (int i = 0; i < num_rows_; ++i) {\n      for (int j = 0; j < num_cols_; ++j) {\n        if (row_id_present[i] && col_id_present[j]) continue;\n        OP_REQUIRES(\n            context, initializing_values_index < initializing_values.size(),\n            errors::InvalidArgument(\n                \"initializing_values contained \", initializing_values.size(),\n                \" elements, but more missing values remain.\"));\n        output_matrix(i, j) = initializing_values(initializing_values_index);\n        ++initializing_values_index;\n      }\n    }\n\n    // Checks that we used all the given initializing values.\n    OP_REQUIRES(\n        context, initializing_values_index == initializing_values.size(),\n        errors::InvalidArgument(\n            \"initializing_values contained \", initializing_values.size(),\n            \" elements, but only \", initializing_values_index,\n            \" elements were used to fill in missing values.\"));\n  }",
        "func_hash": 219722258688637064068607537553301810412,
        "file_name": "load_and_remap_matrix_op.cc",
        "file_hash": 213297145030896672862854801534820332645,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2022-29199",
        "cve_desc": "TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, the implementation of `tf.raw_ops.LoadAndRemapMatrix does not fully validate the input arguments. This results in a `CHECK`-failure which can be used to trigger a denial of service attack. The code assumes `initializing_values` is a vector but there is no validation for this before accessing its value. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-29199",
        "func_name": "Compute",
        "diff": [
            "diff --git a/tensorflow/core/kernels/load_and_remap_matrix_op.cc b/tensorflow/core/kernels/load_and_remap_matrix_op.cc\nindex 3fa753251c0f4f..4276e16059a9c6 100644\n--- a/tensorflow/core/kernels/load_and_remap_matrix_op.cc\n+++ b/tensorflow/core/kernels/load_and_remap_matrix_op.cc\n@@ -74,6 +74,11 @@ class LoadAndRemapMatrixOp : public OpKernel {\n     std::vector<bool> row_id_present;\n     const Tensor* row_remapping_t;\n     OP_REQUIRES_OK(context, context->input(\"row_remapping\", &row_remapping_t));\n+    OP_REQUIRES(\n+        context, row_remapping_t->dims() == 1,\n+        errors::InvalidArgument(\"The `row_remapping` tensor must be 1-D, got \"\n+                                \"a tensor of shape \",\n+                                row_remapping_t->shape().DebugString()));\n     const auto row_remapping = row_remapping_t->vec<int64_t>();\n     OP_REQUIRES(context, row_remapping.size() == num_rows_,\n                 errors::InvalidArgument(strings::StrCat(\ndiff --git a/tensorflow/python/kernel_tests/io_ops/checkpoint_ops_test.py b/tensorflow/python/kernel_tests/io_ops/checkpoint_ops_test.py\nindex f357de2de7c845..91618f974b31a2 100644\n--- a/tensorflow/python/kernel_tests/io_ops/checkpoint_ops_test.py\n+++ b/tensorflow/python/kernel_tests/io_ops/checkpoint_ops_test.py\n@@ -227,6 +227,32 @@ def test_load_and_remap_all_missing_rows_and_cols(self):\n           np.reshape(initializing_values, (num_rows, num_cols)),\n           self.evaluate(remapped_matrix))\n \n+  def test_load_and_remap_invalid_dims(self):\n+    ckpt_path = constant_op.constant(\n+        '/tmp/warm_starting_util_test5kl2a3pc/tmpph76tep2/model-0',\n+        shape=[],\n+        dtype=dtypes.string)\n+    old_tensor_name = constant_op.constant(\n+        '/tmp/warm_starting_util_test5kl2a3pc/tmpph76tep2/model-0',\n+        shape=[],\n+        dtype=dtypes.string)\n+    row_remapping = constant_op.constant(0, shape=[], dtype=dtypes.int64)\n+    col_remapping = constant_op.constant(3, shape=[3], dtype=dtypes.int64)\n+    initializing_values = constant_op.constant([],\n+                                               shape=[0, 1],\n+                                               dtype=dtypes.float32)\n+    with self.cached_session(), self.assertRaisesRegex(\n+        (ValueError, errors.InvalidArgumentError), 'tensor must be 1-D'):\n+      self.evaluate(\n+          gen_checkpoint_ops.load_and_remap_matrix(\n+              ckpt_path=ckpt_path,\n+              old_tensor_name=old_tensor_name,\n+              row_remapping=row_remapping,\n+              col_remapping=col_remapping,\n+              initializing_values=initializing_values,\n+              num_rows=1,\n+              num_cols=1))\n+\n   @test_util.run_deprecated_v1\n   def test_load_and_remap_invalid_remapping(self):\n     \"\"\"Tests that errors are raised when an ID maps to multiple new IDs.\n"
        ],
        "func_after": []
    },
    {
        "idx": 198116,
        "project": "tensorflow",
        "commit_id": "87158f43f05f2720a374f3e6d22a7aaa3a33f750",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/87158f43f05f2720a374f3e6d22a7aaa3a33f750",
        "commit_message": "Prevent heap OOB in sparse reduction ops.\n\nPiperOrigin-RevId: 387934524\nChange-Id: I894aa30f1e454f09b471d565b4a325da49322c1a",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext *ctx) override {\n    const Tensor *indices_t, *values_t, *shape_t, *reduction_axes_t;\n    OP_REQUIRES_OK(ctx, ctx->input(\"input_indices\", &indices_t));\n    OP_REQUIRES_OK(ctx, ctx->input(\"input_values\", &values_t));\n    OP_REQUIRES_OK(ctx, ctx->input(\"input_shape\", &shape_t));\n    OP_REQUIRES_OK(ctx, ctx->input(\"reduction_axes\", &reduction_axes_t));\n\n    OP_REQUIRES_OK(ctx, ValidateInputs(shape_t, reduction_axes_t));\n\n    // TODO(zongheng): we will call Reorder() below, which will modify\n    // in-place the underlying indices and values buffers.  To avoid\n    // surprises of this kernel being stateful, we work around the above by\n    // making deep copies here.  Remove this if/when we change Reorder()'s\n    // semantics.\n    const auto shape_vec = shape_t->vec<int64>();\n    SparseTensor sp;\n    OP_REQUIRES_OK(ctx, SparseTensor::Create(\n        tensor::DeepCopy(*indices_t), tensor::DeepCopy(*values_t),\n                    TensorShape(shape_vec), &sp));\n    ReduceDetails reduction = SparseTensorReduceHelper(\n        sp, reduction_axes_t->flat<int32>(), keep_dims_);\n\n    Tensor *out_values;\n    OP_REQUIRES_OK(\n        ctx, ctx->allocate_output(0, reduction.reduced_shape, &out_values));\n    auto out_flat = out_values->flat<T>();\n    out_flat.setZero();\n\n    Tensor tmp_reduced_val;\n    OP_REQUIRES_OK(ctx, ctx->allocate_temp(DataTypeToEnum<T>::value,\n                                           TensorShape({}), &tmp_reduced_val));\n    auto reduced_val = tmp_reduced_val.scalar<T>();\n\n    // Compute strides, and use it to convert coords to flat index.  The\n    // coordinates returned by .group() have the same ndims as group_by_dims.\n    gtl::InlinedVector<int64, 8> output_strides(reduction.group_by_dims.size());\n    if (!output_strides.empty()) {  // Do this iff we don't reduce all.\n      output_strides.back() = 1;\n      for (int d = output_strides.size() - 2; d >= 0; --d) {\n        output_strides[d] =\n            output_strides[d + 1] * shape_vec(reduction.group_by_dims[d + 1]);\n      }\n    }\n\n    auto CoordinatesToFlatIndex = [](ArraySlice<int64> coords,\n                                     ArraySlice<int64> strides) -> int64 {\n      if (strides.empty()) {  // Reduce all.\n        return 0;\n      }\n      CHECK_EQ(coords.size(), strides.size());\n      int64_t idx = 0;\n      for (int i = 0; i < coords.size(); ++i) {\n        idx += coords[i] * strides[i];\n      }\n      return idx;\n    };\n\n    // Each group maps one-on-one onto a value in the reduced tensor.\n    // g.group() provides the coordinates of a particular reduced value.\n    sp.Reorder<T>(reduction.reorder_dims);\n    for (const auto &g : sp.group(reduction.group_by_dims)) {\n      Op::template Run<T>(ctx, reduced_val, g.template values<T>());\n      const int64_t idx = CoordinatesToFlatIndex(g.group(), output_strides);\n      out_flat(idx) = reduced_val();\n      VLOG(2) << \"coords: \" << absl::StrJoin(g.group(), \",\")\n              << \"; idx: \" << idx << \"; group \" << Op::Name() << \": \"\n              << reduced_val();\n    }\n  }",
        "func_hash": 226769425429975920381040402527052798393,
        "file_name": "sparse_reduce_op.cc",
        "file_hash": 21049285234129890276227338943103143863,
        "cwe": [
            "CWE-125"
        ],
        "cve": "CVE-2021-37635",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions the implementation of sparse reduction operations in TensorFlow can trigger accesses outside of bounds of heap allocated data. The [implementation](https://github.com/tensorflow/tensorflow/blob/a1bc56203f21a5a4995311825ffaba7a670d7747/tensorflow/core/kernels/sparse_reduce_op.cc#L217-L228) fails to validate that each reduction group does not overflow and that each corresponding index does not point to outside the bounds of the input tensor. We have patched the issue in GitHub commit 87158f43f05f2720a374f3e6d22a7aaa3a33f750. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37635",
        "func_name": "Compute",
        "diff": [
            "diff --git a/tensorflow/core/kernels/sparse_reduce_op.cc b/tensorflow/core/kernels/sparse_reduce_op.cc\nindex 668ea5ae54084c..430be0a271742e 100644\n--- a/tensorflow/core/kernels/sparse_reduce_op.cc\n+++ b/tensorflow/core/kernels/sparse_reduce_op.cc\n@@ -219,7 +219,20 @@ class SparseReduceOp : public OpKernel {\n     sp.Reorder<T>(reduction.reorder_dims);\n     for (const auto &g : sp.group(reduction.group_by_dims)) {\n       Op::template Run<T>(ctx, reduced_val, g.template values<T>());\n+      OP_REQUIRES(ctx,\n+                  output_strides.empty() ||\n+                  (g.group().size() == output_strides.size()),\n+                  errors::Internal(\n+                      \"Expected group size and output_strides size to match\",\n+                      \", but got \", g.group().size(), \" and \",\n+                      output_strides.size()));\n       const int64_t idx = CoordinatesToFlatIndex(g.group(), output_strides);\n+      OP_REQUIRES(ctx,\n+                  idx >= 0 && idx < out_flat.size(),\n+                  errors::Internal(\n+                      \"Obtained a write index of \", idx,\n+                      \" which is outside of bounds of [0, \",\n+                      out_flat.size(), \")\"));\n       out_flat(idx) = reduced_val();\n       VLOG(2) << \"coords: \" << absl::StrJoin(g.group(), \",\")\n               << \"; idx: \" << idx << \"; group \" << Op::Name() << \": \"\n"
        ],
        "func_after": []
    },
    {
        "idx": 198117,
        "project": "tensorflow",
        "commit_id": "0f931751fb20f565c4e94aa6df58d54a003cdb30",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/0f931751fb20f565c4e94aa6df58d54a003cdb30",
        "commit_message": "Validate dimensions of input tensor in `FractionalAvgPoolGrad`\n\nPiperOrigin-RevId: 388286227\nChange-Id: Ieb7566155e92acc8993a2212c76deacadc0edc8a",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext* context) override {\n    // Here's the basic idea:\n    // Batch and depth dimension are independent from row and col dimension. And\n    // because FractionalAvgPool currently only support pooling along row and\n    // col, we can basically think of this 4D tensor backpropagation as\n    // operation of a series of 2D planes.\n    //\n    // For each element of a 'slice' (2D plane) of output_backprop, we need to\n    // figure out its contributors when doing FractionalAvgPool operation. This\n    // can be done based on row_pooling_sequence, col_pooling_seq and\n    // overlapping.\n    // Once we figure out the original contributors, we just need to evenly\n    // divide the value of this element among these contributors.\n    //\n    // Internally, we divide the out_backprop tensor and store it in a temporary\n    // tensor of double type. And cast it to the corresponding type.\n    typedef Eigen::Map<const Eigen::Matrix<T, Eigen::Dynamic, Eigen::Dynamic>>\n        ConstEigenMatrixMap;\n    typedef Eigen::Map<Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic>>\n        EigenDoubleMatrixMap;\n\n    // Grab the inputs.\n    const Tensor& orig_input_tensor_shape = context->input(0);\n    OP_REQUIRES(context,\n                orig_input_tensor_shape.dims() == 1 &&\n                    orig_input_tensor_shape.NumElements() == 4,\n                errors::InvalidArgument(\"original input tensor shape must be\"\n                                        \"1-dimensional and 4 elements\"));\n    const Tensor& out_backprop = context->input(1);\n    const Tensor& row_seq_tensor = context->input(2);\n    const Tensor& col_seq_tensor = context->input(3);\n\n    const int64_t out_batch = out_backprop.dim_size(0);\n    const int64_t out_rows = out_backprop.dim_size(1);\n    const int64_t out_cols = out_backprop.dim_size(2);\n    const int64_t out_depth = out_backprop.dim_size(3);\n\n    OP_REQUIRES(context, row_seq_tensor.NumElements() > out_rows,\n                errors::InvalidArgument(\"Given out_backprop shape \",\n                                        out_backprop.shape().DebugString(),\n                                        \", row_seq_tensor must have at least \",\n                                        out_rows + 1, \" elements, but got \",\n                                        row_seq_tensor.NumElements()));\n    OP_REQUIRES(context, col_seq_tensor.NumElements() > out_cols,\n                errors::InvalidArgument(\"Given out_backprop shape \",\n                                        out_backprop.shape().DebugString(),\n                                        \", col_seq_tensor must have at least \",\n                                        out_cols + 1, \" elements, but got \",\n                                        col_seq_tensor.NumElements()));\n\n    auto row_seq_tensor_flat = row_seq_tensor.flat<int64>();\n    auto col_seq_tensor_flat = col_seq_tensor.flat<int64>();\n    auto orig_input_tensor_shape_flat = orig_input_tensor_shape.flat<int64>();\n\n    const int64_t in_batch = orig_input_tensor_shape_flat(0);\n    const int64_t in_rows = orig_input_tensor_shape_flat(1);\n    const int64_t in_cols = orig_input_tensor_shape_flat(2);\n    const int64_t in_depth = orig_input_tensor_shape_flat(3);\n\n    constexpr int tensor_in_and_out_dims = 4;\n    // Transform orig_input_tensor_shape into TensorShape\n    TensorShape in_shape;\n    for (auto i = 0; i < tensor_in_and_out_dims; ++i) {\n      in_shape.AddDim(orig_input_tensor_shape_flat(i));\n    }\n\n    // Create intermediate in_backprop.\n    Tensor in_backprop_tensor_temp;\n    OP_REQUIRES_OK(context, context->forward_input_or_allocate_temp(\n                                {0}, DataTypeToEnum<double>::v(), in_shape,\n                                &in_backprop_tensor_temp));\n    in_backprop_tensor_temp.flat<double>().setZero();\n    // Transform 4D tensor to 2D matrix.\n    EigenDoubleMatrixMap in_backprop_tensor_temp_mat(\n        in_backprop_tensor_temp.flat<double>().data(), in_depth,\n        in_cols * in_rows * in_batch);\n    ConstEigenMatrixMap out_backprop_mat(out_backprop.flat<T>().data(),\n                                         out_depth,\n                                         out_cols * out_rows * out_batch);\n    // Loop through each element of out_backprop and evenly distribute the\n    // element to the corresponding pooling cell.\n    const int64_t in_max_row_index = in_rows - 1;\n    const int64_t in_max_col_index = in_cols - 1;\n    for (int64_t b = 0; b < out_batch; ++b) {\n      for (int64_t r = 0; r < out_rows; ++r) {\n        const int64_t in_row_start = row_seq_tensor_flat(r);\n        int64_t in_row_end = overlapping_ ? row_seq_tensor_flat(r + 1)\n                                          : row_seq_tensor_flat(r + 1) - 1;\n        in_row_end = std::min(in_row_end, in_max_row_index);\n        for (int64_t c = 0; c < out_cols; ++c) {\n          const int64_t in_col_start = col_seq_tensor_flat(c);\n          int64_t in_col_end = overlapping_ ? col_seq_tensor_flat(c + 1)\n                                            : col_seq_tensor_flat(c + 1) - 1;\n          in_col_end = std::min(in_col_end, in_max_col_index);\n\n          const int64_t num_elements_in_pooling_cell =\n              (in_row_end - in_row_start + 1) * (in_col_end - in_col_start + 1);\n          const int64_t out_index = (b * out_rows + r) * out_cols + c;\n          // Now we can evenly distribute out_backprop(b, h, w, *) to\n          // in_backprop(b, hs:he, ws:we, *).\n          for (int64_t in_r = in_row_start; in_r <= in_row_end; ++in_r) {\n            for (int64_t in_c = in_col_start; in_c <= in_col_end; ++in_c) {\n              const int64_t in_index = (b * in_rows + in_r) * in_cols + in_c;\n              // Walk through each channel (depth).\n              for (int64_t d = 0; d < out_depth; ++d) {\n                const double out_backprop_element = static_cast<double>(\n                    out_backprop_mat.coeffRef(d, out_index));\n                double& in_backprop_ref =\n                    in_backprop_tensor_temp_mat.coeffRef(d, in_index);\n                in_backprop_ref +=\n                    out_backprop_element / num_elements_in_pooling_cell;\n              }\n            }\n          }\n        }\n      }\n    }\n\n    // Depending on the type, cast double to type T.\n    Tensor* in_backprop_tensor = nullptr;\n    OP_REQUIRES_OK(context, context->forward_input_or_allocate_output(\n                                {0}, 0, in_shape, &in_backprop_tensor));\n    auto in_backprop_tensor_flat = in_backprop_tensor->flat<T>();\n    auto in_backprop_tensor_temp_flat = in_backprop_tensor_temp.flat<double>();\n    for (int64_t i = 0; i < in_backprop_tensor_flat.size(); ++i) {\n      in_backprop_tensor_flat(i) =\n          static_cast<T>(in_backprop_tensor_temp_flat(i));\n    }\n  }",
        "func_hash": 1946187127976060435937085266146503817,
        "file_name": "fractional_avg_pool_op.cc",
        "file_hash": 123284094403203358257933187084228510511,
        "cwe": [
            "CWE-476"
        ],
        "cve": "CVE-2021-37651",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions the implementation for `tf.raw_ops.FractionalAvgPoolGrad` can be tricked into accessing data outside of bounds of heap allocated buffers. The [implementation](https://github.com/tensorflow/tensorflow/blob/f24faa153ad31a4b51578f8181d3aaab77a1ddeb/tensorflow/core/kernels/fractional_avg_pool_op.cc#L205) does not validate that the input tensor is non-empty. Thus, code constructs an empty `EigenDoubleMatrixMap` and then accesses this buffer with indices that are outside of the empty area. We have patched the issue in GitHub commit 0f931751fb20f565c4e94aa6df58d54a003cdb30. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37651",
        "func_name": "Compute",
        "diff": [
            "diff --git a/tensorflow/core/kernels/fractional_avg_pool_op.cc b/tensorflow/core/kernels/fractional_avg_pool_op.cc\nindex 3c80e87bcf76dc..63f8d67d93cc47 100644\n--- a/tensorflow/core/kernels/fractional_avg_pool_op.cc\n+++ b/tensorflow/core/kernels/fractional_avg_pool_op.cc\n@@ -271,6 +271,18 @@ class FractionalAvgPoolGradOp : public OpKernel {\n     const int64_t in_rows = orig_input_tensor_shape_flat(1);\n     const int64_t in_cols = orig_input_tensor_shape_flat(2);\n     const int64_t in_depth = orig_input_tensor_shape_flat(3);\n+    OP_REQUIRES(\n+        context, in_batch != 0,\n+        errors::InvalidArgument(\"Batch dimension of input must not be 0\"));\n+    OP_REQUIRES(\n+        context, in_rows != 0,\n+        errors::InvalidArgument(\"Rows dimension of input must not be 0\"));\n+    OP_REQUIRES(\n+        context, in_cols != 0,\n+        errors::InvalidArgument(\"Columns dimension of input must not be 0\"));\n+    OP_REQUIRES(\n+        context, in_depth != 0,\n+        errors::InvalidArgument(\"Depth dimension of input must not be 0\"));\n \n     constexpr int tensor_in_and_out_dims = 4;\n     // Transform orig_input_tensor_shape into TensorShape\n"
        ],
        "func_after": []
    },
    {
        "idx": 198146,
        "project": "tensorflow",
        "commit_id": "429f009d2b2c09028647dd4bb7b3f6f414bbaad7",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/429f009d2b2c09028647dd4bb7b3f6f414bbaad7",
        "commit_message": "Add remaining missing validation to `BoostedTreesCalculateBestFeatureSplit`\n\nPiperOrigin-RevId: 387423006\nChange-Id: I8eaf30efb223011519e60707bfa751b275d3a443",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext* const context) override {\n    // node_id_range\n    const Tensor* node_id_range_t;\n    OP_REQUIRES_OK(context, context->input(\"node_id_range\", &node_id_range_t));\n    const auto node_id_range = node_id_range_t->vec<int32>();\n    const int32_t node_id_first = node_id_range(0);  // inclusive\n    const int32_t node_id_last = node_id_range(1);   // exclusive\n\n    const Tensor* stats_summary_t;\n    OP_REQUIRES_OK(context, context->input(\"stats_summary\", &stats_summary_t));\n    TTypes<float, 4>::ConstTensor stats_summary =\n        stats_summary_t->tensor<float, 4>();\n    const int32_t feature_dims = stats_summary_t->dim_size(1);\n    // The last bucket is for default/missing value.\n    const int32_t num_buckets = stats_summary_t->dim_size(2) - 1;\n    const int32_t logits_dim = logits_dim_;\n    const int32_t hessian_dim = stats_summary_t->dim_size(3) - logits_dim;\n    DCHECK_GT(hessian_dim, 0);\n    DCHECK_LE(hessian_dim, logits_dim * logits_dim);\n\n    const Tensor* l1_t;\n    OP_REQUIRES_OK(context, context->input(\"l1\", &l1_t));\n    const auto l1 = l1_t->scalar<float>()();\n    DCHECK_GE(l1, 0);\n    if (logits_dim_ > 1) {\n      // Multi-class L1 regularization not supported yet.\n      DCHECK_EQ(l1, 0);\n    }\n\n    const Tensor* l2_t;\n    OP_REQUIRES_OK(context, context->input(\"l2\", &l2_t));\n    const auto l2 = l2_t->scalar<float>()();\n    DCHECK_GE(l2, 0);\n\n    const Tensor* tree_complexity_t;\n    OP_REQUIRES_OK(context,\n                   context->input(\"tree_complexity\", &tree_complexity_t));\n    const auto tree_complexity = tree_complexity_t->scalar<float>()();\n\n    const Tensor* min_node_weight_t;\n    OP_REQUIRES_OK(context,\n                   context->input(\"min_node_weight\", &min_node_weight_t));\n    const auto min_node_weight = min_node_weight_t->scalar<float>()();\n\n    std::vector<int32> output_node_ids;\n    std::vector<float> output_gains;\n    std::vector<int32> output_feature_dimensions;\n    std::vector<int32> output_thresholds;\n    std::vector<Eigen::VectorXf> output_left_node_contribs;\n    std::vector<Eigen::VectorXf> output_right_node_contribs;\n    std::vector<string> output_split_types;\n\n    // TODO(tanzheny) parallelize the computation.\n    // Iterate each node and find the best gain per node.\n    for (int32_t node_id = node_id_first; node_id < node_id_last; ++node_id) {\n      float best_gain = std::numeric_limits<float>::lowest();\n      int32_t best_bucket = 0;\n      int32_t best_f_dim = 0;\n      string best_split_type;\n      Eigen::VectorXf best_contrib_for_left(logits_dim);\n      Eigen::VectorXf best_contrib_for_right(logits_dim);\n      float parent_gain;\n\n      // Including default bucket.\n      ConstMatrixMap stats_mat(&stats_summary(node_id, 0, 0, 0),\n                               num_buckets + 1, logits_dim + hessian_dim);\n      const Eigen::VectorXf total_grad =\n          stats_mat.leftCols(logits_dim).colwise().sum();\n      const Eigen::VectorXf total_hess =\n          stats_mat.rightCols(hessian_dim).colwise().sum();\n      if (total_hess.norm() < min_node_weight) {\n        continue;\n      }\n      Eigen::VectorXf parent_weight(logits_dim);\n      CalculateWeightsAndGains(total_grad, total_hess, l1, l2, &parent_weight,\n                               &parent_gain);\n\n      if (split_type_ == \"inequality\") {\n        CalculateBestInequalitySplit(\n            stats_summary, node_id, feature_dims, logits_dim, hessian_dim,\n            num_buckets, min_node_weight, l1, l2, &best_gain, &best_bucket,\n            &best_f_dim, &best_split_type, &best_contrib_for_left,\n            &best_contrib_for_right);\n      } else {\n        CalculateBestEqualitySplit(\n            stats_summary, total_grad, total_hess, node_id, feature_dims,\n            logits_dim, hessian_dim, num_buckets, l1, l2, &best_gain,\n            &best_bucket, &best_f_dim, &best_split_type, &best_contrib_for_left,\n            &best_contrib_for_right);\n      }\n\n      if (best_gain == std::numeric_limits<float>::lowest()) {\n        // Do not add the node if not split if found.\n        continue;\n      }\n      output_node_ids.push_back(node_id);\n      // Remove the parent gain for the parent node.\n      output_gains.push_back(best_gain - parent_gain);\n      output_feature_dimensions.push_back(best_f_dim);\n      // default direction is fixed for dense splits.\n      // TODO(tanzheny) account for default values.\n      output_split_types.push_back(best_split_type);\n      output_thresholds.push_back(best_bucket);\n      output_left_node_contribs.push_back(best_contrib_for_left);\n      output_right_node_contribs.push_back(best_contrib_for_right);\n    }  // for node id\n    const int num_nodes = output_node_ids.size();\n    // output_node_ids\n    Tensor* output_node_ids_t = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(\"node_ids\", {num_nodes},\n                                                     &output_node_ids_t));\n    auto output_node_ids_vec = output_node_ids_t->vec<int32>();\n\n    // output_gains\n    Tensor* output_gains_t;\n    OP_REQUIRES_OK(context, context->allocate_output(\"gains\", {num_nodes},\n                                                     &output_gains_t));\n    auto output_gains_vec = output_gains_t->vec<float>();\n\n    // output_feature_dimensions\n    Tensor* output_feature_dimension_t;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(\"feature_dimensions\", {num_nodes},\n                                            &output_feature_dimension_t));\n    auto output_feature_dimensions_vec =\n        output_feature_dimension_t->vec<int32>();\n\n    // output_thresholds\n    Tensor* output_thresholds_t;\n    OP_REQUIRES_OK(context, context->allocate_output(\"thresholds\", {num_nodes},\n                                                     &output_thresholds_t));\n    auto output_thresholds_vec = output_thresholds_t->vec<int32>();\n\n    // output_left_node_contribs\n    Tensor* output_left_node_contribs_t;\n    OP_REQUIRES_OK(context, context->allocate_output(\n                                \"left_node_contribs\", {num_nodes, logits_dim},\n                                &output_left_node_contribs_t));\n    auto output_left_node_contribs_matrix =\n        output_left_node_contribs_t->matrix<float>();\n\n    // output_right_node_contribs\n    Tensor* output_right_node_contribs_t;\n    OP_REQUIRES_OK(context, context->allocate_output(\n                                \"right_node_contribs\", {num_nodes, logits_dim},\n                                &output_right_node_contribs_t));\n    auto output_right_node_contribs_matrix =\n        output_right_node_contribs_t->matrix<float>();\n\n    // split type\n    Tensor* output_split_types_t;\n    OP_REQUIRES_OK(\n        context, context->allocate_output(\"split_with_default_directions\",\n                                          {num_nodes}, &output_split_types_t));\n    auto output_split_types_vec = output_split_types_t->vec<tstring>();\n\n    // Sets output tensors from vectors.\n    for (int i = 0; i < num_nodes; ++i) {\n      output_node_ids_vec(i) = output_node_ids[i];\n      // Adjust the gains to penalize by tree complexity.\n      output_gains_vec(i) = output_gains[i] - tree_complexity;\n      output_feature_dimensions_vec(i) = output_feature_dimensions[i];\n      output_thresholds_vec(i) = output_thresholds[i];\n      for (int j = 0; j < logits_dim; ++j) {\n        output_left_node_contribs_matrix(i, j) =\n            output_left_node_contribs[i][j];\n        output_right_node_contribs_matrix(i, j) =\n            output_right_node_contribs[i][j];\n      }\n      output_split_types_vec(i) = output_split_types[i];\n    }\n  }",
        "func_hash": 329288218153569846583726994870166814749,
        "file_name": "stats_ops.cc",
        "file_hash": 99816312750255630357955125041994485531,
        "cwe": [
            "CWE-824"
        ],
        "cve": "CVE-2021-37662",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions an attacker can generate undefined behavior via a reference binding to nullptr in `BoostedTreesCalculateBestGainsPerFeature` and similar attack can occur in `BoostedTreesCalculateBestFeatureSplitV2`. The [implementation](https://github.com/tensorflow/tensorflow/blob/84d053187cb80d975ef2b9684d4b61981bca0c41/tensorflow/core/kernels/boosted_trees/stats_ops.cc) does not validate the input values. We have patched the issue in GitHub commit 9c87c32c710d0b5b53dc6fd3bfde4046e1f7a5ad and in commit 429f009d2b2c09028647dd4bb7b3f6f414bbaad7. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37662",
        "func_name": "Compute",
        "diff": [
            "diff --git a/tensorflow/core/kernels/boosted_trees/stats_ops.cc b/tensorflow/core/kernels/boosted_trees/stats_ops.cc\nindex 2636909855a386..60c1d191f5232c 100644\n--- a/tensorflow/core/kernels/boosted_trees/stats_ops.cc\n+++ b/tensorflow/core/kernels/boosted_trees/stats_ops.cc\n@@ -14,6 +14,7 @@ limitations under the License.\n ==============================================================================*/\n \n #include <limits>\n+#include <string>\n #include <vector>\n \n #include \"third_party/eigen3/Eigen/Core\"\n@@ -22,6 +23,7 @@ limitations under the License.\n #include \"tensorflow/core/framework/tensor_shape.h\"\n #include \"tensorflow/core/kernels/boosted_trees/boosted_trees.pb.h\"\n #include \"tensorflow/core/kernels/boosted_trees/tree_helper.h\"\n+#include \"tensorflow/core/platform/errors.h\"\n #include \"tensorflow/core/platform/logging.h\"\n \n namespace tensorflow {\n@@ -254,12 +256,18 @@ class BoostedTreesCalculateBestFeatureSplitOp : public OpKernel {\n     // node_id_range\n     const Tensor* node_id_range_t;\n     OP_REQUIRES_OK(context, context->input(\"node_id_range\", &node_id_range_t));\n+    OP_REQUIRES(\n+        context, node_id_range_t->NumElements() == 2,\n+        errors::InvalidArgument(\"node_id_range argument must have shape [2]\"));\n     const auto node_id_range = node_id_range_t->vec<int32>();\n     const int32_t node_id_first = node_id_range(0);  // inclusive\n     const int32_t node_id_last = node_id_range(1);   // exclusive\n \n     const Tensor* stats_summary_t;\n     OP_REQUIRES_OK(context, context->input(\"stats_summary\", &stats_summary_t));\n+    OP_REQUIRES(\n+        context, stats_summary_t->shape().dims() == 4,\n+        errors::InvalidArgument(\"stats_summary argument must have rank 4\"));\n     TTypes<float, 4>::ConstTensor stats_summary =\n         stats_summary_t->tensor<float, 4>();\n     const int32_t feature_dims = stats_summary_t->dim_size(1);\n@@ -272,6 +280,8 @@ class BoostedTreesCalculateBestFeatureSplitOp : public OpKernel {\n \n     const Tensor* l1_t;\n     OP_REQUIRES_OK(context, context->input(\"l1\", &l1_t));\n+    OP_REQUIRES(context, l1_t->NumElements() == 1,\n+                errors::InvalidArgument(\"l1 argument must be a scalar\"));\n     const auto l1 = l1_t->scalar<float>()();\n     DCHECK_GE(l1, 0);\n     if (logits_dim_ > 1) {\n@@ -281,17 +291,25 @@ class BoostedTreesCalculateBestFeatureSplitOp : public OpKernel {\n \n     const Tensor* l2_t;\n     OP_REQUIRES_OK(context, context->input(\"l2\", &l2_t));\n+    OP_REQUIRES(context, l2_t->NumElements() == 1,\n+                errors::InvalidArgument(\"l2 argument must be a scalar\"));\n     const auto l2 = l2_t->scalar<float>()();\n     DCHECK_GE(l2, 0);\n \n     const Tensor* tree_complexity_t;\n     OP_REQUIRES_OK(context,\n                    context->input(\"tree_complexity\", &tree_complexity_t));\n+    OP_REQUIRES(\n+        context, tree_complexity_t->NumElements() == 1,\n+        errors::InvalidArgument(\"tree_complexity argument must be a scalar\"));\n     const auto tree_complexity = tree_complexity_t->scalar<float>()();\n \n     const Tensor* min_node_weight_t;\n     OP_REQUIRES_OK(context,\n                    context->input(\"min_node_weight\", &min_node_weight_t));\n+    OP_REQUIRES(\n+        context, min_node_weight_t->NumElements() == 1,\n+        errors::InvalidArgument(\"min_node_weight argument must be a scalar\"));\n     const auto min_node_weight = min_node_weight_t->scalar<float>()();\n \n     std::vector<int32> output_node_ids;\n@@ -300,7 +318,7 @@ class BoostedTreesCalculateBestFeatureSplitOp : public OpKernel {\n     std::vector<int32> output_thresholds;\n     std::vector<Eigen::VectorXf> output_left_node_contribs;\n     std::vector<Eigen::VectorXf> output_right_node_contribs;\n-    std::vector<string> output_split_types;\n+    std::vector<std::string> output_split_types;\n \n     // TODO(tanzheny) parallelize the computation.\n     // Iterate each node and find the best gain per node.\n"
        ],
        "func_after": []
    },
    {
        "idx": 198161,
        "project": "ImageMagick",
        "commit_id": "a6240a163cb787909703d9fc649cf861f60ddd7c",
        "project_url": "https://github.com/ImageMagick/ImageMagick",
        "commit_url": "https://github.com/ImageMagick/ImageMagick/commit/a6240a163cb787909703d9fc649cf861f60ddd7c",
        "commit_message": "https://github.com/ImageMagick/ImageMagick/issues/131",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static Image *ReadMATImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n  Image *image, *image2=NULL,\n   *rotated_image;\n  register Quantum *q;\n\n  unsigned int status;\n  MATHeader MATLAB_HDR;\n  size_t size;  \n  size_t CellType;\n  QuantumInfo *quantum_info;\n  ImageInfo *clone_info;\n  int i;\n  ssize_t ldblk;\n  unsigned char *BImgBuff = NULL;\n  double MinVal, MaxVal;\n  unsigned z, z2;\n  unsigned Frames;\n  int logging;\n  int sample_size;\n  MagickOffsetType filepos=0x80;\n  BlobInfo *blob;\n  size_t one;\n  \n  unsigned int (*ReadBlobXXXLong)(Image *image);\n  unsigned short (*ReadBlobXXXShort)(Image *image);\n  void (*ReadBlobDoublesXXX)(Image * image, size_t len, double *data);\n  void (*ReadBlobFloatsXXX)(Image * image, size_t len, float *data);\n\n\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  logging = LogMagickEvent(CoderEvent,GetMagickModule(),\"enter\"); \n\n  /*\n     Open image file.\n   */\n  image = AcquireImage(image_info,exception);\n\n  status = OpenBlob(image_info, image, ReadBinaryBlobMode, exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n     Read MATLAB image.\n   */\n  clone_info=CloneImageInfo(image_info);\n  if(ReadBlob(image,124,(unsigned char *) &MATLAB_HDR.identific) != 124)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  MATLAB_HDR.Version = ReadBlobLSBShort(image);\n  if(ReadBlob(image,2,(unsigned char *) &MATLAB_HDR.EndianIndicator) != 2)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n\n  if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\"  Endian %c%c\",\n        MATLAB_HDR.EndianIndicator[0],MATLAB_HDR.EndianIndicator[1]);\n  if (!strncmp(MATLAB_HDR.EndianIndicator, \"IM\", 2))\n  {\n    ReadBlobXXXLong = ReadBlobLSBLong;\n    ReadBlobXXXShort = ReadBlobLSBShort;\n    ReadBlobDoublesXXX = ReadBlobDoublesLSB;\n    ReadBlobFloatsXXX = ReadBlobFloatsLSB;\n    image->endian = LSBEndian;\n  } \n  else if (!strncmp(MATLAB_HDR.EndianIndicator, \"MI\", 2))\n  {\n    ReadBlobXXXLong = ReadBlobMSBLong;\n    ReadBlobXXXShort = ReadBlobMSBShort;\n    ReadBlobDoublesXXX = ReadBlobDoublesMSB;\n    ReadBlobFloatsXXX = ReadBlobFloatsMSB;\n    image->endian = MSBEndian;\n  }\n  else \n    goto MATLAB_KO;    /* unsupported endian */\n\n  if (strncmp(MATLAB_HDR.identific, \"MATLAB\", 6))\nMATLAB_KO: ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n\n  filepos = TellBlob(image);\n  while(!EOFBlob(image)) /* object parser loop */\n  {\n    Frames = 1;\n    (void) SeekBlob(image,filepos,SEEK_SET);\n    /* printf(\"pos=%X\\n\",TellBlob(image)); */\n\n    MATLAB_HDR.DataType = ReadBlobXXXLong(image);\n    if(EOFBlob(image)) break;\n    MATLAB_HDR.ObjectSize = ReadBlobXXXLong(image);\n    if(EOFBlob(image)) break;\n    filepos += MATLAB_HDR.ObjectSize + 4 + 4;\n\n    image2 = image;\n#if defined(MAGICKCORE_ZLIB_DELEGATE)\n    if(MATLAB_HDR.DataType == miCOMPRESSED)\n    {\n      image2 = DecompressBlock(image,MATLAB_HDR.ObjectSize,clone_info,exception);\n      if(image2==NULL) continue;\n      MATLAB_HDR.DataType = ReadBlobXXXLong(image2); /* replace compressed object type. */\n    }\n#endif    \n\n    if(MATLAB_HDR.DataType!=miMATRIX) continue;  /* skip another objects. */\n \n    MATLAB_HDR.unknown1 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.unknown2 = ReadBlobXXXLong(image2);  \n\n    MATLAB_HDR.unknown5 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.StructureClass = MATLAB_HDR.unknown5 & 0xFF;\n    MATLAB_HDR.StructureFlag = (MATLAB_HDR.unknown5>>8) & 0xFF;  \n\n    MATLAB_HDR.unknown3 = ReadBlobXXXLong(image2);\n    if(image!=image2)\n      MATLAB_HDR.unknown4 = ReadBlobXXXLong(image2);  /* ??? don't understand why ?? */\n    MATLAB_HDR.unknown4 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.DimFlag = ReadBlobXXXLong(image2);\n    MATLAB_HDR.SizeX = ReadBlobXXXLong(image2);\n    MATLAB_HDR.SizeY = ReadBlobXXXLong(image2);  \n   \n\n    switch(MATLAB_HDR.DimFlag)\n    {     \n      case  8: z2=z=1; break;      /* 2D matrix*/\n      case 12: z2=z = ReadBlobXXXLong(image2);  /* 3D matrix RGB*/\n           (void) ReadBlobXXXLong(image2);\n         if(z!=3) ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n         break;\n      case 16: z2=z = ReadBlobXXXLong(image2);  /* 4D matrix animation */\n         if(z!=3 && z!=1)\n            ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n           Frames = ReadBlobXXXLong(image2);\n         break;\n      default: ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n    }  \n\n    MATLAB_HDR.Flag1 = ReadBlobXXXShort(image2);\n    MATLAB_HDR.NameFlag = ReadBlobXXXShort(image2);\n\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"MATLAB_HDR.StructureClass %d\",MATLAB_HDR.StructureClass);\n    if (MATLAB_HDR.StructureClass != mxCHAR_CLASS && \n        MATLAB_HDR.StructureClass != mxSINGLE_CLASS &&    /* float + complex float */\n        MATLAB_HDR.StructureClass != mxDOUBLE_CLASS &&    /* double + complex double */\n        MATLAB_HDR.StructureClass != mxINT8_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT8_CLASS &&    /* uint8 + uint8 3D */\n        MATLAB_HDR.StructureClass != mxINT16_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT16_CLASS &&    /* uint16 + uint16 3D */\n        MATLAB_HDR.StructureClass != mxINT32_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT32_CLASS &&    /* uint32 + uint32 3D */\n        MATLAB_HDR.StructureClass != mxINT64_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT64_CLASS)    /* uint64 + uint64 3D */\n      ThrowReaderException(CoderError,\"UnsupportedCellTypeInTheMatrix\");\n\n    switch (MATLAB_HDR.NameFlag)\n    {\n      case 0:\n        size = ReadBlobXXXLong(image2);  /* Object name string size */\n        size = 4 * (ssize_t) ((size + 3 + 1) / 4);\n        (void) SeekBlob(image2, size, SEEK_CUR);\n        break;\n      case 1:\n      case 2:\n      case 3:\n      case 4:\n        (void) ReadBlob(image2, 4, (unsigned char *) &size); /* Object name string */\n        break;\n      default:\n        goto MATLAB_KO;\n    }\n\n    CellType = ReadBlobXXXLong(image2);    /* Additional object type */\n    if (logging)\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"MATLAB_HDR.CellType: %.20g\",(double) CellType);\n  \n    (void) ReadBlob(image2, 4, (unsigned char *) &size);     /* data size */\n\n    NEXT_FRAME:\n    switch (CellType)\n    {\n      case miINT8:\n      case miUINT8:\n        sample_size = 8;\n        if(MATLAB_HDR.StructureFlag & FLAG_LOGICAL) \n          image->depth = 1;\n        else\n          image->depth = 8;         /* Byte type cell */\n        ldblk = (ssize_t) MATLAB_HDR.SizeX;      \n        break;\n      case miINT16:\n      case miUINT16:\n        sample_size = 16;\n        image->depth = 16;        /* Word type cell */\n        ldblk = (ssize_t) (2 * MATLAB_HDR.SizeX);\n        break;\n      case miINT32:\n      case miUINT32:\n        sample_size = 32;\n        image->depth = 32;        /* Dword type cell */\n        ldblk = (ssize_t) (4 * MATLAB_HDR.SizeX);      \n        break;\n      case miINT64:\n      case miUINT64:\n        sample_size = 64;\n        image->depth = 64;        /* Qword type cell */\n        ldblk = (ssize_t) (8 * MATLAB_HDR.SizeX);      \n        break;   \n      case miSINGLE:\n        sample_size = 32;\n        image->depth = 32;        /* double type cell */\n        (void) SetImageOption(clone_info,\"quantum:format\",\"floating-point\");\n        if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n  {              /* complex float type cell */\n  }\n        ldblk = (ssize_t) (4 * MATLAB_HDR.SizeX);\n        break;\n      case miDOUBLE:\n        sample_size = 64; \n        image->depth = 64;        /* double type cell */\n        (void) SetImageOption(clone_info,\"quantum:format\",\"floating-point\");\nDisableMSCWarning(4127)\n        if (sizeof(double) != 8)\nRestoreMSCWarning\n          ThrowReaderException(CoderError, \"IncompatibleSizeOfDouble\");\n        if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n  {                         /* complex double type cell */        \n  }\n        ldblk = (ssize_t) (8 * MATLAB_HDR.SizeX);\n        break;\n      default:\n        ThrowReaderException(CoderError, \"UnsupportedCellTypeInTheMatrix\");\n    }\n    (void) sample_size;\n    image->columns = MATLAB_HDR.SizeX;\n    image->rows = MATLAB_HDR.SizeY;    \n    quantum_info=AcquireQuantumInfo(clone_info,image);\n    if (quantum_info == (QuantumInfo *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    one=1;\n    image->colors = one << image->depth;\n    if (image->columns == 0 || image->rows == 0)\n      goto MATLAB_KO;\n    /* Image is gray when no complex flag is set and 2D Matrix */\n    if ((MATLAB_HDR.DimFlag == 8) &&\n        ((MATLAB_HDR.StructureFlag & FLAG_COMPLEX) == 0))\n      {\n        image->type=GrayscaleType;\n        SetImageColorspace(image,GRAYColorspace,exception);\n      }\n\n\n    /*\n      If ping is true, then only set image size and colors without\n      reading any image data.\n    */\n    if (image_info->ping)\n    {\n      size_t temp = image->columns;\n      image->columns = image->rows;\n      image->rows = temp;\n      goto done_reading; /* !!!!!! BAD  !!!! */\n    }  \n    status=SetImageExtent(image,image->columns,image->rows,exception);\n    if (status == MagickFalse)\n      return(DestroyImageList(image));\n\n  /* ----- Load raster data ----- */\n    BImgBuff = (unsigned char *) AcquireQuantumMemory((size_t) (ldblk),sizeof(double));    /* Ldblk was set in the check phase */\n    if (BImgBuff == NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n\n    MinVal = 0;\n    MaxVal = 0;\n    if (CellType==miDOUBLE || CellType==miSINGLE)        /* Find Min and Max Values for floats */\n    {\n      CalcMinMax(image2, image_info->endian,  MATLAB_HDR.SizeX, MATLAB_HDR.SizeY, CellType, ldblk, BImgBuff, &quantum_info->minimum, &quantum_info->maximum);\n    }\n\n    /* Main loop for reading all scanlines */\n    if(z==1) z=0; /* read grey scanlines */\n    /* else read color scanlines */\n    do\n    {\n      for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n      {\n        q=GetAuthenticPixels(image,0,MATLAB_HDR.SizeY-i-1,image->columns,1,exception);\n        if (q == (Quantum *) NULL)\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"  MAT set image pixels returns unexpected NULL on a row %u.\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto done_reading;    /* Skip image rotation, when cannot set image pixels    */\n  }\n        if(ReadBlob(image2,ldblk,(unsigned char *)BImgBuff) != (ssize_t) ldblk)\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n             \"  MAT cannot read scanrow %u from a file.\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto ExitLoop;\n  }\n        if((CellType==miINT8 || CellType==miUINT8) && (MATLAB_HDR.StructureFlag & FLAG_LOGICAL))\n        {\n          FixLogical((unsigned char *)BImgBuff,ldblk);\n          if(ImportQuantumPixels(image,(CacheView *) NULL,quantum_info,z2qtype[z],BImgBuff,exception) <= 0)\n    {\nImportQuantumPixelsFailed:\n      if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"  MAT failed to ImportQuantumPixels for a row %u\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n      break;\n    }\n        }\n        else\n        {\n          if(ImportQuantumPixels(image,(CacheView *) NULL,quantum_info,z2qtype[z],BImgBuff,exception) <= 0)\n      goto ImportQuantumPixelsFailed;\n\n\n          if (z<=1 &&       /* fix only during a last pass z==0 || z==1 */\n          (CellType==miINT8 || CellType==miINT16 || CellType==miINT32 || CellType==miINT64))\n      FixSignedValues(image,q,MATLAB_HDR.SizeX);\n        }\n\n        if (!SyncAuthenticPixels(image,exception))\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  MAT failed to sync image pixels for a row %u\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto ExitLoop;\n  }\n      }\n    } while(z-- >= 2);\nExitLoop:\n\n\n    /* Read complex part of numbers here */\n    if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n    {        /* Find Min and Max Values for complex parts of floats */\n      CellType = ReadBlobXXXLong(image2);    /* Additional object type */\n      i = ReadBlobXXXLong(image2);           /* size of a complex part - toss away*/\n\n      if (CellType==miDOUBLE || CellType==miSINGLE)\n      {\n        CalcMinMax(image2,  image_info->endian, MATLAB_HDR.SizeX, MATLAB_HDR.SizeY, CellType, ldblk, BImgBuff, &MinVal, &MaxVal);      \n      }\n\n      if (CellType==miDOUBLE)\n        for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n  {\n          ReadBlobDoublesXXX(image2, ldblk, (double *)BImgBuff);\n          InsertComplexDoubleRow(image, (double *)BImgBuff, i, MinVal, MaxVal,\n            exception);\n  }\n\n      if (CellType==miSINGLE)\n        for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n  {\n          ReadBlobFloatsXXX(image2, ldblk, (float *)BImgBuff);\n          InsertComplexFloatRow(image,(float *)BImgBuff,i,MinVal,MaxVal,\n            exception);\n  }    \n    }\n\n      /* Image is gray when no complex flag is set and 2D Matrix AGAIN!!! */\n    if ((MATLAB_HDR.DimFlag == 8) &&\n        ((MATLAB_HDR.StructureFlag & FLAG_COMPLEX) == 0))\n      image->type=GrayscaleType;\n    if (image->depth == 1)\n      image->type=BilevelType;\n\n    if(image2==image)\n        image2 = NULL;    /* Remove shadow copy to an image before rotation. */\n\n      /*  Rotate image. */\n    rotated_image = RotateImage(image, 90.0, exception);\n    if (rotated_image != (Image *) NULL)\n    {\n        /* Remove page offsets added by RotateImage */\n      rotated_image->page.x=0;\n      rotated_image->page.y=0;\n\n      blob = rotated_image->blob;\n      rotated_image->blob = image->blob;\n      rotated_image->colors = image->colors;\n      image->blob = blob;\n      AppendImageToList(&image,rotated_image);      \n      DeleteImageFromList(&image);      \n    }\n\ndone_reading:\n\n    if(image2!=NULL)\n      if(image2!=image)\n      {\n        DeleteImageFromList(&image2); \n  if(clone_info)\n  {\n          if(clone_info->file)\n    {\n            fclose(clone_info->file);\n            clone_info->file = NULL;\n            (void) remove_utf8(clone_info->filename);\n    }\n        }    \n      }\n\n      /* Allocate next image structure. */    \n    AcquireNextImage(image_info,image,exception);\n    if (image->next == (Image *) NULL) break;                \n    image=SyncNextImageInList(image);\n    image->columns=image->rows=0;\n    image->colors=0;    \n\n      /* row scan buffer is no longer needed */\n    RelinquishMagickMemory(BImgBuff);\n    BImgBuff = NULL;\n\n    if(--Frames>0)\n    {\n      z = z2;\n      if(image2==NULL) image2 = image;\n      goto NEXT_FRAME;\n    }\n    if ((image2!=NULL) && (image2!=image))   /* Does shadow temporary decompressed image exist? */\n      {\n/*  CloseBlob(image2); */\n        DeleteImageFromList(&image2);\n        if(clone_info)\n        {\n          if(clone_info->file)\n          {\n            fclose(clone_info->file);\n            clone_info->file = NULL;\n            (void) remove_utf8(clone_info->filename);\n          }\n        }\n        }\n  }\n\n  clone_info=DestroyImageInfo(clone_info);\n  RelinquishMagickMemory(BImgBuff);\n  CloseBlob(image);\n\n\n  {\n    Image *p;    \n    ssize_t scene=0;\n    \n    /*\n      Rewind list, removing any empty images while rewinding.\n    */\n    p=image;\n    image=NULL;\n    while (p != (Image *) NULL)\n      {\n        Image *tmp=p;\n        if ((p->rows == 0) || (p->columns == 0)) {\n          p=p->previous;\n          DeleteImageFromList(&tmp);\n        } else {\n          image=p;\n          p=p->previous;\n        }\n      }\n    \n    /*\n      Fix scene numbers\n    */\n    for (p=image; p != (Image *) NULL; p=p->next)\n      p->scene=scene++;\n  }\n\n  if(clone_info != NULL)  /* cleanup garbage file from compression */\n  {\n    if(clone_info->file)\n    {\n      fclose(clone_info->file);\n      clone_info->file = NULL;\n      (void) remove_utf8(clone_info->filename);\n    }\n    DestroyImageInfo(clone_info);\n    clone_info = NULL;\n  }\n  if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\"return\");\n  if(image==NULL)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  return (image);\n}",
        "func_hash": 123189732868835832469086799441508888909,
        "file_name": "mat.c",
        "file_hash": 184758751839368977736100938972533937602,
        "cwe": [
            "CWE-125"
        ],
        "cve": "CVE-2016-10070",
        "cve_desc": "Heap-based buffer overflow in the CalcMinMax function in coders/mat.c in ImageMagick before 6.9.4-0 allows remote attackers to cause a denial of service (out-of-bounds read and application crash) via a crafted mat file.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2016-10070",
        "func_name": "ReadMATImage",
        "diff": [
            "diff --git a/coders/mat.c b/coders/mat.c\nindex 93a9d8710ab..9bc442274ae 100644\n--- a/coders/mat.c\n+++ b/coders/mat.c\n@@ -925,6 +925,7 @@ RestoreMSCWarning\n   }\n       }\n     } while(z-- >= 2);\n+    quantum_info=DestroyQuantumInfo(quantum_info);\n ExitLoop:\n \n \n"
        ],
        "func_after": []
    },
    {
        "idx": 198169,
        "project": "tensorflow",
        "commit_id": "5b048e87e4e55990dae6b547add4dae59f4e1c76",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/5b048e87e4e55990dae6b547add4dae59f4e1c76",
        "commit_message": "Fix a null pointer exception in SVDF\n\nThis is due to not checking that `GetVariableInput` returns non-null tensor.\n\nAlso fix a potential null pointer exception in `GetVariableInput`.\n\nPiperOrigin-RevId: 385160147\nChange-Id: Iadf3f0705b036a9014d27caa5a8bbd91f4c4c401",
        "target": 1,
        "irrelevant": 0,
        "func_before": "TfLiteTensor* GetVariableInput(TfLiteContext* context, const TfLiteNode* node,\n                               int index) {\n  TfLiteTensor* tensor = GetMutableInput(context, node, index);\n  return tensor->is_variable ? tensor : nullptr;\n}",
        "func_hash": 10926286429278682792722078244037344195,
        "file_name": "kernel_util.cc",
        "file_hash": 18607953596861130302659896453881171161,
        "cwe": [
            "CWE-369"
        ],
        "cve": "CVE-2021-37681",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions the implementation of SVDF in TFLite is [vulnerable to a null pointer error](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/lite/kernels/svdf.cc#L300-L313). The [`GetVariableInput` function](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/lite/kernels/kernel_util.cc#L115-L119) can return a null pointer but `GetTensorData` assumes that the argument is always a valid tensor. Furthermore, because `GetVariableInput` calls [`GetMutableInput`](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/lite/kernels/kernel_util.cc#L82-L90) which might return `nullptr`, the `tensor->is_variable` expression can also trigger a null pointer exception. We have patched the issue in GitHub commit 5b048e87e4e55990dae6b547add4dae59f4e1c76. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37681",
        "func_name": "GetVariableInput",
        "diff": [
            "diff --git a/tensorflow/lite/kernels/kernel_util.cc b/tensorflow/lite/kernels/kernel_util.cc\nindex c64a49d316b217..6a53757bbdff67 100644\n--- a/tensorflow/lite/kernels/kernel_util.cc\n+++ b/tensorflow/lite/kernels/kernel_util.cc\n@@ -119,6 +119,7 @@ TfLiteStatus GetInputSafe(const TfLiteContext* context, const TfLiteNode* node,\n TfLiteTensor* GetVariableInput(TfLiteContext* context, const TfLiteNode* node,\n                                int index) {\n   TfLiteTensor* tensor = GetMutableInput(context, node, index);\n+  if (tensor == nullptr) return nullptr;\n   return tensor->is_variable ? tensor : nullptr;\n }\n \ndiff --git a/tensorflow/lite/kernels/svdf.cc b/tensorflow/lite/kernels/svdf.cc\nindex 31b8b32c98295a..6c02508e26b1da 100644\n--- a/tensorflow/lite/kernels/svdf.cc\n+++ b/tensorflow/lite/kernels/svdf.cc\n@@ -299,6 +299,7 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n                     GetTemporarySafe(context, node, /*index=*/0, &scratch));\n \n   TfLiteTensor* state = GetVariableInput(context, node, kStateTensor);\n+  TF_LITE_ENSURE(context, state != nullptr);\n   TfLiteTensor* output;\n   TF_LITE_ENSURE_OK(context,\n                     GetOutputSafe(context, node, kOutputTensor, &output));\n"
        ],
        "func_after": []
    },
    {
        "idx": 198170,
        "project": "tensorflow",
        "commit_id": "5b048e87e4e55990dae6b547add4dae59f4e1c76",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/5b048e87e4e55990dae6b547add4dae59f4e1c76",
        "commit_message": "Fix a null pointer exception in SVDF\n\nThis is due to not checking that `GetVariableInput` returns non-null tensor.\n\nAlso fix a potential null pointer exception in `GetVariableInput`.\n\nPiperOrigin-RevId: 385160147\nChange-Id: Iadf3f0705b036a9014d27caa5a8bbd91f4c4c401",
        "target": 1,
        "irrelevant": 0,
        "func_before": "TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n  auto* params = reinterpret_cast<TfLiteSVDFParams*>(node->builtin_data);\n  OpData* op_data = reinterpret_cast<OpData*>(node->user_data);\n\n  const TfLiteTensor* input;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n  const TfLiteTensor* weights_feature;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kWeightsFeatureTensor,\n                                          &weights_feature));\n  const TfLiteTensor* weights_time;\n  TF_LITE_ENSURE_OK(\n      context, GetInputSafe(context, node, kWeightsTimeTensor, &weights_time));\n  const TfLiteTensor* bias = GetOptionalInputTensor(context, node, kBiasTensor);\n\n  TfLiteTensor* scratch;\n  TF_LITE_ENSURE_OK(context,\n                    GetTemporarySafe(context, node, /*index=*/0, &scratch));\n\n  TfLiteTensor* state = GetVariableInput(context, node, kStateTensor);\n  TfLiteTensor* output;\n  TF_LITE_ENSURE_OK(context,\n                    GetOutputSafe(context, node, kOutputTensor, &output));\n\n  switch (weights_feature->type) {\n    case kTfLiteFloat32: {\n      reference_ops::EvalFloatSVDF(\n          params, GetTensorShape(input), GetTensorData<float>(input),\n          GetTensorShape(weights_feature),\n          GetTensorData<float>(weights_feature), GetTensorShape(weights_time),\n          GetTensorData<float>(weights_time), GetTensorShape(bias),\n          GetTensorData<float>(bias), GetTensorData<float>(scratch),\n          GetTensorData<float>(state), GetTensorShape(output),\n          GetTensorData<float>(output));\n      return kTfLiteOk;\n    }\n    case kTfLiteUInt8:\n    case kTfLiteInt8: {\n      if (input->type == kTfLiteFloat32) {\n        TfLiteTensor* input_quantized;\n        TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/1,\n                                                    &input_quantized));\n        TfLiteTensor* scaling_factors;\n        TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/2,\n                                                    &scaling_factors));\n        TfLiteTensor* float_weights_time;\n        TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/3,\n                                                    &float_weights_time));\n        TfLiteTensor* zero_points;\n        TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/4,\n                                                    &zero_points));\n        TfLiteTensor* row_sums;\n        TF_LITE_ENSURE_OK(\n            context, GetTemporarySafe(context, node, /*index=*/5, &row_sums));\n        // Dequantize weights time.\n        // TODO(alanchiao): this dequantization initialization only needs to\n        // happen once per model and should theoretically be placed in either\n        // Init or Prepare. However, TFLite doesn't allocate float_weights_time\n        // until the Eval function.\n        // TODO(alanchiao): refactor logic out into dequantize function.\n        if (!op_data->float_weights_time_initialized) {\n          const float dequantization_scale = weights_time->params.scale;\n          const int8_t* weights_time_ptr = GetTensorData<int8_t>(weights_time);\n          float* float_weights_time_ptr =\n              GetTensorData<float>(float_weights_time);\n          for (int i = 0; i < NumElements(float_weights_time); ++i) {\n            float_weights_time_ptr[i] =\n                weights_time_ptr[i] * dequantization_scale;\n          }\n          op_data->float_weights_time_initialized = true;\n        }\n\n        int32_t* zero_points_ptr = nullptr;\n        int32_t* row_sums_ptr = nullptr;\n        if (params->asymmetric_quantize_inputs && row_sums != nullptr) {\n          zero_points_ptr = GetTensorData<int32_t>(zero_points);\n          row_sums_ptr = GetTensorData<int32_t>(row_sums);\n        }\n\n        reference_ops::EvalHybridSVDF(\n            params, GetTensorShape(input), GetTensorData<float>(input),\n            GetTensorShape(weights_feature),\n            GetTensorData<int8_t>(weights_feature),\n            weights_feature->params.scale, GetTensorShape(float_weights_time),\n            GetTensorData<float>(float_weights_time), GetTensorShape(bias),\n            GetTensorData<float>(bias), GetTensorData<float>(scratch),\n            GetTensorData<float>(scaling_factors),\n            GetTensorData<int8_t>(input_quantized), GetTensorData<float>(state),\n            GetTensorShape(output), GetTensorData<float>(output),\n            zero_points_ptr, row_sums_ptr, &op_data->compute_row_sums);\n        return kTfLiteOk;\n      }\n      auto* input_params = reinterpret_cast<TfLiteAffineQuantization*>(\n          input->quantization.params);\n      auto* output_params = reinterpret_cast<TfLiteAffineQuantization*>(\n          output->quantization.params);\n      TfLiteTensor* output_temp;\n      TF_LITE_ENSURE_OK(\n          context, GetTemporarySafe(context, node, /*index=*/1, &output_temp));\n\n      // Currently supports only ReLU.\n      // TODO(jianlijianli): support other activations.\n      TF_LITE_ENSURE_EQ(context, params->activation, kTfLiteActRelu);\n\n      reference_ops::EvalIntegerSVDF(\n          params, GetTensorShape(input), GetTensorData<int8_t>(input),\n          GetTensorShape(weights_feature),\n          GetTensorData<int8_t>(weights_feature), GetTensorShape(weights_time),\n          GetTensorData<int16_t>(weights_time), GetTensorShape(bias),\n          GetTensorData<int32_t>(bias), GetTensorData<int16_t>(state),\n          GetTensorShape(output), GetTensorData<int8_t>(output),\n          GetTensorData<int32_t>(scratch), GetTensorData<int32_t>(output_temp),\n          op_data->effective_scale_1_a, op_data->effective_scale_1_b,\n          op_data->effective_scale_2_a, op_data->effective_scale_2_b,\n          input_params->zero_point->data[0],\n          output_params->zero_point->data[0]);\n      return kTfLiteOk;\n    }\n    default:\n      context->ReportError(context, \"Type %s not currently supported.\",\n                           TfLiteTypeGetName(weights_feature->type));\n      return kTfLiteError;\n  }\n}",
        "func_hash": 212919005141808616331409957930472583788,
        "file_name": "svdf.cc",
        "file_hash": 98626637255820911713355792561260448866,
        "cwe": [
            "CWE-369"
        ],
        "cve": "CVE-2021-37681",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions the implementation of SVDF in TFLite is [vulnerable to a null pointer error](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/lite/kernels/svdf.cc#L300-L313). The [`GetVariableInput` function](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/lite/kernels/kernel_util.cc#L115-L119) can return a null pointer but `GetTensorData` assumes that the argument is always a valid tensor. Furthermore, because `GetVariableInput` calls [`GetMutableInput`](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/lite/kernels/kernel_util.cc#L82-L90) which might return `nullptr`, the `tensor->is_variable` expression can also trigger a null pointer exception. We have patched the issue in GitHub commit 5b048e87e4e55990dae6b547add4dae59f4e1c76. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37681",
        "func_name": "Eval",
        "diff": [
            "diff --git a/tensorflow/lite/kernels/kernel_util.cc b/tensorflow/lite/kernels/kernel_util.cc\nindex c64a49d316b217..6a53757bbdff67 100644\n--- a/tensorflow/lite/kernels/kernel_util.cc\n+++ b/tensorflow/lite/kernels/kernel_util.cc\n@@ -119,6 +119,7 @@ TfLiteStatus GetInputSafe(const TfLiteContext* context, const TfLiteNode* node,\n TfLiteTensor* GetVariableInput(TfLiteContext* context, const TfLiteNode* node,\n                                int index) {\n   TfLiteTensor* tensor = GetMutableInput(context, node, index);\n+  if (tensor == nullptr) return nullptr;\n   return tensor->is_variable ? tensor : nullptr;\n }\n \ndiff --git a/tensorflow/lite/kernels/svdf.cc b/tensorflow/lite/kernels/svdf.cc\nindex 31b8b32c98295a..6c02508e26b1da 100644\n--- a/tensorflow/lite/kernels/svdf.cc\n+++ b/tensorflow/lite/kernels/svdf.cc\n@@ -299,6 +299,7 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n                     GetTemporarySafe(context, node, /*index=*/0, &scratch));\n \n   TfLiteTensor* state = GetVariableInput(context, node, kStateTensor);\n+  TF_LITE_ENSURE(context, state != nullptr);\n   TfLiteTensor* output;\n   TF_LITE_ENSURE_OK(context,\n                     GetOutputSafe(context, node, kOutputTensor, &output));\n"
        ],
        "func_after": []
    },
    {
        "idx": 198198,
        "project": "tensorflow",
        "commit_id": "01cff3f986259d661103412a20745928c727326f",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/01cff3f986259d661103412a20745928c727326f",
        "commit_message": "Fix heap OOB due to dimension mismatch in `ResourceScatterUpdate`\n\nPiperOrigin-RevId: 388292801\nChange-Id: Id9bd7244d98d41b1517d4771850b32782c0cc949",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void DoCompute(OpKernelContext* c) {\n    core::RefCountPtr<Var> v;\n    OP_REQUIRES_OK(c, LookupResource(c, HandleFromInput(c, 0), &v));\n    Tensor* params = v->tensor();\n    const Tensor& indices = c->input(1);\n    const Tensor& updates = c->input(2);\n\n    // Check that rank(updates.shape) = rank(indices.shape + params.shape[1:])\n    OP_REQUIRES(c,\n                updates.dims() == 0 ||\n                    updates.dims() == indices.dims() + params->dims() - 1,\n                errors::InvalidArgument(\n                    \"Must have updates.shape = indices.shape + \"\n                    \"params.shape[1:] or updates.shape = [], got \",\n                    \"updates.shape \", updates.shape().DebugString(),\n                    \", indices.shape \", indices.shape().DebugString(),\n                    \", params.shape \", params->shape().DebugString()));\n\n    // Check that we have enough index space\n    const int64_t N_big = indices.NumElements();\n    OP_REQUIRES(\n        c, N_big <= std::numeric_limits<Index>::max(),\n        errors::InvalidArgument(\"indices has too many elements for \",\n                                DataTypeString(DataTypeToEnum<Index>::v()),\n                                \" indexing: \", N_big, \" > \",\n                                std::numeric_limits<Index>::max()));\n    const Index N = static_cast<Index>(N_big);\n    OP_REQUIRES(\n        c, params->dim_size(0) <= std::numeric_limits<Index>::max(),\n        errors::InvalidArgument(\"params.shape[0] too large for \",\n                                DataTypeString(DataTypeToEnum<Index>::v()),\n                                \" indexing: \", params->dim_size(0), \" > \",\n                                std::numeric_limits<Index>::max()));\n\n    if (N > 0) {\n      auto indices_flat = indices.flat<Index>();\n      auto params_flat = params->flat_outer_dims<T>();\n      if (TensorShapeUtils::IsScalar(updates.shape())) {\n        const auto update = updates.scalar<T>();\n\n        functor::ScatterScalarFunctor<Device, T, Index, op> functor;\n        const Index bad_i = functor(c, c->template eigen_device<Device>(),\n                                    params_flat, update, indices_flat);\n        OP_REQUIRES(c, bad_i < 0,\n                    errors::InvalidArgument(\n                        \"indices\", SliceDebugString(indices.shape(), bad_i),\n                        \" = \", indices_flat(bad_i), \" is not in [0, \",\n                        params->dim_size(0), \")\"));\n      } else {\n        int64_t num_updates = updates.NumElements();\n        OP_REQUIRES(c, num_updates % N == 0,\n                    errors::InvalidArgument(\n                        \"shape of indices (\", indices.shape().DebugString(),\n                        \") is not compatible with the shape of updates (\",\n                        updates.shape().DebugString(), \")\"));\n        auto updates_flat = updates.shaped<T, 2>({N, num_updates / N});\n\n        functor::ScatterFunctor<Device, T, Index, op> functor;\n        const Index bad_i = functor(c, c->template eigen_device<Device>(),\n                                    params_flat, updates_flat, indices_flat);\n        OP_REQUIRES(c, bad_i < 0,\n                    errors::InvalidArgument(\n                        \"indices\", SliceDebugString(indices.shape(), bad_i),\n                        \" = \", indices_flat(bad_i), \" is not in [0, \",\n                        params->dim_size(0), \")\"));\n      }\n    }\n  }",
        "func_hash": 295685199526661026529481535318072250955,
        "file_name": "resource_variable_ops.cc",
        "file_hash": 45667374759135889125974448808093275693,
        "cwe": [
            "CWE-125"
        ],
        "cve": "CVE-2021-37655",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions an attacker can trigger a read from outside of bounds of heap allocated data by sending invalid arguments to `tf.raw_ops.ResourceScatterUpdate`. The [implementation](https://github.com/tensorflow/tensorflow/blob/f24faa153ad31a4b51578f8181d3aaab77a1ddeb/tensorflow/core/kernels/resource_variable_ops.cc#L919-L923) has an incomplete validation of the relationship between the shapes of `indices` and `updates`: instead of checking that the shape of `indices` is a prefix of the shape of `updates` (so that broadcasting can happen), code only checks that the number of elements in these two tensors are in a divisibility relationship. We have patched the issue in GitHub commit 01cff3f986259d661103412a20745928c727326f. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37655",
        "func_name": "DoCompute",
        "diff": [
            "diff --git a/tensorflow/core/kernels/resource_variable_ops.cc b/tensorflow/core/kernels/resource_variable_ops.cc\nindex 8b9610724e5826..b81a7a517ea6d2 100644\n--- a/tensorflow/core/kernels/resource_variable_ops.cc\n+++ b/tensorflow/core/kernels/resource_variable_ops.cc\n@@ -955,11 +955,12 @@ class ResourceScatterUpdateOp : public OpKernel {\n                         params->dim_size(0), \")\"));\n       } else {\n         int64_t num_updates = updates.NumElements();\n-        OP_REQUIRES(c, num_updates % N == 0,\n-                    errors::InvalidArgument(\n-                        \"shape of indices (\", indices.shape().DebugString(),\n-                        \") is not compatible with the shape of updates (\",\n-                        updates.shape().DebugString(), \")\"));\n+        OP_REQUIRES(\n+            c, TensorShapeUtils::StartsWith(updates.shape(), indices.shape()),\n+            errors::InvalidArgument(\n+                \"The shape of indices (\", indices.shape().DebugString(),\n+                \") must be a prefix of the shape of updates (\",\n+                updates.shape().DebugString(), \")\"));\n         auto updates_flat = updates.shaped<T, 2>({N, num_updates / N});\n \n         functor::ScatterFunctor<Device, T, Index, op> functor;\n"
        ],
        "func_after": []
    },
    {
        "idx": 198239,
        "project": "barebox",
        "commit_id": "a3337563c705bc8e0cf32f910b3e9e3c43d962ff",
        "project_url": "https://github.com/saschahauer/barebox",
        "commit_url": "https://github.com/saschahauer/barebox/commit/a3337563c705bc8e0cf32f910b3e9e3c43d962ff",
        "commit_message": "password: Use crypto_memneq() to compare hashes\n\nCryptographic verifications should be time-constant so that an attacker\ncannot get information about the secrets used by observing the system,\nso use crypto_memneq() rather than memcmp() to compare password hashes.\n\nSigned-off-by: Sascha Hauer <s.hauer@pengutronix.de>",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static int check_passwd(unsigned char *passwd, size_t length)\n{\n\tstruct digest *d = NULL;\n\tunsigned char *passwd1_sum;\n\tunsigned char *passwd2_sum;\n\tint ret = 0;\n\tint hash_len;\n\n\tif (IS_ENABLED(CONFIG_PASSWD_CRYPTO_PBKDF2)) {\n\t\thash_len = PBKDF2_LENGTH;\n\t} else {\n\t\td = digest_alloc(PASSWD_SUM);\n\t\tif (!d) {\n\t\t\tpr_err(\"No such digest: %s\\n\",\n\t\t\t       PASSWD_SUM ? PASSWD_SUM : \"NULL\");\n\t\t\treturn -ENOENT;\n\t\t}\n\n\t\thash_len = digest_length(d);\n\t}\n\n\tpasswd1_sum = calloc(hash_len * 2, sizeof(unsigned char));\n\tif (!passwd1_sum)\n\t\treturn -ENOMEM;\n\n\tpasswd2_sum = passwd1_sum + hash_len;\n\n\tif (is_passwd_env_enable())\n\t\tret = read_env_passwd(passwd2_sum, hash_len);\n\telse if (is_passwd_default_enable())\n\t\tret = read_default_passwd(passwd2_sum, hash_len);\n\telse\n\t\tret = -EINVAL;\n\n\tif (ret < 0)\n\t\tgoto err;\n\n\tif (IS_ENABLED(CONFIG_PASSWD_CRYPTO_PBKDF2)) {\n\t\tchar *key = passwd2_sum + PBKDF2_SALT_LEN;\n\t\tchar *salt = passwd2_sum;\n\t\tint keylen = PBKDF2_LENGTH - PBKDF2_SALT_LEN;\n\n\t\tret = pkcs5_pbkdf2_hmac_sha1(passwd, length, salt,\n\t\t\tPBKDF2_SALT_LEN, PBKDF2_COUNT, keylen, passwd1_sum);\n\t\tif (ret)\n\t\t\tgoto err;\n\n\t\tif (strncmp(passwd1_sum, key, keylen) == 0)\n\t\t\tret = 1;\n\t} else {\n\t\tret = digest_digest(d, passwd, length, passwd1_sum);\n\n\t\tif (ret)\n\t\t\tgoto err;\n\n\t\tif (strncmp(passwd1_sum, passwd2_sum, hash_len) == 0)\n\t\t\tret = 1;\n\t}\n\nerr:\n\tfree(passwd1_sum);\n\tdigest_free(d);\n\n\treturn ret;\n}",
        "func_hash": 69404159605803282192043232030112739673,
        "file_name": "password.c",
        "file_hash": 155548681482248654497093234101023237595,
        "cwe": [
            "CWE-200"
        ],
        "cve": "CVE-2021-37848",
        "cve_desc": "common/password.c in Pengutronix barebox through 2021.07.0 leaks timing information because strncmp is used during hash comparison.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37848",
        "func_name": "check_passwd",
        "diff": [
            "diff --git a/common/password.c b/common/password.c\nindex 3f05b81c0c..aea7c7ff5d 100644\n--- a/common/password.c\n+++ b/common/password.c\n@@ -18,6 +18,7 @@\n #include <init.h>\n #include <stdlib.h>\n #include <globalvar.h>\n+#include <crypto.h>\n #include <generated/passwd.h>\n #include <crypto/pbkdf2.h>\n \n@@ -311,7 +312,7 @@ static int check_passwd(unsigned char *passwd, size_t length)\n \t\tif (ret)\n \t\t\tgoto err;\n \n-\t\tif (strncmp(passwd1_sum, key, keylen) == 0)\n+\t\tif (!crypto_memneq(passwd1_sum, key, keylen))\n \t\t\tret = 1;\n \t} else {\n \t\tret = digest_digest(d, passwd, length, passwd1_sum);\n@@ -319,7 +320,7 @@ static int check_passwd(unsigned char *passwd, size_t length)\n \t\tif (ret)\n \t\t\tgoto err;\n \n-\t\tif (strncmp(passwd1_sum, passwd2_sum, hash_len) == 0)\n+\t\tif (!crypto_memneq(passwd1_sum, passwd2_sum, hash_len))\n \t\t\tret = 1;\n \t}\n \n"
        ],
        "func_after": []
    },
    {
        "idx": 198259,
        "project": "tensorflow",
        "commit_id": "a2b743f6017d7b97af1fe49087ae15f0ac634373",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/a2b743f6017d7b97af1fe49087ae15f0ac634373",
        "commit_message": "Fix heap OOB in `tf.raw_ops.RaggedGather`\n\nPiperOrigin-RevId: 388355464\nChange-Id: If14d96231d1cd7aad7c4d1c22c1bab1576b75717",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext* context) override {\n    // Get the input Tensors.\n    OpInputList params_nested_splits_in;\n    OP_REQUIRES_OK(context, context->input_list(\"params_nested_splits\",\n                                                &params_nested_splits_in));\n    const Tensor& params_dense_values_in =\n        context->input(params_nested_splits_in.size());\n    const Tensor& indices_in =\n        context->input(params_nested_splits_in.size() + 1);\n\n    DCHECK_GT(params_nested_splits_in.size(), 0);  // Enforced by REGISTER_OP.\n    SPLITS_TYPE num_params = params_nested_splits_in[0].dim_size(0) - 1;\n    OP_REQUIRES_OK(context, ValidateIndices(indices_in, num_params));\n\n    OP_REQUIRES(context, params_dense_values_in.dims() > 0,\n                errors::InvalidArgument(\"params.rank must be nonzero\"));\n    SPLITS_TYPE num_params_dense_values = params_dense_values_in.dim_size(0);\n\n    // Calculate the `splits`, and store the value slices that we need to\n    // copy in `value_slices`.\n    std::vector<std::pair<SPLITS_TYPE, SPLITS_TYPE>> value_slices;\n    SPLITS_TYPE num_values = 0;\n    std::vector<std::vector<SPLITS_TYPE>> out_splits;\n    OP_REQUIRES_OK(context, MakeSplits(indices_in, params_nested_splits_in,\n                                       num_params_dense_values, &out_splits,\n                                       &value_slices, &num_values));\n\n    // Write the output tensors.\n    OP_REQUIRES_OK(context, WriteSplits(out_splits, context));\n    OP_REQUIRES_OK(context,\n                   WriteValues(params_dense_values_in, value_slices,\n                               out_splits.size(), num_values, context));\n  }",
        "func_hash": 307099744677498626698554862398752331906,
        "file_name": "ragged_gather_op.cc",
        "file_hash": 101959606941305621670893175769931334336,
        "cwe": [
            "CWE-369"
        ],
        "cve": "CVE-2021-37641",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions if the arguments to `tf.raw_ops.RaggedGather` don't determine a valid ragged tensor code can trigger a read from outside of bounds of heap allocated buffers. The [implementation](https://github.com/tensorflow/tensorflow/blob/8d72537c6abf5a44103b57b9c2e22c14f5f49698/tensorflow/core/kernels/ragged_gather_op.cc#L70) directly reads the first dimension of a tensor shape before checking that said tensor has rank of at least 1 (i.e., it is not a scalar). Furthermore, the implementation does not check that the list given by `params_nested_splits` is not an empty list of tensors. We have patched the issue in GitHub commit a2b743f6017d7b97af1fe49087ae15f0ac634373. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37641",
        "func_name": "Compute",
        "diff": [
            "diff --git a/tensorflow/core/kernels/ragged_gather_op.cc b/tensorflow/core/kernels/ragged_gather_op.cc\nindex 3bf82cba050e3b..d6d51c770bbb7a 100644\n--- a/tensorflow/core/kernels/ragged_gather_op.cc\n+++ b/tensorflow/core/kernels/ragged_gather_op.cc\n@@ -58,15 +58,21 @@ class RaggedGatherOpBase : public OpKernel {\n \n   void Compute(OpKernelContext* context) override {\n     // Get the input Tensors.\n+\n     OpInputList params_nested_splits_in;\n     OP_REQUIRES_OK(context, context->input_list(\"params_nested_splits\",\n                                                 &params_nested_splits_in));\n+    OP_REQUIRES(\n+        context, params_nested_splits_in.size() > 0,\n+        errors::InvalidArgument(\"params_nested_splits must be non empty\"));\n+\n     const Tensor& params_dense_values_in =\n         context->input(params_nested_splits_in.size());\n     const Tensor& indices_in =\n         context->input(params_nested_splits_in.size() + 1);\n \n-    DCHECK_GT(params_nested_splits_in.size(), 0);  // Enforced by REGISTER_OP.\n+    OP_REQUIRES(context, params_nested_splits_in[0].dims() > 0,\n+                errors::InvalidArgument(\"Split tensors must not be scalars\"));\n     SPLITS_TYPE num_params = params_nested_splits_in[0].dim_size(0) - 1;\n     OP_REQUIRES_OK(context, ValidateIndices(indices_in, num_params));\n \n"
        ],
        "func_after": []
    },
    {
        "idx": 195385,
        "project": "flatpak",
        "commit_id": "65cbfac982cb1c83993a9e19aa424daee8e9f042",
        "project_url": "https://github.com/flatpak/flatpak",
        "commit_url": "https://github.com/flatpak/flatpak/commit/65cbfac982cb1c83993a9e19aa424daee8e9f042",
        "commit_message": "Ensure that bundles have metadata on install\n\nIf we have a bundle without metadata we wouldn't properly present\nthe permissions in the transaction.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "flatpak_dir_ensure_bundle_remote (FlatpakDir         *self,\n                                  GFile              *file,\n                                  GBytes             *extra_gpg_data,\n                                  FlatpakDecomposed **out_ref,\n                                  char              **out_checksum,\n                                  char              **out_metadata,\n                                  gboolean           *out_created_remote,\n                                  GCancellable       *cancellable,\n                                  GError            **error)\n{\n  g_autoptr(FlatpakDecomposed) ref = NULL;\n  gboolean created_remote = FALSE;\n  g_autoptr(GBytes) deploy_data = NULL;\n  g_autoptr(GVariant) metadata = NULL;\n  g_autofree char *origin = NULL;\n  g_autofree char *fp_metadata = NULL;\n  g_autofree char *basename = NULL;\n  g_autoptr(GBytes) included_gpg_data = NULL;\n  GBytes *gpg_data = NULL;\n  g_autofree char *to_checksum = NULL;\n  g_autofree char *remote = NULL;\n  g_autofree char *collection_id = NULL;\n\n  if (!flatpak_dir_ensure_repo (self, cancellable, error))\n    return NULL;\n\n  metadata = flatpak_bundle_load (file, &to_checksum,\n                                  &ref,\n                                  &origin,\n                                  NULL, &fp_metadata, NULL,\n                                  &included_gpg_data,\n                                  &collection_id,\n                                  error);\n  if (metadata == NULL)\n    return NULL;\n\n  gpg_data = extra_gpg_data ? extra_gpg_data : included_gpg_data;\n\n  deploy_data = flatpak_dir_get_deploy_data (self, ref, FLATPAK_DEPLOY_VERSION_ANY, cancellable, NULL);\n  if (deploy_data != NULL)\n    {\n      remote = g_strdup (flatpak_deploy_data_get_origin (deploy_data));\n\n      /* We need to import any gpg keys because otherwise the pull will fail */\n      if (gpg_data != NULL)\n        {\n          g_autoptr(GKeyFile) new_config = NULL;\n\n          new_config = ostree_repo_copy_config (flatpak_dir_get_repo (self));\n\n          if (!flatpak_dir_modify_remote (self, remote, new_config,\n                                          gpg_data, cancellable, error))\n            return NULL;\n        }\n    }\n  else\n    {\n      g_autofree char *id = flatpak_decomposed_dup_id (ref);\n      /* Add a remote for later updates */\n      basename = g_file_get_basename (file);\n      remote = flatpak_dir_create_origin_remote (self,\n                                                 origin,\n                                                 id,\n                                                 basename,\n                                                 flatpak_decomposed_get_ref (ref),\n                                                 gpg_data,\n                                                 collection_id,\n                                                 &created_remote,\n                                                 cancellable,\n                                                 error);\n      if (remote == NULL)\n        return NULL;\n    }\n\n  if (out_created_remote)\n    *out_created_remote = created_remote;\n\n  if (out_ref)\n    *out_ref = g_steal_pointer (&ref);\n\n  if (out_checksum)\n    *out_checksum = g_steal_pointer (&to_checksum);\n\n  if (out_metadata)\n    *out_metadata = g_steal_pointer (&fp_metadata);\n\n\n  return g_steal_pointer (&remote);\n}",
        "func_hash": 117751554146896350574194025697057651898,
        "file_name": "flatpak-dir.c",
        "file_hash": 41005800026546918810123079124181990480,
        "cwe": [
            "CWE-276"
        ],
        "cve": "CVE-2021-43860",
        "cve_desc": "Flatpak is a Linux application sandboxing and distribution framework. Prior to versions 1.12.3 and 1.10.6, Flatpak doesn't properly validate that the permissions displayed to the user for an app at install time match the actual permissions granted to the app at runtime, in the case that there's a null byte in the metadata file of an app. Therefore apps can grant themselves permissions without the consent of the user. Flatpak shows permissions to the user during install by reading them from the \"xa.metadata\" key in the commit metadata. This cannot contain a null terminator, because it is an untrusted GVariant. Flatpak compares these permissions to the *actual* metadata, from the \"metadata\" file to ensure it wasn't lied to. However, the actual metadata contents are loaded in several places where they are read as simple C-style strings. That means that, if the metadata file includes a null terminator, only the content of the file from *before* the terminator gets compared to xa.metadata. Thus, any permissions that appear in the metadata file after a null terminator are applied at runtime but not shown to the user. So maliciously crafted apps can give themselves hidden permissions. Users who have Flatpaks installed from untrusted sources are at risk in case the Flatpak has a maliciously crafted metadata file, either initially or in an update. This issue is patched in versions 1.12.3 and 1.10.6. As a workaround, users can manually check the permissions of installed apps by checking the metadata file or the xa.metadata key on the commit metadata.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-43860",
        "func_name": "flatpak_dir_ensure_bundle_remote",
        "diff": [
            "diff --git a/common/flatpak-dir.c b/common/flatpak-dir.c\nindex e8bf106cca..4debffea33 100644\n--- a/common/flatpak-dir.c\n+++ b/common/flatpak-dir.c\n@@ -9372,6 +9372,13 @@ flatpak_dir_ensure_bundle_remote (FlatpakDir         *self,\n   if (metadata == NULL)\n     return NULL;\n \n+  /* If we rely on metadata (to e.g. print permissions), check it exists before creating the remote */\n+  if (out_metadata && fp_metadata == NULL)\n+    {\n+      flatpak_fail_error (error, FLATPAK_ERROR_INVALID_DATA, \"No metadata in bundler header\");\n+      return NULL;\n+    }\n+\n   gpg_data = extra_gpg_data ? extra_gpg_data : included_gpg_data;\n \n   deploy_data = flatpak_dir_get_deploy_data (self, ref, FLATPAK_DEPLOY_VERSION_ANY, cancellable, NULL);\n"
        ],
        "func_after": []
    },
    {
        "idx": 195388,
        "project": "postgres",
        "commit_id": "160c0258802d10b0600d7671b1bbea55d8e17d45",
        "project_url": "https://github.com/postgres/postgres",
        "commit_url": "https://github.com/postgres/postgres/commit/160c0258802d10b0600d7671b1bbea55d8e17d45",
        "commit_message": "libpq: reject extraneous data after SSL or GSS encryption handshake.\n\nlibpq collects up to a bufferload of data whenever it reads data from\nthe socket.  When SSL or GSS encryption is requested during startup,\nany additional data received with the server's yes-or-no reply\nremained in the buffer, and would be treated as already-decrypted data\nonce the encryption handshake completed.  Thus, a man-in-the-middle\nwith the ability to inject data into the TCP connection could stuff\nsome cleartext data into the start of a supposedly encryption-protected\ndatabase session.\n\nThis could probably be abused to inject faked responses to the\nclient's first few queries, although other details of libpq's behavior\nmake that harder than it sounds.  A different line of attack is to\nexfiltrate the client's password, or other sensitive data that might\nbe sent early in the session.  That has been shown to be possible with\na server vulnerable to CVE-2021-23214.\n\nTo fix, throw a protocol-violation error if the internal buffer\nis not empty after the encryption handshake.\n\nOur thanks to Jacob Champion for reporting this problem.\n\nSecurity: CVE-2021-23222",
        "target": 1,
        "irrelevant": 0,
        "func_before": "PQconnectPoll(PGconn *conn)\n{\n\tbool\t\treset_connection_state_machine = false;\n\tbool\t\tneed_new_connection = false;\n\tPGresult   *res;\n\tchar\t\tsebuf[PG_STRERROR_R_BUFLEN];\n\tint\t\t\toptval;\n\n\tif (conn == NULL)\n\t\treturn PGRES_POLLING_FAILED;\n\n\t/* Get the new data */\n\tswitch (conn->status)\n\t{\n\t\t\t/*\n\t\t\t * We really shouldn't have been polled in these two cases, but we\n\t\t\t * can handle it.\n\t\t\t */\n\t\tcase CONNECTION_BAD:\n\t\t\treturn PGRES_POLLING_FAILED;\n\t\tcase CONNECTION_OK:\n\t\t\treturn PGRES_POLLING_OK;\n\n\t\t\t/* These are reading states */\n\t\tcase CONNECTION_AWAITING_RESPONSE:\n\t\tcase CONNECTION_AUTH_OK:\n\t\tcase CONNECTION_CHECK_WRITABLE:\n\t\tcase CONNECTION_CONSUME:\n\t\tcase CONNECTION_CHECK_STANDBY:\n\t\t\t{\n\t\t\t\t/* Load waiting data */\n\t\t\t\tint\t\t\tn = pqReadData(conn);\n\n\t\t\t\tif (n < 0)\n\t\t\t\t\tgoto error_return;\n\t\t\t\tif (n == 0)\n\t\t\t\t\treturn PGRES_POLLING_READING;\n\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t/* These are writing states, so we just proceed. */\n\t\tcase CONNECTION_STARTED:\n\t\tcase CONNECTION_MADE:\n\t\t\tbreak;\n\n\t\t\t/* Special cases: proceed without waiting. */\n\t\tcase CONNECTION_SSL_STARTUP:\n\t\tcase CONNECTION_NEEDED:\n\t\tcase CONNECTION_GSS_STARTUP:\n\t\tcase CONNECTION_CHECK_TARGET:\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tappendPQExpBufferStr(&conn->errorMessage,\n\t\t\t\t\t\t\t\t libpq_gettext(\"invalid connection state, probably indicative of memory corruption\\n\"));\n\t\t\tgoto error_return;\n\t}\n\n\nkeep_going:\t\t\t\t\t\t/* We will come back to here until there is\n\t\t\t\t\t\t\t\t * nothing left to do. */\n\n\t/* Time to advance to next address, or next host if no more addresses? */\n\tif (conn->try_next_addr)\n\t{\n\t\tif (conn->addr_cur && conn->addr_cur->ai_next)\n\t\t{\n\t\t\tconn->addr_cur = conn->addr_cur->ai_next;\n\t\t\treset_connection_state_machine = true;\n\t\t}\n\t\telse\n\t\t\tconn->try_next_host = true;\n\t\tconn->try_next_addr = false;\n\t}\n\n\t/* Time to advance to next connhost[] entry? */\n\tif (conn->try_next_host)\n\t{\n\t\tpg_conn_host *ch;\n\t\tstruct addrinfo hint;\n\t\tint\t\t\tthisport;\n\t\tint\t\t\tret;\n\t\tchar\t\tportstr[MAXPGPATH];\n\n\t\tif (conn->whichhost + 1 < conn->nconnhost)\n\t\t\tconn->whichhost++;\n\t\telse\n\t\t{\n\t\t\t/*\n\t\t\t * Oops, no more hosts.\n\t\t\t *\n\t\t\t * If we are trying to connect in \"prefer-standby\" mode, then drop\n\t\t\t * the standby requirement and start over.\n\t\t\t *\n\t\t\t * Otherwise, an appropriate error message is already set up, so\n\t\t\t * we just need to set the right status.\n\t\t\t */\n\t\t\tif (conn->target_server_type == SERVER_TYPE_PREFER_STANDBY &&\n\t\t\t\tconn->nconnhost > 0)\n\t\t\t{\n\t\t\t\tconn->target_server_type = SERVER_TYPE_PREFER_STANDBY_PASS2;\n\t\t\t\tconn->whichhost = 0;\n\t\t\t}\n\t\t\telse\n\t\t\t\tgoto error_return;\n\t\t}\n\n\t\t/* Drop any address info for previous host */\n\t\trelease_conn_addrinfo(conn);\n\n\t\t/*\n\t\t * Look up info for the new host.  On failure, log the problem in\n\t\t * conn->errorMessage, then loop around to try the next host.  (Note\n\t\t * we don't clear try_next_host until we've succeeded.)\n\t\t */\n\t\tch = &conn->connhost[conn->whichhost];\n\n\t\t/* Initialize hint structure */\n\t\tMemSet(&hint, 0, sizeof(hint));\n\t\thint.ai_socktype = SOCK_STREAM;\n\t\tconn->addrlist_family = hint.ai_family = AF_UNSPEC;\n\n\t\t/* Figure out the port number we're going to use. */\n\t\tif (ch->port == NULL || ch->port[0] == '\\0')\n\t\t\tthisport = DEF_PGPORT;\n\t\telse\n\t\t{\n\t\t\tif (!parse_int_param(ch->port, &thisport, conn, \"port\"))\n\t\t\t\tgoto error_return;\n\n\t\t\tif (thisport < 1 || thisport > 65535)\n\t\t\t{\n\t\t\t\tappendPQExpBuffer(&conn->errorMessage,\n\t\t\t\t\t\t\t\t  libpq_gettext(\"invalid port number: \\\"%s\\\"\\n\"),\n\t\t\t\t\t\t\t\t  ch->port);\n\t\t\t\tgoto keep_going;\n\t\t\t}\n\t\t}\n\t\tsnprintf(portstr, sizeof(portstr), \"%d\", thisport);\n\n\t\t/* Use pg_getaddrinfo_all() to resolve the address */\n\t\tswitch (ch->type)\n\t\t{\n\t\t\tcase CHT_HOST_NAME:\n\t\t\t\tret = pg_getaddrinfo_all(ch->host, portstr, &hint,\n\t\t\t\t\t\t\t\t\t\t &conn->addrlist);\n\t\t\t\tif (ret || !conn->addrlist)\n\t\t\t\t{\n\t\t\t\t\tappendPQExpBuffer(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t  libpq_gettext(\"could not translate host name \\\"%s\\\" to address: %s\\n\"),\n\t\t\t\t\t\t\t\t\t  ch->host, gai_strerror(ret));\n\t\t\t\t\tgoto keep_going;\n\t\t\t\t}\n\t\t\t\tbreak;\n\n\t\t\tcase CHT_HOST_ADDRESS:\n\t\t\t\thint.ai_flags = AI_NUMERICHOST;\n\t\t\t\tret = pg_getaddrinfo_all(ch->hostaddr, portstr, &hint,\n\t\t\t\t\t\t\t\t\t\t &conn->addrlist);\n\t\t\t\tif (ret || !conn->addrlist)\n\t\t\t\t{\n\t\t\t\t\tappendPQExpBuffer(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t  libpq_gettext(\"could not parse network address \\\"%s\\\": %s\\n\"),\n\t\t\t\t\t\t\t\t\t  ch->hostaddr, gai_strerror(ret));\n\t\t\t\t\tgoto keep_going;\n\t\t\t\t}\n\t\t\t\tbreak;\n\n\t\t\tcase CHT_UNIX_SOCKET:\n#ifdef HAVE_UNIX_SOCKETS\n\t\t\t\tconn->addrlist_family = hint.ai_family = AF_UNIX;\n\t\t\t\tUNIXSOCK_PATH(portstr, thisport, ch->host);\n\t\t\t\tif (strlen(portstr) >= UNIXSOCK_PATH_BUFLEN)\n\t\t\t\t{\n\t\t\t\t\tappendPQExpBuffer(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t  libpq_gettext(\"Unix-domain socket path \\\"%s\\\" is too long (maximum %d bytes)\\n\"),\n\t\t\t\t\t\t\t\t\t  portstr,\n\t\t\t\t\t\t\t\t\t  (int) (UNIXSOCK_PATH_BUFLEN - 1));\n\t\t\t\t\tgoto keep_going;\n\t\t\t\t}\n\n\t\t\t\t/*\n\t\t\t\t * NULL hostname tells pg_getaddrinfo_all to parse the service\n\t\t\t\t * name as a Unix-domain socket path.\n\t\t\t\t */\n\t\t\t\tret = pg_getaddrinfo_all(NULL, portstr, &hint,\n\t\t\t\t\t\t\t\t\t\t &conn->addrlist);\n\t\t\t\tif (ret || !conn->addrlist)\n\t\t\t\t{\n\t\t\t\t\tappendPQExpBuffer(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t  libpq_gettext(\"could not translate Unix-domain socket path \\\"%s\\\" to address: %s\\n\"),\n\t\t\t\t\t\t\t\t\t  portstr, gai_strerror(ret));\n\t\t\t\t\tgoto keep_going;\n\t\t\t\t}\n#else\n\t\t\t\tAssert(false);\n#endif\n\t\t\t\tbreak;\n\t\t}\n\n\t\t/* OK, scan this addrlist for a working server address */\n\t\tconn->addr_cur = conn->addrlist;\n\t\treset_connection_state_machine = true;\n\t\tconn->try_next_host = false;\n\t}\n\n\t/* Reset connection state machine? */\n\tif (reset_connection_state_machine)\n\t{\n\t\t/*\n\t\t * (Re) initialize our connection control variables for a set of\n\t\t * connection attempts to a single server address.  These variables\n\t\t * must persist across individual connection attempts, but we must\n\t\t * reset them when we start to consider a new server.\n\t\t */\n\t\tconn->pversion = PG_PROTOCOL(3, 0);\n\t\tconn->send_appname = true;\n#ifdef USE_SSL\n\t\t/* initialize these values based on SSL mode */\n\t\tconn->allow_ssl_try = (conn->sslmode[0] != 'd');\t/* \"disable\" */\n\t\tconn->wait_ssl_try = (conn->sslmode[0] == 'a'); /* \"allow\" */\n#endif\n#ifdef ENABLE_GSS\n\t\tconn->try_gss = (conn->gssencmode[0] != 'd');\t/* \"disable\" */\n#endif\n\n\t\treset_connection_state_machine = false;\n\t\tneed_new_connection = true;\n\t}\n\n\t/* Force a new connection (perhaps to the same server as before)? */\n\tif (need_new_connection)\n\t{\n\t\t/* Drop any existing connection */\n\t\tpqDropConnection(conn, true);\n\n\t\t/* Reset all state obtained from old server */\n\t\tpqDropServerData(conn);\n\n\t\t/* Drop any PGresult we might have, too */\n\t\tconn->asyncStatus = PGASYNC_IDLE;\n\t\tconn->xactStatus = PQTRANS_IDLE;\n\t\tconn->pipelineStatus = PQ_PIPELINE_OFF;\n\t\tpqClearAsyncResult(conn);\n\n\t\t/* Reset conn->status to put the state machine in the right state */\n\t\tconn->status = CONNECTION_NEEDED;\n\n\t\tneed_new_connection = false;\n\t}\n\n\t/* Now try to advance the state machine for this connection */\n\tswitch (conn->status)\n\t{\n\t\tcase CONNECTION_NEEDED:\n\t\t\t{\n\t\t\t\t/*\n\t\t\t\t * Try to initiate a connection to one of the addresses\n\t\t\t\t * returned by pg_getaddrinfo_all().  conn->addr_cur is the\n\t\t\t\t * next one to try.\n\t\t\t\t *\n\t\t\t\t * The extra level of braces here is historical.  It's not\n\t\t\t\t * worth reindenting this whole switch case to remove 'em.\n\t\t\t\t */\n\t\t\t\t{\n\t\t\t\t\tstruct addrinfo *addr_cur = conn->addr_cur;\n\t\t\t\t\tchar\t\thost_addr[NI_MAXHOST];\n\n\t\t\t\t\t/*\n\t\t\t\t\t * Advance to next possible host, if we've tried all of\n\t\t\t\t\t * the addresses for the current host.\n\t\t\t\t\t */\n\t\t\t\t\tif (addr_cur == NULL)\n\t\t\t\t\t{\n\t\t\t\t\t\tconn->try_next_host = true;\n\t\t\t\t\t\tgoto keep_going;\n\t\t\t\t\t}\n\n\t\t\t\t\t/* Remember current address for possible use later */\n\t\t\t\t\tmemcpy(&conn->raddr.addr, addr_cur->ai_addr,\n\t\t\t\t\t\t   addr_cur->ai_addrlen);\n\t\t\t\t\tconn->raddr.salen = addr_cur->ai_addrlen;\n\n\t\t\t\t\t/*\n\t\t\t\t\t * Set connip, too.  Note we purposely ignore strdup\n\t\t\t\t\t * failure; not a big problem if it fails.\n\t\t\t\t\t */\n\t\t\t\t\tif (conn->connip != NULL)\n\t\t\t\t\t{\n\t\t\t\t\t\tfree(conn->connip);\n\t\t\t\t\t\tconn->connip = NULL;\n\t\t\t\t\t}\n\t\t\t\t\tgetHostaddr(conn, host_addr, NI_MAXHOST);\n\t\t\t\t\tif (host_addr[0])\n\t\t\t\t\t\tconn->connip = strdup(host_addr);\n\n\t\t\t\t\t/* Try to create the socket */\n\t\t\t\t\tconn->sock = socket(addr_cur->ai_family, SOCK_STREAM, 0);\n\t\t\t\t\tif (conn->sock == PGINVALID_SOCKET)\n\t\t\t\t\t{\n\t\t\t\t\t\tint\t\t\terrorno = SOCK_ERRNO;\n\n\t\t\t\t\t\t/*\n\t\t\t\t\t\t * Silently ignore socket() failure if we have more\n\t\t\t\t\t\t * addresses to try; this reduces useless chatter in\n\t\t\t\t\t\t * cases where the address list includes both IPv4 and\n\t\t\t\t\t\t * IPv6 but kernel only accepts one family.\n\t\t\t\t\t\t */\n\t\t\t\t\t\tif (addr_cur->ai_next != NULL ||\n\t\t\t\t\t\t\tconn->whichhost + 1 < conn->nconnhost)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tconn->try_next_addr = true;\n\t\t\t\t\t\t\tgoto keep_going;\n\t\t\t\t\t\t}\n\t\t\t\t\t\temitHostIdentityInfo(conn, host_addr);\n\t\t\t\t\t\tappendPQExpBuffer(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t\t  libpq_gettext(\"could not create socket: %s\\n\"),\n\t\t\t\t\t\t\t\t\t\t  SOCK_STRERROR(errorno, sebuf, sizeof(sebuf)));\n\t\t\t\t\t\tgoto error_return;\n\t\t\t\t\t}\n\n\t\t\t\t\t/*\n\t\t\t\t\t * Once we've identified a target address, all errors\n\t\t\t\t\t * except the preceding socket()-failure case should be\n\t\t\t\t\t * prefixed with host-identity information.  (If the\n\t\t\t\t\t * connection succeeds, the contents of conn->errorMessage\n\t\t\t\t\t * won't matter, so this is harmless.)\n\t\t\t\t\t */\n\t\t\t\t\temitHostIdentityInfo(conn, host_addr);\n\n\t\t\t\t\t/*\n\t\t\t\t\t * Select socket options: no delay of outgoing data for\n\t\t\t\t\t * TCP sockets, nonblock mode, close-on-exec.  Try the\n\t\t\t\t\t * next address if any of this fails.\n\t\t\t\t\t */\n\t\t\t\t\tif (!IS_AF_UNIX(addr_cur->ai_family))\n\t\t\t\t\t{\n\t\t\t\t\t\tif (!connectNoDelay(conn))\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t/* error message already created */\n\t\t\t\t\t\t\tconn->try_next_addr = true;\n\t\t\t\t\t\t\tgoto keep_going;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif (!pg_set_noblock(conn->sock))\n\t\t\t\t\t{\n\t\t\t\t\t\tappendPQExpBuffer(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t\t  libpq_gettext(\"could not set socket to nonblocking mode: %s\\n\"),\n\t\t\t\t\t\t\t\t\t\t  SOCK_STRERROR(SOCK_ERRNO, sebuf, sizeof(sebuf)));\n\t\t\t\t\t\tconn->try_next_addr = true;\n\t\t\t\t\t\tgoto keep_going;\n\t\t\t\t\t}\n\n#ifdef F_SETFD\n\t\t\t\t\tif (fcntl(conn->sock, F_SETFD, FD_CLOEXEC) == -1)\n\t\t\t\t\t{\n\t\t\t\t\t\tappendPQExpBuffer(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t\t  libpq_gettext(\"could not set socket to close-on-exec mode: %s\\n\"),\n\t\t\t\t\t\t\t\t\t\t  SOCK_STRERROR(SOCK_ERRNO, sebuf, sizeof(sebuf)));\n\t\t\t\t\t\tconn->try_next_addr = true;\n\t\t\t\t\t\tgoto keep_going;\n\t\t\t\t\t}\n#endif\t\t\t\t\t\t\t/* F_SETFD */\n\n\t\t\t\t\tif (!IS_AF_UNIX(addr_cur->ai_family))\n\t\t\t\t\t{\n#ifndef WIN32\n\t\t\t\t\t\tint\t\t\ton = 1;\n#endif\n\t\t\t\t\t\tint\t\t\tusekeepalives = useKeepalives(conn);\n\t\t\t\t\t\tint\t\t\terr = 0;\n\n\t\t\t\t\t\tif (usekeepalives < 0)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tappendPQExpBufferStr(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t\t\t\t libpq_gettext(\"keepalives parameter must be an integer\\n\"));\n\t\t\t\t\t\t\terr = 1;\n\t\t\t\t\t\t}\n\t\t\t\t\t\telse if (usekeepalives == 0)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t/* Do nothing */\n\t\t\t\t\t\t}\n#ifndef WIN32\n\t\t\t\t\t\telse if (setsockopt(conn->sock,\n\t\t\t\t\t\t\t\t\t\t\tSOL_SOCKET, SO_KEEPALIVE,\n\t\t\t\t\t\t\t\t\t\t\t(char *) &on, sizeof(on)) < 0)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tappendPQExpBuffer(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t\t\t  libpq_gettext(\"%s(%s) failed: %s\\n\"),\n\t\t\t\t\t\t\t\t\t\t\t  \"setsockopt\",\n\t\t\t\t\t\t\t\t\t\t\t  \"SO_KEEPALIVE\",\n\t\t\t\t\t\t\t\t\t\t\t  SOCK_STRERROR(SOCK_ERRNO, sebuf, sizeof(sebuf)));\n\t\t\t\t\t\t\terr = 1;\n\t\t\t\t\t\t}\n\t\t\t\t\t\telse if (!setKeepalivesIdle(conn)\n\t\t\t\t\t\t\t\t || !setKeepalivesInterval(conn)\n\t\t\t\t\t\t\t\t || !setKeepalivesCount(conn))\n\t\t\t\t\t\t\terr = 1;\n#else\t\t\t\t\t\t\t/* WIN32 */\n#ifdef SIO_KEEPALIVE_VALS\n\t\t\t\t\t\telse if (!setKeepalivesWin32(conn))\n\t\t\t\t\t\t\terr = 1;\n#endif\t\t\t\t\t\t\t/* SIO_KEEPALIVE_VALS */\n#endif\t\t\t\t\t\t\t/* WIN32 */\n\t\t\t\t\t\telse if (!setTCPUserTimeout(conn))\n\t\t\t\t\t\t\terr = 1;\n\n\t\t\t\t\t\tif (err)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tconn->try_next_addr = true;\n\t\t\t\t\t\t\tgoto keep_going;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\t/*----------\n\t\t\t\t\t * We have three methods of blocking SIGPIPE during\n\t\t\t\t\t * send() calls to this socket:\n\t\t\t\t\t *\n\t\t\t\t\t *\t- setsockopt(sock, SO_NOSIGPIPE)\n\t\t\t\t\t *\t- send(sock, ..., MSG_NOSIGNAL)\n\t\t\t\t\t *\t- setting the signal mask to SIG_IGN during send()\n\t\t\t\t\t *\n\t\t\t\t\t * The third method requires three syscalls per send,\n\t\t\t\t\t * so we prefer either of the first two, but they are\n\t\t\t\t\t * less portable.  The state is tracked in the following\n\t\t\t\t\t * members of PGconn:\n\t\t\t\t\t *\n\t\t\t\t\t * conn->sigpipe_so\t\t- we have set up SO_NOSIGPIPE\n\t\t\t\t\t * conn->sigpipe_flag\t- we're specifying MSG_NOSIGNAL\n\t\t\t\t\t *\n\t\t\t\t\t * If we can use SO_NOSIGPIPE, then set sigpipe_so here\n\t\t\t\t\t * and we're done.  Otherwise, set sigpipe_flag so that\n\t\t\t\t\t * we will try MSG_NOSIGNAL on sends.  If we get an error\n\t\t\t\t\t * with MSG_NOSIGNAL, we'll clear that flag and revert to\n\t\t\t\t\t * signal masking.\n\t\t\t\t\t *----------\n\t\t\t\t\t */\n\t\t\t\t\tconn->sigpipe_so = false;\n#ifdef MSG_NOSIGNAL\n\t\t\t\t\tconn->sigpipe_flag = true;\n#else\n\t\t\t\t\tconn->sigpipe_flag = false;\n#endif\t\t\t\t\t\t\t/* MSG_NOSIGNAL */\n\n#ifdef SO_NOSIGPIPE\n\t\t\t\t\toptval = 1;\n\t\t\t\t\tif (setsockopt(conn->sock, SOL_SOCKET, SO_NOSIGPIPE,\n\t\t\t\t\t\t\t\t   (char *) &optval, sizeof(optval)) == 0)\n\t\t\t\t\t{\n\t\t\t\t\t\tconn->sigpipe_so = true;\n\t\t\t\t\t\tconn->sigpipe_flag = false;\n\t\t\t\t\t}\n#endif\t\t\t\t\t\t\t/* SO_NOSIGPIPE */\n\n\t\t\t\t\t/*\n\t\t\t\t\t * Start/make connection.  This should not block, since we\n\t\t\t\t\t * are in nonblock mode.  If it does, well, too bad.\n\t\t\t\t\t */\n\t\t\t\t\tif (connect(conn->sock, addr_cur->ai_addr,\n\t\t\t\t\t\t\t\taddr_cur->ai_addrlen) < 0)\n\t\t\t\t\t{\n\t\t\t\t\t\tif (SOCK_ERRNO == EINPROGRESS ||\n#ifdef WIN32\n\t\t\t\t\t\t\tSOCK_ERRNO == EWOULDBLOCK ||\n#endif\n\t\t\t\t\t\t\tSOCK_ERRNO == EINTR)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t/*\n\t\t\t\t\t\t\t * This is fine - we're in non-blocking mode, and\n\t\t\t\t\t\t\t * the connection is in progress.  Tell caller to\n\t\t\t\t\t\t\t * wait for write-ready on socket.\n\t\t\t\t\t\t\t */\n\t\t\t\t\t\t\tconn->status = CONNECTION_STARTED;\n\t\t\t\t\t\t\treturn PGRES_POLLING_WRITING;\n\t\t\t\t\t\t}\n\t\t\t\t\t\t/* otherwise, trouble */\n\t\t\t\t\t}\n\t\t\t\t\telse\n\t\t\t\t\t{\n\t\t\t\t\t\t/*\n\t\t\t\t\t\t * Hm, we're connected already --- seems the \"nonblock\n\t\t\t\t\t\t * connection\" wasn't.  Advance the state machine and\n\t\t\t\t\t\t * go do the next stuff.\n\t\t\t\t\t\t */\n\t\t\t\t\t\tconn->status = CONNECTION_STARTED;\n\t\t\t\t\t\tgoto keep_going;\n\t\t\t\t\t}\n\n\t\t\t\t\t/*\n\t\t\t\t\t * This connection failed.  Add the error report to\n\t\t\t\t\t * conn->errorMessage, then try the next address if any.\n\t\t\t\t\t */\n\t\t\t\t\tconnectFailureMessage(conn, SOCK_ERRNO);\n\t\t\t\t\tconn->try_next_addr = true;\n\t\t\t\t\tgoto keep_going;\n\t\t\t\t}\n\t\t\t}\n\n\t\tcase CONNECTION_STARTED:\n\t\t\t{\n\t\t\t\tACCEPT_TYPE_ARG3 optlen = sizeof(optval);\n\n\t\t\t\t/*\n\t\t\t\t * Write ready, since we've made it here, so the connection\n\t\t\t\t * has been made ... or has failed.\n\t\t\t\t */\n\n\t\t\t\t/*\n\t\t\t\t * Now check (using getsockopt) that there is not an error\n\t\t\t\t * state waiting for us on the socket.\n\t\t\t\t */\n\n\t\t\t\tif (getsockopt(conn->sock, SOL_SOCKET, SO_ERROR,\n\t\t\t\t\t\t\t   (char *) &optval, &optlen) == -1)\n\t\t\t\t{\n\t\t\t\t\tappendPQExpBuffer(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t  libpq_gettext(\"could not get socket error status: %s\\n\"),\n\t\t\t\t\t\t\t\t\t  SOCK_STRERROR(SOCK_ERRNO, sebuf, sizeof(sebuf)));\n\t\t\t\t\tgoto error_return;\n\t\t\t\t}\n\t\t\t\telse if (optval != 0)\n\t\t\t\t{\n\t\t\t\t\t/*\n\t\t\t\t\t * When using a nonblocking connect, we will typically see\n\t\t\t\t\t * connect failures at this point, so provide a friendly\n\t\t\t\t\t * error message.\n\t\t\t\t\t */\n\t\t\t\t\tconnectFailureMessage(conn, optval);\n\n\t\t\t\t\t/*\n\t\t\t\t\t * Try the next address if any, just as in the case where\n\t\t\t\t\t * connect() returned failure immediately.\n\t\t\t\t\t */\n\t\t\t\t\tconn->try_next_addr = true;\n\t\t\t\t\tgoto keep_going;\n\t\t\t\t}\n\n\t\t\t\t/* Fill in the client address */\n\t\t\t\tconn->laddr.salen = sizeof(conn->laddr.addr);\n\t\t\t\tif (getsockname(conn->sock,\n\t\t\t\t\t\t\t\t(struct sockaddr *) &conn->laddr.addr,\n\t\t\t\t\t\t\t\t&conn->laddr.salen) < 0)\n\t\t\t\t{\n\t\t\t\t\tappendPQExpBuffer(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t  libpq_gettext(\"could not get client address from socket: %s\\n\"),\n\t\t\t\t\t\t\t\t\t  SOCK_STRERROR(SOCK_ERRNO, sebuf, sizeof(sebuf)));\n\t\t\t\t\tgoto error_return;\n\t\t\t\t}\n\n\t\t\t\t/*\n\t\t\t\t * Make sure we can write before advancing to next step.\n\t\t\t\t */\n\t\t\t\tconn->status = CONNECTION_MADE;\n\t\t\t\treturn PGRES_POLLING_WRITING;\n\t\t\t}\n\n\t\tcase CONNECTION_MADE:\n\t\t\t{\n\t\t\t\tchar\t   *startpacket;\n\t\t\t\tint\t\t\tpacketlen;\n\n\t\t\t\t/*\n\t\t\t\t * Implement requirepeer check, if requested and it's a\n\t\t\t\t * Unix-domain socket.\n\t\t\t\t */\n\t\t\t\tif (conn->requirepeer && conn->requirepeer[0] &&\n\t\t\t\t\tIS_AF_UNIX(conn->raddr.addr.ss_family))\n\t\t\t\t{\n#ifndef WIN32\n\t\t\t\t\tchar\t\tpwdbuf[BUFSIZ];\n\t\t\t\t\tstruct passwd pass_buf;\n\t\t\t\t\tstruct passwd *pass;\n\t\t\t\t\tint\t\t\tpasserr;\n#endif\n\t\t\t\t\tuid_t\t\tuid;\n\t\t\t\t\tgid_t\t\tgid;\n\n\t\t\t\t\terrno = 0;\n\t\t\t\t\tif (getpeereid(conn->sock, &uid, &gid) != 0)\n\t\t\t\t\t{\n\t\t\t\t\t\t/*\n\t\t\t\t\t\t * Provide special error message if getpeereid is a\n\t\t\t\t\t\t * stub\n\t\t\t\t\t\t */\n\t\t\t\t\t\tif (errno == ENOSYS)\n\t\t\t\t\t\t\tappendPQExpBufferStr(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t\t\t\t libpq_gettext(\"requirepeer parameter is not supported on this platform\\n\"));\n\t\t\t\t\t\telse\n\t\t\t\t\t\t\tappendPQExpBuffer(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t\t\t  libpq_gettext(\"could not get peer credentials: %s\\n\"),\n\t\t\t\t\t\t\t\t\t\t\t  strerror_r(errno, sebuf, sizeof(sebuf)));\n\t\t\t\t\t\tgoto error_return;\n\t\t\t\t\t}\n\n#ifndef WIN32\n\t\t\t\t\tpasserr = pqGetpwuid(uid, &pass_buf, pwdbuf, sizeof(pwdbuf), &pass);\n\t\t\t\t\tif (pass == NULL)\n\t\t\t\t\t{\n\t\t\t\t\t\tif (passerr != 0)\n\t\t\t\t\t\t\tappendPQExpBuffer(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t\t\t  libpq_gettext(\"could not look up local user ID %d: %s\\n\"),\n\t\t\t\t\t\t\t\t\t\t\t  (int) uid,\n\t\t\t\t\t\t\t\t\t\t\t  strerror_r(passerr, sebuf, sizeof(sebuf)));\n\t\t\t\t\t\telse\n\t\t\t\t\t\t\tappendPQExpBuffer(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t\t\t  libpq_gettext(\"local user with ID %d does not exist\\n\"),\n\t\t\t\t\t\t\t\t\t\t\t  (int) uid);\n\t\t\t\t\t\tgoto error_return;\n\t\t\t\t\t}\n\n\t\t\t\t\tif (strcmp(pass->pw_name, conn->requirepeer) != 0)\n\t\t\t\t\t{\n\t\t\t\t\t\tappendPQExpBuffer(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t\t  libpq_gettext(\"requirepeer specifies \\\"%s\\\", but actual peer user name is \\\"%s\\\"\\n\"),\n\t\t\t\t\t\t\t\t\t\t  conn->requirepeer, pass->pw_name);\n\t\t\t\t\t\tgoto error_return;\n\t\t\t\t\t}\n#else\t\t\t\t\t\t\t/* WIN32 */\n\t\t\t\t\t/* should have failed with ENOSYS above */\n\t\t\t\t\tAssert(false);\n#endif\t\t\t\t\t\t\t/* WIN32 */\n\t\t\t\t}\n\n\t\t\t\tif (IS_AF_UNIX(conn->raddr.addr.ss_family))\n\t\t\t\t{\n\t\t\t\t\t/* Don't request SSL or GSSAPI over Unix sockets */\n#ifdef USE_SSL\n\t\t\t\t\tconn->allow_ssl_try = false;\n#endif\n#ifdef ENABLE_GSS\n\t\t\t\t\tconn->try_gss = false;\n#endif\n\t\t\t\t}\n\n#ifdef ENABLE_GSS\n\n\t\t\t\t/*\n\t\t\t\t * If GSSAPI encryption is enabled, then call\n\t\t\t\t * pg_GSS_have_cred_cache() which will return true if we can\n\t\t\t\t * acquire credentials (and give us a handle to use in\n\t\t\t\t * conn->gcred), and then send a packet to the server asking\n\t\t\t\t * for GSSAPI Encryption (and skip past SSL negotiation and\n\t\t\t\t * regular startup below).\n\t\t\t\t */\n\t\t\t\tif (conn->try_gss && !conn->gctx)\n\t\t\t\t\tconn->try_gss = pg_GSS_have_cred_cache(&conn->gcred);\n\t\t\t\tif (conn->try_gss && !conn->gctx)\n\t\t\t\t{\n\t\t\t\t\tProtocolVersion pv = pg_hton32(NEGOTIATE_GSS_CODE);\n\n\t\t\t\t\tif (pqPacketSend(conn, 0, &pv, sizeof(pv)) != STATUS_OK)\n\t\t\t\t\t{\n\t\t\t\t\t\tappendPQExpBuffer(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t\t  libpq_gettext(\"could not send GSSAPI negotiation packet: %s\\n\"),\n\t\t\t\t\t\t\t\t\t\t  SOCK_STRERROR(SOCK_ERRNO, sebuf, sizeof(sebuf)));\n\t\t\t\t\t\tgoto error_return;\n\t\t\t\t\t}\n\n\t\t\t\t\t/* Ok, wait for response */\n\t\t\t\t\tconn->status = CONNECTION_GSS_STARTUP;\n\t\t\t\t\treturn PGRES_POLLING_READING;\n\t\t\t\t}\n\t\t\t\telse if (!conn->gctx && conn->gssencmode[0] == 'r')\n\t\t\t\t{\n\t\t\t\t\tappendPQExpBufferStr(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t\t libpq_gettext(\"GSSAPI encryption required but was impossible (possibly no credential cache, no server support, or using a local socket)\\n\"));\n\t\t\t\t\tgoto error_return;\n\t\t\t\t}\n#endif\n\n#ifdef USE_SSL\n\n\t\t\t\t/*\n\t\t\t\t * Enable the libcrypto callbacks before checking if SSL needs\n\t\t\t\t * to be done.  This is done before sending the startup packet\n\t\t\t\t * as depending on the type of authentication done, like MD5\n\t\t\t\t * or SCRAM that use cryptohashes, the callbacks would be\n\t\t\t\t * required even without a SSL connection\n\t\t\t\t */\n\t\t\t\tif (pqsecure_initialize(conn, false, true) < 0)\n\t\t\t\t\tgoto error_return;\n\n\t\t\t\t/*\n\t\t\t\t * If SSL is enabled and we haven't already got encryption of\n\t\t\t\t * some sort running, request SSL instead of sending the\n\t\t\t\t * startup message.\n\t\t\t\t */\n\t\t\t\tif (conn->allow_ssl_try && !conn->wait_ssl_try &&\n\t\t\t\t\t!conn->ssl_in_use\n#ifdef ENABLE_GSS\n\t\t\t\t\t&& !conn->gssenc\n#endif\n\t\t\t\t\t)\n\t\t\t\t{\n\t\t\t\t\tProtocolVersion pv;\n\n\t\t\t\t\t/*\n\t\t\t\t\t * Send the SSL request packet.\n\t\t\t\t\t *\n\t\t\t\t\t * Theoretically, this could block, but it really\n\t\t\t\t\t * shouldn't since we only got here if the socket is\n\t\t\t\t\t * write-ready.\n\t\t\t\t\t */\n\t\t\t\t\tpv = pg_hton32(NEGOTIATE_SSL_CODE);\n\t\t\t\t\tif (pqPacketSend(conn, 0, &pv, sizeof(pv)) != STATUS_OK)\n\t\t\t\t\t{\n\t\t\t\t\t\tappendPQExpBuffer(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t\t  libpq_gettext(\"could not send SSL negotiation packet: %s\\n\"),\n\t\t\t\t\t\t\t\t\t\t  SOCK_STRERROR(SOCK_ERRNO, sebuf, sizeof(sebuf)));\n\t\t\t\t\t\tgoto error_return;\n\t\t\t\t\t}\n\t\t\t\t\t/* Ok, wait for response */\n\t\t\t\t\tconn->status = CONNECTION_SSL_STARTUP;\n\t\t\t\t\treturn PGRES_POLLING_READING;\n\t\t\t\t}\n#endif\t\t\t\t\t\t\t/* USE_SSL */\n\n\t\t\t\t/*\n\t\t\t\t * Build the startup packet.\n\t\t\t\t */\n\t\t\t\tstartpacket = pqBuildStartupPacket3(conn, &packetlen,\n\t\t\t\t\t\t\t\t\t\t\t\t\tEnvironmentOptions);\n\t\t\t\tif (!startpacket)\n\t\t\t\t{\n\t\t\t\t\tappendPQExpBufferStr(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t\t libpq_gettext(\"out of memory\\n\"));\n\t\t\t\t\tgoto error_return;\n\t\t\t\t}\n\n\t\t\t\t/*\n\t\t\t\t * Send the startup packet.\n\t\t\t\t *\n\t\t\t\t * Theoretically, this could block, but it really shouldn't\n\t\t\t\t * since we only got here if the socket is write-ready.\n\t\t\t\t */\n\t\t\t\tif (pqPacketSend(conn, 0, startpacket, packetlen) != STATUS_OK)\n\t\t\t\t{\n\t\t\t\t\tappendPQExpBuffer(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t  libpq_gettext(\"could not send startup packet: %s\\n\"),\n\t\t\t\t\t\t\t\t\t  SOCK_STRERROR(SOCK_ERRNO, sebuf, sizeof(sebuf)));\n\t\t\t\t\tfree(startpacket);\n\t\t\t\t\tgoto error_return;\n\t\t\t\t}\n\n\t\t\t\tfree(startpacket);\n\n\t\t\t\tconn->status = CONNECTION_AWAITING_RESPONSE;\n\t\t\t\treturn PGRES_POLLING_READING;\n\t\t\t}\n\n\t\t\t/*\n\t\t\t * Handle SSL negotiation: wait for postmaster messages and\n\t\t\t * respond as necessary.\n\t\t\t */\n\t\tcase CONNECTION_SSL_STARTUP:\n\t\t\t{\n#ifdef USE_SSL\n\t\t\t\tPostgresPollingStatusType pollres;\n\n\t\t\t\t/*\n\t\t\t\t * On first time through, get the postmaster's response to our\n\t\t\t\t * SSL negotiation packet.\n\t\t\t\t */\n\t\t\t\tif (!conn->ssl_in_use)\n\t\t\t\t{\n\t\t\t\t\t/*\n\t\t\t\t\t * We use pqReadData here since it has the logic to\n\t\t\t\t\t * distinguish no-data-yet from connection closure. Since\n\t\t\t\t\t * conn->ssl isn't set, a plain recv() will occur.\n\t\t\t\t\t */\n\t\t\t\t\tchar\t\tSSLok;\n\t\t\t\t\tint\t\t\trdresult;\n\n\t\t\t\t\trdresult = pqReadData(conn);\n\t\t\t\t\tif (rdresult < 0)\n\t\t\t\t\t{\n\t\t\t\t\t\t/* errorMessage is already filled in */\n\t\t\t\t\t\tgoto error_return;\n\t\t\t\t\t}\n\t\t\t\t\tif (rdresult == 0)\n\t\t\t\t\t{\n\t\t\t\t\t\t/* caller failed to wait for data */\n\t\t\t\t\t\treturn PGRES_POLLING_READING;\n\t\t\t\t\t}\n\t\t\t\t\tif (pqGetc(&SSLok, conn) < 0)\n\t\t\t\t\t{\n\t\t\t\t\t\t/* should not happen really */\n\t\t\t\t\t\treturn PGRES_POLLING_READING;\n\t\t\t\t\t}\n\t\t\t\t\tif (SSLok == 'S')\n\t\t\t\t\t{\n\t\t\t\t\t\t/* mark byte consumed */\n\t\t\t\t\t\tconn->inStart = conn->inCursor;\n\n\t\t\t\t\t\t/*\n\t\t\t\t\t\t * Set up global SSL state if required.  The crypto\n\t\t\t\t\t\t * state has already been set if libpq took care of\n\t\t\t\t\t\t * doing that, so there is no need to make that happen\n\t\t\t\t\t\t * again.\n\t\t\t\t\t\t */\n\t\t\t\t\t\tif (pqsecure_initialize(conn, true, false) != 0)\n\t\t\t\t\t\t\tgoto error_return;\n\t\t\t\t\t}\n\t\t\t\t\telse if (SSLok == 'N')\n\t\t\t\t\t{\n\t\t\t\t\t\t/* mark byte consumed */\n\t\t\t\t\t\tconn->inStart = conn->inCursor;\n\t\t\t\t\t\t/* OK to do without SSL? */\n\t\t\t\t\t\tif (conn->sslmode[0] == 'r' ||\t/* \"require\" */\n\t\t\t\t\t\t\tconn->sslmode[0] == 'v')\t/* \"verify-ca\" or\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t * \"verify-full\" */\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t/* Require SSL, but server does not want it */\n\t\t\t\t\t\t\tappendPQExpBufferStr(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t\t\t\t libpq_gettext(\"server does not support SSL, but SSL was required\\n\"));\n\t\t\t\t\t\t\tgoto error_return;\n\t\t\t\t\t\t}\n\t\t\t\t\t\t/* Otherwise, proceed with normal startup */\n\t\t\t\t\t\tconn->allow_ssl_try = false;\n\t\t\t\t\t\t/* We can proceed using this connection */\n\t\t\t\t\t\tconn->status = CONNECTION_MADE;\n\t\t\t\t\t\treturn PGRES_POLLING_WRITING;\n\t\t\t\t\t}\n\t\t\t\t\telse if (SSLok == 'E')\n\t\t\t\t\t{\n\t\t\t\t\t\t/*\n\t\t\t\t\t\t * Server failure of some sort, such as failure to\n\t\t\t\t\t\t * fork a backend process.  We need to process and\n\t\t\t\t\t\t * report the error message, which might be formatted\n\t\t\t\t\t\t * according to either protocol 2 or protocol 3.\n\t\t\t\t\t\t * Rather than duplicate the code for that, we flip\n\t\t\t\t\t\t * into AWAITING_RESPONSE state and let the code there\n\t\t\t\t\t\t * deal with it.  Note we have *not* consumed the \"E\"\n\t\t\t\t\t\t * byte here.\n\t\t\t\t\t\t */\n\t\t\t\t\t\tconn->status = CONNECTION_AWAITING_RESPONSE;\n\t\t\t\t\t\tgoto keep_going;\n\t\t\t\t\t}\n\t\t\t\t\telse\n\t\t\t\t\t{\n\t\t\t\t\t\tappendPQExpBuffer(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t\t  libpq_gettext(\"received invalid response to SSL negotiation: %c\\n\"),\n\t\t\t\t\t\t\t\t\t\t  SSLok);\n\t\t\t\t\t\tgoto error_return;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t/*\n\t\t\t\t * Begin or continue the SSL negotiation process.\n\t\t\t\t */\n\t\t\t\tpollres = pqsecure_open_client(conn);\n\t\t\t\tif (pollres == PGRES_POLLING_OK)\n\t\t\t\t{\n\t\t\t\t\t/* SSL handshake done, ready to send startup packet */\n\t\t\t\t\tconn->status = CONNECTION_MADE;\n\t\t\t\t\treturn PGRES_POLLING_WRITING;\n\t\t\t\t}\n\t\t\t\tif (pollres == PGRES_POLLING_FAILED)\n\t\t\t\t{\n\t\t\t\t\t/*\n\t\t\t\t\t * Failed ... if sslmode is \"prefer\" then do a non-SSL\n\t\t\t\t\t * retry\n\t\t\t\t\t */\n\t\t\t\t\tif (conn->sslmode[0] == 'p' /* \"prefer\" */\n\t\t\t\t\t\t&& conn->allow_ssl_try\t/* redundant? */\n\t\t\t\t\t\t&& !conn->wait_ssl_try) /* redundant? */\n\t\t\t\t\t{\n\t\t\t\t\t\t/* only retry once */\n\t\t\t\t\t\tconn->allow_ssl_try = false;\n\t\t\t\t\t\tneed_new_connection = true;\n\t\t\t\t\t\tgoto keep_going;\n\t\t\t\t\t}\n\t\t\t\t\t/* Else it's a hard failure */\n\t\t\t\t\tgoto error_return;\n\t\t\t\t}\n\t\t\t\t/* Else, return POLLING_READING or POLLING_WRITING status */\n\t\t\t\treturn pollres;\n#else\t\t\t\t\t\t\t/* !USE_SSL */\n\t\t\t\t/* can't get here */\n\t\t\t\tgoto error_return;\n#endif\t\t\t\t\t\t\t/* USE_SSL */\n\t\t\t}\n\n\t\tcase CONNECTION_GSS_STARTUP:\n\t\t\t{\n#ifdef ENABLE_GSS\n\t\t\t\tPostgresPollingStatusType pollres;\n\n\t\t\t\t/*\n\t\t\t\t * If we haven't yet, get the postmaster's response to our\n\t\t\t\t * negotiation packet\n\t\t\t\t */\n\t\t\t\tif (conn->try_gss && !conn->gctx)\n\t\t\t\t{\n\t\t\t\t\tchar\t\tgss_ok;\n\t\t\t\t\tint\t\t\trdresult = pqReadData(conn);\n\n\t\t\t\t\tif (rdresult < 0)\n\t\t\t\t\t\t/* pqReadData fills in error message */\n\t\t\t\t\t\tgoto error_return;\n\t\t\t\t\telse if (rdresult == 0)\n\t\t\t\t\t\t/* caller failed to wait for data */\n\t\t\t\t\t\treturn PGRES_POLLING_READING;\n\t\t\t\t\tif (pqGetc(&gss_ok, conn) < 0)\n\t\t\t\t\t\t/* shouldn't happen... */\n\t\t\t\t\t\treturn PGRES_POLLING_READING;\n\n\t\t\t\t\tif (gss_ok == 'E')\n\t\t\t\t\t{\n\t\t\t\t\t\t/*\n\t\t\t\t\t\t * Server failure of some sort.  Assume it's a\n\t\t\t\t\t\t * protocol version support failure, and let's see if\n\t\t\t\t\t\t * we can't recover (if it's not, we'll get a better\n\t\t\t\t\t\t * error message on retry).  Server gets fussy if we\n\t\t\t\t\t\t * don't hang up the socket, though.\n\t\t\t\t\t\t */\n\t\t\t\t\t\tconn->try_gss = false;\n\t\t\t\t\t\tneed_new_connection = true;\n\t\t\t\t\t\tgoto keep_going;\n\t\t\t\t\t}\n\n\t\t\t\t\t/* mark byte consumed */\n\t\t\t\t\tconn->inStart = conn->inCursor;\n\n\t\t\t\t\tif (gss_ok == 'N')\n\t\t\t\t\t{\n\t\t\t\t\t\t/* Server doesn't want GSSAPI; fall back if we can */\n\t\t\t\t\t\tif (conn->gssencmode[0] == 'r')\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tappendPQExpBufferStr(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t\t\t\t libpq_gettext(\"server doesn't support GSSAPI encryption, but it was required\\n\"));\n\t\t\t\t\t\t\tgoto error_return;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tconn->try_gss = false;\n\t\t\t\t\t\t/* We can proceed using this connection */\n\t\t\t\t\t\tconn->status = CONNECTION_MADE;\n\t\t\t\t\t\treturn PGRES_POLLING_WRITING;\n\t\t\t\t\t}\n\t\t\t\t\telse if (gss_ok != 'G')\n\t\t\t\t\t{\n\t\t\t\t\t\tappendPQExpBuffer(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t\t  libpq_gettext(\"received invalid response to GSSAPI negotiation: %c\\n\"),\n\t\t\t\t\t\t\t\t\t\t  gss_ok);\n\t\t\t\t\t\tgoto error_return;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t/* Begin or continue GSSAPI negotiation */\n\t\t\t\tpollres = pqsecure_open_gss(conn);\n\t\t\t\tif (pollres == PGRES_POLLING_OK)\n\t\t\t\t{\n\t\t\t\t\t/* All set for startup packet */\n\t\t\t\t\tconn->status = CONNECTION_MADE;\n\t\t\t\t\treturn PGRES_POLLING_WRITING;\n\t\t\t\t}\n\t\t\t\telse if (pollres == PGRES_POLLING_FAILED &&\n\t\t\t\t\t\t conn->gssencmode[0] == 'p')\n\t\t\t\t{\n\t\t\t\t\t/*\n\t\t\t\t\t * We failed, but we can retry on \"prefer\".  Have to drop\n\t\t\t\t\t * the current connection to do so, though.\n\t\t\t\t\t */\n\t\t\t\t\tconn->try_gss = false;\n\t\t\t\t\tneed_new_connection = true;\n\t\t\t\t\tgoto keep_going;\n\t\t\t\t}\n\t\t\t\treturn pollres;\n#else\t\t\t\t\t\t\t/* !ENABLE_GSS */\n\t\t\t\t/* unreachable */\n\t\t\t\tgoto error_return;\n#endif\t\t\t\t\t\t\t/* ENABLE_GSS */\n\t\t\t}\n\n\t\t\t/*\n\t\t\t * Handle authentication exchange: wait for postmaster messages\n\t\t\t * and respond as necessary.\n\t\t\t */\n\t\tcase CONNECTION_AWAITING_RESPONSE:\n\t\t\t{\n\t\t\t\tchar\t\tberesp;\n\t\t\t\tint\t\t\tmsgLength;\n\t\t\t\tint\t\t\tavail;\n\t\t\t\tAuthRequest areq;\n\t\t\t\tint\t\t\tres;\n\n\t\t\t\t/*\n\t\t\t\t * Scan the message from current point (note that if we find\n\t\t\t\t * the message is incomplete, we will return without advancing\n\t\t\t\t * inStart, and resume here next time).\n\t\t\t\t */\n\t\t\t\tconn->inCursor = conn->inStart;\n\n\t\t\t\t/* Read type byte */\n\t\t\t\tif (pqGetc(&beresp, conn))\n\t\t\t\t{\n\t\t\t\t\t/* We'll come back when there is more data */\n\t\t\t\t\treturn PGRES_POLLING_READING;\n\t\t\t\t}\n\n\t\t\t\t/*\n\t\t\t\t * Validate message type: we expect only an authentication\n\t\t\t\t * request or an error here.  Anything else probably means\n\t\t\t\t * it's not Postgres on the other end at all.\n\t\t\t\t */\n\t\t\t\tif (!(beresp == 'R' || beresp == 'E'))\n\t\t\t\t{\n\t\t\t\t\tappendPQExpBuffer(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t  libpq_gettext(\"expected authentication request from server, but received %c\\n\"),\n\t\t\t\t\t\t\t\t\t  beresp);\n\t\t\t\t\tgoto error_return;\n\t\t\t\t}\n\n\t\t\t\t/* Read message length word */\n\t\t\t\tif (pqGetInt(&msgLength, 4, conn))\n\t\t\t\t{\n\t\t\t\t\t/* We'll come back when there is more data */\n\t\t\t\t\treturn PGRES_POLLING_READING;\n\t\t\t\t}\n\n\t\t\t\t/*\n\t\t\t\t * Try to validate message length before using it.\n\t\t\t\t * Authentication requests can't be very large, although GSS\n\t\t\t\t * auth requests may not be that small.  Errors can be a\n\t\t\t\t * little larger, but not huge.  If we see a large apparent\n\t\t\t\t * length in an error, it means we're really talking to a\n\t\t\t\t * pre-3.0-protocol server; cope.  (Before version 14, the\n\t\t\t\t * server also used the old protocol for errors that happened\n\t\t\t\t * before processing the startup packet.)\n\t\t\t\t */\n\t\t\t\tif (beresp == 'R' && (msgLength < 8 || msgLength > 2000))\n\t\t\t\t{\n\t\t\t\t\tappendPQExpBuffer(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t  libpq_gettext(\"expected authentication request from server, but received %c\\n\"),\n\t\t\t\t\t\t\t\t\t  beresp);\n\t\t\t\t\tgoto error_return;\n\t\t\t\t}\n\n\t\t\t\tif (beresp == 'E' && (msgLength < 8 || msgLength > 30000))\n\t\t\t\t{\n\t\t\t\t\t/* Handle error from a pre-3.0 server */\n\t\t\t\t\tconn->inCursor = conn->inStart + 1; /* reread data */\n\t\t\t\t\tif (pqGets_append(&conn->errorMessage, conn))\n\t\t\t\t\t{\n\t\t\t\t\t\t/* We'll come back when there is more data */\n\t\t\t\t\t\treturn PGRES_POLLING_READING;\n\t\t\t\t\t}\n\t\t\t\t\t/* OK, we read the message; mark data consumed */\n\t\t\t\t\tconn->inStart = conn->inCursor;\n\n\t\t\t\t\t/*\n\t\t\t\t\t * Before 7.2, the postmaster didn't always end its\n\t\t\t\t\t * messages with a newline, so add one if needed to\n\t\t\t\t\t * conform to libpq conventions.\n\t\t\t\t\t */\n\t\t\t\t\tif (conn->errorMessage.len == 0 ||\n\t\t\t\t\t\tconn->errorMessage.data[conn->errorMessage.len - 1] != '\\n')\n\t\t\t\t\t{\n\t\t\t\t\t\tappendPQExpBufferChar(&conn->errorMessage, '\\n');\n\t\t\t\t\t}\n\n\t\t\t\t\tgoto error_return;\n\t\t\t\t}\n\n\t\t\t\t/*\n\t\t\t\t * Can't process if message body isn't all here yet.\n\t\t\t\t */\n\t\t\t\tmsgLength -= 4;\n\t\t\t\tavail = conn->inEnd - conn->inCursor;\n\t\t\t\tif (avail < msgLength)\n\t\t\t\t{\n\t\t\t\t\t/*\n\t\t\t\t\t * Before returning, try to enlarge the input buffer if\n\t\t\t\t\t * needed to hold the whole message; see notes in\n\t\t\t\t\t * pqParseInput3.\n\t\t\t\t\t */\n\t\t\t\t\tif (pqCheckInBufferSpace(conn->inCursor + (size_t) msgLength,\n\t\t\t\t\t\t\t\t\t\t\t conn))\n\t\t\t\t\t\tgoto error_return;\n\t\t\t\t\t/* We'll come back when there is more data */\n\t\t\t\t\treturn PGRES_POLLING_READING;\n\t\t\t\t}\n\n\t\t\t\t/* Handle errors. */\n\t\t\t\tif (beresp == 'E')\n\t\t\t\t{\n\t\t\t\t\tif (pqGetErrorNotice3(conn, true))\n\t\t\t\t\t{\n\t\t\t\t\t\t/* We'll come back when there is more data */\n\t\t\t\t\t\treturn PGRES_POLLING_READING;\n\t\t\t\t\t}\n\t\t\t\t\t/* OK, we read the message; mark data consumed */\n\t\t\t\t\tconn->inStart = conn->inCursor;\n\n\t\t\t\t\t/*\n\t\t\t\t\t * If error is \"cannot connect now\", try the next host if\n\t\t\t\t\t * any (but we don't want to consider additional addresses\n\t\t\t\t\t * for this host, nor is there much point in changing SSL\n\t\t\t\t\t * or GSS mode).  This is helpful when dealing with\n\t\t\t\t\t * standby servers that might not be in hot-standby state.\n\t\t\t\t\t */\n\t\t\t\t\tif (strcmp(conn->last_sqlstate,\n\t\t\t\t\t\t\t   ERRCODE_CANNOT_CONNECT_NOW) == 0)\n\t\t\t\t\t{\n\t\t\t\t\t\tconn->try_next_host = true;\n\t\t\t\t\t\tgoto keep_going;\n\t\t\t\t\t}\n\n\t\t\t\t\t/* Check to see if we should mention pgpassfile */\n\t\t\t\t\tpgpassfileWarning(conn);\n\n#ifdef ENABLE_GSS\n\n\t\t\t\t\t/*\n\t\t\t\t\t * If gssencmode is \"prefer\" and we're using GSSAPI, retry\n\t\t\t\t\t * without it.\n\t\t\t\t\t */\n\t\t\t\t\tif (conn->gssenc && conn->gssencmode[0] == 'p')\n\t\t\t\t\t{\n\t\t\t\t\t\t/* only retry once */\n\t\t\t\t\t\tconn->try_gss = false;\n\t\t\t\t\t\tneed_new_connection = true;\n\t\t\t\t\t\tgoto keep_going;\n\t\t\t\t\t}\n#endif\n\n#ifdef USE_SSL\n\n\t\t\t\t\t/*\n\t\t\t\t\t * if sslmode is \"allow\" and we haven't tried an SSL\n\t\t\t\t\t * connection already, then retry with an SSL connection\n\t\t\t\t\t */\n\t\t\t\t\tif (conn->sslmode[0] == 'a' /* \"allow\" */\n\t\t\t\t\t\t&& !conn->ssl_in_use\n\t\t\t\t\t\t&& conn->allow_ssl_try\n\t\t\t\t\t\t&& conn->wait_ssl_try)\n\t\t\t\t\t{\n\t\t\t\t\t\t/* only retry once */\n\t\t\t\t\t\tconn->wait_ssl_try = false;\n\t\t\t\t\t\tneed_new_connection = true;\n\t\t\t\t\t\tgoto keep_going;\n\t\t\t\t\t}\n\n\t\t\t\t\t/*\n\t\t\t\t\t * if sslmode is \"prefer\" and we're in an SSL connection,\n\t\t\t\t\t * then do a non-SSL retry\n\t\t\t\t\t */\n\t\t\t\t\tif (conn->sslmode[0] == 'p' /* \"prefer\" */\n\t\t\t\t\t\t&& conn->ssl_in_use\n\t\t\t\t\t\t&& conn->allow_ssl_try\t/* redundant? */\n\t\t\t\t\t\t&& !conn->wait_ssl_try) /* redundant? */\n\t\t\t\t\t{\n\t\t\t\t\t\t/* only retry once */\n\t\t\t\t\t\tconn->allow_ssl_try = false;\n\t\t\t\t\t\tneed_new_connection = true;\n\t\t\t\t\t\tgoto keep_going;\n\t\t\t\t\t}\n#endif\n\n\t\t\t\t\tgoto error_return;\n\t\t\t\t}\n\n\t\t\t\t/* It is an authentication request. */\n\t\t\t\tconn->auth_req_received = true;\n\n\t\t\t\t/* Get the type of request. */\n\t\t\t\tif (pqGetInt((int *) &areq, 4, conn))\n\t\t\t\t{\n\t\t\t\t\t/* We'll come back when there are more data */\n\t\t\t\t\treturn PGRES_POLLING_READING;\n\t\t\t\t}\n\t\t\t\tmsgLength -= 4;\n\n\t\t\t\t/*\n\t\t\t\t * Process the rest of the authentication request message, and\n\t\t\t\t * respond to it if necessary.\n\t\t\t\t *\n\t\t\t\t * Note that conn->pghost must be non-NULL if we are going to\n\t\t\t\t * avoid the Kerberos code doing a hostname look-up.\n\t\t\t\t */\n\t\t\t\tres = pg_fe_sendauth(areq, msgLength, conn);\n\n\t\t\t\t/* OK, we have processed the message; mark data consumed */\n\t\t\t\tconn->inStart = conn->inCursor;\n\n\t\t\t\tif (res != STATUS_OK)\n\t\t\t\t\tgoto error_return;\n\n\t\t\t\t/*\n\t\t\t\t * Just make sure that any data sent by pg_fe_sendauth is\n\t\t\t\t * flushed out.  Although this theoretically could block, it\n\t\t\t\t * really shouldn't since we don't send large auth responses.\n\t\t\t\t */\n\t\t\t\tif (pqFlush(conn))\n\t\t\t\t\tgoto error_return;\n\n\t\t\t\tif (areq == AUTH_REQ_OK)\n\t\t\t\t{\n\t\t\t\t\t/* We are done with authentication exchange */\n\t\t\t\t\tconn->status = CONNECTION_AUTH_OK;\n\n\t\t\t\t\t/*\n\t\t\t\t\t * Set asyncStatus so that PQgetResult will think that\n\t\t\t\t\t * what comes back next is the result of a query.  See\n\t\t\t\t\t * below.\n\t\t\t\t\t */\n\t\t\t\t\tconn->asyncStatus = PGASYNC_BUSY;\n\t\t\t\t}\n\n\t\t\t\t/* Look to see if we have more data yet. */\n\t\t\t\tgoto keep_going;\n\t\t\t}\n\n\t\tcase CONNECTION_AUTH_OK:\n\t\t\t{\n\t\t\t\t/*\n\t\t\t\t * Now we expect to hear from the backend. A ReadyForQuery\n\t\t\t\t * message indicates that startup is successful, but we might\n\t\t\t\t * also get an Error message indicating failure. (Notice\n\t\t\t\t * messages indicating nonfatal warnings are also allowed by\n\t\t\t\t * the protocol, as are ParameterStatus and BackendKeyData\n\t\t\t\t * messages.) Easiest way to handle this is to let\n\t\t\t\t * PQgetResult() read the messages. We just have to fake it\n\t\t\t\t * out about the state of the connection, by setting\n\t\t\t\t * asyncStatus = PGASYNC_BUSY (done above).\n\t\t\t\t */\n\n\t\t\t\tif (PQisBusy(conn))\n\t\t\t\t\treturn PGRES_POLLING_READING;\n\n\t\t\t\tres = PQgetResult(conn);\n\n\t\t\t\t/*\n\t\t\t\t * NULL return indicating we have gone to IDLE state is\n\t\t\t\t * expected\n\t\t\t\t */\n\t\t\t\tif (res)\n\t\t\t\t{\n\t\t\t\t\tif (res->resultStatus != PGRES_FATAL_ERROR)\n\t\t\t\t\t\tappendPQExpBufferStr(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t\t\t libpq_gettext(\"unexpected message from server during startup\\n\"));\n\t\t\t\t\telse if (conn->send_appname &&\n\t\t\t\t\t\t\t (conn->appname || conn->fbappname))\n\t\t\t\t\t{\n\t\t\t\t\t\t/*\n\t\t\t\t\t\t * If we tried to send application_name, check to see\n\t\t\t\t\t\t * if the error is about that --- pre-9.0 servers will\n\t\t\t\t\t\t * reject it at this stage of the process.  If so,\n\t\t\t\t\t\t * close the connection and retry without sending\n\t\t\t\t\t\t * application_name.  We could possibly get a false\n\t\t\t\t\t\t * SQLSTATE match here and retry uselessly, but there\n\t\t\t\t\t\t * seems no great harm in that; we'll just get the\n\t\t\t\t\t\t * same error again if it's unrelated.\n\t\t\t\t\t\t */\n\t\t\t\t\t\tconst char *sqlstate;\n\n\t\t\t\t\t\tsqlstate = PQresultErrorField(res, PG_DIAG_SQLSTATE);\n\t\t\t\t\t\tif (sqlstate &&\n\t\t\t\t\t\t\tstrcmp(sqlstate, ERRCODE_APPNAME_UNKNOWN) == 0)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tPQclear(res);\n\t\t\t\t\t\t\tconn->send_appname = false;\n\t\t\t\t\t\t\tneed_new_connection = true;\n\t\t\t\t\t\t\tgoto keep_going;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\t/*\n\t\t\t\t\t * if the resultStatus is FATAL, then conn->errorMessage\n\t\t\t\t\t * already has a copy of the error; needn't copy it back.\n\t\t\t\t\t * But add a newline if it's not there already, since\n\t\t\t\t\t * postmaster error messages may not have one.\n\t\t\t\t\t */\n\t\t\t\t\tif (conn->errorMessage.len <= 0 ||\n\t\t\t\t\t\tconn->errorMessage.data[conn->errorMessage.len - 1] != '\\n')\n\t\t\t\t\t\tappendPQExpBufferChar(&conn->errorMessage, '\\n');\n\t\t\t\t\tPQclear(res);\n\t\t\t\t\tgoto error_return;\n\t\t\t\t}\n\n\t\t\t\t/* Almost there now ... */\n\t\t\t\tconn->status = CONNECTION_CHECK_TARGET;\n\t\t\t\tgoto keep_going;\n\t\t\t}\n\n\t\tcase CONNECTION_CHECK_TARGET:\n\t\t\t{\n\t\t\t\t/*\n\t\t\t\t * If a read-write, read-only, primary, or standby connection\n\t\t\t\t * is required, see if we have one.\n\t\t\t\t */\n\t\t\t\tif (conn->target_server_type == SERVER_TYPE_READ_WRITE ||\n\t\t\t\t\tconn->target_server_type == SERVER_TYPE_READ_ONLY)\n\t\t\t\t{\n\t\t\t\t\tbool\t\tread_only_server;\n\n\t\t\t\t\t/*\n\t\t\t\t\t * If the server didn't report\n\t\t\t\t\t * \"default_transaction_read_only\" or \"in_hot_standby\" at\n\t\t\t\t\t * startup, we must determine its state by sending the\n\t\t\t\t\t * query \"SHOW transaction_read_only\".  This GUC exists in\n\t\t\t\t\t * all server versions that support 3.0 protocol.\n\t\t\t\t\t */\n\t\t\t\t\tif (conn->default_transaction_read_only == PG_BOOL_UNKNOWN ||\n\t\t\t\t\t\tconn->in_hot_standby == PG_BOOL_UNKNOWN)\n\t\t\t\t\t{\n\t\t\t\t\t\t/*\n\t\t\t\t\t\t * We use PQsendQueryContinue so that\n\t\t\t\t\t\t * conn->errorMessage does not get cleared.  We need\n\t\t\t\t\t\t * to preserve any error messages related to previous\n\t\t\t\t\t\t * hosts we have tried and failed to connect to.\n\t\t\t\t\t\t */\n\t\t\t\t\t\tconn->status = CONNECTION_OK;\n\t\t\t\t\t\tif (!PQsendQueryContinue(conn,\n\t\t\t\t\t\t\t\t\t\t\t\t \"SHOW transaction_read_only\"))\n\t\t\t\t\t\t\tgoto error_return;\n\t\t\t\t\t\t/* We'll return to this state when we have the answer */\n\t\t\t\t\t\tconn->status = CONNECTION_CHECK_WRITABLE;\n\t\t\t\t\t\treturn PGRES_POLLING_READING;\n\t\t\t\t\t}\n\n\t\t\t\t\t/* OK, we can make the test */\n\t\t\t\t\tread_only_server =\n\t\t\t\t\t\t(conn->default_transaction_read_only == PG_BOOL_YES ||\n\t\t\t\t\t\t conn->in_hot_standby == PG_BOOL_YES);\n\n\t\t\t\t\tif ((conn->target_server_type == SERVER_TYPE_READ_WRITE) ?\n\t\t\t\t\t\tread_only_server : !read_only_server)\n\t\t\t\t\t{\n\t\t\t\t\t\t/* Wrong server state, reject and try the next host */\n\t\t\t\t\t\tif (conn->target_server_type == SERVER_TYPE_READ_WRITE)\n\t\t\t\t\t\t\tappendPQExpBufferStr(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t\t\t\t libpq_gettext(\"session is read-only\\n\"));\n\t\t\t\t\t\telse\n\t\t\t\t\t\t\tappendPQExpBufferStr(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t\t\t\t libpq_gettext(\"session is not read-only\\n\"));\n\n\t\t\t\t\t\t/* Close connection politely. */\n\t\t\t\t\t\tconn->status = CONNECTION_OK;\n\t\t\t\t\t\tsendTerminateConn(conn);\n\n\t\t\t\t\t\t/*\n\t\t\t\t\t\t * Try next host if any, but we don't want to consider\n\t\t\t\t\t\t * additional addresses for this host.\n\t\t\t\t\t\t */\n\t\t\t\t\t\tconn->try_next_host = true;\n\t\t\t\t\t\tgoto keep_going;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telse if (conn->target_server_type == SERVER_TYPE_PRIMARY ||\n\t\t\t\t\t\t conn->target_server_type == SERVER_TYPE_STANDBY ||\n\t\t\t\t\t\t conn->target_server_type == SERVER_TYPE_PREFER_STANDBY)\n\t\t\t\t{\n\t\t\t\t\t/*\n\t\t\t\t\t * If the server didn't report \"in_hot_standby\" at\n\t\t\t\t\t * startup, we must determine its state by sending the\n\t\t\t\t\t * query \"SELECT pg_catalog.pg_is_in_recovery()\".  Servers\n\t\t\t\t\t * before 9.0 don't have that function, but by the same\n\t\t\t\t\t * token they don't have any standby mode, so we may just\n\t\t\t\t\t * assume the result.\n\t\t\t\t\t */\n\t\t\t\t\tif (conn->sversion < 90000)\n\t\t\t\t\t\tconn->in_hot_standby = PG_BOOL_NO;\n\n\t\t\t\t\tif (conn->in_hot_standby == PG_BOOL_UNKNOWN)\n\t\t\t\t\t{\n\t\t\t\t\t\t/*\n\t\t\t\t\t\t * We use PQsendQueryContinue so that\n\t\t\t\t\t\t * conn->errorMessage does not get cleared.  We need\n\t\t\t\t\t\t * to preserve any error messages related to previous\n\t\t\t\t\t\t * hosts we have tried and failed to connect to.\n\t\t\t\t\t\t */\n\t\t\t\t\t\tconn->status = CONNECTION_OK;\n\t\t\t\t\t\tif (!PQsendQueryContinue(conn,\n\t\t\t\t\t\t\t\t\t\t\t\t \"SELECT pg_catalog.pg_is_in_recovery()\"))\n\t\t\t\t\t\t\tgoto error_return;\n\t\t\t\t\t\t/* We'll return to this state when we have the answer */\n\t\t\t\t\t\tconn->status = CONNECTION_CHECK_STANDBY;\n\t\t\t\t\t\treturn PGRES_POLLING_READING;\n\t\t\t\t\t}\n\n\t\t\t\t\t/* OK, we can make the test */\n\t\t\t\t\tif ((conn->target_server_type == SERVER_TYPE_PRIMARY) ?\n\t\t\t\t\t\t(conn->in_hot_standby == PG_BOOL_YES) :\n\t\t\t\t\t\t(conn->in_hot_standby == PG_BOOL_NO))\n\t\t\t\t\t{\n\t\t\t\t\t\t/* Wrong server state, reject and try the next host */\n\t\t\t\t\t\tif (conn->target_server_type == SERVER_TYPE_PRIMARY)\n\t\t\t\t\t\t\tappendPQExpBufferStr(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t\t\t\t libpq_gettext(\"server is in hot standby mode\\n\"));\n\t\t\t\t\t\telse\n\t\t\t\t\t\t\tappendPQExpBufferStr(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t\t\t\t libpq_gettext(\"server is not in hot standby mode\\n\"));\n\n\t\t\t\t\t\t/* Close connection politely. */\n\t\t\t\t\t\tconn->status = CONNECTION_OK;\n\t\t\t\t\t\tsendTerminateConn(conn);\n\n\t\t\t\t\t\t/*\n\t\t\t\t\t\t * Try next host if any, but we don't want to consider\n\t\t\t\t\t\t * additional addresses for this host.\n\t\t\t\t\t\t */\n\t\t\t\t\t\tconn->try_next_host = true;\n\t\t\t\t\t\tgoto keep_going;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t/* We can release the address list now. */\n\t\t\t\trelease_conn_addrinfo(conn);\n\n\t\t\t\t/*\n\t\t\t\t * Contents of conn->errorMessage are no longer interesting\n\t\t\t\t * (and it seems some clients expect it to be empty after a\n\t\t\t\t * successful connection).\n\t\t\t\t */\n\t\t\t\tresetPQExpBuffer(&conn->errorMessage);\n\n\t\t\t\t/* We are open for business! */\n\t\t\t\tconn->status = CONNECTION_OK;\n\t\t\t\treturn PGRES_POLLING_OK;\n\t\t\t}\n\n\t\tcase CONNECTION_CONSUME:\n\t\t\t{\n\t\t\t\t/*\n\t\t\t\t * This state just makes sure the connection is idle after\n\t\t\t\t * we've obtained the result of a SHOW or SELECT query.  Once\n\t\t\t\t * we're clear, return to CONNECTION_CHECK_TARGET state to\n\t\t\t\t * decide what to do next.  We must transiently set status =\n\t\t\t\t * CONNECTION_OK in order to use the result-consuming\n\t\t\t\t * subroutines.\n\t\t\t\t */\n\t\t\t\tconn->status = CONNECTION_OK;\n\t\t\t\tif (!PQconsumeInput(conn))\n\t\t\t\t\tgoto error_return;\n\n\t\t\t\tif (PQisBusy(conn))\n\t\t\t\t{\n\t\t\t\t\tconn->status = CONNECTION_CONSUME;\n\t\t\t\t\treturn PGRES_POLLING_READING;\n\t\t\t\t}\n\n\t\t\t\t/* Call PQgetResult() again until we get a NULL result */\n\t\t\t\tres = PQgetResult(conn);\n\t\t\t\tif (res != NULL)\n\t\t\t\t{\n\t\t\t\t\tPQclear(res);\n\t\t\t\t\tconn->status = CONNECTION_CONSUME;\n\t\t\t\t\treturn PGRES_POLLING_READING;\n\t\t\t\t}\n\n\t\t\t\tconn->status = CONNECTION_CHECK_TARGET;\n\t\t\t\tgoto keep_going;\n\t\t\t}\n\n\t\tcase CONNECTION_CHECK_WRITABLE:\n\t\t\t{\n\t\t\t\t/*\n\t\t\t\t * Waiting for result of \"SHOW transaction_read_only\".  We\n\t\t\t\t * must transiently set status = CONNECTION_OK in order to use\n\t\t\t\t * the result-consuming subroutines.\n\t\t\t\t */\n\t\t\t\tconn->status = CONNECTION_OK;\n\t\t\t\tif (!PQconsumeInput(conn))\n\t\t\t\t\tgoto error_return;\n\n\t\t\t\tif (PQisBusy(conn))\n\t\t\t\t{\n\t\t\t\t\tconn->status = CONNECTION_CHECK_WRITABLE;\n\t\t\t\t\treturn PGRES_POLLING_READING;\n\t\t\t\t}\n\n\t\t\t\tres = PQgetResult(conn);\n\t\t\t\tif (res && PQresultStatus(res) == PGRES_TUPLES_OK &&\n\t\t\t\t\tPQntuples(res) == 1)\n\t\t\t\t{\n\t\t\t\t\tchar\t   *val = PQgetvalue(res, 0, 0);\n\n\t\t\t\t\t/*\n\t\t\t\t\t * \"transaction_read_only = on\" proves that at least one\n\t\t\t\t\t * of default_transaction_read_only and in_hot_standby is\n\t\t\t\t\t * on, but we don't actually know which.  We don't care\n\t\t\t\t\t * though for the purpose of identifying a read-only\n\t\t\t\t\t * session, so satisfy the CONNECTION_CHECK_TARGET code by\n\t\t\t\t\t * claiming they are both on.  On the other hand, if it's\n\t\t\t\t\t * a read-write session, they are certainly both off.\n\t\t\t\t\t */\n\t\t\t\t\tif (strncmp(val, \"on\", 2) == 0)\n\t\t\t\t\t{\n\t\t\t\t\t\tconn->default_transaction_read_only = PG_BOOL_YES;\n\t\t\t\t\t\tconn->in_hot_standby = PG_BOOL_YES;\n\t\t\t\t\t}\n\t\t\t\t\telse\n\t\t\t\t\t{\n\t\t\t\t\t\tconn->default_transaction_read_only = PG_BOOL_NO;\n\t\t\t\t\t\tconn->in_hot_standby = PG_BOOL_NO;\n\t\t\t\t\t}\n\t\t\t\t\tPQclear(res);\n\n\t\t\t\t\t/* Finish reading messages before continuing */\n\t\t\t\t\tconn->status = CONNECTION_CONSUME;\n\t\t\t\t\tgoto keep_going;\n\t\t\t\t}\n\n\t\t\t\t/* Something went wrong with \"SHOW transaction_read_only\". */\n\t\t\t\tif (res)\n\t\t\t\t\tPQclear(res);\n\n\t\t\t\t/* Append error report to conn->errorMessage. */\n\t\t\t\tappendPQExpBuffer(&conn->errorMessage,\n\t\t\t\t\t\t\t\t  libpq_gettext(\"\\\"%s\\\" failed\\n\"),\n\t\t\t\t\t\t\t\t  \"SHOW transaction_read_only\");\n\n\t\t\t\t/* Close connection politely. */\n\t\t\t\tconn->status = CONNECTION_OK;\n\t\t\t\tsendTerminateConn(conn);\n\n\t\t\t\t/* Try next host. */\n\t\t\t\tconn->try_next_host = true;\n\t\t\t\tgoto keep_going;\n\t\t\t}\n\n\t\tcase CONNECTION_CHECK_STANDBY:\n\t\t\t{\n\t\t\t\t/*\n\t\t\t\t * Waiting for result of \"SELECT pg_is_in_recovery()\".  We\n\t\t\t\t * must transiently set status = CONNECTION_OK in order to use\n\t\t\t\t * the result-consuming subroutines.\n\t\t\t\t */\n\t\t\t\tconn->status = CONNECTION_OK;\n\t\t\t\tif (!PQconsumeInput(conn))\n\t\t\t\t\tgoto error_return;\n\n\t\t\t\tif (PQisBusy(conn))\n\t\t\t\t{\n\t\t\t\t\tconn->status = CONNECTION_CHECK_STANDBY;\n\t\t\t\t\treturn PGRES_POLLING_READING;\n\t\t\t\t}\n\n\t\t\t\tres = PQgetResult(conn);\n\t\t\t\tif (res && PQresultStatus(res) == PGRES_TUPLES_OK &&\n\t\t\t\t\tPQntuples(res) == 1)\n\t\t\t\t{\n\t\t\t\t\tchar\t   *val = PQgetvalue(res, 0, 0);\n\n\t\t\t\t\tif (strncmp(val, \"t\", 1) == 0)\n\t\t\t\t\t\tconn->in_hot_standby = PG_BOOL_YES;\n\t\t\t\t\telse\n\t\t\t\t\t\tconn->in_hot_standby = PG_BOOL_NO;\n\t\t\t\t\tPQclear(res);\n\n\t\t\t\t\t/* Finish reading messages before continuing */\n\t\t\t\t\tconn->status = CONNECTION_CONSUME;\n\t\t\t\t\tgoto keep_going;\n\t\t\t\t}\n\n\t\t\t\t/* Something went wrong with \"SELECT pg_is_in_recovery()\". */\n\t\t\t\tif (res)\n\t\t\t\t\tPQclear(res);\n\n\t\t\t\t/* Append error report to conn->errorMessage. */\n\t\t\t\tappendPQExpBuffer(&conn->errorMessage,\n\t\t\t\t\t\t\t\t  libpq_gettext(\"\\\"%s\\\" failed\\n\"),\n\t\t\t\t\t\t\t\t  \"SELECT pg_is_in_recovery()\");\n\n\t\t\t\t/* Close connection politely. */\n\t\t\t\tconn->status = CONNECTION_OK;\n\t\t\t\tsendTerminateConn(conn);\n\n\t\t\t\t/* Try next host. */\n\t\t\t\tconn->try_next_host = true;\n\t\t\t\tgoto keep_going;\n\t\t\t}\n\n\t\tdefault:\n\t\t\tappendPQExpBuffer(&conn->errorMessage,\n\t\t\t\t\t\t\t  libpq_gettext(\"invalid connection state %d, \"\n\t\t\t\t\t\t\t\t\t\t\t\"probably indicative of memory corruption\\n\"),\n\t\t\t\t\t\t\t  conn->status);\n\t\t\tgoto error_return;\n\t}\n\n\t/* Unreachable */\n\nerror_return:\n\n\t/*\n\t * We used to close the socket at this point, but that makes it awkward\n\t * for those above us if they wish to remove this socket from their own\n\t * records (an fd_set for example).  We'll just have this socket closed\n\t * when PQfinish is called (which is compulsory even after an error, since\n\t * the connection structure must be freed).\n\t */\n\tconn->status = CONNECTION_BAD;\n\treturn PGRES_POLLING_FAILED;\n}",
        "func_hash": 145605680477709719969453491383463044279,
        "file_name": "fe-connect.c",
        "file_hash": 157537093140020562394962573075779914657,
        "cwe": [
            "CWE-522"
        ],
        "cve": "CVE-2021-23222",
        "cve_desc": "A man-in-the-middle attacker can inject false responses to the client's first few queries, despite the use of SSL certificate verification and encryption.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-23222",
        "func_name": "PQconnectPoll",
        "diff": [
            "diff --git a/doc/src/sgml/protocol.sgml b/doc/src/sgml/protocol.sgml\nindex 132436c6e6842..43b74e9423e0c 100644\n--- a/doc/src/sgml/protocol.sgml\n+++ b/doc/src/sgml/protocol.sgml\n@@ -1477,6 +1477,20 @@ SELCT 1/0;<!-- this typo is intentional -->\n     and proceed without requesting <acronym>SSL</acronym>.\n    </para>\n \n+   <para>\n+    When <acronym>SSL</acronym> encryption can be performed, the server\n+    is expected to send only the single <literal>S</literal> byte and then\n+    wait for the frontend to initiate an <acronym>SSL</acronym> handshake.\n+    If additional bytes are available to read at this point, it likely\n+    means that a man-in-the-middle is attempting to perform a\n+    buffer-stuffing attack\n+    (<ulink url=\"https://www.postgresql.org/support/security/CVE-2021-23222/\">CVE-2021-23222</ulink>).\n+    Frontends should be coded either to read exactly one byte from the\n+    socket before turning the socket over to their SSL library, or to\n+    treat it as a protocol violation if they find they have read additional\n+    bytes.\n+   </para>\n+\n    <para>\n     An initial SSLRequest can also be used in a connection that is being\n     opened to send a CancelRequest message.\n@@ -1539,6 +1553,20 @@ SELCT 1/0;<!-- this typo is intentional -->\n     encryption.\n    </para>\n \n+   <para>\n+    When <acronym>GSSAPI</acronym> encryption can be performed, the server\n+    is expected to send only the single <literal>G</literal> byte and then\n+    wait for the frontend to initiate a <acronym>GSSAPI</acronym> handshake.\n+    If additional bytes are available to read at this point, it likely\n+    means that a man-in-the-middle is attempting to perform a\n+    buffer-stuffing attack\n+    (<ulink url=\"https://www.postgresql.org/support/security/CVE-2021-23222/\">CVE-2021-23222</ulink>).\n+    Frontends should be coded either to read exactly one byte from the\n+    socket before turning the socket over to their GSSAPI library, or to\n+    treat it as a protocol violation if they find they have read additional\n+    bytes.\n+   </para>\n+\n    <para>\n     An initial GSSENCRequest can also be used in a connection that is being\n     opened to send a CancelRequest message.\ndiff --git a/src/interfaces/libpq/fe-connect.c b/src/interfaces/libpq/fe-connect.c\nindex b288d346f9268..f0fdd294a401d 100644\n--- a/src/interfaces/libpq/fe-connect.c\n+++ b/src/interfaces/libpq/fe-connect.c\n@@ -3097,6 +3097,19 @@ PQconnectPoll(PGconn *conn)\n \t\t\t\tpollres = pqsecure_open_client(conn);\n \t\t\t\tif (pollres == PGRES_POLLING_OK)\n \t\t\t\t{\n+\t\t\t\t\t/*\n+\t\t\t\t\t * At this point we should have no data already buffered.\n+\t\t\t\t\t * If we do, it was received before we performed the SSL\n+\t\t\t\t\t * handshake, so it wasn't encrypted and indeed may have\n+\t\t\t\t\t * been injected by a man-in-the-middle.\n+\t\t\t\t\t */\n+\t\t\t\t\tif (conn->inCursor != conn->inEnd)\n+\t\t\t\t\t{\n+\t\t\t\t\t\tappendPQExpBufferStr(&conn->errorMessage,\n+\t\t\t\t\t\t\t\t\t\t\t libpq_gettext(\"received unencrypted data after SSL response\\n\"));\n+\t\t\t\t\t\tgoto error_return;\n+\t\t\t\t\t}\n+\n \t\t\t\t\t/* SSL handshake done, ready to send startup packet */\n \t\t\t\t\tconn->status = CONNECTION_MADE;\n \t\t\t\t\treturn PGRES_POLLING_WRITING;\n@@ -3196,6 +3209,19 @@ PQconnectPoll(PGconn *conn)\n \t\t\t\tpollres = pqsecure_open_gss(conn);\n \t\t\t\tif (pollres == PGRES_POLLING_OK)\n \t\t\t\t{\n+\t\t\t\t\t/*\n+\t\t\t\t\t * At this point we should have no data already buffered.\n+\t\t\t\t\t * If we do, it was received before we performed the GSS\n+\t\t\t\t\t * handshake, so it wasn't encrypted and indeed may have\n+\t\t\t\t\t * been injected by a man-in-the-middle.\n+\t\t\t\t\t */\n+\t\t\t\t\tif (conn->inCursor != conn->inEnd)\n+\t\t\t\t\t{\n+\t\t\t\t\t\tappendPQExpBufferStr(&conn->errorMessage,\n+\t\t\t\t\t\t\t\t\t\t\t libpq_gettext(\"received unencrypted data after GSSAPI encryption response\\n\"));\n+\t\t\t\t\t\tgoto error_return;\n+\t\t\t\t\t}\n+\n \t\t\t\t\t/* All set for startup packet */\n \t\t\t\t\tconn->status = CONNECTION_MADE;\n \t\t\t\t\treturn PGRES_POLLING_WRITING;\n"
        ],
        "func_after": []
    },
    {
        "idx": 195389,
        "project": "tensorflow",
        "commit_id": "c2b31ff2d3151acb230edc3f5b1832d2c713a9e0",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/c2b31ff2d3151acb230edc3f5b1832d2c713a9e0",
        "commit_message": "Remove a `DCHECK`-fail, log an error instead.\n\n`DCHECK` in debug mode results in crashes. TensorFlow has had multiple vulnerabilities due to this.\n\nOutside of debug mode, `DCHECK` is a no-op.\n\nA better alternative is to report an error to the log buffer and continue. This should happen both in debug mode and in prod mode.\n\nPiperOrigin-RevId: 408375925\nChange-Id: Id5b3e19c73f3fbe0cc4bba26ca44ff9607bb6356",
        "target": 1,
        "irrelevant": 0,
        "func_before": "bool RepeatedAttrDefEqual(\n    const protobuf::RepeatedPtrField<OpDef::AttrDef>& a1,\n    const protobuf::RepeatedPtrField<OpDef::AttrDef>& a2) {\n  std::unordered_map<string, const OpDef::AttrDef*> a1_set;\n  for (const OpDef::AttrDef& def : a1) {\n    DCHECK(a1_set.find(def.name()) == a1_set.end())\n        << \"AttrDef names must be unique, but '\" << def.name()\n        << \"' appears more than once\";\n    a1_set[def.name()] = &def;\n  }\n  for (const OpDef::AttrDef& def : a2) {\n    auto iter = a1_set.find(def.name());\n    if (iter == a1_set.end()) return false;\n    if (!AttrDefEqual(*iter->second, def)) return false;\n    a1_set.erase(iter);\n  }\n  if (!a1_set.empty()) return false;\n  return true;\n}",
        "func_hash": 228350956694349821922378909162368693155,
        "file_name": "op_def_util.cc",
        "file_hash": 43202597261631718571985626227626810269,
        "cwe": [
            "CWE-617"
        ],
        "cve": "CVE-2022-23565",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. An attacker can trigger denial of service via assertion failure by altering a `SavedModel` on disk such that `AttrDef`s of some operation are duplicated. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23565",
        "func_name": "RepeatedAttrDefEqual",
        "diff": [
            "diff --git a/tensorflow/core/framework/op_def_util.cc b/tensorflow/core/framework/op_def_util.cc\nindex dcbe5f38ce88ea..6127913d9ba1f0 100644\n--- a/tensorflow/core/framework/op_def_util.cc\n+++ b/tensorflow/core/framework/op_def_util.cc\n@@ -821,9 +821,10 @@ bool RepeatedAttrDefEqual(\n     const protobuf::RepeatedPtrField<OpDef::AttrDef>& a2) {\n   std::unordered_map<string, const OpDef::AttrDef*> a1_set;\n   for (const OpDef::AttrDef& def : a1) {\n-    DCHECK(a1_set.find(def.name()) == a1_set.end())\n-        << \"AttrDef names must be unique, but '\" << def.name()\n-        << \"' appears more than once\";\n+    if (a1_set.find(def.name()) != a1_set.end()) {\n+      LOG(ERROR) << \"AttrDef names must be unique, but '\" << def.name()\n+                 << \"' appears more than once\";\n+    }\n     a1_set[def.name()] = &def;\n   }\n   for (const OpDef::AttrDef& def : a2) {\n"
        ],
        "func_after": []
    },
    {
        "idx": 195391,
        "project": "tensorflow",
        "commit_id": "f68fdab93fb7f4ddb4eb438c8fe052753c9413e8",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/f68fdab93fb7f4ddb4eb438c8fe052753c9413e8",
        "commit_message": "Add a check for pad width to be a positive value.\n\nPiperOrigin-RevId: 413275853\nChange-Id: I261a8db9dabf5ce48a806a9e58129080c9fac619",
        "target": 1,
        "irrelevant": 1,
        "func_before": "  void Compute(tensorflow::OpKernelContext* context) override {\n    for (int ngram_width : ngram_widths_) {\n      OP_REQUIRES(\n          context, ngram_width > 0,\n          errors::InvalidArgument(\"ngram_widths must contain positive values\"));\n    }\n\n    const tensorflow::Tensor* data;\n    OP_REQUIRES_OK(context, context->input(\"data\", &data));\n    const auto& input_data = data->flat<tstring>().data();\n\n    const tensorflow::Tensor* splits;\n    OP_REQUIRES_OK(context, context->input(\"data_splits\", &splits));\n    const auto& splits_vec = splits->flat<SPLITS_TYPE>();\n\n    // Validate that the splits are valid indices into data, only if there are\n    // splits specified.\n    const int input_data_size = data->flat<tstring>().size();\n    const int splits_vec_size = splits_vec.size();\n    if (splits_vec_size > 0) {\n      int prev_split = splits_vec(0);\n      OP_REQUIRES(context, prev_split == 0,\n                  errors::InvalidArgument(\"First split value must be 0, got \",\n                                          prev_split));\n      for (int i = 1; i < splits_vec_size; ++i) {\n        bool valid_splits = splits_vec(i) >= prev_split;\n        valid_splits = valid_splits && (splits_vec(i) <= input_data_size);\n        OP_REQUIRES(context, valid_splits,\n                    errors::InvalidArgument(\n                        \"Invalid split value \", splits_vec(i), \", must be in [\",\n                        prev_split, \", \", input_data_size, \"]\"));\n        prev_split = splits_vec(i);\n      }\n      OP_REQUIRES(context, prev_split == input_data_size,\n                  errors::InvalidArgument(\n                      \"Last split value must be data size. Expected \",\n                      input_data_size, \", got \", prev_split));\n    }\n\n    int num_batch_items = splits_vec.size() - 1;\n    tensorflow::Tensor* ngrams_splits;\n    OP_REQUIRES_OK(\n        context, context->allocate_output(1, splits->shape(), &ngrams_splits));\n    auto ngrams_splits_data = ngrams_splits->flat<SPLITS_TYPE>().data();\n\n    // If there is no data or size, return an empty RT.\n    if (data->flat<tstring>().size() == 0 || splits_vec.size() == 0) {\n      tensorflow::Tensor* empty;\n      OP_REQUIRES_OK(context,\n                     context->allocate_output(0, data->shape(), &empty));\n      for (int i = 0; i <= num_batch_items; ++i) {\n        ngrams_splits_data[i] = 0;\n      }\n      return;\n    }\n\n    ngrams_splits_data[0] = 0;\n    for (int i = 1; i <= num_batch_items; ++i) {\n      int length = splits_vec(i) - splits_vec(i - 1);\n      int num_ngrams = 0;\n      for (int ngram_width : ngram_widths_)\n        num_ngrams += get_num_ngrams(length, ngram_width);\n      if (preserve_short_ && length > 0 && num_ngrams == 0) {\n        num_ngrams = 1;\n      }\n      ngrams_splits_data[i] = ngrams_splits_data[i - 1] + num_ngrams;\n    }\n\n    tensorflow::Tensor* ngrams;\n    OP_REQUIRES_OK(\n        context,\n        context->allocate_output(\n            0, TensorShape({ngrams_splits_data[num_batch_items]}), &ngrams));\n    auto ngrams_data = ngrams->flat<tstring>().data();\n\n    for (int i = 0; i < num_batch_items; ++i) {\n      auto data_start = &input_data[splits_vec(i)];\n      int output_start_idx = ngrams_splits_data[i];\n      for (int ngram_width : ngram_widths_) {\n        auto output_start = &ngrams_data[output_start_idx];\n        int length = splits_vec(i + 1) - splits_vec(i);\n        int num_ngrams = get_num_ngrams(length, ngram_width);\n        CreateNgrams(data_start, output_start, num_ngrams, ngram_width);\n        output_start_idx += num_ngrams;\n      }\n      // If we're preserving short sequences, check to see if no sequence was\n      // generated by comparing the current output start idx to the original\n      // one (ngram_splits_data). If no ngrams were generated, then they will\n      // be equal (since we increment output_start_idx by num_ngrams every\n      // time we create a set of ngrams.)\n      if (preserve_short_ && output_start_idx == ngrams_splits_data[i]) {\n        int data_length = splits_vec(i + 1) - splits_vec(i);\n        // One legitimate reason to not have any ngrams when preserve_short_\n        // is true is if the sequence itself is empty. In that case, move on.\n        if (data_length == 0) {\n          continue;\n        }\n        // We don't have to worry about dynamic padding sizes here: if padding\n        // was dynamic, every sequence would have had sufficient padding to\n        // generate at least one ngram.\n        int ngram_width = data_length + 2 * pad_width_;\n        auto output_start = &ngrams_data[output_start_idx];\n        int num_ngrams = 1;\n        CreateNgrams(data_start, output_start, num_ngrams, ngram_width);\n      }\n    }\n  }",
        "func_hash": 93012019628610956612764593105283326156,
        "file_name": "string_ngrams_op.cc",
        "file_hash": 245905885483763938680185872776744444218,
        "cwe": [
            "CWE-190"
        ],
        "cve": "CVE-2022-21733",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The implementation of `StringNGrams` can be used to trigger a denial of service attack by causing an out of memory condition after an integer overflow. We are missing a validation on `pad_witdh` and that result in computing a negative value for `ngram_width` which is later used to allocate parts of the output. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-21733",
        "func_name": "Compute",
        "diff": [
            "diff --git a/tensorflow/core/kernels/string_ngrams_op.cc b/tensorflow/core/kernels/string_ngrams_op.cc\nindex 6acf846f95812f..07904fa04019ff 100644\n--- a/tensorflow/core/kernels/string_ngrams_op.cc\n+++ b/tensorflow/core/kernels/string_ngrams_op.cc\n@@ -152,6 +152,16 @@ class StringNGramsOp : public tensorflow::OpKernel {\n         // We don't have to worry about dynamic padding sizes here: if padding\n         // was dynamic, every sequence would have had sufficient padding to\n         // generate at least one ngram.\n+\n+        // If reached here, pad_width should be > 0, pad_width_ = -1,\n+        // which indicates max(ngram_widths) - 1 cannot be used here since\n+        // ngram_width is not known.\n+        OP_REQUIRES(\n+            context, pad_width_ >= 0,\n+            errors::InvalidArgument(\"Pad width should be >= 0 when \"\n+                                    \"preserve_short_sequences is True and \"\n+                                    \"ngram_widths are not provided, got \",\n+                                    pad_width_));\n         int ngram_width = data_length + 2 * pad_width_;\n         auto output_start = &ngrams_data[output_start_idx];\n         int num_ngrams = 1;\ndiff --git a/tensorflow/python/ops/raw_ops_test.py b/tensorflow/python/ops/raw_ops_test.py\nindex 953ab570f7d101..5097800d9ea13e 100644\n--- a/tensorflow/python/ops/raw_ops_test.py\n+++ b/tensorflow/python/ops/raw_ops_test.py\n@@ -28,7 +28,6 @@\n \n \n @test_util.run_all_in_graph_and_eager_modes\n-@test_util.disable_tfrt\n class RawOpsTest(test.TestCase, parameterized.TestCase):\n \n   def testSimple(self):\n@@ -63,8 +62,9 @@ def testDefaults(self):\n   @parameterized.parameters([[0, 8]], [[-1, 6]])\n   def testStringNGramsBadDataSplits(self, splits):\n     data = [\"aa\", \"bb\", \"cc\", \"dd\", \"ee\", \"ff\"]\n-    with self.assertRaisesRegex(errors.InvalidArgumentError,\n-                                \"Invalid split value\"):\n+    with self.assertRaisesRegex(\n+        errors.InvalidArgumentError,\n+        r\"Invalid split value|First split value must be 0\"):\n       self.evaluate(\n           gen_string_ops.string_n_grams(\n               data=data,\n@@ -76,6 +76,25 @@ def testStringNGramsBadDataSplits(self, splits):\n               pad_width=0,\n               preserve_short_sequences=False))\n \n+  def testStringSplit(self):\n+    data = [\"123456\"]\n+    data_splits = [0, 1]\n+    separator = \"a\" * 15\n+    ngram_widths = []\n+    pad_width = -5\n+    left_pad = right_pad = \"\"\n+    with self.assertRaisesRegex(errors.InvalidArgumentError,\n+                                \"Pad width should be >= 0\"):\n+      self.evaluate(gen_string_ops.string_n_grams(\n+          data=data,\n+          data_splits=data_splits,\n+          separator=separator,\n+          ngram_widths=ngram_widths,\n+          left_pad=left_pad,\n+          right_pad=right_pad,\n+          pad_width=pad_width,\n+          preserve_short_sequences=True))\n+\n   def testGetSessionHandle(self):\n     if context.executing_eagerly():\n       with self.assertRaisesRegex(\n"
        ],
        "func_after": []
    },
    {
        "idx": 195398,
        "project": "v4l2loopback",
        "commit_id": "e4cd225557486c420f6a34411f98c575effd43dd",
        "project_url": "https://github.com/umlaeute/v4l2loopback",
        "commit_url": "https://github.com/umlaeute/v4l2loopback/commit/e4cd225557486c420f6a34411f98c575effd43dd",
        "commit_message": "add explicit format specifier to printf() invocations\n\nCWE-134",
        "target": 1,
        "irrelevant": 1,
        "func_before": "static int vidioc_querycap(struct file *file, void *priv,\n\t\t\t   struct v4l2_capability *cap)\n{\n\tstruct v4l2_loopback_device *dev = v4l2loopback_getdevice(file);\n\tint labellen = (sizeof(cap->card) < sizeof(dev->card_label)) ?\n\t\t\t       sizeof(cap->card) :\n\t\t\t\t     sizeof(dev->card_label);\n\tint device_nr =\n\t\t((struct v4l2loopback_private *)video_get_drvdata(dev->vdev))\n\t\t\t->device_nr;\n\t__u32 capabilities = V4L2_CAP_STREAMING | V4L2_CAP_READWRITE;\n\n\tstrlcpy(cap->driver, \"v4l2 loopback\", sizeof(cap->driver));\n\tsnprintf(cap->card, labellen, dev->card_label);\n\tsnprintf(cap->bus_info, sizeof(cap->bus_info),\n\t\t \"platform:v4l2loopback-%03d\", device_nr);\n\n#if LINUX_VERSION_CODE < KERNEL_VERSION(3, 1, 0)\n\t/* since 3.1.0, the v4l2-core system is supposed to set the version */\n\tcap->version = V4L2LOOPBACK_VERSION_CODE;\n#endif\n\n#ifdef V4L2_CAP_VIDEO_M2M\n\tcapabilities |= V4L2_CAP_VIDEO_M2M;\n#endif /* V4L2_CAP_VIDEO_M2M */\n\n\tif (dev->announce_all_caps) {\n\t\tcapabilities |= V4L2_CAP_VIDEO_CAPTURE | V4L2_CAP_VIDEO_OUTPUT;\n\t} else {\n\t\tif (dev->ready_for_capture) {\n\t\t\tcapabilities |= V4L2_CAP_VIDEO_CAPTURE;\n\t\t}\n\t\tif (dev->ready_for_output) {\n\t\t\tcapabilities |= V4L2_CAP_VIDEO_OUTPUT;\n\t\t}\n\t}\n\n#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 7, 0)\n\tdev->vdev->device_caps =\n#endif /* >=linux-4.7.0 */\n\t\tcap->device_caps = cap->capabilities = capabilities;\n\n#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 3, 0)\n\tcap->capabilities |= V4L2_CAP_DEVICE_CAPS;\n#endif\n\n\tmemset(cap->reserved, 0, sizeof(cap->reserved));\n\treturn 0;\n}",
        "func_hash": 275249025528691740507199336736969659771,
        "file_name": "v4l2loopback.c",
        "file_hash": 113113223463037707180278012059265756483,
        "cwe": [
            "CWE-134"
        ],
        "cve": "CVE-2022-2652",
        "cve_desc": "Depending on the way the format strings in the card label are crafted it's possible to leak kernel stack memory. There is also the possibility for DoS due to the v4l2loopback kernel module crashing when providing the card label on request (reproduce e.g. with many %s modifiers in a row).",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-2652",
        "func_name": "vidioc_querycap",
        "diff": [
            "diff --git a/v4l2loopback.c b/v4l2loopback.c\nindex 8c88ae8d..50380547 100644\n--- a/v4l2loopback.c\n+++ b/v4l2loopback.c\n@@ -756,7 +756,7 @@ static int vidioc_querycap(struct file *file, void *priv,\n \t__u32 capabilities = V4L2_CAP_STREAMING | V4L2_CAP_READWRITE;\n \n \tstrlcpy(cap->driver, \"v4l2 loopback\", sizeof(cap->driver));\n-\tsnprintf(cap->card, labellen, dev->card_label);\n+\tsnprintf(cap->card, labellen, \"%s\", dev->card_label);\n \tsnprintf(cap->bus_info, sizeof(cap->bus_info),\n \t\t \"platform:v4l2loopback-%03d\", device_nr);\n \n@@ -2494,7 +2494,7 @@ static int v4l2_loopback_add(struct v4l2_loopback_config *conf, int *ret_nr)\n \t}\n \n \tMARK();\n-\tsnprintf(dev->vdev->name, sizeof(dev->vdev->name), dev->card_label);\n+\tsnprintf(dev->vdev->name, sizeof(dev->vdev->name), \"%s\", dev->card_label);\n \n \tvdev_priv->device_nr = nr;\n \n"
        ],
        "func_after": []
    },
    {
        "idx": 195399,
        "project": "tensorflow",
        "commit_id": "045deec1cbdebb27d817008ad5df94d96a08b1bf",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/045deec1cbdebb27d817008ad5df94d96a08b1bf",
        "commit_message": "Prevent null pointer dereference in `mutable_graph_view`\n\nPiperOrigin-RevId: 409684472\nChange-Id: I577eb9d9ac470fcec0501423171e739a4ec0cb5c",
        "target": 1,
        "irrelevant": 1,
        "func_before": "bool IsIdentityConsumingSwitch(const MutableGraphView& graph,\n                               const NodeDef& node) {\n  if ((IsIdentity(node) || IsIdentityNSingleInput(node)) &&\n      node.input_size() > 0) {\n    TensorId tensor_id = ParseTensorName(node.input(0));\n    if (IsTensorIdControlling(tensor_id)) {\n      return false;\n    }\n\n    NodeDef* input_node = graph.GetNode(tensor_id.node());\n    return IsSwitch(*input_node);\n  }\n  return false;\n}",
        "func_hash": 313619660222966312087557415210995637728,
        "file_name": "mutable_graph_view.cc",
        "file_hash": 11824580899895481141820753687530297202,
        "cwe": [
            "CWE-476"
        ],
        "cve": "CVE-2022-23589",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. Under certain scenarios, Grappler component of TensorFlow can trigger a null pointer dereference. There are 2 places where this can occur, for the same malicious alteration of a `SavedModel` file (fixing the first one would trigger the same dereference in the second place). First, during constant folding, the `GraphDef` might not have the required nodes for the binary operation. If a node is missing, the correposning `mul_*child` would be null, and the dereference in the subsequent line would be incorrect. We have a similar issue during `IsIdentityConsumingSwitch`. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23589",
        "func_name": "IsIdentityConsumingSwitch",
        "diff": [
            "diff --git a/tensorflow/core/grappler/mutable_graph_view.cc b/tensorflow/core/grappler/mutable_graph_view.cc\nindex e1eeb42e9c4f44..d70dc2e01c1484 100644\n--- a/tensorflow/core/grappler/mutable_graph_view.cc\n+++ b/tensorflow/core/grappler/mutable_graph_view.cc\n@@ -68,6 +68,9 @@ bool IsIdentityConsumingSwitch(const MutableGraphView& graph,\n     }\n \n     NodeDef* input_node = graph.GetNode(tensor_id.node());\n+    if (input_node == nullptr) {\n+      return false;\n+    }\n     return IsSwitch(*input_node);\n   }\n   return false;\n"
        ],
        "func_after": []
    },
    {
        "idx": 195402,
        "project": "tensorflow",
        "commit_id": "a1e1511dde36b3f8aa27a6ec630838e7ea40e091",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/a1e1511dde36b3f8aa27a6ec630838e7ea40e091",
        "commit_message": "[lite] Update TfLiteIntArrayCreate to return size_t\n\nPiperOrigin-RevId: 416439896\nChange-Id: I847f69b68d1ddaff4b1e925a09b8b69c1756653b",
        "target": 1,
        "irrelevant": 0,
        "func_before": "int TfLiteIntArrayGetSizeInBytes(int size) {\n  static TfLiteIntArray dummy;\n\n  int computed_size = sizeof(dummy) + sizeof(dummy.data[0]) * size;\n#if defined(_MSC_VER)\n  // Context for why this is needed is in http://b/189926408#comment21\n  computed_size -= sizeof(dummy.data[0]);\n#endif\n  return computed_size;\n}",
        "func_hash": 331591508579524081379498872268044006906,
        "file_name": "common.c",
        "file_hash": 227108095659128555473924245568634074234,
        "cwe": [
            "CWE-190"
        ],
        "cve": "CVE-2022-23558",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. An attacker can craft a TFLite model that would cause an integer overflow in `TfLiteIntArrayCreate`. The `TfLiteIntArrayGetSizeInBytes` returns an `int` instead of a `size_t. An attacker can control model inputs such that `computed_size` overflows the size of `int` datatype. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23558",
        "func_name": "TfLiteIntArrayGetSizeInBytes",
        "diff": [
            "diff --git a/tensorflow/lite/c/common.c b/tensorflow/lite/c/common.c\nindex ef4d3ffdec555d..d149d22c567c53 100644\n--- a/tensorflow/lite/c/common.c\n+++ b/tensorflow/lite/c/common.c\n@@ -21,10 +21,10 @@ limitations under the License.\n #include <string.h>\n #endif  // TF_LITE_STATIC_MEMORY\n \n-int TfLiteIntArrayGetSizeInBytes(int size) {\n+size_t TfLiteIntArrayGetSizeInBytes(int size) {\n   static TfLiteIntArray dummy;\n \n-  int computed_size = sizeof(dummy) + sizeof(dummy.data[0]) * size;\n+  size_t computed_size = sizeof(dummy) + sizeof(dummy.data[0]) * size;\n #if defined(_MSC_VER)\n   // Context for why this is needed is in http://b/189926408#comment21\n   computed_size -= sizeof(dummy.data[0]);\n@@ -51,7 +51,7 @@ int TfLiteIntArrayEqualsArray(const TfLiteIntArray* a, int b_size,\n #ifndef TF_LITE_STATIC_MEMORY\n \n TfLiteIntArray* TfLiteIntArrayCreate(int size) {\n-  int alloc_size = TfLiteIntArrayGetSizeInBytes(size);\n+  size_t alloc_size = TfLiteIntArrayGetSizeInBytes(size);\n   if (alloc_size <= 0) return NULL;\n   TfLiteIntArray* ret = (TfLiteIntArray*)malloc(alloc_size);\n   if (!ret) return ret;\ndiff --git a/tensorflow/lite/c/common.h b/tensorflow/lite/c/common.h\nindex e02f6ef6d7c7e0..7056d1e2211323 100644\n--- a/tensorflow/lite/c/common.h\n+++ b/tensorflow/lite/c/common.h\n@@ -98,7 +98,7 @@ typedef struct TfLiteIntArray {\n \n // Given the size (number of elements) in a TfLiteIntArray, calculate its size\n // in bytes.\n-int TfLiteIntArrayGetSizeInBytes(int size);\n+size_t TfLiteIntArrayGetSizeInBytes(int size);\n \n #ifndef TF_LITE_STATIC_MEMORY\n // Create a array of a given `size` (uninitialized entries).\n"
        ],
        "func_after": []
    },
    {
        "idx": 195403,
        "project": "tensorflow",
        "commit_id": "a1e1511dde36b3f8aa27a6ec630838e7ea40e091",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/a1e1511dde36b3f8aa27a6ec630838e7ea40e091",
        "commit_message": "[lite] Update TfLiteIntArrayCreate to return size_t\n\nPiperOrigin-RevId: 416439896\nChange-Id: I847f69b68d1ddaff4b1e925a09b8b69c1756653b",
        "target": 1,
        "irrelevant": 0,
        "func_before": "TfLiteIntArray* TfLiteIntArrayCreate(int size) {\n  int alloc_size = TfLiteIntArrayGetSizeInBytes(size);\n  if (alloc_size <= 0) return NULL;\n  TfLiteIntArray* ret = (TfLiteIntArray*)malloc(alloc_size);\n  if (!ret) return ret;\n  ret->size = size;\n  return ret;\n}",
        "func_hash": 64742066879088615123277599572040485093,
        "file_name": "common.c",
        "file_hash": 227108095659128555473924245568634074234,
        "cwe": [
            "CWE-190"
        ],
        "cve": "CVE-2022-23558",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. An attacker can craft a TFLite model that would cause an integer overflow in `TfLiteIntArrayCreate`. The `TfLiteIntArrayGetSizeInBytes` returns an `int` instead of a `size_t. An attacker can control model inputs such that `computed_size` overflows the size of `int` datatype. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23558",
        "func_name": "TfLiteIntArrayCreate",
        "diff": [
            "diff --git a/tensorflow/lite/c/common.c b/tensorflow/lite/c/common.c\nindex ef4d3ffdec555d..d149d22c567c53 100644\n--- a/tensorflow/lite/c/common.c\n+++ b/tensorflow/lite/c/common.c\n@@ -21,10 +21,10 @@ limitations under the License.\n #include <string.h>\n #endif  // TF_LITE_STATIC_MEMORY\n \n-int TfLiteIntArrayGetSizeInBytes(int size) {\n+size_t TfLiteIntArrayGetSizeInBytes(int size) {\n   static TfLiteIntArray dummy;\n \n-  int computed_size = sizeof(dummy) + sizeof(dummy.data[0]) * size;\n+  size_t computed_size = sizeof(dummy) + sizeof(dummy.data[0]) * size;\n #if defined(_MSC_VER)\n   // Context for why this is needed is in http://b/189926408#comment21\n   computed_size -= sizeof(dummy.data[0]);\n@@ -51,7 +51,7 @@ int TfLiteIntArrayEqualsArray(const TfLiteIntArray* a, int b_size,\n #ifndef TF_LITE_STATIC_MEMORY\n \n TfLiteIntArray* TfLiteIntArrayCreate(int size) {\n-  int alloc_size = TfLiteIntArrayGetSizeInBytes(size);\n+  size_t alloc_size = TfLiteIntArrayGetSizeInBytes(size);\n   if (alloc_size <= 0) return NULL;\n   TfLiteIntArray* ret = (TfLiteIntArray*)malloc(alloc_size);\n   if (!ret) return ret;\ndiff --git a/tensorflow/lite/c/common.h b/tensorflow/lite/c/common.h\nindex e02f6ef6d7c7e0..7056d1e2211323 100644\n--- a/tensorflow/lite/c/common.h\n+++ b/tensorflow/lite/c/common.h\n@@ -98,7 +98,7 @@ typedef struct TfLiteIntArray {\n \n // Given the size (number of elements) in a TfLiteIntArray, calculate its size\n // in bytes.\n-int TfLiteIntArrayGetSizeInBytes(int size);\n+size_t TfLiteIntArrayGetSizeInBytes(int size);\n \n #ifndef TF_LITE_STATIC_MEMORY\n // Create a array of a given `size` (uninitialized entries).\n"
        ],
        "func_after": []
    },
    {
        "idx": 195404,
        "project": "tensorflow",
        "commit_id": "ba4e8ac4dc2991e350d5cc407f8598c8d4ee70fb",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/ba4e8ac4dc2991e350d5cc407f8598c8d4ee70fb",
        "commit_message": "Fix potential divide by zero error when executing FractionalMaxPool, when pooling ratio is higher than input size for a particular dimension.\n\nPiperOrigin-RevId: 412151722\nChange-Id: I06e57cbb8eca43816eff79eac264fa7aae8f7163",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext* context) override {\n    typedef Eigen::Map<const Eigen::Matrix<T, Eigen::Dynamic, Eigen::Dynamic>>\n        ConstEigenMatrixMap;\n    typedef Eigen::Map<Eigen::Matrix<T, Eigen::Dynamic, Eigen::Dynamic>>\n        EigenMatrixMap;\n\n    constexpr int tensor_in_and_out_dims = 4;\n\n    const Tensor& tensor_in = context->input(0);\n    OP_REQUIRES(context, tensor_in.dims() == tensor_in_and_out_dims,\n                errors::InvalidArgument(\"tensor_in must be 4-dimensional\"));\n\n    std::vector<int> input_size(tensor_in_and_out_dims);\n    std::vector<int> output_size(tensor_in_and_out_dims);\n    for (int i = 0; i < tensor_in_and_out_dims; ++i) {\n      input_size[i] = tensor_in.dim_size(i);\n    }\n    // Output size.\n    for (int i = 0; i < tensor_in_and_out_dims; ++i) {\n      // This must match the same logic in the shape function in\n      // core/ops/nn_ops.cc.\n      output_size[i] =\n          static_cast<int>(std::floor(input_size[i] / pooling_ratio_[i]));\n      DCHECK_GT(output_size[i], 0);\n    }\n\n    // Generate pooling sequence.\n    std::vector<int64_t> height_cum_seq;\n    std::vector<int64_t> width_cum_seq;\n    GuardedPhiloxRandom generator;\n    generator.Init(seed_, seed2_);\n    height_cum_seq = GeneratePoolingSequence(input_size[1], output_size[1],\n                                             &generator, pseudo_random_);\n    width_cum_seq = GeneratePoolingSequence(input_size[2], output_size[2],\n                                            &generator, pseudo_random_);\n\n    // Prepare output.\n    Tensor* output_tensor = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(\n                                0,\n                                TensorShape({output_size[0], output_size[1],\n                                             output_size[2], output_size[3]}),\n                                &output_tensor));\n    Tensor* output_height_seq_tensor = nullptr;\n    OP_REQUIRES_OK(\n        context,\n        context->allocate_output(\n            1, TensorShape({static_cast<int64_t>(height_cum_seq.size())}),\n            &output_height_seq_tensor));\n    Tensor* output_width_seq_tensor = nullptr;\n    OP_REQUIRES_OK(\n        context,\n        context->allocate_output(\n            2, TensorShape({static_cast<int64_t>(width_cum_seq.size())}),\n            &output_width_seq_tensor));\n\n    ConstEigenMatrixMap in_mat(tensor_in.flat<T>().data(), input_size[3],\n                               input_size[2] * input_size[1] * input_size[0]);\n\n    EigenMatrixMap out_mat(output_tensor->flat<T>().data(), output_size[3],\n                           output_size[2] * output_size[1] * output_size[0]);\n\n    // Initializes the output tensor with MIN<T>.\n    output_tensor->flat<T>().setConstant(Eigen::NumTraits<T>::lowest());\n\n    auto output_height_seq_flat = output_height_seq_tensor->flat<int64_t>();\n    auto output_width_seq_flat = output_width_seq_tensor->flat<int64_t>();\n\n    // Set output tensors.\n    for (int i = 0; i < height_cum_seq.size(); ++i) {\n      output_height_seq_flat(i) = height_cum_seq[i];\n    }\n\n    for (int i = 0; i < width_cum_seq.size(); ++i) {\n      output_width_seq_flat(i) = width_cum_seq[i];\n    }\n\n    // For both input and output,\n    // 0: batch\n    // 1: height / row\n    // 2: width / col\n    // 3: depth / channel\n    const int64_t height_max = input_size[1] - 1;\n    const int64_t width_max = input_size[2] - 1;\n    for (int64_t b = 0; b < input_size[0]; ++b) {\n      // height sequence.\n      for (int64_t hs = 0; hs < height_cum_seq.size() - 1; ++hs) {\n        // height start and end.\n        const int64_t height_start = height_cum_seq[hs];\n        int64_t height_end =\n            overlapping_ ? height_cum_seq[hs + 1] : height_cum_seq[hs + 1] - 1;\n        height_end = std::min(height_end, height_max);\n\n        // width sequence.\n        for (int64_t ws = 0; ws < width_cum_seq.size() - 1; ++ws) {\n          const int64_t out_offset =\n              (b * output_size[1] + hs) * output_size[2] + ws;\n          // width start and end.\n          const int64_t width_start = width_cum_seq[ws];\n          int64_t width_end =\n              overlapping_ ? width_cum_seq[ws + 1] : width_cum_seq[ws + 1] - 1;\n          width_end = std::min(width_end, width_max);\n          for (int64_t h = height_start; h <= height_end; ++h) {\n            for (int64_t w = width_start; w <= width_end; ++w) {\n              const int64_t in_offset =\n                  (b * input_size[1] + h) * input_size[2] + w;\n              out_mat.col(out_offset) =\n                  out_mat.col(out_offset).cwiseMax(in_mat.col(in_offset));\n            }\n          }\n        }\n      }\n    }\n  }",
        "func_hash": 329653208386215793548956261636203970964,
        "file_name": "fractional_max_pool_op.cc",
        "file_hash": 38088244475067119710916669469162645605,
        "cwe": [
            "CWE-369"
        ],
        "cve": "CVE-2022-21735",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The implementation of `FractionalMaxPool` can be made to crash a TensorFlow process via a division by 0. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-21735",
        "func_name": "Compute",
        "diff": [
            "diff --git a/tensorflow/core/kernels/fractional_max_pool_op.cc b/tensorflow/core/kernels/fractional_max_pool_op.cc\nindex 7519c84667409f..0722c408fba9d4 100644\n--- a/tensorflow/core/kernels/fractional_max_pool_op.cc\n+++ b/tensorflow/core/kernels/fractional_max_pool_op.cc\n@@ -83,6 +83,13 @@ class FractionalMaxPoolOp : public OpKernel {\n     std::vector<int> output_size(tensor_in_and_out_dims);\n     for (int i = 0; i < tensor_in_and_out_dims; ++i) {\n       input_size[i] = tensor_in.dim_size(i);\n+\n+      OP_REQUIRES(\n+          context, input_size[i] >= pooling_ratio_[i],\n+          errors::InvalidArgument(\"Pooling ratio is higher than input \"\n+                                  \"dimension size for dimension \",\n+                                  i, \". Input dim size: \", input_size[i],\n+                                  \" pooling ratio: \", pooling_ratio_[i]));\n     }\n     // Output size.\n     for (int i = 0; i < tensor_in_and_out_dims; ++i) {\ndiff --git a/tensorflow/python/kernel_tests/nn_ops/fractional_max_pool_op_test.py b/tensorflow/python/kernel_tests/nn_ops/fractional_max_pool_op_test.py\nindex f5b5bd92a283ea..5acacdbb7463b2 100644\n--- a/tensorflow/python/kernel_tests/nn_ops/fractional_max_pool_op_test.py\n+++ b/tensorflow/python/kernel_tests/nn_ops/fractional_max_pool_op_test.py\n@@ -20,6 +20,7 @@\n \n from tensorflow.python.framework import constant_op\n from tensorflow.python.framework import dtypes\n+from tensorflow.python.framework import errors\n from tensorflow.python.framework import test_util\n from tensorflow.python.ops import array_ops\n from tensorflow.python.ops import gen_nn_ops\n@@ -319,6 +320,24 @@ def testDeterminismExceptionThrowing(self):\n       nn_ops.fractional_max_pool(\n           rand_mat, [1, 1.5, 1.5, 1], seed=1, seed2=1, deterministic=True)\n \n+  def testPoolingRatio(self):\n+    with self.cached_session() as _:\n+      with self.assertRaisesRegex(\n+          errors.InvalidArgumentError,\n+          r\"Pooling ratio is higher than input dimension size for dimension 1.*\"\n+      ):\n+        result = nn_ops.gen_nn_ops.fractional_max_pool(\n+            value=constant_op.constant(\n+                value=[[[[1, 4, 2, 3]]]], dtype=dtypes.int64),\n+            pooling_ratio=[1.0, 1.44, 1.73, 1.0],\n+            pseudo_random=False,\n+            overlapping=False,\n+            deterministic=False,\n+            seed=0,\n+            seed2=0,\n+            name=None)\n+        self.evaluate(result)\n+\n \n class FractionalMaxPoolGradTest(test.TestCase):\n   \"\"\"Tests for FractionalMaxPoolGrad.\n"
        ],
        "func_after": []
    },
    {
        "idx": 195405,
        "project": "ImageMagick6",
        "commit_id": "29c8abce0da56b536542f76a9ddfebdaab5b2943",
        "project_url": "https://github.com/ImageMagick/ImageMagick6",
        "commit_url": "https://github.com/ImageMagick/ImageMagick6/commit/29c8abce0da56b536542f76a9ddfebdaab5b2943",
        "commit_message": "https://github.com/ImageMagick/ImageMagick/pull/4986",
        "target": 1,
        "irrelevant": 1,
        "func_before": "static Image *ReadPCLImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n#define CropBox  \"CropBox\"\n#define DeviceCMYK  \"DeviceCMYK\"\n#define MediaBox  \"MediaBox\"\n#define RenderPCLText  \"  Rendering PCL...  \"\n\n  char\n    command[MaxTextExtent],\n    *density,\n    filename[MaxTextExtent],\n    geometry[MaxTextExtent],\n    *options,\n    input_filename[MaxTextExtent];\n\n  const DelegateInfo\n    *delegate_info;\n\n  Image\n    *image,\n    *next_image;\n\n  ImageInfo\n    *read_info;\n\n  int\n    c;\n\n  MagickBooleanType\n    cmyk,\n    status;\n\n  PointInfo\n    delta;\n\n  RectangleInfo\n    bounding_box,\n    page;\n\n  char\n    *p;\n\n  SegmentInfo\n    bounds;\n\n  size_t\n    height,\n    width;\n\n  ssize_t\n    count;\n\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  /*\n    Open image file.\n  */\n  image=AcquireImage(image_info);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  status=AcquireUniqueSymbolicLink(image_info->filename,input_filename);\n  if (status == MagickFalse)\n    {\n      ThrowFileException(exception,FileOpenError,\"UnableToCreateTemporaryFile\",\n        image_info->filename);\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    Set the page density.\n  */\n  delta.x=DefaultResolution;\n  delta.y=DefaultResolution;\n  if ((image->x_resolution == 0.0) || (image->y_resolution == 0.0))\n    {\n      GeometryInfo\n        geometry_info;\n\n      MagickStatusType\n        flags;\n\n      flags=ParseGeometry(PSDensityGeometry,&geometry_info);\n      if ((flags & RhoValue) != 0)\n        image->x_resolution=geometry_info.rho;\n      image->y_resolution=image->x_resolution;\n      if ((flags & SigmaValue) != 0)\n        image->y_resolution=geometry_info.sigma;\n    }\n  /*\n    Determine page geometry from the PCL media box.\n  */\n  cmyk=image->colorspace == CMYKColorspace ? MagickTrue : MagickFalse;\n  count=0;\n  (void) memset(&bounding_box,0,sizeof(bounding_box));\n  (void) memset(&bounds,0,sizeof(bounds));\n  (void) memset(&page,0,sizeof(page));\n  (void) memset(command,0,sizeof(command));\n  p=command;\n  for (c=ReadBlobByte(image); c != EOF; c=ReadBlobByte(image))\n  {\n    if (image_info->page != (char *) NULL)\n      continue;\n    /*\n      Note PCL elements.\n    */\n    *p++=(char) c;\n    if ((c != (int) '/') && (c != '\\n') &&\n        ((size_t) (p-command) < (MaxTextExtent-1)))\n      continue;\n    *p='\\0';\n    p=command;\n    /*\n      Is this a CMYK document?\n    */\n    if (LocaleNCompare(DeviceCMYK,command,strlen(DeviceCMYK)) == 0)\n      cmyk=MagickTrue;\n    if (LocaleNCompare(CropBox,command,strlen(CropBox)) == 0)\n      {\n        /*\n          Note region defined by crop box.\n        */\n        count=(ssize_t) sscanf(command,\"CropBox [%lf %lf %lf %lf\",\n          &bounds.x1,&bounds.y1,&bounds.x2,&bounds.y2);\n        if (count != 4)\n          count=(ssize_t) sscanf(command,\"CropBox[%lf %lf %lf %lf\",\n            &bounds.x1,&bounds.y1,&bounds.x2,&bounds.y2);\n      }\n    if (LocaleNCompare(MediaBox,command,strlen(MediaBox)) == 0)\n      {\n        /*\n          Note region defined by media box.\n        */\n        count=(ssize_t) sscanf(command,\"MediaBox [%lf %lf %lf %lf\",\n          &bounds.x1,&bounds.y1,&bounds.x2,&bounds.y2);\n        if (count != 4)\n          count=(ssize_t) sscanf(command,\"MediaBox[%lf %lf %lf %lf\",\n            &bounds.x1,&bounds.y1,&bounds.x2,&bounds.y2);\n      }\n    if (count != 4)\n      continue;\n    /*\n      Set PCL render geometry.\n    */\n    width=(size_t) floor(bounds.x2-bounds.x1+0.5);\n    height=(size_t) floor(bounds.y2-bounds.y1+0.5);\n    if (width > page.width)\n      page.width=width;\n    if (height > page.height)\n      page.height=height;\n  }\n  (void) CloseBlob(image);\n  /*\n    Render PCL with the GhostPCL delegate.\n  */\n  if ((page.width == 0) || (page.height == 0))\n    (void) ParseAbsoluteGeometry(PSPageGeometry,&page);\n  if (image_info->page != (char *) NULL)\n    (void) ParseAbsoluteGeometry(image_info->page,&page);\n  (void) FormatLocaleString(geometry,MaxTextExtent,\"%.20gx%.20g\",(double)\n    page.width,(double) page.height);\n  if (image_info->monochrome != MagickFalse)\n    delegate_info=GetDelegateInfo(\"pcl:mono\",(char *) NULL,exception);\n  else\n     if (cmyk != MagickFalse)\n       delegate_info=GetDelegateInfo(\"pcl:cmyk\",(char *) NULL,exception);\n     else\n       delegate_info=GetDelegateInfo(\"pcl:color\",(char *) NULL,exception);\n  if (delegate_info == (const DelegateInfo *) NULL)\n    {\n      image=DestroyImage(image);\n      return((Image *) NULL);\n    }\n  if ((page.width == 0) || (page.height == 0))\n    (void) ParseAbsoluteGeometry(PSPageGeometry,&page);\n  if (image_info->page != (char *) NULL)\n    (void) ParseAbsoluteGeometry(image_info->page,&page);\n  density=AcquireString(\"\");\n  options=AcquireString(\"\");\n  (void) FormatLocaleString(density,MaxTextExtent,\"%gx%g\",\n    image->x_resolution,image->y_resolution);\n  if (image_info->ping != MagickFalse)\n    (void) FormatLocaleString(density,MagickPathExtent,\"2.0x2.0\");\n  page.width=(size_t) floor((double) page.width*image->x_resolution/delta.x+\n    0.5);\n  page.height=(size_t) floor((double) page.height*image->y_resolution/delta.y+\n    0.5);\n  (void) FormatLocaleString(options,MaxTextExtent,\"-g%.20gx%.20g \",(double)\n     page.width,(double) page.height);\n  image=DestroyImage(image);\n  read_info=CloneImageInfo(image_info);\n  *read_info->magick='\\0';\n  if (read_info->number_scenes != 0)\n    {\n      if (read_info->number_scenes != 1)\n        (void) FormatLocaleString(options,MaxTextExtent,\"-dLastPage=%.20g\",\n          (double) (read_info->scene+read_info->number_scenes));\n      else\n        (void) FormatLocaleString(options,MaxTextExtent,\n          \"-dFirstPage=%.20g -dLastPage=%.20g\",(double) read_info->scene+1,\n          (double) (read_info->scene+read_info->number_scenes));\n      read_info->number_scenes=0;\n      if (read_info->scenes != (char *) NULL)\n        *read_info->scenes='\\0';\n    }\n  (void) CopyMagickString(filename,read_info->filename,MaxTextExtent);\n  (void) AcquireUniqueFilename(read_info->filename);\n  (void) FormatLocaleString(command,MaxTextExtent,\n    GetDelegateCommands(delegate_info),\n    read_info->antialias != MagickFalse ? 4 : 1,\n    read_info->antialias != MagickFalse ? 4 : 1,density,options,\n    read_info->filename,input_filename);\n  options=DestroyString(options);\n  density=DestroyString(density);\n  status=ExternalDelegateCommand(MagickFalse,read_info->verbose,command,\n    (char *) NULL,exception) != 0 ? MagickTrue : MagickFalse;\n  image=ReadImage(read_info,exception);\n  (void) RelinquishUniqueFileResource(read_info->filename);\n  (void) RelinquishUniqueFileResource(input_filename);\n  read_info=DestroyImageInfo(read_info);\n  if (image == (Image *) NULL)\n    ThrowReaderException(DelegateError,\"PCLDelegateFailed\");\n  if (LocaleCompare(image->magick,\"BMP\") == 0)\n    {\n      Image\n        *cmyk_image;\n\n      cmyk_image=ConsolidateCMYKImages(image,&image->exception);\n      if (cmyk_image != (Image *) NULL)\n        {\n          image=DestroyImageList(image);\n          image=cmyk_image;\n        }\n    }\n  do\n  {\n    (void) CopyMagickString(image->filename,filename,MaxTextExtent);\n    image->page=page;\n    if (image_info->ping != MagickFalse)\n      {\n        image->magick_columns*=image->x_resolution/2.0;\n        image->magick_rows*=image->y_resolution/2.0;\n        image->columns*=image->x_resolution/2.0;\n        image->rows*=image->y_resolution/2.0;\n      }\n    next_image=SyncNextImageInList(image);\n    if (next_image != (Image *) NULL)\n      image=next_image;\n  } while (next_image != (Image *) NULL);\n  return(GetFirstImageInList(image));\n}",
        "func_hash": 285956846610376765198872183403915882061,
        "file_name": "pcl.c",
        "file_hash": 338547174937023730341471137685130471169,
        "cwe": [
            "CWE-190"
        ],
        "cve": "CVE-2022-32546",
        "cve_desc": "A vulnerability was found in ImageMagick, causing an outside the range of representable values of type 'unsigned long' at coders/pcl.c, when crafted or untrusted input is processed. This leads to a negative impact to application availability or other problems related to undefined behavior.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-32546",
        "func_name": "ReadPCLImage",
        "diff": [
            "diff --git a/coders/pcl.c b/coders/pcl.c\nindex 5e57086e45..a7456dae6c 100644\n--- a/coders/pcl.c\n+++ b/coders/pcl.c\n@@ -295,8 +295,8 @@ static Image *ReadPCLImage(const ImageInfo *image_info,ExceptionInfo *exception)\n     /*\n       Set PCL render geometry.\n     */\n-    width=(size_t) floor(bounds.x2-bounds.x1+0.5);\n-    height=(size_t) floor(bounds.y2-bounds.y1+0.5);\n+    width=(size_t) CastDoubleToLong(floor(bounds.x2-bounds.x1+0.5));\n+    height=(size_t) CastDoubleToLong(floor(bounds.y2-bounds.y1+0.5));\n     if (width > page.width)\n       page.width=width;\n     if (height > page.height)\n"
        ],
        "func_after": []
    },
    {
        "idx": 195409,
        "project": "gpac",
        "commit_id": "64a2e1b799352ac7d7aad1989bc06e7b0f2b01db",
        "project_url": "https://github.com/gpac/gpac",
        "commit_url": "https://github.com/gpac/gpac/commit/64a2e1b799352ac7d7aad1989bc06e7b0f2b01db",
        "commit_message": "fixed #2092",
        "target": 1,
        "irrelevant": 1,
        "func_before": "\nvoid gitn_box_del(GF_Box *s)\n{\n\tu32 i;\n\tGroupIdToNameBox *ptr = (GroupIdToNameBox *)s;\n\tif (ptr == NULL) return;\n\tfor (i=0; i<ptr->nb_entries; i++) {\n\t\tif (ptr->entries[i].name) gf_free(ptr->entries[i].name);\n\t}\n\tif (ptr->entries) gf_free(ptr->entries);\n\tgf_free(ptr);",
        "func_hash": 37642310110270321687625000100653046485,
        "file_name": "box_code_base.c",
        "file_hash": 212802147696207025803784466432150384318,
        "cwe": [
            "CWE-476"
        ],
        "cve": "CVE-2021-4043",
        "cve_desc": "NULL Pointer Dereference in GitHub repository gpac/gpac prior to 1.1.0.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-4043",
        "func_name": "gitn_box_del",
        "diff": [
            "diff --git a/src/isomedia/box_code_base.c b/src/isomedia/box_code_base.c\nindex b3c38310ad..126084b0ea 100644\n--- a/src/isomedia/box_code_base.c\n+++ b/src/isomedia/box_code_base.c\n@@ -11083,10 +11083,12 @@ void gitn_box_del(GF_Box *s)\n \tu32 i;\n \tGroupIdToNameBox *ptr = (GroupIdToNameBox *)s;\n \tif (ptr == NULL) return;\n-\tfor (i=0; i<ptr->nb_entries; i++) {\n-\t\tif (ptr->entries[i].name) gf_free(ptr->entries[i].name);\n+\tif (ptr->entries) {\n+\t\tfor (i=0; i<ptr->nb_entries; i++) {\n+\t\t\tif (ptr->entries[i].name) gf_free(ptr->entries[i].name);\n+\t\t}\n+\t\tgf_free(ptr->entries);\n \t}\n-\tif (ptr->entries) gf_free(ptr->entries);\n \tgf_free(ptr);\n }\n \n"
        ],
        "func_after": []
    },
    {
        "idx": 195410,
        "project": "tensorflow",
        "commit_id": "965b97e4a9650495cda5a8c210ef6684b4b9eceb",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/965b97e4a9650495cda5a8c210ef6684b4b9eceb",
        "commit_message": "Properly validate sparse tensor in `SparseTensorSliceDataset`\n\nExisting validation was incomplete.\n\nPiperOrigin-RevId: 415375048\nChange-Id: I14cd18f29ede73286f3ffac35171bd15828997e9",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void MakeDataset(OpKernelContext* ctx, DatasetBase** output) override {\n    // Create a new SparseTensorSliceDatasetOp::Dataset, insert it in\n    // the step container, and return it as the output.\n    const Tensor* indices;\n    OP_REQUIRES_OK(ctx, ctx->input(\"indices\", &indices));\n    const Tensor* values;\n    OP_REQUIRES_OK(ctx, ctx->input(\"values\", &values));\n    const Tensor* dense_shape;\n    OP_REQUIRES_OK(ctx, ctx->input(\"dense_shape\", &dense_shape));\n\n    OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(indices->shape()),\n                errors::InvalidArgument(\n                    \"Input indices should be a matrix but received shape \",\n                    indices->shape().DebugString()));\n\n    const auto num_indices = indices->NumElements();\n    const auto num_values = values->NumElements();\n    if (num_indices == 0 || num_values == 0) {\n      OP_REQUIRES(ctx, num_indices == num_values,\n                  errors::InvalidArgument(\n                      \"If indices or values are empty, the other one must also \"\n                      \"be. Got indices of shape \",\n                      indices->shape().DebugString(), \" and values of shape \",\n                      values->shape().DebugString()));\n    }\n    OP_REQUIRES(ctx, TensorShapeUtils::IsVector(values->shape()),\n                errors::InvalidArgument(\n                    \"Input values should be a vector but received shape \",\n                    indices->shape().DebugString()));\n    OP_REQUIRES(ctx, TensorShapeUtils::IsVector(dense_shape->shape()),\n                errors::InvalidArgument(\n                    \"Input shape should be a vector but received shape \",\n                    dense_shape->shape().DebugString()));\n\n    // We currently ensure that `sparse_tensor` is ordered in the\n    // batch dimension.\n    // TODO(mrry): Investigate ways to avoid this unconditional check\n    // if we can be sure that the sparse tensor was produced in an\n    // appropriate order (e.g. by `tf.parse_example()` or a Dataset\n    // that batches elements into rows of a SparseTensor).\n    int64_t previous_batch_index = -1;\n    for (int64_t i = 0; i < indices->dim_size(0); ++i) {\n      int64_t next_batch_index = indices->matrix<int64_t>()(i, 0);\n      OP_REQUIRES(\n          ctx, next_batch_index >= previous_batch_index,\n          errors::Unimplemented(\"The SparseTensor must be ordered in the batch \"\n                                \"dimension; handling arbitrarily ordered input \"\n                                \"is not currently supported.\"));\n      previous_batch_index = next_batch_index;\n    }\n    gtl::InlinedVector<int64_t, 8> std_order(dense_shape->NumElements(), 0);\n    sparse::SparseTensor tensor;\n    OP_REQUIRES_OK(\n        ctx, sparse::SparseTensor::Create(\n                 *indices, *values, TensorShape(dense_shape->vec<int64_t>()),\n                 std_order, &tensor));\n    *output = new Dataset<T>(ctx, std::move(tensor));\n  }",
        "func_hash": 232798786480644222523895580158118045723,
        "file_name": "sparse_tensor_slice_dataset_op.cc",
        "file_hash": 20179985196620256343354076777909821072,
        "cwe": [
            "CWE-476"
        ],
        "cve": "CVE-2022-21736",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The implementation of `SparseTensorSliceDataset` has an undefined behavior: under certain condition it can be made to dereference a `nullptr` value. The 3 input arguments to `SparseTensorSliceDataset` represent a sparse tensor. However, there are some preconditions that these arguments must satisfy but these are not validated in the implementation. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-21736",
        "func_name": "MakeDataset",
        "diff": [
            "diff --git a/tensorflow/core/kernels/data/sparse_tensor_slice_dataset_op.cc b/tensorflow/core/kernels/data/sparse_tensor_slice_dataset_op.cc\nindex c8f3db30c37f4d..c6901de5c34267 100644\n--- a/tensorflow/core/kernels/data/sparse_tensor_slice_dataset_op.cc\n+++ b/tensorflow/core/kernels/data/sparse_tensor_slice_dataset_op.cc\n@@ -240,28 +240,29 @@ class SparseTensorSliceDatasetOp : public DatasetOpKernel {\n     OP_REQUIRES_OK(ctx, ctx->input(\"dense_shape\", &dense_shape));\n \n     OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(indices->shape()),\n-                errors::InvalidArgument(\n-                    \"Input indices should be a matrix but received shape \",\n-                    indices->shape().DebugString()));\n-\n-    const auto num_indices = indices->NumElements();\n-    const auto num_values = values->NumElements();\n-    if (num_indices == 0 || num_values == 0) {\n-      OP_REQUIRES(ctx, num_indices == num_values,\n-                  errors::InvalidArgument(\n-                      \"If indices or values are empty, the other one must also \"\n-                      \"be. Got indices of shape \",\n-                      indices->shape().DebugString(), \" and values of shape \",\n-                      values->shape().DebugString()));\n-    }\n+                errors::InvalidArgument(\"Input indices must be a matrix. Got: \",\n+                                        indices->shape().DebugString()));\n     OP_REQUIRES(ctx, TensorShapeUtils::IsVector(values->shape()),\n-                errors::InvalidArgument(\n-                    \"Input values should be a vector but received shape \",\n-                    indices->shape().DebugString()));\n+                errors::InvalidArgument(\"Input values must be a vector. Got: \",\n+                                        values->shape().DebugString()));\n     OP_REQUIRES(ctx, TensorShapeUtils::IsVector(dense_shape->shape()),\n+                errors::InvalidArgument(\"Input shape must be a vector. Got: \",\n+                                        dense_shape->shape().DebugString()));\n+    OP_REQUIRES(\n+        ctx, values->shape().dim_size(0) == indices->shape().dim_size(0),\n+        errors::InvalidArgument(\n+            \"Number of values must match first dimension of indices. \", \"Got \",\n+            values->shape().dim_size(0),\n+            \" values, indices shape: \", indices->shape().DebugString()));\n+    OP_REQUIRES(\n+        ctx, dense_shape->shape().dim_size(0) == indices->shape().dim_size(1),\n+        errors::InvalidArgument(\n+            \"Number of dimensions must match second dimension of indices. \",\n+            \"Got \", dense_shape->shape().dim_size(0),\n+            \" dimensions, indices shape: \", indices->shape().DebugString()));\n+    OP_REQUIRES(ctx, dense_shape->NumElements() > 0,\n                 errors::InvalidArgument(\n-                    \"Input shape should be a vector but received shape \",\n-                    dense_shape->shape().DebugString()));\n+                    \"The shape argument requires at least one element.\"));\n \n     // We currently ensure that `sparse_tensor` is ordered in the\n     // batch dimension.\ndiff --git a/tensorflow/python/data/kernel_tests/from_sparse_tensor_slices_test.py b/tensorflow/python/data/kernel_tests/from_sparse_tensor_slices_test.py\nindex 04f2c27bb9fe72..3d8ee43272fbf8 100644\n--- a/tensorflow/python/data/kernel_tests/from_sparse_tensor_slices_test.py\n+++ b/tensorflow/python/data/kernel_tests/from_sparse_tensor_slices_test.py\n@@ -134,6 +134,25 @@ def testEmptySparseTensorSlicesInvalid(self):\n       with self.assertRaises(errors.InvalidArgumentError):\n         sess.run(init_op, feed_dict={st: sparse_feed})\n \n+  @combinations.generate(combinations.combine(tf_api_version=1, mode=[\"graph\"]))\n+  def testEmptySparseTensorSlicesInvalid2(self):\n+    \"\"\"Test a dataset based on invalid `tf.sparse.SparseTensor`.\"\"\"\n+    st = array_ops.sparse_placeholder(dtypes.float64)\n+    iterator = dataset_ops.make_initializable_iterator(\n+        dataset_ops.Dataset.from_sparse_tensor_slices(st))\n+    init_op = iterator.initializer\n+\n+    with self.cached_session() as sess:\n+      # Test with an empty sparse tensor but with non empty values.\n+      empty_indices = [[]]\n+      empty_values = []\n+      dense_shape = [1, 1]\n+      sparse_feed = sparse_tensor.SparseTensorValue(empty_indices, empty_values,\n+                                                    dense_shape)\n+      # Here, we expect the test to fail when running the feed.\n+      with self.assertRaises(errors.InvalidArgumentError):\n+        sess.run(init_op, feed_dict={st: sparse_feed})\n+\n   @combinations.generate(combinations.combine(tf_api_version=2, mode=[\"eager\"]))\n   def testFromSparseTensorSlicesError(self):\n     with self.assertRaises(AttributeError):\n"
        ],
        "func_after": []
    },
    {
        "idx": 195471,
        "project": "weechat",
        "commit_id": "9904cb6d2eb40f679d8ff6557c22d53a3e3dc75a",
        "project_url": "https://github.com/weechat/weechat",
        "commit_url": "https://github.com/weechat/weechat/commit/9904cb6d2eb40f679d8ff6557c22d53a3e3dc75a",
        "commit_message": "irc: fix crash when receiving a malformed message 352 (who)\n\nThanks to Stuart Nevans Locke for reporting the issue.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "IRC_PROTOCOL_CALLBACK(352)\n{\n    char *pos_attr, *pos_hopcount, *pos_realname, *str_host;\n    int arg_start, length;\n    struct t_irc_channel *ptr_channel;\n    struct t_irc_nick *ptr_nick;\n\n    IRC_PROTOCOL_MIN_ARGS(5);\n\n    /* silently ignore malformed 352 message (missing infos) */\n    if (argc < 8)\n        return WEECHAT_RC_OK;\n\n    pos_attr = NULL;\n    pos_hopcount = NULL;\n    pos_realname = NULL;\n\n    if (argc > 8)\n    {\n        arg_start = (strcmp (argv[8], \"*\") == 0) ? 9 : 8;\n        if (argv[arg_start][0] == ':')\n        {\n            pos_attr = NULL;\n            pos_hopcount = (argc > arg_start) ? argv[arg_start] + 1 : NULL;\n            pos_realname = (argc > arg_start + 1) ? argv_eol[arg_start + 1] : NULL;\n        }\n        else\n        {\n            pos_attr = argv[arg_start];\n            pos_hopcount = (argc > arg_start + 1) ? argv[arg_start + 1] + 1 : NULL;\n            pos_realname = (argc > arg_start + 2) ? argv_eol[arg_start + 2] : NULL;\n        }\n    }\n\n    ptr_channel = irc_channel_search (server, argv[3]);\n    ptr_nick = (ptr_channel) ?\n        irc_nick_search (server, ptr_channel, argv[7]) : NULL;\n\n    /* update host in nick */\n    if (ptr_nick)\n    {\n        length = strlen (argv[4]) + 1 + strlen (argv[5]) + 1;\n        str_host = malloc (length);\n        if (str_host)\n        {\n            snprintf (str_host, length, \"%s@%s\", argv[4], argv[5]);\n            irc_nick_set_host (ptr_nick, str_host);\n            free (str_host);\n        }\n    }\n\n    /* update away flag in nick */\n    if (ptr_channel && ptr_nick && pos_attr)\n    {\n        irc_nick_set_away (server, ptr_channel, ptr_nick,\n                           (pos_attr[0] == 'G') ? 1 : 0);\n    }\n\n    /* update realname in nick */\n    if (ptr_channel && ptr_nick && pos_realname)\n    {\n        if (ptr_nick->realname)\n            free (ptr_nick->realname);\n        if (pos_realname &&\n            weechat_hashtable_has_key (server->cap_list, \"extended-join\"))\n        {\n            ptr_nick->realname = strdup (pos_realname);\n        }\n        else\n        {\n            ptr_nick->realname = NULL;\n        }\n    }\n\n    /* display output of who (manual who from user) */\n    if (!ptr_channel || (ptr_channel->checking_whox <= 0))\n    {\n        weechat_printf_date_tags (\n            irc_msgbuffer_get_target_buffer (\n                server, NULL, command, \"who\", NULL),\n            date,\n            irc_protocol_tags (command, \"irc_numeric\", NULL, NULL),\n            \"%s%s[%s%s%s] %s%s %s(%s%s@%s%s)%s %s%s%s%s(%s)\",\n            weechat_prefix (\"network\"),\n            IRC_COLOR_CHAT_DELIMITERS,\n            IRC_COLOR_CHAT_CHANNEL,\n            argv[3],\n            IRC_COLOR_CHAT_DELIMITERS,\n            irc_nick_color_for_msg (server, 1, NULL, argv[7]),\n            argv[7],\n            IRC_COLOR_CHAT_DELIMITERS,\n            IRC_COLOR_CHAT_HOST,\n            argv[4],\n            argv[5],\n            IRC_COLOR_CHAT_DELIMITERS,\n            IRC_COLOR_RESET,\n            (pos_attr) ? pos_attr : \"\",\n            (pos_attr) ? \" \" : \"\",\n            (pos_hopcount) ? pos_hopcount : \"\",\n            (pos_hopcount) ? \" \" : \"\",\n            (pos_realname) ? pos_realname : \"\");\n    }\n\n    return WEECHAT_RC_OK;\n}",
        "func_hash": 334241185700640959176375322270000746009,
        "file_name": "irc-protocol.c",
        "file_hash": 25326141648227228091841815556030791460,
        "cwe": [
            "CWE-476"
        ],
        "cve": "CVE-2020-9759",
        "cve_desc": "A Vulnerability of LG Electronic web OS TV Emulator could allow an attacker to escalate privileges and overwrite certain files. This vulnerability is due to wrong environment setting. An attacker could exploit this vulnerability through crafted configuration files and executable files.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2020-9759",
        "func_name": "IRC_PROTOCOL_CALLBACK",
        "diff": [
            "diff --git a/ChangeLog.adoc b/ChangeLog.adoc\nindex 862c4d429b2..475255e7431 100644\n--- a/ChangeLog.adoc\n+++ b/ChangeLog.adoc\n@@ -31,6 +31,7 @@ Bug fixes::\n   * core: fix memory leak in completion\n   * core: flush stdout/stderr before forking in hook_process function (issue #1441)\n   * core: fix evaluation of condition with nested \"if\" (issue #1434)\n+  * irc: fix crash when receiving a malformed message 352 (who)\n   * irc: fix crash when a new message 005 is received with longer nick prefixes\n   * irc: fix crash when receiving a malformed message 324 (channel mode)\n   * irc: add nick changes in the hotlist (except self nick change)\ndiff --git a/src/plugins/irc/irc-protocol.c b/src/plugins/irc/irc-protocol.c\nindex 05433d34e94..9238e8802f1 100644\n--- a/src/plugins/irc/irc-protocol.c\n+++ b/src/plugins/irc/irc-protocol.c\n@@ -4689,7 +4689,7 @@ IRC_PROTOCOL_CALLBACK(352)\n \n     if (argc > 8)\n     {\n-        arg_start = (strcmp (argv[8], \"*\") == 0) ? 9 : 8;\n+        arg_start = ((argc > 9) && (strcmp (argv[8], \"*\") == 0)) ? 9 : 8;\n         if (argv[arg_start][0] == ':')\n         {\n             pos_attr = NULL;\n"
        ],
        "func_after": []
    },
    {
        "idx": 195549,
        "project": "hhvm",
        "commit_id": "dabd48caf74995e605f1700344f1ff4a5d83441d",
        "project_url": "https://github.com/facebook/hhvm",
        "commit_url": "https://github.com/facebook/hhvm/commit/dabd48caf74995e605f1700344f1ff4a5d83441d",
        "commit_message": "Fix a json_decode crash when depth==0\n\nSummary:\nSetting depth=0 is an error, and should result in NULL, but we weren't\nchecking for it, so in the case of a single, top-level string, we\nwould reading the -1th element of the stack.\n\nDifferential Revision: D19609959\n\nfbshipit-source-id: 04ca1e0965e04b44df2d5c806a73c3da99ff66fb",
        "target": 1,
        "irrelevant": 0,
        "func_before": "bool JSON_parser(Variant &z, const char *p, int length, bool const assoc,\n                 int depth, int64_t options) {\n  // No GC safepoints during JSON parsing, please. Code is not re-entrant.\n  NoHandleSurpriseScope no_surprise(SafepointFlags);\n\n  json_parser *json = s_json_parser.get(); /* the parser state */\n  // Clear and reuse the thread-local string buffers. They are only freed if\n  // they exceed kMaxPersistentStringBufferCapacity at exit or if the thread\n  // is explicitly flushed (e.g., due to being idle).\n  json->initSb(length);\n  SCOPE_EXIT {\n    constexpr int kMaxPersistentStringBufferCapacity = 256 * 1024;\n    if (json->sb_cap > kMaxPersistentStringBufferCapacity) json->flushSb();\n  };\n  // SimpleParser only handles the most common set of options. Also, only use it\n  // if its array nesting depth check is *more* restrictive than what the user\n  // asks for, to ensure that the precise semantics of the general case is\n  // applied for all nesting overflows.\n  if (assoc &&\n      options == (options & (k_JSON_FB_LOOSE |\n                             k_JSON_FB_DARRAYS |\n                             k_JSON_FB_DARRAYS_AND_VARRAYS |\n                             k_JSON_FB_HACK_ARRAYS |\n                             k_JSON_FB_THRIFT_SIMPLE_JSON |\n                             k_JSON_FB_LEGACY_HACK_ARRAYS)) &&\n      depth >= SimpleParser::kMaxArrayDepth &&\n      length <= RuntimeOption::EvalSimpleJsonMaxLength &&\n      SimpleParser::TryParse(p, length, json->tl_buffer.tv, z,\n                             get_container_type_from_options(options),\n                             options & k_JSON_FB_THRIFT_SIMPLE_JSON)) {\n    return true;\n  }\n\n  int b;  /* the next character */\n  int c;  /* the next character class */\n  int s;  /* the next state */\n  int state = 0;\n\n  /*<fb>*/\n  bool const loose = options & k_JSON_FB_LOOSE;\n  JSONContainerType const container_type =\n    get_container_type_from_options(options);\n  int qchr = 0;\n  int8_t const *byte_class;\n  int8_t const (*next_state_table)[32];\n  if (loose) {\n    byte_class = loose_ascii_class;\n    next_state_table = loose_state_transition_table;\n  } else {\n    byte_class = ascii_class;\n    next_state_table = state_transition_table;\n  }\n  /*</fb>*/\n\n  UncheckedBuffer *buf = &json->sb_buf;\n  UncheckedBuffer *key = &json->sb_key;\n\n  DataType type = kInvalidDataType;\n  unsigned short escaped_bytes = 0;\n\n  auto reset_type = [&] { type = kInvalidDataType; };\n\n  json->depth = depth;\n  // Since the stack is maintainined on a per request basis, for performance\n  // reasons, it only makes sense to expand if necessary and cycles are wasted\n  // contracting. Calls with a depth other than default should be rare.\n  if (depth > json->stack.size()) {\n    json->stack.resize(depth);\n  }\n  SCOPE_EXIT {\n    if (json->stack.empty()) return;\n    for (int i = 0; i <= json->mark; i++) {\n      json->stack[i].key.reset();\n      json->stack[i].val.unset();\n    }\n    json->mark = -1;\n  };\n\n  json->mark = json->top = -1;\n  push(json, Mode::DONE);\n\n  UTF8To16Decoder decoder(p, length, loose);\n  for (;;) {\n    b = decoder.decode();\n    // Fast-case most common transition: append a simple string character.\n    if (state == 3 && type == KindOfString) {\n      while (b != '\\\"' &&  b != '\\\\' && b != '\\'' && b <= 127 && b >= ' ') {\n        buf->append((char)b);\n        b = decoder.decode();\n      }\n    }\n    if (b == UTF8_END) break; // UTF-8 decoding finishes successfully.\n    if (b == UTF8_ERROR) {\n      s_json_parser->error_code = JSON_ERROR_UTF8;\n      return false;\n    }\n    assertx(b >= 0);\n\n    if ((b & 127) == b) {\n      /*<fb>*/\n      c = byte_class[b];\n      /*</fb>*/\n      if (c <= S_ERR) {\n        s_json_parser->error_code = JSON_ERROR_CTRL_CHAR;\n        return false;\n      }\n    } else {\n      c = S_ETC;\n    }\n    /*\n      Get the next state from the transition table.\n    */\n\n    /*<fb>*/\n    s = next_state_table[state][c];\n\n    if (s == -4) {\n      if (b != qchr) {\n        s = 3;\n      } else {\n        qchr = 0;\n      }\n    }\n    /*</fb>*/\n\n    if (s < 0) {\n      /*\n        Perform one of the predefined actions.\n      */\n      switch (s) {\n        /*\n          empty }\n        */\n      case -9:\n        /*<fb>*/\n        if (json->top == 1) z = json->stack[json->top].val;\n        else {\n        /*</fb>*/\n          attach_zval(json, json->stack[json->top].key, assoc, container_type);\n        /*<fb>*/\n        }\n        /*</fb>*/\n        if (!pop(json, Mode::KEY)) {\n          return false;\n        }\n        state = 9;\n        break;\n        /*\n          {\n        */\n      case -8:\n        if (!push(json, Mode::KEY)) {\n          s_json_parser->error_code = JSON_ERROR_DEPTH;\n          return false;\n        }\n\n        state = 1;\n        if (json->top > 0) {\n          Variant &top = json->stack[json->top].val;\n          /*<fb>*/\n          if (container_type == JSONContainerType::COLLECTIONS) {\n            // stable_maps is meaningless\n            top = req::make<c_Map>();\n          } else {\n          /*</fb>*/\n            if (!assoc) {\n              top = SystemLib::AllocStdClassObject();\n            /* <fb> */\n            } else if (container_type == JSONContainerType::HACK_ARRAYS) {\n              top = Array::CreateDict();\n            } else if (container_type == JSONContainerType::DARRAYS ||\n                       container_type == JSONContainerType::DARRAYS_AND_VARRAYS)\n            {\n              top = Array::CreateDArray();\n            /* </fb> */\n            } else if (\n              container_type == JSONContainerType::LEGACY_HACK_ARRAYS) {\n              auto arr = staticEmptyDictArray()->copy();\n              arr->setLegacyArray(true);\n              top = arr;\n            } else {\n              top = Array::CreateDArray();\n            }\n          /*<fb>*/\n          }\n          /*</fb>*/\n          json->stack[json->top].key = copy_and_clear(*key);\n          reset_type();\n        }\n        break;\n        /*\n          }\n        */\n      case -7:\n        /*** BEGIN Facebook: json_utf8_loose ***/\n        /*\n          If this is a trailing comma in an object definition,\n          we're in Mode::KEY. In that case, throw that off the\n          stack and restore Mode::OBJECT so that we pretend the\n          trailing comma just didn't happen.\n        */\n        if (loose) {\n          if (pop(json, Mode::KEY)) {\n            push(json, Mode::OBJECT);\n          }\n        }\n        /*** END Facebook: json_utf8_loose ***/\n\n        if (type != kInvalidDataType &&\n            json->stack[json->top].mode == Mode::OBJECT) {\n          Variant mval;\n          json_create_zval(mval, *buf, type, options);\n          Variant &top = json->stack[json->top].val;\n          object_set(json, top, copy_and_clear(*key),\n                     mval, assoc, container_type);\n          buf->clear();\n          reset_type();\n        }\n\n        /*<fb>*/\n        if (json->top == 1) z = json->stack[json->top].val;\n        else {\n        /*</fb>*/\n          attach_zval(json, json->stack[json->top].key,\n            assoc, container_type);\n        /*<fb>*/\n        }\n        /*</fb>*/\n        if (!pop(json, Mode::OBJECT)) {\n          s_json_parser->error_code = JSON_ERROR_STATE_MISMATCH;\n          return false;\n        }\n        state = 9;\n        break;\n        /*\n          [\n        */\n      case -6:\n        if (!push(json, Mode::ARRAY)) {\n          s_json_parser->error_code = JSON_ERROR_DEPTH;\n          return false;\n        }\n        state = 2;\n\n        if (json->top > 0) {\n          Variant &top = json->stack[json->top].val;\n          /*<fb>*/\n          if (container_type == JSONContainerType::COLLECTIONS) {\n            top = req::make<c_Vector>();\n          } else if (container_type == JSONContainerType::HACK_ARRAYS) {\n            top = Array::CreateVec();\n          } else if (container_type == JSONContainerType::DARRAYS_AND_VARRAYS) {\n            top = Array::CreateVArray();\n          } else if (container_type == JSONContainerType::DARRAYS) {\n            top = Array::CreateDArray();\n          } else if (container_type == JSONContainerType::LEGACY_HACK_ARRAYS) {\n            auto arr = staticEmptyVecArray()->copy();\n            arr->setLegacyArray(true);\n            top = arr;\n          } else {\n            top = Array::CreateDArray();\n          }\n          /*</fb>*/\n          json->stack[json->top].key = copy_and_clear(*key);\n          reset_type();\n        }\n        break;\n        /*\n          ]\n        */\n      case -5:\n        {\n          if (type != kInvalidDataType &&\n               json->stack[json->top].mode == Mode::ARRAY) {\n            Variant mval;\n            json_create_zval(mval, *buf, type, options);\n            auto& top = json->stack[json->top].val;\n            if (container_type == JSONContainerType::COLLECTIONS) {\n              collections::append(top.getObjectData(), mval.asTypedValue());\n            } else {\n              top.asArrRef().append(mval);\n            }\n            buf->clear();\n            reset_type();\n          }\n\n          /*<fb>*/\n          if (json->top == 1) z = json->stack[json->top].val;\n          else {\n          /*</fb>*/\n            attach_zval(json, json->stack[json->top].key, assoc,\n              container_type);\n          /*<fb>*/\n          }\n          /*</fb>*/\n          if (!pop(json, Mode::ARRAY)) {\n            s_json_parser->error_code = JSON_ERROR_STATE_MISMATCH;\n            return false;\n          }\n          state = 9;\n        }\n        break;\n        /*\n          \"\n        */\n      case -4:\n        switch (json->stack[json->top].mode) {\n        case Mode::KEY:\n          state = 27;\n          std::swap(buf, key);\n          reset_type();\n          break;\n        case Mode::ARRAY:\n        case Mode::OBJECT:\n          state = 9;\n          break;\n        case Mode::DONE:\n          if (type == KindOfString) {\n            z = copy_and_clear(*buf);\n            state = 9;\n            break;\n          }\n          /* fall through if not KindOfString */\n        default:\n          s_json_parser->error_code = JSON_ERROR_SYNTAX;\n          return false;\n        }\n        break;\n        /*\n          ,\n        */\n      case -3:\n        {\n          Variant mval;\n          if (type != kInvalidDataType &&\n              (json->stack[json->top].mode == Mode::OBJECT ||\n               json->stack[json->top].mode == Mode::ARRAY)) {\n            json_create_zval(mval, *buf, type, options);\n          }\n\n          switch (json->stack[json->top].mode) {\n          case Mode::OBJECT:\n            if (pop(json, Mode::OBJECT) &&\n                push(json, Mode::KEY)) {\n              if (type != kInvalidDataType) {\n                Variant &top = json->stack[json->top].val;\n                object_set(\n                  json,\n                  top,\n                  copy_and_clear(*key),\n                  mval,\n                  assoc,\n                  container_type\n                );\n              }\n              state = 29;\n            }\n            break;\n          case Mode::ARRAY:\n            if (type != kInvalidDataType) {\n              auto& top = json->stack[json->top].val;\n              if (container_type == JSONContainerType::COLLECTIONS) {\n                collections::append(top.getObjectData(), mval.asTypedValue());\n              } else {\n                top.asArrRef().append(mval);\n              }\n            }\n            state = 28;\n            break;\n          default:\n            s_json_parser->error_code = JSON_ERROR_SYNTAX;\n            return false;\n          }\n          buf->clear();\n          reset_type();\n          check_non_safepoint_surprise();\n        }\n        break;\n\n        /*<fb>*/\n        /*\n          : (after unquoted string)\n        */\n      case -10:\n        if (json->stack[json->top].mode == Mode::KEY) {\n          state = 27;\n          std::swap(buf, key);\n          reset_type();\n          s = -2;\n        } else {\n          s = 3;\n          break;\n        }\n        /*</fb>*/\n\n        /*\n          :\n        */\n      case -2:\n        if (pop(json, Mode::KEY) && push(json, Mode::OBJECT)) {\n          state = 28;\n          break;\n        }\n        /*\n          syntax error\n        */\n      case -1:\n        s_json_parser->error_code = JSON_ERROR_SYNTAX;\n        return false;\n      }\n    } else {\n      /*\n        Change the state and iterate.\n      */\n      bool is_tsimplejson = options & k_JSON_FB_THRIFT_SIMPLE_JSON;\n      if (type == KindOfString) {\n        if (/*<fb>*/(/*</fb>*/s == 3/*<fb>*/ || s == 30)/*</fb>*/ &&\n            state != 8) {\n          if (state != 4) {\n            utf16_to_utf8(*buf, b);\n          } else {\n            switch (b) {\n            case 'b': buf->append('\\b'); break;\n            case 't': buf->append('\\t'); break;\n            case 'n': buf->append('\\n'); break;\n            case 'f': buf->append('\\f'); break;\n            case 'r': buf->append('\\r'); break;\n            default:\n              utf16_to_utf8(*buf, b);\n              break;\n            }\n          }\n        } else if (s == 6) {\n          if (UNLIKELY(is_tsimplejson)) {\n            if (UNLIKELY(b != '0'))  {\n              s_json_parser->error_code = JSON_ERROR_SYNTAX;\n              return false;\n            }\n            escaped_bytes = 0;\n          } else {\n            escaped_bytes = dehexchar(b) << 12;\n          }\n        } else if (s == 7) {\n          if (UNLIKELY(is_tsimplejson)) {\n            if (UNLIKELY(b != '0'))  {\n              s_json_parser->error_code = JSON_ERROR_SYNTAX;\n              return false;\n            }\n          } else {\n            escaped_bytes += dehexchar(b) << 8;\n          }\n        } else if (s == 8) {\n          escaped_bytes += dehexchar(b) << 4;\n        } else if (s == 3 && state == 8) {\n          escaped_bytes += dehexchar(b);\n          if (UNLIKELY(is_tsimplejson)) {\n            buf->append((char)escaped_bytes);\n          } else {\n            utf16_to_utf8(*buf, escaped_bytes);\n          }\n        }\n      } else if ((type == kInvalidDataType || type == KindOfNull) &&\n                 (c == S_DIG || c == S_ZER)) {\n        type = KindOfInt64;\n        buf->append((char)b);\n      } else if (type == KindOfInt64 && s == 24) {\n        type = KindOfDouble;\n        buf->append((char)b);\n      } else if ((type == kInvalidDataType || type == KindOfNull ||\n                  type == KindOfInt64) &&\n                 c == S_DOT) {\n        type = KindOfDouble;\n        buf->append((char)b);\n      } else if (type != KindOfString && c == S_QUO) {\n        type = KindOfString;\n        /*<fb>*/qchr = b;/*</fb>*/\n      } else if ((type == kInvalidDataType || type == KindOfNull ||\n                  type == KindOfInt64 || type == KindOfDouble) &&\n                 ((state == 12 && s == 9) ||\n                  (state == 16 && s == 9))) {\n        type = KindOfBoolean;\n      } else if (type == kInvalidDataType && state == 19 && s == 9) {\n        type = KindOfNull;\n      } else if (type != KindOfString && c > S_WSP) {\n        utf16_to_utf8(*buf, b);\n      }\n\n      state = s;\n    }\n  }\n\n  if (state == 9 && pop(json, Mode::DONE)) {\n    s_json_parser->error_code = JSON_ERROR_NONE;\n    return true;\n  }\n\n  s_json_parser->error_code = JSON_ERROR_SYNTAX;\n  return false;\n}",
        "func_hash": 279425347197289676453081001044103129987,
        "file_name": "JSON_parser.cpp",
        "file_hash": 153660966749897898132051442502557946400,
        "cwe": [
            "CWE-125"
        ],
        "cve": "CVE-2020-1892",
        "cve_desc": "Insufficient boundary checks when decoding JSON in JSON_parser allows read access to out of bounds memory, potentially leading to information leak and DOS. This issue affects HHVM 4.45.0, 4.44.0, 4.43.0, 4.42.0, 4.41.0, 4.40.0, 4.39.0, versions between 4.33.0 and 4.38.0 (inclusive), versions between 4.9.0 and 4.32.0 (inclusive), and versions prior to 4.8.7.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2020-1892",
        "func_name": "JSON_parser",
        "diff": [
            "diff --git a/hphp/runtime/ext/json/JSON_parser.cpp b/hphp/runtime/ext/json/JSON_parser.cpp\nindex b1b4f51b2e5dcf..5d3b3cfb25a2f1 100644\n--- a/hphp/runtime/ext/json/JSON_parser.cpp\n+++ b/hphp/runtime/ext/json/JSON_parser.cpp\n@@ -1148,6 +1148,10 @@ bool JSON_parser(Variant &z, const char *p, int length, bool const assoc,\n   // they exceed kMaxPersistentStringBufferCapacity at exit or if the thread\n   // is explicitly flushed (e.g., due to being idle).\n   json->initSb(length);\n+  if (depth <= 0) {\n+    json->error_code = json_error_codes::JSON_ERROR_DEPTH;\n+    return false;\n+  }\n   SCOPE_EXIT {\n     constexpr int kMaxPersistentStringBufferCapacity = 256 * 1024;\n     if (json->sb_cap > kMaxPersistentStringBufferCapacity) json->flushSb();\ndiff --git a/hphp/test/slow/ext_json/decode_crash.php b/hphp/test/slow/ext_json/decode_crash.php\nnew file mode 100644\nindex 00000000000000..9944145e454efe\n--- /dev/null\n+++ b/hphp/test/slow/ext_json/decode_crash.php\n@@ -0,0 +1,3 @@\n+<?hh\n+\n+var_dump(json_decode('\"a\"', false, 0, 0));\ndiff --git a/hphp/test/slow/ext_json/decode_crash.php.expect b/hphp/test/slow/ext_json/decode_crash.php.expect\nnew file mode 100644\nindex 00000000000000..7951defec192aa\n--- /dev/null\n+++ b/hphp/test/slow/ext_json/decode_crash.php.expect\n@@ -0,0 +1 @@\n+NULL\n"
        ],
        "func_after": []
    },
    {
        "idx": 195565,
        "project": "hhvm",
        "commit_id": "dbeb9a56a638e3fdcef8b691c2a2967132dae692",
        "project_url": "https://github.com/facebook/hhvm",
        "commit_url": "https://github.com/facebook/hhvm/commit/dbeb9a56a638e3fdcef8b691c2a2967132dae692",
        "commit_message": "string_number_format: Correctly handles return value of snprintf\n\nSummary: `snprintf` can return a value greater than the number of bytes copied. In case the first byte of the string is not a digit (could be '-'), size of `tmpstr` was being updated without checking `tmplen`. This resulted in either an assertion error or a heap overflow depending on whether the assertion is compiled or not.\n\nReviewed By: mofarrell, qianxuweiren\n\nDifferential Revision: D17327899\n\nfbshipit-source-id: ee53875d21e02608c6d870388eecf1464de24ff1",
        "target": 1,
        "irrelevant": 1,
        "func_before": "String string_number_format(double d, int dec,\n                            const String& dec_point,\n                            const String& thousand_sep) {\n  char *tmpbuf = nullptr, *resbuf;\n  char *s, *t;  /* source, target */\n  char *dp;\n  int integral;\n  int tmplen, reslen=0;\n  int count=0;\n  int is_negative=0;\n\n  if (d < 0) {\n    is_negative = 1;\n    d = -d;\n  }\n\n  if (dec < 0) dec = 0;\n  d = php_math_round(d, dec);\n\n  // departure from PHP: we got rid of dependencies on spprintf() here.\n  String tmpstr(63, ReserveString);\n  tmpbuf = tmpstr.mutableData();\n  tmplen = snprintf(tmpbuf, 64, \"%.*F\", dec, d);\n  if (tmplen < 0) return empty_string();\n  if (tmpbuf == nullptr || !isdigit((int)tmpbuf[0])) {\n    tmpstr.setSize(tmplen);\n    return tmpstr;\n  }\n  if (tmplen >= 64) {\n    // Uncommon, asked for more than 64 chars worth of precision\n    tmpstr = String(tmplen, ReserveString);\n    tmpbuf = tmpstr.mutableData();\n    tmplen = snprintf(tmpbuf, tmplen + 1, \"%.*F\", dec, d);\n    if (tmplen < 0) return empty_string();\n    if (tmpbuf == nullptr || !isdigit((int)tmpbuf[0])) {\n      tmpstr.setSize(tmplen);\n      return tmpstr;\n    }\n  }\n\n  /* find decimal point, if expected */\n  if (dec) {\n    dp = strpbrk(tmpbuf, \".,\");\n  } else {\n    dp = nullptr;\n  }\n\n  /* calculate the length of the return buffer */\n  if (dp) {\n    integral = dp - tmpbuf;\n  } else {\n    /* no decimal point was found */\n    integral = tmplen;\n  }\n\n  /* allow for thousand separators */\n  if (!thousand_sep.empty()) {\n    if (integral + thousand_sep.size() * ((integral-1) / 3) < integral) {\n      /* overflow */\n      raise_error(\"String overflow\");\n    }\n\n    integral += ((integral-1) / 3) * thousand_sep.size();\n  }\n\n  reslen = integral;\n\n  if (dec) {\n    reslen += dec;\n\n    if (!dec_point.empty()) {\n      if (reslen + dec_point.size() < dec_point.size()) {\n        /* overflow */\n        raise_error(\"String overflow\");\n      }\n      reslen += dec_point.size();\n    }\n  }\n\n  /* add a byte for minus sign */\n  if (is_negative) {\n    reslen++;\n  }\n  String resstr(reslen, ReserveString);\n  resbuf = resstr.mutableData();\n\n  s = tmpbuf+tmplen-1;\n  t = resbuf+reslen-1;\n\n  /* copy the decimal places.\n   * Take care, as the sprintf implementation may return less places than\n   * we requested due to internal buffer limitations */\n  if (dec) {\n    int declen = dp ? s - dp : 0;\n    int topad = dec > declen ? dec - declen : 0;\n\n    /* pad with '0's */\n    while (topad--) {\n      *t-- = '0';\n    }\n\n    if (dp) {\n      s -= declen + 1; /* +1 to skip the point */\n      t -= declen;\n\n      /* now copy the chars after the point */\n      memcpy(t + 1, dp + 1, declen);\n    }\n\n    /* add decimal point */\n    if (!dec_point.empty()) {\n      memcpy(t + (1 - dec_point.size()), dec_point.data(), dec_point.size());\n      t -= dec_point.size();\n    }\n  }\n\n  /* copy the numbers before the decimal point, adding thousand\n   * separator every three digits */\n  while(s >= tmpbuf) {\n    *t-- = *s--;\n    if (thousand_sep && (++count%3)==0 && s>=tmpbuf) {\n      memcpy(t + (1 - thousand_sep.size()),\n             thousand_sep.data(),\n             thousand_sep.size());\n      t -= thousand_sep.size();\n    }\n  }\n\n  /* and a minus sign, if needed */\n  if (is_negative) {\n    *t-- = '-';\n  }\n\n  resstr.setSize(reslen);\n  return resstr;\n}",
        "func_hash": 125018652199743804521817207176944376682,
        "file_name": "zend-string.cpp",
        "file_hash": 157727558891612041764030573186624095506,
        "cwe": [
            "CWE-119"
        ],
        "cve": "CVE-2019-11929",
        "cve_desc": "Insufficient boundary checks when formatting numbers in number_format allows read/write access to out-of-bounds memory, potentially leading to remote code execution. This issue affects HHVM versions prior to 3.30.10, all versions between 4.0.0 and 4.8.5, all versions between 4.9.0 and 4.18.2, and versions 4.19.0, 4.19.1, 4.20.0, 4.20.1, 4.20.2, 4.21.0, 4.22.0, 4.23.0.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2019-11929",
        "func_name": "string_number_format",
        "diff": [
            "diff --git a/hphp/runtime/base/zend-string.cpp b/hphp/runtime/base/zend-string.cpp\nindex 8a5ec8933691be..7caef317c51fdf 100644\n--- a/hphp/runtime/base/zend-string.cpp\n+++ b/hphp/runtime/base/zend-string.cpp\n@@ -1618,11 +1618,15 @@ String string_number_format(double d, int dec,\n   d = php_math_round(d, dec);\n \n   // departure from PHP: we got rid of dependencies on spprintf() here.\n+  // This actually means 63 bytes for characters + 1 byte for '\\0'\n   String tmpstr(63, ReserveString);\n   tmpbuf = tmpstr.mutableData();\n   tmplen = snprintf(tmpbuf, 64, \"%.*F\", dec, d);\n+  // From the man page of snprintf, the return value is:\n+  // The number of characters that would have been written if n had been\n+  // sufficiently large, not counting the terminating null character.\n   if (tmplen < 0) return empty_string();\n-  if (tmpbuf == nullptr || !isdigit((int)tmpbuf[0])) {\n+  if (tmplen < 64 && (tmpbuf == nullptr || !isdigit((int)tmpbuf[0]))) {\n     tmpstr.setSize(tmplen);\n     return tmpstr;\n   }\ndiff --git a/hphp/test/slow/string/number_format_t53795309.php b/hphp/test/slow/string/number_format_t53795309.php\nnew file mode 100644\nindex 00000000000000..c6fee71a722f01\n--- /dev/null\n+++ b/hphp/test/slow/string/number_format_t53795309.php\n@@ -0,0 +1,9 @@\n+<?hh\n+// Copyright 2004-present Facebook. All Rights Reserved.\n+\n+<<__EntryPoint>>\n+function main() {\n+  $bin_repr = \"\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x80\";\n+  $double_num = unpack(\"dnum\", $bin_repr)['num'];\n+  var_dump(number_format($double_num, 100));\n+}\ndiff --git a/hphp/test/slow/string/number_format_t53795309.php.expect b/hphp/test/slow/string/number_format_t53795309.php.expect\nnew file mode 100644\nindex 00000000000000..f4417f7682bb5d\n--- /dev/null\n+++ b/hphp/test/slow/string/number_format_t53795309.php.expect\n@@ -0,0 +1 @@\n+string(103) \"-0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\"\n"
        ],
        "func_after": []
    },
    {
        "idx": 195626,
        "project": "qemu",
        "commit_id": "7882080388be5088e72c425b02223c02e6cb4295",
        "project_url": "https://github.com/bonzini/qemu",
        "commit_url": "https://github.com/qemu/qemu/commit/7882080388be5088e72c425b02223c02e6cb4295",
        "commit_message": "virtio-serial: fix ANY_LAYOUT\n\nDon't assume a specific layout for control messages.\nRequired by virtio 1.\n\nSigned-off-by: Michael S. Tsirkin <mst@redhat.com>\nReviewed-by: Amit Shah <amit.shah@redhat.com>\nReviewed-by: Jason Wang <jasowang@redhat.com>",
        "target": 1,
        "irrelevant": 1,
        "func_before": "static size_t send_control_msg(VirtIOSerial *vser, void *buf, size_t len)\n{\n    VirtQueueElement elem;\n    VirtQueue *vq;\n\n    vq = vser->c_ivq;\n    if (!virtio_queue_ready(vq)) {\n        return 0;\n    }\n    if (!virtqueue_pop(vq, &elem)) {\n        return 0;\n    }\n\n    memcpy(elem.in_sg[0].iov_base, buf, len);\n\n    virtqueue_push(vq, &elem, len);\n    virtio_notify(VIRTIO_DEVICE(vser), vq);\n    return len;\n}",
        "func_hash": 301712778748262907171467771526276497164,
        "file_name": "virtio-serial-bus.c",
        "file_hash": 253157734411856913752064284433381457044,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2015-5745",
        "cve_desc": "Buffer overflow in the send_control_msg function in hw/char/virtio-serial-bus.c in QEMU before 2.4.0 allows guest users to cause a denial of service (QEMU process crash) via a crafted virtio control message.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2015-5745",
        "func_name": "send_control_msg",
        "diff": [
            "diff --git a/hw/char/virtio-serial-bus.c b/hw/char/virtio-serial-bus.c\nindex 78c73e5abe01..929e49c67165 100644\n--- a/hw/char/virtio-serial-bus.c\n+++ b/hw/char/virtio-serial-bus.c\n@@ -195,7 +195,8 @@ static size_t send_control_msg(VirtIOSerial *vser, void *buf, size_t len)\n         return 0;\n     }\n \n-    memcpy(elem.in_sg[0].iov_base, buf, len);\n+    /* TODO: detect a buffer that's too short, set NEEDS_RESET */\n+    iov_from_buf(elem.in_sg, elem.in_num, 0, buf, len);\n \n     virtqueue_push(vq, &elem, len);\n     virtio_notify(VIRTIO_DEVICE(vser), vq);\n"
        ],
        "func_after": []
    },
    {
        "idx": 195629,
        "project": "tensorflow",
        "commit_id": "a5b89cd68c02329d793356bda85d079e9e69b4e7",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/a5b89cd68c02329d793356bda85d079e9e69b4e7",
        "commit_message": "Fix empty resource handle vulnerability.\n\nSome ops that attempt to extract a resource handle from user input\ncan lead to nullptr dereferences.  This returns an error in such\na case.\n\nPiperOrigin-RevId: 445571938",
        "target": 1,
        "irrelevant": 1,
        "func_before": "Status GetDeviceForInput(const EagerOperation& op, const EagerContext& ctx,\n                         TensorHandle* tensor_handle, Device** result) {\n  Device* cpu_device = ctx.HostCPU();\n  string device_name;\n  if (tensor_handle->Type() != TensorHandle::LOCAL) {\n    Device* device = tensor_handle->device();\n    device_name = device != nullptr ? device->name() : cpu_device->name();\n    *result = (device == nullptr ? cpu_device : device);\n  } else if (tensor_handle->dtype == DT_RESOURCE) {\n    // Use the resource's actual device because it is the device that will\n    // influence partitioning the multi-device function.\n    const Tensor* tensor;\n    // TODO(fishx): Avoid blocking here.\n    TF_RETURN_IF_ERROR(tensor_handle->Tensor(&tensor));\n    const ResourceHandle& handle = tensor->flat<ResourceHandle>()(0);\n    device_name = handle.device();\n\n    Device* input_device;\n    TF_RETURN_IF_ERROR(\n        ctx.FindDeviceFromName(device_name.c_str(), &input_device));\n    *result = input_device;\n  } else {\n    Device* device = tensor_handle->device();\n    const bool is_tpu = device != nullptr && device->device_type() == \"TPU\";\n    // int32 return values can be placed on TPUs.\n    const bool use_host_memory =\n        is_tpu ? MTypeFromDTypeIntsOnDevice(tensor_handle->dtype)\n               : MTypeFromDType(tensor_handle->dtype);\n    if (use_host_memory) {\n      *result = cpu_device;\n    } else {\n      // Eager ops executing as functions should have their preferred inputs set\n      // to the op's device. This allows us to avoid expensive D2H copies if a\n      // mirror of the tensor already exists on the op's device.\n      if (!op.is_function() && device != nullptr && device != cpu_device) {\n        device = absl::get<Device*>(op.Device());\n      }\n      *result = (device == nullptr ? cpu_device : device);\n    }\n  }\n  return Status::OK();\n}",
        "func_hash": 227007805370541421392187811352073944672,
        "file_name": "execute.cc",
        "file_hash": 250138698264718373642663717664797527317,
        "cwe": [
            "CWE-476"
        ],
        "cve": "CVE-2022-29207",
        "cve_desc": "TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, multiple TensorFlow operations misbehave in eager mode when the resource handle provided to them is invalid. In graph mode, it would have been impossible to perform these API calls, but migration to TF 2.x eager mode opened up this vulnerability. If the resource handle is empty, then a reference is bound to a null pointer inside TensorFlow codebase (various codepaths). This is undefined behavior. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-29207",
        "func_name": "GetDeviceForInput",
        "diff": [
            "diff --git a/tensorflow/core/common_runtime/eager/execute.cc b/tensorflow/core/common_runtime/eager/execute.cc\nindex dd64174a4ddeff..904996c7e64652 100644\n--- a/tensorflow/core/common_runtime/eager/execute.cc\n+++ b/tensorflow/core/common_runtime/eager/execute.cc\n@@ -304,6 +304,9 @@ Status GetDeviceForInput(const EagerOperation& op, const EagerContext& ctx,\n     const Tensor* tensor;\n     // TODO(fishx): Avoid blocking here.\n     TF_RETURN_IF_ERROR(tensor_handle->Tensor(&tensor));\n+    if (tensor->NumElements() == 0) {\n+      return errors::InvalidArgument(\"Empty resource handle\");\n+    }\n     const ResourceHandle& handle = tensor->flat<ResourceHandle>()(0);\n     device_name = handle.device();\n \n"
        ],
        "func_after": []
    },
    {
        "idx": 195665,
        "project": "njs",
        "commit_id": "2e00e95473861846aa8538be87db07699d9f676d",
        "project_url": "https://github.com/nginx/njs",
        "commit_url": "https://github.com/nginx/njs/commit/2e00e95473861846aa8538be87db07699d9f676d",
        "commit_message": "Fixed Array.prototype.slice() with slow \"this\" argument.\n\nPreviously, when \"this\" argument was not a fast array, but the \"deleted\" array\nwas a fast array, the \"deleted\" array may be left in uninitialized state if\n\"this\" argument had gaps.\n\nThis fix is to ensure that \"deleted\" is properly initialized.\n\nThis fixes #485 issue on Github.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "njs_array_prototype_splice(njs_vm_t *vm, njs_value_t *args, njs_uint_t nargs,\n    njs_index_t unused)\n{\n    int64_t      i, n, start, length, items, delta, delete;\n    njs_int_t    ret;\n    njs_value_t  *this, value, del_object;\n    njs_array_t  *array, *deleted;\n\n    this = njs_argument(args, 0);\n\n    ret = njs_value_to_object(vm, this);\n    if (njs_slow_path(ret != NJS_OK)) {\n        return ret;\n    }\n\n    ret = njs_object_length(vm, this, &length);\n    if (njs_slow_path(ret == NJS_ERROR)) {\n        return ret;\n    }\n\n    ret = njs_value_to_integer(vm, njs_arg(args, nargs, 1), &start);\n    if (njs_slow_path(ret != NJS_OK)) {\n        return ret;\n    }\n\n    start = (start < 0) ? njs_max(length + start, 0) : njs_min(start, length);\n\n    items = 0;\n    delete = 0;\n\n    if (nargs == 2) {\n        delete = length - start;\n\n    } else if (nargs > 2) {\n        items = nargs - 3;\n\n        ret = njs_value_to_integer(vm, njs_arg(args, nargs, 2), &delete);\n        if (njs_slow_path(ret != NJS_OK)) {\n            return ret;\n        }\n\n        delete = njs_min(njs_max(delete, 0), length - start);\n    }\n\n    delta = items - delete;\n\n    if (njs_slow_path((length + delta) > NJS_MAX_LENGTH)) {\n        njs_type_error(vm, \"Invalid length\");\n        return NJS_ERROR;\n    }\n\n    /* TODO: ArraySpeciesCreate(). */\n\n    deleted = njs_array_alloc(vm, 0, delete, 0);\n    if (njs_slow_path(deleted == NULL)) {\n        return NJS_ERROR;\n    }\n\n    if (njs_fast_path(njs_is_fast_array(this) && deleted->object.fast_array)) {\n        array = njs_array(this);\n        for (i = 0, n = start; i < delete; i++, n++) {\n            deleted->start[i] = array->start[n];\n        }\n\n    } else {\n        njs_set_array(&del_object, deleted);\n\n        for (i = 0, n = start; i < delete; i++, n++) {\n            ret = njs_value_property_i64(vm, this, n, &value);\n            if (njs_slow_path(ret == NJS_ERROR)) {\n                return NJS_ERROR;\n            }\n\n            if (ret == NJS_OK) {\n                /* TODO:  CreateDataPropertyOrThrow(). */\n                ret = njs_value_property_i64_set(vm, &del_object, i, &value);\n                if (njs_slow_path(ret == NJS_ERROR)) {\n                    return ret;\n                }\n            }\n        }\n\n        ret = njs_object_length_set(vm, &del_object, delete);\n        if (njs_slow_path(ret != NJS_OK)) {\n            return NJS_ERROR;\n        }\n    }\n\n    if (njs_fast_path(njs_is_fast_array(this))) {\n        array = njs_array(this);\n\n        if (delta != 0) {\n            /*\n             * Relocate the rest of items.\n             * Index of the first item is in \"n\".\n             */\n            if (delta > 0) {\n                ret = njs_array_expand(vm, array, 0, delta);\n                if (njs_slow_path(ret != NJS_OK)) {\n                    return ret;\n                }\n            }\n\n            ret = njs_array_copy_within(vm, this, start + items, start + delete,\n                                        array->length - (start + delete), 0);\n            if (njs_slow_path(ret != NJS_OK)) {\n                return ret;\n            }\n\n            array->length += delta;\n        }\n\n        /* Copy new items. */\n\n        if (items > 0) {\n            memcpy(&array->start[start], &args[3],\n                   items * sizeof(njs_value_t));\n        }\n\n    } else {\n\n       if (delta != 0) {\n           ret = njs_array_copy_within(vm, this, start + items, start + delete,\n                                       length - (start + delete), delta < 0);\n            if (njs_slow_path(ret != NJS_OK)) {\n                return ret;\n            }\n\n            for (i = length - 1; i >= length + delta; i--) {\n                ret = njs_value_property_i64_delete(vm, this, i, NULL);\n                if (njs_slow_path(ret == NJS_ERROR)) {\n                    return NJS_ERROR;\n                }\n            }\n       }\n\n        /* Copy new items. */\n\n        for (i = 3, n = start; items-- > 0; i++, n++) {\n            ret = njs_value_property_i64_set(vm, this, n, &args[i]);\n            if (njs_slow_path(ret == NJS_ERROR)) {\n                return NJS_ERROR;\n            }\n        }\n\n        ret = njs_object_length_set(vm, this, length + delta);\n        if (njs_slow_path(ret != NJS_OK)) {\n            return NJS_ERROR;\n        }\n    }\n\n    njs_set_array(&vm->retval, deleted);\n\n    return NJS_OK;\n}",
        "func_hash": 41889957200154277256182614621042854713,
        "file_name": "njs_array.c",
        "file_hash": 27861953644579332654826088207600556930,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2022-29779",
        "cve_desc": "Nginx NJS v0.7.2 was discovered to contain a segmentation violation in the function njs_value_own_enumerate at src/njs_value.c.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-29779",
        "func_name": "njs_array_prototype_splice",
        "diff": [
            "diff --git a/src/njs_array.c b/src/njs_array.c\nindex 0b8c7b919..2ceb6be7e 100644\n--- a/src/njs_array.c\n+++ b/src/njs_array.c\n@@ -1284,6 +1284,11 @@ njs_array_prototype_splice(njs_vm_t *vm, njs_value_t *args, njs_uint_t nargs,\n                 if (njs_slow_path(ret == NJS_ERROR)) {\n                     return ret;\n                 }\n+\n+            } else {\n+                if (deleted->object.fast_array) {\n+                    njs_set_invalid(&deleted->start[i]);\n+                }\n             }\n         }\n \ndiff --git a/src/test/njs_unit_test.c b/src/test/njs_unit_test.c\nindex 25e066c32..b28e34fef 100644\n--- a/src/test/njs_unit_test.c\n+++ b/src/test/njs_unit_test.c\n@@ -4869,6 +4869,15 @@ static njs_unit_test_t  njs_test[] =\n               \"Array.prototype.splice.call(obj, 2**53-2, 0, 'C');\"),\n       njs_str(\"TypeError: Invalid length\") },\n \n+    { njs_str(\"var a = {1: 'B', length: 2};\"\n+              \"Array.prototype.splice.call(a, 0)\"),\n+      njs_str(\",B\") },\n+\n+    { njs_str(\"var a = new Uint8Array();\"\n+              \"a.__proto__ = [1,2,3];\"\n+              \"a.splice(0)\"),\n+      njs_str(\",,\") },\n+\n     { njs_str(\"var a = []; a.reverse()\"),\n       njs_str(\"\") },\n \n"
        ],
        "func_after": []
    },
    {
        "idx": 195668,
        "project": "mruby",
        "commit_id": "38b164ace7d6ae1c367883a3d67d7f559783faad",
        "project_url": "https://github.com/mruby/mruby",
        "commit_url": "https://github.com/mruby/mruby/commit/38b164ace7d6ae1c367883a3d67d7f559783faad",
        "commit_message": "codegen.c: fix a bug in `gen_values()`.\n\n- Fix limit handling that fails 15 arguments method calls.\n- Fix too early argument packing in arrays.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "gen_values(codegen_scope *s, node *t, int val, int limit)\n{\n  int n = 0;\n  int first = 1;\n  int slimit = GEN_VAL_STACK_MAX;\n\n  if (limit == 0) limit = GEN_LIT_ARY_MAX;\n  if (cursp() >= slimit) slimit = INT16_MAX;\n\n  if (!val) {\n    while (t) {\n      codegen(s, t->car, NOVAL);\n      n++;\n      t = t->cdr;\n    }\n    return n;\n  }\n\n  while (t) {\n    int is_splat = nint(t->car->car) == NODE_SPLAT;\n\n    if (is_splat || n > limit || cursp() >= slimit) { /* flush stack */\n      pop_n(n);\n      if (first) {\n        if (n == 0) {\n          genop_1(s, OP_LOADNIL, cursp());\n        }\n        else {\n          genop_2(s, OP_ARRAY, cursp(), n);\n        }\n        push();\n        first = 0;\n        limit = GEN_LIT_ARY_MAX;\n      }\n      else if (n > 0) {\n        pop();\n        genop_2(s, OP_ARYPUSH, cursp(), n);\n        push();\n      }\n      n = 0;\n    }\n    codegen(s, t->car, val);\n    if (is_splat) {\n      pop(); pop();\n      genop_1(s, OP_ARYCAT, cursp());\n      push();\n    }\n    else {\n      n++;\n    }\n    t = t->cdr;\n  }\n  if (!first) {\n    pop();\n    if (n > 0) {\n      pop_n(n);\n      genop_2(s, OP_ARYPUSH, cursp(), n);\n    }\n    return -1;                  /* variable length */\n  }\n  return n;\n}",
        "func_hash": 322425551847944018477435186419959863555,
        "file_name": "codegen.c",
        "file_hash": 88374800173229199956653339408236459963,
        "cwe": [
            "CWE-415"
        ],
        "cve": "CVE-2022-0570",
        "cve_desc": "Heap-based Buffer Overflow in Homebrew mruby prior to 3.2.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-0570",
        "func_name": "gen_values",
        "diff": [
            "diff --git a/mrbgems/mruby-compiler/core/codegen.c b/mrbgems/mruby-compiler/core/codegen.c\nindex c49ea75141..b90eae3e85 100644\n--- a/mrbgems/mruby-compiler/core/codegen.c\n+++ b/mrbgems/mruby-compiler/core/codegen.c\n@@ -1551,7 +1551,7 @@ gen_values(codegen_scope *s, node *t, int val, int limit)\n   while (t) {\n     int is_splat = nint(t->car->car) == NODE_SPLAT;\n \n-    if (is_splat || n > limit || cursp() >= slimit) { /* flush stack */\n+    if (is_splat || cursp() >= slimit) { /* flush stack */\n       pop_n(n);\n       if (first) {\n         if (n == 0) {\n@@ -1590,6 +1590,11 @@ gen_values(codegen_scope *s, node *t, int val, int limit)\n     }\n     return -1;                  /* variable length */\n   }\n+  else if (n > limit) {\n+    pop_n(n);\n+    genop_2(s, OP_ARRAY, cursp(), n);\n+    return -1;\n+  }\n   return n;\n }\n \n"
        ],
        "func_after": []
    },
    {
        "idx": 195670,
        "project": "pjproject",
        "commit_id": "856f87c2e97a27b256482dbe0d748b1194355a21",
        "project_url": "https://github.com/pjsip/pjproject",
        "commit_url": "https://github.com/pjsip/pjproject/commit/856f87c2e97a27b256482dbe0d748b1194355a21",
        "commit_message": "Merge pull request from GHSA-5x45-qp78-g4p4\n\n* Prevent infinite loop in scanning xml content\n\n* Simplify scanning method\n\n* Optimization",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static pj_xml_node *xml_parse_node( pj_pool_t *pool, pj_scanner *scanner)\n{\n    pj_xml_node *node;\n    pj_str_t end_name;\n\n    PJ_CHECK_STACK();\n\n    if (*scanner->curptr != '<')\n\ton_syntax_error(scanner);\n\n    /* Handle Processing Instructino (PI) construct (i.e. \"<?\") */\n    if (*scanner->curptr == '<' && *(scanner->curptr+1) == '?') {\n\tpj_scan_advance_n(scanner, 2, PJ_FALSE);\n\tfor (;;) {\n\t    pj_str_t dummy;\n\t    pj_scan_get_until_ch(scanner, '?', &dummy);\n\t    if (*scanner->curptr=='?' && *(scanner->curptr+1)=='>') {\n\t\tpj_scan_advance_n(scanner, 2, PJ_TRUE);\n\t\tbreak;\n\t    } else {\n\t\tpj_scan_advance_n(scanner, 1, PJ_FALSE);\n\t    }\n\t}\n\treturn xml_parse_node(pool, scanner);\n    }\n\n    /* Handle comments construct (i.e. \"<!\") */\n    if (pj_scan_strcmp(scanner, \"<!\", 2) == 0) {\n\tpj_scan_advance_n(scanner, 2, PJ_FALSE);\n\tfor (;;) {\n\t    pj_str_t dummy;\n\t    pj_scan_get_until_ch(scanner, '>', &dummy);\n\t    if (pj_scan_strcmp(scanner, \">\", 1) == 0) {\n\t\tpj_scan_advance_n(scanner, 1, PJ_TRUE);\n\t\tbreak;\n\t    } else {\n\t\tpj_scan_advance_n(scanner, 1, PJ_FALSE);\n\t    }\n\t}\n\treturn xml_parse_node(pool, scanner);\n    }\n\n    /* Alloc node. */\n    node = alloc_node(pool);\n\n    /* Get '<' */\n    pj_scan_get_char(scanner);\n\n    /* Get node name. */\n    pj_scan_get_until_chr( scanner, \" />\\t\\r\\n\", &node->name);\n\n    /* Get attributes. */\n    while (*scanner->curptr != '>' && *scanner->curptr != '/') {\n\tpj_xml_attr *attr = alloc_attr(pool);\n\t\n\tpj_scan_get_until_chr( scanner, \"=> \\t\\r\\n\", &attr->name);\n\tif (*scanner->curptr == '=') {\n\t    pj_scan_get_char( scanner );\n            pj_scan_get_quotes(scanner, \"\\\"'\", \"\\\"'\", 2, &attr->value);\n\t    /* remove quote characters */\n\t    ++attr->value.ptr;\n\t    attr->value.slen -= 2;\n\t}\n\t\n\tpj_list_push_back( &node->attr_head, attr );\n    }\n\n    if (*scanner->curptr == '/') {\n\tpj_scan_get_char(scanner);\n\tif (pj_scan_get_char(scanner) != '>')\n\t    on_syntax_error(scanner);\n\treturn node;\n    }\n\n    /* Enclosing bracket. */\n    if (pj_scan_get_char(scanner) != '>')\n\ton_syntax_error(scanner);\n\n    /* Sub nodes. */\n    while (*scanner->curptr == '<' && *(scanner->curptr+1) != '/'\n\t\t\t\t   && *(scanner->curptr+1) != '!')\n    {\n\tpj_xml_node *sub_node = xml_parse_node(pool, scanner);\n\tpj_list_push_back( &node->node_head, sub_node );\n    }\n\n    /* Content. */\n    if (!pj_scan_is_eof(scanner) && *scanner->curptr != '<') {\n\tpj_scan_get_until_ch(scanner, '<', &node->content);\n    }\n\n    /* CDATA content. */\n    if (*scanner->curptr == '<' && *(scanner->curptr+1) == '!' &&\n\tpj_scan_strcmp(scanner, \"<![CDATA[\", 9) == 0)\n    {\n\tpj_scan_advance_n(scanner, 9, PJ_FALSE);\n\tpj_scan_get_until_ch(scanner, ']', &node->content);\n\twhile (pj_scan_strcmp(scanner, \"]]>\", 3)) {\n\t    pj_str_t dummy;\n\t    pj_scan_get_until_ch(scanner, ']', &dummy);\n\t}\n\tnode->content.slen = scanner->curptr - node->content.ptr;\n\tpj_scan_advance_n(scanner, 3, PJ_TRUE);\n    }\n\n    /* Enclosing node. */\n    if (pj_scan_get_char(scanner) != '<' || pj_scan_get_char(scanner) != '/')\n\ton_syntax_error(scanner);\n\n    pj_scan_get_until_chr(scanner, \" \\t>\", &end_name);\n\n    /* Compare name. */\n    if (pj_stricmp(&node->name, &end_name) != 0)\n\ton_syntax_error(scanner);\n\n    /* Enclosing '>' */\n    if (pj_scan_get_char(scanner) != '>')\n\ton_syntax_error(scanner);\n\n    return node;\n}",
        "func_hash": 277240174945375908655928995975016589842,
        "file_name": "xml.c",
        "file_hash": 319030018310003515806173873266013713455,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2022-24763",
        "cve_desc": "PJSIP is a free and open source multimedia communication library written in the C language. Versions 2.12 and prior contain a denial-of-service vulnerability that affects PJSIP users that consume PJSIP's XML parsing in their apps. Users are advised to update. There are no known workarounds.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-24763",
        "func_name": "xml_parse_node",
        "diff": [
            "diff --git a/pjlib-util/src/pjlib-util/xml.c b/pjlib-util/src/pjlib-util/xml.c\nindex b0aad26608..5c2d8eb174 100644\n--- a/pjlib-util/src/pjlib-util/xml.c\n+++ b/pjlib-util/src/pjlib-util/xml.c\n@@ -150,6 +150,8 @@ static pj_xml_node *xml_parse_node( pj_pool_t *pool, pj_scanner *scanner)\n \tpj_scan_get_until_ch(scanner, ']', &node->content);\n \twhile (pj_scan_strcmp(scanner, \"]]>\", 3)) {\n \t    pj_str_t dummy;\n+\n+\t    pj_scan_advance_n(scanner, 1, PJ_FALSE);\n \t    pj_scan_get_until_ch(scanner, ']', &dummy);\n \t}\n \tnode->content.slen = scanner->curptr - node->content.ptr;\n"
        ],
        "func_after": []
    },
    {
        "idx": 196889,
        "project": "rpm",
        "commit_id": "bd36c5dc9fb6d90c46fbfed8c2d67516fc571ec8",
        "project_url": "https://github.com/rpm-software-management/rpm",
        "commit_url": "https://github.com/rpm-software-management/rpm/commit/bd36c5dc9fb6d90c46fbfed8c2d67516fc571ec8",
        "commit_message": "Validate and require subkey binding signatures on PGP public keys\n\nAll subkeys must be followed by a binding signature by the primary key\nas per the OpenPGP RFC, enforce the presence and validity in the parser.\n\nThe implementation is as kludgey as they come to work around our\nsimple-minded parser structure without touching API, to maximise\nbackportability. Store all the raw packets internally as we decode them\nto be able to access previous elements at will, needed to validate ordering\nand access the actual data. Add testcases for manipulated keys whose\nimport previously would succeed.\n\nDepends on the two previous commits:\n7b399fcb8f52566e6f3b4327197a85facd08db91 and\n236b802a4aa48711823a191d1b7f753c82a89ec5\n\nFixes CVE-2021-3521.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "int pgpPrtParams(const uint8_t * pkts, size_t pktlen, unsigned int pkttype,\n\t\t pgpDigParams * ret)\n{\n    const uint8_t *p = pkts;\n    const uint8_t *pend = pkts + pktlen;\n    pgpDigParams digp = NULL;\n    struct pgpPkt pkt;\n    int rc = -1; /* assume failure */\n\n    while (p < pend) {\n\tif (decodePkt(p, (pend - p), &pkt))\n\t    break;\n\n\tif (digp == NULL) {\n\t    if (pkttype && pkt.tag != pkttype) {\n\t\tbreak;\n\t    } else {\n\t\tdigp = pgpDigParamsNew(pkt.tag);\n\t    }\n\t}\n\n\tif (pgpPrtPkt(&pkt, digp))\n\t    break;\n\n\tp += (pkt.body - pkt.head) + pkt.blen;\n\tif (pkttype == PGPTAG_SIGNATURE)\n\t    break;\n    }\n\n    rc = (digp && (p == pend)) ? 0 : -1;\n\n    if (ret && rc == 0) {\n\t*ret = digp;\n    } else {\n\tpgpDigParamsFree(digp);\n    }\n    return rc;\n}",
        "func_hash": 241902861702092358566393446057169117418,
        "file_name": "rpmpgp.c",
        "file_hash": 261680371397829724328332349939648686474,
        "cwe": [
            "CWE-284"
        ],
        "cve": "CVE-2021-3521",
        "cve_desc": "There is a flaw in RPM's signature functionality. OpenPGP subkeys are associated with a primary key via a \"binding signature.\" RPM does not check the binding signature of subkeys prior to importing them. If an attacker is able to add or socially engineer another party to add a malicious subkey to a legitimate public key, RPM could wrongly trust a malicious signature. The greatest impact of this flaw is to data integrity. To exploit this flaw, an attacker must either compromise an RPM repository or convince an administrator to install an untrusted RPM or public key. It is strongly recommended to only use RPMs and public keys from trusted sources.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-3521",
        "func_name": "pgpPrtParams",
        "diff": [
            "diff --git a/rpmio/rpmpgp.c b/rpmio/rpmpgp.c\nindex aad7c275c9..d70802ae86 100644\n--- a/rpmio/rpmpgp.c\n+++ b/rpmio/rpmpgp.c\n@@ -1062,37 +1062,121 @@ static pgpDigParams pgpDigParamsNew(uint8_t tag)\n     return digp;\n }\n \n+static int hashKey(DIGEST_CTX hash, const struct pgpPkt *pkt, int exptag)\n+{\n+    int rc = -1;\n+    if (pkt->tag == exptag) {\n+\tuint8_t head[] = {\n+\t    0x99,\n+\t    (pkt->blen >> 8),\n+\t    (pkt->blen     ),\n+\t};\n+\n+\trpmDigestUpdate(hash, head, 3);\n+\trpmDigestUpdate(hash, pkt->body, pkt->blen);\n+\trc = 0;\n+    }\n+    return rc;\n+}\n+\n+static int pgpVerifySelf(pgpDigParams key, pgpDigParams selfsig,\n+\t\t\tconst struct pgpPkt *all, int i)\n+{\n+    int rc = -1;\n+    DIGEST_CTX hash = NULL;\n+\n+    switch (selfsig->sigtype) {\n+    case PGPSIGTYPE_SUBKEY_BINDING:\n+\thash = rpmDigestInit(selfsig->hash_algo, 0);\n+\tif (hash) {\n+\t    rc = hashKey(hash, &all[0], PGPTAG_PUBLIC_KEY);\n+\t    if (!rc)\n+\t\trc = hashKey(hash, &all[i-1], PGPTAG_PUBLIC_SUBKEY);\n+\t}\n+\tbreak;\n+    default:\n+\t/* ignore types we can't handle */\n+\trc = 0;\n+\tbreak;\n+    }\n+\n+    if (hash && rc == 0)\n+\trc = pgpVerifySignature(key, selfsig, hash);\n+\n+    rpmDigestFinal(hash, NULL, NULL, 0);\n+\n+    return rc;\n+}\n+\n int pgpPrtParams(const uint8_t * pkts, size_t pktlen, unsigned int pkttype,\n \t\t pgpDigParams * ret)\n {\n     const uint8_t *p = pkts;\n     const uint8_t *pend = pkts + pktlen;\n     pgpDigParams digp = NULL;\n-    struct pgpPkt pkt;\n+    pgpDigParams selfsig = NULL;\n+    int i = 0;\n+    int alloced = 16; /* plenty for normal cases */\n+    struct pgpPkt *all = xmalloc(alloced * sizeof(*all));\n     int rc = -1; /* assume failure */\n+    int expect = 0;\n+    int prevtag = 0;\n \n     while (p < pend) {\n-\tif (decodePkt(p, (pend - p), &pkt))\n+\tstruct pgpPkt *pkt = &all[i];\n+\tif (decodePkt(p, (pend - p), pkt))\n \t    break;\n \n \tif (digp == NULL) {\n-\t    if (pkttype && pkt.tag != pkttype) {\n+\t    if (pkttype && pkt->tag != pkttype) {\n \t\tbreak;\n \t    } else {\n-\t\tdigp = pgpDigParamsNew(pkt.tag);\n+\t\tdigp = pgpDigParamsNew(pkt->tag);\n \t    }\n \t}\n \n-\tif (pgpPrtPkt(&pkt, digp))\n+\tif (expect) {\n+\t    if (pkt->tag != expect)\n+\t\tbreak;\n+\t    selfsig = pgpDigParamsNew(pkt->tag);\n+\t}\n+\n+\tif (pgpPrtPkt(pkt, selfsig ? selfsig : digp))\n \t    break;\n \n-\tp += (pkt.body - pkt.head) + pkt.blen;\n+\tif (selfsig) {\n+\t    /* subkeys must be followed by binding signature */\n+\t    if (prevtag == PGPTAG_PUBLIC_SUBKEY) {\n+\t\tif (selfsig->sigtype != PGPSIGTYPE_SUBKEY_BINDING)\n+\t\t    break;\n+\t    }\n+\n+\t    int xx = pgpVerifySelf(digp, selfsig, all, i);\n+\n+\t    selfsig = pgpDigParamsFree(selfsig);\n+\t    if (xx)\n+\t\tbreak;\n+\t    expect = 0;\n+\t}\n+\n+\tif (pkt->tag == PGPTAG_PUBLIC_SUBKEY)\n+\t    expect = PGPTAG_SIGNATURE;\n+\tprevtag = pkt->tag;\n+\n+\ti++;\n+\tp += (pkt->body - pkt->head) + pkt->blen;\n \tif (pkttype == PGPTAG_SIGNATURE)\n \t    break;\n+\n+\tif (alloced <= i) {\n+\t    alloced *= 2;\n+\t    all = xrealloc(all, alloced * sizeof(*all));\n+\t}\n     }\n \n-    rc = (digp && (p == pend)) ? 0 : -1;\n+    rc = (digp && (p == pend) && expect == 0) ? 0 : -1;\n \n+    free(all);\n     if (ret && rc == 0) {\n \t*ret = digp;\n     } else {\ndiff --git a/tests/Makefile.am b/tests/Makefile.am\nindex b4a2e2e1ce..bc535d2833 100644\n--- a/tests/Makefile.am\n+++ b/tests/Makefile.am\n@@ -108,6 +108,9 @@ EXTRA_DIST += data/SPECS/hello-config-buildid.spec\n EXTRA_DIST += data/SPECS/hello-cd.spec\n EXTRA_DIST += data/keys/rpm.org-rsa-2048-test.pub\n EXTRA_DIST += data/keys/rpm.org-rsa-2048-test.secret\n+EXTRA_DIST += data/keys/CVE-2021-3521-badbind.asc\n+EXTRA_DIST += data/keys/CVE-2021-3521-nosubsig.asc\n+EXTRA_DIST += data/keys/CVE-2021-3521-nosubsig-last.asc\n EXTRA_DIST += data/macros.testfile\n EXTRA_DIST += data/macros.debug\n EXTRA_DIST += data/SOURCES/foo.c\ndiff --git a/tests/data/keys/CVE-2021-3521-badbind.asc b/tests/data/keys/CVE-2021-3521-badbind.asc\nnew file mode 100644\nindex 0000000000..aea00f9d7a\n--- /dev/null\n+++ b/tests/data/keys/CVE-2021-3521-badbind.asc\n@@ -0,0 +1,25 @@\n+-----BEGIN PGP PUBLIC KEY BLOCK-----\n+Version: rpm-4.17.90 (NSS-3)\n+\n+mQENBFjmORgBCAC7TMEk6wnjSs8Dr4yqSScWdU2pjcqrkTxuzdWvowcIUPZI0w/g\n+HkRqGd4apjvY2V15kjL10gk3QhFP3pZ/9p7zh8o8NHX7aGdSGDK7NOq1eFaErPRY\n+91LW9RiZ0lbOjXEzIL0KHxUiTQEmdXJT43DJMFPyW9fkCWg0OltiX618FUdWWfI8\n+eySdLur1utnqBvdEbCUvWK2RX3vQZQdvEBODnNk2pxqTyV0w6VPQ96W++lF/5Aas\n+7rUv3HIyIXxIggc8FRrnH+y9XvvHDonhTIlGnYZN4ubm9i4y3gOkrZlGTrEw7elQ\n+1QeMyG2QQEbze8YjpTm4iLABCBrRfPRaQpwrABEBAAG0IXJwbS5vcmcgUlNBIHRl\n+c3RrZXkgPHJzYUBycG0ub3JnPokBNwQTAQgAIQUCWOY5GAIbAwULCQgHAgYVCAkK\n+CwIEFgIDAQIeAQIXgAAKCRBDRFkeGWTF/MxxCACnjqFL+MmPh9W9JQKT2DcLbBzf\n+Cqo6wcEBoCOcwgRSk8dSikhARoteoa55JRJhuMyeKhhEAogE9HRmCPFdjezFTwgB\n+BDVBpO2dZ023mLXDVCYX3S8pShOgCP6Tn4wqCnYeAdLcGg106N4xcmgtcssJE+Pr\n+XzTZksbZsrTVEmL/Ym+R5w5jBfFnGk7Yw7ndwfQsfNXQb5AZynClFxnX546lcyZX\n+fEx3/e6ezw57WNOUK6WT+8b+EGovPkbetK/rGxNXuWaP6X4A/QUm8O98nCuHYFQq\n++mvNdsCBqGf7mhaRGtpHk/JgCn5rFvArMDqLVrR9hX0LdCSsH7EGE+bR3r7wuQEN\n+BFjmORgBCACk+vDZrIXQuFXEYToZVwb2attzbbJJCqD71vmZTLsW0QxuPKRgbcYY\n+zp4K4lVBnHhFrF8MOUOxJ7kQWIJZMZFt+BDcptCYurbD2H4W2xvnWViiC+LzCMzz\n+iMJT6165uefL4JHTDPxC2fFiM9yrc72LmylJNkM/vepT128J5Qv0gRUaQbHiQuS6\n+Dm/+WRnUfx3i89SV4mnBxb/Ta93GVqoOciWwzWSnwEnWYAvOb95JL4U7c5J5f/+c\n+KnQDHsW7sIiIdscsWzvgf6qs2Ra1Zrt7Fdk4+ZS2f/adagLhDO1C24sXf5XfMk5m\n+L0OGwZSr9m5s17VXxfspgU5ugc8kBJfzABEBAAE=\n+=WCfs\n+-----END PGP PUBLIC KEY BLOCK-----\n+\ndiff --git a/tests/data/keys/CVE-2021-3521-nosubsig-last.asc b/tests/data/keys/CVE-2021-3521-nosubsig-last.asc\nnew file mode 100644\nindex 0000000000..aea00f9d7a\n--- /dev/null\n+++ b/tests/data/keys/CVE-2021-3521-nosubsig-last.asc\n@@ -0,0 +1,25 @@\n+-----BEGIN PGP PUBLIC KEY BLOCK-----\n+Version: rpm-4.17.90 (NSS-3)\n+\n+mQENBFjmORgBCAC7TMEk6wnjSs8Dr4yqSScWdU2pjcqrkTxuzdWvowcIUPZI0w/g\n+HkRqGd4apjvY2V15kjL10gk3QhFP3pZ/9p7zh8o8NHX7aGdSGDK7NOq1eFaErPRY\n+91LW9RiZ0lbOjXEzIL0KHxUiTQEmdXJT43DJMFPyW9fkCWg0OltiX618FUdWWfI8\n+eySdLur1utnqBvdEbCUvWK2RX3vQZQdvEBODnNk2pxqTyV0w6VPQ96W++lF/5Aas\n+7rUv3HIyIXxIggc8FRrnH+y9XvvHDonhTIlGnYZN4ubm9i4y3gOkrZlGTrEw7elQ\n+1QeMyG2QQEbze8YjpTm4iLABCBrRfPRaQpwrABEBAAG0IXJwbS5vcmcgUlNBIHRl\n+c3RrZXkgPHJzYUBycG0ub3JnPokBNwQTAQgAIQUCWOY5GAIbAwULCQgHAgYVCAkK\n+CwIEFgIDAQIeAQIXgAAKCRBDRFkeGWTF/MxxCACnjqFL+MmPh9W9JQKT2DcLbBzf\n+Cqo6wcEBoCOcwgRSk8dSikhARoteoa55JRJhuMyeKhhEAogE9HRmCPFdjezFTwgB\n+BDVBpO2dZ023mLXDVCYX3S8pShOgCP6Tn4wqCnYeAdLcGg106N4xcmgtcssJE+Pr\n+XzTZksbZsrTVEmL/Ym+R5w5jBfFnGk7Yw7ndwfQsfNXQb5AZynClFxnX546lcyZX\n+fEx3/e6ezw57WNOUK6WT+8b+EGovPkbetK/rGxNXuWaP6X4A/QUm8O98nCuHYFQq\n++mvNdsCBqGf7mhaRGtpHk/JgCn5rFvArMDqLVrR9hX0LdCSsH7EGE+bR3r7wuQEN\n+BFjmORgBCACk+vDZrIXQuFXEYToZVwb2attzbbJJCqD71vmZTLsW0QxuPKRgbcYY\n+zp4K4lVBnHhFrF8MOUOxJ7kQWIJZMZFt+BDcptCYurbD2H4W2xvnWViiC+LzCMzz\n+iMJT6165uefL4JHTDPxC2fFiM9yrc72LmylJNkM/vepT128J5Qv0gRUaQbHiQuS6\n+Dm/+WRnUfx3i89SV4mnBxb/Ta93GVqoOciWwzWSnwEnWYAvOb95JL4U7c5J5f/+c\n+KnQDHsW7sIiIdscsWzvgf6qs2Ra1Zrt7Fdk4+ZS2f/adagLhDO1C24sXf5XfMk5m\n+L0OGwZSr9m5s17VXxfspgU5ugc8kBJfzABEBAAE=\n+=WCfs\n+-----END PGP PUBLIC KEY BLOCK-----\n+\ndiff --git a/tests/data/keys/CVE-2021-3521-nosubsig.asc b/tests/data/keys/CVE-2021-3521-nosubsig.asc\nnew file mode 100644\nindex 0000000000..3a2e7417f8\n--- /dev/null\n+++ b/tests/data/keys/CVE-2021-3521-nosubsig.asc\n@@ -0,0 +1,37 @@\n+-----BEGIN PGP PUBLIC KEY BLOCK-----\n+Version: rpm-4.17.90 (NSS-3)\n+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\n+E4XX4jtDmdZPreZALsiB\n+=rRop\n+-----END PGP PUBLIC KEY BLOCK-----\n+\ndiff --git a/tests/rpmsigdig.at b/tests/rpmsigdig.at\nindex 0f8f2b4884..c8b9f139e1 100644\n--- a/tests/rpmsigdig.at\n+++ b/tests/rpmsigdig.at\n@@ -240,6 +240,34 @@ gpg(185e6146f00650f8) = 4:185e6146f00650f8-58e63918\n [])\n AT_CLEANUP\n \n+AT_SETUP([rpmkeys --import invalid keys])\n+AT_KEYWORDS([rpmkeys import])\n+RPMDB_INIT\n+\n+AT_CHECK([\n+runroot rpmkeys --import /data/keys/CVE-2021-3521-badbind.asc\n+],\n+[1],\n+[],\n+[error: /data/keys/CVE-2021-3521-badbind.asc: key 1 import failed.]\n+)\n+AT_CHECK([\n+runroot rpmkeys --import /data/keys/CVE-2021-3521-nosubsig.asc\n+],\n+[1],\n+[],\n+[error: /data/keys/CVE-2021-3521-nosubsig.asc: key 1 import failed.]\n+)\n+\n+AT_CHECK([\n+runroot rpmkeys --import /data/keys/CVE-2021-3521-nosubsig-last.asc\n+],\n+[1],\n+[],\n+[error: /data/keys/CVE-2021-3521-nosubsig-last.asc: key 1 import failed.]\n+)\n+AT_CLEANUP\n+\n # ------------------------------\n # Test pre-built package verification\n AT_SETUP([rpmkeys -K <signed> 1])\n"
        ],
        "func_after": []
    },
    {
        "idx": 196893,
        "project": "envoy",
        "commit_id": "e9f936d85dc1edc34fabd0a1725ec180f2316353",
        "project_url": "https://github.com/istio/envoy",
        "commit_url": "https://github.com/envoyproxy/envoy/commit/e9f936d85dc1edc34fabd0a1725ec180f2316353",
        "commit_message": "CVE-2022-21654\n\ntls allows re-use when some cert validation settings have changed\n\nSigned-off-by: Yan Avlasov <yavlasov@google.com>",
        "target": 1,
        "irrelevant": 0,
        "func_before": "void DefaultCertValidator::updateDigestForSessionId(bssl::ScopedEVP_MD_CTX& md,\n                                                    uint8_t hash_buffer[EVP_MAX_MD_SIZE],\n                                                    unsigned hash_length) {\n  int rc;\n\n  // Hash all the settings that affect whether the server will allow/accept\n  // the client connection. This ensures that the client is always validated against\n  // the correct settings, even if session resumption across different listeners\n  // is enabled.\n  if (ca_cert_ != nullptr) {\n    rc = X509_digest(ca_cert_.get(), EVP_sha256(), hash_buffer, &hash_length);\n    RELEASE_ASSERT(rc == 1, Utility::getLastCryptoError().value_or(\"\"));\n    RELEASE_ASSERT(hash_length == SHA256_DIGEST_LENGTH,\n                   fmt::format(\"invalid SHA256 hash length {}\", hash_length));\n\n    rc = EVP_DigestUpdate(md.get(), hash_buffer, hash_length);\n    RELEASE_ASSERT(rc == 1, Utility::getLastCryptoError().value_or(\"\"));\n  }\n\n  for (const auto& hash : verify_certificate_hash_list_) {\n    rc = EVP_DigestUpdate(md.get(), hash.data(),\n                          hash.size() *\n                              sizeof(std::remove_reference<decltype(hash)>::type::value_type));\n    RELEASE_ASSERT(rc == 1, Utility::getLastCryptoError().value_or(\"\"));\n  }\n\n  for (const auto& hash : verify_certificate_spki_list_) {\n    rc = EVP_DigestUpdate(md.get(), hash.data(),\n                          hash.size() *\n                              sizeof(std::remove_reference<decltype(hash)>::type::value_type));\n    RELEASE_ASSERT(rc == 1, Utility::getLastCryptoError().value_or(\"\"));\n  }\n}",
        "func_hash": 140411723524972581248505271605198365196,
        "file_name": "default_validator.cc",
        "file_hash": 12469299547216327731154844869138538271,
        "cwe": [
            "CWE-362"
        ],
        "cve": "CVE-2022-21654",
        "cve_desc": "Envoy is an open source edge and service proxy, designed for cloud-native applications. Envoy's tls allows re-use when some cert validation settings have changed from their default configuration. The only workaround for this issue is to ensure that default tls settings are used. Users are advised to upgrade.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-21654",
        "func_name": "DefaultCertValidator::updateDigestForSessionId",
        "diff": [
            "diff --git a/envoy/ssl/certificate_validation_context_config.h b/envoy/ssl/certificate_validation_context_config.h\nindex d331c45ce254..1d839be7e45a 100644\n--- a/envoy/ssl/certificate_validation_context_config.h\n+++ b/envoy/ssl/certificate_validation_context_config.h\n@@ -15,6 +15,11 @@\n namespace Envoy {\n namespace Ssl {\n \n+// SECURITY NOTE\n+//\n+// When adding or changing this interface, it is likely that a change is needed to\n+// `DefaultCertValidator::updateDigestForSessionId` in\n+// `source/extensions/transport_sockets/tls/cert_validator/default_validator.cc`.\n class CertificateValidationContextConfig {\n public:\n   virtual ~CertificateValidationContextConfig() = default;\ndiff --git a/source/extensions/transport_sockets/tls/cert_validator/cert_validator.h b/source/extensions/transport_sockets/tls/cert_validator/cert_validator.h\nindex 5e0f589b4890..57d18c595210 100644\n--- a/source/extensions/transport_sockets/tls/cert_validator/cert_validator.h\n+++ b/source/extensions/transport_sockets/tls/cert_validator/cert_validator.h\n@@ -62,7 +62,10 @@ class CertValidator {\n                                     bool handshaker_provides_certificates) PURE;\n \n   /**\n-   * Called when calculation hash for session context ids\n+   * Called when calculation hash for session context ids. This hash MUST include all\n+   * configuration used to validate a peer certificate, so that if this configuration\n+   * is changed, sessions cannot be re-used and must be re-negotiated and re-validated\n+   * using the new settings.\n    *\n    * @param md the store context\n    * @param hash_buffer the buffer used for digest calculation\ndiff --git a/source/extensions/transport_sockets/tls/cert_validator/default_validator.cc b/source/extensions/transport_sockets/tls/cert_validator/default_validator.cc\nindex 3b28200b73ab..da61d6115c02 100644\n--- a/source/extensions/transport_sockets/tls/cert_validator/default_validator.cc\n+++ b/source/extensions/transport_sockets/tls/cert_validator/default_validator.cc\n@@ -378,6 +378,35 @@ void DefaultCertValidator::updateDigestForSessionId(bssl::ScopedEVP_MD_CTX& md,\n                               sizeof(std::remove_reference<decltype(hash)>::type::value_type));\n     RELEASE_ASSERT(rc == 1, Utility::getLastCryptoError().value_or(\"\"));\n   }\n+\n+  rc = EVP_DigestUpdate(md.get(), &verify_trusted_ca_, sizeof(verify_trusted_ca_));\n+  RELEASE_ASSERT(rc == 1, Utility::getLastCryptoError().value_or(\"\"));\n+\n+  if (config_ != nullptr) {\n+    for (const auto& matcher : config_->subjectAltNameMatchers()) {\n+      size_t hash = MessageUtil::hash(matcher);\n+      rc = EVP_DigestUpdate(md.get(), &hash, sizeof(hash));\n+      RELEASE_ASSERT(rc == 1, Utility::getLastCryptoError().value_or(\"\"));\n+    }\n+\n+    const std::string& crl = config_->certificateRevocationList();\n+    if (!crl.empty()) {\n+      rc = EVP_DigestUpdate(md.get(), crl.data(), crl.length());\n+      RELEASE_ASSERT(rc == 1, Utility::getLastCryptoError().value_or(\"\"));\n+    }\n+\n+    bool allow_expired = config_->allowExpiredCertificate();\n+    rc = EVP_DigestUpdate(md.get(), &allow_expired, sizeof(allow_expired));\n+    RELEASE_ASSERT(rc == 1, Utility::getLastCryptoError().value_or(\"\"));\n+\n+    auto trust_chain_verification = config_->trustChainVerification();\n+    rc = EVP_DigestUpdate(md.get(), &trust_chain_verification, sizeof(trust_chain_verification));\n+    RELEASE_ASSERT(rc == 1, Utility::getLastCryptoError().value_or(\"\"));\n+\n+    auto only_leaf_crl = config_->onlyVerifyLeafCertificateCrl();\n+    rc = EVP_DigestUpdate(md.get(), &only_leaf_crl, sizeof(only_leaf_crl));\n+    RELEASE_ASSERT(rc == 1, Utility::getLastCryptoError().value_or(\"\"));\n+  }\n }\n \n void DefaultCertValidator::addClientValidationContext(SSL_CTX* ctx, bool require_client_cert) {\ndiff --git a/test/extensions/transport_sockets/tls/ssl_socket_test.cc b/test/extensions/transport_sockets/tls/ssl_socket_test.cc\nindex 5e9d7fa605b0..06b61503fe81 100644\n--- a/test/extensions/transport_sockets/tls/ssl_socket_test.cc\n+++ b/test/extensions/transport_sockets/tls/ssl_socket_test.cc\n@@ -3373,6 +3373,164 @@ TEST_P(SslSocketTest, TicketSessionResumptionDifferentServerNames) {\n                               client_ctx_yaml, false, GetParam());\n }\n \n+// Sessions cannot be resumed even though the server certificates are the same,\n+// because of the different `verify_certificate_hash` settings.\n+TEST_P(SslSocketTest, TicketSessionResumptionDifferentVerifyCertHash) {\n+  const std::string server_ctx_yaml1 = absl::StrCat(R\"EOF(\n+  session_ticket_keys:\n+    keys:\n+      filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/ticket_key_a\"\n+  common_tls_context:\n+    tls_certificates:\n+      certificate_chain:\n+        filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/unittest_cert.pem\"\n+      private_key:\n+        filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/unittest_key.pem\"\n+    validation_context:\n+      trusted_ca:\n+        filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/ca_cert.pem\"\n+      verify_certificate_hash:\n+        - \")EOF\",\n+                                                    TEST_SAN_URI_CERT_256_HASH, \"\\\"\");\n+\n+  const std::string server_ctx_yaml2 = absl::StrCat(R\"EOF(\n+  session_ticket_keys:\n+    keys:\n+      filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/ticket_key_a\"\n+  common_tls_context:\n+    tls_certificates:\n+      certificate_chain:\n+        filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/unittest_cert.pem\"\n+      private_key:\n+        filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/unittest_key.pem\"\n+    validation_context:\n+      trusted_ca:\n+        filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/ca_cert.pem\"\n+      verify_certificate_hash:\n+        - \"0000000000000000000000000000000000000000000000000000000000000000\"\n+        - \")EOF\",\n+                                                    TEST_SAN_URI_CERT_256_HASH, \"\\\"\");\n+\n+  const std::string client_ctx_yaml = R\"EOF(\n+  common_tls_context:\n+    tls_certificates:\n+      certificate_chain:\n+        filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/san_uri_cert.pem\"\n+      private_key:\n+        filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/san_uri_key.pem\"\n+)EOF\";\n+\n+  testTicketSessionResumption(server_ctx_yaml1, {}, server_ctx_yaml1, {}, client_ctx_yaml, true,\n+                              GetParam());\n+  testTicketSessionResumption(server_ctx_yaml1, {}, server_ctx_yaml2, {}, client_ctx_yaml, false,\n+                              GetParam());\n+}\n+\n+// Sessions cannot be resumed even though the server certificates are the same,\n+// because of the different `verify_certificate_spki` settings.\n+TEST_P(SslSocketTest, TicketSessionResumptionDifferentVerifyCertSpki) {\n+  const std::string server_ctx_yaml1 = absl::StrCat(R\"EOF(\n+  session_ticket_keys:\n+    keys:\n+      filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/ticket_key_a\"\n+  common_tls_context:\n+    tls_certificates:\n+      certificate_chain:\n+        filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/unittest_cert.pem\"\n+      private_key:\n+        filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/unittest_key.pem\"\n+    validation_context:\n+      trusted_ca:\n+        filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/ca_cert.pem\"\n+      verify_certificate_spki:\n+        - \")EOF\",\n+                                                    TEST_SAN_URI_CERT_SPKI, \"\\\"\");\n+\n+  const std::string server_ctx_yaml2 = absl::StrCat(R\"EOF(\n+  session_ticket_keys:\n+    keys:\n+      filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/ticket_key_a\"\n+  common_tls_context:\n+    tls_certificates:\n+      certificate_chain:\n+        filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/unittest_cert.pem\"\n+      private_key:\n+        filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/unittest_key.pem\"\n+    validation_context:\n+      trusted_ca:\n+        filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/ca_cert.pem\"\n+      verify_certificate_spki:\n+        - \"NvqYIYSbgK2vCJpQhObf77vv+bQWtc5ek5RIOwPiC9A=\"\n+        - \")EOF\",\n+                                                    TEST_SAN_URI_CERT_SPKI, \"\\\"\");\n+\n+  const std::string client_ctx_yaml = R\"EOF(\n+  common_tls_context:\n+    tls_certificates:\n+      certificate_chain:\n+        filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/san_uri_cert.pem\"\n+      private_key:\n+        filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/san_uri_key.pem\"\n+)EOF\";\n+\n+  testTicketSessionResumption(server_ctx_yaml1, {}, server_ctx_yaml1, {}, client_ctx_yaml, true,\n+                              GetParam());\n+  testTicketSessionResumption(server_ctx_yaml1, {}, server_ctx_yaml2, {}, client_ctx_yaml, false,\n+                              GetParam());\n+}\n+\n+// Sessions cannot be resumed even though the server certificates are the same,\n+// because of the different `match_subject_alt_names` settings.\n+TEST_P(SslSocketTest, TicketSessionResumptionDifferentMatchSAN) {\n+  const std::string server_ctx_yaml1 = R\"EOF(\n+  session_ticket_keys:\n+    keys:\n+      filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/ticket_key_a\"\n+  common_tls_context:\n+    tls_certificates:\n+      certificate_chain:\n+        filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/unittest_cert.pem\"\n+      private_key:\n+        filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/unittest_key.pem\"\n+    validation_context:\n+      trusted_ca:\n+        filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/ca_cert.pem\"\n+      match_subject_alt_names:\n+        - exact: \"spiffe://lyft.com/test-team\"\n+)EOF\";\n+\n+  const std::string server_ctx_yaml2 = R\"EOF(\n+  session_ticket_keys:\n+    keys:\n+      filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/ticket_key_a\"\n+  common_tls_context:\n+    tls_certificates:\n+      certificate_chain:\n+        filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/unittest_cert.pem\"\n+      private_key:\n+        filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/unittest_key.pem\"\n+    validation_context:\n+      trusted_ca:\n+        filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/ca_cert.pem\"\n+      match_subject_alt_names:\n+        - prefix: \"spiffe://lyft.com/test-team\"\n+\")EOF\";\n+\n+  const std::string client_ctx_yaml = R\"EOF(\n+  common_tls_context:\n+    tls_certificates:\n+      certificate_chain:\n+        filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/san_uri_cert.pem\"\n+      private_key:\n+        filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/san_uri_key.pem\"\n+)EOF\";\n+\n+  testTicketSessionResumption(server_ctx_yaml1, {}, server_ctx_yaml1, {}, client_ctx_yaml, true,\n+                              GetParam());\n+  testTicketSessionResumption(server_ctx_yaml1, {}, server_ctx_yaml2, {}, client_ctx_yaml, false,\n+                              GetParam());\n+}\n+\n // Sessions can be resumed because the server certificates are different but the CN/SANs and\n // issuer are identical\n TEST_P(SslSocketTest, TicketSessionResumptionDifferentServerCert) {\n"
        ],
        "func_after": []
    },
    {
        "idx": 196894,
        "project": "cryptopp",
        "commit_id": "9425e16437439e68c7d96abef922167d68fafaff",
        "project_url": "https://github.com/weidai11/cryptopp",
        "commit_url": "https://github.com/weidai11/cryptopp/commit/9425e16437439e68c7d96abef922167d68fafaff",
        "commit_message": "Fix for CVE-2015-2141. Thanks to Evgeny Sidorov for reporting. Squaring to satisfy Jacobi requirements suggested by JPM.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "Integer InvertibleRWFunction::CalculateInverse(RandomNumberGenerator &rng, const Integer &x) const\n{\n\tDoQuickSanityCheck();\n\tModularArithmetic modn(m_n);\n\tInteger r, rInv;\n\tdo {\t// do this in a loop for people using small numbers for testing\n\t\tr.Randomize(rng, Integer::One(), m_n - Integer::One());\n\t\trInv = modn.MultiplicativeInverse(r);\n\t} while (rInv.IsZero());\n\tInteger re = modn.Square(r);\n\tre = modn.Multiply(re, x);\t\t\t// blind\n\n\tInteger cp=re%m_p, cq=re%m_q;\n\tif (Jacobi(cp, m_p) * Jacobi(cq, m_q) != 1)\n\t{\n\t\tcp = cp.IsOdd() ? (cp+m_p) >> 1 : cp >> 1;\n\t\tcq = cq.IsOdd() ? (cq+m_q) >> 1 : cq >> 1;\n\t}\n\n\t#pragma omp parallel\n\t\t#pragma omp sections\n\t\t{\n\t\t\t#pragma omp section\n\t\t\t\tcp = ModularSquareRoot(cp, m_p);\n\t\t\t#pragma omp section\n\t\t\t\tcq = ModularSquareRoot(cq, m_q);\n\t\t}\n\n\tInteger y = CRT(cq, m_q, cp, m_p, m_u);\n\ty = modn.Multiply(y, rInv);\t\t\t\t// unblind\n\ty = STDMIN(y, m_n-y);\n\tif (ApplyFunction(y) != x)\t\t\t\t// check\n\t\tthrow Exception(Exception::OTHER_ERROR, \"InvertibleRWFunction: computational error during private key operation\");\n\treturn y;\n}",
        "func_hash": 290420030541756407514179370586675759104,
        "file_name": "rw.cpp",
        "file_hash": 28365074804944330860384058197646130181,
        "cwe": [
            "CWE-399"
        ],
        "cve": "CVE-2015-2141",
        "cve_desc": "The InvertibleRWFunction::CalculateInverse function in rw.cpp in libcrypt++ 5.6.2 does not properly blind private key operations for the Rabin-Williams digital signature algorithm, which allows remote attackers to obtain private keys via a timing attack.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2015-2141",
        "func_name": "InvertibleRWFunction::CalculateInverse",
        "diff": [
            "diff --git a/rw.cpp b/rw.cpp\nindex cdd9f2d22..0b9318bfd 100644\n--- a/rw.cpp\n+++ b/rw.cpp\n@@ -126,10 +126,16 @@ Integer InvertibleRWFunction::CalculateInverse(RandomNumberGenerator &rng, const\n \tDoQuickSanityCheck();\n \tModularArithmetic modn(m_n);\n \tInteger r, rInv;\n-\tdo {\t// do this in a loop for people using small numbers for testing\n+\n+\t// do this in a loop for people using small numbers for testing\n+\tdo {\n \t\tr.Randomize(rng, Integer::One(), m_n - Integer::One());\n+\t\t// Fix for CVE-2015-2141. Thanks to Evgeny Sidorov for reporting.\n+\t\t// Squaring to satisfy Jacobi requirements suggested by JPM.\n+\t\tr = modn.Square(r);\n \t\trInv = modn.MultiplicativeInverse(r);\n \t} while (rInv.IsZero());\n+\n \tInteger re = modn.Square(r);\n \tre = modn.Multiply(re, x);\t\t\t// blind\n \n"
        ],
        "func_after": []
    },
    {
        "idx": 196993,
        "project": "libjxl",
        "commit_id": "7dfa400ded53919d986c5d3d23446a09e0cf481b",
        "project_url": "https://github.com/libjxl/libjxl",
        "commit_url": "https://github.com/libjxl/libjxl/commit/7dfa400ded53919d986c5d3d23446a09e0cf481b",
        "commit_message": "Fix handling of APNG with 0 delay_den (#313)",
        "target": 1,
        "irrelevant": 0,
        "func_before": "Status DecodeImageAPNG(Span<const uint8_t> bytes, ThreadPool* pool,\n                       CodecInOut* io) {\n  Reader r;\n  unsigned int id, i, j, w, h, w0, h0, x0, y0;\n  unsigned int delay_num, delay_den, dop, bop, rowbytes, imagesize;\n  unsigned char sig[8];\n  png_structp png_ptr;\n  png_infop info_ptr;\n  CHUNK chunk;\n  CHUNK chunkIHDR;\n  std::vector<CHUNK> chunksInfo;\n  bool isAnimated = false;\n  bool skipFirst = false;\n  bool hasInfo = false;\n  bool all_dispose_bg = true;\n  APNGFrame frameRaw = {};\n\n  r = {bytes.data(), bytes.data() + bytes.size()};\n  // Not an aPNG => not an error\n  unsigned char png_signature[8] = {137, 80, 78, 71, 13, 10, 26, 10};\n  if (r.Read(sig, 8) || memcmp(sig, png_signature, 8) != 0) {\n    return false;\n  }\n  id = read_chunk(&r, &chunkIHDR);\n\n  io->frames.clear();\n  io->dec_pixels = 0;\n  io->metadata.m.SetUintSamples(8);\n  io->metadata.m.SetAlphaBits(8);\n  io->metadata.m.color_encoding =\n      ColorEncoding::SRGB();  // todo: get data from png metadata\n  (void)io->dec_hints.Foreach(\n      [](const std::string& key, const std::string& /*value*/) {\n        JXL_WARNING(\"APNG decoder ignoring %s hint\", key.c_str());\n        return true;\n      });\n\n  bool errorstate = true;\n  if (id == kId_IHDR && chunkIHDR.size == 25) {\n    w0 = w = png_get_uint_32(chunkIHDR.p + 8);\n    h0 = h = png_get_uint_32(chunkIHDR.p + 12);\n\n    if (w > cMaxPNGSize || h > cMaxPNGSize) {\n      return false;\n    }\n\n    x0 = 0;\n    y0 = 0;\n    delay_num = 1;\n    delay_den = 10;\n    dop = 0;\n    bop = 0;\n    rowbytes = w * 4;\n    imagesize = h * rowbytes;\n\n    frameRaw.p = new unsigned char[imagesize];\n    frameRaw.rows = new png_bytep[h * sizeof(png_bytep)];\n    for (j = 0; j < h; j++) frameRaw.rows[j] = frameRaw.p + j * rowbytes;\n\n    if (!processing_start(png_ptr, info_ptr, (void*)&frameRaw, hasInfo,\n                          chunkIHDR, chunksInfo)) {\n      bool last_base_was_none = true;\n      while (!r.Eof()) {\n        id = read_chunk(&r, &chunk);\n        if (!id) break;\n        JXL_ASSERT(chunk.p != nullptr);\n\n        if (id == kId_acTL && !hasInfo && !isAnimated) {\n          isAnimated = true;\n          skipFirst = true;\n          io->metadata.m.have_animation = true;\n          io->metadata.m.animation.tps_numerator = 1000;\n        } else if (id == kId_IEND ||\n                   (id == kId_fcTL && (!hasInfo || isAnimated))) {\n          if (hasInfo) {\n            if (!processing_finish(png_ptr, info_ptr)) {\n              ImageBundle bundle(&io->metadata.m);\n              bundle.duration = delay_num * 1000 / delay_den;\n              bundle.origin.x0 = x0;\n              bundle.origin.y0 = y0;\n              // TODO(veluca): this could in principle be implemented.\n              if (last_base_was_none && !all_dispose_bg &&\n                  (x0 != 0 || y0 != 0 || w0 != w || h0 != h || bop != 0)) {\n                return JXL_FAILURE(\n                    \"APNG with dispose-to-0 is not supported for non-full or \"\n                    \"blended frames\");\n              }\n              switch (dop) {\n                case 0:\n                  bundle.use_for_next_frame = true;\n                  last_base_was_none = false;\n                  all_dispose_bg = false;\n                  break;\n                case 2:\n                  bundle.use_for_next_frame = false;\n                  all_dispose_bg = false;\n                  break;\n                default:\n                  bundle.use_for_next_frame = false;\n                  last_base_was_none = true;\n              }\n              bundle.blend = bop != 0;\n              io->dec_pixels += w0 * h0;\n\n              Image3F sub_frame(w0, h0);\n              ImageF sub_frame_alpha(w0, h0);\n              for (size_t y = 0; y < h0; ++y) {\n                float* const JXL_RESTRICT row_r = sub_frame.PlaneRow(0, y);\n                float* const JXL_RESTRICT row_g = sub_frame.PlaneRow(1, y);\n                float* const JXL_RESTRICT row_b = sub_frame.PlaneRow(2, y);\n                float* const JXL_RESTRICT row_alpha = sub_frame_alpha.Row(y);\n                uint8_t* const f = frameRaw.rows[y];\n                for (size_t x = 0; x < w0; ++x) {\n                  if (f[4 * x + 3] == 0) {\n                    row_alpha[x] = 0;\n                    row_r[x] = 0;\n                    row_g[x] = 0;\n                    row_b[x] = 0;\n                    continue;\n                  }\n                  row_r[x] = f[4 * x + 0] * (1.f / 255);\n                  row_g[x] = f[4 * x + 1] * (1.f / 255);\n                  row_b[x] = f[4 * x + 2] * (1.f / 255);\n                  row_alpha[x] = f[4 * x + 3] * (1.f / 255);\n                }\n              }\n              bundle.SetFromImage(std::move(sub_frame), ColorEncoding::SRGB());\n              bundle.SetAlpha(std::move(sub_frame_alpha),\n                              /*alpha_is_premultiplied=*/false);\n              io->frames.push_back(std::move(bundle));\n            } else {\n              delete[] chunk.p;\n              break;\n            }\n          }\n\n          if (id == kId_IEND) {\n            errorstate = false;\n            break;\n          }\n          // At this point the old frame is done. Let's start a new one.\n          w0 = png_get_uint_32(chunk.p + 12);\n          h0 = png_get_uint_32(chunk.p + 16);\n          x0 = png_get_uint_32(chunk.p + 20);\n          y0 = png_get_uint_32(chunk.p + 24);\n          delay_num = png_get_uint_16(chunk.p + 28);\n          delay_den = png_get_uint_16(chunk.p + 30);\n          dop = chunk.p[32];\n          bop = chunk.p[33];\n\n          if (w0 > cMaxPNGSize || h0 > cMaxPNGSize || x0 > cMaxPNGSize ||\n              y0 > cMaxPNGSize || x0 + w0 > w || y0 + h0 > h || dop > 2 ||\n              bop > 1) {\n            delete[] chunk.p;\n            break;\n          }\n\n          if (hasInfo) {\n            memcpy(chunkIHDR.p + 8, chunk.p + 12, 8);\n            if (processing_start(png_ptr, info_ptr, (void*)&frameRaw, hasInfo,\n                                 chunkIHDR, chunksInfo)) {\n              delete[] chunk.p;\n              break;\n            }\n          } else\n            skipFirst = false;\n\n          if (io->frames.size() == (skipFirst ? 1 : 0)) {\n            bop = 0;\n            if (dop == 2) dop = 1;\n          }\n        } else if (id == kId_IDAT) {\n          hasInfo = true;\n          if (processing_data(png_ptr, info_ptr, chunk.p, chunk.size)) {\n            delete[] chunk.p;\n            break;\n          }\n        } else if (id == kId_fdAT && isAnimated) {\n          png_save_uint_32(chunk.p + 4, chunk.size - 16);\n          memcpy(chunk.p + 8, \"IDAT\", 4);\n          if (processing_data(png_ptr, info_ptr, chunk.p + 4, chunk.size - 4)) {\n            delete[] chunk.p;\n            break;\n          }\n        } else if (!isAbc(chunk.p[4]) || !isAbc(chunk.p[5]) ||\n                   !isAbc(chunk.p[6]) || !isAbc(chunk.p[7])) {\n          delete[] chunk.p;\n          break;\n        } else if (!hasInfo) {\n          if (processing_data(png_ptr, info_ptr, chunk.p, chunk.size)) {\n            delete[] chunk.p;\n            break;\n          }\n          chunksInfo.push_back(chunk);\n          continue;\n        }\n        delete[] chunk.p;\n      }\n    }\n    delete[] frameRaw.rows;\n    delete[] frameRaw.p;\n  }\n\n  for (i = 0; i < chunksInfo.size(); i++) delete[] chunksInfo[i].p;\n\n  chunksInfo.clear();\n  delete[] chunkIHDR.p;\n\n  if (errorstate) return false;\n  SetIntensityTarget(io);\n  return true;\n}",
        "func_hash": 313851366023244520296960010326993371914,
        "file_name": "codec_apng.cc",
        "file_hash": 303923165706235443177070807550807665571,
        "cwe": [
            "CWE-369"
        ],
        "cve": "CVE-2021-36692",
        "cve_desc": "libjxl v0.3.7 is affected by a Divide By Zero in issue in lib/extras/codec_apng.cc jxl::DecodeImageAPNG(). When encoding a malicous APNG file using cjxl, an attacker can trigger a denial of service.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-36692",
        "func_name": "DecodeImageAPNG",
        "diff": [
            "diff --git a/AUTHORS b/AUTHORS\nindex d74bca225ef7..bc1ff2a7bb70 100644\n--- a/AUTHORS\n+++ b/AUTHORS\n@@ -16,6 +16,7 @@ Cloudinary Ltd. <*@cloudinary.com>\n Google LLC <*@google.com>\n \n # Individuals:\n+Alexander Sago <cagelight@gmail.com>\n Dirk Lemstra <dirk@lemstra.org>\n Jon Sneyers <jon@cloudinary.com>\n Pieter Wuille\ndiff --git a/lib/extras/codec_apng.cc b/lib/extras/codec_apng.cc\nindex 48b7653d8bfe..bef59f6369f9 100644\n--- a/lib/extras/codec_apng.cc\n+++ b/lib/extras/codec_apng.cc\n@@ -342,6 +342,8 @@ Status DecodeImageAPNG(Span<const uint8_t> bytes, ThreadPool* pool,\n           dop = chunk.p[32];\n           bop = chunk.p[33];\n \n+          if (!delay_den) delay_den = 100;\n+\n           if (w0 > cMaxPNGSize || h0 > cMaxPNGSize || x0 > cMaxPNGSize ||\n               y0 > cMaxPNGSize || x0 + w0 > w || y0 + h0 > h || dop > 2 ||\n               bop > 1) {\n"
        ],
        "func_after": []
    },
    {
        "idx": 197015,
        "project": "gpac",
        "commit_id": "dae9900580a8888969481cd72035408091edb11b",
        "project_url": "https://github.com/gpac/gpac",
        "commit_url": "https://github.com/gpac/gpac/commit/dae9900580a8888969481cd72035408091edb11b",
        "commit_message": "fixed #1659",
        "target": 1,
        "irrelevant": 1,
        "func_before": "GF_Err SetupWriters(MovieWriter *mw, GF_List *writers, u8 interleaving)\n{\n\tu32 i, trackCount;\n\tTrackWriter *writer;\n\tGF_TrackBox *trak;\n\tGF_ISOFile *movie = mw->movie;\n\n\tmw->total_samples = mw->nb_done = 0;\n\tif (!movie->moov) return GF_OK;\n\n\ttrackCount = gf_list_count(movie->moov->trackList);\n\tfor (i = 0; i < trackCount; i++) {\n\t\ttrak = gf_isom_get_track(movie->moov, i+1);\n\n\t\tGF_SAFEALLOC(writer, TrackWriter);\n\t\tif (!writer) goto exit;\n\t\twriter->sampleNumber = 1;\n\t\twriter->mdia = trak->Media;\n\t\twriter->stbl = trak->Media->information->sampleTable;\n\t\twriter->timeScale = trak->Media->mediaHeader->timeScale;\n\t\twriter->all_dref_mode = Media_SelfContainedType(writer->mdia);\n\n\t\tif (trak->sample_encryption)\n\t\t\twriter->prevent_dispatch = GF_TRUE;\n\n\t\twriter->isDone = 0;\n\t\twriter->DTSprev = 0;\n\t\twriter->chunkDur = 0;\n\t\twriter->chunkSize = 0;\n\t\twriter->constant_size = writer->constant_dur = 0;\n\t\tif (writer->stbl->SampleSize->sampleSize)\n\t\t\twriter->constant_size = writer->stbl->SampleSize->sampleSize;\n\t\tif (writer->stbl->TimeToSample->nb_entries==1) {\n\t\t\twriter->constant_dur = writer->stbl->TimeToSample->entries[0].sampleDelta;\n\t\t\tif (writer->constant_dur>1) writer->constant_dur = 0;\n\t\t}\n\t\tif (!writer->constant_dur || !writer->constant_size || (writer->constant_size>=10))\n\t\t\twriter->constant_size = writer->constant_dur = 0;\n\n\t\twriter->stsc = (GF_SampleToChunkBox *) gf_isom_box_new(GF_ISOM_BOX_TYPE_STSC);\n\t\tif (!writer->stsc) return GF_OUT_OF_MEM;\n\t\tif (writer->stbl->ChunkOffset->type == GF_ISOM_BOX_TYPE_STCO) {\n\t\t\twriter->stco = gf_isom_box_new(GF_ISOM_BOX_TYPE_STCO);\n\t\t} else {\n\t\t\twriter->stco = gf_isom_box_new(GF_ISOM_BOX_TYPE_CO64);\n\t\t}\n\t\tif (!writer->stco) return GF_OUT_OF_MEM;\n\t\t/*stops from chunk escape*/\n\t\tif (interleaving) writer->stbl->MaxSamplePerChunk = 0;\n\t\t/*for progress, assume only one descIndex*/\n\t\tif (Media_IsSelfContained(writer->mdia, 1))\n\t\t\tmw->total_samples += writer->stbl->SampleSize->sampleCount;\n\t\t/*optimization for interleaving: put audio last (this can be overridden by priorities)*/\n\t\tif (movie->storageMode != GF_ISOM_STORE_INTERLEAVED) {\n\t\t\tgf_list_add(writers, writer);\n\t\t} else {\n\t\t\tif (writer->mdia->information->InfoHeader && writer->mdia->information->InfoHeader->type == GF_ISOM_BOX_TYPE_SMHD) {\n\t\t\t\tgf_list_add(writers, writer);\n\t\t\t} else {\n\t\t\t\tgf_list_insert(writers, writer, 0);\n\t\t\t}\n\t\t}\n\t\tif (movie->sample_groups_in_traf && trak->Media->information->sampleTable) {\n\t\t\tgf_isom_box_array_del_parent(&trak->Media->information->sampleTable->child_boxes, trak->Media->information->sampleTable->sampleGroupsDescription);\n\t\t\ttrak->Media->information->sampleTable->sampleGroupsDescription = NULL;\n\t\t}\n\t}\n\treturn GF_OK;\n\nexit:\n\tCleanWriters(writers);\n\treturn GF_OUT_OF_MEM;\n}",
        "func_hash": 186223260006462489135452631752417424978,
        "file_name": "isom_store.c",
        "file_hash": 163429096111764821481093789064862178187,
        "cwe": [
            "CWE-476"
        ],
        "cve": "CVE-2020-35981",
        "cve_desc": "An issue was discovered in GPAC version 0.8.0 and 1.0.1. There is an invalid pointer dereference in the function SetupWriters() in isomedia/isom_store.c.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2020-35981",
        "func_name": "SetupWriters",
        "diff": [
            "diff --git a/src/isomedia/isom_store.c b/src/isomedia/isom_store.c\nindex 37dfbe55a9..ee2b2cfaf2 100644\n--- a/src/isomedia/isom_store.c\n+++ b/src/isomedia/isom_store.c\n@@ -150,8 +150,14 @@ GF_Err SetupWriters(MovieWriter *mw, GF_List *writers, u8 interleaving)\n \n \ttrackCount = gf_list_count(movie->moov->trackList);\n \tfor (i = 0; i < trackCount; i++) {\n+\t\tGF_SampleTableBox *stbl;\n \t\ttrak = gf_isom_get_track(movie->moov, i+1);\n \n+\t\tstbl = (trak->Media && trak->Media->information) ? trak->Media->information->sampleTable : NULL;\n+\t\tif (!stbl || !stbl->SampleSize || !stbl->ChunkOffset || !stbl->SampleToChunk) {\n+\t\t\treturn GF_ISOM_INVALID_FILE;\n+\t\t}\n+\n \t\tGF_SAFEALLOC(writer, TrackWriter);\n \t\tif (!writer) goto exit;\n \t\twriter->sampleNumber = 1;\n"
        ],
        "func_after": []
    },
    {
        "idx": 197024,
        "project": "tensorflow",
        "commit_id": "93f428fd1768df147171ed674fee1fc5ab8309ec",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/93f428fd1768df147171ed674fee1fc5ab8309ec",
        "commit_message": "Fix nullptr deref and heap OOB access in binary cwise ops.\n\nPiperOrigin-RevId: 387936777\nChange-Id: I608b8074cec36a982cca622b7144cb2c43e6e19f",
        "target": 1,
        "irrelevant": 1,
        "func_before": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor& in0 = ctx->input(0);\n    const Tensor& in1 = ctx->input(1);\n    auto in0_flat = in0.flat<Tin>();\n    auto in1_flat = in1.flat<Tin>();\n    const Device& eigen_device = ctx->eigen_device<Device>();\n\n    Tensor* out = nullptr;\n    if (std::is_same<Tin, Tout>::value) {\n      OP_REQUIRES_OK(ctx, ctx->forward_input_or_allocate_output(\n                              {0, 1}, 0, in0.shape(), &out));\n    } else {\n      OP_REQUIRES_OK(ctx, ctx->allocate_output(0, in0.shape(), &out));\n    }\n    auto out_flat = out->flat<Tout>();\n    functor::SimpleBinaryFunctor<Device, Functor>()(eigen_device, out_flat,\n                                                    in0_flat, in1_flat);\n  }",
        "func_hash": 84336962255031391560456997711771904797,
        "file_name": "cwise_ops_common.h",
        "file_hash": 158457487648144003832850895201682084763,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2021-37659",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions an attacker can cause undefined behavior via binding a reference to null pointer in all binary cwise operations that don't require broadcasting (e.g., gradients of binary cwise operations). The [implementation](https://github.com/tensorflow/tensorflow/blob/84d053187cb80d975ef2b9684d4b61981bca0c41/tensorflow/core/kernels/cwise_ops_common.h#L264) assumes that the two inputs have exactly the same number of elements but does not check that. Hence, when the eigen functor executes it triggers heap OOB reads and undefined behavior due to binding to nullptr. We have patched the issue in GitHub commit 93f428fd1768df147171ed674fee1fc5ab8309ec. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37659",
        "func_name": "Compute",
        "diff": [
            "diff --git a/tensorflow/core/kernels/cwise_ops_common.h b/tensorflow/core/kernels/cwise_ops_common.h\nindex 9adc628421d046..4f2c83322ba00f 100644\n--- a/tensorflow/core/kernels/cwise_ops_common.h\n+++ b/tensorflow/core/kernels/cwise_ops_common.h\n@@ -265,6 +265,11 @@ class SimpleBinaryOp : public OpKernel {\n   void Compute(OpKernelContext* ctx) override {\n     const Tensor& in0 = ctx->input(0);\n     const Tensor& in1 = ctx->input(1);\n+    OP_REQUIRES(\n+        ctx, in0.NumElements() == in1.NumElements(),\n+        errors::InvalidArgument(\"The two arguments to a cwise op must have \"\n+                                \"same number of elements, got \",\n+                                in0.NumElements(), \" and \", in1.NumElements()));\n     auto in0_flat = in0.flat<Tin>();\n     auto in1_flat = in1.flat<Tin>();\n     const Device& eigen_device = ctx->eigen_device<Device>();\n"
        ],
        "func_after": []
    },
    {
        "idx": 197057,
        "project": "drogon",
        "commit_id": "3c785326c63a34aa1799a639ae185bc9453cb447",
        "project_url": "https://github.com/drogonframework/drogon",
        "commit_url": "https://github.com/drogonframework/drogon/commit/3c785326c63a34aa1799a639ae185bc9453cb447",
        "commit_message": "Prevent malformed upload path causing arbitrary write (#1174)",
        "target": 1,
        "irrelevant": 0,
        "func_before": "int HttpFileImpl::save(const std::string &path) const\n{\n    assert(!path.empty());\n    if (fileName_.empty())\n        return -1;\n    filesystem::path fsPath(utils::toNativePath(path));\n    if (!fsPath.is_absolute() &&\n        (!fsPath.has_parent_path() ||\n         (fsPath.begin()->string() != \".\" && fsPath.begin()->string() != \"..\")))\n    {\n        filesystem::path fsUploadPath(utils::toNativePath(\n            HttpAppFrameworkImpl::instance().getUploadPath()));\n        fsPath = fsUploadPath / fsPath;\n    }\n    filesystem::path fsFileName(utils::toNativePath(fileName_));\n    if (!filesystem::exists(fsPath))\n    {\n        LOG_TRACE << \"create path:\" << fsPath;\n        drogon::error_code err;\n        filesystem::create_directories(fsPath, err);\n        if (err)\n        {\n            LOG_SYSERR;\n            return -1;\n        }\n    }\n    return saveTo(fsPath / fsFileName);\n}",
        "func_hash": 314463188138781431986696466899338798829,
        "file_name": "HttpFileImpl.cc",
        "file_hash": null,
        "cwe": [
            "CWE-552"
        ],
        "cve": "CVE-2022-25297",
        "cve_desc": "This affects the package drogonframework/drogon before 1.7.5. The unsafe handling of file names during upload using HttpFile::save() method may enable attackers to write files to arbitrary locations outside the designated target folder.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-25297",
        "func_name": "HttpFileImpl::save",
        "diff": [
            "diff --git a/lib/src/HttpFileImpl.cc b/lib/src/HttpFileImpl.cc\nindex ad9c692a76..faf9394246 100644\n--- a/lib/src/HttpFileImpl.cc\n+++ b/lib/src/HttpFileImpl.cc\n@@ -18,6 +18,7 @@\n #include <drogon/MultiPart.h>\n #include <fstream>\n #include <iostream>\n+#include <algorithm>\n \n using namespace drogon;\n \n@@ -31,28 +32,45 @@ int HttpFileImpl::save(const std::string &path) const\n     assert(!path.empty());\n     if (fileName_.empty())\n         return -1;\n-    filesystem::path fsPath(utils::toNativePath(path));\n-    if (!fsPath.is_absolute() &&\n-        (!fsPath.has_parent_path() ||\n-         (fsPath.begin()->string() != \".\" && fsPath.begin()->string() != \"..\")))\n+    filesystem::path fsUploadDir(utils::toNativePath(path));\n+\n+    if (!fsUploadDir.is_absolute() && (!fsUploadDir.has_parent_path() ||\n+                                       (fsUploadDir.begin()->string() != \".\" &&\n+                                        fsUploadDir.begin()->string() != \"..\")))\n     {\n-        filesystem::path fsUploadPath(utils::toNativePath(\n-            HttpAppFrameworkImpl::instance().getUploadPath()));\n-        fsPath = fsUploadPath / fsPath;\n+        fsUploadDir = utils::toNativePath(\n+                          HttpAppFrameworkImpl::instance().getUploadPath()) /\n+                      fsUploadDir;\n     }\n-    filesystem::path fsFileName(utils::toNativePath(fileName_));\n-    if (!filesystem::exists(fsPath))\n+\n+    fsUploadDir = filesystem::weakly_canonical(fsUploadDir);\n+\n+    if (!filesystem::exists(fsUploadDir))\n     {\n-        LOG_TRACE << \"create path:\" << fsPath;\n+        LOG_TRACE << \"create path:\" << fsUploadDir;\n         drogon::error_code err;\n-        filesystem::create_directories(fsPath, err);\n+        filesystem::create_directories(fsUploadDir, err);\n         if (err)\n         {\n             LOG_SYSERR;\n             return -1;\n         }\n     }\n-    return saveTo(fsPath / fsFileName);\n+\n+    filesystem::path fsSaveToPath(filesystem::weakly_canonical(\n+        fsUploadDir / utils::toNativePath(fileName_)));\n+\n+    if (!std::equal(fsUploadDir.begin(),\n+                    fsUploadDir.end(),\n+                    fsSaveToPath.begin()))\n+    {\n+        LOG_ERROR\n+            << \"Attempt writing outside of upload directory detected. Path: \"\n+            << fileName_;\n+        return -1;\n+    }\n+\n+    return saveTo(fsSaveToPath);\n }\n int HttpFileImpl::saveAs(const std::string &fileName) const\n {\ndiff --git a/lib/tests/CMakeLists.txt b/lib/tests/CMakeLists.txt\nindex 824d5b58b1..79409527c0 100644\n--- a/lib/tests/CMakeLists.txt\n+++ b/lib/tests/CMakeLists.txt\n@@ -1,45 +1,49 @@\n link_libraries(${PROJECT_NAME})\n-set(UNITTEST_SOURCES unittests/main.cc\n-                        unittests/Base64Test.cc\n-                        unittests/UrlCodecTest.cc\n-                        unittests/GzipTest.cc\n-                        unittests/HttpViewDataTest.cc\n-                        unittests/CookieTest.cc\n-                        unittests/ClassNameTest.cc\n-                        unittests/HttpDateTest.cc\n-                        unittests/HttpHeaderTest.cc\n-                        unittests/MD5Test.cc\n-                        unittests/MsgBufferTest.cc\n-                        unittests/OStringStreamTest.cc\n-                        unittests/PubSubServiceUnittest.cc\n-                        unittests/Sha1Test.cc\n-                        ../src/ssl_funcs/Sha1.cc\n-                        ../src/HttpUtils.cc\n-                        unittests/FileTypeTest.cc\n-                        unittests/DrObjectTest.cc\n-                        unittests/HttpFullDateTest.cc\n-                        unittests/MainLoopTest.cc\n-                        unittests/CacheMapTest.cc\n-                        unittests/StringOpsTest.cc)\n+set(UNITTEST_SOURCES\n+    unittests/main.cc\n+    unittests/Base64Test.cc\n+    unittests/UrlCodecTest.cc\n+    unittests/GzipTest.cc\n+    unittests/HttpViewDataTest.cc\n+    unittests/CookieTest.cc\n+    unittests/ClassNameTest.cc\n+    unittests/HttpDateTest.cc\n+    unittests/HttpHeaderTest.cc\n+    unittests/MD5Test.cc\n+    unittests/MsgBufferTest.cc\n+    unittests/OStringStreamTest.cc\n+    unittests/PubSubServiceUnittest.cc\n+    unittests/Sha1Test.cc\n+    ../src/ssl_funcs/Sha1.cc\n+    unittests/FileTypeTest.cc\n+    unittests/DrObjectTest.cc\n+    unittests/HttpFullDateTest.cc\n+    unittests/MainLoopTest.cc\n+    unittests/CacheMapTest.cc\n+    unittests/StringOpsTest.cc)\n \n if(DROGON_CXX_STANDARD GREATER_EQUAL 20 AND HAS_COROUTINE)\n-    set(UNITTEST_SOURCES ${UNITTEST_SOURCES} unittests/CoroutineTest.cc)\n+  set(UNITTEST_SOURCES ${UNITTEST_SOURCES} unittests/CoroutineTest.cc)\n endif()\n \n if(Brotli_FOUND)\n-    set(UNITTEST_SOURCES ${UNITTEST_SOURCES} unittests/BrotliTest.cc)\n+  set(UNITTEST_SOURCES ${UNITTEST_SOURCES} unittests/BrotliTest.cc)\n endif()\n \n-if (CMAKE_CXX_COMPILER_ID MATCHES \"MSVC\" AND BUILD_DROGON_SHARED)\n-    set(UNITTEST_SOURCES ${UNITTEST_SOURCES} ../src/HttpUtils.cc)\n+if(CMAKE_CXX_COMPILER_ID MATCHES \"MSVC\" AND BUILD_DROGON_SHARED)\n+  set(UNITTEST_SOURCES ${UNITTEST_SOURCES} ../src/HttpUtils.cc)\n+else()\n+  set(UNITTEST_SOURCES ${UNITTEST_SOURCES} ../src/HttpFileImpl.cc\n+                       unittests/HttpFileTest.cc)\n endif()\n \n add_executable(unittest ${UNITTEST_SOURCES})\n \n-set(INTEGRATION_TEST_CLIENT_SOURCES integration_test/client/main.cc\n-                                    integration_test/client/WebSocketTest.cc\n-                                    integration_test/client/MultipleWsTest.cc\n-                                    integration_test/client/HttpPipeliningTest.cc)\n+set(INTEGRATION_TEST_CLIENT_SOURCES\n+    integration_test/client/main.cc\n+    integration_test/client/WebSocketTest.cc\n+    integration_test/client/MultipleWsTest.cc\n+    integration_test/client/HttpPipeliningTest.cc)\n add_executable(integration_test_client ${INTEGRATION_TEST_CLIENT_SOURCES})\n \n set(INTEGRATION_TEST_SERVER_SOURCES\n@@ -64,10 +68,11 @@ set(INTEGRATION_TEST_SERVER_SOURCES\n     integration_test/server/main.cc)\n \n if(DROGON_CXX_STANDARD GREATER_EQUAL 20 AND HAS_COROUTINE)\n-    set(INTEGRATION_TEST_SERVER_SOURCES ${INTEGRATION_TEST_SERVER_SOURCES}\n-        integration_test/server/api_v1_CoroTest.cc)\n-    set(CMAKE_CXX_STANDARD 20)\n-    set(CMAKE_CXX_STANDARD_REQUIRED TRUE)\n+  set(INTEGRATION_TEST_SERVER_SOURCES\n+      ${INTEGRATION_TEST_SERVER_SOURCES}\n+      integration_test/server/api_v1_CoroTest.cc)\n+  set(CMAKE_CXX_STANDARD 20)\n+  set(CMAKE_CXX_STANDARD_REQUIRED TRUE)\n endif(DROGON_CXX_STANDARD GREATER_EQUAL 20 AND HAS_COROUTINE)\n \n add_executable(integration_test_server ${INTEGRATION_TEST_SERVER_SOURCES})\n@@ -98,9 +103,8 @@ add_custom_command(\n           $<TARGET_FILE_DIR:integration_test_server>/a-directory)\n \n set(tests unittest integration_test_server integration_test_client)\n-set_property(TARGET ${tests}\n-             PROPERTY CXX_STANDARD ${DROGON_CXX_STANDARD})\n+set_property(TARGET ${tests} PROPERTY CXX_STANDARD ${DROGON_CXX_STANDARD})\n set_property(TARGET ${tests} PROPERTY CXX_STANDARD_REQUIRED ON)\n set_property(TARGET ${tests} PROPERTY CXX_EXTENSIONS OFF)\n \n-ParseAndAddDrogonTests(unittest)\n+parseandadddrogontests(unittest)\ndiff --git a/lib/tests/unittests/HttpFileTest.cc b/lib/tests/unittests/HttpFileTest.cc\nnew file mode 100644\nindex 0000000000..d7bd50e5c9\n--- /dev/null\n+++ b/lib/tests/unittests/HttpFileTest.cc\n@@ -0,0 +1,52 @@\n+#include \"../../lib/src/HttpFileImpl.h\"\n+#include <drogon/drogon_test.h>\n+#include <filesystem>\n+\n+using namespace drogon;\n+using namespace std;\n+\n+DROGON_TEST(HttpFile)\n+{\n+    SUBSECTION(Save)\n+    {\n+        HttpFileImpl file;\n+        file.setFileName(\"test_file_name\");\n+        file.setFile(\"test\", 4);\n+        auto out = file.save(\"./test_uploads_dir\");\n+\n+        CHECK(out == 0);\n+        CHECK(filesystem::exists(\"./test_uploads_dir/test_file_name\"));\n+\n+        filesystem::remove_all(\"./test_uploads_dir\");\n+    }\n+\n+    SUBSECTION(SavePathRelativeTraversal)\n+    {\n+        auto uploadPath = filesystem::current_path() / \"test_uploads_dir\";\n+\n+        HttpFileImpl file;\n+        file.setFileName(\"../test_malicious_file_name\");\n+        file.setFile(\"test\", 4);\n+        auto out = file.save(uploadPath.string());\n+\n+        CHECK(out == -1);\n+        CHECK(!filesystem::exists(uploadPath / \"../test_malicious_file_name\"));\n+\n+        filesystem::remove_all(uploadPath);\n+        filesystem::remove(uploadPath / \"../test_malicious_file_name\");\n+    }\n+\n+    SUBSECTION(SavePathAbsoluteTraversal)\n+    {\n+        HttpFileImpl file;\n+        file.setFileName(\"/tmp/test_malicious_file_name\");\n+        file.setFile(\"test\", 4);\n+        auto out = file.save(\"./test_uploads_dir\");\n+\n+        CHECK(out == -1);\n+        CHECK(!filesystem::exists(\"/tmp/test_malicious_file_name\"));\n+\n+        filesystem::remove_all(\"test_uploads_dir\");\n+        filesystem::remove_all(\"/tmp/test_malicious_file_name\");\n+    }\n+}\n"
        ],
        "func_after": []
    },
    {
        "idx": 197095,
        "project": "tensorflow",
        "commit_id": "15691e456c7dc9bd6be203b09765b063bf4a380c",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/15691e456c7dc9bd6be203b09765b063bf4a380c",
        "commit_message": "Prevent dereferencing of null pointers in TFLite's `add.cc`.\n\nPiperOrigin-RevId: 387244946\nChange-Id: I56094233327fbd8439b92e1dbb1262176e00eeb9",
        "target": 1,
        "irrelevant": 1,
        "func_before": "inline void BinaryBroadcastFiveFold(const ArithmeticParams& unswitched_params,\n                                    const RuntimeShape& unswitched_input1_shape,\n                                    const T* unswitched_input1_data,\n                                    const RuntimeShape& unswitched_input2_shape,\n                                    const T* unswitched_input2_data,\n                                    const RuntimeShape& output_shape,\n                                    T* output_data, ElementwiseF elementwise_f,\n                                    ScalarBroadcastF scalar_broadcast_f) {\n  ArithmeticParams switched_params = unswitched_params;\n  switched_params.input1_offset = unswitched_params.input2_offset;\n  switched_params.input1_multiplier = unswitched_params.input2_multiplier;\n  switched_params.input1_shift = unswitched_params.input2_shift;\n  switched_params.input2_offset = unswitched_params.input1_offset;\n  switched_params.input2_multiplier = unswitched_params.input1_multiplier;\n  switched_params.input2_shift = unswitched_params.input1_shift;\n\n  const bool use_unswitched =\n      unswitched_params.broadcast_category ==\n      tflite::BroadcastableOpCategory::kFirstInputBroadcastsFast;\n\n  const ArithmeticParams& params =\n      use_unswitched ? unswitched_params : switched_params;\n  const T* input1_data =\n      use_unswitched ? unswitched_input1_data : unswitched_input2_data;\n  const T* input2_data =\n      use_unswitched ? unswitched_input2_data : unswitched_input1_data;\n\n  // Fivefold nested loops. The second input resets its position for each\n  // iteration of the second loop. The first input resets its position at the\n  // beginning of the fourth loop. The innermost loop is an elementwise add of\n  // sections of the arrays.\n  T* output_data_ptr = output_data;\n  const T* input1_data_ptr = input1_data;\n  const T* input2_data_reset = input2_data;\n  // In the fivefold pattern, y0, y2 and y4 are not broadcast, and so shared\n  // between input shapes. y3 for input 1 is always broadcast, and so the\n  // dimension there is 1, whereas optionally y1 might be broadcast for\n  // input 2. Put another way, input1.shape.FlatSize = y0 * y1 * y2 * y4,\n  // input2.shape.FlatSize = y0 * y2 * y3 * y4.\n  int y0 = params.broadcast_shape[0];\n  int y1 = params.broadcast_shape[1];\n  int y2 = params.broadcast_shape[2];\n  int y3 = params.broadcast_shape[3];\n  int y4 = params.broadcast_shape[4];\n  if (y4 > 1) {\n    // General fivefold pattern, with y4 > 1 so there is a non-broadcast inner\n    // dimension.\n    for (int i0 = 0; i0 < y0; ++i0) {\n      const T* input2_data_ptr = nullptr;\n      for (int i1 = 0; i1 < y1; ++i1) {\n        input2_data_ptr = input2_data_reset;\n        for (int i2 = 0; i2 < y2; ++i2) {\n          for (int i3 = 0; i3 < y3; ++i3) {\n            elementwise_f(y4, params, input1_data_ptr, input2_data_ptr,\n                          output_data_ptr);\n            input2_data_ptr += y4;\n            output_data_ptr += y4;\n          }\n          // We have broadcast y4 of input1 data y3 times, and now move on.\n          input1_data_ptr += y4;\n        }\n      }\n      // We have broadcast y2*y3*y4 of input2 data y1 times, and now move on.\n      input2_data_reset = input2_data_ptr;\n    }\n  } else {\n    // Special case of y4 == 1, in which the innermost loop is a single\n    // element and can be combined with the next (y3) as an inner broadcast.\n    //\n    // Note that this handles the case of pure scalar broadcast when\n    // y0 == y1 == y2 == 1. With low overhead it handles cases such as scalar\n    // broadcast with batch (as y2 > 1).\n    //\n    // NOTE The process is the same as the above general case except\n    // simplified for y4 == 1 and the loop over y3 is contained within the\n    // AddScalarBroadcast function.\n    for (int i0 = 0; i0 < y0; ++i0) {\n      const T* input2_data_ptr = nullptr;\n      for (int i1 = 0; i1 < y1; ++i1) {\n        input2_data_ptr = input2_data_reset;\n        for (int i2 = 0; i2 < y2; ++i2) {\n          scalar_broadcast_f(y3, params, *input1_data_ptr, input2_data_ptr,\n                             output_data_ptr);\n          input2_data_ptr += y3;\n          output_data_ptr += y3;\n          input1_data_ptr += 1;\n        }\n      }\n      input2_data_reset = input2_data_ptr;\n    }\n  }\n}",
        "func_hash": 189506316609912057332068378278926028013,
        "file_name": "optimized_ops.h",
        "file_hash": 272937509923686290195986142976705267114,
        "cwe": [
            "CWE-369"
        ],
        "cve": "CVE-2021-37688",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions an attacker can craft a TFLite model that would trigger a null pointer dereference, which would result in a crash and denial of service. The [implementation](https://github.com/tensorflow/tensorflow/blob/149562d49faa709ea80df1d99fc41d005b81082a/tensorflow/lite/kernels/internal/optimized/optimized_ops.h#L268-L285) unconditionally dereferences a pointer. We have patched the issue in GitHub commit 15691e456c7dc9bd6be203b09765b063bf4a380c. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37688",
        "func_name": "BinaryBroadcastFiveFold",
        "diff": [
            "diff --git a/tensorflow/lite/kernels/internal/optimized/optimized_ops.h b/tensorflow/lite/kernels/internal/optimized/optimized_ops.h\nindex 241405a6bbae19..296b3923a257a9 100644\n--- a/tensorflow/lite/kernels/internal/optimized/optimized_ops.h\n+++ b/tensorflow/lite/kernels/internal/optimized/optimized_ops.h\n@@ -265,7 +265,7 @@ inline void BinaryBroadcastFiveFold(const ArithmeticParams& unswitched_params,\n       // We have broadcast y2*y3*y4 of input2 data y1 times, and now move on.\n       input2_data_reset = input2_data_ptr;\n     }\n-  } else {\n+  } else if (input1_data_ptr != nullptr) {\n     // Special case of y4 == 1, in which the innermost loop is a single\n     // element and can be combined with the next (y3) as an inner broadcast.\n     //\n"
        ],
        "func_after": []
    },
    {
        "idx": 197110,
        "project": "tensorflow",
        "commit_id": "bc9c546ce7015c57c2f15c168b3d9201de679a1d",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/bc9c546ce7015c57c2f15c168b3d9201de679a1d",
        "commit_message": "Prevent heap oob access in `resource_variable_ops.cc`\n\nPiperOrigin-RevId: 387936433\nChange-Id: I9e71ddaa8dbd51ec6afbf163a6b3b591f193b4f6",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext* c) override {\n    core::RefCountPtr<Var> v;\n    OP_REQUIRES_OK(c, LookupResource(c, HandleFromInput(c, 0), &v));\n    OP_REQUIRES_OK(c, EnsureSparseVariableAccess<Device, T>(c, v.get()));\n    // NOTE: We hold the lock for the whole gather operation instead\n    // of increasing the reference count of v->tensor() to avoid a\n    // situation where a write to the same variable will see a\n    // reference count greater than one and make a copy of the\n    // (potentially very large) tensor buffer.\n    tf_shared_lock ml(*v->mu());\n    const Tensor& params = *v->tensor();\n    const Tensor& indices = c->input(1);\n    OP_REQUIRES(\n        c, TensorShapeUtils::IsVectorOrHigher(params.shape()),\n        errors::InvalidArgument(\"params must be at least 1 dimensional\"));\n\n    // Check that we have enough index space\n    const int64_t N = indices.NumElements();\n    OP_REQUIRES(\n        c, params.dim_size(0) <= std::numeric_limits<Index>::max(),\n        errors::InvalidArgument(\"params.shape[0] too large for \",\n                                DataTypeString(DataTypeToEnum<Index>::v()),\n                                \" indexing: \", params.dim_size(0), \" > \",\n                                std::numeric_limits<Index>::max()));\n\n    // The result shape is params.shape[:batch_dims] +\n    // indices.shape[batch_dims:] + params.shape[batch_dims+1:].\n    TensorShape result_shape;\n    for (int i = 0; i < batch_dims_; ++i) {\n      result_shape.AddDim(params.dim_size(i));\n    }\n    for (int i = batch_dims_; i < indices.dims(); ++i) {\n      result_shape.AddDim(indices.dim_size(i));\n    }\n    for (int i = batch_dims_ + 1; i < params.dims(); ++i) {\n      result_shape.AddDim(params.dim_size(i));\n    }\n\n    Tensor* out = nullptr;\n    Tensor tmp;\n    if (params.dtype() == DT_VARIANT) {\n      tmp = Tensor(DT_VARIANT, result_shape);\n      c->set_output(0, tmp);\n      out = &tmp;\n    } else {\n      OP_REQUIRES_OK(c, c->allocate_output(0, result_shape, &out));\n    }\n\n    if (N > 0) {\n      Tensor tmp_indices;\n\n      // Points to the original or updated (if batch_dims is set) indices.\n      const Tensor* op_indices = &indices;\n      if (batch_dims_ > 0) {\n        OP_REQUIRES_OK(c, c->allocate_temp(indices.dtype(), indices.shape(),\n                                           &tmp_indices));\n        functor::DenseUpdate<Device, Index, ASSIGN> copy_functor;\n        copy_functor(c->eigen_device<Device>(), tmp_indices.flat<Index>(),\n                     indices.flat<Index>());\n\n        AddBatchOffsets(&tmp_indices, params);\n        op_indices = &tmp_indices;\n      }\n\n      int64_t gather_dim_size = 1;\n      for (int idx = 0; idx <= batch_dims_; ++idx) {\n        gather_dim_size *= params.dim_size(idx);\n      }\n      int64_t inner_size = 1;\n      for (int i = batch_dims_ + 1; i < params.dims(); ++i) {\n        inner_size *= params.dim_size(i);\n      }\n      auto params_flat = params.shaped<T, 3>({1, gather_dim_size, inner_size});\n      const auto indices_flat = op_indices->flat<Index>();\n      auto out_flat = out->shaped<T, 3>({1, N, out->NumElements() / N});\n\n      functor::GatherFunctor<Device, T, Index> functor;\n      int64_t bad_i = functor(c, params_flat, indices_flat, out_flat);\n\n      OP_REQUIRES(\n          c, bad_i < 0,\n          errors::InvalidArgument(\n              \"indices\", SliceDebugString(indices.shape(), bad_i), \" = \",\n              indices_flat(bad_i), \" is not in [0, \", params.dim_size(0), \")\"));\n    }\n  }",
        "func_hash": 175944317482821883294168342214722979534,
        "file_name": "resource_variable_ops.cc",
        "file_hash": 82185528001770551132319474008789135292,
        "cwe": [
            "CWE-369"
        ],
        "cve": "CVE-2021-37654",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions an attacker can trigger a crash via a `CHECK`-fail in debug builds of TensorFlow using `tf.raw_ops.ResourceGather` or a read from outside the bounds of heap allocated data in the same API in a release build. The [implementation](https://github.com/tensorflow/tensorflow/blob/f24faa153ad31a4b51578f8181d3aaab77a1ddeb/tensorflow/core/kernels/resource_variable_ops.cc#L660-L668) does not check that the `batch_dims` value that the user supplies is less than the rank of the input tensor. Since the implementation uses several for loops over the dimensions of `tensor`, this results in reading data from outside the bounds of heap allocated buffer backing the tensor. We have patched the issue in GitHub commit bc9c546ce7015c57c2f15c168b3d9201de679a1d. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37654",
        "func_name": "Compute",
        "diff": [
            "diff --git a/tensorflow/core/kernels/resource_variable_ops.cc b/tensorflow/core/kernels/resource_variable_ops.cc\nindex 71aead55690d65..32a0a43364deae 100644\n--- a/tensorflow/core/kernels/resource_variable_ops.cc\n+++ b/tensorflow/core/kernels/resource_variable_ops.cc\n@@ -660,6 +660,11 @@ class ResourceGatherOp : public OpKernel {\n     OP_REQUIRES(\n         c, TensorShapeUtils::IsVectorOrHigher(params.shape()),\n         errors::InvalidArgument(\"params must be at least 1 dimensional\"));\n+    OP_REQUIRES(\n+        c, params.shape().dims() >= batch_dims_,\n+        errors::InvalidArgument(\"params must have at least \", batch_dims_,\n+                                \" (batch_dims) dimensions but it has shape \",\n+                                params.shape().DebugString()));\n \n     // Check that we have enough index space\n     const int64_t N = indices.NumElements();\n"
        ],
        "func_after": []
    },
    {
        "idx": 197111,
        "project": "tinyexr",
        "commit_id": "a685e3332f61cd4e59324bf3f669d36973d64270",
        "project_url": "https://github.com/syoyo/tinyexr",
        "commit_url": "https://github.com/syoyo/tinyexr/commit/a685e3332f61cd4e59324bf3f669d36973d64270",
        "commit_message": "Make line_no with too large value(2**20) invalid. Fixes #124",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static int DecodeChunk(EXRImage *exr_image, const EXRHeader *exr_header,\n                       const std::vector<tinyexr::tinyexr_uint64> &offsets,\n                       const unsigned char *head, const size_t size,\n                       std::string *err) {\n  int num_channels = exr_header->num_channels;\n\n  int num_scanline_blocks = 1;\n  if (exr_header->compression_type == TINYEXR_COMPRESSIONTYPE_ZIP) {\n    num_scanline_blocks = 16;\n  } else if (exr_header->compression_type == TINYEXR_COMPRESSIONTYPE_PIZ) {\n    num_scanline_blocks = 32;\n  } else if (exr_header->compression_type == TINYEXR_COMPRESSIONTYPE_ZFP) {\n    num_scanline_blocks = 16;\n  }\n\n  int data_width = exr_header->data_window[2] - exr_header->data_window[0] + 1;\n  int data_height = exr_header->data_window[3] - exr_header->data_window[1] + 1;\n\n  if ((data_width < 0) || (data_height < 0)) {\n    if (err) {\n      std::stringstream ss;\n      ss << \"Invalid data width or data height: \" << data_width << \", \"\n         << data_height << std::endl;\n      (*err) += ss.str();\n    }\n    return TINYEXR_ERROR_INVALID_DATA;\n  }\n\n  // Do not allow too large data_width and data_height. header invalid?\n  {\n    const int threshold = 1024 * 8192;  // heuristics\n    if ((data_width > threshold) || (data_height > threshold)) {\n      if (err) {\n        std::stringstream ss;\n        ss << \"data_with or data_height too large. data_width: \" << data_width\n           << \", \"\n           << \"data_height = \" << data_height << std::endl;\n        (*err) += ss.str();\n      }\n      return TINYEXR_ERROR_INVALID_DATA;\n    }\n  }\n\n  size_t num_blocks = offsets.size();\n\n  std::vector<size_t> channel_offset_list;\n  int pixel_data_size = 0;\n  size_t channel_offset = 0;\n  if (!tinyexr::ComputeChannelLayout(&channel_offset_list, &pixel_data_size,\n                                     &channel_offset, num_channels,\n                                     exr_header->channels)) {\n    if (err) {\n      (*err) += \"Failed to compute channel layout.\\n\";\n    }\n    return TINYEXR_ERROR_INVALID_DATA;\n  }\n\n  bool invalid_data = false;  // TODO(LTE): Use atomic lock for MT safety.\n\n  if (exr_header->tiled) {\n    // value check\n    if (exr_header->tile_size_x < 0) {\n      if (err) {\n        std::stringstream ss;\n        ss << \"Invalid tile size x : \" << exr_header->tile_size_x << \"\\n\";\n        (*err) += ss.str();\n      }\n      return TINYEXR_ERROR_INVALID_HEADER;\n    }\n\n    if (exr_header->tile_size_y < 0) {\n      if (err) {\n        std::stringstream ss;\n        ss << \"Invalid tile size y : \" << exr_header->tile_size_y << \"\\n\";\n        (*err) += ss.str();\n      }\n      return TINYEXR_ERROR_INVALID_HEADER;\n    }\n\n    size_t num_tiles = offsets.size();  // = # of blocks\n\n    exr_image->tiles = static_cast<EXRTile *>(\n        calloc(sizeof(EXRTile), static_cast<size_t>(num_tiles)));\n\n    for (size_t tile_idx = 0; tile_idx < num_tiles; tile_idx++) {\n      // Allocate memory for each tile.\n      exr_image->tiles[tile_idx].images = tinyexr::AllocateImage(\n          num_channels, exr_header->channels, exr_header->requested_pixel_types,\n          exr_header->tile_size_x, exr_header->tile_size_y);\n\n      // 16 byte: tile coordinates\n      // 4 byte : data size\n      // ~      : data(uncompressed or compressed)\n      if (offsets[tile_idx] + sizeof(int) * 5 > size) {\n        if (err) {\n          (*err) += \"Insufficient data size.\\n\";\n        }\n        return TINYEXR_ERROR_INVALID_DATA;\n      }\n\n      size_t data_size = size_t(size - (offsets[tile_idx] + sizeof(int) * 5));\n      const unsigned char *data_ptr =\n          reinterpret_cast<const unsigned char *>(head + offsets[tile_idx]);\n\n      int tile_coordinates[4];\n      memcpy(tile_coordinates, data_ptr, sizeof(int) * 4);\n      tinyexr::swap4(reinterpret_cast<unsigned int *>(&tile_coordinates[0]));\n      tinyexr::swap4(reinterpret_cast<unsigned int *>(&tile_coordinates[1]));\n      tinyexr::swap4(reinterpret_cast<unsigned int *>(&tile_coordinates[2]));\n      tinyexr::swap4(reinterpret_cast<unsigned int *>(&tile_coordinates[3]));\n\n      // @todo{ LoD }\n      if (tile_coordinates[2] != 0) {\n        return TINYEXR_ERROR_UNSUPPORTED_FEATURE;\n      }\n      if (tile_coordinates[3] != 0) {\n        return TINYEXR_ERROR_UNSUPPORTED_FEATURE;\n      }\n\n      int data_len;\n      memcpy(&data_len, data_ptr + 16,\n             sizeof(int));  // 16 = sizeof(tile_coordinates)\n      tinyexr::swap4(reinterpret_cast<unsigned int *>(&data_len));\n\n      if (data_len < 4 || size_t(data_len) > data_size) {\n        if (err) {\n          (*err) += \"Insufficient data length.\\n\";\n        }\n        return TINYEXR_ERROR_INVALID_DATA;\n      }\n\n      // Move to data addr: 20 = 16 + 4;\n      data_ptr += 20;\n\n      tinyexr::DecodeTiledPixelData(\n          exr_image->tiles[tile_idx].images,\n          &(exr_image->tiles[tile_idx].width),\n          &(exr_image->tiles[tile_idx].height),\n          exr_header->requested_pixel_types, data_ptr,\n          static_cast<size_t>(data_len), exr_header->compression_type,\n          exr_header->line_order, data_width, data_height, tile_coordinates[0],\n          tile_coordinates[1], exr_header->tile_size_x, exr_header->tile_size_y,\n          static_cast<size_t>(pixel_data_size),\n          static_cast<size_t>(exr_header->num_custom_attributes),\n          exr_header->custom_attributes,\n          static_cast<size_t>(exr_header->num_channels), exr_header->channels,\n          channel_offset_list);\n\n      exr_image->tiles[tile_idx].offset_x = tile_coordinates[0];\n      exr_image->tiles[tile_idx].offset_y = tile_coordinates[1];\n      exr_image->tiles[tile_idx].level_x = tile_coordinates[2];\n      exr_image->tiles[tile_idx].level_y = tile_coordinates[3];\n\n      exr_image->num_tiles = static_cast<int>(num_tiles);\n    }\n  } else {  // scanline format\n\n    // Don't allow too large image(256GB * pixel_data_size or more). Workaround\n    // for #104.\n    size_t total_data_len =\n        size_t(data_width) * size_t(data_height) * size_t(num_channels);\n    const bool total_data_len_overflown = sizeof(void*) == 8 ? (total_data_len >= 0x4000000000) : false;\n    if ((total_data_len == 0) || total_data_len_overflown ) {\n      if (err) {\n        std::stringstream ss;\n        ss << \"Image data size is zero or too large: width = \" << data_width\n           << \", height = \" << data_height << \", channels = \" << num_channels\n           << std::endl;\n        (*err) += ss.str();\n      }\n      return TINYEXR_ERROR_INVALID_DATA;\n    }\n\n    exr_image->images = tinyexr::AllocateImage(\n        num_channels, exr_header->channels, exr_header->requested_pixel_types,\n        data_width, data_height);\n\n#ifdef _OPENMP\n#pragma omp parallel for\n#endif\n    for (int y = 0; y < static_cast<int>(num_blocks); y++) {\n      size_t y_idx = static_cast<size_t>(y);\n\n      if (offsets[y_idx] + sizeof(int) * 2 > size) {\n        invalid_data = true;\n      } else {\n        // 4 byte: scan line\n        // 4 byte: data size\n        // ~     : pixel data(uncompressed or compressed)\n        size_t data_size = size_t(size - (offsets[y_idx] + sizeof(int) * 2));\n        const unsigned char *data_ptr =\n            reinterpret_cast<const unsigned char *>(head + offsets[y_idx]);\n\n        int line_no;\n        memcpy(&line_no, data_ptr, sizeof(int));\n        int data_len;\n        memcpy(&data_len, data_ptr + 4, sizeof(int));\n        tinyexr::swap4(reinterpret_cast<unsigned int *>(&line_no));\n        tinyexr::swap4(reinterpret_cast<unsigned int *>(&data_len));\n\n        if (size_t(data_len) > data_size) {\n          invalid_data = true;\n        } else if (data_len == 0) {\n          // TODO(syoyo): May be ok to raise the threshold for example `data_len\n          // < 4`\n          invalid_data = true;\n        } else {\n          // line_no may be negative.\n          int end_line_no = (std::min)(line_no + num_scanline_blocks,\n                                       (exr_header->data_window[3] + 1));\n\n          int num_lines = end_line_no - line_no;\n\n          if (num_lines <= 0) {\n            invalid_data = true;\n          } else {\n            // Move to data addr: 8 = 4 + 4;\n            data_ptr += 8;\n\n            // Adjust line_no with data_window.bmin.y\n\n            // overflow check\n            tinyexr_int64 lno = static_cast<tinyexr_int64>(line_no) - static_cast<tinyexr_int64>(exr_header->data_window[1]);\n            if (lno > std::numeric_limits<int>::max()) {\n              line_no = -1; // invalid\n            } else if (lno < -std::numeric_limits<int>::max()) {\n              line_no = -1; // invalid\n            } else {\n              line_no -= exr_header->data_window[1];\n            }\n\n            if (line_no < 0) {\n              invalid_data = true;\n            } else {\n              if (!tinyexr::DecodePixelData(\n                      exr_image->images, exr_header->requested_pixel_types,\n                      data_ptr, static_cast<size_t>(data_len),\n                      exr_header->compression_type, exr_header->line_order,\n                      data_width, data_height, data_width, y, line_no,\n                      num_lines, static_cast<size_t>(pixel_data_size),\n                      static_cast<size_t>(exr_header->num_custom_attributes),\n                      exr_header->custom_attributes,\n                      static_cast<size_t>(exr_header->num_channels),\n                      exr_header->channels, channel_offset_list)) {\n                invalid_data = true;\n              }\n            }\n          }\n        }\n      }\n    }  // omp parallel\n  }\n\n  if (invalid_data) {\n    if (err) {\n      std::stringstream ss;\n      (*err) += \"Invalid data found when decoding pixels.\\n\";\n    }\n    return TINYEXR_ERROR_INVALID_DATA;\n  }\n\n  // Overwrite `pixel_type` with `requested_pixel_type`.\n  {\n    for (int c = 0; c < exr_header->num_channels; c++) {\n      exr_header->pixel_types[c] = exr_header->requested_pixel_types[c];\n    }\n  }\n\n  {\n    exr_image->num_channels = num_channels;\n\n    exr_image->width = data_width;\n    exr_image->height = data_height;\n  }\n\n  return TINYEXR_SUCCESS;\n}",
        "func_hash": 204576660378471471312302041175468111939,
        "file_name": "tinyexr.h",
        "file_hash": 28581937103314011160798682220091501322,
        "cwe": [
            "CWE-20"
        ],
        "cve": "CVE-2020-19490",
        "cve_desc": "tinyexr 0.9.5 has a integer overflow over-write in tinyexr::DecodePixelData in tinyexr.h, related to OpenEXR code.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2020-19490",
        "func_name": "DecodeChunk",
        "diff": [
            "diff --git a/tinyexr.h b/tinyexr.h\nindex 564a0c0..f221637 100644\n--- a/tinyexr.h\n+++ b/tinyexr.h\n@@ -472,7 +472,7 @@ extern int LoadEXRFromMemory(float **out_rgba, int *width, int *height,\n #include <cstring>\n #include <sstream>\n \n-// #include <iostream> // debug\n+//#include <iostream> // debug\n \n #include <limits>\n #include <string>\n@@ -7013,6 +7013,11 @@ static void swap2(unsigned short *val) {\n #pragma clang diagnostic push\n #pragma clang diagnostic ignored \"-Wunused-function\"\n #endif\n+\n+#ifdef __GNUC__\n+#pragma GCC diagnostic push\n+#pragma GCC diagnostic ignored \"-Wunused-function\"\n+#endif\n static void cpy4(int *dst_val, const int *src_val) {\n   unsigned char *dst = reinterpret_cast<unsigned char *>(dst_val);\n   const unsigned char *src = reinterpret_cast<const unsigned char *>(src_val);\n@@ -7046,6 +7051,10 @@ static void cpy4(float *dst_val, const float *src_val) {\n #pragma clang diagnostic pop\n #endif\n \n+#ifdef __GNUC__\n+#pragma GCC diagnostic pop\n+#endif\n+\n static void swap4(unsigned int *val) {\n #ifdef MINIZ_LITTLE_ENDIAN\n   (void)val;\n@@ -10949,6 +10958,11 @@ static int DecodeChunk(EXRImage *exr_image, const EXRHeader *exr_header,\n \n         if (size_t(data_len) > data_size) {\n           invalid_data = true;\n+\n+        } else if ((line_no > (2 << 20)) || (line_no < -(2 << 20))) {\n+          // Too large value. Assume this is invalid\n+          // 2**20 = 1048576 = heuristic value.\n+          invalid_data = true;\n         } else if (data_len == 0) {\n           // TODO(syoyo): May be ok to raise the threshold for example `data_len\n           // < 4`\n"
        ],
        "func_after": []
    },
    {
        "idx": 197128,
        "project": "mruby",
        "commit_id": "f72315575f78a9a773adbce0ee7d3ec33434cb76",
        "project_url": "https://github.com/mruby/mruby",
        "commit_url": "https://github.com/mruby/mruby/commit/f72315575f78a9a773adbce0ee7d3ec33434cb76",
        "commit_message": "codegen.c: fix a argument generation bug in array assignment.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "gen_assignment(codegen_scope *s, node *tree, node *rhs, int sp, int val)\n{\n  int idx;\n  int type = nint(tree->car);\n\n  switch (type) {\n  case NODE_GVAR:\n  case NODE_ARG:\n  case NODE_LVAR:\n  case NODE_IVAR:\n  case NODE_CVAR:\n  case NODE_CONST:\n  case NODE_NIL:\n  case NODE_MASGN:\n    if (rhs) {\n      codegen(s, rhs, VAL);\n      pop();\n      sp = cursp();\n    }\n    break;\n\n  case NODE_COLON2:\n  case NODE_CALL:\n  case NODE_SCALL:\n    /* keep evaluation order */\n    break;\n\n  case NODE_NVAR:\n    codegen_error(s, \"Can't assign to numbered parameter\");\n    break;\n\n  default:\n    codegen_error(s, \"unknown lhs\");\n    break;\n  }\n\n  tree = tree->cdr;\n  switch (type) {\n  case NODE_GVAR:\n    gen_setxv(s, OP_SETGV, sp, nsym(tree), val);\n    break;\n  case NODE_ARG:\n  case NODE_LVAR:\n    idx = lv_idx(s, nsym(tree));\n    if (idx > 0) {\n      if (idx != sp) {\n        gen_move(s, idx, sp, val);\n      }\n      break;\n    }\n    else {                      /* upvar */\n      gen_setupvar(s, sp, nsym(tree));\n    }\n    break;\n  case NODE_IVAR:\n    gen_setxv(s, OP_SETIV, sp, nsym(tree), val);\n    break;\n  case NODE_CVAR:\n    gen_setxv(s, OP_SETCV, sp, nsym(tree), val);\n    break;\n  case NODE_CONST:\n    gen_setxv(s, OP_SETCONST, sp, nsym(tree), val);\n    break;\n  case NODE_COLON2:\n    if (sp) {\n      gen_move(s, cursp(), sp, 0);\n    }\n    sp = cursp();\n    push();\n    codegen(s, tree->car, VAL);\n    if (rhs) {\n      codegen(s, rhs, VAL); pop();\n      gen_move(s, sp, cursp(), 0);\n    }\n    pop_n(2);\n    idx = new_sym(s, nsym(tree->cdr));\n    genop_2(s, OP_SETMCNST, sp, idx);\n    break;\n\n  case NODE_CALL:\n  case NODE_SCALL:\n    {\n      int noself = 0, safe = (type == NODE_SCALL), skip = 0, top, call, n = 0;\n      mrb_sym mid = nsym(tree->cdr->car);\n\n      top = cursp();\n      if (val || sp == cursp()) {\n        push();                   /* room for retval */\n      }\n      call = cursp();\n      if (!tree->car) {\n        noself = 1;\n        push();\n      }\n      else {\n        codegen(s, tree->car, VAL); /* receiver */\n      }\n      if (safe) {\n        int recv = cursp()-1;\n        gen_move(s, cursp(), recv, 1);\n        skip = genjmp2_0(s, OP_JMPNIL, cursp(), val);\n      }\n      tree = tree->cdr->cdr->car;\n      if (tree) {\n        if (tree->car) {            /* positional arguments */\n          n = gen_values(s, tree->car, VAL, (tree->cdr->car)?13:14);\n          if (n < 0) {              /* variable length */\n            n = 15;\n            push();\n          }\n        }\n        if (tree->cdr->car) {       /* keyword arguments */\n          if (n == 14) {\n            pop_n(n);\n            genop_2(s, OP_ARRAY, cursp(), n);\n            push();\n            n = 15;\n          }\n          gen_hash(s, tree->cdr->car->cdr, VAL, 0);\n          if (n < 14) {\n            n++;\n          }\n          else {\n            pop_n(2);\n            genop_2(s, OP_ARYPUSH, cursp(), 1);\n          }\n          push();\n        }\n      }\n      if (rhs) {\n        codegen(s, rhs, VAL);\n        pop();\n      }\n      else {\n        gen_move(s, cursp(), sp, 0);\n      }\n      if (val) {\n        gen_move(s, top, cursp(), 1);\n      }\n      if (n < 14) {\n        n++;\n      }\n      else {\n        pop();\n        genop_2(s, OP_ARYPUSH, cursp(), 1);\n      }\n      s->sp = call;\n      if (mid == MRB_OPSYM_2(s->mrb, aref) && n == 2) {\n        genop_1(s, OP_SETIDX, cursp());\n      }\n      else {\n        genop_3(s, noself ? OP_SSEND : OP_SEND, cursp(), new_sym(s, attrsym(s, mid)), n);\n      }\n      if (safe) {\n        dispatch(s, skip);\n      }\n      s->sp = top;\n    }\n    break;\n\n  case NODE_MASGN:\n    gen_vmassignment(s, tree->car, sp, val);\n    break;\n\n  /* splat without assignment */\n  case NODE_NIL:\n    break;\n\n  default:\n    codegen_error(s, \"unknown lhs\");\n    break;\n  }\n  if (val) push();\n}",
        "func_hash": 236078569306136776334536654321578023921,
        "file_name": "codegen.c",
        "file_hash": 69656694646846748382204460208931803734,
        "cwe": [
            "CWE-125"
        ],
        "cve": "CVE-2022-0717",
        "cve_desc": "Out-of-bounds Read in GitHub repository mruby/mruby prior to 3.2.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-0717",
        "func_name": "gen_assignment",
        "diff": [
            "diff --git a/mrbgems/mruby-compiler/core/codegen.c b/mrbgems/mruby-compiler/core/codegen.c\nindex 729f575661..37b1307e65 100644\n--- a/mrbgems/mruby-compiler/core/codegen.c\n+++ b/mrbgems/mruby-compiler/core/codegen.c\n@@ -1904,8 +1904,12 @@ gen_assignment(codegen_scope *s, node *tree, node *rhs, int sp, int val)\n       if (val) {\n         gen_move(s, top, cursp(), 1);\n       }\n-      if (n < 14) {\n+      if (n < 15) {\n         n++;\n+        if (n == 15) {\n+          pop_n(14);\n+          genop_2(s, OP_ARRAY, cursp(), 15);\n+        }\n       }\n       else {\n         pop();\n"
        ],
        "func_after": []
    },
    {
        "idx": 197135,
        "project": "linux",
        "commit_id": "505d9dcb0f7ddf9d075e729523a33d38642ae680",
        "project_url": "https://github.com/torvalds/linux",
        "commit_url": "https://github.com/torvalds/linux/commit/505d9dcb0f7ddf9d075e729523a33d38642ae680",
        "commit_message": "crypto: ccp - fix resource leaks in ccp_run_aes_gcm_cmd()\n\nThere are three bugs in this code:\n\n1) If we ccp_init_data() fails for &src then we need to free aad.\n   Use goto e_aad instead of goto e_ctx.\n2) The label to free the &final_wa was named incorrectly as \"e_tag\" but\n   it should have been \"e_final_wa\".  One error path leaked &final_wa.\n3) The &tag was leaked on one error path.  In that case, I added a free\n   before the goto because the resource was local to that block.\n\nFixes: 36cf515b9bbe (\"crypto: ccp - Enable support for AES GCM on v5 CCPs\")\nReported-by: \"minihanshen(\u6c88\u660e\u822a)\" <minihanshen@tencent.com>\nSigned-off-by: Dan Carpenter <dan.carpenter@oracle.com>\nReviewed-by: John Allen <john.allen@amd.com>\nTested-by: John Allen <john.allen@amd.com>\nSigned-off-by: Herbert Xu <herbert@gondor.apana.org.au>",
        "target": 1,
        "irrelevant": 0,
        "func_before": "ccp_run_aes_gcm_cmd(struct ccp_cmd_queue *cmd_q, struct ccp_cmd *cmd)\n{\n\tstruct ccp_aes_engine *aes = &cmd->u.aes;\n\tstruct ccp_dm_workarea key, ctx, final_wa, tag;\n\tstruct ccp_data src, dst;\n\tstruct ccp_data aad;\n\tstruct ccp_op op;\n\tunsigned int dm_offset;\n\tunsigned int authsize;\n\tunsigned int jobid;\n\tunsigned int ilen;\n\tbool in_place = true; /* Default value */\n\t__be64 *final;\n\tint ret;\n\n\tstruct scatterlist *p_inp, sg_inp[2];\n\tstruct scatterlist *p_tag, sg_tag[2];\n\tstruct scatterlist *p_outp, sg_outp[2];\n\tstruct scatterlist *p_aad;\n\n\tif (!aes->iv)\n\t\treturn -EINVAL;\n\n\tif (!((aes->key_len == AES_KEYSIZE_128) ||\n\t\t(aes->key_len == AES_KEYSIZE_192) ||\n\t\t(aes->key_len == AES_KEYSIZE_256)))\n\t\treturn -EINVAL;\n\n\tif (!aes->key) /* Gotta have a key SGL */\n\t\treturn -EINVAL;\n\n\t/* Zero defaults to 16 bytes, the maximum size */\n\tauthsize = aes->authsize ? aes->authsize : AES_BLOCK_SIZE;\n\tswitch (authsize) {\n\tcase 16:\n\tcase 15:\n\tcase 14:\n\tcase 13:\n\tcase 12:\n\tcase 8:\n\tcase 4:\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\t/* First, decompose the source buffer into AAD & PT,\n\t * and the destination buffer into AAD, CT & tag, or\n\t * the input into CT & tag.\n\t * It is expected that the input and output SGs will\n\t * be valid, even if the AAD and input lengths are 0.\n\t */\n\tp_aad = aes->src;\n\tp_inp = scatterwalk_ffwd(sg_inp, aes->src, aes->aad_len);\n\tp_outp = scatterwalk_ffwd(sg_outp, aes->dst, aes->aad_len);\n\tif (aes->action == CCP_AES_ACTION_ENCRYPT) {\n\t\tilen = aes->src_len;\n\t\tp_tag = scatterwalk_ffwd(sg_tag, p_outp, ilen);\n\t} else {\n\t\t/* Input length for decryption includes tag */\n\t\tilen = aes->src_len - authsize;\n\t\tp_tag = scatterwalk_ffwd(sg_tag, p_inp, ilen);\n\t}\n\n\tjobid = CCP_NEW_JOBID(cmd_q->ccp);\n\n\tmemset(&op, 0, sizeof(op));\n\top.cmd_q = cmd_q;\n\top.jobid = jobid;\n\top.sb_key = cmd_q->sb_key; /* Pre-allocated */\n\top.sb_ctx = cmd_q->sb_ctx; /* Pre-allocated */\n\top.init = 1;\n\top.u.aes.type = aes->type;\n\n\t/* Copy the key to the LSB */\n\tret = ccp_init_dm_workarea(&key, cmd_q,\n\t\t\t\t   CCP_AES_CTX_SB_COUNT * CCP_SB_BYTES,\n\t\t\t\t   DMA_TO_DEVICE);\n\tif (ret)\n\t\treturn ret;\n\n\tdm_offset = CCP_SB_BYTES - aes->key_len;\n\tret = ccp_set_dm_area(&key, dm_offset, aes->key, 0, aes->key_len);\n\tif (ret)\n\t\tgoto e_key;\n\tret = ccp_copy_to_sb(cmd_q, &key, op.jobid, op.sb_key,\n\t\t\t     CCP_PASSTHRU_BYTESWAP_256BIT);\n\tif (ret) {\n\t\tcmd->engine_error = cmd_q->cmd_error;\n\t\tgoto e_key;\n\t}\n\n\t/* Copy the context (IV) to the LSB.\n\t * There is an assumption here that the IV is 96 bits in length, plus\n\t * a nonce of 32 bits. If no IV is present, use a zeroed buffer.\n\t */\n\tret = ccp_init_dm_workarea(&ctx, cmd_q,\n\t\t\t\t   CCP_AES_CTX_SB_COUNT * CCP_SB_BYTES,\n\t\t\t\t   DMA_BIDIRECTIONAL);\n\tif (ret)\n\t\tgoto e_key;\n\n\tdm_offset = CCP_AES_CTX_SB_COUNT * CCP_SB_BYTES - aes->iv_len;\n\tret = ccp_set_dm_area(&ctx, dm_offset, aes->iv, 0, aes->iv_len);\n\tif (ret)\n\t\tgoto e_ctx;\n\n\tret = ccp_copy_to_sb(cmd_q, &ctx, op.jobid, op.sb_ctx,\n\t\t\t     CCP_PASSTHRU_BYTESWAP_256BIT);\n\tif (ret) {\n\t\tcmd->engine_error = cmd_q->cmd_error;\n\t\tgoto e_ctx;\n\t}\n\n\top.init = 1;\n\tif (aes->aad_len > 0) {\n\t\t/* Step 1: Run a GHASH over the Additional Authenticated Data */\n\t\tret = ccp_init_data(&aad, cmd_q, p_aad, aes->aad_len,\n\t\t\t\t    AES_BLOCK_SIZE,\n\t\t\t\t    DMA_TO_DEVICE);\n\t\tif (ret)\n\t\t\tgoto e_ctx;\n\n\t\top.u.aes.mode = CCP_AES_MODE_GHASH;\n\t\top.u.aes.action = CCP_AES_GHASHAAD;\n\n\t\twhile (aad.sg_wa.bytes_left) {\n\t\t\tccp_prepare_data(&aad, NULL, &op, AES_BLOCK_SIZE, true);\n\n\t\t\tret = cmd_q->ccp->vdata->perform->aes(&op);\n\t\t\tif (ret) {\n\t\t\t\tcmd->engine_error = cmd_q->cmd_error;\n\t\t\t\tgoto e_aad;\n\t\t\t}\n\n\t\t\tccp_process_data(&aad, NULL, &op);\n\t\t\top.init = 0;\n\t\t}\n\t}\n\n\top.u.aes.mode = CCP_AES_MODE_GCTR;\n\top.u.aes.action = aes->action;\n\n\tif (ilen > 0) {\n\t\t/* Step 2: Run a GCTR over the plaintext */\n\t\tin_place = (sg_virt(p_inp) == sg_virt(p_outp)) ? true : false;\n\n\t\tret = ccp_init_data(&src, cmd_q, p_inp, ilen,\n\t\t\t\t    AES_BLOCK_SIZE,\n\t\t\t\t    in_place ? DMA_BIDIRECTIONAL\n\t\t\t\t\t     : DMA_TO_DEVICE);\n\t\tif (ret)\n\t\t\tgoto e_ctx;\n\n\t\tif (in_place) {\n\t\t\tdst = src;\n\t\t} else {\n\t\t\tret = ccp_init_data(&dst, cmd_q, p_outp, ilen,\n\t\t\t\t\t    AES_BLOCK_SIZE, DMA_FROM_DEVICE);\n\t\t\tif (ret)\n\t\t\t\tgoto e_src;\n\t\t}\n\n\t\top.soc = 0;\n\t\top.eom = 0;\n\t\top.init = 1;\n\t\twhile (src.sg_wa.bytes_left) {\n\t\t\tccp_prepare_data(&src, &dst, &op, AES_BLOCK_SIZE, true);\n\t\t\tif (!src.sg_wa.bytes_left) {\n\t\t\t\tunsigned int nbytes = ilen % AES_BLOCK_SIZE;\n\n\t\t\t\tif (nbytes) {\n\t\t\t\t\top.eom = 1;\n\t\t\t\t\top.u.aes.size = (nbytes * 8) - 1;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tret = cmd_q->ccp->vdata->perform->aes(&op);\n\t\t\tif (ret) {\n\t\t\t\tcmd->engine_error = cmd_q->cmd_error;\n\t\t\t\tgoto e_dst;\n\t\t\t}\n\n\t\t\tccp_process_data(&src, &dst, &op);\n\t\t\top.init = 0;\n\t\t}\n\t}\n\n\t/* Step 3: Update the IV portion of the context with the original IV */\n\tret = ccp_copy_from_sb(cmd_q, &ctx, op.jobid, op.sb_ctx,\n\t\t\t       CCP_PASSTHRU_BYTESWAP_256BIT);\n\tif (ret) {\n\t\tcmd->engine_error = cmd_q->cmd_error;\n\t\tgoto e_dst;\n\t}\n\n\tret = ccp_set_dm_area(&ctx, dm_offset, aes->iv, 0, aes->iv_len);\n\tif (ret)\n\t\tgoto e_dst;\n\n\tret = ccp_copy_to_sb(cmd_q, &ctx, op.jobid, op.sb_ctx,\n\t\t\t     CCP_PASSTHRU_BYTESWAP_256BIT);\n\tif (ret) {\n\t\tcmd->engine_error = cmd_q->cmd_error;\n\t\tgoto e_dst;\n\t}\n\n\t/* Step 4: Concatenate the lengths of the AAD and source, and\n\t * hash that 16 byte buffer.\n\t */\n\tret = ccp_init_dm_workarea(&final_wa, cmd_q, AES_BLOCK_SIZE,\n\t\t\t\t   DMA_BIDIRECTIONAL);\n\tif (ret)\n\t\tgoto e_dst;\n\tfinal = (__be64 *)final_wa.address;\n\tfinal[0] = cpu_to_be64(aes->aad_len * 8);\n\tfinal[1] = cpu_to_be64(ilen * 8);\n\n\tmemset(&op, 0, sizeof(op));\n\top.cmd_q = cmd_q;\n\top.jobid = jobid;\n\top.sb_key = cmd_q->sb_key; /* Pre-allocated */\n\top.sb_ctx = cmd_q->sb_ctx; /* Pre-allocated */\n\top.init = 1;\n\top.u.aes.type = aes->type;\n\top.u.aes.mode = CCP_AES_MODE_GHASH;\n\top.u.aes.action = CCP_AES_GHASHFINAL;\n\top.src.type = CCP_MEMTYPE_SYSTEM;\n\top.src.u.dma.address = final_wa.dma.address;\n\top.src.u.dma.length = AES_BLOCK_SIZE;\n\top.dst.type = CCP_MEMTYPE_SYSTEM;\n\top.dst.u.dma.address = final_wa.dma.address;\n\top.dst.u.dma.length = AES_BLOCK_SIZE;\n\top.eom = 1;\n\top.u.aes.size = 0;\n\tret = cmd_q->ccp->vdata->perform->aes(&op);\n\tif (ret)\n\t\tgoto e_dst;\n\n\tif (aes->action == CCP_AES_ACTION_ENCRYPT) {\n\t\t/* Put the ciphered tag after the ciphertext. */\n\t\tccp_get_dm_area(&final_wa, 0, p_tag, 0, authsize);\n\t} else {\n\t\t/* Does this ciphered tag match the input? */\n\t\tret = ccp_init_dm_workarea(&tag, cmd_q, authsize,\n\t\t\t\t\t   DMA_BIDIRECTIONAL);\n\t\tif (ret)\n\t\t\tgoto e_tag;\n\t\tret = ccp_set_dm_area(&tag, 0, p_tag, 0, authsize);\n\t\tif (ret)\n\t\t\tgoto e_tag;\n\n\t\tret = crypto_memneq(tag.address, final_wa.address,\n\t\t\t\t    authsize) ? -EBADMSG : 0;\n\t\tccp_dm_free(&tag);\n\t}\n\ne_tag:\n\tccp_dm_free(&final_wa);\n\ne_dst:\n\tif (ilen > 0 && !in_place)\n\t\tccp_free_data(&dst, cmd_q);\n\ne_src:\n\tif (ilen > 0)\n\t\tccp_free_data(&src, cmd_q);\n\ne_aad:\n\tif (aes->aad_len)\n\t\tccp_free_data(&aad, cmd_q);\n\ne_ctx:\n\tccp_dm_free(&ctx);\n\ne_key:\n\tccp_dm_free(&key);\n\n\treturn ret;\n}",
        "func_hash": 164338035268758054525512134234222500237,
        "file_name": "ccp-ops.c",
        "file_hash": 220238669007539960746784666211129167889,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2021-3744",
        "cve_desc": "A memory leak flaw was found in the Linux kernel in the ccp_run_aes_gcm_cmd() function in drivers/crypto/ccp/ccp-ops.c, which allows attackers to cause a denial of service (memory consumption). This vulnerability is similar with the older CVE-2019-18808.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-3744",
        "func_name": "ccp_run_aes_gcm_cmd",
        "diff": [
            "diff --git a/drivers/crypto/ccp/ccp-ops.c b/drivers/crypto/ccp/ccp-ops.c\nindex bb88198c874e0e..aa4e1a5006919d 100644\n--- a/drivers/crypto/ccp/ccp-ops.c\n+++ b/drivers/crypto/ccp/ccp-ops.c\n@@ -778,7 +778,7 @@ ccp_run_aes_gcm_cmd(struct ccp_cmd_queue *cmd_q, struct ccp_cmd *cmd)\n \t\t\t\t    in_place ? DMA_BIDIRECTIONAL\n \t\t\t\t\t     : DMA_TO_DEVICE);\n \t\tif (ret)\n-\t\t\tgoto e_ctx;\n+\t\t\tgoto e_aad;\n \n \t\tif (in_place) {\n \t\t\tdst = src;\n@@ -863,7 +863,7 @@ ccp_run_aes_gcm_cmd(struct ccp_cmd_queue *cmd_q, struct ccp_cmd *cmd)\n \top.u.aes.size = 0;\n \tret = cmd_q->ccp->vdata->perform->aes(&op);\n \tif (ret)\n-\t\tgoto e_dst;\n+\t\tgoto e_final_wa;\n \n \tif (aes->action == CCP_AES_ACTION_ENCRYPT) {\n \t\t/* Put the ciphered tag after the ciphertext. */\n@@ -873,17 +873,19 @@ ccp_run_aes_gcm_cmd(struct ccp_cmd_queue *cmd_q, struct ccp_cmd *cmd)\n \t\tret = ccp_init_dm_workarea(&tag, cmd_q, authsize,\n \t\t\t\t\t   DMA_BIDIRECTIONAL);\n \t\tif (ret)\n-\t\t\tgoto e_tag;\n+\t\t\tgoto e_final_wa;\n \t\tret = ccp_set_dm_area(&tag, 0, p_tag, 0, authsize);\n-\t\tif (ret)\n-\t\t\tgoto e_tag;\n+\t\tif (ret) {\n+\t\t\tccp_dm_free(&tag);\n+\t\t\tgoto e_final_wa;\n+\t\t}\n \n \t\tret = crypto_memneq(tag.address, final_wa.address,\n \t\t\t\t    authsize) ? -EBADMSG : 0;\n \t\tccp_dm_free(&tag);\n \t}\n \n-e_tag:\n+e_final_wa:\n \tccp_dm_free(&final_wa);\n \n e_dst:\n"
        ],
        "func_after": []
    },
    {
        "idx": 197142,
        "project": "tensorflow",
        "commit_id": "6da6620efad397c85493b8f8667b821403516708",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/6da6620efad397c85493b8f8667b821403516708",
        "commit_message": "Secure tf.raw_ops.QuantizeV2\n\nValidate size and shape of min_range and max_range\nEnsure axis is within input dims limits\n\nPiperOrigin-RevId: 387232799\nChange-Id: I36975281f7b5758e9e31a8dcc73fe610ef456318",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor& input = ctx->input(0);\n    const Tensor& input_min_range = ctx->input(1);\n    const Tensor& input_max_range = ctx->input(2);\n\n    int num_slices = 1;\n    if (axis_ > -1) {\n      num_slices = input.dim_size(axis_);\n    }\n\n    const TensorShape& minmax_shape = ctx->input(1).shape();\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));\n\n    Tensor* output_min_tensor = nullptr;\n    Tensor* output_max_tensor = nullptr;\n\n    if (num_slices == 1) {\n      OP_REQUIRES_OK(ctx, ctx->allocate_output(1, {}, &output_min_tensor));\n      OP_REQUIRES_OK(ctx, ctx->allocate_output(2, {}, &output_max_tensor));\n      const float min_range = input_min_range.template flat<float>()(0);\n      const float max_range = input_max_range.template flat<float>()(0);\n      QuantizeTensor(ctx, input, min_range, max_range, output,\n                     output_min_tensor, output_max_tensor);\n      return;\n    }\n\n    OP_REQUIRES(ctx, mode_ != QUANTIZE_MODE_MIN_FIRST,\n                errors::Unimplemented(\"MIN_FIRST mode is not implemented for \"\n                                      \"Quantize with axis != -1.\"));\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_output(1, minmax_shape, &output_min_tensor));\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_output(2, minmax_shape, &output_max_tensor));\n\n    auto input_tensor =\n        input.template flat_inner_outer_dims<float, 3>(axis_ - 1);\n    int64_t pre_dim = 1, post_dim = 1;\n    for (int i = 0; i < axis_; ++i) {\n      pre_dim *= output->dim_size(i);\n    }\n    for (int i = axis_ + 1; i < output->dims(); ++i) {\n      post_dim *= output->dim_size(i);\n    }\n    auto output_tensor = output->template bit_casted_shaped<T, 3>(\n        {pre_dim, num_slices, post_dim});\n    auto min_ranges = input_min_range.template vec<float>();\n    auto max_ranges = input_max_range.template vec<float>();\n    for (int i = 0; i < num_slices; ++i) {\n      QuantizeSlice(ctx->eigen_device<Device>(), ctx,\n                    input_tensor.template chip<1>(i), min_ranges(i),\n                    max_ranges(i), output_tensor.template chip<1>(i),\n                    &output_min_tensor->flat<float>()(i),\n                    &output_max_tensor->flat<float>()(i));\n    }\n  }",
        "func_hash": 175054869100587978050053791864843631748,
        "file_name": "quantize_op.cc",
        "file_hash": 45910676002815731564213734124644481802,
        "cwe": [
            "CWE-476"
        ],
        "cve": "CVE-2021-37663",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions due to incomplete validation in `tf.raw_ops.QuantizeV2`, an attacker can trigger undefined behavior via binding a reference to a null pointer or can access data outside the bounds of heap allocated arrays. The [implementation](https://github.com/tensorflow/tensorflow/blob/84d053187cb80d975ef2b9684d4b61981bca0c41/tensorflow/core/kernels/quantize_op.cc#L59) has some validation but does not check that `min_range` and `max_range` both have the same non-zero number of elements. If `axis` is provided (i.e., not `-1`), then validation should check that it is a value in range for the rank of `input` tensor and then the lengths of `min_range` and `max_range` inputs match the `axis` dimension of the `input` tensor. We have patched the issue in GitHub commit 6da6620efad397c85493b8f8667b821403516708. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37663",
        "func_name": "Compute",
        "diff": [
            "diff --git a/tensorflow/core/kernels/quantize_op.cc b/tensorflow/core/kernels/quantize_op.cc\nindex f64a2188fa9547..be73d4f8291f7b 100644\n--- a/tensorflow/core/kernels/quantize_op.cc\n+++ b/tensorflow/core/kernels/quantize_op.cc\n@@ -113,7 +113,50 @@ class QuantizeV2Op : public OpKernel {\n \n     int num_slices = 1;\n     if (axis_ > -1) {\n+      OP_REQUIRES(\n+          ctx, input.dims() > axis_,\n+          errors::InvalidArgument(\n+              \"Axis is on a zero-based index, so its value must always be less \"\n+              \"than number of input's dims, but given axis value was \",\n+              axis_, \" and input's dims was \", input.dims()));\n       num_slices = input.dim_size(axis_);\n+      OP_REQUIRES(ctx, input_min_range.dims() == 1,\n+                  errors::InvalidArgument(\n+                      \"If axis is specified, min_range must be a 1-D tensor \"\n+                      \"whose size matches the axis dimension of the input and \"\n+                      \"output tensors, but min_range dims are \",\n+                      input_min_range.dims()));\n+      OP_REQUIRES(ctx, input_min_range.dim_size(0) == num_slices,\n+                  errors::InvalidArgument(\n+                      \"If axis is specified, min_range must be a 1-D tensor \"\n+                      \"whose size matches the axis dimension of the input and \"\n+                      \"output tensors, but min_range is a 1-D tensor of size \",\n+                      input_min_range.dim_size(0),\n+                      \" and input's axis dimension is of size \", num_slices));\n+      OP_REQUIRES(ctx, input_max_range.dims() == 1,\n+                  errors::InvalidArgument(\n+                      \"If axis is specified, max_range must be a 1-D tensor \"\n+                      \"whose size matches the axis dimension of the input and \"\n+                      \"output tensors, but max_range dims are \",\n+                      input_max_range.dims()));\n+      OP_REQUIRES(ctx, input_max_range.dim_size(0) == num_slices,\n+                  errors::InvalidArgument(\n+                      \"If axis is specified, max_range must be a 1-D tensor \"\n+                      \"whose size matches the axis dimension of the input and \"\n+                      \"output tensors, but max_range is a 1-D tensor of size \",\n+                      input_max_range.dim_size(0),\n+                      \" and input's axis dimension is of size \", num_slices));\n+    } else {\n+      OP_REQUIRES(ctx, input_min_range.NumElements() == 1,\n+                  errors::InvalidArgument(\n+                      \"If axis is not specified, min_range must contain a \"\n+                      \"single float element, but it contains \",\n+                      input_min_range.NumElements(), \" elements\"));\n+      OP_REQUIRES(ctx, input_max_range.NumElements() == 1,\n+                  errors::InvalidArgument(\n+                      \"If axis is not specified, max_range must contain a \"\n+                      \"single float element, but it contains \",\n+                      input_max_range.NumElements(), \" elements\"));\n     }\n \n     const TensorShape& minmax_shape = ctx->input(1).shape();\n"
        ],
        "func_after": []
    },
    {
        "idx": 197185,
        "project": "FFmpeg",
        "commit_id": "9ffa49496d1aae4cbbb387aac28a9e061a6ab0a6",
        "project_url": "https://github.com/FFmpeg/FFmpeg",
        "commit_url": "https://github.com/FFmpeg/FFmpeg/commit/9ffa49496d1aae4cbbb387aac28a9e061a6ab0a6",
        "commit_message": "avformat/adtsenc: return value check for init_get_bits in adts_decode_extradata\n\nAs the second argument for init_get_bits (buf) can be crafted, a return value check for this function call is necessary.\n'buf' is  part of  'AVPacket pkt'.\nreplace init_get_bits with init_get_bits8.\n\nSigned-off-by: Michael Niedermayer <michael@niedermayer.cc>",
        "target": 1,
        "irrelevant": 1,
        "func_before": "static int adts_decode_extradata(AVFormatContext *s, ADTSContext *adts, const uint8_t *buf, int size)\n{\n    GetBitContext gb;\n    PutBitContext pb;\n    MPEG4AudioConfig m4ac;\n    int off;\n\n    init_get_bits(&gb, buf, size * 8);\n    off = avpriv_mpeg4audio_get_config2(&m4ac, buf, size, 1, s);\n    if (off < 0)\n        return off;\n    skip_bits_long(&gb, off);\n    adts->objecttype        = m4ac.object_type - 1;\n    adts->sample_rate_index = m4ac.sampling_index;\n    adts->channel_conf      = m4ac.chan_config;\n\n    if (adts->objecttype > 3U) {\n        av_log(s, AV_LOG_ERROR, \"MPEG-4 AOT %d is not allowed in ADTS\\n\", adts->objecttype+1);\n        return AVERROR_INVALIDDATA;\n    }\n    if (adts->sample_rate_index == 15) {\n        av_log(s, AV_LOG_ERROR, \"Escape sample rate index illegal in ADTS\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n    if (get_bits(&gb, 1)) {\n        av_log(s, AV_LOG_ERROR, \"960/120 MDCT window is not allowed in ADTS\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n    if (get_bits(&gb, 1)) {\n        av_log(s, AV_LOG_ERROR, \"Scalable configurations are not allowed in ADTS\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n    if (get_bits(&gb, 1)) {\n        av_log(s, AV_LOG_ERROR, \"Extension flag is not allowed in ADTS\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n    if (!adts->channel_conf) {\n        init_put_bits(&pb, adts->pce_data, MAX_PCE_SIZE);\n\n        put_bits(&pb, 3, 5); //ID_PCE\n        adts->pce_size = (ff_copy_pce_data(&pb, &gb) + 3) / 8;\n        flush_put_bits(&pb);\n    }\n\n    adts->write_adts = 1;\n\n    return 0;\n}",
        "func_hash": 158925528540777233957652669648532881464,
        "file_name": "adtsenc.c",
        "file_hash": null,
        "cwe": [
            "CWE-252"
        ],
        "cve": "CVE-2021-38171",
        "cve_desc": "adts_decode_extradata in libavformat/adtsenc.c in FFmpeg 4.4 does not check the init_get_bits return value, which is a necessary step because the second argument to init_get_bits can be crafted.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-38171",
        "func_name": "adts_decode_extradata",
        "diff": [
            "diff --git a/libavformat/adtsenc.c b/libavformat/adtsenc.c\nindex ba15c0a72494e..3924e678d917d 100644\n--- a/libavformat/adtsenc.c\n+++ b/libavformat/adtsenc.c\n@@ -53,9 +53,11 @@ static int adts_decode_extradata(AVFormatContext *s, ADTSContext *adts, const ui\n     GetBitContext gb;\n     PutBitContext pb;\n     MPEG4AudioConfig m4ac;\n-    int off;\n+    int off, ret;\n \n-    init_get_bits(&gb, buf, size * 8);\n+    ret = init_get_bits8(&gb, buf, size);\n+    if (ret < 0)\n+        return ret;\n     off = avpriv_mpeg4audio_get_config2(&m4ac, buf, size, 1, s);\n     if (off < 0)\n         return off;\n"
        ],
        "func_after": []
    },
    {
        "idx": 197223,
        "project": "njs",
        "commit_id": "ab1702c7af9959366a5ddc4a75b4357d4e9ebdc1",
        "project_url": "https://github.com/nginx/njs",
        "commit_url": "https://github.com/nginx/njs/commit/ab1702c7af9959366a5ddc4a75b4357d4e9ebdc1",
        "commit_message": "Fixed typo while calculating module path length.\n\nThe issue was introduced in 77c398f26d7e (not released yet).",
        "target": 1,
        "irrelevant": 0,
        "func_before": "njs_module_path(njs_vm_t *vm, const njs_str_t *dir, njs_module_info_t *info)\n{\n    char        *p;\n    size_t      length;\n    njs_bool_t  trail;\n    char        src[NJS_MAX_PATH + 1];\n\n    trail = 0;\n    length = info->name.length;\n\n    if (dir != NULL) {\n        length = dir->length;\n\n        if (length == 0) {\n            return NJS_DECLINED;\n        }\n\n        trail = (dir->start[dir->length - 1] != '/');\n\n        if (trail) {\n            length++;\n        }\n    }\n\n    if (njs_slow_path(length > NJS_MAX_PATH)) {\n        return NJS_ERROR;\n    }\n\n    p = &src[0];\n\n    if (dir != NULL) {\n        p = (char *) njs_cpymem(p, dir->start, dir->length);\n\n        if (trail) {\n            *p++ = '/';\n        }\n    }\n\n    p = (char *) njs_cpymem(p, info->name.start, info->name.length);\n    *p = '\\0';\n\n    p = realpath(&src[0], &info->path[0]);\n    if (p == NULL) {\n        return NJS_DECLINED;\n    }\n\n    info->fd = open(&info->path[0], O_RDONLY);\n    if (info->fd < 0) {\n        return NJS_DECLINED;\n    }\n\n\n    info->file.start = (u_char *) &info->path[0];\n    info->file.length = njs_strlen(info->file.start);\n\n    return NJS_OK;\n}",
        "func_hash": 236847431367932249474325490160608146650,
        "file_name": "njs_module.c",
        "file_hash": 230069477074111336405443824718201036517,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2022-29379",
        "cve_desc": "Nginx NJS v0.7.3 was discovered to contain a stack overflow in the function njs_default_module_loader at /src/njs/src/njs_module.c. NOTE: multiple third parties dispute this report, e.g., the behavior is only found in unreleased development code that was not part of the 0.7.2, 0.7.3, or 0.7.4 release",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-29379",
        "func_name": "njs_module_path",
        "diff": [
            "diff --git a/src/njs_module.c b/src/njs_module.c\nindex 16e29a57b..78206b3ba 100644\n--- a/src/njs_module.c\n+++ b/src/njs_module.c\n@@ -118,7 +118,7 @@ njs_module_path(njs_vm_t *vm, const njs_str_t *dir, njs_module_info_t *info)\n     length = info->name.length;\n \n     if (dir != NULL) {\n-        length = dir->length;\n+        length += dir->length;\n \n         if (length == 0) {\n             return NJS_DECLINED;\ndiff --git a/test/js/import_very_long_path.t.js b/test/js/import_very_long_path.t.js\nnew file mode 100644\nindex 000000000..a2a3ebff5\n--- /dev/null\n+++ b/test/js/import_very_long_path.t.js\n@@ -0,0 +1,9 @@\n+/*---\n+: []\n+paths: [test/js/module/]\n+negative:\n+  phase: runtime\n+---*/\n+\n+import name from 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx';\n+ \n"
        ],
        "func_after": []
    },
    {
        "idx": 197239,
        "project": "tensorflow",
        "commit_id": "203214568f5bc237603dbab6e1fd389f1572f5c9",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/203214568f5bc237603dbab6e1fd389f1572f5c9",
        "commit_message": "Reorganize and add more validation to MKL requantization\n\nPiperOrigin-RevId: 387901341\nChange-Id: I2515b9034c64e113db0bcec8337d30643ab0a0f1",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext* ctx) override {\n    try {\n      const Tensor& input = ctx->input(kInputTensorIndex);\n      const Tensor& input_min_vec = ctx->input(kInputMinVecIndex);\n      float* input_min_vec_data = (float*)const_cast<void*>(\n          static_cast<const void*>(input_min_vec.flat<float>().data()));\n      const Tensor& input_max_vec = ctx->input(kInputMaxVecIndex);\n      float* input_max_vec_data = (float*)const_cast<void*>(\n          static_cast<const void*>(input_max_vec.flat<float>().data()));\n\n      const Tensor& input_requested_min = ctx->input(this->kRequestMinIndex);\n      const float input_requested_min_float =\n          input_requested_min.flat<float>()(0);\n      const Tensor& input_requested_max = ctx->input(this->kRequestMaxIndex);\n      const float input_requested_max_float =\n          input_requested_max.flat<float>()(0);\n\n      size_t depth = input_min_vec.NumElements();\n      OP_REQUIRES(\n          ctx, input.dims() == 4,\n          errors::InvalidArgument(\"Current RequantizePerChannel operator\"\n                                  \"supports 4D tensors only.\"));\n      OP_REQUIRES(\n          ctx, input_min_vec.dim_size(0) == depth,\n          errors::InvalidArgument(\"input_min has incorrect size, expected \",\n                                  depth, \" was \", input_min_vec.dim_size(0)));\n      OP_REQUIRES(\n          ctx, input_max_vec.dim_size(0) == depth,\n          errors::InvalidArgument(\"input_max has incorrect size, expected \",\n                                  depth, \" was \", input_max_vec.dim_size(0)));\n\n      if (out_type_ == DT_QINT8) DCHECK(input_requested_min_float < 0.0f);\n\n      const float factor = (out_type_ == DT_QINT8) ? 127.0f : 255.0f;\n      const float requested_min_max =\n          std::max(std::abs(input_requested_min_float),\n                   std::abs(input_requested_max_float));\n      Tensor* output = nullptr;\n      OP_REQUIRES_OK(ctx, ctx->allocate_output(kOutputTensorIndex,\n                                               input.shape(), &output));\n\n      std::vector<float> scales(depth);\n      for (int i = 0; i < depth; ++i) {\n        float min_max_from_vec = std::max(std::abs(input_min_vec_data[i]),\n                                          std::abs(input_max_vec_data[i]));\n        scales[i] = factor * (min_max_from_vec / requested_min_max /\n                              static_cast<float>(1L << 31));\n      }\n\n      mkldnn::primitive_attr reorder_attr;\n      reorder_attr.set_output_scales(2, scales);\n\n      memory::dims dims_mkl_order =\n          TFShapeToMklDnnDimsInNCHW(input.shape(), FORMAT_NHWC);\n      memory::desc input_md = memory::desc(dims_mkl_order, MklDnnType<qint32>(),\n                                           memory::format_tag::nhwc);\n      memory::desc output_md =\n          (out_type_ == DT_QINT8)\n              ? memory::desc(dims_mkl_order, MklDnnType<qint8>(),\n                             memory::format_tag::nhwc)\n              : memory::desc(dims_mkl_order, MklDnnType<quint8>(),\n                             memory::format_tag::nhwc);\n\n      void* input_buf =\n          static_cast<void*>(const_cast<qint32*>(input.flat<qint32>().data()));\n      void* output_buf;\n      if (out_type_ == DT_QINT8) {\n        output_buf = static_cast<void*>(\n            const_cast<qint8*>(output->flat<qint8>().data()));\n      } else {\n        output_buf = static_cast<void*>(\n            const_cast<quint8*>(output->flat<quint8>().data()));\n      }\n\n      std::unique_ptr<memory> input_mem_prim(\n          new memory(input_md, cpu_engine_, input_buf));\n      std::unique_ptr<memory> output_mem_prim(\n          new memory(output_md, cpu_engine_, output_buf));\n\n      mkldnn::reorder::primitive_desc reorder_pd =\n          ReorderPd(cpu_engine_, input_mem_prim->get_desc(), cpu_engine_,\n                    output_mem_prim->get_desc(), reorder_attr);\n      std::shared_ptr<stream> reorder_stream;\n      MklDnnThreadPool eigen_tp(ctx);\n      reorder_stream.reset(CreateStream(&eigen_tp, cpu_engine_));\n      std::unordered_map<int, mkldnn::memory> reorder_args = {\n          {MKLDNN_ARG_FROM, *input_mem_prim},\n          {MKLDNN_ARG_TO, *output_mem_prim}};\n      std::unique_ptr<mkldnn::primitive> reorder_prim(\n          new mkldnn::reorder(reorder_pd));\n      reorder_prim->execute(*reorder_stream, reorder_args);\n\n      Tensor* output_min = nullptr;\n      Tensor* output_max = nullptr;\n      OP_REQUIRES_OK(ctx,\n                     ctx->allocate_output(kOutputMinIndex, {}, &output_min));\n      OP_REQUIRES_OK(ctx,\n                     ctx->allocate_output(kOutputMaxIndex, {}, &output_max));\n\n      output_min->flat<float>()(0) = input_requested_min_float;\n      output_max->flat<float>()(0) = input_requested_max_float;\n    } catch (mkldnn::error& e) {\n      string error_msg = \"Status: \" + std::to_string(e.status) +\n                         \", message: \" + std::string(e.message) + \", in file \" +\n                         std::string(__FILE__) + \":\" + std::to_string(__LINE__);\n      OP_REQUIRES_OK(\n          ctx, errors::Aborted(\"Operation received an exception:\", error_msg));\n    }\n  }",
        "func_hash": 324241400481110766657474950076141174434,
        "file_name": "mkl_requantize_per_channel_op.cc",
        "file_hash": 251676487738280920031977890166955496760,
        "cwe": [
            "CWE-20"
        ],
        "cve": "CVE-2021-37665",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions due to incomplete validation in MKL implementation of requantization, an attacker can trigger undefined behavior via binding a reference to a null pointer or can access data outside the bounds of heap allocated arrays. The [implementation](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/core/kernels/mkl/mkl_requantization_range_per_channel_op.cc) does not validate the dimensions of the `input` tensor. A similar issue occurs in `MklRequantizePerChannelOp`. The [implementation](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/core/kernels/mkl/mkl_requantize_per_channel_op.cc) does not perform full validation for all the input arguments. We have patched the issue in GitHub commit 9e62869465573cb2d9b5053f1fa02a81fce21d69 and in the Github commit 203214568f5bc237603dbab6e1fd389f1572f5c9. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37665",
        "func_name": "Compute",
        "diff": [
            "diff --git a/tensorflow/core/kernels/mkl/mkl_requantize_per_channel_op.cc b/tensorflow/core/kernels/mkl/mkl_requantize_per_channel_op.cc\nindex c0f9845cd4b084..6ffbd09b44f543 100644\n--- a/tensorflow/core/kernels/mkl/mkl_requantize_per_channel_op.cc\n+++ b/tensorflow/core/kernels/mkl/mkl_requantize_per_channel_op.cc\n@@ -49,35 +49,45 @@ class MklRequantizePerChannelOp : public OpKernel {\n   void Compute(OpKernelContext* ctx) override {\n     try {\n       const Tensor& input = ctx->input(kInputTensorIndex);\n+      OP_REQUIRES(\n+          ctx, input.dims() == 4,\n+          errors::InvalidArgument(\"Current RequantizePerChannel operator\"\n+                                  \"supports 4D tensors only.\"));\n+\n       const Tensor& input_min_vec = ctx->input(kInputMinVecIndex);\n+      size_t depth = input_min_vec.NumElements();\n       float* input_min_vec_data = (float*)const_cast<void*>(\n           static_cast<const void*>(input_min_vec.flat<float>().data()));\n+\n       const Tensor& input_max_vec = ctx->input(kInputMaxVecIndex);\n+      OP_REQUIRES(\n+          ctx, input_max_vec.NumElements() == depth,\n+          errors::InvalidArgument(\"input_max has incorrect size, expected \",\n+                                  depth, \" was \", input_max_vec.NumElements()));\n       float* input_max_vec_data = (float*)const_cast<void*>(\n           static_cast<const void*>(input_max_vec.flat<float>().data()));\n \n       const Tensor& input_requested_min = ctx->input(this->kRequestMinIndex);\n+      OP_REQUIRES(\n+          ctx, input_requested_min.NumElements() == 1,\n+          errors::InvalidArgument(\"requested_output_min must be a scalar\"));\n       const float input_requested_min_float =\n           input_requested_min.flat<float>()(0);\n+\n       const Tensor& input_requested_max = ctx->input(this->kRequestMaxIndex);\n+      OP_REQUIRES(\n+          ctx, input_requested_min.NumElements() == 1,\n+          errors::InvalidArgument(\"requested_output_max must be a scalar\"));\n       const float input_requested_max_float =\n           input_requested_max.flat<float>()(0);\n \n-      size_t depth = input_min_vec.NumElements();\n-      OP_REQUIRES(\n-          ctx, input.dims() == 4,\n-          errors::InvalidArgument(\"Current RequantizePerChannel operator\"\n-                                  \"supports 4D tensors only.\"));\n-      OP_REQUIRES(\n-          ctx, input_min_vec.dim_size(0) == depth,\n-          errors::InvalidArgument(\"input_min has incorrect size, expected \",\n-                                  depth, \" was \", input_min_vec.dim_size(0)));\n-      OP_REQUIRES(\n-          ctx, input_max_vec.dim_size(0) == depth,\n-          errors::InvalidArgument(\"input_max has incorrect size, expected \",\n-                                  depth, \" was \", input_max_vec.dim_size(0)));\n-\n-      if (out_type_ == DT_QINT8) DCHECK(input_requested_min_float < 0.0f);\n+      if (out_type_ == DT_QINT8) {\n+        OP_REQUIRES(ctx, input_requested_min_float < 0.0f,\n+                    errors::InvalidArgument(\n+                        \"If out_type is QINT8, requested_output_max must be \"\n+                        \"non negative, got \",\n+                        input_requested_min_float));\n+      }\n \n       const float factor = (out_type_ == DT_QINT8) ? 127.0f : 255.0f;\n       const float requested_min_max =\n"
        ],
        "func_after": []
    },
    {
        "idx": 197242,
        "project": "tensorflow",
        "commit_id": "537bc7c723439b9194a358f64d871dd326c18887",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/537bc7c723439b9194a358f64d871dd326c18887",
        "commit_message": "Fix a null pointer exception caused by branching on uninitialized data.\n\nThis is due to not checking that the params for the quantization exists. If there is no quantization, we should not access the `.params` field.\n\nPiperOrigin-RevId: 385163909\nChange-Id: I2beb8d50649b6542db224c163033fbcbaa49314f",
        "target": 1,
        "irrelevant": 0,
        "func_before": "TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n  const auto* params = reinterpret_cast<TfLiteSVDFParams*>(node->builtin_data);\n  OpData* op_data = reinterpret_cast<OpData*>(node->user_data);\n  int scratch_tensor_index = op_data->scratch_tensor_index;\n\n  // Check we have all the inputs and outputs we need.\n  TF_LITE_ENSURE_EQ(context, node->outputs->size, 1);\n  TF_LITE_ENSURE_EQ(context, node->inputs->size, 5);\n\n  const TfLiteTensor* input;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n  const TfLiteTensor* weights_feature;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kWeightsFeatureTensor,\n                                          &weights_feature));\n  const TfLiteTensor* weights_time;\n  TF_LITE_ENSURE_OK(\n      context, GetInputSafe(context, node, kWeightsTimeTensor, &weights_time));\n\n  TF_LITE_ENSURE(context,\n                 input->type == kTfLiteFloat32 || input->type == kTfLiteInt8);\n\n  // Check all the parameters of tensor match within themselves and match the\n  // input configuration.\n  const int rank = params->rank;\n  const int batch_size = input->dims->data[0];\n  const int num_filters = weights_feature->dims->data[0];\n  TF_LITE_ENSURE(context, rank != 0);\n  TF_LITE_ENSURE_EQ(context, num_filters % rank, 0);\n  const int num_units = num_filters / rank;\n  const int memory_size = weights_time->dims->data[1];\n  TF_LITE_ENSURE_EQ(context, input->dims->data[1],\n                    weights_feature->dims->data[1]);\n  TF_LITE_ENSURE_EQ(context, weights_time->dims->data[0], num_filters);\n\n  const TfLiteTensor* bias = GetOptionalInputTensor(context, node, kBiasTensor);\n  if (bias) {\n    TF_LITE_ENSURE_EQ(context, bias->dims->data[0], num_units);\n  }\n\n  const TfLiteTensor* state;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kStateTensor, &state));\n  TfLiteTensor* output;\n  TF_LITE_ENSURE_OK(context,\n                    GetOutputSafe(context, node, kOutputTensor, &output));\n\n  // Check the shape of input state tensors.\n  TF_LITE_ENSURE_EQ(context, NumDimensions(state), 2);\n  TF_LITE_ENSURE_EQ(context, SizeOfDimension(state, 0), batch_size);\n  TF_LITE_ENSURE_EQ(context, SizeOfDimension(state, 1),\n                    memory_size * num_filters);\n\n  // Resize output.\n  TfLiteIntArray* output_size_array = TfLiteIntArrayCreate(2);\n  output_size_array->data[0] = batch_size;\n  output_size_array->data[1] = num_units;\n  TF_LITE_ENSURE_OK(context,\n                    context->ResizeTensor(context, output, output_size_array));\n\n  // The weights are of consistent type, so it suffices to check one.\n  const bool is_hybrid_op = IsHybridOp(input, weights_feature);\n  const bool is_full_integer = input->type == kTfLiteInt8;\n\n  // Resize scratch.\n  TfLiteIntArrayFree(node->temporaries);\n  if (is_hybrid_op) {\n    node->temporaries = TfLiteIntArrayCreate(6);\n  } else if (is_full_integer) {\n    node->temporaries = TfLiteIntArrayCreate(2);\n  } else {\n    node->temporaries = TfLiteIntArrayCreate(1);\n  }\n  node->temporaries->data[0] = scratch_tensor_index;\n\n  TfLiteIntArray* scratch_size_array = TfLiteIntArrayCreate(2);\n  scratch_size_array->data[0] = batch_size;\n  scratch_size_array->data[1] = num_filters;\n\n  TfLiteTensor* scratch_tensor;\n  TF_LITE_ENSURE_OK(\n      context, GetTemporarySafe(context, node, /*index=*/0, &scratch_tensor));\n\n  // The scratch buffer is of type int32 for full integer svdf and it's of type\n  // float32 for hybrid and float case.\n  if (is_full_integer) {\n    scratch_tensor->type = kTfLiteInt32;\n  } else {\n    scratch_tensor->type = kTfLiteFloat32;\n  }\n  scratch_tensor->allocation_type = kTfLiteArenaRw;\n  TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, scratch_tensor,\n                                                   scratch_size_array));\n\n  if (is_hybrid_op) {\n    op_data->compute_row_sums = true;\n    // Tell interpreter to allocate temporary tensors to store quantized values\n    // of input tensors.\n    node->temporaries->data[1] = scratch_tensor_index + 1;\n    TfLiteTensor* input_quantized;\n    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/1,\n                                                &input_quantized));\n    input_quantized->type = weights_feature->type;\n    input_quantized->allocation_type = kTfLiteArenaRw;\n    if (!TfLiteIntArrayEqual(input_quantized->dims, input->dims)) {\n      TfLiteIntArray* input_quantized_size = TfLiteIntArrayCopy(input->dims);\n      TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, input_quantized,\n                                                       input_quantized_size));\n    }\n\n    // Tell interpreter to allocate temporary tensors to store scaling factors.\n    node->temporaries->data[2] = scratch_tensor_index + 2;\n    TfLiteTensor* scaling_factors;\n    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/2,\n                                                &scaling_factors));\n    scaling_factors->type = kTfLiteFloat32;\n    scaling_factors->allocation_type = kTfLiteArenaRw;\n    int scaling_dims[1] = {batch_size};\n    if (!TfLiteIntArrayEqualsArray(scaling_factors->dims, 1, scaling_dims)) {\n      TfLiteIntArray* scaling_factors_size = TfLiteIntArrayCreate(1);\n      scaling_factors_size->data[0] = batch_size;\n      TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, scaling_factors,\n                                                       scaling_factors_size));\n    }\n\n    // Used to store dequantized weights_time matrix for hybrid computation of\n    // matmul(state, weights_time), which occurs in floating point.\n    node->temporaries->data[3] = scratch_tensor_index + 3;\n    TfLiteTensor* float_weights_time;\n    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/3,\n                                                &float_weights_time));\n    float_weights_time->type = kTfLiteFloat32;\n    // Persistent so that we can compute the dequantized weights only once.\n    float_weights_time->allocation_type = kTfLiteArenaRwPersistent;\n    if (!TfLiteIntArrayEqual(float_weights_time->dims, weights_time->dims)) {\n      TfLiteIntArray* float_weights_time_size =\n          TfLiteIntArrayCopy(weights_time->dims);\n      TF_LITE_ENSURE_OK(context,\n                        context->ResizeTensor(context, float_weights_time,\n                                              float_weights_time_size));\n    }\n\n    node->temporaries->data[4] = scratch_tensor_index + 4;\n    TfLiteTensor* zero_points;\n    TF_LITE_ENSURE_OK(\n        context, GetTemporarySafe(context, node, /*index=*/4, &zero_points));\n    zero_points->type = kTfLiteFloat32;\n    zero_points->allocation_type = kTfLiteArenaRw;\n    int zero_points_dims[1] = {batch_size};\n    if (!TfLiteIntArrayEqualsArray(zero_points->dims, 1, zero_points_dims)) {\n      TfLiteIntArray* zero_points_size = TfLiteIntArrayCreate(1);\n      zero_points_size->data[0] = zero_points_dims[0];\n      TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, zero_points,\n                                                       zero_points_size));\n    }\n\n    node->temporaries->data[5] = scratch_tensor_index + 5;\n    TfLiteTensor* row_sums;\n    TF_LITE_ENSURE_OK(context,\n                      GetTemporarySafe(context, node, /*index=*/5, &row_sums));\n    row_sums->type = kTfLiteFloat32;\n    row_sums->allocation_type = kTfLiteArenaRwPersistent;\n    int row_sums_dims[1] = {num_filters};\n    if (!TfLiteIntArrayEqualsArray(row_sums->dims, 1, row_sums_dims)) {\n      TfLiteIntArray* row_sums_size = TfLiteIntArrayCreate(1);\n      row_sums_size->data[0] = row_sums_dims[0];\n      TF_LITE_ENSURE_OK(\n          context, context->ResizeTensor(context, row_sums, row_sums_size));\n    }\n  }\n  if (is_full_integer) {\n    // Allocated one extra tensor.\n    TfLiteIntArray* output_temp_size_array = TfLiteIntArrayCreate(2);\n    output_temp_size_array->data[0] = num_units;\n    output_temp_size_array->data[1] = batch_size;\n    node->temporaries->data[1] = scratch_tensor_index + 1;\n    TfLiteTensor* output_temp;\n    TF_LITE_ENSURE_OK(\n        context, GetTemporarySafe(context, node, /*index=*/1, &output_temp));\n    output_temp->type = kTfLiteInt32;\n    output_temp->allocation_type = kTfLiteArenaRw;\n    TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, output_temp,\n                                                     output_temp_size_array));\n\n    // Calculate effective scales.\n    auto* input_params =\n        reinterpret_cast<TfLiteAffineQuantization*>(input->quantization.params);\n    auto* weights_feature_params = reinterpret_cast<TfLiteAffineQuantization*>(\n        weights_feature->quantization.params);\n    auto* state_params =\n        reinterpret_cast<TfLiteAffineQuantization*>(state->quantization.params);\n    auto* weight_time_params = reinterpret_cast<TfLiteAffineQuantization*>(\n        weights_time->quantization.params);\n    auto* output_params = reinterpret_cast<TfLiteAffineQuantization*>(\n        output->quantization.params);\n    const double effective_scale_1 = input_params->scale->data[0] *\n                                     weights_feature_params->scale->data[0] /\n                                     state_params->scale->data[0];\n    const double effective_scale_2 = state_params->scale->data[0] *\n                                     weight_time_params->scale->data[0] /\n                                     output_params->scale->data[0];\n    QuantizeMultiplier(effective_scale_1, &op_data->effective_scale_1_a,\n                       &op_data->effective_scale_1_b);\n    QuantizeMultiplier(effective_scale_2, &op_data->effective_scale_2_a,\n                       &op_data->effective_scale_2_b);\n  }\n  return kTfLiteOk;\n}",
        "func_hash": 233995710646174347190469029723118566827,
        "file_name": "svdf.cc",
        "file_hash": 151141611170941646620182312728274364600,
        "cwe": [
            "CWE-908"
        ],
        "cve": "CVE-2021-37682",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions all TFLite operations that use quantization can be made to use unitialized values. [For example](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/lite/kernels/depthwise_conv.cc#L198-L200). The issue stems from the fact that `quantization.params` is only valid if `quantization.type` is different that `kTfLiteNoQuantization`. However, these checks are missing in large parts of the code. We have patched the issue in GitHub commits 537bc7c723439b9194a358f64d871dd326c18887, 4a91f2069f7145aab6ba2d8cfe41be8a110c18a5 and 8933b8a21280696ab119b63263babdb54c298538. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37682",
        "func_name": "Prepare",
        "diff": [
            "diff --git a/tensorflow/lite/kernels/svdf.cc b/tensorflow/lite/kernels/svdf.cc\nindex 6c02508e26b1da..41a71c54a8c922 100644\n--- a/tensorflow/lite/kernels/svdf.cc\n+++ b/tensorflow/lite/kernels/svdf.cc\n@@ -256,14 +256,21 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n                                                      output_temp_size_array));\n \n     // Calculate effective scales.\n+    TF_LITE_ENSURE(context, input->quantization.type != kTfLiteNoQuantization);\n     auto* input_params =\n         reinterpret_cast<TfLiteAffineQuantization*>(input->quantization.params);\n+    TF_LITE_ENSURE(context,\n+                   weights_feature->quantization.type != kTfLiteNoQuantization);\n     auto* weights_feature_params = reinterpret_cast<TfLiteAffineQuantization*>(\n         weights_feature->quantization.params);\n+    TF_LITE_ENSURE(context, state->quantization.type != kTfLiteNoQuantization);\n     auto* state_params =\n         reinterpret_cast<TfLiteAffineQuantization*>(state->quantization.params);\n+    TF_LITE_ENSURE(context,\n+                   weights_time->quantization.type != kTfLiteNoQuantization);\n     auto* weight_time_params = reinterpret_cast<TfLiteAffineQuantization*>(\n         weights_time->quantization.params);\n+    TF_LITE_ENSURE(context, output->quantization.type != kTfLiteNoQuantization);\n     auto* output_params = reinterpret_cast<TfLiteAffineQuantization*>(\n         output->quantization.params);\n     const double effective_scale_1 = input_params->scale->data[0] *\n"
        ],
        "func_after": []
    },
    {
        "idx": 197247,
        "project": "tensorflow",
        "commit_id": "ee119d4a498979525046fba1c3dd3f13a039fbb1",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/ee119d4a498979525046fba1c3dd3f13a039fbb1",
        "commit_message": "Fix segmentation fault in shape inference logic.\n\nWhen running shape functions, some functions (such as `MutableHashTableShape`)\nproduce extra output information in the form of a `ShapeAndType` struct.  The\nshapes embedded in this struct are owned by an inference context that is\ncleaned up almost immediately; if the upstream code attempts to access this\nshape information, it can trigger a segfault.\n\n`ShapeRefiner` is mitigating this for normal output shapes by cloning them\n(and thus putting the newly created shape under ownership of an inference\ncontext that will not die), but we were not doing the same for shapes and\ntypes.  This commit fixes that by doing similar logic on output shapes and\ntypes.\n\nPiperOrigin-RevId: 384761124\nChange-Id: I07c0c42d29dfbb55bfa13ec1f09ef825fb0a1a1d",
        "target": 1,
        "irrelevant": 1,
        "func_before": "Status ShapeRefiner::InferShapesForFunctionSubNode(\n    const Node* node, InferenceContext* outer_context) {\n  TF_RETURN_IF_ERROR(AddNodeInternal(node, outer_context));\n  InferenceContext* node_context = CHECK_NOTNULL(GetContext(node));\n\n  if (StringPiece(node->type_string()) == kArgOp) {\n    // Handle special node: function input.\n    // Shapes for these nodes are provided in the outer inference\n    // context.\n\n    int index;\n    TF_RETURN_IF_ERROR(GetNodeAttr(AttrSlice(node->def()), \"index\", &index));\n\n    if (index < 0 || outer_context->num_inputs() <= index) {\n      return errors::Internal(\n          \"Function instantiation included invalid input index: \", index,\n          \" not in [0, \", outer_context->num_inputs(), \").\");\n    }\n\n    // TODO(b/134547156): TEMPORARY WORKAROUND. If input shape handle is not set\n    // in outer context, set _Arg node output shape to unknown.\n    if (outer_context->input(index).SameHandle(ShapeHandle())) {\n      VLOG(1) << \"Function instantiation has undefined input shape at \"\n              << \"index: \" << index << \" in the outer inference context.\";\n      node_context->set_output(0, node_context->UnknownShape());\n    } else {\n      node_context->set_output(0, outer_context->input(index));\n    }\n\n    auto* resource = outer_context->input_handle_shapes_and_types(index);\n    if (resource) {\n      node_context->set_output_handle_shapes_and_types(0, *resource);\n    }\n  } else if (StringPiece(node->type_string()) == kRetvalOp) {\n    // Handle special node: function output.\n    // Shapes inferred for these nodes go into the outer inference\n    // context.\n\n    int index;\n    TF_RETURN_IF_ERROR(GetNodeAttr(AttrSlice(node->def()), \"index\", &index));\n\n    if (index < 0 || outer_context->num_outputs() <= index) {\n      return errors::Internal(\n          \"Function instantiation included invalid output index: \", index,\n          \" not in [0, \", outer_context->num_outputs(), \").\");\n    }\n\n    // outer_context outlives node_context, therefore we need to create\n    // a new shape handle owned by outer_context instead.\n    ShapeHandle handle;\n    TensorShapeProto proto;\n    node_context->ShapeHandleToProto(node_context->input(0), &proto);\n    TF_RETURN_IF_ERROR(outer_context->MakeShapeFromShapeProto(proto, &handle));\n    outer_context->set_output(index, handle);\n\n    auto* resource = node_context->input_handle_shapes_and_types(0);\n    if (resource) {\n      outer_context->set_output_handle_shapes_and_types(index, *resource);\n    }\n  }\n\n  return Status::OK();\n}",
        "func_hash": 296174489268649475183296977682065052967,
        "file_name": "shape_refiner.cc",
        "file_hash": null,
        "cwe": [
            "CWE-369"
        ],
        "cve": "CVE-2021-37690",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions when running shape functions, some functions (such as `MutableHashTableShape`) produce extra output information in the form of a `ShapeAndType` struct. The shapes embedded in this struct are owned by an inference context that is cleaned up almost immediately; if the upstream code attempts to access this shape information, it can trigger a segfault. `ShapeRefiner` is mitigating this for normal output shapes by cloning them (and thus putting the newly created shape under ownership of an inference context that will not die), but we were not doing the same for shapes and types. This commit fixes that by doing similar logic on output shapes and types. We have patched the issue in GitHub commit ee119d4a498979525046fba1c3dd3f13a039fbb1. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37690",
        "func_name": "ShapeRefiner::InferShapesForFunctionSubNode",
        "diff": [
            "diff --git a/tensorflow/core/common_runtime/shape_refiner.cc b/tensorflow/core/common_runtime/shape_refiner.cc\nindex 375f809b31b369..2e29ef48189a59 100644\n--- a/tensorflow/core/common_runtime/shape_refiner.cc\n+++ b/tensorflow/core/common_runtime/shape_refiner.cc\n@@ -120,9 +120,26 @@ Status ShapeRefiner::InferShapesForFunctionSubNode(\n     TF_RETURN_IF_ERROR(outer_context->MakeShapeFromShapeProto(proto, &handle));\n     outer_context->set_output(index, handle);\n \n-    auto* resource = node_context->input_handle_shapes_and_types(0);\n+    const std::vector<ShapeAndType>* resource =\n+        node_context->input_handle_shapes_and_types(0);\n     if (resource) {\n-      outer_context->set_output_handle_shapes_and_types(index, *resource);\n+      // `ShapesAndType`s contain `ShapeHandle`s.  These `ShapeHandle`s point\n+      // to `Shape`s that are owned by a different inference context too.  We\n+      // need to copy them to the outer context to prevent them from being\n+      // destroyed before they are used.\n+      std::vector<ShapeAndType> copied_shapes_and_types;\n+      for (auto& shape_and_type : *resource) {\n+        ShapeHandle handle;\n+        TensorShapeProto proto;\n+        node_context->ShapeHandleToProto(shape_and_type.shape, &proto);\n+        TF_RETURN_IF_ERROR(\n+            outer_context->MakeShapeFromShapeProto(proto, &handle));\n+        copied_shapes_and_types.push_back(\n+            ShapeAndType(handle, shape_and_type.dtype, shape_and_type.type));\n+      }\n+\n+      outer_context->set_output_handle_shapes_and_types(\n+          index, copied_shapes_and_types);\n     }\n   }\n \n"
        ],
        "func_after": []
    },
    {
        "idx": 197262,
        "project": "tensorflow",
        "commit_id": "e6cf28c72ba2eb949ca950d834dd6d66bb01cfae",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/e6cf28c72ba2eb949ca950d834dd6d66bb01cfae",
        "commit_message": "Validate that matrix dimension sizes in SparseMatMul are positive.\n\nPiperOrigin-RevId: 401149683\nChange-Id: Ib33eafc561a39c8741ece80b2edce6d4aae9a57d",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor& a = ctx->input(0);\n    const Tensor& b = ctx->input(1);\n    OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(a.shape()),\n                errors::InvalidArgument(\"a is not a matrix\"));\n    OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(b.shape()),\n                errors::InvalidArgument(\"b is not a matrix\"));\n\n    const int m = transpose_a_ ? a.dim_size(1) : a.dim_size(0);\n    const int k = transpose_a_ ? a.dim_size(0) : a.dim_size(1);\n    const int n = transpose_b_ ? b.dim_size(0) : b.dim_size(1);\n    const int k2 = transpose_b_ ? b.dim_size(1) : b.dim_size(0);\n\n    OP_REQUIRES(ctx, k == k2,\n                errors::InvalidArgument(\n                    \"Matrix size incompatible: a: \", a.shape().DebugString(),\n                    \", b: \", b.shape().DebugString()));\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, TensorShape({m, n}), &output));\n\n    if (k == 0) {\n      // If the inner dimension k in the matrix multiplication is zero, we fill\n      // the output with zeros.\n      functor::SetZeroFunctor<CPUDevice, float> f;\n      f(ctx->eigen_device<CPUDevice>(), output->flat<float>());\n      return;\n    }\n\n    auto out = output->matrix<float>();\n\n    std::unique_ptr<Tensor> a_float;\n    std::unique_ptr<Tensor> b_float;\n    if (!a_is_sparse_ && !b_is_sparse_) {\n      auto left = &a;\n      auto right = &b;\n      // TODO(agarwal): multi-thread the conversions from bfloat16 to float.\n      if (std::is_same<TL, bfloat16>::value) {\n        a_float.reset(new Tensor(DT_FLOAT, a.shape()));\n        BFloat16ToFloat(a.flat<bfloat16>().data(),\n                        a_float->flat<float>().data(), a.NumElements());\n        left = a_float.get();\n      }\n      if (std::is_same<TR, bfloat16>::value) {\n        b_float.reset(new Tensor(DT_FLOAT, b.shape()));\n        BFloat16ToFloat(b.flat<bfloat16>().data(),\n                        b_float->flat<float>().data(), b.NumElements());\n        right = b_float.get();\n      }\n      Eigen::array<Eigen::IndexPair<Eigen::DenseIndex>, 1> dim_pair;\n      dim_pair[0].first = transpose_a_ ? 0 : 1;\n      dim_pair[0].second = transpose_b_ ? 1 : 0;\n\n      out.device(ctx->template eigen_device<CPUDevice>()) =\n          left->matrix<float>().contract(right->matrix<float>(), dim_pair);\n      return;\n    }\n\n    auto left = &a;\n    auto right = &b;\n    bool transpose_output = false;\n    bool transpose_a = transpose_a_;\n    bool transpose_b = transpose_b_;\n    if (!a_is_sparse_) {\n      // Swap the order of multiplications using the identity:\n      // A * B = (B' *  A')'.\n      std::swap(left, right);\n      std::swap(transpose_a, transpose_b);\n      transpose_a = !transpose_a;\n      transpose_b = !transpose_b;\n      transpose_output = !transpose_output;\n    }\n\n    std::unique_ptr<Tensor> right_tr;\n    if (transpose_b) {\n      // TODO(agarwal): avoid transposing the matrix here and directly handle\n      // transpose in CreateDenseSlices.\n      OP_REQUIRES(ctx, right->dim_size(0) != 0,\n                  errors::InvalidArgument(\"b has an entry 0 in it's shape.\"));\n      OP_REQUIRES(ctx, right->dim_size(1) != 0,\n                  errors::InvalidArgument(\"b has an entry 0 in it's shape.\"));\n      right_tr.reset(\n          new Tensor(right->dtype(),\n                     TensorShape({right->dim_size(1), right->dim_size(0)})));\n\n      const auto perm = dsizes_10();\n      if (transpose_output) {\n        right_tr->matrix<TL>().device(ctx->template eigen_device<CPUDevice>()) =\n            right->matrix<TL>().shuffle(perm);\n      } else {\n        right_tr->matrix<TR>().device(ctx->template eigen_device<CPUDevice>()) =\n            right->matrix<TR>().shuffle(perm);\n      }\n      right = right_tr.get();\n    }\n\n    if (transpose_output) {\n      DoMatMul<TR, TL>::Compute(&this->cache_tr_, left->matrix<TR>(),\n                                right->matrix<TL>(), transpose_a,\n                                ctx->device()->tensorflow_cpu_worker_threads(),\n                                transpose_output, &out);\n    } else {\n      DoMatMul<TL, TR>::Compute(&this->cache_nt_, left->matrix<TL>(),\n                                right->matrix<TR>(), transpose_a,\n                                ctx->device()->tensorflow_cpu_worker_threads(),\n                                transpose_output, &out);\n    }\n  }",
        "func_hash": 281398484697111962957982643274603954439,
        "file_name": "sparse_matmul_op.cc",
        "file_hash": 108103579052154515117474451671828260520,
        "cwe": [
            "CWE-125"
        ],
        "cve": "CVE-2021-41219",
        "cve_desc": "TensorFlow is an open source platform for machine learning. In affected versions the code for sparse matrix multiplication is vulnerable to undefined behavior via binding a reference to `nullptr`. This occurs whenever the dimensions of `a` or `b` are 0 or less. In the case on one of these is 0, an empty output tensor should be allocated (to conserve the invariant that output tensors are always allocated when the operation is successful) but nothing should be written to it (that is, we should return early from the kernel implementation). Otherwise, attempts to write to this empty tensor would result in heap OOB access. The fix will be included in TensorFlow 2.7.0. We will also cherrypick this commit on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-41219",
        "func_name": "Compute",
        "diff": [
            "diff --git a/tensorflow/core/kernels/sparse_matmul_op.cc b/tensorflow/core/kernels/sparse_matmul_op.cc\nindex a02afafa33e3ad..6bf9dfa3d8bb75 100644\n--- a/tensorflow/core/kernels/sparse_matmul_op.cc\n+++ b/tensorflow/core/kernels/sparse_matmul_op.cc\n@@ -32,6 +32,7 @@ limitations under the License.\n #include \"tensorflow/core/kernels/fill_functor.h\"\n #include \"tensorflow/core/lib/core/blocking_counter.h\"\n #include \"tensorflow/core/lib/core/threadpool.h\"\n+#include \"tensorflow/core/platform/errors.h\"\n #include \"tensorflow/core/platform/logging.h\"\n #include \"tensorflow/core/platform/macros.h\"\n #include \"tensorflow/core/platform/mutex.h\"\n@@ -980,9 +981,18 @@ class SparseMatMulOp : public OpKernel {\n                 errors::InvalidArgument(\n                     \"Matrix size incompatible: a: \", a.shape().DebugString(),\n                     \", b: \", b.shape().DebugString()));\n+    OP_REQUIRES(ctx, m >= 0 && n >= 0 && k >= 0,\n+                errors::InvalidArgument(\n+                    \"Matrix dimensions cannot be negative: a: \",\n+                    a.shape().DebugString(), \", b: \", b.shape().DebugString()));\n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, TensorShape({m, n}), &output));\n \n+    // Return early if at least one of the output dimension size is 0.\n+    if (m == 0 || n == 0) {\n+      return;\n+    }\n+\n     if (k == 0) {\n       // If the inner dimension k in the matrix multiplication is zero, we fill\n       // the output with zeros.\n"
        ],
        "func_after": []
    },
    {
        "idx": 197305,
        "project": "pjproject",
        "commit_id": "11559e49e65bdf00922ad5ae28913ec6a198d508",
        "project_url": "https://github.com/pjsip/pjproject",
        "commit_url": "https://github.com/pjsip/pjproject/commit/11559e49e65bdf00922ad5ae28913ec6a198d508",
        "commit_message": "Merge pull request from GHSA-vhxv-phmx-g52q\n\n* Prevent OOB read/write when parsing RTCP FB RPSI\n\n* Add log information\n\n* Modification based on comments.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "PJ_DEF(pj_status_t) pjmedia_rtcp_fb_parse_rpsi(\n\t\t\t\t\tconst void *buf,\n\t\t\t\t\tpj_size_t length,\n\t\t\t\t\tpjmedia_rtcp_fb_rpsi *rpsi)\n{\n    pjmedia_rtcp_common *hdr = (pjmedia_rtcp_common*) buf;\n    pj_uint8_t *p;\n    pj_uint8_t padlen;\n    pj_size_t rpsi_len;\n\n    PJ_ASSERT_RETURN(buf && rpsi, PJ_EINVAL);\n    PJ_ASSERT_RETURN(length >= sizeof(pjmedia_rtcp_common), PJ_ETOOSMALL);\n\n    /* RPSI uses pt==RTCP_PSFB and FMT==3 */\n    if (hdr->pt != RTCP_PSFB || hdr->count != 3)\n\treturn PJ_ENOTFOUND;\n\n    rpsi_len = (pj_ntohs((pj_uint16_t)hdr->length)-2) * 4;\n    if (length < rpsi_len + 12)\n\treturn PJ_ETOOSMALL;\n\n    p = (pj_uint8_t*)hdr + sizeof(*hdr);\n    padlen = *p++;\n    rpsi->pt = (*p++ & 0x7F);\n    rpsi->rpsi_bit_len = rpsi_len*8 - 16 - padlen;\n    pj_strset(&rpsi->rpsi, (char*)p, (rpsi->rpsi_bit_len + 7)/8);\n\n    return PJ_SUCCESS;\n}",
        "func_hash": 36256848360171648205913357387602986017,
        "file_name": "rtcp_fb.c",
        "file_hash": 8904386284990700433551187598162654514,
        "cwe": [
            "CWE-200"
        ],
        "cve": "CVE-2022-24786",
        "cve_desc": "PJSIP is a free and open source multimedia communication library written in C. PJSIP versions 2.12 and prior do not parse incoming RTCP feedback RPSI (Reference Picture Selection Indication) packet, but any app that directly uses pjmedia_rtcp_fb_parse_rpsi() will be affected. A patch is available in the `master` branch of the `pjsip/pjproject` GitHub repository. There are currently no known workarounds.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-24786",
        "func_name": "PJ_DEF",
        "diff": [
            "diff --git a/pjmedia/include/pjmedia/rtcp.h b/pjmedia/include/pjmedia/rtcp.h\nindex 9fc53657ae..f4bff12cda 100644\n--- a/pjmedia/include/pjmedia/rtcp.h\n+++ b/pjmedia/include/pjmedia/rtcp.h\n@@ -115,6 +115,15 @@ typedef struct pjmedia_rtcp_common\n } pjmedia_rtcp_common;\n \n \n+/**\n+ * RTCP feedback common header.\n+ */\n+typedef struct pjmedia_rtcp_fb_common\n+{\n+    pjmedia_rtcp_common rtcp_common;\n+    pj_uint32_t\t    ssrc_src;\t/**< SSRC media source\t    */\n+} pjmedia_rtcp_fb_common;\n+\n /**\n  * This structure declares default RTCP packet (SR) that is sent by pjmedia.\n  * Incoming RTCP packet may have different format, and must be parsed\n@@ -234,6 +243,8 @@ typedef struct pjmedia_rtcp_session\n     char\t\t   *name;\t/**< Name identification.\t    */\n     pjmedia_rtcp_sr_pkt\t    rtcp_sr_pkt;/**< Cached RTCP SR packet.\t    */\n     pjmedia_rtcp_rr_pkt\t    rtcp_rr_pkt;/**< Cached RTCP RR packet.\t    */\n+    pjmedia_rtcp_fb_common  rtcp_fb_com;/**< Cached RTCP feedback common \n+\t\t\t\t\t     header packet.\t\t    */\n     \n     pjmedia_rtp_seq_session seq_ctrl;\t/**< RTCP sequence number control.  */\n     unsigned\t\t    rtp_last_ts;/**< Last timestamp in RX RTP pkt.  */\ndiff --git a/pjmedia/src/pjmedia/rtcp.c b/pjmedia/src/pjmedia/rtcp.c\nindex 4f40e7fe10..ceb1b78fcd 100644\n--- a/pjmedia/src/pjmedia/rtcp.c\n+++ b/pjmedia/src/pjmedia/rtcp.c\n@@ -242,6 +242,11 @@ PJ_DEF(void) pjmedia_rtcp_init2( pjmedia_rtcp_session *sess,\n     sess->rtcp_rr_pkt.common.pt = RTCP_RR;\n     sess->rtcp_rr_pkt.common.length = pj_htons(7);\n \n+    /* Copy to RTCP FB common header */\n+    pj_memcpy(&sess->rtcp_fb_com, &sr_pkt->common, \n+\t      sizeof(pjmedia_rtcp_common));\n+    sess->rtcp_fb_com.ssrc_src = 0;\n+\n     /* Get time and timestamp base and frequency */\n     pj_gettimeofday(&now);\n     sess->tv_base = now;\ndiff --git a/pjmedia/src/pjmedia/rtcp_fb.c b/pjmedia/src/pjmedia/rtcp_fb.c\nindex a2a0140f34..d4e444caab 100644\n--- a/pjmedia/src/pjmedia/rtcp_fb.c\n+++ b/pjmedia/src/pjmedia/rtcp_fb.c\n@@ -43,7 +43,7 @@ PJ_DEF(pj_status_t) pjmedia_rtcp_fb_build_nack(\n \t\t\t\t\tunsigned nack_cnt,\n \t\t\t\t\tconst pjmedia_rtcp_fb_nack nack[])\n {\n-    pjmedia_rtcp_common *hdr;\n+    pjmedia_rtcp_fb_common *hdr;\n     pj_uint8_t *p;\n     unsigned len, i;\n \n@@ -54,11 +54,11 @@ PJ_DEF(pj_status_t) pjmedia_rtcp_fb_build_nack(\n \treturn PJ_ETOOSMALL;\n \n     /* Build RTCP-FB NACK header */\n-    hdr = (pjmedia_rtcp_common*)buf;\n-    pj_memcpy(hdr, &session->rtcp_rr_pkt.common,  sizeof(*hdr));\n-    hdr->pt = RTCP_RTPFB;\n-    hdr->count = 1; /* FMT = 1 */\n-    hdr->length = pj_htons((pj_uint16_t)(len/4 - 1));\n+    hdr = (pjmedia_rtcp_fb_common*)buf;\n+    pj_memcpy(hdr, &session->rtcp_fb_com, sizeof(*hdr));\n+    hdr->rtcp_common.pt = RTCP_RTPFB;\n+    hdr->rtcp_common.count = 1; /* FMT = 1 */\n+    hdr->rtcp_common.length = pj_htons((pj_uint16_t)(len/4 - 1));\n \n     /* Build RTCP-FB NACK FCI */\n     p = (pj_uint8_t*)hdr + sizeof(*hdr);\n@@ -86,7 +86,7 @@ PJ_DEF(pj_status_t) pjmedia_rtcp_fb_build_pli(\n \t\t\t\t\tvoid *buf,\n \t\t\t\t\tpj_size_t *length)\n {\n-    pjmedia_rtcp_common *hdr;\n+    pjmedia_rtcp_fb_common *hdr;\n     unsigned len;\n \n     PJ_ASSERT_RETURN(session && buf && length, PJ_EINVAL);\n@@ -96,11 +96,11 @@ PJ_DEF(pj_status_t) pjmedia_rtcp_fb_build_pli(\n \treturn PJ_ETOOSMALL;\n \n     /* Build RTCP-FB PLI header */\n-    hdr = (pjmedia_rtcp_common*)buf;\n-    pj_memcpy(hdr, &session->rtcp_rr_pkt.common,  sizeof(*hdr));\n-    hdr->pt = RTCP_PSFB;\n-    hdr->count = 1; /* FMT = 1 */\n-    hdr->length = pj_htons((pj_uint16_t)(len/4 - 1));\n+    hdr = (pjmedia_rtcp_fb_common*)buf;\n+    pj_memcpy(hdr, &session->rtcp_fb_com, sizeof(*hdr));\n+    hdr->rtcp_common.pt = RTCP_PSFB;\n+    hdr->rtcp_common.count = 1; /* FMT = 1 */\n+    hdr->rtcp_common.length = pj_htons((pj_uint16_t)(len/4 - 1));\n \n     /* Finally */\n     *length = len;\n@@ -119,7 +119,7 @@ PJ_DEF(pj_status_t) pjmedia_rtcp_fb_build_sli(\n \t\t\t\t\tunsigned sli_cnt,\n \t\t\t\t\tconst pjmedia_rtcp_fb_sli sli[])\n {\n-    pjmedia_rtcp_common *hdr;\n+    pjmedia_rtcp_fb_common *hdr;\n     pj_uint8_t *p;\n     unsigned len, i;\n \n@@ -130,11 +130,11 @@ PJ_DEF(pj_status_t) pjmedia_rtcp_fb_build_sli(\n \treturn PJ_ETOOSMALL;\n \n     /* Build RTCP-FB SLI header */\n-    hdr = (pjmedia_rtcp_common*)buf;\n-    pj_memcpy(hdr, &session->rtcp_rr_pkt.common,  sizeof(*hdr));\n-    hdr->pt = RTCP_PSFB;\n-    hdr->count = 2; /* FMT = 2 */\n-    hdr->length = pj_htons((pj_uint16_t)(len/4 - 1));\n+    hdr = (pjmedia_rtcp_fb_common*)buf;\n+    pj_memcpy(hdr, &session->rtcp_fb_com, sizeof(*hdr));\n+    hdr->rtcp_common.pt = RTCP_PSFB;\n+    hdr->rtcp_common.count = 2; /* FMT = 2 */\n+    hdr->rtcp_common.length = pj_htons((pj_uint16_t)(len/4 - 1));\n \n     /* Build RTCP-FB SLI FCI */\n     p = (pj_uint8_t*)hdr + sizeof(*hdr);\n@@ -166,7 +166,7 @@ PJ_DEF(pj_status_t) pjmedia_rtcp_fb_build_rpsi(\n \t\t\t\t\t    pj_size_t *length,\n \t\t\t\t\t    const pjmedia_rtcp_fb_rpsi *rpsi)\n {\n-    pjmedia_rtcp_common *hdr;\n+    pjmedia_rtcp_fb_common *hdr;\n     pj_uint8_t *p;\n     unsigned bitlen, padlen, len;\n \n@@ -179,11 +179,11 @@ PJ_DEF(pj_status_t) pjmedia_rtcp_fb_build_rpsi(\n \treturn PJ_ETOOSMALL;\n \n     /* Build RTCP-FB RPSI header */\n-    hdr = (pjmedia_rtcp_common*)buf;\n-    pj_memcpy(hdr, &session->rtcp_rr_pkt.common,  sizeof(*hdr));\n-    hdr->pt = RTCP_PSFB;\n-    hdr->count = 3; /* FMT = 3 */\n-    hdr->length = pj_htons((pj_uint16_t)(len/4 - 1));\n+    hdr = (pjmedia_rtcp_fb_common*)buf;\n+    pj_memcpy(hdr, &session->rtcp_fb_com, sizeof(*hdr));\n+    hdr->rtcp_common.pt = RTCP_PSFB;\n+    hdr->rtcp_common.count = 3; /* FMT = 3 */\n+    hdr->rtcp_common.length = pj_htons((pj_uint16_t)(len/4 - 1));\n \n     /* Build RTCP-FB RPSI FCI */\n     p = (pj_uint8_t*)hdr + sizeof(*hdr);\n@@ -620,18 +620,18 @@ PJ_DEF(pj_status_t) pjmedia_rtcp_fb_parse_nack(\n \t\t\t\t\tunsigned *nack_cnt,\n \t\t\t\t\tpjmedia_rtcp_fb_nack nack[])\n {\n-    pjmedia_rtcp_common *hdr = (pjmedia_rtcp_common*) buf;\n+    pjmedia_rtcp_fb_common *hdr = (pjmedia_rtcp_fb_common*) buf;\n     pj_uint8_t *p;\n     unsigned cnt, i;\n \n     PJ_ASSERT_RETURN(buf && nack_cnt && nack, PJ_EINVAL);\n-    PJ_ASSERT_RETURN(length >= sizeof(pjmedia_rtcp_common), PJ_ETOOSMALL);\n+    PJ_ASSERT_RETURN(length >= sizeof(pjmedia_rtcp_fb_common), PJ_ETOOSMALL);\n \n     /* Generic NACK uses pt==RTCP_RTPFB and FMT==1 */\n-    if (hdr->pt != RTCP_RTPFB || hdr->count != 1)\n+    if (hdr->rtcp_common.pt != RTCP_RTPFB || hdr->rtcp_common.count != 1)\n \treturn PJ_ENOTFOUND;\n \n-    cnt = pj_ntohs((pj_uint16_t)hdr->length);\n+    cnt = pj_ntohs((pj_uint16_t)hdr->rtcp_common.length);\n     if (cnt > 2) cnt -= 2; else cnt = 0;\n     if (length < (cnt+3)*4)\n \treturn PJ_ETOOSMALL;\n@@ -661,7 +661,7 @@ PJ_DEF(pj_status_t) pjmedia_rtcp_fb_parse_pli(\n \t\t\t\t\tconst void *buf,\n \t\t\t\t\tpj_size_t length)\n {\n-    pjmedia_rtcp_common *hdr = (pjmedia_rtcp_common*) buf;\n+    pjmedia_rtcp_fb_common *hdr = (pjmedia_rtcp_fb_common*) buf;\n \n     PJ_ASSERT_RETURN(buf, PJ_EINVAL);\n \n@@ -669,7 +669,7 @@ PJ_DEF(pj_status_t) pjmedia_rtcp_fb_parse_pli(\n     \treturn PJ_ETOOSMALL;\n \n     /* PLI uses pt==RTCP_PSFB and FMT==1 */\n-    if (hdr->pt != RTCP_PSFB || hdr->count != 1)\n+    if (hdr->rtcp_common.pt != RTCP_PSFB || hdr->rtcp_common.count != 1)\n \treturn PJ_ENOTFOUND;\n \n     return PJ_SUCCESS;\n@@ -686,18 +686,18 @@ PJ_DEF(pj_status_t) pjmedia_rtcp_fb_parse_sli(\n \t\t\t\t\tunsigned *sli_cnt,\n \t\t\t\t\tpjmedia_rtcp_fb_sli sli[])\n {\n-    pjmedia_rtcp_common *hdr = (pjmedia_rtcp_common*) buf;\n+    pjmedia_rtcp_fb_common *hdr = (pjmedia_rtcp_fb_common*) buf;\n     pj_uint8_t *p;\n     unsigned cnt, i;\n \n     PJ_ASSERT_RETURN(buf && sli_cnt && sli, PJ_EINVAL);\n-    PJ_ASSERT_RETURN(length >= sizeof(pjmedia_rtcp_common), PJ_ETOOSMALL);\n+    PJ_ASSERT_RETURN(length >= sizeof(pjmedia_rtcp_fb_common), PJ_ETOOSMALL);\n \n     /* PLI uses pt==RTCP_PSFB and FMT==2 */\n-    if (hdr->pt != RTCP_PSFB || hdr->count != 2)\n+    if (hdr->rtcp_common.pt != RTCP_PSFB || hdr->rtcp_common.count != 2)\n \treturn PJ_ENOTFOUND;\n \n-    cnt = pj_ntohs((pj_uint16_t)hdr->length) - 2;\n+    cnt = pj_ntohs((pj_uint16_t)hdr->rtcp_common.length) - 2;\n     if (length < (cnt+3)*4)\n \treturn PJ_ETOOSMALL;\n \n@@ -730,24 +730,43 @@ PJ_DEF(pj_status_t) pjmedia_rtcp_fb_parse_rpsi(\n \t\t\t\t\tpj_size_t length,\n \t\t\t\t\tpjmedia_rtcp_fb_rpsi *rpsi)\n {\n-    pjmedia_rtcp_common *hdr = (pjmedia_rtcp_common*) buf;\n+    pjmedia_rtcp_fb_common *hdr = (pjmedia_rtcp_fb_common*) buf;\n     pj_uint8_t *p;\n     pj_uint8_t padlen;\n     pj_size_t rpsi_len;\n \n     PJ_ASSERT_RETURN(buf && rpsi, PJ_EINVAL);\n-    PJ_ASSERT_RETURN(length >= sizeof(pjmedia_rtcp_common), PJ_ETOOSMALL);\n+    PJ_ASSERT_RETURN(length >= sizeof(pjmedia_rtcp_fb_common), PJ_ETOOSMALL);\n \n     /* RPSI uses pt==RTCP_PSFB and FMT==3 */\n-    if (hdr->pt != RTCP_PSFB || hdr->count != 3)\n+    if (hdr->rtcp_common.pt != RTCP_PSFB || hdr->rtcp_common.count != 3)\n \treturn PJ_ENOTFOUND;\n \n-    rpsi_len = (pj_ntohs((pj_uint16_t)hdr->length)-2) * 4;\n+    if (hdr->rtcp_common.length < 3) {    \n+        PJ_PERROR(3, (THIS_FILE, PJ_ETOOSMALL,\n+                      \"Failed parsing FB RPSI, invalid header length\"));\n+\treturn PJ_ETOOSMALL;\n+    }\n+\n+    rpsi_len = (pj_ntohs((pj_uint16_t)hdr->rtcp_common.length)-2) * 4;\n     if (length < rpsi_len + 12)\n \treturn PJ_ETOOSMALL;\n \n     p = (pj_uint8_t*)hdr + sizeof(*hdr);\n     padlen = *p++;\n+\n+    if (padlen >= 32) {\n+        PJ_PERROR(3, (THIS_FILE, PJ_ETOOBIG,\n+                      \"Failed parsing FB RPSI, invalid RPSI padding len\"));\n+\treturn PJ_ETOOBIG;\n+    }\n+\n+    if ((rpsi_len * 8) < (unsigned)(16 + padlen)) {\n+        PJ_PERROR(3, (THIS_FILE, PJ_ETOOSMALL,\n+                      \"Failed parsing FB RPSI, invalid RPSI bit len\"));\n+\treturn PJ_ETOOSMALL;\n+    }\n+\n     rpsi->pt = (*p++ & 0x7F);\n     rpsi->rpsi_bit_len = rpsi_len*8 - 16 - padlen;\n     pj_strset(&rpsi->rpsi, (char*)p, (rpsi->rpsi_bit_len + 7)/8);\n"
        ],
        "func_after": []
    },
    {
        "idx": 200287,
        "project": "linux",
        "commit_id": "d6d86830705f173fca6087a3e67ceaf68db80523",
        "project_url": "https://github.com/torvalds/linux",
        "commit_url": "https://github.com/torvalds/linux/commit/d6d86830705f173fca6087a3e67ceaf68db80523",
        "commit_message": "net ticp:fix a kernel-infoleak in __tipc_sendmsg()\n\nstruct tipc_socket_addr.ref has a 4-byte hole,and __tipc_getname() currently\ncopying it to user space,causing kernel-infoleak.\n\nBUG: KMSAN: kernel-infoleak in instrument_copy_to_user include/linux/instrumented.h:121 [inline]\nBUG: KMSAN: kernel-infoleak in instrument_copy_to_user include/linux/instrumented.h:121 [inline] lib/usercopy.c:33\nBUG: KMSAN: kernel-infoleak in _copy_to_user+0x1c9/0x270 lib/usercopy.c:33 lib/usercopy.c:33\n instrument_copy_to_user include/linux/instrumented.h:121 [inline]\n instrument_copy_to_user include/linux/instrumented.h:121 [inline] lib/usercopy.c:33\n _copy_to_user+0x1c9/0x270 lib/usercopy.c:33 lib/usercopy.c:33\n copy_to_user include/linux/uaccess.h:209 [inline]\n copy_to_user include/linux/uaccess.h:209 [inline] net/socket.c:287\n move_addr_to_user+0x3f6/0x600 net/socket.c:287 net/socket.c:287\n __sys_getpeername+0x470/0x6b0 net/socket.c:1987 net/socket.c:1987\n __do_sys_getpeername net/socket.c:1997 [inline]\n __se_sys_getpeername net/socket.c:1994 [inline]\n __do_sys_getpeername net/socket.c:1997 [inline] net/socket.c:1994\n __se_sys_getpeername net/socket.c:1994 [inline] net/socket.c:1994\n __x64_sys_getpeername+0xda/0x120 net/socket.c:1994 net/socket.c:1994\n do_syscall_x64 arch/x86/entry/common.c:51 [inline]\n do_syscall_x64 arch/x86/entry/common.c:51 [inline] arch/x86/entry/common.c:82\n do_syscall_64+0x54/0xd0 arch/x86/entry/common.c:82 arch/x86/entry/common.c:82\n entry_SYSCALL_64_after_hwframe+0x44/0xae\n\nUninit was stored to memory at:\n tipc_getname+0x575/0x5e0 net/tipc/socket.c:757 net/tipc/socket.c:757\n __sys_getpeername+0x3b3/0x6b0 net/socket.c:1984 net/socket.c:1984\n __do_sys_getpeername net/socket.c:1997 [inline]\n __se_sys_getpeername net/socket.c:1994 [inline]\n __do_sys_getpeername net/socket.c:1997 [inline] net/socket.c:1994\n __se_sys_getpeername net/socket.c:1994 [inline] net/socket.c:1994\n __x64_sys_getpeername+0xda/0x120 net/socket.c:1994 net/socket.c:1994\n do_syscall_x64 arch/x86/entry/common.c:51 [inline]\n do_syscall_x64 arch/x86/entry/common.c:51 [inline] arch/x86/entry/common.c:82\n do_syscall_64+0x54/0xd0 arch/x86/entry/common.c:82 arch/x86/entry/common.c:82\n entry_SYSCALL_64_after_hwframe+0x44/0xae\n\nUninit was stored to memory at:\n msg_set_word net/tipc/msg.h:212 [inline]\n msg_set_destport net/tipc/msg.h:619 [inline]\n msg_set_word net/tipc/msg.h:212 [inline] net/tipc/socket.c:1486\n msg_set_destport net/tipc/msg.h:619 [inline] net/tipc/socket.c:1486\n __tipc_sendmsg+0x44fa/0x5890 net/tipc/socket.c:1486 net/tipc/socket.c:1486\n tipc_sendmsg+0xeb/0x140 net/tipc/socket.c:1402 net/tipc/socket.c:1402\n sock_sendmsg_nosec net/socket.c:704 [inline]\n sock_sendmsg net/socket.c:724 [inline]\n sock_sendmsg_nosec net/socket.c:704 [inline] net/socket.c:2409\n sock_sendmsg net/socket.c:724 [inline] net/socket.c:2409\n ____sys_sendmsg+0xe11/0x12c0 net/socket.c:2409 net/socket.c:2409\n ___sys_sendmsg net/socket.c:2463 [inline]\n ___sys_sendmsg net/socket.c:2463 [inline] net/socket.c:2492\n __sys_sendmsg+0x704/0x840 net/socket.c:2492 net/socket.c:2492\n __do_sys_sendmsg net/socket.c:2501 [inline]\n __se_sys_sendmsg net/socket.c:2499 [inline]\n __do_sys_sendmsg net/socket.c:2501 [inline] net/socket.c:2499\n __se_sys_sendmsg net/socket.c:2499 [inline] net/socket.c:2499\n __x64_sys_sendmsg+0xe2/0x120 net/socket.c:2499 net/socket.c:2499\n do_syscall_x64 arch/x86/entry/common.c:51 [inline]\n do_syscall_x64 arch/x86/entry/common.c:51 [inline] arch/x86/entry/common.c:82\n do_syscall_64+0x54/0xd0 arch/x86/entry/common.c:82 arch/x86/entry/common.c:82\n entry_SYSCALL_64_after_hwframe+0x44/0xae\n\nLocal variable skaddr created at:\n __tipc_sendmsg+0x2d0/0x5890 net/tipc/socket.c:1419 net/tipc/socket.c:1419\n tipc_sendmsg+0xeb/0x140 net/tipc/socket.c:1402 net/tipc/socket.c:1402\n\nBytes 4-7 of 16 are uninitialized\nMemory access of size 16 starts at ffff888113753e00\nData copied to user address 0000000020000280\n\nReported-by: syzbot+cdbd40e0c3ca02cae3b7@syzkaller.appspotmail.com\nSigned-off-by: Haimin Zhang <tcs_kernel@tencent.com>\nAcked-by: Jon Maloy <jmaloy@redhat.com>\nLink: https://lore.kernel.org/r/1640918123-14547-1-git-send-email-tcs.kernel@gmail.com\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static int __tipc_sendmsg(struct socket *sock, struct msghdr *m, size_t dlen)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct net *net = sock_net(sk);\n\tstruct tipc_sock *tsk = tipc_sk(sk);\n\tstruct tipc_uaddr *ua = (struct tipc_uaddr *)m->msg_name;\n\tlong timeout = sock_sndtimeo(sk, m->msg_flags & MSG_DONTWAIT);\n\tstruct list_head *clinks = &tsk->cong_links;\n\tbool syn = !tipc_sk_type_connectionless(sk);\n\tstruct tipc_group *grp = tsk->group;\n\tstruct tipc_msg *hdr = &tsk->phdr;\n\tstruct tipc_socket_addr skaddr;\n\tstruct sk_buff_head pkts;\n\tint atype, mtu, rc;\n\n\tif (unlikely(dlen > TIPC_MAX_USER_MSG_SIZE))\n\t\treturn -EMSGSIZE;\n\n\tif (ua) {\n\t\tif (!tipc_uaddr_valid(ua, m->msg_namelen))\n\t\t\treturn -EINVAL;\n\t\tatype = ua->addrtype;\n\t}\n\n\t/* If socket belongs to a communication group follow other paths */\n\tif (grp) {\n\t\tif (!ua)\n\t\t\treturn tipc_send_group_bcast(sock, m, dlen, timeout);\n\t\tif (atype == TIPC_SERVICE_ADDR)\n\t\t\treturn tipc_send_group_anycast(sock, m, dlen, timeout);\n\t\tif (atype == TIPC_SOCKET_ADDR)\n\t\t\treturn tipc_send_group_unicast(sock, m, dlen, timeout);\n\t\tif (atype == TIPC_SERVICE_RANGE)\n\t\t\treturn tipc_send_group_mcast(sock, m, dlen, timeout);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!ua) {\n\t\tua = (struct tipc_uaddr *)&tsk->peer;\n\t\tif (!syn && ua->family != AF_TIPC)\n\t\t\treturn -EDESTADDRREQ;\n\t\tatype = ua->addrtype;\n\t}\n\n\tif (unlikely(syn)) {\n\t\tif (sk->sk_state == TIPC_LISTEN)\n\t\t\treturn -EPIPE;\n\t\tif (sk->sk_state != TIPC_OPEN)\n\t\t\treturn -EISCONN;\n\t\tif (tsk->published)\n\t\t\treturn -EOPNOTSUPP;\n\t\tif (atype == TIPC_SERVICE_ADDR)\n\t\t\ttsk->conn_addrtype = atype;\n\t\tmsg_set_syn(hdr, 1);\n\t}\n\n\t/* Determine destination */\n\tif (atype == TIPC_SERVICE_RANGE) {\n\t\treturn tipc_sendmcast(sock, ua, m, dlen, timeout);\n\t} else if (atype == TIPC_SERVICE_ADDR) {\n\t\tskaddr.node = ua->lookup_node;\n\t\tua->scope = tipc_node2scope(skaddr.node);\n\t\tif (!tipc_nametbl_lookup_anycast(net, ua, &skaddr))\n\t\t\treturn -EHOSTUNREACH;\n\t} else if (atype == TIPC_SOCKET_ADDR) {\n\t\tskaddr = ua->sk;\n\t} else {\n\t\treturn -EINVAL;\n\t}\n\n\t/* Block or return if destination link is congested */\n\trc = tipc_wait_for_cond(sock, &timeout,\n\t\t\t\t!tipc_dest_find(clinks, skaddr.node, 0));\n\tif (unlikely(rc))\n\t\treturn rc;\n\n\t/* Finally build message header */\n\tmsg_set_destnode(hdr, skaddr.node);\n\tmsg_set_destport(hdr, skaddr.ref);\n\tif (atype == TIPC_SERVICE_ADDR) {\n\t\tmsg_set_type(hdr, TIPC_NAMED_MSG);\n\t\tmsg_set_hdr_sz(hdr, NAMED_H_SIZE);\n\t\tmsg_set_nametype(hdr, ua->sa.type);\n\t\tmsg_set_nameinst(hdr, ua->sa.instance);\n\t\tmsg_set_lookup_scope(hdr, ua->scope);\n\t} else { /* TIPC_SOCKET_ADDR */\n\t\tmsg_set_type(hdr, TIPC_DIRECT_MSG);\n\t\tmsg_set_lookup_scope(hdr, 0);\n\t\tmsg_set_hdr_sz(hdr, BASIC_H_SIZE);\n\t}\n\n\t/* Add message body */\n\t__skb_queue_head_init(&pkts);\n\tmtu = tipc_node_get_mtu(net, skaddr.node, tsk->portid, true);\n\trc = tipc_msg_build(hdr, m, 0, dlen, mtu, &pkts);\n\tif (unlikely(rc != dlen))\n\t\treturn rc;\n\tif (unlikely(syn && !tipc_msg_skb_clone(&pkts, &sk->sk_write_queue))) {\n\t\t__skb_queue_purge(&pkts);\n\t\treturn -ENOMEM;\n\t}\n\n\t/* Send message */\n\ttrace_tipc_sk_sendmsg(sk, skb_peek(&pkts), TIPC_DUMP_SK_SNDQ, \" \");\n\trc = tipc_node_xmit(net, &pkts, skaddr.node, tsk->portid);\n\tif (unlikely(rc == -ELINKCONG)) {\n\t\ttipc_dest_push(clinks, skaddr.node, 0);\n\t\ttsk->cong_link_cnt++;\n\t\trc = 0;\n\t}\n\n\tif (unlikely(syn && !rc)) {\n\t\ttipc_set_sk_state(sk, TIPC_CONNECTING);\n\t\tif (dlen && timeout) {\n\t\t\ttimeout = msecs_to_jiffies(timeout);\n\t\t\ttipc_wait_for_connect(sock, &timeout);\n\t\t}\n\t}\n\n\treturn rc ? rc : dlen;\n}",
        "func_hash": 187316583908925875095721276140565552990,
        "file_name": "socket.c",
        "file_hash": 211909288028562459580061336771266741769,
        "cwe": [
            "CWE-200"
        ],
        "cve": "CVE-2022-0382",
        "cve_desc": "An information leak flaw was found due to uninitialized memory in the Linux kernel's TIPC protocol subsystem, in the way a user sends a TIPC datagram to one or more destinations. This flaw allows a local user to read some kernel memory. This issue is limited to no more than 7 bytes, and the user cannot control what is read. This flaw affects the Linux kernel versions prior to 5.17-rc1.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-0382",
        "func_name": "__tipc_sendmsg",
        "diff": [
            "diff --git a/net/tipc/socket.c b/net/tipc/socket.c\nindex ad570c2450be8b..3e63c83e641c56 100644\n--- a/net/tipc/socket.c\n+++ b/net/tipc/socket.c\n@@ -1461,6 +1461,8 @@ static int __tipc_sendmsg(struct socket *sock, struct msghdr *m, size_t dlen)\n \t\tmsg_set_syn(hdr, 1);\n \t}\n \n+\tmemset(&skaddr, 0, sizeof(skaddr));\n+\n \t/* Determine destination */\n \tif (atype == TIPC_SERVICE_RANGE) {\n \t\treturn tipc_sendmcast(sock, ua, m, dlen, timeout);\n"
        ],
        "func_after": []
    },
    {
        "idx": 200305,
        "project": "ghostpdl",
        "commit_id": "2793769ff107d8d22dadd30c6e68cd781b569550",
        "project_url": "https://github.com/ArtifexSoftware/ghostpdl",
        "commit_url": "https://git.ghostscript.com/?p=ghostpdl.git;a=commitdiff;h=2793769ff107d8d22dadd30c6e68cd781b569550",
        "commit_message": "Bug 701819: fixed ordering in if expression to avoid out-of-bounds access.\n\nFixes:\n    ./sanbin/gs -dBATCH -dNOPAUSE -r965 -sOutputFile=tmp -sDEVICE=pcx16 ../bug-701819.pdf",
        "target": 1,
        "irrelevant": 0,
        "func_before": "pcx_write_rle(const byte * from, const byte * end, int step, gp_file * file)\n{\t\t\t\t/*\n                                 * The PCX format theoretically allows encoding runs of 63\n                                 * identical bytes, but some readers can't handle repetition\n                                 * counts greater than 15.\n                                 */\n#define MAX_RUN_COUNT 15\n    int max_run = step * MAX_RUN_COUNT;\n\n    while (from < end) {\n        byte data = *from;\n\n        from += step;\n        if (data != *from || from == end) {\n            if (data >= 0xc0)\n                gp_fputc(0xc1, file);\n        } else {\n            const byte *start = from;\n\n            while ((from < end) && (*from == data))\n                from += step;\n            /* Now (from - start) / step + 1 is the run length. */\n            while (from - start >= max_run) {\n                gp_fputc(0xc0 + MAX_RUN_COUNT, file);\n                gp_fputc(data, file);\n                start += max_run;\n            }\n            if (from > start || data >= 0xc0)\n                gp_fputc((from - start) / step + 0xc1, file);\n        }\n        gp_fputc(data, file);\n    }\n#undef MAX_RUN_COUNT\n}",
        "func_hash": 302156343438902913796919673468889397004,
        "file_name": "gdevpcx.c",
        "file_hash": 193192744323180393354892924891696445092,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2020-16305",
        "cve_desc": "A buffer overflow vulnerability in pcx_write_rle() in contrib/japanese/gdev10v.c of Artifex Software GhostScript v9.50 allows a remote attacker to cause a denial of service via a crafted PDF file. This is fixed in v9.51.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2020-16305",
        "func_name": "pcx_write_rle",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 200320,
        "project": "samba",
        "commit_id": "eb50fb8f3bf670bd7d1cf8fd4368ef4a73083696",
        "project_url": "https://github.com/samba-team/samba",
        "commit_url": "http://git.samba.org/?p=samba.git;a=commitdiff;h=eb50fb8f3bf670bd7d1cf8fd4368ef4a73083696",
        "commit_message": "FSCTL_GET_SHADOW_COPY_DATA: Don't return 4 extra bytes at end\n\nlabels_data_count already accounts for the unicode null character at the\nend of the array. There is no need in adding space for it again.\n\nSigned-off-by: Christof Schmitt <christof.schmitt@us.ibm.com>\nReviewed-by: Jeremy Allison <jra@samba.org>\nReviewed-by: Simo Sorce <idra@samba.org>\n\nAutobuild-User(master): Jeremy Allison <jra@samba.org>\nAutobuild-Date(master): Tue Aug  6 04:03:17 CEST 2013 on sn-devel-104",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static NTSTATUS vfswrap_fsctl(struct vfs_handle_struct *handle,\n\t\t\t      struct files_struct *fsp,\n\t\t\t      TALLOC_CTX *ctx,\n\t\t\t      uint32_t function,\n\t\t\t      uint16_t req_flags, /* Needed for UNICODE ... */\n\t\t\t      const uint8_t *_in_data,\n\t\t\t      uint32_t in_len,\n\t\t\t      uint8_t **_out_data,\n\t\t\t      uint32_t max_out_len,\n\t\t\t      uint32_t *out_len)\n{\n\tconst char *in_data = (const char *)_in_data;\n\tchar **out_data = (char **)_out_data;\n\n\tswitch (function) {\n\tcase FSCTL_SET_SPARSE:\n\t{\n\t\tbool set_sparse = true;\n\t\tNTSTATUS status;\n\n\t\tif (in_len >= 1 && in_data[0] == 0) {\n\t\t\tset_sparse = false;\n\t\t}\n\n\t\tstatus = file_set_sparse(handle->conn, fsp, set_sparse);\n\t\t\n\t\tDEBUG(NT_STATUS_IS_OK(status) ? 10 : 9,\n\t\t      (\"FSCTL_SET_SPARSE: fname[%s] set[%u] - %s\\n\",\n\t\t       smb_fname_str_dbg(fsp->fsp_name), set_sparse, \n\t\t       nt_errstr(status)));\n\n\t\treturn status;\n\t}\n\n\tcase FSCTL_CREATE_OR_GET_OBJECT_ID:\n\t{\n\t\tunsigned char objid[16];\n\t\tchar *return_data = NULL;\n\n\t\t/* This should return the object-id on this file.\n\t\t * I think I'll make this be the inode+dev. JRA.\n\t\t */\n\n\t\tDEBUG(10,(\"FSCTL_CREATE_OR_GET_OBJECT_ID: called on %s\\n\",\n\t\t\t  fsp_fnum_dbg(fsp)));\n\n\t\t*out_len = (max_out_len >= 64) ? 64 : max_out_len;\n\t\t/* Hmmm, will this cause problems if less data asked for? */\n\t\treturn_data = talloc_array(ctx, char, 64);\n\t\tif (return_data == NULL) {\n\t\t\treturn NT_STATUS_NO_MEMORY;\n\t\t}\n\n\t\t/* For backwards compatibility only store the dev/inode. */\n\t\tpush_file_id_16(return_data, &fsp->file_id);\n\t\tmemcpy(return_data+16,create_volume_objectid(fsp->conn,objid),16);\n\t\tpush_file_id_16(return_data+32, &fsp->file_id);\n\t\t*out_data = return_data;\n\t\treturn NT_STATUS_OK;\n\t}\n\n\tcase FSCTL_GET_REPARSE_POINT:\n\t{\n\t\t/* Fail it with STATUS_NOT_A_REPARSE_POINT */\n\t\tDEBUG(10, (\"FSCTL_GET_REPARSE_POINT: called on %s. \"\n\t\t\t   \"Status: NOT_IMPLEMENTED\\n\", fsp_fnum_dbg(fsp)));\n\t\treturn NT_STATUS_NOT_A_REPARSE_POINT;\n\t}\n\n\tcase FSCTL_SET_REPARSE_POINT:\n\t{\n\t\t/* Fail it with STATUS_NOT_A_REPARSE_POINT */\n\t\tDEBUG(10, (\"FSCTL_SET_REPARSE_POINT: called on %s. \"\n\t\t\t   \"Status: NOT_IMPLEMENTED\\n\", fsp_fnum_dbg(fsp)));\n\t\treturn NT_STATUS_NOT_A_REPARSE_POINT;\n\t}\n\n\tcase FSCTL_GET_SHADOW_COPY_DATA:\n\t{\n\t\t/*\n\t\t * This is called to retrieve the number of Shadow Copies (a.k.a. snapshots)\n\t\t * and return their volume names.  If max_data_count is 16, then it is just\n\t\t * asking for the number of volumes and length of the combined names.\n\t\t *\n\t\t * pdata is the data allocated by our caller, but that uses\n\t\t * total_data_count (which is 0 in our case) rather than max_data_count.\n\t\t * Allocate the correct amount and return the pointer to let\n\t\t * it be deallocated when we return.\n\t\t */\n\t\tstruct shadow_copy_data *shadow_data = NULL;\n\t\tbool labels = False;\n\t\tuint32 labels_data_count = 0;\n\t\tuint32 i;\n\t\tchar *cur_pdata = NULL;\n\n\t\tif (max_out_len < 16) {\n\t\t\tDEBUG(0,(\"FSCTL_GET_SHADOW_COPY_DATA: max_data_count(%u) < 16 is invalid!\\n\",\n\t\t\t\tmax_out_len));\n\t\t\treturn NT_STATUS_INVALID_PARAMETER;\n\t\t}\n\n\t\tif (max_out_len > 16) {\n\t\t\tlabels = True;\n\t\t}\n\n\t\tshadow_data = talloc_zero(ctx, struct shadow_copy_data);\n\t\tif (shadow_data == NULL) {\n\t\t\tDEBUG(0,(\"TALLOC_ZERO() failed!\\n\"));\n\t\t\treturn NT_STATUS_NO_MEMORY;\n\t\t}\n\n\t\t/*\n\t\t * Call the VFS routine to actually do the work.\n\t\t */\n\t\tif (SMB_VFS_GET_SHADOW_COPY_DATA(fsp, shadow_data, labels)!=0) {\n\t\t\tTALLOC_FREE(shadow_data);\n\t\t\tif (errno == ENOSYS) {\n\t\t\t\tDEBUG(5,(\"FSCTL_GET_SHADOW_COPY_DATA: connectpath %s, not supported.\\n\", \n\t\t\t\t\tfsp->conn->connectpath));\n\t\t\t\treturn NT_STATUS_NOT_SUPPORTED;\n\t\t\t} else {\n\t\t\t\tDEBUG(0,(\"FSCTL_GET_SHADOW_COPY_DATA: connectpath %s, failed.\\n\", \n\t\t\t\t\tfsp->conn->connectpath));\n\t\t\t\treturn NT_STATUS_UNSUCCESSFUL;\n\t\t\t}\n\t\t}\n\n\t\tlabels_data_count = (shadow_data->num_volumes * 2 * \n\t\t\t\t\tsizeof(SHADOW_COPY_LABEL)) + 2;\n\n\t\tif (!labels) {\n\t\t\t*out_len = 16;\n\t\t} else {\n\t\t\t*out_len = 12 + labels_data_count + 4;\n\t\t}\n\n\t\tif (max_out_len < *out_len) {\n\t\t\tDEBUG(0,(\"FSCTL_GET_SHADOW_COPY_DATA: max_data_count(%u) too small (%u) bytes needed!\\n\",\n\t\t\t\tmax_out_len, *out_len));\n\t\t\tTALLOC_FREE(shadow_data);\n\t\t\treturn NT_STATUS_BUFFER_TOO_SMALL;\n\t\t}\n\n\t\tcur_pdata = talloc_zero_array(ctx, char, *out_len);\n\t\tif (cur_pdata == NULL) {\n\t\t\tTALLOC_FREE(shadow_data);\n\t\t\treturn NT_STATUS_NO_MEMORY;\n\t\t}\n\n\t\t*out_data = cur_pdata;\n\n\t\t/* num_volumes 4 bytes */\n\t\tSIVAL(cur_pdata, 0, shadow_data->num_volumes);\n\n\t\tif (labels) {\n\t\t\t/* num_labels 4 bytes */\n\t\t\tSIVAL(cur_pdata, 4, shadow_data->num_volumes);\n\t\t}\n\n\t\t/* needed_data_count 4 bytes */\n\t\tSIVAL(cur_pdata, 8, labels_data_count + 4);\n\n\t\tcur_pdata += 12;\n\n\t\tDEBUG(10,(\"FSCTL_GET_SHADOW_COPY_DATA: %u volumes for path[%s].\\n\",\n\t\t\t  shadow_data->num_volumes, fsp_str_dbg(fsp)));\n\t\tif (labels && shadow_data->labels) {\n\t\t\tfor (i=0; i<shadow_data->num_volumes; i++) {\n\t\t\t\tsrvstr_push(cur_pdata, req_flags,\n\t\t\t\t\t    cur_pdata, shadow_data->labels[i],\n\t\t\t\t\t    2 * sizeof(SHADOW_COPY_LABEL),\n\t\t\t\t\t    STR_UNICODE|STR_TERMINATE);\n\t\t\t\tcur_pdata += 2 * sizeof(SHADOW_COPY_LABEL);\n\t\t\t\tDEBUGADD(10,(\"Label[%u]: '%s'\\n\",i,shadow_data->labels[i]));\n\t\t\t}\n\t\t}\n\n\t\tTALLOC_FREE(shadow_data);\n\n\t\treturn NT_STATUS_OK;\n\t}\n\n\tcase FSCTL_FIND_FILES_BY_SID:\n\t{\n\t\t/* pretend this succeeded -\n\t\t *\n\t\t * we have to send back a list with all files owned by this SID\n\t\t *\n\t\t * but I have to check that --metze\n\t\t */\n\t\tstruct dom_sid sid;\n\t\tuid_t uid;\n\t\tsize_t sid_len;\n\n\t\tDEBUG(10, (\"FSCTL_FIND_FILES_BY_SID: called on %s\\n\",\n\t\t\t   fsp_fnum_dbg(fsp)));\n\n\t\tif (in_len < 8) {\n\t\t\t/* NT_STATUS_BUFFER_TOO_SMALL maybe? */\n\t\t\treturn NT_STATUS_INVALID_PARAMETER;\n\t\t}\n\n\t\tsid_len = MIN(in_len - 4,SID_MAX_SIZE);\n\n\t\t/* unknown 4 bytes: this is not the length of the sid :-(  */\n\t\t/*unknown = IVAL(pdata,0);*/\n\n\t\tif (!sid_parse(in_data + 4, sid_len, &sid)) {\n\t\t\treturn NT_STATUS_INVALID_PARAMETER;\n\t\t}\n\t\tDEBUGADD(10, (\"for SID: %s\\n\", sid_string_dbg(&sid)));\n\n\t\tif (!sid_to_uid(&sid, &uid)) {\n\t\t\tDEBUG(0,(\"sid_to_uid: failed, sid[%s] sid_len[%lu]\\n\",\n\t\t\t\t sid_string_dbg(&sid),\n\t\t\t\t (unsigned long)sid_len));\n\t\t\tuid = (-1);\n\t\t}\n\n\t\t/* we can take a look at the find source :-)\n\t\t *\n\t\t * find ./ -uid $uid  -name '*'   is what we need here\n\t\t *\n\t\t *\n\t\t * and send 4bytes len and then NULL terminated unicode strings\n\t\t * for each file\n\t\t *\n\t\t * but I don't know how to deal with the paged results\n\t\t * (maybe we can hang the result anywhere in the fsp struct)\n\t\t *\n\t\t * but I don't know how to deal with the paged results\n\t\t * (maybe we can hang the result anywhere in the fsp struct)\n\t\t *\n\t\t * we don't send all files at once\n\t\t * and at the next we should *not* start from the beginning,\n\t\t * so we have to cache the result\n\t\t *\n\t\t * --metze\n\t\t */\n\n\t\t/* this works for now... */\n\t\treturn NT_STATUS_OK;\n\t}\n\n\tcase FSCTL_QUERY_ALLOCATED_RANGES:\n\t{\n\t\t/* FIXME: This is just a dummy reply, telling that all of the\n\t\t * file is allocated. MKS cp needs that.\n\t\t * Adding the real allocated ranges via FIEMAP on Linux\n\t\t * and SEEK_DATA/SEEK_HOLE on Solaris is needed to make\n\t\t * this FSCTL correct for sparse files.\n\t\t */\n\t\tNTSTATUS status;\n\t\tuint64_t offset, length;\n\t\tchar *out_data_tmp = NULL;\n\n\t\tif (in_len != 16) {\n\t\t\tDEBUG(0,(\"FSCTL_QUERY_ALLOCATED_RANGES: data_count(%u) != 16 is invalid!\\n\",\n\t\t\t\tin_len));\n\t\t\treturn NT_STATUS_INVALID_PARAMETER;\n\t\t}\n\n\t\tif (max_out_len < 16) {\n\t\t\tDEBUG(0,(\"FSCTL_QUERY_ALLOCATED_RANGES: max_out_len (%u) < 16 is invalid!\\n\",\n\t\t\t\tmax_out_len));\n\t\t\treturn NT_STATUS_INVALID_PARAMETER;\n\t\t}\n\n\t\toffset = BVAL(in_data,0);\n\t\tlength = BVAL(in_data,8);\n\n\t\tif (offset + length < offset) {\n\t\t\t/* No 64-bit integer wrap. */\n\t\t\treturn NT_STATUS_INVALID_PARAMETER;\n\t\t}\n\n\t\t/* Shouldn't this be SMB_VFS_STAT ... ? */\n\t\tstatus = vfs_stat_fsp(fsp);\n\t\tif (!NT_STATUS_IS_OK(status)) {\n\t\t\treturn status;\n\t\t}\n\n\t\t*out_len = 16;\n\t\tout_data_tmp = talloc_array(ctx, char, *out_len);\n\t\tif (out_data_tmp == NULL) {\n\t\t\tDEBUG(10, (\"unable to allocate memory for response\\n\"));\n\t\t\treturn NT_STATUS_NO_MEMORY;\n\t\t}\n\n\t\tif (offset > fsp->fsp_name->st.st_ex_size ||\n\t\t\t\tfsp->fsp_name->st.st_ex_size == 0 ||\n\t\t\t\tlength == 0) {\n\t\t\tmemset(out_data_tmp, 0, *out_len);\n\t\t} else {\n\t\t\tuint64_t end = offset + length;\n\t\t\tend = MIN(end, fsp->fsp_name->st.st_ex_size);\n\t\t\tSBVAL(out_data_tmp, 0, 0);\n\t\t\tSBVAL(out_data_tmp, 8, end);\n\t\t}\n\n\t\t*out_data = out_data_tmp;\n\n\t\treturn NT_STATUS_OK;\n\t}\n\n\tcase FSCTL_IS_VOLUME_DIRTY:\n\t{\n\t\tDEBUG(10,(\"FSCTL_IS_VOLUME_DIRTY: called on %s \"\n\t\t\t  \"(but remotely not supported)\\n\", fsp_fnum_dbg(fsp)));\n\t\t/*\n\t\t * http://msdn.microsoft.com/en-us/library/cc232128%28PROT.10%29.aspx\n\t\t * says we have to respond with NT_STATUS_INVALID_PARAMETER\n\t\t */\n\t\treturn NT_STATUS_INVALID_PARAMETER;\n\t}\n\n\tdefault:\n\t\t/* \n\t\t * Only print once ... unfortunately there could be lots of\n\t\t * different FSCTLs that are called.\n\t\t */\n\t\tif (!vfswrap_logged_ioctl_message) {\n\t\t\tvfswrap_logged_ioctl_message = true;\n\t\t\tDEBUG(2, (\"%s (0x%x): Currently not implemented.\\n\",\n\t\t\t__func__, function));\n\t\t}\n\t}\n\n\treturn NT_STATUS_NOT_SUPPORTED;\n}",
        "func_hash": 216855121268945563940656517843611340199,
        "file_name": "vfs_default.c",
        "file_hash": 120656139704674873497493645428059774528,
        "cwe": [
            "CWE-665"
        ],
        "cve": "CVE-2014-0178",
        "cve_desc": "Samba 3.6.6 through 3.6.23, 4.0.x before 4.0.18, and 4.1.x before 4.1.8, when a certain vfs shadow copy configuration is enabled, does not properly initialize the SRV_SNAPSHOT_ARRAY response field, which allows remote authenticated users to obtain potentially sensitive information from process memory via a (1) FSCTL_GET_SHADOW_COPY_DATA or (2) FSCTL_SRV_ENUMERATE_SNAPSHOTS request.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2014-0178",
        "func_name": "vfswrap_fsctl",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 200323,
        "project": "vim",
        "commit_id": "156d3911952d73b03d7420dc3540215247db0fe8",
        "project_url": "https://github.com/vim/vim",
        "commit_url": "https://github.com/vim/vim/commit/156d3911952d73b03d7420dc3540215247db0fe8",
        "commit_message": "patch 8.2.5123: using invalid index when looking for spell suggestions\n\nProblem:    Using invalid index when looking for spell suggestions.\nSolution:   Do not decrement the index when it is zero.",
        "target": 1,
        "irrelevant": 1,
        "func_before": "suggest_trie_walk(\n    suginfo_T\t*su,\n    langp_T\t*lp,\n    char_u\t*fword,\n    int\t\tsoundfold)\n{\n    char_u\ttword[MAXWLEN];\t    // good word collected so far\n    trystate_T\tstack[MAXWLEN];\n    char_u\tpreword[MAXWLEN * 3]; // word found with proper case;\n\t\t\t\t      // concatenation of prefix compound\n\t\t\t\t      // words and split word.  NUL terminated\n\t\t\t\t      // when going deeper but not when coming\n\t\t\t\t      // back.\n    char_u\tcompflags[MAXWLEN];\t// compound flags, one for each word\n    trystate_T\t*sp;\n    int\t\tnewscore;\n    int\t\tscore;\n    char_u\t*byts, *fbyts, *pbyts;\n    idx_T\t*idxs, *fidxs, *pidxs;\n    int\t\tdepth;\n    int\t\tc, c2, c3;\n    int\t\tn = 0;\n    int\t\tflags;\n    garray_T\t*gap;\n    idx_T\tarridx;\n    int\t\tlen;\n    char_u\t*p;\n    fromto_T\t*ftp;\n    int\t\tfl = 0, tl;\n    int\t\trepextra = 0;\t    // extra bytes in fword[] from REP item\n    slang_T\t*slang = lp->lp_slang;\n    int\t\tfword_ends;\n    int\t\tgoodword_ends;\n#ifdef DEBUG_TRIEWALK\n    // Stores the name of the change made at each level.\n    char_u\tchangename[MAXWLEN][80];\n#endif\n    int\t\tbreakcheckcount = 1000;\n#ifdef FEAT_RELTIME\n    proftime_T\ttime_limit;\n#endif\n    int\t\tcompound_ok;\n\n    // Go through the whole case-fold tree, try changes at each node.\n    // \"tword[]\" contains the word collected from nodes in the tree.\n    // \"fword[]\" the word we are trying to match with (initially the bad\n    // word).\n    depth = 0;\n    sp = &stack[0];\n    CLEAR_POINTER(sp);\n    sp->ts_curi = 1;\n\n    if (soundfold)\n    {\n\t// Going through the soundfold tree.\n\tbyts = fbyts = slang->sl_sbyts;\n\tidxs = fidxs = slang->sl_sidxs;\n\tpbyts = NULL;\n\tpidxs = NULL;\n\tsp->ts_prefixdepth = PFD_NOPREFIX;\n\tsp->ts_state = STATE_START;\n    }\n    else\n    {\n\t// When there are postponed prefixes we need to use these first.  At\n\t// the end of the prefix we continue in the case-fold tree.\n\tfbyts = slang->sl_fbyts;\n\tfidxs = slang->sl_fidxs;\n\tpbyts = slang->sl_pbyts;\n\tpidxs = slang->sl_pidxs;\n\tif (pbyts != NULL)\n\t{\n\t    byts = pbyts;\n\t    idxs = pidxs;\n\t    sp->ts_prefixdepth = PFD_PREFIXTREE;\n\t    sp->ts_state = STATE_NOPREFIX;\t// try without prefix first\n\t}\n\telse\n\t{\n\t    byts = fbyts;\n\t    idxs = fidxs;\n\t    sp->ts_prefixdepth = PFD_NOPREFIX;\n\t    sp->ts_state = STATE_START;\n\t}\n    }\n#ifdef FEAT_RELTIME\n    // The loop may take an indefinite amount of time. Break out after some\n    // time.\n    if (spell_suggest_timeout > 0)\n\tprofile_setlimit(spell_suggest_timeout, &time_limit);\n#endif\n\n    // Loop to find all suggestions.  At each round we either:\n    // - For the current state try one operation, advance \"ts_curi\",\n    //   increase \"depth\".\n    // - When a state is done go to the next, set \"ts_state\".\n    // - When all states are tried decrease \"depth\".\n    while (depth >= 0 && !got_int)\n    {\n\tsp = &stack[depth];\n\tswitch (sp->ts_state)\n\t{\n\tcase STATE_START:\n\tcase STATE_NOPREFIX:\n\t    // Start of node: Deal with NUL bytes, which means\n\t    // tword[] may end here.\n\t    arridx = sp->ts_arridx;\t    // current node in the tree\n\t    len = byts[arridx];\t\t    // bytes in this node\n\t    arridx += sp->ts_curi;\t    // index of current byte\n\n\t    if (sp->ts_prefixdepth == PFD_PREFIXTREE)\n\t    {\n\t\t// Skip over the NUL bytes, we use them later.\n\t\tfor (n = 0; n < len && byts[arridx + n] == 0; ++n)\n\t\t    ;\n\t\tsp->ts_curi += n;\n\n\t\t// Always past NUL bytes now.\n\t\tn = (int)sp->ts_state;\n\t\tPROF_STORE(sp->ts_state)\n\t\tsp->ts_state = STATE_ENDNUL;\n\t\tsp->ts_save_badflags = su->su_badflags;\n\n\t\t// At end of a prefix or at start of prefixtree: check for\n\t\t// following word.\n\t\tif (depth < MAXWLEN - 1\n\t\t\t    && (byts[arridx] == 0 || n == (int)STATE_NOPREFIX))\n\t\t{\n\t\t    // Set su->su_badflags to the caps type at this position.\n\t\t    // Use the caps type until here for the prefix itself.\n\t\t    if (has_mbyte)\n\t\t\tn = nofold_len(fword, sp->ts_fidx, su->su_badptr);\n\t\t    else\n\t\t\tn = sp->ts_fidx;\n\t\t    flags = badword_captype(su->su_badptr, su->su_badptr + n);\n\t\t    su->su_badflags = badword_captype(su->su_badptr + n,\n\t\t\t\t\t       su->su_badptr + su->su_badlen);\n#ifdef DEBUG_TRIEWALK\n\t\t    sprintf(changename[depth], \"prefix\");\n#endif\n\t\t    go_deeper(stack, depth, 0);\n\t\t    ++depth;\n\t\t    sp = &stack[depth];\n\t\t    sp->ts_prefixdepth = depth - 1;\n\t\t    byts = fbyts;\n\t\t    idxs = fidxs;\n\t\t    sp->ts_arridx = 0;\n\n\t\t    // Move the prefix to preword[] with the right case\n\t\t    // and make find_keepcap_word() works.\n\t\t    tword[sp->ts_twordlen] = NUL;\n\t\t    make_case_word(tword + sp->ts_splitoff,\n\t\t\t\t\t  preword + sp->ts_prewordlen, flags);\n\t\t    sp->ts_prewordlen = (char_u)STRLEN(preword);\n\t\t    sp->ts_splitoff = sp->ts_twordlen;\n\t\t}\n\t\tbreak;\n\t    }\n\n\t    if (sp->ts_curi > len || byts[arridx] != 0)\n\t    {\n\t\t// Past bytes in node and/or past NUL bytes.\n\t\tPROF_STORE(sp->ts_state)\n\t\tsp->ts_state = STATE_ENDNUL;\n\t\tsp->ts_save_badflags = su->su_badflags;\n\t\tbreak;\n\t    }\n\n\t    // End of word in tree.\n\t    ++sp->ts_curi;\t\t// eat one NUL byte\n\n\t    flags = (int)idxs[arridx];\n\n\t    // Skip words with the NOSUGGEST flag.\n\t    if (flags & WF_NOSUGGEST)\n\t\tbreak;\n\n\t    fword_ends = (fword[sp->ts_fidx] == NUL\n\t\t\t   || (soundfold\n\t\t\t       ? VIM_ISWHITE(fword[sp->ts_fidx])\n\t\t\t       : !spell_iswordp(fword + sp->ts_fidx, curwin)));\n\t    tword[sp->ts_twordlen] = NUL;\n\n\t    if (sp->ts_prefixdepth <= PFD_NOTSPECIAL\n\t\t\t\t\t&& (sp->ts_flags & TSF_PREFIXOK) == 0\n\t\t\t\t\t&& pbyts != NULL)\n\t    {\n\t\t// There was a prefix before the word.  Check that the prefix\n\t\t// can be used with this word.\n\t\t// Count the length of the NULs in the prefix.  If there are\n\t\t// none this must be the first try without a prefix.\n\t\tn = stack[sp->ts_prefixdepth].ts_arridx;\n\t\tlen = pbyts[n++];\n\t\tfor (c = 0; c < len && pbyts[n + c] == 0; ++c)\n\t\t    ;\n\t\tif (c > 0)\n\t\t{\n\t\t    c = valid_word_prefix(c, n, flags,\n\t\t\t\t       tword + sp->ts_splitoff, slang, FALSE);\n\t\t    if (c == 0)\n\t\t\tbreak;\n\n\t\t    // Use the WF_RARE flag for a rare prefix.\n\t\t    if (c & WF_RAREPFX)\n\t\t\tflags |= WF_RARE;\n\n\t\t    // Tricky: when checking for both prefix and compounding\n\t\t    // we run into the prefix flag first.\n\t\t    // Remember that it's OK, so that we accept the prefix\n\t\t    // when arriving at a compound flag.\n\t\t    sp->ts_flags |= TSF_PREFIXOK;\n\t\t}\n\t    }\n\n\t    // Check NEEDCOMPOUND: can't use word without compounding.  Do try\n\t    // appending another compound word below.\n\t    if (sp->ts_complen == sp->ts_compsplit && fword_ends\n\t\t\t\t\t\t     && (flags & WF_NEEDCOMP))\n\t\tgoodword_ends = FALSE;\n\t    else\n\t\tgoodword_ends = TRUE;\n\n\t    p = NULL;\n\t    compound_ok = TRUE;\n\t    if (sp->ts_complen > sp->ts_compsplit)\n\t    {\n\t\tif (slang->sl_nobreak)\n\t\t{\n\t\t    // There was a word before this word.  When there was no\n\t\t    // change in this word (it was correct) add the first word\n\t\t    // as a suggestion.  If this word was corrected too, we\n\t\t    // need to check if a correct word follows.\n\t\t    if (sp->ts_fidx - sp->ts_splitfidx\n\t\t\t\t\t  == sp->ts_twordlen - sp->ts_splitoff\n\t\t\t    && STRNCMP(fword + sp->ts_splitfidx,\n\t\t\t\t\ttword + sp->ts_splitoff,\n\t\t\t\t\t sp->ts_fidx - sp->ts_splitfidx) == 0)\n\t\t    {\n\t\t\tpreword[sp->ts_prewordlen] = NUL;\n\t\t\tnewscore = score_wordcount_adj(slang, sp->ts_score,\n\t\t\t\t\t\t preword + sp->ts_prewordlen,\n\t\t\t\t\t\t sp->ts_prewordlen > 0);\n\t\t\t// Add the suggestion if the score isn't too bad.\n\t\t\tif (newscore <= su->su_maxscore)\n\t\t\t    add_suggestion(su, &su->su_ga, preword,\n\t\t\t\t    sp->ts_splitfidx - repextra,\n\t\t\t\t    newscore, 0, FALSE,\n\t\t\t\t    lp->lp_sallang, FALSE);\n\t\t\tbreak;\n\t\t    }\n\t\t}\n\t\telse\n\t\t{\n\t\t    // There was a compound word before this word.  If this\n\t\t    // word does not support compounding then give up\n\t\t    // (splitting is tried for the word without compound\n\t\t    // flag).\n\t\t    if (((unsigned)flags >> 24) == 0\n\t\t\t    || sp->ts_twordlen - sp->ts_splitoff\n\t\t\t\t\t\t       < slang->sl_compminlen)\n\t\t\tbreak;\n\t\t    // For multi-byte chars check character length against\n\t\t    // COMPOUNDMIN.\n\t\t    if (has_mbyte\n\t\t\t    && slang->sl_compminlen > 0\n\t\t\t    && mb_charlen(tword + sp->ts_splitoff)\n\t\t\t\t\t\t       < slang->sl_compminlen)\n\t\t\tbreak;\n\n\t\t    compflags[sp->ts_complen] = ((unsigned)flags >> 24);\n\t\t    compflags[sp->ts_complen + 1] = NUL;\n\t\t    vim_strncpy(preword + sp->ts_prewordlen,\n\t\t\t    tword + sp->ts_splitoff,\n\t\t\t    sp->ts_twordlen - sp->ts_splitoff);\n\n\t\t    // Verify CHECKCOMPOUNDPATTERN  rules.\n\t\t    if (match_checkcompoundpattern(preword,  sp->ts_prewordlen,\n\t\t\t\t\t\t\t  &slang->sl_comppat))\n\t\t\tcompound_ok = FALSE;\n\n\t\t    if (compound_ok)\n\t\t    {\n\t\t\tp = preword;\n\t\t\twhile (*skiptowhite(p) != NUL)\n\t\t\t    p = skipwhite(skiptowhite(p));\n\t\t\tif (fword_ends && !can_compound(slang, p,\n\t\t\t\t\t\tcompflags + sp->ts_compsplit))\n\t\t\t    // Compound is not allowed.  But it may still be\n\t\t\t    // possible if we add another (short) word.\n\t\t\t    compound_ok = FALSE;\n\t\t    }\n\n\t\t    // Get pointer to last char of previous word.\n\t\t    p = preword + sp->ts_prewordlen;\n\t\t    MB_PTR_BACK(preword, p);\n\t\t}\n\t    }\n\n\t    // Form the word with proper case in preword.\n\t    // If there is a word from a previous split, append.\n\t    // For the soundfold tree don't change the case, simply append.\n\t    if (soundfold)\n\t\tSTRCPY(preword + sp->ts_prewordlen, tword + sp->ts_splitoff);\n\t    else if (flags & WF_KEEPCAP)\n\t\t// Must find the word in the keep-case tree.\n\t\tfind_keepcap_word(slang, tword + sp->ts_splitoff,\n\t\t\t\t\t\t preword + sp->ts_prewordlen);\n\t    else\n\t    {\n\t\t// Include badflags: If the badword is onecap or allcap\n\t\t// use that for the goodword too.  But if the badword is\n\t\t// allcap and it's only one char long use onecap.\n\t\tc = su->su_badflags;\n\t\tif ((c & WF_ALLCAP)\n\t\t\t&& su->su_badlen == (*mb_ptr2len)(su->su_badptr))\n\t\t    c = WF_ONECAP;\n\t\tc |= flags;\n\n\t\t// When appending a compound word after a word character don't\n\t\t// use Onecap.\n\t\tif (p != NULL && spell_iswordp_nmw(p, curwin))\n\t\t    c &= ~WF_ONECAP;\n\t\tmake_case_word(tword + sp->ts_splitoff,\n\t\t\t\t\t      preword + sp->ts_prewordlen, c);\n\t    }\n\n\t    if (!soundfold)\n\t    {\n\t\t// Don't use a banned word.  It may appear again as a good\n\t\t// word, thus remember it.\n\t\tif (flags & WF_BANNED)\n\t\t{\n\t\t    add_banned(su, preword + sp->ts_prewordlen);\n\t\t    break;\n\t\t}\n\t\tif ((sp->ts_complen == sp->ts_compsplit\n\t\t\t    && WAS_BANNED(su, preword + sp->ts_prewordlen))\n\t\t\t\t\t\t   || WAS_BANNED(su, preword))\n\t\t{\n\t\t    if (slang->sl_compprog == NULL)\n\t\t\tbreak;\n\t\t    // the word so far was banned but we may try compounding\n\t\t    goodword_ends = FALSE;\n\t\t}\n\t    }\n\n\t    newscore = 0;\n\t    if (!soundfold)\t// soundfold words don't have flags\n\t    {\n\t\tif ((flags & WF_REGION)\n\t\t\t    && (((unsigned)flags >> 16) & lp->lp_region) == 0)\n\t\t    newscore += SCORE_REGION;\n\t\tif (flags & WF_RARE)\n\t\t    newscore += SCORE_RARE;\n\n\t\tif (!spell_valid_case(su->su_badflags,\n\t\t\t\t  captype(preword + sp->ts_prewordlen, NULL)))\n\t\t    newscore += SCORE_ICASE;\n\t    }\n\n\t    // TODO: how about splitting in the soundfold tree?\n\t    if (fword_ends\n\t\t    && goodword_ends\n\t\t    && sp->ts_fidx >= sp->ts_fidxtry\n\t\t    && compound_ok)\n\t    {\n\t\t// The badword also ends: add suggestions.\n#ifdef DEBUG_TRIEWALK\n\t\tif (soundfold && STRCMP(preword, \"smwrd\") == 0)\n\t\t{\n\t\t    int\t    j;\n\n\t\t    // print the stack of changes that brought us here\n\t\t    smsg(\"------ %s -------\", fword);\n\t\t    for (j = 0; j < depth; ++j)\n\t\t\tsmsg(\"%s\", changename[j]);\n\t\t}\n#endif\n\t\tif (soundfold)\n\t\t{\n\t\t    // For soundfolded words we need to find the original\n\t\t    // words, the edit distance and then add them.\n\t\t    add_sound_suggest(su, preword, sp->ts_score, lp);\n\t\t}\n\t\telse if (sp->ts_fidx > 0)\n\t\t{\n\t\t    // Give a penalty when changing non-word char to word\n\t\t    // char, e.g., \"thes,\" -> \"these\".\n\t\t    p = fword + sp->ts_fidx;\n\t\t    MB_PTR_BACK(fword, p);\n\t\t    if (!spell_iswordp(p, curwin) && *preword != NUL)\n\t\t    {\n\t\t\tp = preword + STRLEN(preword);\n\t\t\tMB_PTR_BACK(preword, p);\n\t\t\tif (spell_iswordp(p, curwin))\n\t\t\t    newscore += SCORE_NONWORD;\n\t\t    }\n\n\t\t    // Give a bonus to words seen before.\n\t\t    score = score_wordcount_adj(slang,\n\t\t\t\t\t\tsp->ts_score + newscore,\n\t\t\t\t\t\tpreword + sp->ts_prewordlen,\n\t\t\t\t\t\tsp->ts_prewordlen > 0);\n\n\t\t    // Add the suggestion if the score isn't too bad.\n\t\t    if (score <= su->su_maxscore)\n\t\t    {\n\t\t\tadd_suggestion(su, &su->su_ga, preword,\n\t\t\t\t    sp->ts_fidx - repextra,\n\t\t\t\t    score, 0, FALSE, lp->lp_sallang, FALSE);\n\n\t\t\tif (su->su_badflags & WF_MIXCAP)\n\t\t\t{\n\t\t\t    // We really don't know if the word should be\n\t\t\t    // upper or lower case, add both.\n\t\t\t    c = captype(preword, NULL);\n\t\t\t    if (c == 0 || c == WF_ALLCAP)\n\t\t\t    {\n\t\t\t\tmake_case_word(tword + sp->ts_splitoff,\n\t\t\t\t\t      preword + sp->ts_prewordlen,\n\t\t\t\t\t\t      c == 0 ? WF_ALLCAP : 0);\n\n\t\t\t\tadd_suggestion(su, &su->su_ga, preword,\n\t\t\t\t\tsp->ts_fidx - repextra,\n\t\t\t\t\tscore + SCORE_ICASE, 0, FALSE,\n\t\t\t\t\tlp->lp_sallang, FALSE);\n\t\t\t    }\n\t\t\t}\n\t\t    }\n\t\t}\n\t    }\n\n\t    // Try word split and/or compounding.\n\t    if ((sp->ts_fidx >= sp->ts_fidxtry || fword_ends)\n\t\t    // Don't split halfway a character.\n\t\t    && (!has_mbyte || sp->ts_tcharlen == 0))\n\t    {\n\t\tint\ttry_compound;\n\t\tint\ttry_split;\n\n\t\t// If past the end of the bad word don't try a split.\n\t\t// Otherwise try changing the next word.  E.g., find\n\t\t// suggestions for \"the the\" where the second \"the\" is\n\t\t// different.  It's done like a split.\n\t\t// TODO: word split for soundfold words\n\t\ttry_split = (sp->ts_fidx - repextra < su->su_badlen)\n\t\t\t\t\t\t\t\t&& !soundfold;\n\n\t\t// Get here in several situations:\n\t\t// 1. The word in the tree ends:\n\t\t//    If the word allows compounding try that.  Otherwise try\n\t\t//    a split by inserting a space.  For both check that a\n\t\t//    valid words starts at fword[sp->ts_fidx].\n\t\t//    For NOBREAK do like compounding to be able to check if\n\t\t//    the next word is valid.\n\t\t// 2. The badword does end, but it was due to a change (e.g.,\n\t\t//    a swap).  No need to split, but do check that the\n\t\t//    following word is valid.\n\t\t// 3. The badword and the word in the tree end.  It may still\n\t\t//    be possible to compound another (short) word.\n\t\ttry_compound = FALSE;\n\t\tif (!soundfold\n\t\t\t&& !slang->sl_nocompoundsugs\n\t\t\t&& slang->sl_compprog != NULL\n\t\t\t&& ((unsigned)flags >> 24) != 0\n\t\t\t&& sp->ts_twordlen - sp->ts_splitoff\n\t\t\t\t\t\t       >= slang->sl_compminlen\n\t\t\t&& (!has_mbyte\n\t\t\t    || slang->sl_compminlen == 0\n\t\t\t    || mb_charlen(tword + sp->ts_splitoff)\n\t\t\t\t\t\t      >= slang->sl_compminlen)\n\t\t\t&& (slang->sl_compsylmax < MAXWLEN\n\t\t\t    || sp->ts_complen + 1 - sp->ts_compsplit\n\t\t\t\t\t\t\t  < slang->sl_compmax)\n\t\t\t&& (can_be_compound(sp, slang,\n\t\t\t\t\t compflags, ((unsigned)flags >> 24))))\n\n\t\t{\n\t\t    try_compound = TRUE;\n\t\t    compflags[sp->ts_complen] = ((unsigned)flags >> 24);\n\t\t    compflags[sp->ts_complen + 1] = NUL;\n\t\t}\n\n\t\t// For NOBREAK we never try splitting, it won't make any word\n\t\t// valid.\n\t\tif (slang->sl_nobreak && !slang->sl_nocompoundsugs)\n\t\t    try_compound = TRUE;\n\n\t\t// If we could add a compound word, and it's also possible to\n\t\t// split at this point, do the split first and set\n\t\t// TSF_DIDSPLIT to avoid doing it again.\n\t\telse if (!fword_ends\n\t\t\t&& try_compound\n\t\t\t&& (sp->ts_flags & TSF_DIDSPLIT) == 0)\n\t\t{\n\t\t    try_compound = FALSE;\n\t\t    sp->ts_flags |= TSF_DIDSPLIT;\n\t\t    --sp->ts_curi;\t    // do the same NUL again\n\t\t    compflags[sp->ts_complen] = NUL;\n\t\t}\n\t\telse\n\t\t    sp->ts_flags &= ~TSF_DIDSPLIT;\n\n\t\tif (try_split || try_compound)\n\t\t{\n\t\t    if (!try_compound && (!fword_ends || !goodword_ends))\n\t\t    {\n\t\t\t// If we're going to split need to check that the\n\t\t\t// words so far are valid for compounding.  If there\n\t\t\t// is only one word it must not have the NEEDCOMPOUND\n\t\t\t// flag.\n\t\t\tif (sp->ts_complen == sp->ts_compsplit\n\t\t\t\t\t\t     && (flags & WF_NEEDCOMP))\n\t\t\t    break;\n\t\t\tp = preword;\n\t\t\twhile (*skiptowhite(p) != NUL)\n\t\t\t    p = skipwhite(skiptowhite(p));\n\t\t\tif (sp->ts_complen > sp->ts_compsplit\n\t\t\t\t&& !can_compound(slang, p,\n\t\t\t\t\t\tcompflags + sp->ts_compsplit))\n\t\t\t    break;\n\n\t\t\tif (slang->sl_nosplitsugs)\n\t\t\t    newscore += SCORE_SPLIT_NO;\n\t\t\telse\n\t\t\t    newscore += SCORE_SPLIT;\n\n\t\t\t// Give a bonus to words seen before.\n\t\t\tnewscore = score_wordcount_adj(slang, newscore,\n\t\t\t\t\t   preword + sp->ts_prewordlen, TRUE);\n\t\t    }\n\n\t\t    if (TRY_DEEPER(su, stack, depth, newscore))\n\t\t    {\n\t\t\tgo_deeper(stack, depth, newscore);\n#ifdef DEBUG_TRIEWALK\n\t\t\tif (!try_compound && !fword_ends)\n\t\t\t    sprintf(changename[depth], \"%.*s-%s: split\",\n\t\t\t\t sp->ts_twordlen, tword, fword + sp->ts_fidx);\n\t\t\telse\n\t\t\t    sprintf(changename[depth], \"%.*s-%s: compound\",\n\t\t\t\t sp->ts_twordlen, tword, fword + sp->ts_fidx);\n#endif\n\t\t\t// Save things to be restored at STATE_SPLITUNDO.\n\t\t\tsp->ts_save_badflags = su->su_badflags;\n\t\t\tPROF_STORE(sp->ts_state)\n\t\t\tsp->ts_state = STATE_SPLITUNDO;\n\n\t\t\t++depth;\n\t\t\tsp = &stack[depth];\n\n\t\t\t// Append a space to preword when splitting.\n\t\t\tif (!try_compound && !fword_ends)\n\t\t\t    STRCAT(preword, \" \");\n\t\t\tsp->ts_prewordlen = (char_u)STRLEN(preword);\n\t\t\tsp->ts_splitoff = sp->ts_twordlen;\n\t\t\tsp->ts_splitfidx = sp->ts_fidx;\n\n\t\t\t// If the badword has a non-word character at this\n\t\t\t// position skip it.  That means replacing the\n\t\t\t// non-word character with a space.  Always skip a\n\t\t\t// character when the word ends.  But only when the\n\t\t\t// good word can end.\n\t\t\tif (((!try_compound && !spell_iswordp_nmw(fword\n\t\t\t\t\t\t\t       + sp->ts_fidx,\n\t\t\t\t\t\t\t       curwin))\n\t\t\t\t    || fword_ends)\n\t\t\t\t&& fword[sp->ts_fidx] != NUL\n\t\t\t\t&& goodword_ends)\n\t\t\t{\n\t\t\t    int\t    l;\n\n\t\t\t    l = mb_ptr2len(fword + sp->ts_fidx);\n\t\t\t    if (fword_ends)\n\t\t\t    {\n\t\t\t\t// Copy the skipped character to preword.\n\t\t\t\tmch_memmove(preword + sp->ts_prewordlen,\n\t\t\t\t\t\t      fword + sp->ts_fidx, l);\n\t\t\t\tsp->ts_prewordlen += l;\n\t\t\t\tpreword[sp->ts_prewordlen] = NUL;\n\t\t\t    }\n\t\t\t    else\n\t\t\t\tsp->ts_score -= SCORE_SPLIT - SCORE_SUBST;\n\t\t\t    sp->ts_fidx += l;\n\t\t\t}\n\n\t\t\t// When compounding include compound flag in\n\t\t\t// compflags[] (already set above).  When splitting we\n\t\t\t// may start compounding over again.\n\t\t\tif (try_compound)\n\t\t\t    ++sp->ts_complen;\n\t\t\telse\n\t\t\t    sp->ts_compsplit = sp->ts_complen;\n\t\t\tsp->ts_prefixdepth = PFD_NOPREFIX;\n\n\t\t\t// set su->su_badflags to the caps type at this\n\t\t\t// position\n\t\t\tif (has_mbyte)\n\t\t\t    n = nofold_len(fword, sp->ts_fidx, su->su_badptr);\n\t\t\telse\n\t\t\t    n = sp->ts_fidx;\n\t\t\tsu->su_badflags = badword_captype(su->su_badptr + n,\n\t\t\t\t\t       su->su_badptr + su->su_badlen);\n\n\t\t\t// Restart at top of the tree.\n\t\t\tsp->ts_arridx = 0;\n\n\t\t\t// If there are postponed prefixes, try these too.\n\t\t\tif (pbyts != NULL)\n\t\t\t{\n\t\t\t    byts = pbyts;\n\t\t\t    idxs = pidxs;\n\t\t\t    sp->ts_prefixdepth = PFD_PREFIXTREE;\n\t\t\t    PROF_STORE(sp->ts_state)\n\t\t\t    sp->ts_state = STATE_NOPREFIX;\n\t\t\t}\n\t\t    }\n\t\t}\n\t    }\n\t    break;\n\n\tcase STATE_SPLITUNDO:\n\t    // Undo the changes done for word split or compound word.\n\t    su->su_badflags = sp->ts_save_badflags;\n\n\t    // Continue looking for NUL bytes.\n\t    PROF_STORE(sp->ts_state)\n\t    sp->ts_state = STATE_START;\n\n\t    // In case we went into the prefix tree.\n\t    byts = fbyts;\n\t    idxs = fidxs;\n\t    break;\n\n\tcase STATE_ENDNUL:\n\t    // Past the NUL bytes in the node.\n\t    su->su_badflags = sp->ts_save_badflags;\n\t    if (fword[sp->ts_fidx] == NUL && sp->ts_tcharlen == 0)\n\t    {\n\t\t// The badword ends, can't use STATE_PLAIN.\n\t\tPROF_STORE(sp->ts_state)\n\t\tsp->ts_state = STATE_DEL;\n\t\tbreak;\n\t    }\n\t    PROF_STORE(sp->ts_state)\n\t    sp->ts_state = STATE_PLAIN;\n\t    // FALLTHROUGH\n\n\tcase STATE_PLAIN:\n\t    // Go over all possible bytes at this node, add each to tword[]\n\t    // and use child node.  \"ts_curi\" is the index.\n\t    arridx = sp->ts_arridx;\n\t    if (sp->ts_curi > byts[arridx])\n\t    {\n\t\t// Done all bytes at this node, do next state.  When still at\n\t\t// already changed bytes skip the other tricks.\n\t\tPROF_STORE(sp->ts_state)\n\t\tif (sp->ts_fidx >= sp->ts_fidxtry)\n\t\t    sp->ts_state = STATE_DEL;\n\t\telse\n\t\t    sp->ts_state = STATE_FINAL;\n\t    }\n\t    else\n\t    {\n\t\tarridx += sp->ts_curi++;\n\t\tc = byts[arridx];\n\n\t\t// Normal byte, go one level deeper.  If it's not equal to the\n\t\t// byte in the bad word adjust the score.  But don't even try\n\t\t// when the byte was already changed.  And don't try when we\n\t\t// just deleted this byte, accepting it is always cheaper than\n\t\t// delete + substitute.\n\t\tif (c == fword[sp->ts_fidx]\n\t\t\t|| (sp->ts_tcharlen > 0 && sp->ts_isdiff != DIFF_NONE))\n\t\t    newscore = 0;\n\t\telse\n\t\t    newscore = SCORE_SUBST;\n\t\tif ((newscore == 0\n\t\t\t    || (sp->ts_fidx >= sp->ts_fidxtry\n\t\t\t\t&& ((sp->ts_flags & TSF_DIDDEL) == 0\n\t\t\t\t    || c != fword[sp->ts_delidx])))\n\t\t\t&& TRY_DEEPER(su, stack, depth, newscore))\n\t\t{\n\t\t    go_deeper(stack, depth, newscore);\n#ifdef DEBUG_TRIEWALK\n\t\t    if (newscore > 0)\n\t\t\tsprintf(changename[depth], \"%.*s-%s: subst %c to %c\",\n\t\t\t\tsp->ts_twordlen, tword, fword + sp->ts_fidx,\n\t\t\t\tfword[sp->ts_fidx], c);\n\t\t    else\n\t\t\tsprintf(changename[depth], \"%.*s-%s: accept %c\",\n\t\t\t\tsp->ts_twordlen, tword, fword + sp->ts_fidx,\n\t\t\t\tfword[sp->ts_fidx]);\n#endif\n\t\t    ++depth;\n\t\t    sp = &stack[depth];\n\t\t    if (fword[sp->ts_fidx] != NUL)\n\t\t\t++sp->ts_fidx;\n\t\t    tword[sp->ts_twordlen++] = c;\n\t\t    sp->ts_arridx = idxs[arridx];\n\t\t    if (newscore == SCORE_SUBST)\n\t\t\tsp->ts_isdiff = DIFF_YES;\n\t\t    if (has_mbyte)\n\t\t    {\n\t\t\t// Multi-byte characters are a bit complicated to\n\t\t\t// handle: They differ when any of the bytes differ\n\t\t\t// and then their length may also differ.\n\t\t\tif (sp->ts_tcharlen == 0)\n\t\t\t{\n\t\t\t    // First byte.\n\t\t\t    sp->ts_tcharidx = 0;\n\t\t\t    sp->ts_tcharlen = MB_BYTE2LEN(c);\n\t\t\t    sp->ts_fcharstart = sp->ts_fidx - 1;\n\t\t\t    sp->ts_isdiff = (newscore != 0)\n\t\t\t\t\t\t       ? DIFF_YES : DIFF_NONE;\n\t\t\t}\n\t\t\telse if (sp->ts_isdiff == DIFF_INSERT)\n\t\t\t    // When inserting trail bytes don't advance in the\n\t\t\t    // bad word.\n\t\t\t    --sp->ts_fidx;\n\t\t\tif (++sp->ts_tcharidx == sp->ts_tcharlen)\n\t\t\t{\n\t\t\t    // Last byte of character.\n\t\t\t    if (sp->ts_isdiff == DIFF_YES)\n\t\t\t    {\n\t\t\t\t// Correct ts_fidx for the byte length of the\n\t\t\t\t// character (we didn't check that before).\n\t\t\t\tsp->ts_fidx = sp->ts_fcharstart\n\t\t\t\t\t    + mb_ptr2len(\n\t\t\t\t\t\t    fword + sp->ts_fcharstart);\n\t\t\t\t// For changing a composing character adjust\n\t\t\t\t// the score from SCORE_SUBST to\n\t\t\t\t// SCORE_SUBCOMP.\n\t\t\t\tif (enc_utf8\n\t\t\t\t\t&& utf_iscomposing(\n\t\t\t\t\t    utf_ptr2char(tword\n\t\t\t\t\t\t+ sp->ts_twordlen\n\t\t\t\t\t\t\t   - sp->ts_tcharlen))\n\t\t\t\t\t&& utf_iscomposing(\n\t\t\t\t\t    utf_ptr2char(fword\n\t\t\t\t\t\t\t+ sp->ts_fcharstart)))\n\t\t\t\t    sp->ts_score -=\n\t\t\t\t\t\t  SCORE_SUBST - SCORE_SUBCOMP;\n\n\t\t\t\t// For a similar character adjust score from\n\t\t\t\t// SCORE_SUBST to SCORE_SIMILAR.\n\t\t\t\telse if (!soundfold\n\t\t\t\t\t&& slang->sl_has_map\n\t\t\t\t\t&& similar_chars(slang,\n\t\t\t\t\t    mb_ptr2char(tword\n\t\t\t\t\t\t+ sp->ts_twordlen\n\t\t\t\t\t\t\t   - sp->ts_tcharlen),\n\t\t\t\t\t    mb_ptr2char(fword\n\t\t\t\t\t\t\t+ sp->ts_fcharstart)))\n\t\t\t\t    sp->ts_score -=\n\t\t\t\t\t\t  SCORE_SUBST - SCORE_SIMILAR;\n\t\t\t    }\n\t\t\t    else if (sp->ts_isdiff == DIFF_INSERT\n\t\t\t\t\t && sp->ts_twordlen > sp->ts_tcharlen)\n\t\t\t    {\n\t\t\t\tp = tword + sp->ts_twordlen - sp->ts_tcharlen;\n\t\t\t\tc = mb_ptr2char(p);\n\t\t\t\tif (enc_utf8 && utf_iscomposing(c))\n\t\t\t\t{\n\t\t\t\t    // Inserting a composing char doesn't\n\t\t\t\t    // count that much.\n\t\t\t\t    sp->ts_score -= SCORE_INS - SCORE_INSCOMP;\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t    // If the previous character was the same,\n\t\t\t\t    // thus doubling a character, give a bonus\n\t\t\t\t    // to the score.  Also for the soundfold\n\t\t\t\t    // tree (might seem illogical but does\n\t\t\t\t    // give better scores).\n\t\t\t\t    MB_PTR_BACK(tword, p);\n\t\t\t\t    if (c == mb_ptr2char(p))\n\t\t\t\t\tsp->ts_score -= SCORE_INS\n\t\t\t\t\t\t\t       - SCORE_INSDUP;\n\t\t\t\t}\n\t\t\t    }\n\n\t\t\t    // Starting a new char, reset the length.\n\t\t\t    sp->ts_tcharlen = 0;\n\t\t\t}\n\t\t    }\n\t\t    else\n\t\t    {\n\t\t\t// If we found a similar char adjust the score.\n\t\t\t// We do this after calling go_deeper() because\n\t\t\t// it's slow.\n\t\t\tif (newscore != 0\n\t\t\t\t&& !soundfold\n\t\t\t\t&& slang->sl_has_map\n\t\t\t\t&& similar_chars(slang,\n\t\t\t\t\t\t   c, fword[sp->ts_fidx - 1]))\n\t\t\t    sp->ts_score -= SCORE_SUBST - SCORE_SIMILAR;\n\t\t    }\n\t\t}\n\t    }\n\t    break;\n\n\tcase STATE_DEL:\n\t    // When past the first byte of a multi-byte char don't try\n\t    // delete/insert/swap a character.\n\t    if (has_mbyte && sp->ts_tcharlen > 0)\n\t    {\n\t\tPROF_STORE(sp->ts_state)\n\t\tsp->ts_state = STATE_FINAL;\n\t\tbreak;\n\t    }\n\t    // Try skipping one character in the bad word (delete it).\n\t    PROF_STORE(sp->ts_state)\n\t    sp->ts_state = STATE_INS_PREP;\n\t    sp->ts_curi = 1;\n\t    if (soundfold && sp->ts_fidx == 0 && fword[sp->ts_fidx] == '*')\n\t\t// Deleting a vowel at the start of a word counts less, see\n\t\t// soundalike_score().\n\t\tnewscore = 2 * SCORE_DEL / 3;\n\t    else\n\t\tnewscore = SCORE_DEL;\n\t    if (fword[sp->ts_fidx] != NUL\n\t\t\t\t    && TRY_DEEPER(su, stack, depth, newscore))\n\t    {\n\t\tgo_deeper(stack, depth, newscore);\n#ifdef DEBUG_TRIEWALK\n\t\tsprintf(changename[depth], \"%.*s-%s: delete %c\",\n\t\t\tsp->ts_twordlen, tword, fword + sp->ts_fidx,\n\t\t\tfword[sp->ts_fidx]);\n#endif\n\t\t++depth;\n\n\t\t// Remember what character we deleted, so that we can avoid\n\t\t// inserting it again.\n\t\tstack[depth].ts_flags |= TSF_DIDDEL;\n\t\tstack[depth].ts_delidx = sp->ts_fidx;\n\n\t\t// Advance over the character in fword[].  Give a bonus to the\n\t\t// score if the same character is following \"nn\" -> \"n\".  It's\n\t\t// a bit illogical for soundfold tree but it does give better\n\t\t// results.\n\t\tif (has_mbyte)\n\t\t{\n\t\t    c = mb_ptr2char(fword + sp->ts_fidx);\n\t\t    stack[depth].ts_fidx += mb_ptr2len(fword + sp->ts_fidx);\n\t\t    if (enc_utf8 && utf_iscomposing(c))\n\t\t\tstack[depth].ts_score -= SCORE_DEL - SCORE_DELCOMP;\n\t\t    else if (c == mb_ptr2char(fword + stack[depth].ts_fidx))\n\t\t\tstack[depth].ts_score -= SCORE_DEL - SCORE_DELDUP;\n\t\t}\n\t\telse\n\t\t{\n\t\t    ++stack[depth].ts_fidx;\n\t\t    if (fword[sp->ts_fidx] == fword[sp->ts_fidx + 1])\n\t\t\tstack[depth].ts_score -= SCORE_DEL - SCORE_DELDUP;\n\t\t}\n\t\tbreak;\n\t    }\n\t    // FALLTHROUGH\n\n\tcase STATE_INS_PREP:\n\t    if (sp->ts_flags & TSF_DIDDEL)\n\t    {\n\t\t// If we just deleted a byte then inserting won't make sense,\n\t\t// a substitute is always cheaper.\n\t\tPROF_STORE(sp->ts_state)\n\t\tsp->ts_state = STATE_SWAP;\n\t\tbreak;\n\t    }\n\n\t    // skip over NUL bytes\n\t    n = sp->ts_arridx;\n\t    for (;;)\n\t    {\n\t\tif (sp->ts_curi > byts[n])\n\t\t{\n\t\t    // Only NUL bytes at this node, go to next state.\n\t\t    PROF_STORE(sp->ts_state)\n\t\t    sp->ts_state = STATE_SWAP;\n\t\t    break;\n\t\t}\n\t\tif (byts[n + sp->ts_curi] != NUL)\n\t\t{\n\t\t    // Found a byte to insert.\n\t\t    PROF_STORE(sp->ts_state)\n\t\t    sp->ts_state = STATE_INS;\n\t\t    break;\n\t\t}\n\t\t++sp->ts_curi;\n\t    }\n\t    break;\n\n\t    // FALLTHROUGH\n\n\tcase STATE_INS:\n\t    // Insert one byte.  Repeat this for each possible byte at this\n\t    // node.\n\t    n = sp->ts_arridx;\n\t    if (sp->ts_curi > byts[n])\n\t    {\n\t\t// Done all bytes at this node, go to next state.\n\t\tPROF_STORE(sp->ts_state)\n\t\tsp->ts_state = STATE_SWAP;\n\t\tbreak;\n\t    }\n\n\t    // Do one more byte at this node, but:\n\t    // - Skip NUL bytes.\n\t    // - Skip the byte if it's equal to the byte in the word,\n\t    //   accepting that byte is always better.\n\t    n += sp->ts_curi++;\n\t    c = byts[n];\n\t    if (soundfold && sp->ts_twordlen == 0 && c == '*')\n\t\t// Inserting a vowel at the start of a word counts less,\n\t\t// see soundalike_score().\n\t\tnewscore = 2 * SCORE_INS / 3;\n\t    else\n\t\tnewscore = SCORE_INS;\n\t    if (c != fword[sp->ts_fidx]\n\t\t\t\t    && TRY_DEEPER(su, stack, depth, newscore))\n\t    {\n\t\tgo_deeper(stack, depth, newscore);\n#ifdef DEBUG_TRIEWALK\n\t\tsprintf(changename[depth], \"%.*s-%s: insert %c\",\n\t\t\tsp->ts_twordlen, tword, fword + sp->ts_fidx,\n\t\t\tc);\n#endif\n\t\t++depth;\n\t\tsp = &stack[depth];\n\t\ttword[sp->ts_twordlen++] = c;\n\t\tsp->ts_arridx = idxs[n];\n\t\tif (has_mbyte)\n\t\t{\n\t\t    fl = MB_BYTE2LEN(c);\n\t\t    if (fl > 1)\n\t\t    {\n\t\t\t// There are following bytes for the same character.\n\t\t\t// We must find all bytes before trying\n\t\t\t// delete/insert/swap/etc.\n\t\t\tsp->ts_tcharlen = fl;\n\t\t\tsp->ts_tcharidx = 1;\n\t\t\tsp->ts_isdiff = DIFF_INSERT;\n\t\t    }\n\t\t}\n\t\telse\n\t\t    fl = 1;\n\t\tif (fl == 1)\n\t\t{\n\t\t    // If the previous character was the same, thus doubling a\n\t\t    // character, give a bonus to the score.  Also for\n\t\t    // soundfold words (illogical but does give a better\n\t\t    // score).\n\t\t    if (sp->ts_twordlen >= 2\n\t\t\t\t\t   && tword[sp->ts_twordlen - 2] == c)\n\t\t\tsp->ts_score -= SCORE_INS - SCORE_INSDUP;\n\t\t}\n\t    }\n\t    break;\n\n\tcase STATE_SWAP:\n\t    // Swap two bytes in the bad word: \"12\" -> \"21\".\n\t    // We change \"fword\" here, it's changed back afterwards at\n\t    // STATE_UNSWAP.\n\t    p = fword + sp->ts_fidx;\n\t    c = *p;\n\t    if (c == NUL)\n\t    {\n\t\t// End of word, can't swap or replace.\n\t\tPROF_STORE(sp->ts_state)\n\t\tsp->ts_state = STATE_FINAL;\n\t\tbreak;\n\t    }\n\n\t    // Don't swap if the first character is not a word character.\n\t    // SWAP3 etc. also don't make sense then.\n\t    if (!soundfold && !spell_iswordp(p, curwin))\n\t    {\n\t\tPROF_STORE(sp->ts_state)\n\t\tsp->ts_state = STATE_REP_INI;\n\t\tbreak;\n\t    }\n\n\t    if (has_mbyte)\n\t    {\n\t\tn = MB_CPTR2LEN(p);\n\t\tc = mb_ptr2char(p);\n\t\tif (p[n] == NUL)\n\t\t    c2 = NUL;\n\t\telse if (!soundfold && !spell_iswordp(p + n, curwin))\n\t\t    c2 = c; // don't swap non-word char\n\t\telse\n\t\t    c2 = mb_ptr2char(p + n);\n\t    }\n\t    else\n\t    {\n\t\tif (p[1] == NUL)\n\t\t    c2 = NUL;\n\t\telse if (!soundfold && !spell_iswordp(p + 1, curwin))\n\t\t    c2 = c; // don't swap non-word char\n\t\telse\n\t\t    c2 = p[1];\n\t    }\n\n\t    // When the second character is NUL we can't swap.\n\t    if (c2 == NUL)\n\t    {\n\t\tPROF_STORE(sp->ts_state)\n\t\tsp->ts_state = STATE_REP_INI;\n\t\tbreak;\n\t    }\n\n\t    // When characters are identical, swap won't do anything.\n\t    // Also get here if the second char is not a word character.\n\t    if (c == c2)\n\t    {\n\t\tPROF_STORE(sp->ts_state)\n\t\tsp->ts_state = STATE_SWAP3;\n\t\tbreak;\n\t    }\n\t    if (c2 != NUL && TRY_DEEPER(su, stack, depth, SCORE_SWAP))\n\t    {\n\t\tgo_deeper(stack, depth, SCORE_SWAP);\n#ifdef DEBUG_TRIEWALK\n\t\tsprintf(changename[depth], \"%.*s-%s: swap %c and %c\",\n\t\t\tsp->ts_twordlen, tword, fword + sp->ts_fidx,\n\t\t\tc, c2);\n#endif\n\t\tPROF_STORE(sp->ts_state)\n\t\tsp->ts_state = STATE_UNSWAP;\n\t\t++depth;\n\t\tif (has_mbyte)\n\t\t{\n\t\t    fl = mb_char2len(c2);\n\t\t    mch_memmove(p, p + n, fl);\n\t\t    mb_char2bytes(c, p + fl);\n\t\t    stack[depth].ts_fidxtry = sp->ts_fidx + n + fl;\n\t\t}\n\t\telse\n\t\t{\n\t\t    p[0] = c2;\n\t\t    p[1] = c;\n\t\t    stack[depth].ts_fidxtry = sp->ts_fidx + 2;\n\t\t}\n\t    }\n\t    else\n\t    {\n\t\t// If this swap doesn't work then SWAP3 won't either.\n\t\tPROF_STORE(sp->ts_state)\n\t\tsp->ts_state = STATE_REP_INI;\n\t    }\n\t    break;\n\n\tcase STATE_UNSWAP:\n\t    // Undo the STATE_SWAP swap: \"21\" -> \"12\".\n\t    p = fword + sp->ts_fidx;\n\t    if (has_mbyte)\n\t    {\n\t\tn = mb_ptr2len(p);\n\t\tc = mb_ptr2char(p + n);\n\t\tmch_memmove(p + mb_ptr2len(p + n), p, n);\n\t\tmb_char2bytes(c, p);\n\t    }\n\t    else\n\t    {\n\t\tc = *p;\n\t\t*p = p[1];\n\t\tp[1] = c;\n\t    }\n\t    // FALLTHROUGH\n\n\tcase STATE_SWAP3:\n\t    // Swap two bytes, skipping one: \"123\" -> \"321\".  We change\n\t    // \"fword\" here, it's changed back afterwards at STATE_UNSWAP3.\n\t    p = fword + sp->ts_fidx;\n\t    if (has_mbyte)\n\t    {\n\t\tn = MB_CPTR2LEN(p);\n\t\tc = mb_ptr2char(p);\n\t\tfl = MB_CPTR2LEN(p + n);\n\t\tc2 = mb_ptr2char(p + n);\n\t\tif (!soundfold && !spell_iswordp(p + n + fl, curwin))\n\t\t    c3 = c;\t// don't swap non-word char\n\t\telse\n\t\t    c3 = mb_ptr2char(p + n + fl);\n\t    }\n\t    else\n\t    {\n\t\tc = *p;\n\t\tc2 = p[1];\n\t\tif (!soundfold && !spell_iswordp(p + 2, curwin))\n\t\t    c3 = c;\t// don't swap non-word char\n\t\telse\n\t\t    c3 = p[2];\n\t    }\n\n\t    // When characters are identical: \"121\" then SWAP3 result is\n\t    // identical, ROT3L result is same as SWAP: \"211\", ROT3L result is\n\t    // same as SWAP on next char: \"112\".  Thus skip all swapping.\n\t    // Also skip when c3 is NUL.\n\t    // Also get here when the third character is not a word character.\n\t    // Second character may any char: \"a.b\" -> \"b.a\"\n\t    if (c == c3 || c3 == NUL)\n\t    {\n\t\tPROF_STORE(sp->ts_state)\n\t\tsp->ts_state = STATE_REP_INI;\n\t\tbreak;\n\t    }\n\t    if (TRY_DEEPER(su, stack, depth, SCORE_SWAP3))\n\t    {\n\t\tgo_deeper(stack, depth, SCORE_SWAP3);\n#ifdef DEBUG_TRIEWALK\n\t\tsprintf(changename[depth], \"%.*s-%s: swap3 %c and %c\",\n\t\t\tsp->ts_twordlen, tword, fword + sp->ts_fidx,\n\t\t\tc, c3);\n#endif\n\t\tPROF_STORE(sp->ts_state)\n\t\tsp->ts_state = STATE_UNSWAP3;\n\t\t++depth;\n\t\tif (has_mbyte)\n\t\t{\n\t\t    tl = mb_char2len(c3);\n\t\t    mch_memmove(p, p + n + fl, tl);\n\t\t    mb_char2bytes(c2, p + tl);\n\t\t    mb_char2bytes(c, p + fl + tl);\n\t\t    stack[depth].ts_fidxtry = sp->ts_fidx + n + fl + tl;\n\t\t}\n\t\telse\n\t\t{\n\t\t    p[0] = p[2];\n\t\t    p[2] = c;\n\t\t    stack[depth].ts_fidxtry = sp->ts_fidx + 3;\n\t\t}\n\t    }\n\t    else\n\t    {\n\t\tPROF_STORE(sp->ts_state)\n\t\tsp->ts_state = STATE_REP_INI;\n\t    }\n\t    break;\n\n\tcase STATE_UNSWAP3:\n\t    // Undo STATE_SWAP3: \"321\" -> \"123\"\n\t    p = fword + sp->ts_fidx;\n\t    if (has_mbyte)\n\t    {\n\t\tn = mb_ptr2len(p);\n\t\tc2 = mb_ptr2char(p + n);\n\t\tfl = mb_ptr2len(p + n);\n\t\tc = mb_ptr2char(p + n + fl);\n\t\ttl = mb_ptr2len(p + n + fl);\n\t\tmch_memmove(p + fl + tl, p, n);\n\t\tmb_char2bytes(c, p);\n\t\tmb_char2bytes(c2, p + tl);\n\t\tp = p + tl;\n\t    }\n\t    else\n\t    {\n\t\tc = *p;\n\t\t*p = p[2];\n\t\tp[2] = c;\n\t\t++p;\n\t    }\n\n\t    if (!soundfold && !spell_iswordp(p, curwin))\n\t    {\n\t\t// Middle char is not a word char, skip the rotate.  First and\n\t\t// third char were already checked at swap and swap3.\n\t\tPROF_STORE(sp->ts_state)\n\t\tsp->ts_state = STATE_REP_INI;\n\t\tbreak;\n\t    }\n\n\t    // Rotate three characters left: \"123\" -> \"231\".  We change\n\t    // \"fword\" here, it's changed back afterwards at STATE_UNROT3L.\n\t    if (TRY_DEEPER(su, stack, depth, SCORE_SWAP3))\n\t    {\n\t\tgo_deeper(stack, depth, SCORE_SWAP3);\n#ifdef DEBUG_TRIEWALK\n\t\tp = fword + sp->ts_fidx;\n\t\tsprintf(changename[depth], \"%.*s-%s: rotate left %c%c%c\",\n\t\t\tsp->ts_twordlen, tword, fword + sp->ts_fidx,\n\t\t\tp[0], p[1], p[2]);\n#endif\n\t\tPROF_STORE(sp->ts_state)\n\t\tsp->ts_state = STATE_UNROT3L;\n\t\t++depth;\n\t\tp = fword + sp->ts_fidx;\n\t\tif (has_mbyte)\n\t\t{\n\t\t    n = MB_CPTR2LEN(p);\n\t\t    c = mb_ptr2char(p);\n\t\t    fl = MB_CPTR2LEN(p + n);\n\t\t    fl += MB_CPTR2LEN(p + n + fl);\n\t\t    mch_memmove(p, p + n, fl);\n\t\t    mb_char2bytes(c, p + fl);\n\t\t    stack[depth].ts_fidxtry = sp->ts_fidx + n + fl;\n\t\t}\n\t\telse\n\t\t{\n\t\t    c = *p;\n\t\t    *p = p[1];\n\t\t    p[1] = p[2];\n\t\t    p[2] = c;\n\t\t    stack[depth].ts_fidxtry = sp->ts_fidx + 3;\n\t\t}\n\t    }\n\t    else\n\t    {\n\t\tPROF_STORE(sp->ts_state)\n\t\tsp->ts_state = STATE_REP_INI;\n\t    }\n\t    break;\n\n\tcase STATE_UNROT3L:\n\t    // Undo ROT3L: \"231\" -> \"123\"\n\t    p = fword + sp->ts_fidx;\n\t    if (has_mbyte)\n\t    {\n\t\tn = mb_ptr2len(p);\n\t\tn += mb_ptr2len(p + n);\n\t\tc = mb_ptr2char(p + n);\n\t\ttl = mb_ptr2len(p + n);\n\t\tmch_memmove(p + tl, p, n);\n\t\tmb_char2bytes(c, p);\n\t    }\n\t    else\n\t    {\n\t\tc = p[2];\n\t\tp[2] = p[1];\n\t\tp[1] = *p;\n\t\t*p = c;\n\t    }\n\n\t    // Rotate three bytes right: \"123\" -> \"312\".  We change \"fword\"\n\t    // here, it's changed back afterwards at STATE_UNROT3R.\n\t    if (TRY_DEEPER(su, stack, depth, SCORE_SWAP3))\n\t    {\n\t\tgo_deeper(stack, depth, SCORE_SWAP3);\n#ifdef DEBUG_TRIEWALK\n\t\tp = fword + sp->ts_fidx;\n\t\tsprintf(changename[depth], \"%.*s-%s: rotate right %c%c%c\",\n\t\t\tsp->ts_twordlen, tword, fword + sp->ts_fidx,\n\t\t\tp[0], p[1], p[2]);\n#endif\n\t\tPROF_STORE(sp->ts_state)\n\t\tsp->ts_state = STATE_UNROT3R;\n\t\t++depth;\n\t\tp = fword + sp->ts_fidx;\n\t\tif (has_mbyte)\n\t\t{\n\t\t    n = MB_CPTR2LEN(p);\n\t\t    n += MB_CPTR2LEN(p + n);\n\t\t    c = mb_ptr2char(p + n);\n\t\t    tl = MB_CPTR2LEN(p + n);\n\t\t    mch_memmove(p + tl, p, n);\n\t\t    mb_char2bytes(c, p);\n\t\t    stack[depth].ts_fidxtry = sp->ts_fidx + n + tl;\n\t\t}\n\t\telse\n\t\t{\n\t\t    c = p[2];\n\t\t    p[2] = p[1];\n\t\t    p[1] = *p;\n\t\t    *p = c;\n\t\t    stack[depth].ts_fidxtry = sp->ts_fidx + 3;\n\t\t}\n\t    }\n\t    else\n\t    {\n\t\tPROF_STORE(sp->ts_state)\n\t\tsp->ts_state = STATE_REP_INI;\n\t    }\n\t    break;\n\n\tcase STATE_UNROT3R:\n\t    // Undo ROT3R: \"312\" -> \"123\"\n\t    p = fword + sp->ts_fidx;\n\t    if (has_mbyte)\n\t    {\n\t\tc = mb_ptr2char(p);\n\t\ttl = mb_ptr2len(p);\n\t\tn = mb_ptr2len(p + tl);\n\t\tn += mb_ptr2len(p + tl + n);\n\t\tmch_memmove(p, p + tl, n);\n\t\tmb_char2bytes(c, p + n);\n\t    }\n\t    else\n\t    {\n\t\tc = *p;\n\t\t*p = p[1];\n\t\tp[1] = p[2];\n\t\tp[2] = c;\n\t    }\n\t    // FALLTHROUGH\n\n\tcase STATE_REP_INI:\n\t    // Check if matching with REP items from the .aff file would work.\n\t    // Quickly skip if:\n\t    // - there are no REP items and we are not in the soundfold trie\n\t    // - the score is going to be too high anyway\n\t    // - already applied a REP item or swapped here\n\t    if ((lp->lp_replang == NULL && !soundfold)\n\t\t    || sp->ts_score + SCORE_REP >= su->su_maxscore\n\t\t    || sp->ts_fidx < sp->ts_fidxtry)\n\t    {\n\t\tPROF_STORE(sp->ts_state)\n\t\tsp->ts_state = STATE_FINAL;\n\t\tbreak;\n\t    }\n\n\t    // Use the first byte to quickly find the first entry that may\n\t    // match.  If the index is -1 there is none.\n\t    if (soundfold)\n\t\tsp->ts_curi = slang->sl_repsal_first[fword[sp->ts_fidx]];\n\t    else\n\t\tsp->ts_curi = lp->lp_replang->sl_rep_first[fword[sp->ts_fidx]];\n\n\t    if (sp->ts_curi < 0)\n\t    {\n\t\tPROF_STORE(sp->ts_state)\n\t\tsp->ts_state = STATE_FINAL;\n\t\tbreak;\n\t    }\n\n\t    PROF_STORE(sp->ts_state)\n\t    sp->ts_state = STATE_REP;\n\t    // FALLTHROUGH\n\n\tcase STATE_REP:\n\t    // Try matching with REP items from the .aff file.  For each match\n\t    // replace the characters and check if the resulting word is\n\t    // valid.\n\t    p = fword + sp->ts_fidx;\n\n\t    if (soundfold)\n\t\tgap = &slang->sl_repsal;\n\t    else\n\t\tgap = &lp->lp_replang->sl_rep;\n\t    while (sp->ts_curi < gap->ga_len)\n\t    {\n\t\tftp = (fromto_T *)gap->ga_data + sp->ts_curi++;\n\t\tif (*ftp->ft_from != *p)\n\t\t{\n\t\t    // past possible matching entries\n\t\t    sp->ts_curi = gap->ga_len;\n\t\t    break;\n\t\t}\n\t\tif (STRNCMP(ftp->ft_from, p, STRLEN(ftp->ft_from)) == 0\n\t\t\t&& TRY_DEEPER(su, stack, depth, SCORE_REP))\n\t\t{\n\t\t    go_deeper(stack, depth, SCORE_REP);\n#ifdef DEBUG_TRIEWALK\n\t\t    sprintf(changename[depth], \"%.*s-%s: replace %s with %s\",\n\t\t\t    sp->ts_twordlen, tword, fword + sp->ts_fidx,\n\t\t\t    ftp->ft_from, ftp->ft_to);\n#endif\n\t\t    // Need to undo this afterwards.\n\t\t    PROF_STORE(sp->ts_state)\n\t\t    sp->ts_state = STATE_REP_UNDO;\n\n\t\t    // Change the \"from\" to the \"to\" string.\n\t\t    ++depth;\n\t\t    fl = (int)STRLEN(ftp->ft_from);\n\t\t    tl = (int)STRLEN(ftp->ft_to);\n\t\t    if (fl != tl)\n\t\t    {\n\t\t\tSTRMOVE(p + tl, p + fl);\n\t\t\trepextra += tl - fl;\n\t\t    }\n\t\t    mch_memmove(p, ftp->ft_to, tl);\n\t\t    stack[depth].ts_fidxtry = sp->ts_fidx + tl;\n\t\t    stack[depth].ts_tcharlen = 0;\n\t\t    break;\n\t\t}\n\t    }\n\n\t    if (sp->ts_curi >= gap->ga_len && sp->ts_state == STATE_REP)\n\t    {\n\t\t// No (more) matches.\n\t\tPROF_STORE(sp->ts_state)\n\t\tsp->ts_state = STATE_FINAL;\n\t    }\n\n\t    break;\n\n\tcase STATE_REP_UNDO:\n\t    // Undo a REP replacement and continue with the next one.\n\t    if (soundfold)\n\t\tgap = &slang->sl_repsal;\n\t    else\n\t\tgap = &lp->lp_replang->sl_rep;\n\t    ftp = (fromto_T *)gap->ga_data + sp->ts_curi - 1;\n\t    fl = (int)STRLEN(ftp->ft_from);\n\t    tl = (int)STRLEN(ftp->ft_to);\n\t    p = fword + sp->ts_fidx;\n\t    if (fl != tl)\n\t    {\n\t\tSTRMOVE(p + fl, p + tl);\n\t\trepextra -= tl - fl;\n\t    }\n\t    mch_memmove(p, ftp->ft_from, fl);\n\t    PROF_STORE(sp->ts_state)\n\t    sp->ts_state = STATE_REP;\n\t    break;\n\n\tdefault:\n\t    // Did all possible states at this level, go up one level.\n\t    --depth;\n\n\t    if (depth >= 0 && stack[depth].ts_prefixdepth == PFD_PREFIXTREE)\n\t    {\n\t\t// Continue in or go back to the prefix tree.\n\t\tbyts = pbyts;\n\t\tidxs = pidxs;\n\t    }\n\n\t    // Don't check for CTRL-C too often, it takes time.\n\t    if (--breakcheckcount == 0)\n\t    {\n\t\tui_breakcheck();\n\t\tbreakcheckcount = 1000;\n#ifdef FEAT_RELTIME\n\t\tif (spell_suggest_timeout > 0\n\t\t\t\t\t  && profile_passed_limit(&time_limit))\n\t\t    got_int = TRUE;\n#endif\n\t    }\n\t}\n    }\n}",
        "func_hash": 86190004113264578506184029642372711349,
        "file_name": "spellsuggest.c",
        "file_hash": 224942464208559430024115846607965193151,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2022-2126",
        "cve_desc": "Out-of-bounds Read in GitHub repository vim/vim prior to 8.2.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-2126",
        "func_name": "suggest_trie_walk",
        "diff": [
            "diff --git a/src/spellsuggest.c b/src/spellsuggest.c\nindex 5b460a3eaaef6f..8f9756534fa2e5 100644\n--- a/src/spellsuggest.c\n+++ b/src/spellsuggest.c\n@@ -1973,7 +1973,8 @@ suggest_trie_walk(\n \t\t\t    sp->ts_isdiff = (newscore != 0)\n \t\t\t\t\t\t       ? DIFF_YES : DIFF_NONE;\n \t\t\t}\n-\t\t\telse if (sp->ts_isdiff == DIFF_INSERT)\n+\t\t\telse if (sp->ts_isdiff == DIFF_INSERT\n+\t\t\t\t\t\t\t    && sp->ts_fidx > 0)\n \t\t\t    // When inserting trail bytes don't advance in the\n \t\t\t    // bad word.\n \t\t\t    --sp->ts_fidx;\ndiff --git a/src/testdir/test_spell.vim b/src/testdir/test_spell.vim\nindex aa5744475338fa..0fd5ed91780fb0 100644\n--- a/src/testdir/test_spell.vim\n+++ b/src/testdir/test_spell.vim\n@@ -70,6 +70,16 @@ func Test_z_equal_on_invalid_utf8_word()\n   bwipe!\n endfunc\n \n+func Test_z_equal_on_single_character()\n+  \" this was decrementing the index below zero\n+  new\n+  norm a0\\\ufffd\n+  norm zW\n+  norm \u0016z=\n+\n+  bwipe!\n+endfunc\n+\n \" Test spellbadword() with argument\n func Test_spellbadword()\n   set spell\ndiff --git a/src/version.c b/src/version.c\nindex 5411e1c189f3e6..0a422742f1ad21 100644\n--- a/src/version.c\n+++ b/src/version.c\n@@ -734,6 +734,8 @@ static char *(features[]) =\n \n static int included_patches[] =\n {   /* Add new patch number below this line */\n+/**/\n+    5123,\n /**/\n     5122,\n /**/\n"
        ],
        "func_after": []
    },
    {
        "idx": 200379,
        "project": "radare2",
        "commit_id": "48f0ea79f99174fb0a62cb2354e13496ce5b7c44",
        "project_url": "https://github.com/radare/radare2",
        "commit_url": "https://github.com/radareorg/radare2/commit/48f0ea79f99174fb0a62cb2354e13496ce5b7c44",
        "commit_message": "Fix null deref in ne parser ##crash\n\n* Reported by @cnitlrt via huntr.dev\n* BountyID: d8b6d239-6d7b-4783-b26b-5be848c01aa1/\n* Reproducer: nenull",
        "target": 1,
        "irrelevant": 1,
        "func_before": "RList *r_bin_ne_get_segments(r_bin_ne_obj_t *bin) {\n\tint i;\n\tif (!bin) {\n\t\treturn NULL;\n\t}\n\tRList *segments = r_list_newf (free);\n\tfor (i = 0; i < bin->ne_header->SegCount; i++) {\n\t\tRBinSection *bs = R_NEW0 (RBinSection);\n\t\tif (!bs) {\n\t\t\treturn segments;\n\t\t}\n\t\tNE_image_segment_entry *se = &bin->segment_entries[i];\n\t\tbs->size = se->length;\n\t\tbs->vsize = se->minAllocSz ? se->minAllocSz : 64000;\n\t\tbs->bits = R_SYS_BITS_16;\n\t\tbs->is_data = se->flags & IS_DATA;\n\t\tbs->perm = __translate_perms (se->flags);\n\t\tbs->paddr = (ut64)se->offset * bin->alignment;\n\t\tbs->name = r_str_newf (\"%s.%\" PFMT64d, se->flags & IS_MOVEABLE ? \"MOVEABLE\" : \"FIXED\", bs->paddr);\n\t\tbs->is_segment = true;\n\t\tr_list_append (segments, bs);\n\t}\n\tbin->segments = segments;\n\treturn segments;\n}",
        "func_hash": 32265811031369210493685487313253460681,
        "file_name": "ne.c",
        "file_hash": 158187364999589473605822811150926540610,
        "cwe": [
            "CWE-476"
        ],
        "cve": "CVE-2022-1382",
        "cve_desc": "NULL Pointer Dereference in GitHub repository radareorg/radare2 prior to 5.6.8. This vulnerability is capable of making the radare2 crash, thus affecting the availability of the system.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-1382",
        "func_name": "r_bin_ne_get_segments",
        "diff": [
            "diff --git a/libr/bin/format/ne/ne.c b/libr/bin/format/ne/ne.c\nindex d9dc886d2177a..e61ca7049101e 100644\n--- a/libr/bin/format/ne/ne.c\n+++ b/libr/bin/format/ne/ne.c\n@@ -77,7 +77,7 @@ static char *__func_name_from_ord(const char *module, ut16 ordinal) {\n \n RList *r_bin_ne_get_segments(r_bin_ne_obj_t *bin) {\n \tint i;\n-\tif (!bin) {\n+\tif (!bin || !bin->segment_entries) {\n \t\treturn NULL;\n \t}\n \tRList *segments = r_list_newf (free);\n"
        ],
        "func_after": []
    },
    {
        "idx": 200672,
        "project": "qemu",
        "commit_id": "bc6f28995ff88f5d82c38afcfd65406f0ae375aa",
        "project_url": "https://github.com/bonzini/qemu",
        "commit_url": "https://git.qemu.org/?p=qemu.git;a=commit;h=bc6f28995ff88f5d82c38afcfd65406f0ae375aa",
        "commit_message": "hw/sd: sdhci: Correctly set the controller status for ADMA\n\nWhen an ADMA transfer is started, the codes forget to set the\ncontroller status to indicate a transfer is in progress.\n\nWith this fix, the following 2 reproducers:\n\nhttps://paste.debian.net/plain/1185136\nhttps://paste.debian.net/plain/1185141\n\ncannot be reproduced with the following QEMU command line:\n\n$ qemu-system-x86_64 -nographic -machine accel=qtest -m 512M \\\n      -nodefaults -device sdhci-pci,sd-spec-version=3 \\\n      -drive if=sd,index=0,file=null-co://,format=raw,id=mydrive \\\n      -device sd-card,drive=mydrive -qtest stdio\n\nCc: qemu-stable@nongnu.org\nFixes: CVE-2020-17380\nFixes: CVE-2020-25085\nFixes: CVE-2021-3409\nFixes: d7dfca0807a0 (\"hw/sdhci: introduce standard SD host controller\")\nReported-by: Alexander Bulekov <alxndr@bu.edu>\nReported-by: Cornelius Aschermann (Ruhr-Universit\u00e4t Bochum)\nReported-by: Sergej Schumilo (Ruhr-Universit\u00e4t Bochum)\nReported-by: Simon W\u00f6rner (Ruhr-Universit\u00e4t Bochum)\nBuglink: https://bugs.launchpad.net/qemu/+bug/1892960\nBuglink: https://bugs.launchpad.net/qemu/+bug/1909418\nBuglink: https://bugzilla.redhat.com/show_bug.cgi?id=1928146\nTested-by: Alexander Bulekov <alxndr@bu.edu>\nReviewed-by: Philippe Mathieu-Daud\u00e9 <f4bug@amsat.org>\nSigned-off-by: Bin Meng <bmeng.cn@gmail.com>\nMessage-Id: <20210303122639.20004-4-bmeng.cn@gmail.com>\nSigned-off-by: Philippe Mathieu-Daud\u00e9 <f4bug@amsat.org>",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static void sdhci_do_adma(SDHCIState *s)\n{\n    unsigned int begin, length;\n    const uint16_t block_size = s->blksize & BLOCK_SIZE_MASK;\n    ADMADescr dscr = {};\n    int i;\n\n    if (s->trnmod & SDHC_TRNS_BLK_CNT_EN && !s->blkcnt) {\n        /* Stop Multiple Transfer */\n        sdhci_end_transfer(s);\n        return;\n    }\n\n    for (i = 0; i < SDHC_ADMA_DESCS_PER_DELAY; ++i) {\n        s->admaerr &= ~SDHC_ADMAERR_LENGTH_MISMATCH;\n\n        get_adma_description(s, &dscr);\n        trace_sdhci_adma_loop(dscr.addr, dscr.length, dscr.attr);\n\n        if ((dscr.attr & SDHC_ADMA_ATTR_VALID) == 0) {\n            /* Indicate that error occurred in ST_FDS state */\n            s->admaerr &= ~SDHC_ADMAERR_STATE_MASK;\n            s->admaerr |= SDHC_ADMAERR_STATE_ST_FDS;\n\n            /* Generate ADMA error interrupt */\n            if (s->errintstsen & SDHC_EISEN_ADMAERR) {\n                s->errintsts |= SDHC_EIS_ADMAERR;\n                s->norintsts |= SDHC_NIS_ERR;\n            }\n\n            sdhci_update_irq(s);\n            return;\n        }\n\n        length = dscr.length ? dscr.length : 64 * KiB;\n\n        switch (dscr.attr & SDHC_ADMA_ATTR_ACT_MASK) {\n        case SDHC_ADMA_ATTR_ACT_TRAN:  /* data transfer */\n            if (s->trnmod & SDHC_TRNS_READ) {\n                while (length) {\n                    if (s->data_count == 0) {\n                        sdbus_read_data(&s->sdbus, s->fifo_buffer, block_size);\n                    }\n                    begin = s->data_count;\n                    if ((length + begin) < block_size) {\n                        s->data_count = length + begin;\n                        length = 0;\n                     } else {\n                        s->data_count = block_size;\n                        length -= block_size - begin;\n                    }\n                    dma_memory_write(s->dma_as, dscr.addr,\n                                     &s->fifo_buffer[begin],\n                                     s->data_count - begin);\n                    dscr.addr += s->data_count - begin;\n                    if (s->data_count == block_size) {\n                        s->data_count = 0;\n                        if (s->trnmod & SDHC_TRNS_BLK_CNT_EN) {\n                            s->blkcnt--;\n                            if (s->blkcnt == 0) {\n                                break;\n                            }\n                        }\n                    }\n                }\n            } else {\n                while (length) {\n                    begin = s->data_count;\n                    if ((length + begin) < block_size) {\n                        s->data_count = length + begin;\n                        length = 0;\n                     } else {\n                        s->data_count = block_size;\n                        length -= block_size - begin;\n                    }\n                    dma_memory_read(s->dma_as, dscr.addr,\n                                    &s->fifo_buffer[begin],\n                                    s->data_count - begin);\n                    dscr.addr += s->data_count - begin;\n                    if (s->data_count == block_size) {\n                        sdbus_write_data(&s->sdbus, s->fifo_buffer, block_size);\n                        s->data_count = 0;\n                        if (s->trnmod & SDHC_TRNS_BLK_CNT_EN) {\n                            s->blkcnt--;\n                            if (s->blkcnt == 0) {\n                                break;\n                            }\n                        }\n                    }\n                }\n            }\n            s->admasysaddr += dscr.incr;\n            break;\n        case SDHC_ADMA_ATTR_ACT_LINK:   /* link to next descriptor table */\n            s->admasysaddr = dscr.addr;\n            trace_sdhci_adma(\"link\", s->admasysaddr);\n            break;\n        default:\n            s->admasysaddr += dscr.incr;\n            break;\n        }\n\n        if (dscr.attr & SDHC_ADMA_ATTR_INT) {\n            trace_sdhci_adma(\"interrupt\", s->admasysaddr);\n            if (s->norintstsen & SDHC_NISEN_DMA) {\n                s->norintsts |= SDHC_NIS_DMA;\n            }\n\n            if (sdhci_update_irq(s) && !(dscr.attr & SDHC_ADMA_ATTR_END)) {\n                /* IRQ delivered, reschedule current transfer */\n                break;\n            }\n        }\n\n        /* ADMA transfer terminates if blkcnt == 0 or by END attribute */\n        if (((s->trnmod & SDHC_TRNS_BLK_CNT_EN) &&\n                    (s->blkcnt == 0)) || (dscr.attr & SDHC_ADMA_ATTR_END)) {\n            trace_sdhci_adma_transfer_completed();\n            if (length || ((dscr.attr & SDHC_ADMA_ATTR_END) &&\n                (s->trnmod & SDHC_TRNS_BLK_CNT_EN) &&\n                s->blkcnt != 0)) {\n                trace_sdhci_error(\"SD/MMC host ADMA length mismatch\");\n                s->admaerr |= SDHC_ADMAERR_LENGTH_MISMATCH |\n                        SDHC_ADMAERR_STATE_ST_TFR;\n                if (s->errintstsen & SDHC_EISEN_ADMAERR) {\n                    trace_sdhci_error(\"Set ADMA error flag\");\n                    s->errintsts |= SDHC_EIS_ADMAERR;\n                    s->norintsts |= SDHC_NIS_ERR;\n                }\n\n                sdhci_update_irq(s);\n            }\n            sdhci_end_transfer(s);\n            return;\n        }\n\n    }\n\n    /* we have unfinished business - reschedule to continue ADMA */\n    timer_mod(s->transfer_timer,\n                   qemu_clock_get_ns(QEMU_CLOCK_VIRTUAL) + SDHC_TRANSFER_DELAY);\n}",
        "func_hash": 54427224725201055548567995202847143006,
        "file_name": "sdhci.c",
        "file_hash": 286742685023344467914463961907520076456,
        "cwe": [
            "CWE-119"
        ],
        "cve": "CVE-2021-3409",
        "cve_desc": "The patch for CVE-2020-17380/CVE-2020-25085 was found to be ineffective, thus making QEMU vulnerable to the out-of-bounds read/write access issues previously found in the SDHCI controller emulation code. This flaw allows a malicious privileged guest to crash the QEMU process on the host, resulting in a denial of service or potential code execution. QEMU up to (including) 5.2.0 is affected by this.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-3409",
        "func_name": "sdhci_do_adma",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 200695,
        "project": "linux",
        "commit_id": "fc739a058d99c9297ef6bfd923b809d85855b9a9",
        "project_url": "https://github.com/torvalds/linux",
        "commit_url": "https://github.com/torvalds/linux/commit/fc739a058d99c9297ef6bfd923b809d85855b9a9",
        "commit_message": "misc: fastrpc: prevent memory leak in fastrpc_dma_buf_attach\n\nIn fastrpc_dma_buf_attach if dma_get_sgtable fails the allocated memory\nfor a should be released.\n\nSigned-off-by: Navid Emamdoost <navid.emamdoost@gmail.com>\nLink: https://lore.kernel.org/r/20190925152742.16258-1-navid.emamdoost@gmail.com\nSigned-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static int fastrpc_dma_buf_attach(struct dma_buf *dmabuf,\n\t\t\t\t  struct dma_buf_attachment *attachment)\n{\n\tstruct fastrpc_dma_buf_attachment *a;\n\tstruct fastrpc_buf *buffer = dmabuf->priv;\n\tint ret;\n\n\ta = kzalloc(sizeof(*a), GFP_KERNEL);\n\tif (!a)\n\t\treturn -ENOMEM;\n\n\tret = dma_get_sgtable(buffer->dev, &a->sgt, buffer->virt,\n\t\t\t      FASTRPC_PHYS(buffer->phys), buffer->size);\n\tif (ret < 0) {\n\t\tdev_err(buffer->dev, \"failed to get scatterlist from DMA API\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\ta->dev = attachment->dev;\n\tINIT_LIST_HEAD(&a->node);\n\tattachment->priv = a;\n\n\tmutex_lock(&buffer->lock);\n\tlist_add(&a->node, &buffer->attachments);\n\tmutex_unlock(&buffer->lock);\n\n\treturn 0;\n}",
        "func_hash": 226882745088672382788622327400287132857,
        "file_name": "fastrpc.c",
        "file_hash": 22170772729445349597675548574301219151,
        "cwe": [
            "CWE-401"
        ],
        "cve": "CVE-2019-19069",
        "cve_desc": "A memory leak in the fastrpc_dma_buf_attach() function in drivers/misc/fastrpc.c in the Linux kernel before 5.3.9 allows attackers to cause a denial of service (memory consumption) by triggering dma_get_sgtable() failures, aka CID-fc739a058d99.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2019-19069",
        "func_name": "fastrpc_dma_buf_attach",
        "diff": [
            "diff --git a/drivers/misc/fastrpc.c b/drivers/misc/fastrpc.c\nindex 47ae84afac2e1e..1b1a794d639d0d 100644\n--- a/drivers/misc/fastrpc.c\n+++ b/drivers/misc/fastrpc.c\n@@ -527,6 +527,7 @@ static int fastrpc_dma_buf_attach(struct dma_buf *dmabuf,\n \t\t\t      FASTRPC_PHYS(buffer->phys), buffer->size);\n \tif (ret < 0) {\n \t\tdev_err(buffer->dev, \"failed to get scatterlist from DMA API\\n\");\n+\t\tkfree(a);\n \t\treturn -EINVAL;\n \t}\n \n"
        ],
        "func_after": []
    },
    {
        "idx": 200781,
        "project": "ncurses",
        "commit_id": "790a85dbd4a81d5f5d8dd02a44d84f01512ef443",
        "project_url": "https://github.com/mirror/ncurses",
        "commit_url": "https://github.com/mirror/ncurses/commit/790a85dbd4a81d5f5d8dd02a44d84f01512ef443#diff-7e95c7bc5f213e9be438e69a9d5d0f261a14952bcbd692f7b9014217b8047340",
        "commit_message": "ncurses 6.2 - patch 20200531\n\n+ correct configure version-check/warnng for g++ to allow for 10.x\n+ re-enable \"bel\" in konsole-base (report by Nia Huang)\n+ add linux-s entry (patch by Alexandre Montaron).\n+ drop long-obsolete convert_configure.pl\n+ add test/test_parm.c, for checking tparm changes.\n+ improve parameter-checking for tparm, adding function _nc_tiparm() to\n  handle the most-used case, which accepts only numeric parameters\n  (report/testcase by \"puppet-meteor\").\n+ use a more conservative estimate of the buffer-size in lib_tparm.c's\n  save_text() and save_number(), in case the sprintf() function\n  passes-through unexpected characters from a format specifier\n  (report/testcase by \"puppet-meteor\").\n+ add a check for end-of-string in cvtchar to handle a malformed\n  string in infotocap (report/testcase by \"puppet-meteor\").",
        "target": 1,
        "irrelevant": 0,
        "func_before": "cvtchar(register const char *sp)\n/* convert a character to a terminfo push */\n{\n    unsigned char c = 0;\n    int len;\n\n    switch (*sp) {\n    case '\\\\':\n\tswitch (*++sp) {\n\tcase '\\'':\n\tcase '$':\n\tcase '\\\\':\n\tcase '%':\n\t    c = UChar(*sp);\n\t    len = 2;\n\t    break;\n\tcase '\\0':\n\t    c = '\\\\';\n\t    len = 1;\n\t    break;\n\tcase '0':\n\tcase '1':\n\tcase '2':\n\tcase '3':\n\t    len = 1;\n\t    while (isdigit(UChar(*sp))) {\n\t\tc = UChar(8 * c + (*sp++ - '0'));\n\t\tlen++;\n\t    }\n\t    break;\n\tdefault:\n\t    c = UChar(*sp);\n\t    len = (c != '\\0') ? 2 : 1;\n\t    break;\n\t}\n\tbreak;\n    case '^':\n\tc = UChar(*++sp);\n\tif (c == '?')\n\t    c = 127;\n\telse\n\t    c &= 0x1f;\n\tlen = 2;\n\tbreak;\n    default:\n\tc = UChar(*sp);\n\tlen = (c != '\\0') ? 1 : 0;\n    }\n    if (isgraph(c) && c != ',' && c != '\\'' && c != '\\\\' && c != ':') {\n\tdp = save_string(dp, \"%\\'\");\n\tdp = save_char(dp, c);\n\tdp = save_char(dp, '\\'');\n    } else if (c != '\\0') {\n\tdp = save_string(dp, \"%{\");\n\tif (c > 99)\n\t    dp = save_char(dp, c / 100 + '0');\n\tif (c > 9)\n\t    dp = save_char(dp, ((int) (c / 10)) % 10 + '0');\n\tdp = save_char(dp, c % 10 + '0');\n\tdp = save_char(dp, '}');\n    }\n    return len;\n}",
        "func_hash": 56621931750240830327732003181202918311,
        "file_name": "captoinfo.c",
        "file_hash": null,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2021-39537",
        "cve_desc": "An issue was discovered in ncurses through v6.2-1. _nc_captoinfo in captoinfo.c has a heap-based buffer overflow.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-39537",
        "func_name": "cvtchar",
        "diff": [
            "diff --git a/Ada95/aclocal.m4 b/Ada95/aclocal.m4\nindex e4ce3771a..24f69deb6 100644\n--- a/Ada95/aclocal.m4\n+++ b/Ada95/aclocal.m4\n@@ -29,7 +29,7 @@ dnl***************************************************************************\n dnl\n dnl Author: Thomas E. Dickey\n dnl\n-dnl $Id: aclocal.m4,v 1.156 2020/05/23 23:39:36 tom Exp $\n+dnl $Id: aclocal.m4,v 1.157 2020/05/31 20:52:36 tom Exp $\n dnl Macros used in NCURSES Ada95 auto-configuration script.\n dnl\n dnl These macros are maintained separately from NCURSES.  The copyright on\n@@ -1421,7 +1421,7 @@ test \"$cf_cv_gnatprep_opt_t\" = yes && GNATPREP_OPTS=\"-T $GNATPREP_OPTS\"\n AC_SUBST(GNATPREP_OPTS)\n ])dnl\n dnl ---------------------------------------------------------------------------\n-dnl CF_GNAT_GENERICS version: 4 updated: 2019/12/31 08:53:54\n+dnl CF_GNAT_GENERICS version: 5 updated: 2020/05/31 16:49:35\n dnl ----------------\n AC_DEFUN([CF_GNAT_GENERICS],\n [\n@@ -1429,7 +1429,7 @@ AC_REQUIRE([CF_GNAT_VERSION])\n \n AC_MSG_CHECKING(if GNAT supports generics)\n case $cf_cv_gnat_version in\n-(3.[[1-9]]*|[[4-9]].*)\n+(3.[[1-9]]*|[[4-9]].*|[[1-9]][[0-9]].*)\n \tcf_gnat_generics=yes\n \t;;\n (*)\ndiff --git a/Ada95/configure b/Ada95/configure\nindex 1b18acd89..61a921f16 100755\n--- a/Ada95/configure\n+++ b/Ada95/configure\n@@ -16670,7 +16670,7 @@ test \"$cf_cv_gnatprep_opt_t\" = yes && GNATPREP_OPTS=\"-T $GNATPREP_OPTS\"\n echo \"$as_me:16670: checking if GNAT supports generics\" >&5\n echo $ECHO_N \"checking if GNAT supports generics... $ECHO_C\" >&6\n case $cf_cv_gnat_version in\n-(3.[1-9]*|[4-9].*)\n+(3.[1-9]*|[4-9].*|[1-9][0-9].*)\n \tcf_gnat_generics=yes\n \t;;\n (*)\ndiff --git a/MANIFEST b/MANIFEST\nindex 61e648793..69edf1570 100644\n--- a/MANIFEST\n+++ b/MANIFEST\n@@ -235,7 +235,6 @@\n ./config.sub\n ./configure\n ./configure.in\n-./convert_configure.pl\n ./dist.mk\n ./doc/hackguide.doc\n ./doc/html/Ada95.html\n@@ -1214,6 +1213,7 @@\n ./test/test_setupterm.c\n ./test/test_sgr.c\n ./test/test_termattrs.c\n+./test/test_tparm.c\n ./test/test_vid_puts.c\n ./test/test_vidputs.c\n ./test/testaddch.c\ndiff --git a/NEWS b/NEWS\nindex 09e1555f4..07434fa20 100644\n--- a/NEWS\n+++ b/NEWS\n@@ -26,7 +26,7 @@\n -- sale, use or other dealings in this Software without prior written        --\n -- authorization.                                                            --\n -------------------------------------------------------------------------------\n--- $Id: NEWS,v 1.3491 2020/05/24 00:07:37 tom Exp $\n+-- $Id: NEWS,v 1.3502 2020/05/31 19:41:31 tom Exp $\n -------------------------------------------------------------------------------\n \n This is a log of changes that ncurses has gone through since Zeyd started\n@@ -46,6 +46,22 @@ See the AUTHORS file for the corresponding full names.\n Changes through 1.9.9e did not credit all contributions;\n it is not possible to add this information.\n \n+20200531\n+\t+ correct configure version-check/warnng for g++ to allow for 10.x\n+\t+ re-enable \"bel\" in konsole-base (report by Nia Huang)\n+\t+ add linux-s entry (patch by Alexandre Montaron).\n+\t+ drop long-obsolete convert_configure.pl \n+\t+ add test/test_parm.c, for checking tparm changes.\n+\t+ improve parameter-checking for tparm, adding function _nc_tiparm() to\n+\t  handle the most-used case, which accepts only numeric parameters\n+\t  (report/testcase by \"puppet-meteor\").\n+\t+ use a more conservative estimate of the buffer-size in lib_tparm.c's\n+\t  save_text() and save_number(), in case the sprintf() function\n+\t  passes-through unexpected characters from a format specifier\n+\t  (report/testcase by \"puppet-meteor\").\n+\t+ add a check for end-of-string in cvtchar to handle a malformed\n+\t  string in infotocap (report/testcase by \"puppet-meteor\").\n+\n 20200523\n \t+ update version-check for gnat to allow for gnat 10.x to 99.x\n \t+ fix an uninitialized variable in lib_mouse.c changes (cf: 20200502)\ndiff --git a/VERSION b/VERSION\nindex f78341a7a..18172f0ce 100644\n--- a/VERSION\n+++ b/VERSION\n@@ -1 +1 @@\n-5:0:10\t6.2\t20200523\n+5:0:10\t6.2\t20200531\ndiff --git a/aclocal.m4 b/aclocal.m4\nindex ba09e6e9e..09260c46c 100644\n--- a/aclocal.m4\n+++ b/aclocal.m4\n@@ -29,7 +29,7 @@ dnl***************************************************************************\n dnl\n dnl Author: Thomas E. Dickey 1995-on\n dnl\n-dnl $Id: aclocal.m4,v 1.913 2020/05/23 23:46:10 tom Exp $\n+dnl $Id: aclocal.m4,v 1.914 2020/05/31 20:50:13 tom Exp $\n dnl Macros used in NCURSES auto-configuration script.\n dnl\n dnl These macros are maintained separately from NCURSES.  The copyright on\n@@ -2811,7 +2811,7 @@ test \"$cf_cv_gnatprep_opt_t\" = yes && GNATPREP_OPTS=\"-T $GNATPREP_OPTS\"\n AC_SUBST(GNATPREP_OPTS)\n ])dnl\n dnl ---------------------------------------------------------------------------\n-dnl CF_GNAT_GENERICS version: 4 updated: 2019/12/31 08:53:54\n+dnl CF_GNAT_GENERICS version: 5 updated: 2020/05/31 16:49:35\n dnl ----------------\n AC_DEFUN([CF_GNAT_GENERICS],\n [\n@@ -2819,7 +2819,7 @@ AC_REQUIRE([CF_GNAT_VERSION])\n \n AC_MSG_CHECKING(if GNAT supports generics)\n case $cf_cv_gnat_version in\n-(3.[[1-9]]*|[[4-9]].*)\n+(3.[[1-9]]*|[[4-9]].*|[[1-9]][[0-9]].*)\n \tcf_gnat_generics=yes\n \t;;\n (*)\ndiff --git a/configure b/configure\nindex 2478a5a17..b3b29cef2 100755\n--- a/configure\n+++ b/configure\n@@ -1,5 +1,5 @@\n #! /bin/sh\n-# From configure.in Revision: 1.707 .\n+# From configure.in Revision: 1.709 .\n # Guess values for system-dependent variables and create Makefiles.\n # Generated by Autoconf 2.52.20200111.\n #\n@@ -3355,9 +3355,9 @@ echo \"${ECHO_T}$GXX_VERSION\" >&6\n fi\n \n case $GXX_VERSION in\n-(1*|2.[0-6]*)\n-\t# GXX=\"\"; CXX=\"\"; ac_cv_prog_gxx=no\n-\t# cf_cxx_library=no\n+([1-9][0-9].*)\n+\t;;\n+(1.*|2.[0-6]*)\n \t{ echo \"$as_me:3361: WARNING: templates do not work\" >&5\n echo \"$as_me: WARNING: templates do not work\" >&2;}\n \t;;\n@@ -20100,6 +20100,7 @@ setenv \\\n setvbuf \\\n sigaction \\\n sigvec \\\n+snprintf \\\n strdup \\\n strstr \\\n sysconf \\\n@@ -20110,13 +20111,13 @@ vsnprintf \\\n \n do\n as_ac_var=`echo \"ac_cv_func_$ac_func\" | $as_tr_sh`\n-echo \"$as_me:20113: checking for $ac_func\" >&5\n+echo \"$as_me:20114: checking for $ac_func\" >&5\n echo $ECHO_N \"checking for $ac_func... $ECHO_C\" >&6\n if eval \"test \\\"\\${$as_ac_var+set}\\\" = set\"; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 20119 \"configure\"\n+#line 20120 \"configure\"\n #include \"confdefs.h\"\n #define $ac_func autoconf_temporary\n #include <limits.h>\t/* least-intrusive standard header which defines gcc2 __stub macros */\n@@ -20147,16 +20148,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:20150: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:20151: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20153: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20154: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:20156: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:20157: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20159: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20160: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   eval \"$as_ac_var=yes\"\n else\n@@ -20166,7 +20167,7 @@ eval \"$as_ac_var=no\"\n fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n fi\n-echo \"$as_me:20169: result: `eval echo '${'$as_ac_var'}'`\" >&5\n+echo \"$as_me:20170: result: `eval echo '${'$as_ac_var'}'`\" >&5\n echo \"${ECHO_T}`eval echo '${'$as_ac_var'}'`\" >&6\n if test `eval echo '${'$as_ac_var'}'` = yes; then\n   cat >>confdefs.h <<EOF\n@@ -20178,7 +20179,7 @@ done\n \n if test \"x$ac_cv_func_getopt\" = xno && \\\n    test \"x$cf_with_progs$cf_with_tests\" != xnono; then\n-\t{ { echo \"$as_me:20181: error: getopt is required for building programs\" >&5\n+\t{ { echo \"$as_me:20182: error: getopt is required for building programs\" >&5\n echo \"$as_me: error: getopt is required for building programs\" >&2;}\n    { (exit 1); exit 1; }; }\n fi\n@@ -20187,7 +20188,7 @@ if test \"x$with_safe_sprintf\" = xyes\n then\n \tif test \"x$ac_cv_func_vsnprintf\" = xyes\n \tthen\n-\t\t{ echo \"$as_me:20190: WARNING: will use vsnprintf instead of safe-sprintf option\" >&5\n+\t\t{ echo \"$as_me:20191: WARNING: will use vsnprintf instead of safe-sprintf option\" >&5\n echo \"$as_me: WARNING: will use vsnprintf instead of safe-sprintf option\" >&2;}\n \telse\n \n@@ -20200,14 +20201,14 @@ fi\n \n if test \"x$with_getcap\" = \"xyes\" ; then\n \n-echo \"$as_me:20203: checking for terminal-capability database functions\" >&5\n+echo \"$as_me:20204: checking for terminal-capability database functions\" >&5\n echo $ECHO_N \"checking for terminal-capability database functions... $ECHO_C\" >&6\n if test \"${cf_cv_cgetent+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n \n cat >conftest.$ac_ext <<_ACEOF\n-#line 20210 \"configure\"\n+#line 20211 \"configure\"\n #include \"confdefs.h\"\n \n #include <stdlib.h>\n@@ -20227,16 +20228,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:20230: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:20231: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20233: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20234: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:20236: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:20237: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20239: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20240: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_cgetent=yes\n else\n@@ -20247,7 +20248,7 @@ fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n \n fi\n-echo \"$as_me:20250: result: $cf_cv_cgetent\" >&5\n+echo \"$as_me:20251: result: $cf_cv_cgetent\" >&5\n echo \"${ECHO_T}$cf_cv_cgetent\" >&6\n \n if test \"$cf_cv_cgetent\" = yes\n@@ -20257,14 +20258,14 @@ cat >>confdefs.h <<\\EOF\n #define HAVE_BSD_CGETENT 1\n EOF\n \n-echo \"$as_me:20260: checking if cgetent uses const parameter\" >&5\n+echo \"$as_me:20261: checking if cgetent uses const parameter\" >&5\n echo $ECHO_N \"checking if cgetent uses const parameter... $ECHO_C\" >&6\n if test \"${cf_cv_cgetent_const+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n \n cat >conftest.$ac_ext <<_ACEOF\n-#line 20267 \"configure\"\n+#line 20268 \"configure\"\n #include \"confdefs.h\"\n \n #pragma GCC diagnostic error \"-Wincompatible-pointer-types-discards-qualifiers\"\n@@ -20287,16 +20288,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:20290: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:20291: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20293: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20294: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:20296: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:20297: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20299: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20300: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_cgetent_const=yes\n else\n@@ -20307,7 +20308,7 @@ fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n \n fi\n-echo \"$as_me:20310: result: $cf_cv_cgetent_const\" >&5\n+echo \"$as_me:20311: result: $cf_cv_cgetent_const\" >&5\n echo \"${ECHO_T}$cf_cv_cgetent_const\" >&6\n \tif test \"$cf_cv_cgetent_const\" = yes\n \tthen\n@@ -20321,14 +20322,14 @@ fi\n \n fi\n \n-echo \"$as_me:20324: checking for isascii\" >&5\n+echo \"$as_me:20325: checking for isascii\" >&5\n echo $ECHO_N \"checking for isascii... $ECHO_C\" >&6\n if test \"${cf_cv_have_isascii+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n \n \tcat >conftest.$ac_ext <<_ACEOF\n-#line 20331 \"configure\"\n+#line 20332 \"configure\"\n #include \"confdefs.h\"\n #include <ctype.h>\n int\n@@ -20340,16 +20341,16 @@ int x = isascii(' ')\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:20343: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:20344: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20346: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20347: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:20349: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:20350: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20352: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20353: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_have_isascii=yes\n else\n@@ -20360,7 +20361,7 @@ fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n \n fi\n-echo \"$as_me:20363: result: $cf_cv_have_isascii\" >&5\n+echo \"$as_me:20364: result: $cf_cv_have_isascii\" >&5\n echo \"${ECHO_T}$cf_cv_have_isascii\" >&6\n test \"$cf_cv_have_isascii\" = yes &&\n cat >>confdefs.h <<\\EOF\n@@ -20368,10 +20369,10 @@ cat >>confdefs.h <<\\EOF\n EOF\n \n if test \"$ac_cv_func_sigaction\" = yes; then\n-echo \"$as_me:20371: checking whether sigaction needs _POSIX_SOURCE\" >&5\n+echo \"$as_me:20372: checking whether sigaction needs _POSIX_SOURCE\" >&5\n echo $ECHO_N \"checking whether sigaction needs _POSIX_SOURCE... $ECHO_C\" >&6\n cat >conftest.$ac_ext <<_ACEOF\n-#line 20374 \"configure\"\n+#line 20375 \"configure\"\n #include \"confdefs.h\"\n \n #include <sys/types.h>\n@@ -20385,16 +20386,16 @@ struct sigaction act\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:20388: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:20389: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20391: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20392: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:20394: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:20395: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20397: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20398: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   sigact_bad=no\n else\n@@ -20402,7 +20403,7 @@ else\n cat conftest.$ac_ext >&5\n \n cat >conftest.$ac_ext <<_ACEOF\n-#line 20405 \"configure\"\n+#line 20406 \"configure\"\n #include \"confdefs.h\"\n \n #define _POSIX_SOURCE\n@@ -20417,16 +20418,16 @@ struct sigaction act\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:20420: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:20421: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20423: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20424: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:20426: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:20427: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20429: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20430: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   sigact_bad=yes\n \n@@ -20442,11 +20443,11 @@ fi\n rm -f conftest.$ac_objext conftest.$ac_ext\n fi\n rm -f conftest.$ac_objext conftest.$ac_ext\n-echo \"$as_me:20445: result: $sigact_bad\" >&5\n+echo \"$as_me:20446: result: $sigact_bad\" >&5\n echo \"${ECHO_T}$sigact_bad\" >&6\n fi\n \n-echo \"$as_me:20449: checking if nanosleep really works\" >&5\n+echo \"$as_me:20450: checking if nanosleep really works\" >&5\n echo $ECHO_N \"checking if nanosleep really works... $ECHO_C\" >&6\n if test \"${cf_cv_func_nanosleep+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -20456,7 +20457,7 @@ if test \"$cross_compiling\" = yes; then\n   cf_cv_func_nanosleep=unknown\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 20459 \"configure\"\n+#line 20460 \"configure\"\n #include \"confdefs.h\"\n \n #include <stdio.h>\n@@ -20481,15 +20482,15 @@ int main(void) {\n \n _ACEOF\n rm -f conftest$ac_exeext\n-if { (eval echo \"$as_me:20484: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:20485: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20487: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20488: \\$? = $ac_status\" >&5\n   (exit $ac_status); } && { ac_try='./conftest$ac_exeext'\n-  { (eval echo \"$as_me:20489: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:20490: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20492: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20493: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_func_nanosleep=yes\n else\n@@ -20501,7 +20502,7 @@ fi\n rm -f core core.* *.core conftest$ac_exeext conftest.$ac_objext conftest.$ac_ext\n fi\n fi\n-echo \"$as_me:20504: result: $cf_cv_func_nanosleep\" >&5\n+echo \"$as_me:20505: result: $cf_cv_func_nanosleep\" >&5\n echo \"${ECHO_T}$cf_cv_func_nanosleep\" >&6\n \n test \"$cf_cv_func_nanosleep\" = \"yes\" &&\n@@ -20518,23 +20519,23 @@ sys/termio.h \\\n \n do\n as_ac_Header=`echo \"ac_cv_header_$ac_header\" | $as_tr_sh`\n-echo \"$as_me:20521: checking for $ac_header\" >&5\n+echo \"$as_me:20522: checking for $ac_header\" >&5\n echo $ECHO_N \"checking for $ac_header... $ECHO_C\" >&6\n if eval \"test \\\"\\${$as_ac_Header+set}\\\" = set\"; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 20527 \"configure\"\n+#line 20528 \"configure\"\n #include \"confdefs.h\"\n #include <$ac_header>\n _ACEOF\n-if { (eval echo \"$as_me:20531: \\\"$ac_cpp conftest.$ac_ext\\\"\") >&5\n+if { (eval echo \"$as_me:20532: \\\"$ac_cpp conftest.$ac_ext\\\"\") >&5\n   (eval $ac_cpp conftest.$ac_ext) 2>conftest.er1\n   ac_status=$?\n   egrep -v '^ *\\+' conftest.er1 >conftest.err\n   rm -f conftest.er1\n   cat conftest.err >&5\n-  echo \"$as_me:20537: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20538: \\$? = $ac_status\" >&5\n   (exit $ac_status); } >/dev/null; then\n   if test -s conftest.err; then\n     ac_cpp_err=$ac_c_preproc_warn_flag\n@@ -20553,7 +20554,7 @@ else\n fi\n rm -f conftest.err conftest.$ac_ext\n fi\n-echo \"$as_me:20556: result: `eval echo '${'$as_ac_Header'}'`\" >&5\n+echo \"$as_me:20557: result: `eval echo '${'$as_ac_Header'}'`\" >&5\n echo \"${ECHO_T}`eval echo '${'$as_ac_Header'}'`\" >&6\n if test `eval echo '${'$as_ac_Header'}'` = yes; then\n   cat >>confdefs.h <<EOF\n@@ -20570,10 +20571,10 @@ if test \"$ac_cv_header_termios_h\" = yes ; then\n \t(*)\ttermios_bad=maybe ;;\n \tesac\n \tif test \"$termios_bad\" = maybe ; then\n-\techo \"$as_me:20573: checking whether termios.h needs _POSIX_SOURCE\" >&5\n+\techo \"$as_me:20574: checking whether termios.h needs _POSIX_SOURCE\" >&5\n echo $ECHO_N \"checking whether termios.h needs _POSIX_SOURCE... $ECHO_C\" >&6\n \tcat >conftest.$ac_ext <<_ACEOF\n-#line 20576 \"configure\"\n+#line 20577 \"configure\"\n #include \"confdefs.h\"\n #include <termios.h>\n int\n@@ -20585,16 +20586,16 @@ struct termios foo; int x = foo.c_iflag = 1; (void)x\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:20588: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:20589: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20591: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20592: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:20594: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:20595: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20597: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20598: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   termios_bad=no\n else\n@@ -20602,7 +20603,7 @@ else\n cat conftest.$ac_ext >&5\n \n \t\tcat >conftest.$ac_ext <<_ACEOF\n-#line 20605 \"configure\"\n+#line 20606 \"configure\"\n #include \"confdefs.h\"\n \n #define _POSIX_SOURCE\n@@ -20616,16 +20617,16 @@ struct termios foo; int x = foo.c_iflag = 2; (void)x\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:20619: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:20620: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20622: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20623: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:20625: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:20626: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20628: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20629: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   termios_bad=unknown\n else\n@@ -20641,19 +20642,19 @@ rm -f conftest.$ac_objext conftest.$ac_ext\n \n fi\n rm -f conftest.$ac_objext conftest.$ac_ext\n-\techo \"$as_me:20644: result: $termios_bad\" >&5\n+\techo \"$as_me:20645: result: $termios_bad\" >&5\n echo \"${ECHO_T}$termios_bad\" >&6\n \tfi\n fi\n \n-echo \"$as_me:20649: checking for tcgetattr\" >&5\n+echo \"$as_me:20650: checking for tcgetattr\" >&5\n echo $ECHO_N \"checking for tcgetattr... $ECHO_C\" >&6\n if test \"${cf_cv_have_tcgetattr+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n \n cat >conftest.$ac_ext <<_ACEOF\n-#line 20656 \"configure\"\n+#line 20657 \"configure\"\n #include \"confdefs.h\"\n \n #include <sys/types.h>\n@@ -20681,16 +20682,16 @@ tcgetattr(1, &foo);\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:20684: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:20685: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20687: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20688: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:20690: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:20691: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20693: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20694: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_have_tcgetattr=yes\n else\n@@ -20700,21 +20701,21 @@ cf_cv_have_tcgetattr=no\n fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n fi\n-echo \"$as_me:20703: result: $cf_cv_have_tcgetattr\" >&5\n+echo \"$as_me:20704: result: $cf_cv_have_tcgetattr\" >&5\n echo \"${ECHO_T}$cf_cv_have_tcgetattr\" >&6\n test \"$cf_cv_have_tcgetattr\" = yes &&\n cat >>confdefs.h <<\\EOF\n #define HAVE_TCGETATTR 1\n EOF\n \n-echo \"$as_me:20710: checking for vsscanf function or workaround\" >&5\n+echo \"$as_me:20711: checking for vsscanf function or workaround\" >&5\n echo $ECHO_N \"checking for vsscanf function or workaround... $ECHO_C\" >&6\n if test \"${cf_cv_func_vsscanf+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n \n cat >conftest.$ac_ext <<_ACEOF\n-#line 20717 \"configure\"\n+#line 20718 \"configure\"\n #include \"confdefs.h\"\n \n #include <stdarg.h>\n@@ -20730,16 +20731,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:20733: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:20734: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20736: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20737: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:20739: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:20740: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20742: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20743: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_func_vsscanf=vsscanf\n else\n@@ -20747,7 +20748,7 @@ else\n cat conftest.$ac_ext >&5\n \n cat >conftest.$ac_ext <<_ACEOF\n-#line 20750 \"configure\"\n+#line 20751 \"configure\"\n #include \"confdefs.h\"\n \n #include <stdarg.h>\n@@ -20769,16 +20770,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:20772: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:20773: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20775: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20776: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:20778: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:20779: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20781: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20782: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_func_vsscanf=vfscanf\n else\n@@ -20786,7 +20787,7 @@ else\n cat conftest.$ac_ext >&5\n \n cat >conftest.$ac_ext <<_ACEOF\n-#line 20789 \"configure\"\n+#line 20790 \"configure\"\n #include \"confdefs.h\"\n \n #include <stdarg.h>\n@@ -20808,16 +20809,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:20811: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:20812: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20814: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20815: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:20817: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:20818: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20820: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20821: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_func_vsscanf=_doscan\n else\n@@ -20832,7 +20833,7 @@ rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n fi\n-echo \"$as_me:20835: result: $cf_cv_func_vsscanf\" >&5\n+echo \"$as_me:20836: result: $cf_cv_func_vsscanf\" >&5\n echo \"${ECHO_T}$cf_cv_func_vsscanf\" >&6\n \n case $cf_cv_func_vsscanf in\n@@ -20858,23 +20859,23 @@ unistd.h \\\n \n do\n as_ac_Header=`echo \"ac_cv_header_$ac_header\" | $as_tr_sh`\n-echo \"$as_me:20861: checking for $ac_header\" >&5\n+echo \"$as_me:20862: checking for $ac_header\" >&5\n echo $ECHO_N \"checking for $ac_header... $ECHO_C\" >&6\n if eval \"test \\\"\\${$as_ac_Header+set}\\\" = set\"; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 20867 \"configure\"\n+#line 20868 \"configure\"\n #include \"confdefs.h\"\n #include <$ac_header>\n _ACEOF\n-if { (eval echo \"$as_me:20871: \\\"$ac_cpp conftest.$ac_ext\\\"\") >&5\n+if { (eval echo \"$as_me:20872: \\\"$ac_cpp conftest.$ac_ext\\\"\") >&5\n   (eval $ac_cpp conftest.$ac_ext) 2>conftest.er1\n   ac_status=$?\n   egrep -v '^ *\\+' conftest.er1 >conftest.err\n   rm -f conftest.er1\n   cat conftest.err >&5\n-  echo \"$as_me:20877: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20878: \\$? = $ac_status\" >&5\n   (exit $ac_status); } >/dev/null; then\n   if test -s conftest.err; then\n     ac_cpp_err=$ac_c_preproc_warn_flag\n@@ -20893,7 +20894,7 @@ else\n fi\n rm -f conftest.err conftest.$ac_ext\n fi\n-echo \"$as_me:20896: result: `eval echo '${'$as_ac_Header'}'`\" >&5\n+echo \"$as_me:20897: result: `eval echo '${'$as_ac_Header'}'`\" >&5\n echo \"${ECHO_T}`eval echo '${'$as_ac_Header'}'`\" >&6\n if test `eval echo '${'$as_ac_Header'}'` = yes; then\n   cat >>confdefs.h <<EOF\n@@ -20903,7 +20904,7 @@ EOF\n fi\n done\n \n-echo \"$as_me:20906: checking for working mkstemp\" >&5\n+echo \"$as_me:20907: checking for working mkstemp\" >&5\n echo $ECHO_N \"checking for working mkstemp... $ECHO_C\" >&6\n if test \"${cf_cv_func_mkstemp+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -20914,7 +20915,7 @@ if test \"$cross_compiling\" = yes; then\n   cf_cv_func_mkstemp=maybe\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 20917 \"configure\"\n+#line 20918 \"configure\"\n #include \"confdefs.h\"\n \n #include <sys/types.h>\n@@ -20955,15 +20956,15 @@ int main(void)\n \n _ACEOF\n rm -f conftest$ac_exeext\n-if { (eval echo \"$as_me:20958: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:20959: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20961: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20962: \\$? = $ac_status\" >&5\n   (exit $ac_status); } && { ac_try='./conftest$ac_exeext'\n-  { (eval echo \"$as_me:20963: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:20964: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20966: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20967: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_func_mkstemp=yes\n \n@@ -20978,16 +20979,16 @@ rm -f core core.* *.core conftest$ac_exeext conftest.$ac_objext conftest.$ac_ext\n fi\n \n fi\n-echo \"$as_me:20981: result: $cf_cv_func_mkstemp\" >&5\n+echo \"$as_me:20982: result: $cf_cv_func_mkstemp\" >&5\n echo \"${ECHO_T}$cf_cv_func_mkstemp\" >&6\n if test \"x$cf_cv_func_mkstemp\" = xmaybe ; then\n-\techo \"$as_me:20984: checking for mkstemp\" >&5\n+\techo \"$as_me:20985: checking for mkstemp\" >&5\n echo $ECHO_N \"checking for mkstemp... $ECHO_C\" >&6\n if test \"${ac_cv_func_mkstemp+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 20990 \"configure\"\n+#line 20991 \"configure\"\n #include \"confdefs.h\"\n #define mkstemp autoconf_temporary\n #include <limits.h>\t/* least-intrusive standard header which defines gcc2 __stub macros */\n@@ -21018,16 +21019,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:21021: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:21022: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21024: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21025: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:21027: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:21028: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21030: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21031: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   ac_cv_func_mkstemp=yes\n else\n@@ -21037,7 +21038,7 @@ ac_cv_func_mkstemp=no\n fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n fi\n-echo \"$as_me:21040: result: $ac_cv_func_mkstemp\" >&5\n+echo \"$as_me:21041: result: $ac_cv_func_mkstemp\" >&5\n echo \"${ECHO_T}$ac_cv_func_mkstemp\" >&6\n \n fi\n@@ -21058,21 +21059,21 @@ else\n fi\n \n if test \"x$cross_compiling\" = xyes ; then\n-\t{ echo \"$as_me:21061: WARNING: cross compiling: assume setvbuf params not reversed\" >&5\n+\t{ echo \"$as_me:21062: WARNING: cross compiling: assume setvbuf params not reversed\" >&5\n echo \"$as_me: WARNING: cross compiling: assume setvbuf params not reversed\" >&2;}\n else\n-\techo \"$as_me:21064: checking whether setvbuf arguments are reversed\" >&5\n+\techo \"$as_me:21065: checking whether setvbuf arguments are reversed\" >&5\n echo $ECHO_N \"checking whether setvbuf arguments are reversed... $ECHO_C\" >&6\n if test \"${ac_cv_func_setvbuf_reversed+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n   if test \"$cross_compiling\" = yes; then\n-  { { echo \"$as_me:21070: error: cannot run test program while cross compiling\" >&5\n+  { { echo \"$as_me:21071: error: cannot run test program while cross compiling\" >&5\n echo \"$as_me: error: cannot run test program while cross compiling\" >&2;}\n    { (exit 1); exit 1; }; }\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 21075 \"configure\"\n+#line 21076 \"configure\"\n #include \"confdefs.h\"\n #include <stdio.h>\n /* If setvbuf has the reversed format, exit 0. */\n@@ -21089,15 +21090,15 @@ main (void)\n }\n _ACEOF\n rm -f conftest$ac_exeext\n-if { (eval echo \"$as_me:21092: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:21093: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21095: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21096: \\$? = $ac_status\" >&5\n   (exit $ac_status); } && { ac_try='./conftest$ac_exeext'\n-  { (eval echo \"$as_me:21097: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:21098: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21100: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21101: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   ac_cv_func_setvbuf_reversed=yes\n else\n@@ -21110,7 +21111,7 @@ rm -f core core.* *.core conftest$ac_exeext conftest.$ac_objext conftest.$ac_ext\n fi\n rm -f core core.* *.core\n fi\n-echo \"$as_me:21113: result: $ac_cv_func_setvbuf_reversed\" >&5\n+echo \"$as_me:21114: result: $ac_cv_func_setvbuf_reversed\" >&5\n echo \"${ECHO_T}$ac_cv_func_setvbuf_reversed\" >&6\n if test $ac_cv_func_setvbuf_reversed = yes; then\n \n@@ -21121,13 +21122,13 @@ EOF\n fi\n \n fi\n-echo \"$as_me:21124: checking for intptr_t\" >&5\n+echo \"$as_me:21125: checking for intptr_t\" >&5\n echo $ECHO_N \"checking for intptr_t... $ECHO_C\" >&6\n if test \"${ac_cv_type_intptr_t+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 21130 \"configure\"\n+#line 21131 \"configure\"\n #include \"confdefs.h\"\n $ac_includes_default\n int\n@@ -21142,16 +21143,16 @@ if (sizeof (intptr_t))\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:21145: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:21146: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21148: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21149: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:21151: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:21152: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21154: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21155: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   ac_cv_type_intptr_t=yes\n else\n@@ -21161,7 +21162,7 @@ ac_cv_type_intptr_t=no\n fi\n rm -f conftest.$ac_objext conftest.$ac_ext\n fi\n-echo \"$as_me:21164: result: $ac_cv_type_intptr_t\" >&5\n+echo \"$as_me:21165: result: $ac_cv_type_intptr_t\" >&5\n echo \"${ECHO_T}$ac_cv_type_intptr_t\" >&6\n if test $ac_cv_type_intptr_t = yes; then\n   :\n@@ -21173,13 +21174,13 @@ EOF\n \n fi\n \n-echo \"$as_me:21176: checking for ssize_t\" >&5\n+echo \"$as_me:21177: checking for ssize_t\" >&5\n echo $ECHO_N \"checking for ssize_t... $ECHO_C\" >&6\n if test \"${ac_cv_type_ssize_t+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 21182 \"configure\"\n+#line 21183 \"configure\"\n #include \"confdefs.h\"\n $ac_includes_default\n int\n@@ -21194,16 +21195,16 @@ if (sizeof (ssize_t))\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:21197: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:21198: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21200: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21201: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:21203: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:21204: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21206: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21207: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   ac_cv_type_ssize_t=yes\n else\n@@ -21213,7 +21214,7 @@ ac_cv_type_ssize_t=no\n fi\n rm -f conftest.$ac_objext conftest.$ac_ext\n fi\n-echo \"$as_me:21216: result: $ac_cv_type_ssize_t\" >&5\n+echo \"$as_me:21217: result: $ac_cv_type_ssize_t\" >&5\n echo \"${ECHO_T}$ac_cv_type_ssize_t\" >&6\n if test $ac_cv_type_ssize_t = yes; then\n   :\n@@ -21225,14 +21226,14 @@ EOF\n \n fi\n \n-echo \"$as_me:21228: checking for type sigaction_t\" >&5\n+echo \"$as_me:21229: checking for type sigaction_t\" >&5\n echo $ECHO_N \"checking for type sigaction_t... $ECHO_C\" >&6\n if test \"${cf_cv_type_sigaction+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n \n \tcat >conftest.$ac_ext <<_ACEOF\n-#line 21235 \"configure\"\n+#line 21236 \"configure\"\n #include \"confdefs.h\"\n \n #include <signal.h>\n@@ -21245,16 +21246,16 @@ sigaction_t x\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:21248: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:21249: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21251: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21252: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:21254: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:21255: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21257: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21258: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_type_sigaction=yes\n else\n@@ -21265,14 +21266,14 @@ fi\n rm -f conftest.$ac_objext conftest.$ac_ext\n fi\n \n-echo \"$as_me:21268: result: $cf_cv_type_sigaction\" >&5\n+echo \"$as_me:21269: result: $cf_cv_type_sigaction\" >&5\n echo \"${ECHO_T}$cf_cv_type_sigaction\" >&6\n test \"$cf_cv_type_sigaction\" = yes &&\n cat >>confdefs.h <<\\EOF\n #define HAVE_TYPE_SIGACTION 1\n EOF\n \n-echo \"$as_me:21275: checking declaration of size-change\" >&5\n+echo \"$as_me:21276: checking declaration of size-change\" >&5\n echo $ECHO_N \"checking declaration of size-change... $ECHO_C\" >&6\n if test \"${cf_cv_sizechange+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -21293,7 +21294,7 @@ do\n \n \tfi\n \tcat >conftest.$ac_ext <<_ACEOF\n-#line 21296 \"configure\"\n+#line 21297 \"configure\"\n #include \"confdefs.h\"\n #include <sys/types.h>\n #ifdef HAVE_TERMIOS_H\n@@ -21343,16 +21344,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:21346: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:21347: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21349: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21350: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:21352: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:21353: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21355: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21356: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_sizechange=yes\n else\n@@ -21371,7 +21372,7 @@ rm -f conftest.$ac_objext conftest.$ac_ext\n done\n \n fi\n-echo \"$as_me:21374: result: $cf_cv_sizechange\" >&5\n+echo \"$as_me:21375: result: $cf_cv_sizechange\" >&5\n echo \"${ECHO_T}$cf_cv_sizechange\" >&6\n if test \"$cf_cv_sizechange\" != no ; then\n \n@@ -21389,13 +21390,13 @@ EOF\n \tesac\n fi\n \n-echo \"$as_me:21392: checking for memmove\" >&5\n+echo \"$as_me:21393: checking for memmove\" >&5\n echo $ECHO_N \"checking for memmove... $ECHO_C\" >&6\n if test \"${ac_cv_func_memmove+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 21398 \"configure\"\n+#line 21399 \"configure\"\n #include \"confdefs.h\"\n #define memmove autoconf_temporary\n #include <limits.h>\t/* least-intrusive standard header which defines gcc2 __stub macros */\n@@ -21426,16 +21427,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:21429: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:21430: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21432: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21433: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:21435: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:21436: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21438: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21439: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   ac_cv_func_memmove=yes\n else\n@@ -21445,19 +21446,19 @@ ac_cv_func_memmove=no\n fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n fi\n-echo \"$as_me:21448: result: $ac_cv_func_memmove\" >&5\n+echo \"$as_me:21449: result: $ac_cv_func_memmove\" >&5\n echo \"${ECHO_T}$ac_cv_func_memmove\" >&6\n if test $ac_cv_func_memmove = yes; then\n   :\n else\n \n-echo \"$as_me:21454: checking for bcopy\" >&5\n+echo \"$as_me:21455: checking for bcopy\" >&5\n echo $ECHO_N \"checking for bcopy... $ECHO_C\" >&6\n if test \"${ac_cv_func_bcopy+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 21460 \"configure\"\n+#line 21461 \"configure\"\n #include \"confdefs.h\"\n #define bcopy autoconf_temporary\n #include <limits.h>\t/* least-intrusive standard header which defines gcc2 __stub macros */\n@@ -21488,16 +21489,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:21491: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:21492: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21494: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21495: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:21497: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:21498: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21500: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21501: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   ac_cv_func_bcopy=yes\n else\n@@ -21507,11 +21508,11 @@ ac_cv_func_bcopy=no\n fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n fi\n-echo \"$as_me:21510: result: $ac_cv_func_bcopy\" >&5\n+echo \"$as_me:21511: result: $ac_cv_func_bcopy\" >&5\n echo \"${ECHO_T}$ac_cv_func_bcopy\" >&6\n if test $ac_cv_func_bcopy = yes; then\n \n-\techo \"$as_me:21514: checking if bcopy does overlapping moves\" >&5\n+\techo \"$as_me:21515: checking if bcopy does overlapping moves\" >&5\n echo $ECHO_N \"checking if bcopy does overlapping moves... $ECHO_C\" >&6\n if test \"${cf_cv_good_bcopy+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -21521,7 +21522,7 @@ else\n   cf_cv_good_bcopy=unknown\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 21524 \"configure\"\n+#line 21525 \"configure\"\n #include \"confdefs.h\"\n \n int main(void) {\n@@ -21535,15 +21536,15 @@ int main(void) {\n \n _ACEOF\n rm -f conftest$ac_exeext\n-if { (eval echo \"$as_me:21538: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:21539: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21541: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21542: \\$? = $ac_status\" >&5\n   (exit $ac_status); } && { ac_try='./conftest$ac_exeext'\n-  { (eval echo \"$as_me:21543: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:21544: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21546: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21547: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_good_bcopy=yes\n else\n@@ -21556,7 +21557,7 @@ rm -f core core.* *.core conftest$ac_exeext conftest.$ac_objext conftest.$ac_ext\n fi\n \n fi\n-echo \"$as_me:21559: result: $cf_cv_good_bcopy\" >&5\n+echo \"$as_me:21560: result: $cf_cv_good_bcopy\" >&5\n echo \"${ECHO_T}$cf_cv_good_bcopy\" >&6\n \n else\n@@ -21583,13 +21584,13 @@ tty 2>&1 >/dev/null || {\n for ac_func in posix_openpt\n do\n as_ac_var=`echo \"ac_cv_func_$ac_func\" | $as_tr_sh`\n-echo \"$as_me:21586: checking for $ac_func\" >&5\n+echo \"$as_me:21587: checking for $ac_func\" >&5\n echo $ECHO_N \"checking for $ac_func... $ECHO_C\" >&6\n if eval \"test \\\"\\${$as_ac_var+set}\\\" = set\"; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 21592 \"configure\"\n+#line 21593 \"configure\"\n #include \"confdefs.h\"\n #define $ac_func autoconf_temporary\n #include <limits.h>\t/* least-intrusive standard header which defines gcc2 __stub macros */\n@@ -21620,16 +21621,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:21623: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:21624: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21626: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21627: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:21629: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:21630: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21632: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21633: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   eval \"$as_ac_var=yes\"\n else\n@@ -21639,7 +21640,7 @@ eval \"$as_ac_var=no\"\n fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n fi\n-echo \"$as_me:21642: result: `eval echo '${'$as_ac_var'}'`\" >&5\n+echo \"$as_me:21643: result: `eval echo '${'$as_ac_var'}'`\" >&5\n echo \"${ECHO_T}`eval echo '${'$as_ac_var'}'`\" >&6\n if test `eval echo '${'$as_ac_var'}'` = yes; then\n   cat >>confdefs.h <<EOF\n@@ -21649,7 +21650,7 @@ EOF\n fi\n done\n  }\n-echo \"$as_me:21652: checking if poll really works\" >&5\n+echo \"$as_me:21653: checking if poll really works\" >&5\n echo $ECHO_N \"checking if poll really works... $ECHO_C\" >&6\n if test \"${cf_cv_working_poll+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -21659,7 +21660,7 @@ if test \"$cross_compiling\" = yes; then\n   cf_cv_working_poll=unknown\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 21662 \"configure\"\n+#line 21663 \"configure\"\n #include \"confdefs.h\"\n \n #include <stdlib.h>\n@@ -21711,15 +21712,15 @@ int main(void) {\n }\n _ACEOF\n rm -f conftest$ac_exeext\n-if { (eval echo \"$as_me:21714: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:21715: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21717: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21718: \\$? = $ac_status\" >&5\n   (exit $ac_status); } && { ac_try='./conftest$ac_exeext'\n-  { (eval echo \"$as_me:21719: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:21720: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21722: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21723: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_working_poll=yes\n else\n@@ -21731,21 +21732,21 @@ fi\n rm -f core core.* *.core conftest$ac_exeext conftest.$ac_objext conftest.$ac_ext\n fi\n fi\n-echo \"$as_me:21734: result: $cf_cv_working_poll\" >&5\n+echo \"$as_me:21735: result: $cf_cv_working_poll\" >&5\n echo \"${ECHO_T}$cf_cv_working_poll\" >&6\n test \"$cf_cv_working_poll\" = \"yes\" &&\n cat >>confdefs.h <<\\EOF\n #define HAVE_WORKING_POLL 1\n EOF\n \n-echo \"$as_me:21741: checking for va_copy\" >&5\n+echo \"$as_me:21742: checking for va_copy\" >&5\n echo $ECHO_N \"checking for va_copy... $ECHO_C\" >&6\n if test \"${cf_cv_have_va_copy+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n \n cat >conftest.$ac_ext <<_ACEOF\n-#line 21748 \"configure\"\n+#line 21749 \"configure\"\n #include \"confdefs.h\"\n \n #include <stdarg.h>\n@@ -21762,16 +21763,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:21765: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:21766: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21768: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21769: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:21771: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:21772: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21774: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21775: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_have_va_copy=yes\n else\n@@ -21781,7 +21782,7 @@ cf_cv_have_va_copy=no\n fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n fi\n-echo \"$as_me:21784: result: $cf_cv_have_va_copy\" >&5\n+echo \"$as_me:21785: result: $cf_cv_have_va_copy\" >&5\n echo \"${ECHO_T}$cf_cv_have_va_copy\" >&6\n \n if test \"$cf_cv_have_va_copy\" = yes;\n@@ -21793,14 +21794,14 @@ EOF\n \n else # !cf_cv_have_va_copy\n \n-echo \"$as_me:21796: checking for __va_copy\" >&5\n+echo \"$as_me:21797: checking for __va_copy\" >&5\n echo $ECHO_N \"checking for __va_copy... $ECHO_C\" >&6\n if test \"${cf_cv_have___va_copy+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n \n cat >conftest.$ac_ext <<_ACEOF\n-#line 21803 \"configure\"\n+#line 21804 \"configure\"\n #include \"confdefs.h\"\n \n #include <stdarg.h>\n@@ -21817,16 +21818,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:21820: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:21821: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21823: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21824: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:21826: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:21827: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21829: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21830: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_have___va_copy=yes\n else\n@@ -21836,7 +21837,7 @@ cf_cv_have___va_copy=no\n fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n fi\n-echo \"$as_me:21839: result: $cf_cv_have___va_copy\" >&5\n+echo \"$as_me:21840: result: $cf_cv_have___va_copy\" >&5\n echo \"${ECHO_T}$cf_cv_have___va_copy\" >&6\n \n if test \"$cf_cv_have___va_copy\" = yes\n@@ -21848,14 +21849,14 @@ EOF\n \n else # !cf_cv_have___va_copy\n \n-echo \"$as_me:21851: checking for __builtin_va_copy\" >&5\n+echo \"$as_me:21852: checking for __builtin_va_copy\" >&5\n echo $ECHO_N \"checking for __builtin_va_copy... $ECHO_C\" >&6\n if test \"${cf_cv_have___builtin_va_copy+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n \n cat >conftest.$ac_ext <<_ACEOF\n-#line 21858 \"configure\"\n+#line 21859 \"configure\"\n #include \"confdefs.h\"\n \n #include <stdarg.h>\n@@ -21872,16 +21873,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:21875: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:21876: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21878: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21879: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:21881: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:21882: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21884: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21885: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_have___builtin_va_copy=yes\n else\n@@ -21891,7 +21892,7 @@ cf_cv_have___builtin_va_copy=no\n fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n fi\n-echo \"$as_me:21894: result: $cf_cv_have___builtin_va_copy\" >&5\n+echo \"$as_me:21895: result: $cf_cv_have___builtin_va_copy\" >&5\n echo \"${ECHO_T}$cf_cv_have___builtin_va_copy\" >&6\n \n test \"$cf_cv_have___builtin_va_copy\" = yes &&\n@@ -21909,14 +21910,14 @@ case \"${cf_cv_have_va_copy}${cf_cv_have___va_copy}${cf_cv_have___builtin_va_copy\n \t;;\n \n (*)\n-\techo \"$as_me:21912: checking if we can simply copy va_list\" >&5\n+\techo \"$as_me:21913: checking if we can simply copy va_list\" >&5\n echo $ECHO_N \"checking if we can simply copy va_list... $ECHO_C\" >&6\n if test \"${cf_cv_pointer_va_list+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n \n cat >conftest.$ac_ext <<_ACEOF\n-#line 21919 \"configure\"\n+#line 21920 \"configure\"\n #include \"confdefs.h\"\n \n #include <stdarg.h>\n@@ -21933,16 +21934,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:21936: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:21937: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21939: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21940: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:21942: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:21943: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21945: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21946: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_pointer_va_list=yes\n else\n@@ -21952,19 +21953,19 @@ cf_cv_pointer_va_list=no\n fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n fi\n-echo \"$as_me:21955: result: $cf_cv_pointer_va_list\" >&5\n+echo \"$as_me:21956: result: $cf_cv_pointer_va_list\" >&5\n echo \"${ECHO_T}$cf_cv_pointer_va_list\" >&6\n \n \tif test \"$cf_cv_pointer_va_list\" = no\n \tthen\n-\t\techo \"$as_me:21960: checking if we can copy va_list indirectly\" >&5\n+\t\techo \"$as_me:21961: checking if we can copy va_list indirectly\" >&5\n echo $ECHO_N \"checking if we can copy va_list indirectly... $ECHO_C\" >&6\n if test \"${cf_cv_array_va_list+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n \n cat >conftest.$ac_ext <<_ACEOF\n-#line 21967 \"configure\"\n+#line 21968 \"configure\"\n #include \"confdefs.h\"\n \n #include <stdarg.h>\n@@ -21981,16 +21982,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:21984: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:21985: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21987: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21988: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:21990: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:21991: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21993: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21994: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_array_va_list=yes\n else\n@@ -22000,7 +22001,7 @@ cf_cv_array_va_list=no\n fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n fi\n-echo \"$as_me:22003: result: $cf_cv_array_va_list\" >&5\n+echo \"$as_me:22004: result: $cf_cv_array_va_list\" >&5\n echo \"${ECHO_T}$cf_cv_array_va_list\" >&6\n \t\ttest \"$cf_cv_array_va_list\" = yes &&\n cat >>confdefs.h <<\\EOF\n@@ -22011,13 +22012,13 @@ EOF\n \t;;\n esac\n \n-echo \"$as_me:22014: checking for pid_t\" >&5\n+echo \"$as_me:22015: checking for pid_t\" >&5\n echo $ECHO_N \"checking for pid_t... $ECHO_C\" >&6\n if test \"${ac_cv_type_pid_t+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 22020 \"configure\"\n+#line 22021 \"configure\"\n #include \"confdefs.h\"\n $ac_includes_default\n int\n@@ -22032,16 +22033,16 @@ if (sizeof (pid_t))\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:22035: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:22036: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:22038: \\$? = $ac_status\" >&5\n+  echo \"$as_me:22039: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:22041: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:22042: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:22044: \\$? = $ac_status\" >&5\n+  echo \"$as_me:22045: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   ac_cv_type_pid_t=yes\n else\n@@ -22051,7 +22052,7 @@ ac_cv_type_pid_t=no\n fi\n rm -f conftest.$ac_objext conftest.$ac_ext\n fi\n-echo \"$as_me:22054: result: $ac_cv_type_pid_t\" >&5\n+echo \"$as_me:22055: result: $ac_cv_type_pid_t\" >&5\n echo \"${ECHO_T}$ac_cv_type_pid_t\" >&6\n if test $ac_cv_type_pid_t = yes; then\n   :\n@@ -22066,23 +22067,23 @@ fi\n for ac_header in unistd.h vfork.h\n do\n as_ac_Header=`echo \"ac_cv_header_$ac_header\" | $as_tr_sh`\n-echo \"$as_me:22069: checking for $ac_header\" >&5\n+echo \"$as_me:22070: checking for $ac_header\" >&5\n echo $ECHO_N \"checking for $ac_header... $ECHO_C\" >&6\n if eval \"test \\\"\\${$as_ac_Header+set}\\\" = set\"; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 22075 \"configure\"\n+#line 22076 \"configure\"\n #include \"confdefs.h\"\n #include <$ac_header>\n _ACEOF\n-if { (eval echo \"$as_me:22079: \\\"$ac_cpp conftest.$ac_ext\\\"\") >&5\n+if { (eval echo \"$as_me:22080: \\\"$ac_cpp conftest.$ac_ext\\\"\") >&5\n   (eval $ac_cpp conftest.$ac_ext) 2>conftest.er1\n   ac_status=$?\n   egrep -v '^ *\\+' conftest.er1 >conftest.err\n   rm -f conftest.er1\n   cat conftest.err >&5\n-  echo \"$as_me:22085: \\$? = $ac_status\" >&5\n+  echo \"$as_me:22086: \\$? = $ac_status\" >&5\n   (exit $ac_status); } >/dev/null; then\n   if test -s conftest.err; then\n     ac_cpp_err=$ac_c_preproc_warn_flag\n@@ -22101,7 +22102,7 @@ else\n fi\n rm -f conftest.err conftest.$ac_ext\n fi\n-echo \"$as_me:22104: result: `eval echo '${'$as_ac_Header'}'`\" >&5\n+echo \"$as_me:22105: result: `eval echo '${'$as_ac_Header'}'`\" >&5\n echo \"${ECHO_T}`eval echo '${'$as_ac_Header'}'`\" >&6\n if test `eval echo '${'$as_ac_Header'}'` = yes; then\n   cat >>confdefs.h <<EOF\n@@ -22114,13 +22115,13 @@ done\n for ac_func in fork vfork\n do\n as_ac_var=`echo \"ac_cv_func_$ac_func\" | $as_tr_sh`\n-echo \"$as_me:22117: checking for $ac_func\" >&5\n+echo \"$as_me:22118: checking for $ac_func\" >&5\n echo $ECHO_N \"checking for $ac_func... $ECHO_C\" >&6\n if eval \"test \\\"\\${$as_ac_var+set}\\\" = set\"; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 22123 \"configure\"\n+#line 22124 \"configure\"\n #include \"confdefs.h\"\n #define $ac_func autoconf_temporary\n #include <limits.h>\t/* least-intrusive standard header which defines gcc2 __stub macros */\n@@ -22151,16 +22152,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:22154: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:22155: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:22157: \\$? = $ac_status\" >&5\n+  echo \"$as_me:22158: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:22160: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:22161: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:22163: \\$? = $ac_status\" >&5\n+  echo \"$as_me:22164: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   eval \"$as_ac_var=yes\"\n else\n@@ -22170,7 +22171,7 @@ eval \"$as_ac_var=no\"\n fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n fi\n-echo \"$as_me:22173: result: `eval echo '${'$as_ac_var'}'`\" >&5\n+echo \"$as_me:22174: result: `eval echo '${'$as_ac_var'}'`\" >&5\n echo \"${ECHO_T}`eval echo '${'$as_ac_var'}'`\" >&6\n if test `eval echo '${'$as_ac_var'}'` = yes; then\n   cat >>confdefs.h <<EOF\n@@ -22182,7 +22183,7 @@ done\n \n ac_cv_func_fork_works=$ac_cv_func_fork\n if test \"x$ac_cv_func_fork\" = xyes; then\n-  echo \"$as_me:22185: checking for working fork\" >&5\n+  echo \"$as_me:22186: checking for working fork\" >&5\n echo $ECHO_N \"checking for working fork... $ECHO_C\" >&6\n if test \"${ac_cv_func_fork_works+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -22205,15 +22206,15 @@ else\n       }\n _ACEOF\n rm -f conftest$ac_exeext\n-if { (eval echo \"$as_me:22208: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:22209: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:22211: \\$? = $ac_status\" >&5\n+  echo \"$as_me:22212: \\$? = $ac_status\" >&5\n   (exit $ac_status); } && { ac_try='./conftest$ac_exeext'\n-  { (eval echo \"$as_me:22213: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:22214: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:22216: \\$? = $ac_status\" >&5\n+  echo \"$as_me:22217: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   ac_cv_func_fork_works=yes\n else\n@@ -22225,7 +22226,7 @@ fi\n rm -f core core.* *.core conftest$ac_exeext conftest.$ac_objext conftest.$ac_ext\n fi\n fi\n-echo \"$as_me:22228: result: $ac_cv_func_fork_works\" >&5\n+echo \"$as_me:22229: result: $ac_cv_func_fork_works\" >&5\n echo \"${ECHO_T}$ac_cv_func_fork_works\" >&6\n \n fi\n@@ -22239,12 +22240,12 @@ if test \"x$ac_cv_func_fork_works\" = xcross; then\n       ac_cv_func_fork_works=yes\n       ;;\n   esac\n-  { echo \"$as_me:22242: WARNING: CROSS: Result $ac_cv_func_fork_works guessed due to cross-compiling.\" >&5\n+  { echo \"$as_me:22243: WARNING: CROSS: Result $ac_cv_func_fork_works guessed due to cross-compiling.\" >&5\n echo \"$as_me: WARNING: CROSS: Result $ac_cv_func_fork_works guessed due to cross-compiling.\" >&2;}\n fi\n ac_cv_func_vfork_works=$ac_cv_func_vfork\n if test \"x$ac_cv_func_vfork\" = xyes; then\n-  echo \"$as_me:22247: checking for working vfork\" >&5\n+  echo \"$as_me:22248: checking for working vfork\" >&5\n echo $ECHO_N \"checking for working vfork... $ECHO_C\" >&6\n if test \"${ac_cv_func_vfork_works+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -22253,7 +22254,7 @@ else\n   ac_cv_func_vfork_works=cross\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 22256 \"configure\"\n+#line 22257 \"configure\"\n #include \"confdefs.h\"\n /* Thanks to Paul Eggert for this test.  */\n #include <stdio.h>\n@@ -22350,15 +22351,15 @@ main (void)\n }\n _ACEOF\n rm -f conftest$ac_exeext\n-if { (eval echo \"$as_me:22353: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:22354: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:22356: \\$? = $ac_status\" >&5\n+  echo \"$as_me:22357: \\$? = $ac_status\" >&5\n   (exit $ac_status); } && { ac_try='./conftest$ac_exeext'\n-  { (eval echo \"$as_me:22358: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:22359: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:22361: \\$? = $ac_status\" >&5\n+  echo \"$as_me:22362: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   ac_cv_func_vfork_works=yes\n else\n@@ -22370,13 +22371,13 @@ fi\n rm -f core core.* *.core conftest$ac_exeext conftest.$ac_objext conftest.$ac_ext\n fi\n fi\n-echo \"$as_me:22373: result: $ac_cv_func_vfork_works\" >&5\n+echo \"$as_me:22374: result: $ac_cv_func_vfork_works\" >&5\n echo \"${ECHO_T}$ac_cv_func_vfork_works\" >&6\n \n fi;\n if test \"x$ac_cv_func_fork_works\" = xcross; then\n   ac_cv_func_vfork_works=ac_cv_func_vfork\n-  { echo \"$as_me:22379: WARNING: CROSS: Result $ac_cv_func_vfork_works guessed due to cross-compiling.\" >&5\n+  { echo \"$as_me:22380: WARNING: CROSS: Result $ac_cv_func_vfork_works guessed due to cross-compiling.\" >&5\n echo \"$as_me: WARNING: CROSS: Result $ac_cv_func_vfork_works guessed due to cross-compiling.\" >&2;}\n fi\n \n@@ -22401,7 +22402,7 @@ EOF\n \n fi\n \n-echo \"$as_me:22404: checking if fopen accepts explicit binary mode\" >&5\n+echo \"$as_me:22405: checking if fopen accepts explicit binary mode\" >&5\n echo $ECHO_N \"checking if fopen accepts explicit binary mode... $ECHO_C\" >&6\n if test \"${cf_cv_fopen_bin_r+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -22411,7 +22412,7 @@ else\n   cf_cv_fopen_bin_r=unknown\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 22414 \"configure\"\n+#line 22415 \"configure\"\n #include \"confdefs.h\"\n \n #include <stdio.h>\n@@ -22444,15 +22445,15 @@ int main(void) {\n \n _ACEOF\n rm -f conftest$ac_exeext\n-if { (eval echo \"$as_me:22447: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:22448: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:22450: \\$? = $ac_status\" >&5\n+  echo \"$as_me:22451: \\$? = $ac_status\" >&5\n   (exit $ac_status); } && { ac_try='./conftest$ac_exeext'\n-  { (eval echo \"$as_me:22452: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:22453: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:22455: \\$? = $ac_status\" >&5\n+  echo \"$as_me:22456: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_fopen_bin_r=yes\n else\n@@ -22465,7 +22466,7 @@ rm -f core core.* *.core conftest$ac_exeext conftest.$ac_objext conftest.$ac_ext\n fi\n \n fi\n-echo \"$as_me:22468: result: $cf_cv_fopen_bin_r\" >&5\n+echo \"$as_me:22469: result: $cf_cv_fopen_bin_r\" >&5\n echo \"${ECHO_T}$cf_cv_fopen_bin_r\" >&6\n test \"x$cf_cv_fopen_bin_r\" != xno &&\n cat >>confdefs.h <<\\EOF\n@@ -22474,7 +22475,7 @@ EOF\n \n # special check for test/ditto.c\n \n-echo \"$as_me:22477: checking for openpty in -lutil\" >&5\n+echo \"$as_me:22478: checking for openpty in -lutil\" >&5\n echo $ECHO_N \"checking for openpty in -lutil... $ECHO_C\" >&6\n if test \"${ac_cv_lib_util_openpty+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -22482,7 +22483,7 @@ else\n   ac_check_lib_save_LIBS=$LIBS\n LIBS=\"-lutil  $LIBS\"\n cat >conftest.$ac_ext <<_ACEOF\n-#line 22485 \"configure\"\n+#line 22486 \"configure\"\n #include \"confdefs.h\"\n \n /* Override any gcc2 internal prototype to avoid an error.  */\n@@ -22501,16 +22502,16 @@ openpty ();\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:22504: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:22505: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:22507: \\$? = $ac_status\" >&5\n+  echo \"$as_me:22508: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:22510: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:22511: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:22513: \\$? = $ac_status\" >&5\n+  echo \"$as_me:22514: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   ac_cv_lib_util_openpty=yes\n else\n@@ -22521,7 +22522,7 @@ fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n LIBS=$ac_check_lib_save_LIBS\n fi\n-echo \"$as_me:22524: result: $ac_cv_lib_util_openpty\" >&5\n+echo \"$as_me:22525: result: $ac_cv_lib_util_openpty\" >&5\n echo \"${ECHO_T}$ac_cv_lib_util_openpty\" >&6\n if test $ac_cv_lib_util_openpty = yes; then\n   cf_cv_lib_util=yes\n@@ -22529,7 +22530,7 @@ else\n   cf_cv_lib_util=no\n fi\n \n-echo \"$as_me:22532: checking for openpty header\" >&5\n+echo \"$as_me:22533: checking for openpty header\" >&5\n echo $ECHO_N \"checking for openpty header... $ECHO_C\" >&6\n if test \"${cf_cv_func_openpty+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -22556,7 +22557,7 @@ LIBS=\"$cf_add_libs\"\n \tfor cf_header in pty.h libutil.h util.h\n \tdo\n \tcat >conftest.$ac_ext <<_ACEOF\n-#line 22559 \"configure\"\n+#line 22560 \"configure\"\n #include \"confdefs.h\"\n \n #include <$cf_header>\n@@ -22573,16 +22574,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:22576: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:22577: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:22579: \\$? = $ac_status\" >&5\n+  echo \"$as_me:22580: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:22582: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:22583: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:22585: \\$? = $ac_status\" >&5\n+  echo \"$as_me:22586: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n \n \t\tcf_cv_func_openpty=$cf_header\n@@ -22600,7 +22601,7 @@ rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n \tLIBS=\"$cf_save_LIBS\"\n \n fi\n-echo \"$as_me:22603: result: $cf_cv_func_openpty\" >&5\n+echo \"$as_me:22604: result: $cf_cv_func_openpty\" >&5\n echo \"${ECHO_T}$cf_cv_func_openpty\" >&6\n \n if test \"$cf_cv_func_openpty\" != no ; then\n@@ -22673,7 +22674,7 @@ if test -n \"$with_hashed_db/include\" ; then\n \tCPPFLAGS=\"${CPPFLAGS}-I$cf_add_incdir\"\n \n \t\t\t  cat >conftest.$ac_ext <<_ACEOF\n-#line 22676 \"configure\"\n+#line 22677 \"configure\"\n #include \"confdefs.h\"\n #include <stdio.h>\n int\n@@ -22685,16 +22686,16 @@ printf(\"Hello\")\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:22688: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:22689: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:22691: \\$? = $ac_status\" >&5\n+  echo \"$as_me:22692: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:22694: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:22695: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:22697: \\$? = $ac_status\" >&5\n+  echo \"$as_me:22698: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   :\n else\n@@ -22711,7 +22712,7 @@ rm -f conftest.$ac_objext conftest.$ac_ext\n \t\tif test \"$cf_have_incdir\" = no ; then\n \t\t  test -n \"$verbose\" && echo \"\tadding $cf_add_incdir to include-path\" 1>&6\n \n-echo \"${as_me:-configure}:22714: testing adding $cf_add_incdir to include-path ...\" 1>&5\n+echo \"${as_me:-configure}:22715: testing adding $cf_add_incdir to include-path ...\" 1>&5\n \n \t\t  CPPFLAGS=\"$CPPFLAGS -I$cf_add_incdir\"\n \n@@ -22747,7 +22748,7 @@ if test -n \"$with_hashed_db/lib\" ; then\n \t\t\tif test \"$cf_have_libdir\" = no ; then\n \t\t\t\ttest -n \"$verbose\" && echo \"\tadding $cf_add_libdir to library-path\" 1>&6\n \n-echo \"${as_me:-configure}:22750: testing adding $cf_add_libdir to library-path ...\" 1>&5\n+echo \"${as_me:-configure}:22751: testing adding $cf_add_libdir to library-path ...\" 1>&5\n \n \t\t\t\tLDFLAGS=\"-L$cf_add_libdir $LDFLAGS\"\n \t\t\tfi\n@@ -22758,7 +22759,7 @@ fi\n \telse\n \t\tcase \"$with_hashed_db\" in\n \t\t(./*|../*|/*)\n-\t\t\t{ echo \"$as_me:22761: WARNING: no such directory $with_hashed_db\" >&5\n+\t\t\t{ echo \"$as_me:22762: WARNING: no such directory $with_hashed_db\" >&5\n echo \"$as_me: WARNING: no such directory $with_hashed_db\" >&2;}\n \t\t\t;;\n \t\t(*)\n@@ -22830,7 +22831,7 @@ if test -n \"$cf_item\" ; then\n \tCPPFLAGS=\"${CPPFLAGS}-I$cf_add_incdir\"\n \n \t\t\t  cat >conftest.$ac_ext <<_ACEOF\n-#line 22833 \"configure\"\n+#line 22834 \"configure\"\n #include \"confdefs.h\"\n #include <stdio.h>\n int\n@@ -22842,16 +22843,16 @@ printf(\"Hello\")\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:22845: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:22846: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:22848: \\$? = $ac_status\" >&5\n+  echo \"$as_me:22849: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:22851: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:22852: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:22854: \\$? = $ac_status\" >&5\n+  echo \"$as_me:22855: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   :\n else\n@@ -22868,7 +22869,7 @@ rm -f conftest.$ac_objext conftest.$ac_ext\n \t\tif test \"$cf_have_incdir\" = no ; then\n \t\t  test -n \"$verbose\" && echo \"\tadding $cf_add_incdir to include-path\" 1>&6\n \n-echo \"${as_me:-configure}:22871: testing adding $cf_add_incdir to include-path ...\" 1>&5\n+echo \"${as_me:-configure}:22872: testing adding $cf_add_incdir to include-path ...\" 1>&5\n \n \t\t  CPPFLAGS=\"$CPPFLAGS -I$cf_add_incdir\"\n \n@@ -22948,7 +22949,7 @@ if test -n \"$cf_item\" ; then\n \t\t\tif test \"$cf_have_libdir\" = no ; then\n \t\t\t\ttest -n \"$verbose\" && echo \"\tadding $cf_add_libdir to library-path\" 1>&6\n \n-echo \"${as_me:-configure}:22951: testing adding $cf_add_libdir to library-path ...\" 1>&5\n+echo \"${as_me:-configure}:22952: testing adding $cf_add_libdir to library-path ...\" 1>&5\n \n \t\t\t\tLDFLAGS=\"-L$cf_add_libdir $LDFLAGS\"\n \t\t\tfi\n@@ -22965,23 +22966,23 @@ fi\n \tfi\n esac\n \n-echo \"$as_me:22968: checking for db.h\" >&5\n+echo \"$as_me:22969: checking for db.h\" >&5\n echo $ECHO_N \"checking for db.h... $ECHO_C\" >&6\n if test \"${ac_cv_header_db_h+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 22974 \"configure\"\n+#line 22975 \"configure\"\n #include \"confdefs.h\"\n #include <db.h>\n _ACEOF\n-if { (eval echo \"$as_me:22978: \\\"$ac_cpp conftest.$ac_ext\\\"\") >&5\n+if { (eval echo \"$as_me:22979: \\\"$ac_cpp conftest.$ac_ext\\\"\") >&5\n   (eval $ac_cpp conftest.$ac_ext) 2>conftest.er1\n   ac_status=$?\n   egrep -v '^ *\\+' conftest.er1 >conftest.err\n   rm -f conftest.er1\n   cat conftest.err >&5\n-  echo \"$as_me:22984: \\$? = $ac_status\" >&5\n+  echo \"$as_me:22985: \\$? = $ac_status\" >&5\n   (exit $ac_status); } >/dev/null; then\n   if test -s conftest.err; then\n     ac_cpp_err=$ac_c_preproc_warn_flag\n@@ -23000,11 +23001,11 @@ else\n fi\n rm -f conftest.err conftest.$ac_ext\n fi\n-echo \"$as_me:23003: result: $ac_cv_header_db_h\" >&5\n+echo \"$as_me:23004: result: $ac_cv_header_db_h\" >&5\n echo \"${ECHO_T}$ac_cv_header_db_h\" >&6\n if test $ac_cv_header_db_h = yes; then\n \n-echo \"$as_me:23007: checking for version of db\" >&5\n+echo \"$as_me:23008: checking for version of db\" >&5\n echo $ECHO_N \"checking for version of db... $ECHO_C\" >&6\n if test \"${cf_cv_hashed_db_version+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -23015,10 +23016,10 @@ cf_cv_hashed_db_version=unknown\n for cf_db_version in 1 2 3 4 5 6\n do\n \n-echo \"${as_me:-configure}:23018: testing checking for db version $cf_db_version ...\" 1>&5\n+echo \"${as_me:-configure}:23019: testing checking for db version $cf_db_version ...\" 1>&5\n \n \tcat >conftest.$ac_ext <<_ACEOF\n-#line 23021 \"configure\"\n+#line 23022 \"configure\"\n #include \"confdefs.h\"\n \n $ac_includes_default\n@@ -23048,16 +23049,16 @@ DBT *foo = 0\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:23051: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:23052: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:23054: \\$? = $ac_status\" >&5\n+  echo \"$as_me:23055: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:23057: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:23058: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:23060: \\$? = $ac_status\" >&5\n+  echo \"$as_me:23061: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n \n \tcf_cv_hashed_db_version=$cf_db_version\n@@ -23071,16 +23072,16 @@ rm -f conftest.$ac_objext conftest.$ac_ext\n done\n \n fi\n-echo \"$as_me:23074: result: $cf_cv_hashed_db_version\" >&5\n+echo \"$as_me:23075: result: $cf_cv_hashed_db_version\" >&5\n echo \"${ECHO_T}$cf_cv_hashed_db_version\" >&6\n \n if test \"$cf_cv_hashed_db_version\" = unknown ; then\n-\t{ { echo \"$as_me:23078: error: Cannot determine version of db\" >&5\n+\t{ { echo \"$as_me:23079: error: Cannot determine version of db\" >&5\n echo \"$as_me: error: Cannot determine version of db\" >&2;}\n    { (exit 1); exit 1; }; }\n else\n \n-echo \"$as_me:23083: checking for db libraries\" >&5\n+echo \"$as_me:23084: checking for db libraries\" >&5\n echo $ECHO_N \"checking for db libraries... $ECHO_C\" >&6\n if test \"${cf_cv_hashed_db_libs+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -23110,10 +23111,10 @@ LIBS=\"$cf_add_libs\"\n \n \tfi\n \n-echo \"${as_me:-configure}:23113: testing checking for library \"$cf_db_libs\" ...\" 1>&5\n+echo \"${as_me:-configure}:23114: testing checking for library \"$cf_db_libs\" ...\" 1>&5\n \n \tcat >conftest.$ac_ext <<_ACEOF\n-#line 23116 \"configure\"\n+#line 23117 \"configure\"\n #include \"confdefs.h\"\n \n $ac_includes_default\n@@ -23168,16 +23169,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:23171: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:23172: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:23174: \\$? = $ac_status\" >&5\n+  echo \"$as_me:23175: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:23177: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:23178: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:23180: \\$? = $ac_status\" >&5\n+  echo \"$as_me:23181: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n \n \tif test -n \"$cf_db_libs\" ; then\n@@ -23197,11 +23198,11 @@ rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n done\n \n fi\n-echo \"$as_me:23200: result: $cf_cv_hashed_db_libs\" >&5\n+echo \"$as_me:23201: result: $cf_cv_hashed_db_libs\" >&5\n echo \"${ECHO_T}$cf_cv_hashed_db_libs\" >&6\n \n \tif test \"$cf_cv_hashed_db_libs\" = unknown ; then\n-\t\t{ { echo \"$as_me:23204: error: Cannot determine library for db\" >&5\n+\t\t{ { echo \"$as_me:23205: error: Cannot determine library for db\" >&5\n echo \"$as_me: error: Cannot determine library for db\" >&2;}\n    { (exit 1); exit 1; }; }\n \telif test \"$cf_cv_hashed_db_libs\" != default ; then\n@@ -23227,7 +23228,7 @@ fi\n \n else\n \n-\t{ { echo \"$as_me:23230: error: Cannot find db.h\" >&5\n+\t{ { echo \"$as_me:23231: error: Cannot find db.h\" >&5\n echo \"$as_me: error: Cannot find db.h\" >&2;}\n    { (exit 1); exit 1; }; }\n \n@@ -23242,7 +23243,7 @@ fi\n \n # Just in case, check if the C compiler has a bool type.\n \n-echo \"$as_me:23245: checking if we should include stdbool.h\" >&5\n+echo \"$as_me:23246: checking if we should include stdbool.h\" >&5\n echo $ECHO_N \"checking if we should include stdbool.h... $ECHO_C\" >&6\n \n if test \"${cf_cv_header_stdbool_h+set}\" = set; then\n@@ -23250,7 +23251,7 @@ if test \"${cf_cv_header_stdbool_h+set}\" = set; then\n else\n \n \tcat >conftest.$ac_ext <<_ACEOF\n-#line 23253 \"configure\"\n+#line 23254 \"configure\"\n #include \"confdefs.h\"\n \n int\n@@ -23262,23 +23263,23 @@ bool foo = false\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:23265: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:23266: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:23268: \\$? = $ac_status\" >&5\n+  echo \"$as_me:23269: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:23271: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:23272: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:23274: \\$? = $ac_status\" >&5\n+  echo \"$as_me:23275: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_header_stdbool_h=0\n else\n   echo \"$as_me: failed program was:\" >&5\n cat conftest.$ac_ext >&5\n cat >conftest.$ac_ext <<_ACEOF\n-#line 23281 \"configure\"\n+#line 23282 \"configure\"\n #include \"confdefs.h\"\n \n #ifndef __BEOS__\n@@ -23294,16 +23295,16 @@ bool foo = false\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:23297: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:23298: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:23300: \\$? = $ac_status\" >&5\n+  echo \"$as_me:23301: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:23303: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:23304: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:23306: \\$? = $ac_status\" >&5\n+  echo \"$as_me:23307: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_header_stdbool_h=1\n else\n@@ -23317,13 +23318,13 @@ rm -f conftest.$ac_objext conftest.$ac_ext\n fi\n \n if test \"$cf_cv_header_stdbool_h\" = 1\n-then\techo \"$as_me:23320: result: yes\" >&5\n+then\techo \"$as_me:23321: result: yes\" >&5\n echo \"${ECHO_T}yes\" >&6\n-else\techo \"$as_me:23322: result: no\" >&5\n+else\techo \"$as_me:23323: result: no\" >&5\n echo \"${ECHO_T}no\" >&6\n fi\n \n-echo \"$as_me:23326: checking for builtin bool type\" >&5\n+echo \"$as_me:23327: checking for builtin bool type\" >&5\n echo $ECHO_N \"checking for builtin bool type... $ECHO_C\" >&6\n \n if test \"${cf_cv_cc_bool_type+set}\" = set; then\n@@ -23331,7 +23332,7 @@ if test \"${cf_cv_cc_bool_type+set}\" = set; then\n else\n \n \tcat >conftest.$ac_ext <<_ACEOF\n-#line 23334 \"configure\"\n+#line 23335 \"configure\"\n #include \"confdefs.h\"\n \n #include <stdio.h>\n@@ -23346,16 +23347,16 @@ bool x = false\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:23349: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:23350: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:23352: \\$? = $ac_status\" >&5\n+  echo \"$as_me:23353: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:23355: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:23356: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:23358: \\$? = $ac_status\" >&5\n+  echo \"$as_me:23359: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_cc_bool_type=1\n else\n@@ -23368,9 +23369,9 @@ rm -f conftest.$ac_objext conftest.$ac_ext\n fi\n \n if test \"$cf_cv_cc_bool_type\" = 1\n-then\techo \"$as_me:23371: result: yes\" >&5\n+then\techo \"$as_me:23372: result: yes\" >&5\n echo \"${ECHO_T}yes\" >&6\n-else\techo \"$as_me:23373: result: no\" >&5\n+else\techo \"$as_me:23374: result: no\" >&5\n echo \"${ECHO_T}no\" >&6\n fi\n \n@@ -23387,10 +23388,10 @@ if test -n \"$GXX\" ; then\n \n \tcf_save=\"$LIBS\"\n \tLIBS=\"$LIBS $CXXLIBS\"\n-\techo \"$as_me:23390: checking if we already have C++ library\" >&5\n+\techo \"$as_me:23391: checking if we already have C++ library\" >&5\n echo $ECHO_N \"checking if we already have C++ library... $ECHO_C\" >&6\n \tcat >conftest.$ac_ext <<_ACEOF\n-#line 23393 \"configure\"\n+#line 23394 \"configure\"\n #include \"confdefs.h\"\n \n \t\t\t#include <iostream>\n@@ -23404,16 +23405,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:23407: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:23408: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:23410: \\$? = $ac_status\" >&5\n+  echo \"$as_me:23411: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:23413: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:23414: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:23416: \\$? = $ac_status\" >&5\n+  echo \"$as_me:23417: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_have_libstdcpp=yes\n else\n@@ -23422,7 +23423,7 @@ cat conftest.$ac_ext >&5\n cf_have_libstdcpp=no\n fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n-\techo \"$as_me:23425: result: $cf_have_libstdcpp\" >&5\n+\techo \"$as_me:23426: result: $cf_have_libstdcpp\" >&5\n echo \"${ECHO_T}$cf_have_libstdcpp\" >&6\n \tLIBS=\"$cf_save\"\n \n@@ -23441,7 +23442,7 @@ echo \"${ECHO_T}$cf_have_libstdcpp\" >&6\n \t\t\t;;\n \t\tesac\n \n-\t\techo \"$as_me:23444: checking for library $cf_stdcpp_libname\" >&5\n+\t\techo \"$as_me:23445: checking for library $cf_stdcpp_libname\" >&5\n echo $ECHO_N \"checking for library $cf_stdcpp_libname... $ECHO_C\" >&6\n if test \"${cf_cv_libstdcpp+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -23467,7 +23468,7 @@ done\n LIBS=\"$cf_add_libs\"\n \n \t\tcat >conftest.$ac_ext <<_ACEOF\n-#line 23470 \"configure\"\n+#line 23471 \"configure\"\n #include \"confdefs.h\"\n \n \t\t\t\t#include <iostream>\n@@ -23481,16 +23482,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:23484: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:23485: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:23487: \\$? = $ac_status\" >&5\n+  echo \"$as_me:23488: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:23490: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:23491: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:23493: \\$? = $ac_status\" >&5\n+  echo \"$as_me:23494: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_libstdcpp=yes\n else\n@@ -23502,7 +23503,7 @@ rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n \t\t\tLIBS=\"$cf_save\"\n \n fi\n-echo \"$as_me:23505: result: $cf_cv_libstdcpp\" >&5\n+echo \"$as_me:23506: result: $cf_cv_libstdcpp\" >&5\n echo \"${ECHO_T}$cf_cv_libstdcpp\" >&6\n \t\ttest \"$cf_cv_libstdcpp\" = yes && {\n cf_add_libs=\"$CXXLIBS\"\n@@ -23524,7 +23525,7 @@ CXXLIBS=\"$cf_add_libs\"\n \tfi\n fi\n \n-\techo \"$as_me:23527: checking whether $CXX understands -c and -o together\" >&5\n+\techo \"$as_me:23528: checking whether $CXX understands -c and -o together\" >&5\n echo $ECHO_N \"checking whether $CXX understands -c and -o together... $ECHO_C\" >&6\n if test \"${cf_cv_prog_CXX_c_o+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -23539,15 +23540,15 @@ CF_EOF\n # We do the test twice because some compilers refuse to overwrite an\n # existing .o file with -o, though they will create one.\n ac_try='$CXX $CXXFLAGS $CPPFLAGS -c conftest.$ac_ext -o conftest2.$ac_objext >&5'\n-if { (eval echo \"$as_me:23542: \\\"$ac_try\\\"\") >&5\n+if { (eval echo \"$as_me:23543: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:23545: \\$? = $ac_status\" >&5\n+  echo \"$as_me:23546: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n-  test -f conftest2.$ac_objext && { (eval echo \"$as_me:23547: \\\"$ac_try\\\"\") >&5\n+  test -f conftest2.$ac_objext && { (eval echo \"$as_me:23548: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:23550: \\$? = $ac_status\" >&5\n+  echo \"$as_me:23551: \\$? = $ac_status\" >&5\n   (exit $ac_status); };\n then\n   eval cf_cv_prog_CXX_c_o=yes\n@@ -23558,15 +23559,15 @@ rm -rf conftest*\n \n fi\n if test $cf_cv_prog_CXX_c_o = yes; then\n-  echo \"$as_me:23561: result: yes\" >&5\n+  echo \"$as_me:23562: result: yes\" >&5\n echo \"${ECHO_T}yes\" >&6\n else\n-  echo \"$as_me:23564: result: no\" >&5\n+  echo \"$as_me:23565: result: no\" >&5\n echo \"${ECHO_T}no\" >&6\n fi\n \n \tcase $GXX_VERSION in\n-\t(1*|2.0-6*)\n+\t(1.*|2.[0-6]*|[1-9][0-9].*)\n \t\tcf_cxx_library=yes\n \t\t;;\n \t(*-2.7*|2.7*)\n@@ -23581,7 +23582,7 @@ case $cf_cv_system_name in\n \t;;\n esac\n if test \"$GXX\" = yes; then\n-\techo \"$as_me:23584: checking for lib$cf_gpp_libname\" >&5\n+\techo \"$as_me:23585: checking for lib$cf_gpp_libname\" >&5\n echo $ECHO_N \"checking for lib$cf_gpp_libname... $ECHO_C\" >&6\n \tcf_save=\"$LIBS\"\n \n@@ -23602,7 +23603,7 @@ done\n LIBS=\"$cf_add_libs\"\n \n \tcat >conftest.$ac_ext <<_ACEOF\n-#line 23605 \"configure\"\n+#line 23606 \"configure\"\n #include \"confdefs.h\"\n \n #include <$cf_gpp_libname/builtin.h>\n@@ -23616,16 +23617,16 @@ two_arg_error_handler_t foo2 = lib_error_handler\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:23619: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:23620: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:23622: \\$? = $ac_status\" >&5\n+  echo \"$as_me:23623: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:23625: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:23626: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:23628: \\$? = $ac_status\" >&5\n+  echo \"$as_me:23629: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cxx_library=yes\n \n@@ -23662,7 +23663,7 @@ else\n   echo \"$as_me: failed program was:\" >&5\n cat conftest.$ac_ext >&5\n cat >conftest.$ac_ext <<_ACEOF\n-#line 23665 \"configure\"\n+#line 23666 \"configure\"\n #include \"confdefs.h\"\n \n #include <builtin.h>\n@@ -23676,16 +23677,16 @@ two_arg_error_handler_t foo2 = lib_error_handler\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:23679: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:23680: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:23682: \\$? = $ac_status\" >&5\n+  echo \"$as_me:23683: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:23685: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:23686: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:23688: \\$? = $ac_status\" >&5\n+  echo \"$as_me:23689: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cxx_library=yes\n \n@@ -23718,7 +23719,7 @@ rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n \tLIBS=\"$cf_save\"\n-\techo \"$as_me:23721: result: $cf_cxx_library\" >&5\n+\techo \"$as_me:23722: result: $cf_cxx_library\" >&5\n echo \"${ECHO_T}$cf_cxx_library\" >&6\n fi\n \n@@ -23734,7 +23735,7 @@ ac_compile='$CXX -c $CXXFLAGS $CPPFLAGS conftest.$ac_ext >&5'\n ac_link='$CXX -o conftest$ac_exeext $CXXFLAGS $CPPFLAGS $LDFLAGS conftest.$ac_ext $LIBS >&5'\n ac_compiler_gnu=$ac_cv_cxx_compiler_gnu\n ac_main_return=return\n-echo \"$as_me:23737: checking how to run the C++ preprocessor\" >&5\n+echo \"$as_me:23738: checking how to run the C++ preprocessor\" >&5\n echo $ECHO_N \"checking how to run the C++ preprocessor... $ECHO_C\" >&6\n if test -z \"$CXXCPP\"; then\n   if test \"${ac_cv_prog_CXXCPP+set}\" = set; then\n@@ -23751,18 +23752,18 @@ do\n   # On the NeXT, cc -E runs the code through the compiler's parser,\n   # not just through cpp. \"Syntax error\" is here to catch this case.\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 23754 \"configure\"\n+#line 23755 \"configure\"\n #include \"confdefs.h\"\n #include <assert.h>\n                      Syntax error\n _ACEOF\n-if { (eval echo \"$as_me:23759: \\\"$ac_cpp conftest.$ac_ext\\\"\") >&5\n+if { (eval echo \"$as_me:23760: \\\"$ac_cpp conftest.$ac_ext\\\"\") >&5\n   (eval $ac_cpp conftest.$ac_ext) 2>conftest.er1\n   ac_status=$?\n   egrep -v '^ *\\+' conftest.er1 >conftest.err\n   rm -f conftest.er1\n   cat conftest.err >&5\n-  echo \"$as_me:23765: \\$? = $ac_status\" >&5\n+  echo \"$as_me:23766: \\$? = $ac_status\" >&5\n   (exit $ac_status); } >/dev/null; then\n   if test -s conftest.err; then\n     ac_cpp_err=$ac_cxx_preproc_warn_flag\n@@ -23785,17 +23786,17 @@ rm -f conftest.err conftest.$ac_ext\n   # OK, works on sane cases.  Now check whether non-existent headers\n   # can be detected and how.\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 23788 \"configure\"\n+#line 23789 \"configure\"\n #include \"confdefs.h\"\n #include <ac_nonexistent.h>\n _ACEOF\n-if { (eval echo \"$as_me:23792: \\\"$ac_cpp conftest.$ac_ext\\\"\") >&5\n+if { (eval echo \"$as_me:23793: \\\"$ac_cpp conftest.$ac_ext\\\"\") >&5\n   (eval $ac_cpp conftest.$ac_ext) 2>conftest.er1\n   ac_status=$?\n   egrep -v '^ *\\+' conftest.er1 >conftest.err\n   rm -f conftest.er1\n   cat conftest.err >&5\n-  echo \"$as_me:23798: \\$? = $ac_status\" >&5\n+  echo \"$as_me:23799: \\$? = $ac_status\" >&5\n   (exit $ac_status); } >/dev/null; then\n   if test -s conftest.err; then\n     ac_cpp_err=$ac_cxx_preproc_warn_flag\n@@ -23832,7 +23833,7 @@ fi\n else\n   ac_cv_prog_CXXCPP=$CXXCPP\n fi\n-echo \"$as_me:23835: result: $CXXCPP\" >&5\n+echo \"$as_me:23836: result: $CXXCPP\" >&5\n echo \"${ECHO_T}$CXXCPP\" >&6\n ac_preproc_ok=false\n for ac_cxx_preproc_warn_flag in '' yes\n@@ -23842,18 +23843,18 @@ do\n   # On the NeXT, cc -E runs the code through the compiler's parser,\n   # not just through cpp. \"Syntax error\" is here to catch this case.\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 23845 \"configure\"\n+#line 23846 \"configure\"\n #include \"confdefs.h\"\n #include <assert.h>\n                      Syntax error\n _ACEOF\n-if { (eval echo \"$as_me:23850: \\\"$ac_cpp conftest.$ac_ext\\\"\") >&5\n+if { (eval echo \"$as_me:23851: \\\"$ac_cpp conftest.$ac_ext\\\"\") >&5\n   (eval $ac_cpp conftest.$ac_ext) 2>conftest.er1\n   ac_status=$?\n   egrep -v '^ *\\+' conftest.er1 >conftest.err\n   rm -f conftest.er1\n   cat conftest.err >&5\n-  echo \"$as_me:23856: \\$? = $ac_status\" >&5\n+  echo \"$as_me:23857: \\$? = $ac_status\" >&5\n   (exit $ac_status); } >/dev/null; then\n   if test -s conftest.err; then\n     ac_cpp_err=$ac_cxx_preproc_warn_flag\n@@ -23876,17 +23877,17 @@ rm -f conftest.err conftest.$ac_ext\n   # OK, works on sane cases.  Now check whether non-existent headers\n   # can be detected and how.\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 23879 \"configure\"\n+#line 23880 \"configure\"\n #include \"confdefs.h\"\n #include <ac_nonexistent.h>\n _ACEOF\n-if { (eval echo \"$as_me:23883: \\\"$ac_cpp conftest.$ac_ext\\\"\") >&5\n+if { (eval echo \"$as_me:23884: \\\"$ac_cpp conftest.$ac_ext\\\"\") >&5\n   (eval $ac_cpp conftest.$ac_ext) 2>conftest.er1\n   ac_status=$?\n   egrep -v '^ *\\+' conftest.er1 >conftest.err\n   rm -f conftest.er1\n   cat conftest.err >&5\n-  echo \"$as_me:23889: \\$? = $ac_status\" >&5\n+  echo \"$as_me:23890: \\$? = $ac_status\" >&5\n   (exit $ac_status); } >/dev/null; then\n   if test -s conftest.err; then\n     ac_cpp_err=$ac_cxx_preproc_warn_flag\n@@ -23914,7 +23915,7 @@ rm -f conftest.err conftest.$ac_ext\n if $ac_preproc_ok; then\n   :\n else\n-  { { echo \"$as_me:23917: error: C++ preprocessor \\\"$CXXCPP\\\" fails sanity check\" >&5\n+  { { echo \"$as_me:23918: error: C++ preprocessor \\\"$CXXCPP\\\" fails sanity check\" >&5\n echo \"$as_me: error: C++ preprocessor \\\"$CXXCPP\\\" fails sanity check\" >&2;}\n    { (exit 1); exit 1; }; }\n fi\n@@ -23929,23 +23930,23 @@ ac_main_return=return\n for ac_header in typeinfo\n do\n as_ac_Header=`echo \"ac_cv_header_$ac_header\" | $as_tr_sh`\n-echo \"$as_me:23932: checking for $ac_header\" >&5\n+echo \"$as_me:23933: checking for $ac_header\" >&5\n echo $ECHO_N \"checking for $ac_header... $ECHO_C\" >&6\n if eval \"test \\\"\\${$as_ac_Header+set}\\\" = set\"; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 23938 \"configure\"\n+#line 23939 \"configure\"\n #include \"confdefs.h\"\n #include <$ac_header>\n _ACEOF\n-if { (eval echo \"$as_me:23942: \\\"$ac_cpp conftest.$ac_ext\\\"\") >&5\n+if { (eval echo \"$as_me:23943: \\\"$ac_cpp conftest.$ac_ext\\\"\") >&5\n   (eval $ac_cpp conftest.$ac_ext) 2>conftest.er1\n   ac_status=$?\n   egrep -v '^ *\\+' conftest.er1 >conftest.err\n   rm -f conftest.er1\n   cat conftest.err >&5\n-  echo \"$as_me:23948: \\$? = $ac_status\" >&5\n+  echo \"$as_me:23949: \\$? = $ac_status\" >&5\n   (exit $ac_status); } >/dev/null; then\n   if test -s conftest.err; then\n     ac_cpp_err=$ac_cxx_preproc_warn_flag\n@@ -23964,7 +23965,7 @@ else\n fi\n rm -f conftest.err conftest.$ac_ext\n fi\n-echo \"$as_me:23967: result: `eval echo '${'$as_ac_Header'}'`\" >&5\n+echo \"$as_me:23968: result: `eval echo '${'$as_ac_Header'}'`\" >&5\n echo \"${ECHO_T}`eval echo '${'$as_ac_Header'}'`\" >&6\n if test `eval echo '${'$as_ac_Header'}'` = yes; then\n   cat >>confdefs.h <<EOF\n@@ -23977,23 +23978,23 @@ done\n for ac_header in iostream\n do\n as_ac_Header=`echo \"ac_cv_header_$ac_header\" | $as_tr_sh`\n-echo \"$as_me:23980: checking for $ac_header\" >&5\n+echo \"$as_me:23981: checking for $ac_header\" >&5\n echo $ECHO_N \"checking for $ac_header... $ECHO_C\" >&6\n if eval \"test \\\"\\${$as_ac_Header+set}\\\" = set\"; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 23986 \"configure\"\n+#line 23987 \"configure\"\n #include \"confdefs.h\"\n #include <$ac_header>\n _ACEOF\n-if { (eval echo \"$as_me:23990: \\\"$ac_cpp conftest.$ac_ext\\\"\") >&5\n+if { (eval echo \"$as_me:23991: \\\"$ac_cpp conftest.$ac_ext\\\"\") >&5\n   (eval $ac_cpp conftest.$ac_ext) 2>conftest.er1\n   ac_status=$?\n   egrep -v '^ *\\+' conftest.er1 >conftest.err\n   rm -f conftest.er1\n   cat conftest.err >&5\n-  echo \"$as_me:23996: \\$? = $ac_status\" >&5\n+  echo \"$as_me:23997: \\$? = $ac_status\" >&5\n   (exit $ac_status); } >/dev/null; then\n   if test -s conftest.err; then\n     ac_cpp_err=$ac_cxx_preproc_warn_flag\n@@ -24012,7 +24013,7 @@ else\n fi\n rm -f conftest.err conftest.$ac_ext\n fi\n-echo \"$as_me:24015: result: `eval echo '${'$as_ac_Header'}'`\" >&5\n+echo \"$as_me:24016: result: `eval echo '${'$as_ac_Header'}'`\" >&5\n echo \"${ECHO_T}`eval echo '${'$as_ac_Header'}'`\" >&6\n if test `eval echo '${'$as_ac_Header'}'` = yes; then\n   cat >>confdefs.h <<EOF\n@@ -24023,10 +24024,10 @@ fi\n done\n \n if test x\"$ac_cv_header_iostream\" = xyes ; then\n-\techo \"$as_me:24026: checking if iostream uses std-namespace\" >&5\n+\techo \"$as_me:24027: checking if iostream uses std-namespace\" >&5\n echo $ECHO_N \"checking if iostream uses std-namespace... $ECHO_C\" >&6\n \tcat >conftest.$ac_ext <<_ACEOF\n-#line 24029 \"configure\"\n+#line 24030 \"configure\"\n #include \"confdefs.h\"\n \n #include <iostream>\n@@ -24043,16 +24044,16 @@ cerr << \"testing\" << endl;\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:24046: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:24047: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:24049: \\$? = $ac_status\" >&5\n+  echo \"$as_me:24050: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:24052: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:24053: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:24055: \\$? = $ac_status\" >&5\n+  echo \"$as_me:24056: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_iostream_namespace=yes\n else\n@@ -24061,7 +24062,7 @@ cat conftest.$ac_ext >&5\n cf_iostream_namespace=no\n fi\n rm -f conftest.$ac_objext conftest.$ac_ext\n-\techo \"$as_me:24064: result: $cf_iostream_namespace\" >&5\n+\techo \"$as_me:24065: result: $cf_iostream_namespace\" >&5\n echo \"${ECHO_T}$cf_iostream_namespace\" >&6\n \tif test \"$cf_iostream_namespace\" = yes ; then\n \n@@ -24072,7 +24073,7 @@ EOF\n \tfi\n fi\n \n-echo \"$as_me:24075: checking if we should include stdbool.h\" >&5\n+echo \"$as_me:24076: checking if we should include stdbool.h\" >&5\n echo $ECHO_N \"checking if we should include stdbool.h... $ECHO_C\" >&6\n \n if test \"${cf_cv_header_stdbool_h+set}\" = set; then\n@@ -24080,7 +24081,7 @@ if test \"${cf_cv_header_stdbool_h+set}\" = set; then\n else\n \n \tcat >conftest.$ac_ext <<_ACEOF\n-#line 24083 \"configure\"\n+#line 24084 \"configure\"\n #include \"confdefs.h\"\n \n int\n@@ -24092,23 +24093,23 @@ bool foo = false\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:24095: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:24096: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:24098: \\$? = $ac_status\" >&5\n+  echo \"$as_me:24099: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:24101: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:24102: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:24104: \\$? = $ac_status\" >&5\n+  echo \"$as_me:24105: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_header_stdbool_h=0\n else\n   echo \"$as_me: failed program was:\" >&5\n cat conftest.$ac_ext >&5\n cat >conftest.$ac_ext <<_ACEOF\n-#line 24111 \"configure\"\n+#line 24112 \"configure\"\n #include \"confdefs.h\"\n \n #ifndef __BEOS__\n@@ -24124,16 +24125,16 @@ bool foo = false\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:24127: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:24128: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:24130: \\$? = $ac_status\" >&5\n+  echo \"$as_me:24131: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:24133: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:24134: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:24136: \\$? = $ac_status\" >&5\n+  echo \"$as_me:24137: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_header_stdbool_h=1\n else\n@@ -24147,13 +24148,13 @@ rm -f conftest.$ac_objext conftest.$ac_ext\n fi\n \n if test \"$cf_cv_header_stdbool_h\" = 1\n-then\techo \"$as_me:24150: result: yes\" >&5\n+then\techo \"$as_me:24151: result: yes\" >&5\n echo \"${ECHO_T}yes\" >&6\n-else\techo \"$as_me:24152: result: no\" >&5\n+else\techo \"$as_me:24153: result: no\" >&5\n echo \"${ECHO_T}no\" >&6\n fi\n \n-echo \"$as_me:24156: checking for builtin bool type\" >&5\n+echo \"$as_me:24157: checking for builtin bool type\" >&5\n echo $ECHO_N \"checking for builtin bool type... $ECHO_C\" >&6\n \n if test \"${cf_cv_builtin_bool+set}\" = set; then\n@@ -24161,7 +24162,7 @@ if test \"${cf_cv_builtin_bool+set}\" = set; then\n else\n \n \tcat >conftest.$ac_ext <<_ACEOF\n-#line 24164 \"configure\"\n+#line 24165 \"configure\"\n #include \"confdefs.h\"\n \n #include <stdio.h>\n@@ -24176,16 +24177,16 @@ bool x = false\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:24179: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:24180: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:24182: \\$? = $ac_status\" >&5\n+  echo \"$as_me:24183: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:24185: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:24186: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:24188: \\$? = $ac_status\" >&5\n+  echo \"$as_me:24189: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_builtin_bool=1\n else\n@@ -24198,13 +24199,13 @@ rm -f conftest.$ac_objext conftest.$ac_ext\n fi\n \n if test \"$cf_cv_builtin_bool\" = 1\n-then\techo \"$as_me:24201: result: yes\" >&5\n+then\techo \"$as_me:24202: result: yes\" >&5\n echo \"${ECHO_T}yes\" >&6\n-else\techo \"$as_me:24203: result: no\" >&5\n+else\techo \"$as_me:24204: result: no\" >&5\n echo \"${ECHO_T}no\" >&6\n fi\n \n-echo \"$as_me:24207: checking for size of bool\" >&5\n+echo \"$as_me:24208: checking for size of bool\" >&5\n echo $ECHO_N \"checking for size of bool... $ECHO_C\" >&6\n if test \"${cf_cv_type_of_bool+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -24215,7 +24216,7 @@ else\n   cf_cv_type_of_bool=unknown\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 24218 \"configure\"\n+#line 24219 \"configure\"\n #include \"confdefs.h\"\n \n #include <stdlib.h>\n@@ -24257,15 +24258,15 @@ int main(void)\n \n _ACEOF\n rm -f conftest$ac_exeext\n-if { (eval echo \"$as_me:24260: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:24261: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:24263: \\$? = $ac_status\" >&5\n+  echo \"$as_me:24264: \\$? = $ac_status\" >&5\n   (exit $ac_status); } && { ac_try='./conftest$ac_exeext'\n-  { (eval echo \"$as_me:24265: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:24266: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:24268: \\$? = $ac_status\" >&5\n+  echo \"$as_me:24269: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_type_of_bool=`cat cf_test.out`\n \t\t if test -z \"$cf_cv_type_of_bool\"; then\n@@ -24283,18 +24284,18 @@ fi\n fi\n \n \trm -f cf_test.out\n-echo \"$as_me:24286: result: $cf_cv_type_of_bool\" >&5\n+echo \"$as_me:24287: result: $cf_cv_type_of_bool\" >&5\n echo \"${ECHO_T}$cf_cv_type_of_bool\" >&6\n if test \"$cf_cv_type_of_bool\" = unknown ; then\n \tcase .$NCURSES_BOOL in\n \t(.auto|.) NCURSES_BOOL=unsigned;;\n \tesac\n-\t{ echo \"$as_me:24292: WARNING: Assuming $NCURSES_BOOL for type of bool\" >&5\n+\t{ echo \"$as_me:24293: WARNING: Assuming $NCURSES_BOOL for type of bool\" >&5\n echo \"$as_me: WARNING: Assuming $NCURSES_BOOL for type of bool\" >&2;}\n \tcf_cv_type_of_bool=$NCURSES_BOOL\n fi\n \n-echo \"$as_me:24297: checking for special defines needed for etip.h\" >&5\n+echo \"$as_me:24298: checking for special defines needed for etip.h\" >&5\n echo $ECHO_N \"checking for special defines needed for etip.h... $ECHO_C\" >&6\n cf_save_CXXFLAGS=\"$CXXFLAGS\"\n cf_result=\"none\"\n@@ -24312,7 +24313,7 @@ do\n \ttest -n \"$cf_math\" && CXXFLAGS=\"$CXXFLAGS -DETIP_NEEDS_${cf_math}\"\n \ttest -n \"$cf_excp\" && CXXFLAGS=\"$CXXFLAGS -DETIP_NEEDS_${cf_excp}\"\n cat >conftest.$ac_ext <<_ACEOF\n-#line 24315 \"configure\"\n+#line 24316 \"configure\"\n #include \"confdefs.h\"\n \n #include <etip.h.in>\n@@ -24326,16 +24327,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:24329: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:24330: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:24332: \\$? = $ac_status\" >&5\n+  echo \"$as_me:24333: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:24335: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:24336: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:24338: \\$? = $ac_status\" >&5\n+  echo \"$as_me:24339: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n \n \ttest -n \"$cf_math\" && cat >>confdefs.h <<EOF\n@@ -24356,12 +24357,12 @@ fi\n rm -f conftest.$ac_objext conftest.$ac_ext\n done\n done\n-echo \"$as_me:24359: result: $cf_result\" >&5\n+echo \"$as_me:24360: result: $cf_result\" >&5\n echo \"${ECHO_T}$cf_result\" >&6\n CXXFLAGS=\"$cf_save_CXXFLAGS\"\n \n if test -n \"$CXX\"; then\n-echo \"$as_me:24364: checking if $CXX accepts parameter initialization\" >&5\n+echo \"$as_me:24365: checking if $CXX accepts parameter initialization\" >&5\n echo $ECHO_N \"checking if $CXX accepts parameter initialization... $ECHO_C\" >&6\n if test \"${cf_cv_cpp_param_init+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -24378,7 +24379,7 @@ ac_main_return=return\n   cf_cv_cpp_param_init=unknown\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 24381 \"configure\"\n+#line 24382 \"configure\"\n #include \"confdefs.h\"\n \n class TEST {\n@@ -24397,15 +24398,15 @@ int main(void) { }\n \n _ACEOF\n rm -f conftest$ac_exeext\n-if { (eval echo \"$as_me:24400: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:24401: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:24403: \\$? = $ac_status\" >&5\n+  echo \"$as_me:24404: \\$? = $ac_status\" >&5\n   (exit $ac_status); } && { ac_try='./conftest$ac_exeext'\n-  { (eval echo \"$as_me:24405: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:24406: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:24408: \\$? = $ac_status\" >&5\n+  echo \"$as_me:24409: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_cpp_param_init=yes\n else\n@@ -24424,7 +24425,7 @@ ac_compiler_gnu=$ac_cv_cxx_compiler_gnu\n ac_main_return=return\n \n fi\n-echo \"$as_me:24427: result: $cf_cv_cpp_param_init\" >&5\n+echo \"$as_me:24428: result: $cf_cv_cpp_param_init\" >&5\n echo \"${ECHO_T}$cf_cv_cpp_param_init\" >&6\n fi\n test \"$cf_cv_cpp_param_init\" = yes &&\n@@ -24434,7 +24435,7 @@ EOF\n \n if test -n \"$CXX\"; then\n \n-echo \"$as_me:24437: checking if $CXX accepts static_cast\" >&5\n+echo \"$as_me:24438: checking if $CXX accepts static_cast\" >&5\n echo $ECHO_N \"checking if $CXX accepts static_cast... $ECHO_C\" >&6\n if test \"${cf_cv_cpp_static_cast+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -24448,7 +24449,7 @@ ac_compiler_gnu=$ac_cv_cxx_compiler_gnu\n ac_main_return=return\n \n \tcat >conftest.$ac_ext <<_ACEOF\n-#line 24451 \"configure\"\n+#line 24452 \"configure\"\n #include \"confdefs.h\"\n \n class NCursesPanel\n@@ -24492,16 +24493,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:24495: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:24496: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:24498: \\$? = $ac_status\" >&5\n+  echo \"$as_me:24499: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:24501: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:24502: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:24504: \\$? = $ac_status\" >&5\n+  echo \"$as_me:24505: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_cpp_static_cast=yes\n else\n@@ -24519,7 +24520,7 @@ ac_compiler_gnu=$ac_cv_cxx_compiler_gnu\n ac_main_return=return\n \n fi\n-echo \"$as_me:24522: result: $cf_cv_cpp_static_cast\" >&5\n+echo \"$as_me:24523: result: $cf_cv_cpp_static_cast\" >&5\n echo \"${ECHO_T}$cf_cv_cpp_static_cast\" >&6\n \n fi\n@@ -24568,7 +24569,7 @@ else\n \telse\n \t\tif test \"$cf_cv_header_stdbool_h\" = 1 ; then\n \n-echo \"$as_me:24571: checking for size of bool\" >&5\n+echo \"$as_me:24572: checking for size of bool\" >&5\n echo $ECHO_N \"checking for size of bool... $ECHO_C\" >&6\n if test \"${cf_cv_type_of_bool+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -24579,7 +24580,7 @@ else\n   cf_cv_type_of_bool=unknown\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 24582 \"configure\"\n+#line 24583 \"configure\"\n #include \"confdefs.h\"\n \n #include <stdlib.h>\n@@ -24621,15 +24622,15 @@ int main(void)\n \n _ACEOF\n rm -f conftest$ac_exeext\n-if { (eval echo \"$as_me:24624: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:24625: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:24627: \\$? = $ac_status\" >&5\n+  echo \"$as_me:24628: \\$? = $ac_status\" >&5\n   (exit $ac_status); } && { ac_try='./conftest$ac_exeext'\n-  { (eval echo \"$as_me:24629: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:24630: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:24632: \\$? = $ac_status\" >&5\n+  echo \"$as_me:24633: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_type_of_bool=`cat cf_test.out`\n \t\t if test -z \"$cf_cv_type_of_bool\"; then\n@@ -24647,25 +24648,25 @@ fi\n fi\n \n \trm -f cf_test.out\n-echo \"$as_me:24650: result: $cf_cv_type_of_bool\" >&5\n+echo \"$as_me:24651: result: $cf_cv_type_of_bool\" >&5\n echo \"${ECHO_T}$cf_cv_type_of_bool\" >&6\n if test \"$cf_cv_type_of_bool\" = unknown ; then\n \tcase .$NCURSES_BOOL in\n \t(.auto|.) NCURSES_BOOL=unsigned;;\n \tesac\n-\t{ echo \"$as_me:24656: WARNING: Assuming $NCURSES_BOOL for type of bool\" >&5\n+\t{ echo \"$as_me:24657: WARNING: Assuming $NCURSES_BOOL for type of bool\" >&5\n echo \"$as_me: WARNING: Assuming $NCURSES_BOOL for type of bool\" >&2;}\n \tcf_cv_type_of_bool=$NCURSES_BOOL\n fi\n \n \t\telse\n-\t\t\techo \"$as_me:24662: checking for fallback type of bool\" >&5\n+\t\t\techo \"$as_me:24663: checking for fallback type of bool\" >&5\n echo $ECHO_N \"checking for fallback type of bool... $ECHO_C\" >&6\n \t\t\tcase \"$host_cpu\" in\n \t\t\t(i?86)\tcf_cv_type_of_bool=char\t;;\n \t\t\t(*)\tcf_cv_type_of_bool=int\t;;\n \t\t\tesac\n-\t\t\techo \"$as_me:24668: result: $cf_cv_type_of_bool\" >&5\n+\t\t\techo \"$as_me:24669: result: $cf_cv_type_of_bool\" >&5\n echo \"${ECHO_T}$cf_cv_type_of_bool\" >&6\n \t\tfi\n \tfi\n@@ -24694,7 +24695,7 @@ if test -f \"${srcdir}/Ada95/Makefile.in\" ; then\n \n \tif test \"$cf_with_ada\" != \"no\" ; then\n \t\tif test \"$with_libtool\" != \"no\"; then\n-\t\t\t{ echo \"$as_me:24697: WARNING: libtool does not support Ada - disabling feature\" >&5\n+\t\t\t{ echo \"$as_me:24698: WARNING: libtool does not support Ada - disabling feature\" >&5\n echo \"$as_me: WARNING: libtool does not support Ada - disabling feature\" >&2;}\n \t\t\tcf_with_ada=no\n \t\tfi\n@@ -24711,7 +24712,7 @@ cf_upper_prog_gnat=`echo \"${cf_prog_gnat}\" | sed y%abcdefghijklmnopqrstuvwxyz./-\n \tunset cf_TEMP_gnat\n \t# Extract the first word of \"$cf_prog_gnat\", so it can be a program name with args.\n set dummy $cf_prog_gnat; ac_word=$2\n-echo \"$as_me:24714: checking for $ac_word\" >&5\n+echo \"$as_me:24715: checking for $ac_word\" >&5\n echo $ECHO_N \"checking for $ac_word... $ECHO_C\" >&6\n if test \"${ac_cv_path_cf_TEMP_gnat+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -24728,7 +24729,7 @@ for ac_dir in $ac_dummy; do\n   test -z \"$ac_dir\" && ac_dir=.\n   if $as_executable_p \"$ac_dir/$ac_word\"; then\n    ac_cv_path_cf_TEMP_gnat=\"$ac_dir/$ac_word\"\n-   echo \"$as_me:24731: found $ac_dir/$ac_word\" >&5\n+   echo \"$as_me:24732: found $ac_dir/$ac_word\" >&5\n    break\n fi\n done\n@@ -24740,10 +24741,10 @@ fi\n cf_TEMP_gnat=$ac_cv_path_cf_TEMP_gnat\n \n if test -n \"$cf_TEMP_gnat\"; then\n-  echo \"$as_me:24743: result: $cf_TEMP_gnat\" >&5\n+  echo \"$as_me:24744: result: $cf_TEMP_gnat\" >&5\n echo \"${ECHO_T}$cf_TEMP_gnat\" >&6\n else\n-  echo \"$as_me:24746: result: no\" >&5\n+  echo \"$as_me:24747: result: no\" >&5\n echo \"${ECHO_T}no\" >&6\n fi\n \n@@ -24753,7 +24754,7 @@ fi\n \t\tunset cf_cv_gnat_version\n \t\tunset cf_TEMP_gnat\n \n-echo \"$as_me:24756: checking for $cf_prog_gnat version\" >&5\n+echo \"$as_me:24757: checking for $cf_prog_gnat version\" >&5\n echo $ECHO_N \"checking for $cf_prog_gnat version... $ECHO_C\" >&6\n if test \"${cf_cv_gnat_version+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -24764,7 +24765,7 @@ cf_cv_gnat_version=`$cf_prog_gnat --version 2>&1 | \\\n \tsed -e '2,$d' -e 's/[^0-9 \\.]//g' -e 's/^[ ]*//' -e 's/ .*//'`\n \n fi\n-echo \"$as_me:24767: result: $cf_cv_gnat_version\" >&5\n+echo \"$as_me:24768: result: $cf_cv_gnat_version\" >&5\n echo \"${ECHO_T}$cf_cv_gnat_version\" >&6\n test -z \"$cf_cv_gnat_version\" && cf_cv_gnat_version=no\n eval cf_TEMP_gnat=$cf_cv_gnat_version; unset cf_cv_gnat_version\n@@ -24793,7 +24794,7 @@ else\n \t\t\tcd conftest.src\n \t\t\tfor cf_gprconfig in Ada C\n \t\t\tdo\n-\t\t\t\techo \"$as_me:24796: checking for gprconfig name for $cf_gprconfig\" >&5\n+\t\t\t\techo \"$as_me:24797: checking for gprconfig name for $cf_gprconfig\" >&5\n echo $ECHO_N \"checking for gprconfig name for $cf_gprconfig... $ECHO_C\" >&6\n \t\t\t\tif test $cf_gprconfig = C\n \t\t\t\tthen\n@@ -24812,10 +24813,10 @@ echo $ECHO_N \"checking for gprconfig name for $cf_gprconfig... $ECHO_C\" >&6\n \t\t\t\tif test -n \"$cf_gprconfig_value\"\n \t\t\t\tthen\n \t\t\t\t\teval cf_ada_config_$cf_gprconfig=$cf_gprconfig_value\n-\t\t\t\t\techo \"$as_me:24815: result: $cf_gprconfig_value\" >&5\n+\t\t\t\t\techo \"$as_me:24816: result: $cf_gprconfig_value\" >&5\n echo \"${ECHO_T}$cf_gprconfig_value\" >&6\n \t\t\t\telse\n-\t\t\t\t\techo \"$as_me:24818: result: missing\" >&5\n+\t\t\t\t\techo \"$as_me:24819: result: missing\" >&5\n echo \"${ECHO_T}missing\" >&6\n \t\t\t\t\tcf_ada_config=\"#\"\n \t\t\t\t\tbreak\n@@ -24828,7 +24829,7 @@ echo \"${ECHO_T}missing\" >&6\n \tif test \"x$cf_ada_config\" != \"x#\"\n \tthen\n \n-echo \"$as_me:24831: checking for gnat version\" >&5\n+echo \"$as_me:24832: checking for gnat version\" >&5\n echo $ECHO_N \"checking for gnat version... $ECHO_C\" >&6\n if test \"${cf_cv_gnat_version+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -24839,7 +24840,7 @@ cf_cv_gnat_version=`${cf_ada_make:-gnatmake} --version 2>&1 | \\\n \tsed -e '2,$d' -e 's/[^0-9 \\.]//g' -e 's/^[ ]*//' -e 's/ .*//'`\n \n fi\n-echo \"$as_me:24842: result: $cf_cv_gnat_version\" >&5\n+echo \"$as_me:24843: result: $cf_cv_gnat_version\" >&5\n echo \"${ECHO_T}$cf_cv_gnat_version\" >&6\n test -z \"$cf_cv_gnat_version\" && cf_cv_gnat_version=no\n \n@@ -24848,7 +24849,7 @@ case $cf_cv_gnat_version in\n \tcf_cv_prog_gnat_correct=yes\n \t;;\n (*)\n-\t{ echo \"$as_me:24851: WARNING: Unsupported GNAT version $cf_cv_gnat_version. We require 3.11 or better. Disabling Ada95 binding.\" >&5\n+\t{ echo \"$as_me:24852: WARNING: Unsupported GNAT version $cf_cv_gnat_version. We require 3.11 or better. Disabling Ada95 binding.\" >&5\n echo \"$as_me: WARNING: Unsupported GNAT version $cf_cv_gnat_version. We require 3.11 or better. Disabling Ada95 binding.\" >&2;}\n \tcf_cv_prog_gnat_correct=no\n \t;;\n@@ -24856,7 +24857,7 @@ esac\n \n \t\t# Extract the first word of \"m4\", so it can be a program name with args.\n set dummy m4; ac_word=$2\n-echo \"$as_me:24859: checking for $ac_word\" >&5\n+echo \"$as_me:24860: checking for $ac_word\" >&5\n echo $ECHO_N \"checking for $ac_word... $ECHO_C\" >&6\n if test \"${ac_cv_prog_M4_exists+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -24871,7 +24872,7 @@ for ac_dir in $ac_dummy; do\n   test -z \"$ac_dir\" && ac_dir=.\n   $as_executable_p \"$ac_dir/$ac_word\" || continue\n ac_cv_prog_M4_exists=\"yes\"\n-echo \"$as_me:24874: found $ac_dir/$ac_word\" >&5\n+echo \"$as_me:24875: found $ac_dir/$ac_word\" >&5\n break\n done\n \n@@ -24880,20 +24881,20 @@ fi\n fi\n M4_exists=$ac_cv_prog_M4_exists\n if test -n \"$M4_exists\"; then\n-  echo \"$as_me:24883: result: $M4_exists\" >&5\n+  echo \"$as_me:24884: result: $M4_exists\" >&5\n echo \"${ECHO_T}$M4_exists\" >&6\n else\n-  echo \"$as_me:24886: result: no\" >&5\n+  echo \"$as_me:24887: result: no\" >&5\n echo \"${ECHO_T}no\" >&6\n fi\n \n \t\tif test \"$ac_cv_prog_M4_exists\" = no; then\n \t\t\tcf_cv_prog_gnat_correct=no\n-\t\t\t{ echo \"$as_me:24892: WARNING: Ada95 binding required program m4 not found. Ada95 binding disabled\" >&5\n+\t\t\t{ echo \"$as_me:24893: WARNING: Ada95 binding required program m4 not found. Ada95 binding disabled\" >&5\n echo \"$as_me: WARNING: Ada95 binding required program m4 not found. Ada95 binding disabled\" >&2;}\n \t\tfi\n \t\tif test \"$cf_cv_prog_gnat_correct\" = yes; then\n-\t\t\techo \"$as_me:24896: checking if GNAT works\" >&5\n+\t\t\techo \"$as_me:24897: checking if GNAT works\" >&5\n echo $ECHO_N \"checking if GNAT works... $ECHO_C\" >&6\n \n rm -rf conftest* *~conftest*\n@@ -24921,7 +24922,7 @@ else\n fi\n rm -rf conftest* *~conftest*\n \n-\t\t\techo \"$as_me:24924: result: $cf_cv_prog_gnat_correct\" >&5\n+\t\t\techo \"$as_me:24925: result: $cf_cv_prog_gnat_correct\" >&5\n echo \"${ECHO_T}$cf_cv_prog_gnat_correct\" >&6\n \t\tfi\n \telse\n@@ -24933,7 +24934,7 @@ fi\n \n  \tADAFLAGS=\"$ADAFLAGS -gnatpn\"\n \n-\techo \"$as_me:24936: checking optimization options for ADAFLAGS\" >&5\n+\techo \"$as_me:24937: checking optimization options for ADAFLAGS\" >&5\n echo $ECHO_N \"checking optimization options for ADAFLAGS... $ECHO_C\" >&6\n \tcase \"$CFLAGS\" in\n \t(*-g*)\n@@ -24950,10 +24951,10 @@ echo $ECHO_N \"checking optimization options for ADAFLAGS... $ECHO_C\" >&6\n \n \t\t;;\n \tesac\n-\techo \"$as_me:24953: result: $ADAFLAGS\" >&5\n+\techo \"$as_me:24954: result: $ADAFLAGS\" >&5\n echo \"${ECHO_T}$ADAFLAGS\" >&6\n \n-echo \"$as_me:24956: checking if GNATPREP supports -T option\" >&5\n+echo \"$as_me:24957: checking if GNATPREP supports -T option\" >&5\n echo $ECHO_N \"checking if GNATPREP supports -T option... $ECHO_C\" >&6\n if test \"${cf_cv_gnatprep_opt_t+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -24963,21 +24964,21 @@ cf_cv_gnatprep_opt_t=no\n gnatprep -T 2>/dev/null >/dev/null && cf_cv_gnatprep_opt_t=yes\n \n fi\n-echo \"$as_me:24966: result: $cf_cv_gnatprep_opt_t\" >&5\n+echo \"$as_me:24967: result: $cf_cv_gnatprep_opt_t\" >&5\n echo \"${ECHO_T}$cf_cv_gnatprep_opt_t\" >&6\n test \"$cf_cv_gnatprep_opt_t\" = yes && GNATPREP_OPTS=\"-T $GNATPREP_OPTS\"\n \n-echo \"$as_me:24970: checking if GNAT supports generics\" >&5\n+echo \"$as_me:24971: checking if GNAT supports generics\" >&5\n echo $ECHO_N \"checking if GNAT supports generics... $ECHO_C\" >&6\n case $cf_cv_gnat_version in\n-(3.[1-9]*|[4-9].*)\n+(3.[1-9]*|[4-9].*|[1-9][0-9].*)\n \tcf_gnat_generics=yes\n \t;;\n (*)\n \tcf_gnat_generics=no\n \t;;\n esac\n-echo \"$as_me:24980: result: $cf_gnat_generics\" >&5\n+echo \"$as_me:24981: result: $cf_gnat_generics\" >&5\n echo \"${ECHO_T}$cf_gnat_generics\" >&6\n \n if test \"$cf_gnat_generics\" = yes\n@@ -24989,7 +24990,7 @@ else\n \tcf_generic_objects=\n fi\n \n-echo \"$as_me:24992: checking if GNAT supports SIGINT\" >&5\n+echo \"$as_me:24993: checking if GNAT supports SIGINT\" >&5\n echo $ECHO_N \"checking if GNAT supports SIGINT... $ECHO_C\" >&6\n if test \"${cf_cv_gnat_sigint+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -25037,7 +25038,7 @@ fi\n rm -rf conftest* *~conftest*\n \n fi\n-echo \"$as_me:25040: result: $cf_cv_gnat_sigint\" >&5\n+echo \"$as_me:25041: result: $cf_cv_gnat_sigint\" >&5\n echo \"${ECHO_T}$cf_cv_gnat_sigint\" >&6\n \n if test $cf_cv_gnat_sigint = yes ; then\n@@ -25050,7 +25051,7 @@ cf_gnat_libraries=no\n cf_gnat_projects=no\n \n if test \"$enable_gnat_projects\" != no ; then\n-echo \"$as_me:25053: checking if GNAT supports project files\" >&5\n+echo \"$as_me:25054: checking if GNAT supports project files\" >&5\n echo $ECHO_N \"checking if GNAT supports project files... $ECHO_C\" >&6\n case $cf_cv_gnat_version in\n (3.[0-9]*)\n@@ -25113,15 +25114,15 @@ CF_EOF\n \tesac\n \t;;\n esac\n-echo \"$as_me:25116: result: $cf_gnat_projects\" >&5\n+echo \"$as_me:25117: result: $cf_gnat_projects\" >&5\n echo \"${ECHO_T}$cf_gnat_projects\" >&6\n fi # enable_gnat_projects\n \n if test $cf_gnat_projects = yes\n then\n-\techo \"$as_me:25122: checking if GNAT supports libraries\" >&5\n+\techo \"$as_me:25123: checking if GNAT supports libraries\" >&5\n echo $ECHO_N \"checking if GNAT supports libraries... $ECHO_C\" >&6\n-\techo \"$as_me:25124: result: $cf_gnat_libraries\" >&5\n+\techo \"$as_me:25125: result: $cf_gnat_libraries\" >&5\n echo \"${ECHO_T}$cf_gnat_libraries\" >&6\n fi\n \n@@ -25141,7 +25142,7 @@ else\n \tUSE_GNAT_LIBRARIES=\"#\"\n fi\n \n-echo \"$as_me:25144: checking for ada-compiler\" >&5\n+echo \"$as_me:25145: checking for ada-compiler\" >&5\n echo $ECHO_N \"checking for ada-compiler... $ECHO_C\" >&6\n \n # Check whether --with-ada-compiler or --without-ada-compiler was given.\n@@ -25152,12 +25153,12 @@ else\n   cf_ada_compiler=gnatmake\n fi;\n \n-echo \"$as_me:25155: result: $cf_ada_compiler\" >&5\n+echo \"$as_me:25156: result: $cf_ada_compiler\" >&5\n echo \"${ECHO_T}$cf_ada_compiler\" >&6\n \n \t\t\tcf_ada_package=terminal_interface\n \n-echo \"$as_me:25160: checking for ada-include\" >&5\n+echo \"$as_me:25161: checking for ada-include\" >&5\n echo $ECHO_N \"checking for ada-include... $ECHO_C\" >&6\n \n # Check whether --with-ada-include or --without-ada-include was given.\n@@ -25193,7 +25194,7 @@ case \".$withval\" in\n \twithval=`echo $withval | sed -e s%NONE%$cf_path_syntax%`\n \t;;\n (*)\n-\t{ { echo \"$as_me:25196: error: expected a pathname, not \\\"$withval\\\"\" >&5\n+\t{ { echo \"$as_me:25197: error: expected a pathname, not \\\"$withval\\\"\" >&5\n echo \"$as_me: error: expected a pathname, not \\\"$withval\\\"\" >&2;}\n    { (exit 1); exit 1; }; }\n \t;;\n@@ -25202,10 +25203,10 @@ esac\n fi\n eval ADA_INCLUDE=\"$withval\"\n \n-echo \"$as_me:25205: result: $ADA_INCLUDE\" >&5\n+echo \"$as_me:25206: result: $ADA_INCLUDE\" >&5\n echo \"${ECHO_T}$ADA_INCLUDE\" >&6\n \n-echo \"$as_me:25208: checking for ada-objects\" >&5\n+echo \"$as_me:25209: checking for ada-objects\" >&5\n echo $ECHO_N \"checking for ada-objects... $ECHO_C\" >&6\n \n # Check whether --with-ada-objects or --without-ada-objects was given.\n@@ -25241,7 +25242,7 @@ case \".$withval\" in\n \twithval=`echo $withval | sed -e s%NONE%$cf_path_syntax%`\n \t;;\n (*)\n-\t{ { echo \"$as_me:25244: error: expected a pathname, not \\\"$withval\\\"\" >&5\n+\t{ { echo \"$as_me:25245: error: expected a pathname, not \\\"$withval\\\"\" >&5\n echo \"$as_me: error: expected a pathname, not \\\"$withval\\\"\" >&2;}\n    { (exit 1); exit 1; }; }\n \t;;\n@@ -25250,10 +25251,10 @@ esac\n fi\n eval ADA_OBJECTS=\"$withval\"\n \n-echo \"$as_me:25253: result: $ADA_OBJECTS\" >&5\n+echo \"$as_me:25254: result: $ADA_OBJECTS\" >&5\n echo \"${ECHO_T}$ADA_OBJECTS\" >&6\n \n-echo \"$as_me:25256: checking if an Ada95 shared-library should be built\" >&5\n+echo \"$as_me:25257: checking if an Ada95 shared-library should be built\" >&5\n echo $ECHO_N \"checking if an Ada95 shared-library should be built... $ECHO_C\" >&6\n \n # Check whether --with-ada-sharedlib or --without-ada-sharedlib was given.\n@@ -25263,14 +25264,14 @@ if test \"${with_ada_sharedlib+set}\" = set; then\n else\n   with_ada_sharedlib=no\n fi;\n-echo \"$as_me:25266: result: $with_ada_sharedlib\" >&5\n+echo \"$as_me:25267: result: $with_ada_sharedlib\" >&5\n echo \"${ECHO_T}$with_ada_sharedlib\" >&6\n \n if test \"x$with_ada_sharedlib\" != xno\n then\n \tif test \"x$cf_gnat_projects\" != xyes\n \tthen\n-\t\t{ echo \"$as_me:25273: WARNING: disabling shared-library since GNAT projects are not supported\" >&5\n+\t\t{ echo \"$as_me:25274: WARNING: disabling shared-library since GNAT projects are not supported\" >&5\n echo \"$as_me: WARNING: disabling shared-library since GNAT projects are not supported\" >&2;}\n \t\twith_ada_sharedlib=no\n \tfi\n@@ -25290,7 +25291,7 @@ fi\n \n \t\t\t# allow the Ada binding to be renamed\n \n-echo \"$as_me:25293: checking for ada-libname\" >&5\n+echo \"$as_me:25294: checking for ada-libname\" >&5\n echo $ECHO_N \"checking for ada-libname... $ECHO_C\" >&6\n \n # Check whether --with-ada-libname or --without-ada-libname was given.\n@@ -25306,7 +25307,7 @@ case \"x$ADA_LIBNAME\" in\n \t;;\n esac\n \n-echo \"$as_me:25309: result: $ADA_LIBNAME\" >&5\n+echo \"$as_me:25310: result: $ADA_LIBNAME\" >&5\n echo \"${ECHO_T}$ADA_LIBNAME\" >&6\n \n \t\tfi\n@@ -25317,13 +25318,13 @@ fi\n \n # do this \"late\" to avoid conflict with header-checks\n if test \"x$with_widec\" = xyes ; then\n-\techo \"$as_me:25320: checking for wchar_t\" >&5\n+\techo \"$as_me:25321: checking for wchar_t\" >&5\n echo $ECHO_N \"checking for wchar_t... $ECHO_C\" >&6\n if test \"${ac_cv_type_wchar_t+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 25326 \"configure\"\n+#line 25327 \"configure\"\n #include \"confdefs.h\"\n $ac_includes_default\n int\n@@ -25338,16 +25339,16 @@ if (sizeof (wchar_t))\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:25341: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:25342: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:25344: \\$? = $ac_status\" >&5\n+  echo \"$as_me:25345: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:25347: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:25348: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:25350: \\$? = $ac_status\" >&5\n+  echo \"$as_me:25351: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   ac_cv_type_wchar_t=yes\n else\n@@ -25357,10 +25358,10 @@ ac_cv_type_wchar_t=no\n fi\n rm -f conftest.$ac_objext conftest.$ac_ext\n fi\n-echo \"$as_me:25360: result: $ac_cv_type_wchar_t\" >&5\n+echo \"$as_me:25361: result: $ac_cv_type_wchar_t\" >&5\n echo \"${ECHO_T}$ac_cv_type_wchar_t\" >&6\n \n-echo \"$as_me:25363: checking size of wchar_t\" >&5\n+echo \"$as_me:25364: checking size of wchar_t\" >&5\n echo $ECHO_N \"checking size of wchar_t... $ECHO_C\" >&6\n if test \"${ac_cv_sizeof_wchar_t+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -25369,7 +25370,7 @@ else\n   if test \"$cross_compiling\" = yes; then\n   # Depending upon the size, compute the lo and hi bounds.\n cat >conftest.$ac_ext <<_ACEOF\n-#line 25372 \"configure\"\n+#line 25373 \"configure\"\n #include \"confdefs.h\"\n $ac_includes_default\n int\n@@ -25381,21 +25382,21 @@ int _array_ [1 - 2 * !((sizeof (wchar_t)) >= 0)]\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:25384: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:25385: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:25387: \\$? = $ac_status\" >&5\n+  echo \"$as_me:25388: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:25390: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:25391: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:25393: \\$? = $ac_status\" >&5\n+  echo \"$as_me:25394: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   ac_lo=0 ac_mid=0\n   while :; do\n     cat >conftest.$ac_ext <<_ACEOF\n-#line 25398 \"configure\"\n+#line 25399 \"configure\"\n #include \"confdefs.h\"\n $ac_includes_default\n int\n@@ -25407,16 +25408,16 @@ int _array_ [1 - 2 * !((sizeof (wchar_t)) <= $ac_mid)]\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:25410: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:25411: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:25413: \\$? = $ac_status\" >&5\n+  echo \"$as_me:25414: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:25416: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:25417: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:25419: \\$? = $ac_status\" >&5\n+  echo \"$as_me:25420: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   ac_hi=$ac_mid; break\n else\n@@ -25432,7 +25433,7 @@ cat conftest.$ac_ext >&5\n ac_hi=-1 ac_mid=-1\n   while :; do\n     cat >conftest.$ac_ext <<_ACEOF\n-#line 25435 \"configure\"\n+#line 25436 \"configure\"\n #include \"confdefs.h\"\n $ac_includes_default\n int\n@@ -25444,16 +25445,16 @@ int _array_ [1 - 2 * !((sizeof (wchar_t)) >= $ac_mid)]\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:25447: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:25448: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:25450: \\$? = $ac_status\" >&5\n+  echo \"$as_me:25451: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:25453: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:25454: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:25456: \\$? = $ac_status\" >&5\n+  echo \"$as_me:25457: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   ac_lo=$ac_mid; break\n else\n@@ -25469,7 +25470,7 @@ rm -f conftest.$ac_objext conftest.$ac_ext\n while test \"x$ac_lo\" != \"x$ac_hi\"; do\n   ac_mid=`expr '(' $ac_hi - $ac_lo ')' / 2 + $ac_lo`\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 25472 \"configure\"\n+#line 25473 \"configure\"\n #include \"confdefs.h\"\n $ac_includes_default\n int\n@@ -25481,16 +25482,16 @@ int _array_ [1 - 2 * !((sizeof (wchar_t)) <= $ac_mid)]\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:25484: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:25485: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:25487: \\$? = $ac_status\" >&5\n+  echo \"$as_me:25488: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:25490: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:25491: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:25493: \\$? = $ac_status\" >&5\n+  echo \"$as_me:25494: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   ac_hi=$ac_mid\n else\n@@ -25503,12 +25504,12 @@ done\n ac_cv_sizeof_wchar_t=$ac_lo\n else\n   if test \"$cross_compiling\" = yes; then\n-  { { echo \"$as_me:25506: error: cannot run test program while cross compiling\" >&5\n+  { { echo \"$as_me:25507: error: cannot run test program while cross compiling\" >&5\n echo \"$as_me: error: cannot run test program while cross compiling\" >&2;}\n    { (exit 1); exit 1; }; }\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 25511 \"configure\"\n+#line 25512 \"configure\"\n #include \"confdefs.h\"\n $ac_includes_default\n int\n@@ -25524,15 +25525,15 @@ fclose (f);\n }\n _ACEOF\n rm -f conftest$ac_exeext\n-if { (eval echo \"$as_me:25527: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:25528: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:25530: \\$? = $ac_status\" >&5\n+  echo \"$as_me:25531: \\$? = $ac_status\" >&5\n   (exit $ac_status); } && { ac_try='./conftest$ac_exeext'\n-  { (eval echo \"$as_me:25532: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:25533: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:25535: \\$? = $ac_status\" >&5\n+  echo \"$as_me:25536: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   ac_cv_sizeof_wchar_t=`cat conftest.val`\n else\n@@ -25548,7 +25549,7 @@ else\n   ac_cv_sizeof_wchar_t=0\n fi\n fi\n-echo \"$as_me:25551: result: $ac_cv_sizeof_wchar_t\" >&5\n+echo \"$as_me:25552: result: $ac_cv_sizeof_wchar_t\" >&5\n echo \"${ECHO_T}$ac_cv_sizeof_wchar_t\" >&6\n cat >>confdefs.h <<EOF\n #define SIZEOF_WCHAR_T $ac_cv_sizeof_wchar_t\n@@ -25561,7 +25562,7 @@ EOF\n \tthen\n \t\ttest -n \"$verbose\" && echo \"\ttest failed (assume 2)\" 1>&6\n \n-echo \"${as_me:-configure}:25564: testing test failed (assume 2) ...\" 1>&5\n+echo \"${as_me:-configure}:25565: testing test failed (assume 2) ...\" 1>&5\n \n \t\tsed /SIZEOF_WCHAR_T/d confdefs.h >confdefs.tmp\n \t\tmv confdefs.tmp confdefs.h\n@@ -25579,7 +25580,7 @@ fi\n ### chooses to split module lists into libraries.\n ###\n ### (see CF_LIB_RULES).\n-echo \"$as_me:25582: checking for library subsets\" >&5\n+echo \"$as_me:25583: checking for library subsets\" >&5\n echo $ECHO_N \"checking for library subsets... $ECHO_C\" >&6\n LIB_SUBSETS=\n \n@@ -25621,7 +25622,7 @@ fi\n test \"x$with_widec\"     = xyes && LIB_SUBSETS=\"${LIB_SUBSETS}+widechar\"\n test \"x$with_ext_funcs\" = xyes && LIB_SUBSETS=\"${LIB_SUBSETS}+ext_funcs\"\n \n-echo \"$as_me:25624: result: $LIB_SUBSETS\" >&5\n+echo \"$as_me:25625: result: $LIB_SUBSETS\" >&5\n echo \"${ECHO_T}$LIB_SUBSETS\" >&6\n \n ### Construct the list of include-directories to be generated\n@@ -25652,7 +25653,7 @@ elif test \"$includedir\" != \"/usr/include\"; then\n fi\n \n ### Build up pieces for makefile rules\n-echo \"$as_me:25655: checking default library suffix\" >&5\n+echo \"$as_me:25656: checking default library suffix\" >&5\n echo $ECHO_N \"checking default library suffix... $ECHO_C\" >&6\n \n \tcase $DFT_LWR_MODEL in\n@@ -25663,10 +25664,10 @@ echo $ECHO_N \"checking default library suffix... $ECHO_C\" >&6\n \t(shared)  DFT_ARG_SUFFIX=''   ;;\n \tesac\n \ttest -n \"$LIB_SUFFIX\" && DFT_ARG_SUFFIX=\"${LIB_SUFFIX}${DFT_ARG_SUFFIX}\"\n-echo \"$as_me:25666: result: $DFT_ARG_SUFFIX\" >&5\n+echo \"$as_me:25667: result: $DFT_ARG_SUFFIX\" >&5\n echo \"${ECHO_T}$DFT_ARG_SUFFIX\" >&6\n \n-echo \"$as_me:25669: checking default library-dependency suffix\" >&5\n+echo \"$as_me:25670: checking default library-dependency suffix\" >&5\n echo $ECHO_N \"checking default library-dependency suffix... $ECHO_C\" >&6\n \n \tcase X$DFT_LWR_MODEL in\n@@ -25749,10 +25750,10 @@ echo $ECHO_N \"checking default library-dependency suffix... $ECHO_C\" >&6\n \t\tDFT_LIB_SUFFIX=\"${LIB_SUFFIX}${EXTRA_SUFFIX}${DFT_LIB_SUFFIX}\"\n \t\tDFT_DEP_SUFFIX=\"${LIB_SUFFIX}${EXTRA_SUFFIX}${DFT_DEP_SUFFIX}\"\n \tfi\n-echo \"$as_me:25752: result: $DFT_DEP_SUFFIX\" >&5\n+echo \"$as_me:25753: result: $DFT_DEP_SUFFIX\" >&5\n echo \"${ECHO_T}$DFT_DEP_SUFFIX\" >&6\n \n-echo \"$as_me:25755: checking default object directory\" >&5\n+echo \"$as_me:25756: checking default object directory\" >&5\n echo $ECHO_N \"checking default object directory... $ECHO_C\" >&6\n \n \tcase $DFT_LWR_MODEL in\n@@ -25768,11 +25769,11 @@ echo $ECHO_N \"checking default object directory... $ECHO_C\" >&6\n \t\t\tDFT_OBJ_SUBDIR='obj_s' ;;\n \t\tesac\n \tesac\n-echo \"$as_me:25771: result: $DFT_OBJ_SUBDIR\" >&5\n+echo \"$as_me:25772: result: $DFT_OBJ_SUBDIR\" >&5\n echo \"${ECHO_T}$DFT_OBJ_SUBDIR\" >&6\n \n if test \"x$cf_with_cxx\" = xyes ; then\n-echo \"$as_me:25775: checking c++ library-dependency suffix\" >&5\n+echo \"$as_me:25776: checking c++ library-dependency suffix\" >&5\n echo $ECHO_N \"checking c++ library-dependency suffix... $ECHO_C\" >&6\n if test \"$with_libtool\" != \"no\"; then\n \t# libtool thinks it can make c++ shared libraries (perhaps only g++)\n@@ -25865,7 +25866,7 @@ else\n \tfi\n \n fi\n-echo \"$as_me:25868: result: $CXX_LIB_SUFFIX\" >&5\n+echo \"$as_me:25869: result: $CXX_LIB_SUFFIX\" >&5\n echo \"${ECHO_T}$CXX_LIB_SUFFIX\" >&6\n \n fi\n@@ -26041,19 +26042,19 @@ fi\n \n if test -n \"$LDFLAGS_STATIC\" && test -n \"$LDFLAGS_SHARED\"\n then\n-\techo \"$as_me:26044: checking if linker supports switching between static/dynamic\" >&5\n+\techo \"$as_me:26045: checking if linker supports switching between static/dynamic\" >&5\n echo $ECHO_N \"checking if linker supports switching between static/dynamic... $ECHO_C\" >&6\n \n \trm -f libconftest.a\n \tcat >conftest.$ac_ext <<EOF\n-#line 26049 \"configure\"\n+#line 26050 \"configure\"\n #include <stdio.h>\n int cf_ldflags_static(FILE *fp) { return fflush(fp); }\n EOF\n-\tif { (eval echo \"$as_me:26053: \\\"$ac_compile\\\"\") >&5\n+\tif { (eval echo \"$as_me:26054: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:26056: \\$? = $ac_status\" >&5\n+  echo \"$as_me:26057: \\$? = $ac_status\" >&5\n   (exit $ac_status); } ; then\n \t\t( $AR $ARFLAGS libconftest.a conftest.o ) 2>&5 1>/dev/null\n \t\t( eval $RANLIB libconftest.a ) 2>&5 >/dev/null\n@@ -26064,10 +26065,10 @@ EOF\n \n \tLIBS=\"$LDFLAGS_STATIC -L`pwd` -lconftest $LDFLAGS_DYNAMIC $LIBS\"\n \tcat >conftest.$ac_ext <<_ACEOF\n-#line 26067 \"configure\"\n+#line 26068 \"configure\"\n #include \"confdefs.h\"\n \n-#line 26070 \"configure\"\n+#line 26071 \"configure\"\n #include <stdio.h>\n int cf_ldflags_static(FILE *fp);\n \n@@ -26082,16 +26083,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:26085: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:26086: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:26088: \\$? = $ac_status\" >&5\n+  echo \"$as_me:26089: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:26091: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:26092: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:26094: \\$? = $ac_status\" >&5\n+  echo \"$as_me:26095: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n \n \t# some linkers simply ignore the -dynamic\n@@ -26114,7 +26115,7 @@ rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n \trm -f libconftest.*\n \tLIBS=\"$cf_save_LIBS\"\n \n-\techo \"$as_me:26117: result: $cf_ldflags_static\" >&5\n+\techo \"$as_me:26118: result: $cf_ldflags_static\" >&5\n echo \"${ECHO_T}$cf_ldflags_static\" >&6\n \n \tif test $cf_ldflags_static != yes\n@@ -26130,7 +26131,7 @@ fi\n \t;;\n esac\n \n-echo \"$as_me:26133: checking where we will install curses.h\" >&5\n+echo \"$as_me:26134: checking where we will install curses.h\" >&5\n echo $ECHO_N \"checking where we will install curses.h... $ECHO_C\" >&6\n \n includesubdir=\n@@ -26140,7 +26141,7 @@ if test \"$with_overwrite\" = no && \\\n then\n \tincludesubdir=\"/ncurses${USE_LIB_SUFFIX}\"\n fi\n-echo \"$as_me:26143: result: ${includedir}${includesubdir}\" >&5\n+echo \"$as_me:26144: result: ${includedir}${includesubdir}\" >&5\n echo \"${ECHO_T}${includedir}${includesubdir}\" >&6\n \n ### Resolve a conflict between normal and wide-curses by forcing applications\n@@ -26148,7 +26149,7 @@ echo \"${ECHO_T}${includedir}${includesubdir}\" >&6\n if test \"$with_overwrite\" != no ; then\n if test \"$NCURSES_LIBUTF8\" = 1 ; then\n \tNCURSES_LIBUTF8='defined(HAVE_LIBUTF8_H)'\n-\t{ echo \"$as_me:26151: WARNING: Wide-character applications must define HAVE_LIBUTF8_H to include curses.h\" >&5\n+\t{ echo \"$as_me:26152: WARNING: Wide-character applications must define HAVE_LIBUTF8_H to include curses.h\" >&5\n echo \"$as_me: WARNING: Wide-character applications must define HAVE_LIBUTF8_H to include curses.h\" >&2;}\n fi\n fi\n@@ -26165,7 +26166,7 @@ EOF\n \n # pkgsrc uses these\n \n-echo \"$as_me:26168: checking for desired basename for form library\" >&5\n+echo \"$as_me:26169: checking for desired basename for form library\" >&5\n echo $ECHO_N \"checking for desired basename for form library... $ECHO_C\" >&6\n \n # Check whether --with-form-libname or --without-form-libname was given.\n@@ -26185,10 +26186,10 @@ case \"x$FORM_NAME\" in\n \t;;\n esac\n \n-echo \"$as_me:26188: result: $FORM_NAME\" >&5\n+echo \"$as_me:26189: result: $FORM_NAME\" >&5\n echo \"${ECHO_T}$FORM_NAME\" >&6\n \n-echo \"$as_me:26191: checking for desired basename for menu library\" >&5\n+echo \"$as_me:26192: checking for desired basename for menu library\" >&5\n echo $ECHO_N \"checking for desired basename for menu library... $ECHO_C\" >&6\n \n # Check whether --with-menu-libname or --without-menu-libname was given.\n@@ -26208,10 +26209,10 @@ case \"x$MENU_NAME\" in\n \t;;\n esac\n \n-echo \"$as_me:26211: result: $MENU_NAME\" >&5\n+echo \"$as_me:26212: result: $MENU_NAME\" >&5\n echo \"${ECHO_T}$MENU_NAME\" >&6\n \n-echo \"$as_me:26214: checking for desired basename for panel library\" >&5\n+echo \"$as_me:26215: checking for desired basename for panel library\" >&5\n echo $ECHO_N \"checking for desired basename for panel library... $ECHO_C\" >&6\n \n # Check whether --with-panel-libname or --without-panel-libname was given.\n@@ -26231,10 +26232,10 @@ case \"x$PANEL_NAME\" in\n \t;;\n esac\n \n-echo \"$as_me:26234: result: $PANEL_NAME\" >&5\n+echo \"$as_me:26235: result: $PANEL_NAME\" >&5\n echo \"${ECHO_T}$PANEL_NAME\" >&6\n \n-echo \"$as_me:26237: checking for desired basename for cxx library\" >&5\n+echo \"$as_me:26238: checking for desired basename for cxx library\" >&5\n echo $ECHO_N \"checking for desired basename for cxx library... $ECHO_C\" >&6\n \n # Check whether --with-cxx-libname or --without-cxx-libname was given.\n@@ -26254,13 +26255,13 @@ case \"x$CXX_NAME\" in\n \t;;\n esac\n \n-echo \"$as_me:26257: result: $CXX_NAME\" >&5\n+echo \"$as_me:26258: result: $CXX_NAME\" >&5\n echo \"${ECHO_T}$CXX_NAME\" >&6\n \n ### Construct the list of subdirectories for which we'll customize makefiles\n ### with the appropriate compile-rules.\n \n-echo \"$as_me:26263: checking for src modules\" >&5\n+echo \"$as_me:26264: checking for src modules\" >&5\n echo $ECHO_N \"checking for src modules... $ECHO_C\" >&6\n \n # dependencies and linker-arguments for test-programs\n@@ -26329,7 +26330,7 @@ eval TEST_ROOT=\\$${cf_map_lib_basename}_NAME\n \t\tfi\n \tfi\n done\n-echo \"$as_me:26332: result: $cf_cv_src_modules\" >&5\n+echo \"$as_me:26333: result: $cf_cv_src_modules\" >&5\n echo \"${ECHO_T}$cf_cv_src_modules\" >&6\n \n TEST_ARGS=\"-L${LIB_DIR} $TEST_ARGS\"\n@@ -26590,7 +26591,7 @@ case $cf_cv_system_name in\n \t(*-D_XOPEN_SOURCE_EXTENDED*)\n \t\ttest -n \"$verbose\" && echo \"\tmoving _XOPEN_SOURCE_EXTENDED to work around g++ problem\" 1>&6\n \n-echo \"${as_me:-configure}:26593: testing moving _XOPEN_SOURCE_EXTENDED to work around g++ problem ...\" 1>&5\n+echo \"${as_me:-configure}:26594: testing moving _XOPEN_SOURCE_EXTENDED to work around g++ problem ...\" 1>&5\n \n \t\tCFLAGS=\"$CFLAGS -D_XOPEN_SOURCE_EXTENDED\"\n \t\tCPPFLAGS=`echo \"x$CPPFLAGS\" | sed -e  's/^.//' -e 's/-D_XOPEN_SOURCE_EXTENDED//'`\n@@ -26601,7 +26602,7 @@ esac\n \n # Help to automatically enable the extended curses features when using either\n # the *-config or the \".pc\" files by adding defines.\n-echo \"$as_me:26604: checking for defines to add to ncurses${USE_CFG_SUFFIX}-config script\" >&5\n+echo \"$as_me:26605: checking for defines to add to ncurses${USE_CFG_SUFFIX}-config script\" >&5\n echo $ECHO_N \"checking for defines to add to ncurses${USE_CFG_SUFFIX}-config script... $ECHO_C\" >&6\n PKG_CFLAGS=\n for cf_loop1 in $CPPFLAGS_after_XOPEN\n@@ -26617,7 +26618,7 @@ do\n \tdone\n \ttest \"$cf_found\" = no && PKG_CFLAGS=\"$PKG_CFLAGS $cf_loop1\"\n done\n-echo \"$as_me:26620: result: $PKG_CFLAGS\" >&5\n+echo \"$as_me:26621: result: $PKG_CFLAGS\" >&5\n echo \"${ECHO_T}$PKG_CFLAGS\" >&6\n \n # AC_CHECK_SIZEOF demands a literal parameter, no variables.  So we do this.\n@@ -26678,7 +26679,7 @@ then\n \tcf_filter_syms=$cf_dft_filter_syms\n \ttest -n \"$verbose\" && echo \"\twill map symbols to ABI=$cf_cv_abi_version\" 1>&6\n \n-echo \"${as_me:-configure}:26681: testing will map symbols to ABI=$cf_cv_abi_version ...\" 1>&5\n+echo \"${as_me:-configure}:26682: testing will map symbols to ABI=$cf_cv_abi_version ...\" 1>&5\n \n fi\n \n@@ -26705,7 +26706,7 @@ fi\n \n # This is used for the *-config script and *.pc data files.\n \n-echo \"$as_me:26708: checking for linker search path\" >&5\n+echo \"$as_me:26709: checking for linker search path\" >&5\n echo $ECHO_N \"checking for linker search path... $ECHO_C\" >&6\n if test \"${cf_cv_ld_searchpath+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -26769,7 +26770,7 @@ done\n test -z \"$cf_cv_ld_searchpath\" && cf_cv_ld_searchpath=/usr/lib\n \n fi\n-echo \"$as_me:26772: result: $cf_cv_ld_searchpath\" >&5\n+echo \"$as_me:26773: result: $cf_cv_ld_searchpath\" >&5\n echo \"${ECHO_T}$cf_cv_ld_searchpath\" >&6\n \n LD_SEARCHPATH=`echo \"$cf_cv_ld_searchpath\"|sed -e 's/ /|/g'`\n@@ -26859,7 +26860,7 @@ DEFS=-DHAVE_CONFIG_H\n : ${CONFIG_STATUS=./config.status}\n ac_clean_files_save=$ac_clean_files\n ac_clean_files=\"$ac_clean_files $CONFIG_STATUS\"\n-{ echo \"$as_me:26862: creating $CONFIG_STATUS\" >&5\n+{ echo \"$as_me:26863: creating $CONFIG_STATUS\" >&5\n echo \"$as_me: creating $CONFIG_STATUS\" >&6;}\n cat >$CONFIG_STATUS <<_ACEOF\n #! $SHELL\n@@ -27035,7 +27036,7 @@ cat >>$CONFIG_STATUS <<\\EOF\n     echo \"$ac_cs_version\"; exit 0 ;;\n   --he | --h)\n     # Conflict between --help and --header\n-    { { echo \"$as_me:27038: error: ambiguous option: $1\n+    { { echo \"$as_me:27039: error: ambiguous option: $1\n Try \\`$0 --help' for more information.\" >&5\n echo \"$as_me: error: ambiguous option: $1\n Try \\`$0 --help' for more information.\" >&2;}\n@@ -27054,7 +27055,7 @@ Try \\`$0 --help' for more information.\" >&2;}\n     ac_need_defaults=false;;\n \n   # This is an error.\n-  -*) { { echo \"$as_me:27057: error: unrecognized option: $1\n+  -*) { { echo \"$as_me:27058: error: unrecognized option: $1\n Try \\`$0 --help' for more information.\" >&5\n echo \"$as_me: error: unrecognized option: $1\n Try \\`$0 --help' for more information.\" >&2;}\n@@ -27177,7 +27178,7 @@ do\n   \"Makefile\" ) CONFIG_FILES=\"$CONFIG_FILES Makefile\" ;;\n   \"default\" ) CONFIG_COMMANDS=\"$CONFIG_COMMANDS default\" ;;\n   \"include/ncurses_cfg.h\" ) CONFIG_HEADERS=\"$CONFIG_HEADERS include/ncurses_cfg.h:include/ncurses_cfg.hin\" ;;\n-  *) { { echo \"$as_me:27180: error: invalid argument: $ac_config_target\" >&5\n+  *) { { echo \"$as_me:27181: error: invalid argument: $ac_config_target\" >&5\n echo \"$as_me: error: invalid argument: $ac_config_target\" >&2;}\n    { (exit 1); exit 1; }; };;\n   esac\n@@ -27676,7 +27677,7 @@ done; }\n   esac\n \n   if test x\"$ac_file\" != x-; then\n-    { echo \"$as_me:27679: creating $ac_file\" >&5\n+    { echo \"$as_me:27680: creating $ac_file\" >&5\n echo \"$as_me: creating $ac_file\" >&6;}\n     rm -f \"$ac_file\"\n   fi\n@@ -27694,7 +27695,7 @@ echo \"$as_me: creating $ac_file\" >&6;}\n       -) echo $tmp/stdin ;;\n       [\\\\/$]*)\n          # Absolute (can't be DOS-style, as IFS=:)\n-         test -f \"$f\" || { { echo \"$as_me:27697: error: cannot find input file: $f\" >&5\n+         test -f \"$f\" || { { echo \"$as_me:27698: error: cannot find input file: $f\" >&5\n echo \"$as_me: error: cannot find input file: $f\" >&2;}\n    { (exit 1); exit 1; }; }\n          echo $f;;\n@@ -27707,7 +27708,7 @@ echo \"$as_me: error: cannot find input file: $f\" >&2;}\n            echo $srcdir/$f\n          else\n            # /dev/null tree\n-           { { echo \"$as_me:27710: error: cannot find input file: $f\" >&5\n+           { { echo \"$as_me:27711: error: cannot find input file: $f\" >&5\n echo \"$as_me: error: cannot find input file: $f\" >&2;}\n    { (exit 1); exit 1; }; }\n          fi;;\n@@ -27723,7 +27724,7 @@ cat >>$CONFIG_STATUS <<\\EOF\n       if test -n \"$ac_seen\"; then\n         ac_used=`grep '@datarootdir@' $ac_item`\n         if test -z \"$ac_used\"; then\n-          { echo \"$as_me:27726: WARNING: datarootdir was used implicitly but not set:\n+          { echo \"$as_me:27727: WARNING: datarootdir was used implicitly but not set:\n $ac_seen\" >&5\n echo \"$as_me: WARNING: datarootdir was used implicitly but not set:\n $ac_seen\" >&2;}\n@@ -27732,7 +27733,7 @@ $ac_seen\" >&2;}\n       fi\n       ac_seen=`grep '${datarootdir}' $ac_item`\n       if test -n \"$ac_seen\"; then\n-        { echo \"$as_me:27735: WARNING: datarootdir was used explicitly but not set:\n+        { echo \"$as_me:27736: WARNING: datarootdir was used explicitly but not set:\n $ac_seen\" >&5\n echo \"$as_me: WARNING: datarootdir was used explicitly but not set:\n $ac_seen\" >&2;}\n@@ -27769,7 +27770,7 @@ s,@INSTALL@,$ac_INSTALL,;t t\n             ac_init=`egrep '[ \t]*'$ac_name'[ \t]*=' $ac_file`\n             if test -z \"$ac_init\"; then\n               ac_seen=`echo \"$ac_seen\" |sed -e 's,^,'$ac_file':,'`\n-              { echo \"$as_me:27772: WARNING: Variable $ac_name is used but was not set:\n+              { echo \"$as_me:27773: WARNING: Variable $ac_name is used but was not set:\n $ac_seen\" >&5\n echo \"$as_me: WARNING: Variable $ac_name is used but was not set:\n $ac_seen\" >&2;}\n@@ -27780,7 +27781,7 @@ $ac_seen\" >&2;}\n     egrep -n '@[A-Z_][A-Z_0-9]+@' $ac_file >>$tmp/out\n     if test -s $tmp/out; then\n       ac_seen=`sed -e 's,^,'$ac_file':,' < $tmp/out`\n-      { echo \"$as_me:27783: WARNING: Some variables may not be substituted:\n+      { echo \"$as_me:27784: WARNING: Some variables may not be substituted:\n $ac_seen\" >&5\n echo \"$as_me: WARNING: Some variables may not be substituted:\n $ac_seen\" >&2;}\n@@ -27829,7 +27830,7 @@ for ac_file in : $CONFIG_HEADERS; do test \"x$ac_file\" = x: && continue\n   * )   ac_file_in=$ac_file.in ;;\n   esac\n \n-  test x\"$ac_file\" != x- && { echo \"$as_me:27832: creating $ac_file\" >&5\n+  test x\"$ac_file\" != x- && { echo \"$as_me:27833: creating $ac_file\" >&5\n echo \"$as_me: creating $ac_file\" >&6;}\n \n   # First look for the input files in the build tree, otherwise in the\n@@ -27840,7 +27841,7 @@ echo \"$as_me: creating $ac_file\" >&6;}\n       -) echo $tmp/stdin ;;\n       [\\\\/$]*)\n          # Absolute (can't be DOS-style, as IFS=:)\n-         test -f \"$f\" || { { echo \"$as_me:27843: error: cannot find input file: $f\" >&5\n+         test -f \"$f\" || { { echo \"$as_me:27844: error: cannot find input file: $f\" >&5\n echo \"$as_me: error: cannot find input file: $f\" >&2;}\n    { (exit 1); exit 1; }; }\n          echo $f;;\n@@ -27853,7 +27854,7 @@ echo \"$as_me: error: cannot find input file: $f\" >&2;}\n            echo $srcdir/$f\n          else\n            # /dev/null tree\n-           { { echo \"$as_me:27856: error: cannot find input file: $f\" >&5\n+           { { echo \"$as_me:27857: error: cannot find input file: $f\" >&5\n echo \"$as_me: error: cannot find input file: $f\" >&2;}\n    { (exit 1); exit 1; }; }\n          fi;;\n@@ -27911,7 +27912,7 @@ cat >>$CONFIG_STATUS <<\\EOF\n   rm -f $tmp/in\n   if test x\"$ac_file\" != x-; then\n     if cmp -s $ac_file $tmp/config.h 2>/dev/null; then\n-      { echo \"$as_me:27914: $ac_file is unchanged\" >&5\n+      { echo \"$as_me:27915: $ac_file is unchanged\" >&5\n echo \"$as_me: $ac_file is unchanged\" >&6;}\n     else\n       ac_dir=`$as_expr X\"$ac_file\" : 'X\\(.*[^/]\\)//*[^/][^/]*/*$' \\| \\\n@@ -28298,7 +28299,7 @@ cf_ITEM=`echo \"$cf_item\" | sed y%abcdefghijklmnopqrstuvwxyz./-%ABCDEFGHIJKLMNOPQ\n \t\t\t\t(cygdll|msysdll|mingw|msvcdll)\n \t\t\t\t\ttest \"x$with_shared_cxx\" = xno && test -n \"$verbose\" && echo \"\toverriding CXX_MODEL to SHARED\" 1>&6\n \n-echo \"${as_me:-configure}:28301: testing overriding CXX_MODEL to SHARED ...\" 1>&5\n+echo \"${as_me:-configure}:28302: testing overriding CXX_MODEL to SHARED ...\" 1>&5\n \n \t\t\t\t\twith_shared_cxx=yes\n \t\t\t\t\t;;\ndiff --git a/configure.in b/configure.in\nindex 10857b8de..7454c9aea 100644\n--- a/configure.in\n+++ b/configure.in\n@@ -29,7 +29,7 @@ dnl***************************************************************************\n dnl\n dnl Author: Thomas E. Dickey 1995-on\n dnl\n-dnl $Id: configure.in,v 1.707 2020/05/23 18:16:07 tom Exp $\n+dnl $Id: configure.in,v 1.709 2020/05/31 20:04:09 tom Exp $\n dnl Process this file with autoconf to produce a configure script.\n dnl\n dnl For additional information, see\n@@ -38,7 +38,7 @@ dnl     https://invisible-island.net/autoconf/my-autoconf.html\n dnl\n dnl ---------------------------------------------------------------------------\n AC_PREREQ(2.52.20200111)\n-AC_REVISION($Revision: 1.707 $)\n+AC_REVISION($Revision: 1.709 $)\n AC_INIT(ncurses/base/lib_initscr.c)\n AC_CONFIG_HEADER(include/ncurses_cfg.h:include/ncurses_cfg.hin)\n \n@@ -145,9 +145,9 @@ fi\n \n CF_GXX_VERSION\n case $GXX_VERSION in\n-(1*|2.[[0-6]]*)\n-\t# GXX=\"\"; CXX=\"\"; ac_cv_prog_gxx=no\n-\t# cf_cxx_library=no\n+([[1-9]][[0-9]].*)\n+\t;;\n+(1.*|2.[[0-6]]*)\n \tAC_MSG_WARN(templates do not work)\n \t;;\n esac\n@@ -1761,6 +1761,7 @@ setenv \\\n setvbuf \\\n sigaction \\\n sigvec \\\n+snprintf \\\n strdup \\\n strstr \\\n sysconf \\\n@@ -1848,7 +1849,7 @@ if test -n \"$CXX\" ; then\n \tCF_PROG_CC_C_O(CXX,[$CXXFLAGS $CPPFLAGS])\n \n \tcase $GXX_VERSION in\n-\t(1*|2.[0-6]*)\n+\t(1.*|2.[[0-6]]*|[[1-9]][[0-9]].*)\n \t\tcf_cxx_library=yes\n \t\t;;\n \t(*-2.7*|2.7*)\ndiff --git a/convert_configure.pl b/convert_configure.pl\ndeleted file mode 100644\nindex f35d154ff..000000000\n--- a/convert_configure.pl\n+++ /dev/null\n@@ -1,120 +0,0 @@\n-extproc perl -S -w\n-\n-# $Id: convert_configure.pl,v 1.4 2020/02/02 23:34:34 tom Exp $\n-##############################################################################\n-# Copyright 2020 Thomas E. Dickey                                            #\n-# Copyright 1998-2000,2006 Free Software Foundation, Inc.                    #\n-#                                                                            #\n-# Permission is hereby granted, free of charge, to any person obtaining a    #\n-# copy of this software and associated documentation files (the \"Software\"), #\n-# to deal in the Software without restriction, including without limitation  #\n-# the rights to use, copy, modify, merge, publish, distribute, distribute    #\n-# with modifications, sublicense, and/or sell copies of the Software, and to #\n-# permit persons to whom the Software is furnished to do so, subject to the  #\n-# following conditions:                                                      #\n-#                                                                            #\n-# The above copyright notice and this permission notice shall be included in #\n-# all copies or substantial portions of the Software.                        #\n-#                                                                            #\n-# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR #\n-# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,   #\n-# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL    #\n-# THE ABOVE COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER      #\n-# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING    #\n-# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER        #\n-# DEALINGS IN THE SOFTWARE.                                                  #\n-#                                                                            #\n-# Except as contained in this notice, the name(s) of the above copyright     #\n-# holders shall not be used in advertising or otherwise to promote the sale, #\n-# use or other dealings in this Software without prior written               #\n-# authorization.                                                             #\n-##############################################################################\n-\n-# The converted script is written to stdout, so run this script as\n-#    convert_configure configure > configure.cmd\n-#\n-# When the converted script runs, it expects that /tmp dir is\n-# available (so we create it).\n-#\n-# run the result like this:\n-#    .\\configure\n-\n-# Some frequent manual intervention:\n-# a) Some makefiles hardwire SHELL = /bin/sh ==> change to: sh\n-# b) Some makefiles recognize that exe files terminate on .exe\n-#    You need to give this script -no-zexe option...\n-\n-shift, $no_zexe = 1 if @ARGV and $ARGV[0] eq '-no-zexe';\n-\n-mkdir '/tmp', 0777 unless -d '/tmp';\n-\n-print <<EOF;\n-extproc sh\n-\n-EOF\n-\n-print <<EOF unless $no_zexe;\n-# Make sensible defaults:\n-CC=\"gcc -Zexe -Zmt\"\n-export CC\n-CXX=\"gcc -Zexe -Zmt\"\n-export CXX\n-#GCCOPT=\"$GCCOPT -Zexe\"\n-#export GCCOPT\n-EOF\n-\n-print <<EOF;\n-CONFIG_SHELL=sh\n-export CONFIG_SHELL\n-\n-# Optimization (GNU make 3.74 cannot be loaded :-():\n-emxload -m 30 sh.exe ls.exe tr.exe id.exe sed.exe # make.exe \n-emxload -m 30 grep.exe egrep.exe fgrep.exe cat.exe rm.exe mv.exe cp.exe\n-emxload -m 30 uniq.exe basename.exe sort.exe awk.exe echo.exe\n-\n-\n-EOF\n-\n-$checking_path = 0;\n-\n-while (<>) {\n-  if (/for\\s+(\\w+)\\s+in\\s*\\$(PATH|ac_dummy)\\s*;/) {\n-    $checking_path = 1;\n-    $varname = $1;\n-    $subst= <<EOS\n-$varname=\"`echo -E \\\\\"\\$$varname\\\\\" | tr \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ / `\"\n-EOS\n-  } \n-  if (/if\\s+test\\s+-z\\s+\\\"\\$INSTALL\\\"/) {\n-    $checking_install = 1;\n-  } \n-  $checking_install = $checking_path = 0 if /^\\s*done\\s*$/;\n-  # We want to create an extra line like this one:\n-#   ac_dir=\"`echo -E \\\"$ac_dir\\\" | tr \\\\\\\\\\\\\\\\ / `\"\n-  s{^((\\s*)if\\s+test)\\s*-f\\s*(\\$$varname/\\S+)\\s*;}\n-   {$2$subst$1 -f $3 -o -f $3.exe ;}\n-      if $checking_path;\t# Checking for executables\n-  # change |/usr/sbin/*| to |/usr/sbin/*|?:[\\\\/]os2[\\\\/]install[\\\\/]*|\n-  # in the list of things to skip (with both cases)\n-  s{\\Q|/usr/sbin/*|}\n-   {|/usr/sbin/*|?:[\\\\\\\\/]os2[\\\\\\\\/]install[\\\\\\\\/]*|?:[\\\\\\\\/]OS2[\\\\\\\\/]INSTALL[\\\\\\\\/]*|}\n-      if $checking_install;\t# Do not accept d:/os2/install/install.exe\n-  s/^(host|build)=NONE$/$1=x86-emx-os2/;\t# Make default host/build\n-  s/\"\\$\\{IFS}:\"$/\"\\${IFS};\"/;\t# Fix IFS line\n-  s/\\bIFS=\\\":\\\"$/IFS=\";\"/;\t# Fix another IFS line\n-  s/\\btest\\s+-s\\s+conftest\\b/test -f conftest/g; # Fix exe test\n-  # This one is needed for curses:\n-  s/^\\s*host=`.*\\$ac_config_sub \\$host_alias`/$&\\nif test -z \"\\$host\"; then host=\\$host_alias; fi/;\n-  s,/bin/sh(?![/\\w]),sh,g;\n-  s,^(\\s*/usr/sbin/sendmail\\s*)\\\\$,$1 \"`whence sendmail | tr '\\\\\\\\\\\\\\\\' / `\" \\\\,;\n-  print;\n-}\n-\n-__END__\n-\n-Changes:\t98/11 : support check for executables in ncurses.\n-\t\t99/2  : support INSTALL, \n-\t\t\tnew IFS=':' style\n-\t\t99/11 : find sendmail\n-\t\t00/01 : export CONFIG_SHELL\n-\t\t00/10 : new syntax for host=`...` line\ndiff --git a/dist.mk b/dist.mk\nindex 4e711ef8f..6bfdbd5ec 100644\n--- a/dist.mk\n+++ b/dist.mk\n@@ -26,7 +26,7 @@\n # use or other dealings in this Software without prior written               #\n # authorization.                                                             #\n ##############################################################################\n-# $Id: dist.mk,v 1.1351 2020/05/23 09:35:39 tom Exp $\n+# $Id: dist.mk,v 1.1354 2020/05/31 18:56:59 tom Exp $\n # Makefile for creating ncurses distributions.\n #\n # This only needs to be used directly as a makefile by developers, but\n@@ -38,7 +38,7 @@ SHELL = /bin/sh\n # These define the major/minor/patch versions of ncurses.\n NCURSES_MAJOR = 6\n NCURSES_MINOR = 2\n-NCURSES_PATCH = 20200523\n+NCURSES_PATCH = 20200531\n \n # We don't append the patch to the version, since this only applies to releases\n VERSION = $(NCURSES_MAJOR).$(NCURSES_MINOR)\ndiff --git a/include/MKterm.h.awk.in b/include/MKterm.h.awk.in\nindex ee4e2b48d..3c7eb72c1 100644\n--- a/include/MKterm.h.awk.in\n+++ b/include/MKterm.h.awk.in\n@@ -60,7 +60,7 @@ BEGIN {\n \tprint  \"/*    and: Thomas E. Dickey                        1995-on                  */\"\n \tprint  \"/****************************************************************************/\"\n \tprint  \"\"\n-\tprint  \"/* $Id: MKterm.h.awk.in,v 1.74 2020/02/02 23:34:34 tom Exp $ */\"\n+\tprint  \"/* $Id: MKterm.h.awk.in,v 1.76 2020/05/30 19:24:03 tom Exp $ */\"\n \tprint  \"\"\n \tprint  \"/*\"\n \tprint  \"**\tterm.h -- Definition of struct term\"\n@@ -298,6 +298,7 @@ END {\n \tprint  \"extern NCURSES_EXPORT(int) _nc_read_termtype (TERMTYPE2 *, char *, int);\"\n \tprint  \"extern NCURSES_EXPORT(char *) _nc_first_name (const char *const);\"\n \tprint  \"extern NCURSES_EXPORT(int) _nc_name_match (const char *const, const char *const, const char *const);\"\n+\tprint  \"extern NCURSES_EXPORT(char *) _nc_tiparm(int, const char *, ...);\"\n \tprint  \"\"\n \tprint  \"#endif /* NCURSES_INTERNALS */\"\n \tprint  \"\"\n@@ -330,7 +331,6 @@ END {\n \tprint  \"extern NCURSES_EXPORT(char *) tparm (const char *, ...);\t/* special */\"\n \tprint  \"#else\"\n \tprint  \"extern NCURSES_EXPORT(char *) tparm (const char *, long,long,long,long,long,long,long,long,long);\t/* special */\"\n-\tprint  \"extern NCURSES_EXPORT(char *) tparm_varargs (const char *, ...);\t/* special */\"\n \tprint  \"#endif\"\n \tprint  \"\"\n \tprint  \"extern NCURSES_EXPORT(char *) tiparm (const char *, ...);\t\t/* special */\"\n@@ -361,7 +361,6 @@ END {\n \tprint  \"extern NCURSES_EXPORT(char *)  NCURSES_SP_NAME(tparm) (SCREEN*, const char *, ...);\t/* special */\"\n \tprint  \"#else\"\n \tprint  \"extern NCURSES_EXPORT(char *)  NCURSES_SP_NAME(tparm) (SCREEN*, const char *, long,long,long,long,long,long,long,long,long);\t/* special */\"\n-\tprint  \"extern NCURSES_EXPORT(char *)  NCURSES_SP_NAME(tparm_varargs) (SCREEN*, const char *, ...);\t/* special */\"\n \tprint  \"#endif\"\n \tprint  \"\"\n \tprint  \"/* termcap database emulation (XPG4 uses const only for 2nd param of tgetent) */\"\ndiff --git a/include/curses.h.in b/include/curses.h.in\nindex 2cb3224b3..db07cb53d 100644\n--- a/include/curses.h.in\n+++ b/include/curses.h.in\n@@ -33,7 +33,7 @@\n  *     and: Thomas E. Dickey                        1996-on                 *\n  ****************************************************************************/\n \n-/* $Id: curses.h.in,v 1.266 2020/02/08 10:51:53 tom Exp $ */\n+/* $Id: curses.h.in,v 1.267 2020/05/30 19:23:28 tom Exp $ */\n \n #ifndef __NCURSES_H\n #define __NCURSES_H\n@@ -895,7 +895,6 @@ extern NCURSES_EXPORT(int) putp (const char *);\t\t\t\t/* implemented */\n extern NCURSES_EXPORT(char *) tparm (const char *, ...);\t\t/* special */\n #else\n extern NCURSES_EXPORT(char *) tparm (const char *, NCURSES_TPARM_ARG,NCURSES_TPARM_ARG,NCURSES_TPARM_ARG,NCURSES_TPARM_ARG,NCURSES_TPARM_ARG,NCURSES_TPARM_ARG,NCURSES_TPARM_ARG,NCURSES_TPARM_ARG,NCURSES_TPARM_ARG);\t/* special */\n-extern NCURSES_EXPORT(char *) tparm_varargs (const char *, ...);\t/* special */\n #endif\n \n extern NCURSES_EXPORT(char *) tiparm (const char *, ...);\t\t/* special */\ndiff --git a/include/nc_tparm.h b/include/nc_tparm.h\nindex 61570959c..943d94760 100644\n--- a/include/nc_tparm.h\n+++ b/include/nc_tparm.h\n@@ -31,7 +31,7 @@\n  *  Author: Thomas E. Dickey                        2006                    *\n  ****************************************************************************/\n \n-/* $Id: nc_tparm.h,v 1.10 2020/02/02 23:34:34 tom Exp $ */\n+/* $Id: nc_tparm.h,v 1.11 2020/05/27 23:33:31 tom Exp $ */\n \n #ifndef NC_TPARM_included\n #define NC_TPARM_included 1\n@@ -77,4 +77,16 @@\n #define TPARM_0(a) TPARM_1(a,0)\n #endif\n \n+#ifdef NCURSES_INTERNALS\n+#define TIPARM_1(s,a) _nc_tiparm(1,s,a)\n+#define TIPARM_2(s,a,b) _nc_tiparm(2,s,a,b)\n+#define TIPARM_3(s,a,b,c) _nc_tiparm(3,s,a,b,c)\n+#define TIPARM_4(s,a,b,c,d) _nc_tiparm(4,s,a,b,c,d)\n+#define TIPARM_5(s,a,b,c,d,e) _nc_tiparm(5,s,a,b,c,d,e)\n+#define TIPARM_6(s,a,b,c,d,e,f) _nc_tiparm(6,s,a,b,c,d,e,f)\n+#define TIPARM_7(s,a,b,c,d,e,f,g) _nc_tiparm(7,s,a,b,c,d,e,f,g)\n+#define TIPARM_8(s,a,b,c,d,e,f,g,h) _nc_tiparm(8,s,a,b,c,d,e,f,g,h)\n+#define TIPARM_9(s,a,b,c,d,e,f,g,h,i) _nc_tiparm(9,s,a,b,c,d,e,f,g,h,i)\n+#endif\n+\n #endif /* NC_TPARM_included */\ndiff --git a/misc/terminfo.src b/misc/terminfo.src\nindex a68de86ea..21fdd2e91 100644\n--- a/misc/terminfo.src\n+++ b/misc/terminfo.src\n@@ -6,8 +6,8 @@\n # Report bugs and new terminal descriptions to\n #\tbug-ncurses@gnu.org\n #\n-#\t$Revision: 1.800 $\n-#\t$Date: 2020/05/16 16:59:20 $\n+#\t$Revision: 1.802 $\n+#\t$Date: 2020/05/30 21:37:01 $\n #\n # The original header is preserved below for reference.  It is noted that there\n # is a \"newer\" version which differs in some cosmetic details (but actually\n@@ -4447,7 +4447,7 @@ xterm-old|antique xterm version,\n # initially part of the xterm sources (in XFree86).  But \"xterm\" continued to\n # grow, while \"xterm-mono\" had none of the newer features.  Additionally,\n # inheriting from \"xtermm\" runs into several problems, including different\n-# function keys as well as the fact that the mouse support is not compatible. \n+# function keys as well as the fact that the mouse support is not compatible.\n # This entry restores the original intent, intentionally not an alias to\n # simplify maintenance -TD\n xterm-mono|monochrome xterm,\n@@ -5781,10 +5781,13 @@ kvt|KDE terminal,\n #    (also overline, which is too rarely used to provide as an extension)\n #\n # Updated for konsole 17.12.0 (late 2017):\n+#\n+# Re-enable \"bel\", since it is latent in the source-code even though KDE config\n+# often hides the feature (2020/5/30)\n konsole-base|KDE console window,\n \tbce, km@, npc, XT,\n \tncv@,\n-\tbel@, blink=\\E[5m, civis=\\E[?25l, cnorm=\\E[?25h, dim=\\E[2m,\n+\tblink=\\E[5m, civis=\\E[?25l, cnorm=\\E[?25h, dim=\\E[2m,\n \tech=\\E[%p1%dX, flash=\\E[?5h$<100/>\\E[?5l,\n \thpa=\\E[%i%p1%dG, invis=\\E[8m, kbs=^?, kdch1=\\E[3~,\n \tkend=\\E[4~, kf1@, kf10@, kf11@, kf12@, kf13@, kf14@, kf15@, kf16@,\n@@ -20911,6 +20914,17 @@ linux-m2|Linux Minitel 2 \"like\" Couleurs (Vert/Blanc/Noir+Bleu),\n \t       \\E]PFFFFFFF\\E[;37m,\n \tuse=linux-m1,\n \n+# From: Alexandre Montaron, 27 May 2020\n+linux-s|Linux Console with added status line at bottom,\n+\ths,\n+\tclear=\\E[255;255H\\E[A\\E[1J\\E[H, csr@,\n+\tdsl=\\E7\\E[255H\\E[K\\E8, ed@, fsl=\\E8,\n+\tiprog=\\sbash\\s-c\\s'echo\\s-ne\\s\"\\E[?6l\\E[255H\\E[A\\E[6n\"\\s;\n+\t      \\sread\\s-d\\sR\\sTMP\\s;\\sLINES=`echo\\s$TMP\\s|\\scut\\s-f1\n+\t      \\s-d\\s\";\"\\s|\\scut\\s-f2\\s-d\\s\"[\"`\\s;\\sstty\\srows\\s$LINE\n+\t      S\\s;\\secho\\s-ne\\s\"\\E[;\"$LINES\"r\\E[J\"',\n+\trs1=\\E]R, tsl=\\E7\\E[255;%p1%dH, .rc@, .sc@, use=linux,\n+\n # Screen entries counterpart :\n \n screen.linux-m1|Linux m1 specific for screen,\n@@ -26557,4 +26571,8 @@ v3220|LANPAR Vision II model 3220/3221/3222,\n # 2020-05-16\n #\t+ update notes on vscode / xterm.js -TD\n #\n+# 2020-05-30\n+#\t+ re-enable \"bel\" in konsole-base (report by Nia Huang)\n+#\t+ add linux-s entry (patch by Alexandre Montaron).\n+#\n ######## SHANTIH!  SHANTIH!  SHANTIH!\ndiff --git a/ncurses/base/lib_color.c b/ncurses/base/lib_color.c\nindex 376ad4f60..2343219e0 100644\n--- a/ncurses/base/lib_color.c\n+++ b/ncurses/base/lib_color.c\n@@ -49,7 +49,7 @@\n #define CUR SP_TERMTYPE\n #endif\n \n-MODULE_ID(\"$Id: lib_color.c,v 1.143 2020/02/02 23:34:34 tom Exp $\")\n+MODULE_ID(\"$Id: lib_color.c,v 1.145 2020/05/27 23:55:32 tom Exp $\")\n \n #ifdef USE_TERM_DRIVER\n #define CanChange      InfoOf(SP_PARM).canchange\n@@ -140,7 +140,6 @@ NCURSES_EXPORT_VAR(const color_t*) _nc_hls_palette = hls_palette;\n #endif\n \n /* *INDENT-ON* */\n-\n #if NCURSES_EXT_FUNCS\n /*\n  * These are called from _nc_do_color(), which in turn is called from\n@@ -190,12 +189,12 @@ set_background_color(NCURSES_SP_DCLx int bg, NCURSES_SP_OUTC outc)\n     if (set_a_background) {\n \tTPUTS_TRACE(\"set_a_background\");\n \tNCURSES_SP_NAME(tputs) (NCURSES_SP_ARGx\n-\t\t\t\tTPARM_1(set_a_background, bg),\n+\t\t\t\tTIPARM_1(set_a_background, bg),\n \t\t\t\t1, outc);\n     } else {\n \tTPUTS_TRACE(\"set_background\");\n \tNCURSES_SP_NAME(tputs) (NCURSES_SP_ARGx\n-\t\t\t\tTPARM_1(set_background, toggled_colors(bg)),\n+\t\t\t\tTIPARM_1(set_background, toggled_colors(bg)),\n \t\t\t\t1, outc);\n     }\n #endif\n@@ -210,12 +209,12 @@ set_foreground_color(NCURSES_SP_DCLx int fg, NCURSES_SP_OUTC outc)\n     if (set_a_foreground) {\n \tTPUTS_TRACE(\"set_a_foreground\");\n \tNCURSES_SP_NAME(tputs) (NCURSES_SP_ARGx\n-\t\t\t\tTPARM_1(set_a_foreground, fg),\n+\t\t\t\tTIPARM_1(set_a_foreground, fg),\n \t\t\t\t1, outc);\n     } else {\n \tTPUTS_TRACE(\"set_foreground\");\n \tNCURSES_SP_NAME(tputs) (NCURSES_SP_ARGx\n-\t\t\t\tTPARM_1(set_foreground, toggled_colors(fg)),\n+\t\t\t\tTIPARM_1(set_foreground, toggled_colors(fg)),\n \t\t\t\t1, outc);\n     }\n #endif\n@@ -672,14 +671,14 @@ _nc_init_pair(SCREEN *sp, int pair, int f, int b)\n \t    (int) tp[b].red, (int) tp[b].green, (int) tp[b].blue));\n \n \tNCURSES_PUTP2(\"initialize_pair\",\n-\t\t      TPARM_7(initialize_pair,\n-\t\t\t      pair,\n-\t\t\t      (int) tp[f].red,\n-\t\t\t      (int) tp[f].green,\n-\t\t\t      (int) tp[f].blue,\n-\t\t\t      (int) tp[b].red,\n-\t\t\t      (int) tp[b].green,\n-\t\t\t      (int) tp[b].blue));\n+\t\t      TIPARM_7(initialize_pair,\n+\t\t\t       pair,\n+\t\t\t       (int) tp[f].red,\n+\t\t\t       (int) tp[f].green,\n+\t\t\t       (int) tp[f].blue,\n+\t\t\t       (int) tp[b].red,\n+\t\t\t       (int) tp[b].green,\n+\t\t\t       (int) tp[b].blue));\n     }\n #endif\n \n@@ -746,7 +745,7 @@ _nc_init_color(SCREEN *sp, int color, int r, int g, int b)\n \tCallDriver_4(sp, td_initcolor, color, r, g, b);\n #else\n \tNCURSES_PUTP2(\"initialize_color\",\n-\t\t      TPARM_4(initialize_color, color, r, g, b));\n+\t\t      TIPARM_4(initialize_color, color, r, g, b));\n #endif\n \tsp->_color_defs = max(color + 1, sp->_color_defs);\n \n@@ -1004,7 +1003,7 @@ NCURSES_SP_NAME(_nc_do_color) (NCURSES_SP_DCLx\n \tif (set_color_pair) {\n \t    TPUTS_TRACE(\"set_color_pair\");\n \t    NCURSES_SP_NAME(tputs) (NCURSES_SP_ARGx\n-\t\t\t\t    TPARM_1(set_color_pair, pair),\n+\t\t\t\t    TIPARM_1(set_color_pair, pair),\n \t\t\t\t    1, outc);\n \t    return;\n \t} else if (SP_PARM != 0) {\ndiff --git a/ncurses/base/lib_mouse.c b/ncurses/base/lib_mouse.c\nindex 887f1ab5c..6422b52e0 100644\n--- a/ncurses/base/lib_mouse.c\n+++ b/ncurses/base/lib_mouse.c\n@@ -85,7 +85,7 @@\n #define CUR SP_TERMTYPE\n #endif\n \n-MODULE_ID(\"$Id: lib_mouse.c,v 1.188 2020/05/23 23:35:35 tom Exp $\")\n+MODULE_ID(\"$Id: lib_mouse.c,v 1.190 2020/05/27 23:55:32 tom Exp $\")\n \n #include <tic.h>\n \n@@ -436,7 +436,7 @@ enable_xterm_mouse(SCREEN *sp, int enable)\n #if USE_EMX_MOUSE\n     sp->_emxmouse_activated = enable;\n #else\n-    NCURSES_PUTP2(\"xterm-mouse\", TPARM_1(sp->_mouse_xtermcap, enable));\n+    NCURSES_PUTP2(\"xterm-mouse\", TIPARM_1(sp->_mouse_xtermcap, enable));\n #endif\n     sp->_mouse_active = enable;\n }\ndiff --git a/ncurses/base/lib_screen.c b/ncurses/base/lib_screen.c\nindex d306e1e86..6afba6611 100644\n--- a/ncurses/base/lib_screen.c\n+++ b/ncurses/base/lib_screen.c\n@@ -42,7 +42,7 @@\n #define CUR SP_TERMTYPE\n #endif\n \n-MODULE_ID(\"$Id: lib_screen.c,v 1.99 2020/05/23 19:12:01 tom Exp $\")\n+MODULE_ID(\"$Id: lib_screen.c,v 1.100 2020/05/25 22:48:41 tom Exp $\")\n \n #define MAX_SIZE 0x3fff\t\t/* 16k is big enough for a window or pad */\n \n@@ -58,7 +58,7 @@ MODULE_ID(\"$Id: lib_screen.c,v 1.99 2020/05/23 19:12:01 tom Exp $\")\n #define ARG_SLIMIT(name)\t/* nothing */\n #endif\n \n-#define CUR_SLIMIT _nc_SLIMIT(limit - (target - base))\n+#define CUR_SLIMIT _nc_SLIMIT(limit - (size_t) (target - base))\n #define TOP_SLIMIT _nc_SLIMIT(sizeof(buffer))\n \n /*\ndiff --git a/ncurses/tinfo/captoinfo.c b/ncurses/tinfo/captoinfo.c\nindex 8b3b83d18..9362105ab 100644\n--- a/ncurses/tinfo/captoinfo.c\n+++ b/ncurses/tinfo/captoinfo.c\n@@ -98,7 +98,7 @@\n #include <ctype.h>\n #include <tic.h>\n \n-MODULE_ID(\"$Id: captoinfo.c,v 1.98 2020/02/02 23:34:34 tom Exp $\")\n+MODULE_ID(\"$Id: captoinfo.c,v 1.99 2020/05/25 21:28:29 tom Exp $\")\n \n #if 0\n #define DEBUG_THIS(p) DEBUG(9, p)\n@@ -216,12 +216,15 @@ cvtchar(register const char *sp)\n \t}\n \tbreak;\n     case '^':\n+\tlen = 2;\n \tc = UChar(*++sp);\n-\tif (c == '?')\n+\tif (c == '?') {\n \t    c = 127;\n-\telse\n+\t} else if (c == '\\0') {\n+\t    len = 1;\n+\t} else {\n \t    c &= 0x1f;\n-\tlen = 2;\n+\t}\n \tbreak;\n     default:\n \tc = UChar(*sp);\ndiff --git a/ncurses/tinfo/lib_print.c b/ncurses/tinfo/lib_print.c\nindex eb9214925..25e45170b 100644\n--- a/ncurses/tinfo/lib_print.c\n+++ b/ncurses/tinfo/lib_print.c\n@@ -40,7 +40,7 @@\n #define CUR SP_TERMTYPE\n #endif\n \n-MODULE_ID(\"$Id: lib_print.c,v 1.25 2020/02/02 23:34:34 tom Exp $\")\n+MODULE_ID(\"$Id: lib_print.c,v 1.27 2020/05/27 23:55:56 tom Exp $\")\n \n NCURSES_EXPORT(int)\n NCURSES_SP_NAME(mcprint) (NCURSES_SP_DCLx char *data, int len)\n@@ -60,7 +60,7 @@ NCURSES_SP_NAME(mcprint) (NCURSES_SP_DCLx char *data, int len)\n     }\n \n     if (prtr_non) {\n-\tswitchon = TPARM_1(prtr_non, len);\n+\tswitchon = TIPARM_1(prtr_non, len);\n \tonsize = strlen(switchon);\n \toffsize = 0;\n     } else {\ndiff --git a/ncurses/tinfo/lib_tgoto.c b/ncurses/tinfo/lib_tgoto.c\nindex 8e240856f..9cf5e100c 100644\n--- a/ncurses/tinfo/lib_tgoto.c\n+++ b/ncurses/tinfo/lib_tgoto.c\n@@ -36,7 +36,7 @@\n #include <ctype.h>\n #include <termcap.h>\n \n-MODULE_ID(\"$Id: lib_tgoto.c,v 1.19 2020/02/02 23:34:34 tom Exp $\")\n+MODULE_ID(\"$Id: lib_tgoto.c,v 1.21 2020/05/27 23:55:56 tom Exp $\")\n \n #if !PURE_TERMINFO\n static bool\n@@ -207,6 +207,6 @@ tgoto(const char *string, int x, int y)\n \tresult = tgoto_internal(string, x, y);\n     else\n #endif\n-\tresult = TPARM_2(string, y, x);\n+\tresult = TIPARM_2(string, y, x);\n     returnPtr(result);\n }\ndiff --git a/ncurses/tinfo/lib_tparm.c b/ncurses/tinfo/lib_tparm.c\nindex 400cd3199..00380151f 100644\n--- a/ncurses/tinfo/lib_tparm.c\n+++ b/ncurses/tinfo/lib_tparm.c\n@@ -38,12 +38,22 @@\n  *\n  */\n \n+#define entry _ncu_entry\n+#define ENTRY _ncu_ENTRY\n+\n #include <curses.priv.h>\n \n+#undef entry\n+#undef ENTRY\n+\n+#if HAVE_TSEARCH\n+#include <search.h>\n+#endif\n+\n #include <ctype.h>\n #include <tic.h>\n \n-MODULE_ID(\"$Id: lib_tparm.c,v 1.108 2020/02/02 23:34:34 tom Exp $\")\n+MODULE_ID(\"$Id: lib_tparm.c,v 1.126 2020/05/31 00:02:03 tom Exp $\")\n \n /*\n  *\tchar *\n@@ -110,17 +120,81 @@ NCURSES_EXPORT_VAR(int) _nc_tparm_err = 0;\n #define TPS(var) _nc_prescreen.tparm_state.var\n #define popcount _nc_popcount\t/* workaround for NetBSD 6.0 defect */\n \n+#define isUPPER(c) ((c) >= 'A' && (c) <= 'Z')\n+#define isLOWER(c) ((c) >= 'a' && (c) <= 'z')\n+#define tc_BUMP()  if (level < 0 && number < 2) number++\n+\n+typedef struct {\n+    const char *format;\t\t/* format-string can be used as cache-key */\n+    int tparm_type;\t\t/* bit-set for each string-parameter */\n+    int num_actual;\n+    int num_parsed;\n+    int num_popped;\n+    TPARM_ARG param[NUM_PARM];\n+    char *p_is_s[NUM_PARM];\n+} TPARM_DATA;\n+\n+#if HAVE_TSEARCH\n+static void *cached_tparm;\n+static int count_tparm;\n+#if NO_LEAKS\n+static int which_tparm;\n+static TPARM_DATA **delete_tparm;\n+#endif\n+#endif /* HAVE_TSEARCH */\n+\n+static char dummy[] = \"\";\t/* avoid const-cast */\n+\n+#if HAVE_TSEARCH\n+static int\n+cmp_format(const void *p, const void *q)\n+{\n+    const char *a = *(char *const *) p;\n+    const char *b = *(char *const *) q;\n+    return strcmp(a, b);\n+}\n+#endif\n+\n #if NO_LEAKS\n+#if HAVE_TSEARCH\n+static void\n+visit_nodes(const void *nodep, const VISIT which, const int depth)\n+{\n+    (void) depth;\n+    if (which == preorder || which == leaf) {\n+\tdelete_tparm[which_tparm] = *(TPARM_DATA **) nodep;\n+\twhich_tparm++;\n+    }\n+}\n+#endif\n+\n NCURSES_EXPORT(void)\n _nc_free_tparm(void)\n {\n-    if (TPS(out_buff) != 0) {\n-\tFreeAndNull(TPS(out_buff));\n-\tTPS(out_size) = 0;\n-\tTPS(out_used) = 0;\n-\tFreeAndNull(TPS(fmt_buff));\n-\tTPS(fmt_size) = 0;\n+#if HAVE_TSEARCH\n+    if (count_tparm != 0) {\n+\tdelete_tparm = typeMalloc(TPARM_DATA *, count_tparm);\n+\twhich_tparm = 0;\n+\ttwalk(cached_tparm, visit_nodes);\n+\tfor (which_tparm = 0; which_tparm < count_tparm; ++which_tparm) {\n+\t    TPARM_DATA *ptr = delete_tparm[which_tparm];\n+\t    tdelete(ptr, &cached_tparm, cmp_format);\n+\t    free((char *) ptr->format);\n+\t    free(ptr);\n+\t}\n+\twhich_tparm = 0;\n+\ttwalk(cached_tparm, visit_nodes);\n+\tFreeAndNull(delete_tparm);\n+\tcount_tparm = 0;\n+\twhich_tparm = 0;\n     }\n+#endif\n+    FreeAndNull(TPS(out_buff));\n+    TPS(out_size) = 0;\n+    TPS(out_used) = 0;\n+\n+    FreeAndNull(TPS(fmt_buff));\n+    TPS(fmt_size) = 0;\n }\n #endif\n \n@@ -137,10 +211,7 @@ get_space(size_t need)\n static NCURSES_INLINE void\n save_text(const char *fmt, const char *s, int len)\n {\n-    size_t s_len = strlen(s);\n-    if (len > (int) s_len)\n-\ts_len = (size_t) len;\n-\n+    size_t s_len = (size_t) len + strlen(s) + strlen(fmt);\n     get_space(s_len + 1);\n \n     _nc_SPRINTF(TPS(out_buff) + TPS(out_used),\n@@ -152,10 +223,8 @@ save_text(const char *fmt, const char *s, int len)\n static NCURSES_INLINE void\n save_number(const char *fmt, int number, int len)\n {\n-    if (len < 30)\n-\tlen = 30;\t\t/* actually log10(MAX_INT)+1 */\n-\n-    get_space((size_t) len + 1);\n+    size_t s_len = (size_t) len + 30 + strlen(fmt);\n+    get_space(s_len + 1);\n \n     _nc_SPRINTF(TPS(out_buff) + TPS(out_used),\n \t\t_nc_SLIMIT(TPS(out_size) - TPS(out_used))\n@@ -216,7 +285,6 @@ spush(char *x)\n static NCURSES_INLINE char *\n spop(void)\n {\n-    static char dummy[] = \"\";\t/* avoid const-cast */\n     char *result = dummy;\n     if (TPS(stack_ptr) > 0) {\n \tTPS(stack_ptr)--;\n@@ -325,10 +393,6 @@ parse_format(const char *s, char *format, int *len)\n     return s;\n }\n \n-#define isUPPER(c) ((c) >= 'A' && (c) <= 'Z')\n-#define isLOWER(c) ((c) >= 'a' && (c) <= 'z')\n-#define tc_BUMP()  if (level < 0 && number < 2) number++\n-\n /*\n  * Analyze the string to see how many parameters we need from the varargs list,\n  * and what their types are.  We will only accept string parameters if they\n@@ -350,7 +414,6 @@ _nc_tparm_analyze(const char *string, char *p_is_s[NUM_PARM], int *popcount)\n     int number = 0;\n     int level = -1;\n     const char *cp = string;\n-    static char dummy[] = \"\";\n \n     if (cp == 0)\n \treturn 0;\n@@ -469,106 +532,179 @@ _nc_tparm_analyze(const char *string, char *p_is_s[NUM_PARM], int *popcount)\n     return number;\n }\n \n-static NCURSES_INLINE char *\n-tparam_internal(int use_TPARM_ARG, const char *string, va_list ap)\n+/*\n+ * Analyze the capability string, finding the number of parameters and their\n+ * types.\n+ *\n+ * TODO: cache the result so that this is done once per capability per term.\n+ */\n+static int\n+tparm_setup(const char *string, TPARM_DATA * result)\n {\n-    char *p_is_s[NUM_PARM];\n-    TPARM_ARG param[NUM_PARM];\n-    int popcount = 0;\n-    int number;\n-    int num_args;\n-    int len;\n-    int level;\n-    int x, y;\n-    int i;\n-    const char *cp = string;\n-    size_t len2;\n-    bool termcap_hack;\n-    bool incremented_two;\n+    int rc = OK;\n+\n+    TPS(out_used) = 0;\n+    memset(result, 0, sizeof(*result));\n \n-    if (cp == NULL) {\n+    if (string == NULL) {\n \tTR(TRACE_CALLS, (\"%s: format is null\", TPS(tname)));\n-\treturn NULL;\n-    }\n+\trc = ERR;\n+    } else {\n+#if HAVE_TSEARCH\n+\tTPARM_DATA *fs;\n+\tvoid *ft;\n+\n+\tresult->format = string;\n+\tif ((ft = tfind(result, &cached_tparm, cmp_format)) != 0) {\n+\t    fs = *(TPARM_DATA **) ft;\n+\t    *result = *fs;\n+\t} else\n+#endif\n+\t{\n+\t    /*\n+\t     * Find the highest parameter-number referred to in the format\n+\t     * string.  Use this value to limit the number of arguments copied\n+\t     * from the variable-length argument list.\n+\t     */\n+\t    result->num_parsed = _nc_tparm_analyze(string,\n+\t\t\t\t\t\t   result->p_is_s,\n+\t\t\t\t\t\t   &(result->num_popped));\n+\t    if (TPS(fmt_buff) == 0) {\n+\t\tTR(TRACE_CALLS, (\"%s: error in analysis\", TPS(tname)));\n+\t\trc = ERR;\n+\t    } else {\n+\t\tint n;\n \n-    TPS(out_used) = 0;\n-    len2 = strlen(cp);\n-\n-    /*\n-     * Find the highest parameter-number referred to in the format string.\n-     * Use this value to limit the number of arguments copied from the\n-     * variable-length argument list.\n-     */\n-    number = _nc_tparm_analyze(cp, p_is_s, &popcount);\n-    if (TPS(fmt_buff) == 0) {\n-\tTR(TRACE_CALLS, (\"%s: error in analysis\", TPS(tname)));\n-\treturn NULL;\n+\t\tif (result->num_parsed > NUM_PARM)\n+\t\t    result->num_parsed = NUM_PARM;\n+\t\tif (result->num_popped > NUM_PARM)\n+\t\t    result->num_popped = NUM_PARM;\n+\t\tresult->num_actual = max(result->num_popped, result->num_parsed);\n+\n+\t\tfor (n = 0; n < result->num_actual; ++n) {\n+\t\t    if (result->p_is_s[n])\n+\t\t\tresult->tparm_type |= (1 << n);\n+\t\t}\n+#if HAVE_TSEARCH\n+\t\tif ((fs = typeCalloc(TPARM_DATA, 1)) != 0) {\n+\t\t    *fs = *result;\n+\t\t    if ((fs->format = strdup(string)) != 0) {\n+\t\t\tif ((ft = tsearch(fs, &cached_tparm, cmp_format)) != 0) {\n+\t\t\t    ++count_tparm;\n+\t\t\t} else {\n+\t\t\t    rc = ERR;\n+\t\t\t}\n+\t\t    } else {\n+\t\t\trc = ERR;\n+\t\t    }\n+\t\t} else {\n+\t\t    rc = ERR;\n+\t\t}\n+#endif\n+\t    }\n+\t}\n     }\n \n-    incremented_two = FALSE;\n+    return rc;\n+}\n \n-    if (number > NUM_PARM)\n-\tnumber = NUM_PARM;\n-    if (popcount > NUM_PARM)\n-\tpopcount = NUM_PARM;\n-    num_args = max(popcount, number);\n+/*\n+ * A few caps (such as plab_norm) have string-valued parms.  We'll have to\n+ * assume that the caller knows the difference, since a char* and an int may\n+ * not be the same size on the stack.  The normal prototype for tparm uses 9\n+ * long's, which is consistent with our va_arg() usage.\n+ */\n+static void\n+tparm_copy_valist(TPARM_DATA * data, int use_TPARM_ARG, va_list ap)\n+{\n+    int i;\n \n-    for (i = 0; i < num_args; i++) {\n-\t/*\n-\t * A few caps (such as plab_norm) have string-valued parms.\n-\t * We'll have to assume that the caller knows the difference, since\n-\t * a char* and an int may not be the same size on the stack.  The\n-\t * normal prototype for this uses 9 long's, which is consistent with\n-\t * our va_arg() usage.\n-\t */\n-\tif (p_is_s[i] != 0) {\n-\t    p_is_s[i] = va_arg(ap, char *);\n-\t    param[i] = 0;\n+    for (i = 0; i < data->num_actual; i++) {\n+\tif (data->p_is_s[i] != 0) {\n+\t    char *value = va_arg(ap, char *);\n+\t    if (value == 0)\n+\t\tvalue = dummy;\n+\t    data->p_is_s[i] = value;\n+\t    data->param[i] = 0;\n \t} else if (use_TPARM_ARG) {\n-\t    param[i] = va_arg(ap, TPARM_ARG);\n+\t    data->param[i] = va_arg(ap, TPARM_ARG);\n \t} else {\n-\t    param[i] = (TPARM_ARG) va_arg(ap, int);\n+\t    data->param[i] = (TPARM_ARG) va_arg(ap, int);\n \t}\n     }\n+}\n+\n+/*\n+ * This is a termcap compatibility hack.  If there are no explicit pop\n+ * operations in the string, load the stack in such a way that successive pops\n+ * will grab successive parameters.  That will make the expansion of (for\n+ * example) \\E[%d;%dH work correctly in termcap style, which means tparam()\n+ * will expand termcap strings OK.\n+ */\n+static bool\n+tparm_tc_compat(TPARM_DATA * data)\n+{\n+    bool termcap_hack = FALSE;\n \n-    /*\n-     * This is a termcap compatibility hack.  If there are no explicit pop\n-     * operations in the string, load the stack in such a way that\n-     * successive pops will grab successive parameters.  That will make\n-     * the expansion of (for example) \\E[%d;%dH work correctly in termcap\n-     * style, which means tparam() will expand termcap strings OK.\n-     */\n     TPS(stack_ptr) = 0;\n-    termcap_hack = FALSE;\n-    if (popcount == 0) {\n+\n+    if (data->num_popped == 0) {\n+\tint i;\n+\n \ttermcap_hack = TRUE;\n-\tfor (i = number - 1; i >= 0; i--) {\n-\t    if (p_is_s[i])\n-\t\tspush(p_is_s[i]);\n+\tfor (i = data->num_parsed - 1; i >= 0; i--) {\n+\t    if (data->p_is_s[i])\n+\t\tspush(data->p_is_s[i]);\n \t    else\n-\t\tnpush((int) param[i]);\n+\t\tnpush((int) data->param[i]);\n \t}\n     }\n+    return termcap_hack;\n+}\n+\n #ifdef TRACE\n+static void\n+tparm_trace_call(const char *string, TPARM_DATA * data)\n+{\n     if (USE_TRACEF(TRACE_CALLS)) {\n-\tfor (i = 0; i < num_args; i++) {\n-\t    if (p_is_s[i] != 0) {\n-\t\tsave_text(\", %s\", _nc_visbuf(p_is_s[i]), 0);\n-\t    } else if ((long) param[i] > MAX_OF_TYPE(NCURSES_INT2) ||\n-\t\t       (long) param[i] < 0) {\n+\tint i;\n+\tfor (i = 0; i < data->num_actual; i++) {\n+\t    if (data->p_is_s[i] != 0) {\n+\t\tsave_text(\", %s\", _nc_visbuf(data->p_is_s[i]), 0);\n+\t    } else if ((long) data->param[i] > MAX_OF_TYPE(NCURSES_INT2) ||\n+\t\t       (long) data->param[i] < 0) {\n \t\t_tracef(\"BUG: problem with tparm parameter #%d of %d\",\n-\t\t\ti + 1, num_args);\n+\t\t\ti + 1, data->num_actual);\n \t\tbreak;\n \t    } else {\n-\t\tsave_number(\", %d\", (int) param[i], 0);\n+\t\tsave_number(\", %d\", (int) data->param[i], 0);\n \t    }\n \t}\n-\t_tracef(T_CALLED(\"%s(%s%s)\"), TPS(tname), _nc_visbuf(cp), TPS(out_buff));\n+\t_tracef(T_CALLED(\"%s(%s%s)\"), TPS(tname), _nc_visbuf(string), TPS(out_buff));\n \tTPS(out_used) = 0;\n \t_nc_unlock_global(tracef);\n     }\n+}\n+\n+#else\n+#define tparm_trace_call(string, data)\t/* nothing */\n #endif /* TRACE */\n \n+static NCURSES_INLINE char *\n+tparam_internal(const char *string, TPARM_DATA * data)\n+{\n+    int number;\n+    int len;\n+    int level;\n+    int x, y;\n+    int i;\n+    const char *cp = string;\n+    size_t len2 = strlen(cp);\n+    bool incremented_two = FALSE;\n+    bool termcap_hack = tparm_tc_compat(data);\n+\n+    tparm_trace_call(string, data);\n+\n     while ((cp - string) < (int) len2) {\n \tif (*cp != '%') {\n \t    save_char(UChar(*cp));\n@@ -619,10 +755,10 @@ tparam_internal(int use_TPARM_ARG, const char *string, va_list ap)\n \t\tcp++;\n \t\ti = (UChar(*cp) - '1');\n \t\tif (i >= 0 && i < NUM_PARM) {\n-\t\t    if (p_is_s[i]) {\n-\t\t\tspush(p_is_s[i]);\n+\t\t    if (data->p_is_s[i]) {\n+\t\t\tspush(data->p_is_s[i]);\n \t\t    } else {\n-\t\t\tnpush((int) param[i]);\n+\t\t\tnpush((int) data->param[i]);\n \t\t    }\n \t\t}\n \t\tbreak;\n@@ -751,15 +887,15 @@ tparam_internal(int use_TPARM_ARG, const char *string, va_list ap)\n \t\t */\n \t\tif (!incremented_two) {\n \t\t    incremented_two = TRUE;\n-\t\t    if (p_is_s[0] == 0) {\n-\t\t\tparam[0]++;\n+\t\t    if (data->p_is_s[0] == 0) {\n+\t\t\tdata->param[0]++;\n \t\t\tif (termcap_hack)\n-\t\t\t    TPS(stack)[0].data.num = (int) param[0];\n+\t\t\t    TPS(stack)[0].data.num = (int) data->param[0];\n \t\t    }\n-\t\t    if (p_is_s[1] == 0) {\n-\t\t\tparam[1]++;\n+\t\t    if (data->p_is_s[1] == 0) {\n+\t\t\tdata->param[1]++;\n \t\t\tif (termcap_hack)\n-\t\t\t    TPS(stack)[1].data.num = (int) param[1];\n+\t\t\t    TPS(stack)[1].data.num = (int) data->param[1];\n \t\t    }\n \t\t}\n \t\tbreak;\n@@ -835,56 +971,118 @@ tparam_internal(int use_TPARM_ARG, const char *string, va_list ap)\n }\n \n #if NCURSES_TPARM_VARARGS\n-#define tparm_varargs tparm\n-#else\n-#define tparm_proto tparm\n-#endif\n \n NCURSES_EXPORT(char *)\n-tparm_varargs(const char *string, ...)\n+tparm(const char *string, ...)\n {\n+    TPARM_DATA myData;\n     va_list ap;\n-    char *result;\n+    char *result = NULL;\n \n     _nc_tparm_err = 0;\n-    va_start(ap, string);\n #ifdef TRACE\n     TPS(tname) = \"tparm\";\n #endif /* TRACE */\n-    result = tparam_internal(TRUE, string, ap);\n-    va_end(ap);\n+\n+    if (tparm_setup(string, &myData) == OK) {\n+\n+\tva_start(ap, string);\n+\ttparm_copy_valist(&myData, TRUE, ap);\n+\tva_end(ap);\n+\n+\tresult = tparam_internal(string, &myData);\n+    }\n     return result;\n }\n \n-#if !NCURSES_TPARM_VARARGS\n+#else /* !NCURSES_TPARM_VARARGS */\n+\n NCURSES_EXPORT(char *)\n-tparm_proto(const char *string,\n-\t    TPARM_ARG a1,\n-\t    TPARM_ARG a2,\n-\t    TPARM_ARG a3,\n-\t    TPARM_ARG a4,\n-\t    TPARM_ARG a5,\n-\t    TPARM_ARG a6,\n-\t    TPARM_ARG a7,\n-\t    TPARM_ARG a8,\n-\t    TPARM_ARG a9)\n+tparm(const char *string,\n+      TPARM_ARG a1,\n+      TPARM_ARG a2,\n+      TPARM_ARG a3,\n+      TPARM_ARG a4,\n+      TPARM_ARG a5,\n+      TPARM_ARG a6,\n+      TPARM_ARG a7,\n+      TPARM_ARG a8,\n+      TPARM_ARG a9)\n {\n-    return tparm_varargs(string, a1, a2, a3, a4, a5, a6, a7, a8, a9);\n+    TPARM_DATA myData;\n+    char *result = NULL;\n+\n+    _nc_tparm_err = 0;\n+#ifdef TRACE\n+    TPS(tname) = \"tparm\";\n+#endif /* TRACE */\n+\n+    if (tparm_setup(string, &myData) == OK) {\n+\n+\tmyData.param[0] = a1;\n+\tmyData.param[1] = a2;\n+\tmyData.param[2] = a3;\n+\tmyData.param[3] = a4;\n+\tmyData.param[4] = a5;\n+\tmyData.param[5] = a6;\n+\tmyData.param[6] = a7;\n+\tmyData.param[7] = a8;\n+\tmyData.param[8] = a9;\n+\n+\tresult = tparam_internal(string, &myData);\n+    }\n+    return result;\n }\n+\n #endif /* NCURSES_TPARM_VARARGS */\n \n NCURSES_EXPORT(char *)\n tiparm(const char *string, ...)\n {\n+    TPARM_DATA myData;\n     va_list ap;\n-    char *result;\n+    char *result = NULL;\n \n     _nc_tparm_err = 0;\n-    va_start(ap, string);\n #ifdef TRACE\n     TPS(tname) = \"tiparm\";\n #endif /* TRACE */\n-    result = tparam_internal(FALSE, string, ap);\n-    va_end(ap);\n+\n+    if (tparm_setup(string, &myData) == OK) {\n+\n+\tva_start(ap, string);\n+\ttparm_copy_valist(&myData, FALSE, ap);\n+\tva_end(ap);\n+\n+\tresult = tparam_internal(string, &myData);\n+    }\n+    return result;\n+}\n+\n+/*\n+ * The internal-use flavor ensures that the parameters are numbers, not strings\n+ */\n+NCURSES_EXPORT(char *)\n+_nc_tiparm(int expected, const char *string, ...)\n+{\n+    TPARM_DATA myData;\n+    va_list ap;\n+    char *result = NULL;\n+\n+    _nc_tparm_err = 0;\n+#ifdef TRACE\n+    TPS(tname) = \"_nc_tiparm\";\n+#endif /* TRACE */\n+\n+    if (tparm_setup(string, &myData) == OK\n+\t&& myData.num_actual <= expected\n+\t&& myData.tparm_type == 0) {\n+\n+\tva_start(ap, string);\n+\ttparm_copy_valist(&myData, FALSE, ap);\n+\tva_end(ap);\n+\n+\tresult = tparam_internal(string, &myData);\n+    }\n     return result;\n }\ndiff --git a/ncurses/tinfo/tinfo_driver.c b/ncurses/tinfo/tinfo_driver.c\nindex 7919a9b09..3089cf0aa 100644\n--- a/ncurses/tinfo/tinfo_driver.c\n+++ b/ncurses/tinfo/tinfo_driver.c\n@@ -52,7 +52,7 @@\n # endif\n #endif\n \n-MODULE_ID(\"$Id: tinfo_driver.c,v 1.67 2020/02/02 23:34:34 tom Exp $\")\n+MODULE_ID(\"$Id: tinfo_driver.c,v 1.69 2020/05/27 23:55:56 tom Exp $\")\n \n /*\n  * SCO defines TIOCGSIZE and the corresponding struct.  Other systems (SunOS,\n@@ -356,23 +356,23 @@ drv_setcolor(TERMINAL_CONTROL_BLOCK * TCB,\n \tif (set_a_foreground) {\n \t    TPUTS_TRACE(\"set_a_foreground\");\n \t    NCURSES_SP_NAME(tputs) (NCURSES_SP_ARGx\n-\t\t\t\t    TPARM_1(set_a_foreground, color), 1, outc);\n+\t\t\t\t    TIPARM_1(set_a_foreground, color), 1, outc);\n \t} else {\n \t    TPUTS_TRACE(\"set_foreground\");\n \t    NCURSES_SP_NAME(tputs) (NCURSES_SP_ARGx\n-\t\t\t\t    TPARM_1(set_foreground,\n-\t\t\t\t\t    toggled_colors(color)), 1, outc);\n+\t\t\t\t    TIPARM_1(set_foreground,\n+\t\t\t\t\t     toggled_colors(color)), 1, outc);\n \t}\n     } else {\n \tif (set_a_background) {\n \t    TPUTS_TRACE(\"set_a_background\");\n \t    NCURSES_SP_NAME(tputs) (NCURSES_SP_ARGx\n-\t\t\t\t    TPARM_1(set_a_background, color), 1, outc);\n+\t\t\t\t    TIPARM_1(set_a_background, color), 1, outc);\n \t} else {\n \t    TPUTS_TRACE(\"set_background\");\n \t    NCURSES_SP_NAME(tputs) (NCURSES_SP_ARGx\n-\t\t\t\t    TPARM_1(set_background,\n-\t\t\t\t\t    toggled_colors(color)), 1, outc);\n+\t\t\t\t    TIPARM_1(set_background,\n+\t\t\t\t\t     toggled_colors(color)), 1, outc);\n \t}\n     }\n }\n@@ -764,10 +764,10 @@ drv_initpair(TERMINAL_CONTROL_BLOCK * TCB, int pair, int f, int b)\n \t    tp[b].red, tp[b].green, tp[b].blue));\n \n \tNCURSES_PUTP2(\"initialize_pair\",\n-\t\t      TPARM_7(initialize_pair,\n-\t\t\t      pair,\n-\t\t\t      tp[f].red, tp[f].green, tp[f].blue,\n-\t\t\t      tp[b].red, tp[b].green, tp[b].blue));\n+\t\t      TIPARM_7(initialize_pair,\n+\t\t\t       pair,\n+\t\t\t       tp[f].red, tp[f].green, tp[f].blue,\n+\t\t\t       tp[b].red, tp[b].green, tp[b].blue));\n     }\n }\n \n@@ -800,7 +800,7 @@ drv_initcolor(TERMINAL_CONTROL_BLOCK * TCB,\n     AssertTCB();\n     if (initialize_color != NULL) {\n \tNCURSES_PUTP2(\"initialize_color\",\n-\t\t      TPARM_4(initialize_color, color, r, g, b));\n+\t\t      TIPARM_4(initialize_color, color, r, g, b));\n     }\n }\n \n@@ -826,7 +826,7 @@ drv_do_color(TERMINAL_CONTROL_BLOCK * TCB,\n \tif (set_color_pair) {\n \t    TPUTS_TRACE(\"set_color_pair\");\n \t    NCURSES_SP_NAME(tputs) (NCURSES_SP_ARGx\n-\t\t\t\t    TPARM_1(set_color_pair, pair), 1, outc);\n+\t\t\t\t    TIPARM_1(set_color_pair, pair), 1, outc);\n \t    return;\n \t} else if (sp != 0) {\n \t    _nc_pair_content(SP_PARM, pair, &fg, &bg);\ndiff --git a/ncurses/tinfo/trim_sgr0.c b/ncurses/tinfo/trim_sgr0.c\nindex 4d10529c0..30c8f75c1 100644\n--- a/ncurses/tinfo/trim_sgr0.c\n+++ b/ncurses/tinfo/trim_sgr0.c\n@@ -37,7 +37,7 @@\n \n #include <tic.h>\n \n-MODULE_ID(\"$Id: trim_sgr0.c,v 1.18 2020/02/02 23:34:34 tom Exp $\")\n+MODULE_ID(\"$Id: trim_sgr0.c,v 1.20 2020/05/27 23:54:31 tom Exp $\")\n \n #undef CUR\n #define CUR tp->\n@@ -52,7 +52,7 @@ set_attribute_9(TERMTYPE2 *tp, int flag)\n     const char *value;\n     char *result;\n \n-    value = tparm(set_attributes, 0, 0, 0, 0, 0, 0, 0, 0, flag);\n+    value = TIPARM_9(set_attributes, 0, 0, 0, 0, 0, 0, 0, 0, flag);\n     if (PRESENT(value))\n \tresult = strdup(value);\n     else\ndiff --git a/ncurses/trace/lib_trace.c b/ncurses/trace/lib_trace.c\nindex 2c10b51d0..28ce5196f 100644\n--- a/ncurses/trace/lib_trace.c\n+++ b/ncurses/trace/lib_trace.c\n@@ -48,7 +48,7 @@\n \n #include <ctype.h>\n \n-MODULE_ID(\"$Id: lib_trace.c,v 1.95 2020/02/02 23:34:34 tom Exp $\")\n+MODULE_ID(\"$Id: lib_trace.c,v 1.96 2020/05/25 22:48:18 tom Exp $\")\n \n NCURSES_EXPORT_VAR(unsigned) _nc_tracing = 0; /* always define this */\n \n@@ -349,7 +349,7 @@ _nc_fmt_funcptr(char *target, const char *source, size_t size)\n \tif (ch != 0 || (n + 1) >= size)\n \t    leading = FALSE;\n \tif (!leading) {\n-\t    _nc_SPRINTF(dst, _nc_SLIMIT(TR_FUNC_LEN - (dst - target))\n+\t    _nc_SPRINTF(dst, _nc_SLIMIT(TR_FUNC_LEN - (size_t) (dst - target))\n \t\t\t\"%02x\", ch & 0xff);\n \t    dst += 2;\n \t}\ndiff --git a/ncurses/tty/hashmap.c b/ncurses/tty/hashmap.c\nindex 9d1e482b0..3f124c96c 100644\n--- a/ncurses/tty/hashmap.c\n+++ b/ncurses/tty/hashmap.c\n@@ -74,7 +74,7 @@ AUTHOR\n #define CUR SP_TERMTYPE\n #endif\n \n-MODULE_ID(\"$Id: hashmap.c,v 1.68 2020/02/02 23:34:34 tom Exp $\")\n+MODULE_ID(\"$Id: hashmap.c,v 1.69 2020/05/31 17:50:48 tom Exp $\")\n \n #ifdef HASHDEBUG\n \n@@ -88,7 +88,7 @@ MODULE_ID(\"$Id: hashmap.c,v 1.68 2020/02/02 23:34:34 tom Exp $\")\n # undef screen_lines\n # define screen_lines(sp) MAXLINES\n # define TEXTWIDTH(sp)\t1\n-int oldnums[MAXLINES], reallines[MAXLINES];\n+static int oldnums[MAXLINES], reallines[MAXLINES];\n static NCURSES_CH_T oldtext[MAXLINES][TEXTWIDTH(sp)];\n static NCURSES_CH_T newtext[MAXLINES][TEXTWIDTH(sp)];\n # define OLDNUM(sp,n)\toldnums[n]\ndiff --git a/ncurses/tty/lib_mvcur.c b/ncurses/tty/lib_mvcur.c\nindex 5382b3bfe..86e2fb183 100644\n--- a/ncurses/tty/lib_mvcur.c\n+++ b/ncurses/tty/lib_mvcur.c\n@@ -160,7 +160,7 @@\n #define CUR SP_TERMTYPE\n #endif\n \n-MODULE_ID(\"$Id: lib_mvcur.c,v 1.151 2020/02/02 23:34:34 tom Exp $\")\n+MODULE_ID(\"$Id: lib_mvcur.c,v 1.153 2020/05/27 23:56:32 tom Exp $\")\n \n #define WANT_CHAR(sp, y, x) NewScreen(sp)->_line[y].text[x]\t/* desired state */\n \n@@ -279,8 +279,8 @@ reset_scroll_region(NCURSES_SP_DCL0)\n {\n     if (change_scroll_region) {\n \tNCURSES_PUTP2(\"change_scroll_region\",\n-\t\t      TPARM_2(change_scroll_region,\n-\t\t\t      0, screen_lines(SP_PARM) - 1));\n+\t\t      TIPARM_2(change_scroll_region,\n+\t\t\t       0, screen_lines(SP_PARM) - 1));\n     }\n }\n \n@@ -399,13 +399,13 @@ NCURSES_SP_NAME(_nc_mvcur_init) (NCURSES_SP_DCL0)\n      * All these averages depend on the assumption that all parameter values\n      * are equally probable.\n      */\n-    SP_PARM->_cup_cost = CostOf(TPARM_2(SP_PARM->_address_cursor, 23, 23), 1);\n-    SP_PARM->_cub_cost = CostOf(TPARM_1(parm_left_cursor, 23), 1);\n-    SP_PARM->_cuf_cost = CostOf(TPARM_1(parm_right_cursor, 23), 1);\n-    SP_PARM->_cud_cost = CostOf(TPARM_1(parm_down_cursor, 23), 1);\n-    SP_PARM->_cuu_cost = CostOf(TPARM_1(parm_up_cursor, 23), 1);\n-    SP_PARM->_hpa_cost = CostOf(TPARM_1(column_address, 23), 1);\n-    SP_PARM->_vpa_cost = CostOf(TPARM_1(row_address, 23), 1);\n+    SP_PARM->_cup_cost = CostOf(TIPARM_2(SP_PARM->_address_cursor, 23, 23), 1);\n+    SP_PARM->_cub_cost = CostOf(TIPARM_1(parm_left_cursor, 23), 1);\n+    SP_PARM->_cuf_cost = CostOf(TIPARM_1(parm_right_cursor, 23), 1);\n+    SP_PARM->_cud_cost = CostOf(TIPARM_1(parm_down_cursor, 23), 1);\n+    SP_PARM->_cuu_cost = CostOf(TIPARM_1(parm_up_cursor, 23), 1);\n+    SP_PARM->_hpa_cost = CostOf(TIPARM_1(column_address, 23), 1);\n+    SP_PARM->_vpa_cost = CostOf(TIPARM_1(row_address, 23), 1);\n \n     /* non-parameterized screen-update strings */\n     SP_PARM->_ed_cost = NormalizedCost(clr_eos, 1);\n@@ -422,17 +422,16 @@ NCURSES_SP_NAME(_nc_mvcur_init) (NCURSES_SP_DCL0)\n \tSP_PARM->_el_cost = 0;\n \n     /* parameterized screen-update strings */\n-    SP_PARM->_dch_cost = NormalizedCost(TPARM_1(parm_dch, 23), 1);\n-    SP_PARM->_ich_cost = NormalizedCost(TPARM_1(parm_ich, 23), 1);\n-    SP_PARM->_ech_cost = NormalizedCost(TPARM_1(erase_chars, 23), 1);\n-    SP_PARM->_rep_cost = NormalizedCost(TPARM_2(repeat_char, ' ', 23), 1);\n-\n-    SP_PARM->_cup_ch_cost = NormalizedCost(\n-\t\t\t\t\t      TPARM_2(SP_PARM->_address_cursor,\n-\t\t\t\t\t\t      23, 23),\n-\t\t\t\t\t      1);\n-    SP_PARM->_hpa_ch_cost = NormalizedCost(TPARM_1(column_address, 23), 1);\n-    SP_PARM->_cuf_ch_cost = NormalizedCost(TPARM_1(parm_right_cursor, 23), 1);\n+    SP_PARM->_dch_cost = NormalizedCost(TIPARM_1(parm_dch, 23), 1);\n+    SP_PARM->_ich_cost = NormalizedCost(TIPARM_1(parm_ich, 23), 1);\n+    SP_PARM->_ech_cost = NormalizedCost(TIPARM_1(erase_chars, 23), 1);\n+    SP_PARM->_rep_cost = NormalizedCost(TIPARM_2(repeat_char, ' ', 23), 1);\n+\n+    SP_PARM->_cup_ch_cost = NormalizedCost(TIPARM_2(SP_PARM->_address_cursor,\n+\t\t\t\t\t\t    23, 23),\n+\t\t\t\t\t   1);\n+    SP_PARM->_hpa_ch_cost = NormalizedCost(TIPARM_1(column_address, 23), 1);\n+    SP_PARM->_cuf_ch_cost = NormalizedCost(TIPARM_1(parm_right_cursor, 23), 1);\n     SP_PARM->_inline_cost = min(SP_PARM->_cup_ch_cost,\n \t\t\t\tmin(SP_PARM->_hpa_ch_cost,\n \t\t\t\t    SP_PARM->_cuf_ch_cost));\n@@ -563,7 +562,7 @@ relative_move(NCURSES_SP_DCLx\n \tvcost = INFINITY;\n \n \tif (row_address != 0\n-\t    && _nc_safe_strcat(target, TPARM_1(row_address, to_y))) {\n+\t    && _nc_safe_strcat(target, TIPARM_1(row_address, to_y))) {\n \t    vcost = SP_PARM->_vpa_cost;\n \t}\n \n@@ -573,7 +572,7 @@ relative_move(NCURSES_SP_DCLx\n \t    if (parm_down_cursor\n \t\t&& SP_PARM->_cud_cost < vcost\n \t\t&& _nc_safe_strcat(_nc_str_copy(target, &save),\n-\t\t\t\t   TPARM_1(parm_down_cursor, n))) {\n+\t\t\t\t   TIPARM_1(parm_down_cursor, n))) {\n \t\tvcost = SP_PARM->_cud_cost;\n \t    }\n \n@@ -589,7 +588,7 @@ relative_move(NCURSES_SP_DCLx\n \t    if (parm_up_cursor\n \t\t&& SP_PARM->_cuu_cost < vcost\n \t\t&& _nc_safe_strcat(_nc_str_copy(target, &save),\n-\t\t\t\t   TPARM_1(parm_up_cursor, n))) {\n+\t\t\t\t   TIPARM_1(parm_up_cursor, n))) {\n \t\tvcost = SP_PARM->_cuu_cost;\n \t    }\n \n@@ -613,7 +612,7 @@ relative_move(NCURSES_SP_DCLx\n \n \tif (column_address\n \t    && _nc_safe_strcat(_nc_str_copy(target, &save),\n-\t\t\t       TPARM_1(column_address, to_x))) {\n+\t\t\t       TIPARM_1(column_address, to_x))) {\n \t    hcost = SP_PARM->_hpa_cost;\n \t}\n \n@@ -623,7 +622,7 @@ relative_move(NCURSES_SP_DCLx\n \t    if (parm_right_cursor\n \t\t&& SP_PARM->_cuf_cost < hcost\n \t\t&& _nc_safe_strcat(_nc_str_copy(target, &save),\n-\t\t\t\t   TPARM_1(parm_right_cursor, n))) {\n+\t\t\t\t   TIPARM_1(parm_right_cursor, n))) {\n \t\thcost = SP_PARM->_cuf_cost;\n \t    }\n \n@@ -716,7 +715,7 @@ relative_move(NCURSES_SP_DCLx\n \t    if (parm_left_cursor\n \t\t&& SP_PARM->_cub_cost < hcost\n \t\t&& _nc_safe_strcat(_nc_str_copy(target, &save),\n-\t\t\t\t   TPARM_1(parm_left_cursor, n))) {\n+\t\t\t\t   TIPARM_1(parm_left_cursor, n))) {\n \t\thcost = SP_PARM->_cub_cost;\n \t    }\n \n@@ -793,7 +792,8 @@ onscreen_mvcur(NCURSES_SP_DCLx\n #define InitResult _nc_str_init(&result, buffer, sizeof(buffer))\n \n     /* tactic #0: use direct cursor addressing */\n-    if (_nc_safe_strcpy(InitResult, TPARM_2(SP_PARM->_address_cursor, ynew, xnew))) {\n+    if (_nc_safe_strcpy(InitResult, TIPARM_2(SP_PARM->_address_cursor,\n+\t\t\t\t\t     ynew, xnew))) {\n \ttactic = 0;\n \tusecost = SP_PARM->_cup_cost;\n \ndiff --git a/ncurses/tty/lib_vidattr.c b/ncurses/tty/lib_vidattr.c\nindex c752919bf..15e7397d5 100644\n--- a/ncurses/tty/lib_vidattr.c\n+++ b/ncurses/tty/lib_vidattr.c\n@@ -70,7 +70,7 @@\n #define CUR SP_TERMTYPE\n #endif\n \n-MODULE_ID(\"$Id: lib_vidattr.c,v 1.76 2020/02/02 23:34:34 tom Exp $\")\n+MODULE_ID(\"$Id: lib_vidattr.c,v 1.78 2020/05/27 23:56:32 tom Exp $\")\n \n #define doPut(mode) \\\n \tTPUTS_TRACE(#mode); \\\n@@ -258,16 +258,16 @@ NCURSES_SP_NAME(vidputs) (NCURSES_SP_DCLx\n \tif (turn_on || turn_off) {\n \t    TPUTS_TRACE(\"set_attributes\");\n \t    NCURSES_SP_NAME(tputs) (NCURSES_SP_ARGx\n-\t\t\t\t    tparm(set_attributes,\n-\t\t\t\t\t  (newmode & A_STANDOUT) != 0,\n-\t\t\t\t\t  (newmode & A_UNDERLINE) != 0,\n-\t\t\t\t\t  (newmode & A_REVERSE) != 0,\n-\t\t\t\t\t  (newmode & A_BLINK) != 0,\n-\t\t\t\t\t  (newmode & A_DIM) != 0,\n-\t\t\t\t\t  (newmode & A_BOLD) != 0,\n-\t\t\t\t\t  (newmode & A_INVIS) != 0,\n-\t\t\t\t\t  (newmode & A_PROTECT) != 0,\n-\t\t\t\t\t  (newmode & A_ALTCHARSET) != 0),\n+\t\t\t\t    TIPARM_9(set_attributes,\n+\t\t\t\t\t     (newmode & A_STANDOUT) != 0,\n+\t\t\t\t\t     (newmode & A_UNDERLINE) != 0,\n+\t\t\t\t\t     (newmode & A_REVERSE) != 0,\n+\t\t\t\t\t     (newmode & A_BLINK) != 0,\n+\t\t\t\t\t     (newmode & A_DIM) != 0,\n+\t\t\t\t\t     (newmode & A_BOLD) != 0,\n+\t\t\t\t\t     (newmode & A_INVIS) != 0,\n+\t\t\t\t\t     (newmode & A_PROTECT) != 0,\n+\t\t\t\t\t     (newmode & A_ALTCHARSET) != 0),\n \t\t\t\t    1, outc);\n \t    PreviousAttr &= ALL_BUT_COLOR;\n \t}\ndiff --git a/ncurses/tty/tty_update.c b/ncurses/tty/tty_update.c\nindex d57f23f10..9691f8996 100644\n--- a/ncurses/tty/tty_update.c\n+++ b/ncurses/tty/tty_update.c\n@@ -85,7 +85,7 @@\n \n #include <ctype.h>\n \n-MODULE_ID(\"$Id: tty_update.c,v 1.307 2020/05/23 19:10:35 tom Exp $\")\n+MODULE_ID(\"$Id: tty_update.c,v 1.309 2020/05/27 23:56:32 tom Exp $\")\n \n /*\n  * This define controls the line-breakout optimization.  Every once in a\n@@ -170,9 +170,9 @@ position_check(NCURSES_SP_DCLx int expected_y, int expected_x, char *legend)\n \tif (y - 1 != expected_y || x - 1 != expected_x) {\n \t    NCURSES_SP_NAME(beep) (NCURSES_SP_ARG);\n \t    NCURSES_SP_NAME(tputs) (NCURSES_SP_ARGx\n-\t\t\t\t    tparm(\"\\033[%d;%dH\",\n-\t\t\t\t\t  expected_y + 1,\n-\t\t\t\t\t  expected_x + 1),\n+\t\t\t\t    TIPARM_2(\"\\033[%d;%dH\",\n+\t\t\t\t\t     expected_y + 1,\n+\t\t\t\t\t     expected_x + 1),\n \t\t\t\t    1, NCURSES_SP_NAME(_nc_outch));\n \t    _tracef(\"position seen (%d, %d) doesn't match expected one (%d, %d) in %s\",\n \t\t    y - 1, x - 1, expected_y, expected_x, legend);\n@@ -605,7 +605,7 @@ EmitRange(NCURSES_SP_DCLx const NCURSES_CH_T *ntext, int num)\n \t\t&& runcount > SP_PARM->_ech_cost + SP_PARM->_cup_ch_cost\n \t\t&& can_clear_with(NCURSES_SP_ARGx CHREF(ntext0))) {\n \t\tUpdateAttrs(SP_PARM, ntext0);\n-\t\tNCURSES_PUTP2(\"erase_chars\", TPARM_1(erase_chars, runcount));\n+\t\tNCURSES_PUTP2(\"erase_chars\", TIPARM_1(erase_chars, runcount));\n \n \t\t/*\n \t\t * If this is the last part of the given interval,\n@@ -648,9 +648,9 @@ EmitRange(NCURSES_SP_DCLx const NCURSES_CH_T *ntext, int num)\n \t\t\t    AttrOf(ntext0) | A_ALTCHARSET);\n \t\t}\n \t\tNCURSES_SP_NAME(tputs) (NCURSES_SP_ARGx\n-\t\t\t\t\tTPARM_2(repeat_char,\n-\t\t\t\t\t\tCharOf(temp),\n-\t\t\t\t\t\trep_count),\n+\t\t\t\t\tTIPARM_2(repeat_char,\n+\t\t\t\t\t\t CharOf(temp),\n+\t\t\t\t\t\t rep_count),\n \t\t\t\t\t1,\n \t\t\t\t\tNCURSES_SP_NAME(_nc_outch));\n \t\tSP_PARM->_curscol += rep_count;\n@@ -1716,7 +1716,7 @@ InsStr(NCURSES_SP_DCLx NCURSES_CH_T *line, int count)\n     if (parm_ich) {\n \tTPUTS_TRACE(\"parm_ich\");\n \tNCURSES_SP_NAME(tputs) (NCURSES_SP_ARGx\n-\t\t\t\tTPARM_1(parm_ich, count),\n+\t\t\t\tTIPARM_1(parm_ich, count),\n \t\t\t\t1,\n \t\t\t\tNCURSES_SP_NAME(_nc_outch));\n \twhile (count > 0) {\n@@ -1769,7 +1769,7 @@ DelChar(NCURSES_SP_DCLx int count)\n     if (parm_dch) {\n \tTPUTS_TRACE(\"parm_dch\");\n \tNCURSES_SP_NAME(tputs) (NCURSES_SP_ARGx\n-\t\t\t\tTPARM_1(parm_dch, count),\n+\t\t\t\tTIPARM_1(parm_dch, count),\n \t\t\t\t1,\n \t\t\t\tNCURSES_SP_NAME(_nc_outch));\n     } else {\n@@ -1838,7 +1838,7 @@ scroll_csr_forward(NCURSES_SP_DCLx\n \tUpdateAttrs(SP_PARM, blank);\n \tTPUTS_TRACE(\"parm_index\");\n \tNCURSES_SP_NAME(tputs) (NCURSES_SP_ARGx\n-\t\t\t\tTPARM_2(parm_index, n, 0),\n+\t\t\t\tTIPARM_1(parm_index, n),\n \t\t\t\tn,\n \t\t\t\tNCURSES_SP_NAME(_nc_outch));\n     } else if (parm_delete_line && bot == maxy) {\n@@ -1846,7 +1846,7 @@ scroll_csr_forward(NCURSES_SP_DCLx\n \tUpdateAttrs(SP_PARM, blank);\n \tTPUTS_TRACE(\"parm_delete_line\");\n \tNCURSES_SP_NAME(tputs) (NCURSES_SP_ARGx\n-\t\t\t\tTPARM_2(parm_delete_line, n, 0),\n+\t\t\t\tTIPARM_1(parm_delete_line, n),\n \t\t\t\tn,\n \t\t\t\tNCURSES_SP_NAME(_nc_outch));\n     } else if (scroll_forward && top == miny && bot == maxy) {\n@@ -1903,7 +1903,7 @@ scroll_csr_backward(NCURSES_SP_DCLx\n \tUpdateAttrs(SP_PARM, blank);\n \tTPUTS_TRACE(\"parm_rindex\");\n \tNCURSES_SP_NAME(tputs) (NCURSES_SP_ARGx\n-\t\t\t\tTPARM_2(parm_rindex, n, 0),\n+\t\t\t\tTIPARM_1(parm_rindex, n),\n \t\t\t\tn,\n \t\t\t\tNCURSES_SP_NAME(_nc_outch));\n     } else if (parm_insert_line && bot == maxy) {\n@@ -1911,7 +1911,7 @@ scroll_csr_backward(NCURSES_SP_DCLx\n \tUpdateAttrs(SP_PARM, blank);\n \tTPUTS_TRACE(\"parm_insert_line\");\n \tNCURSES_SP_NAME(tputs) (NCURSES_SP_ARGx\n-\t\t\t\tTPARM_2(parm_insert_line, n, 0),\n+\t\t\t\tTIPARM_1(parm_insert_line, n),\n \t\t\t\tn,\n \t\t\t\tNCURSES_SP_NAME(_nc_outch));\n     } else if (scroll_reverse && top == miny && bot == maxy) {\n@@ -1959,7 +1959,7 @@ scroll_idl(NCURSES_SP_DCLx int n, int del, int ins, NCURSES_CH_T blank)\n     } else if (parm_delete_line) {\n \tTPUTS_TRACE(\"parm_delete_line\");\n \tNCURSES_SP_NAME(tputs) (NCURSES_SP_ARGx\n-\t\t\t\tTPARM_2(parm_delete_line, n, 0),\n+\t\t\t\tTIPARM_1(parm_delete_line, n),\n \t\t\t\tn,\n \t\t\t\tNCURSES_SP_NAME(_nc_outch));\n     } else {\t\t\t/* if (delete_line) */\n@@ -1975,7 +1975,7 @@ scroll_idl(NCURSES_SP_DCLx int n, int del, int ins, NCURSES_CH_T blank)\n     } else if (parm_insert_line) {\n \tTPUTS_TRACE(\"parm_insert_line\");\n \tNCURSES_SP_NAME(tputs) (NCURSES_SP_ARGx\n-\t\t\t\tTPARM_2(parm_insert_line, n, 0),\n+\t\t\t\tTIPARM_1(parm_insert_line, n),\n \t\t\t\tn,\n \t\t\t\tNCURSES_SP_NAME(_nc_outch));\n     } else {\t\t\t/* if (insert_line) */\n@@ -2040,7 +2040,7 @@ NCURSES_SP_NAME(_nc_scrolln) (NCURSES_SP_DCLx\n \t\tNCURSES_PUTP2(\"save_cursor\", save_cursor);\n \t    }\n \t    NCURSES_PUTP2(\"change_scroll_region\",\n-\t\t\t  TPARM_2(change_scroll_region, top, bot));\n+\t\t\t  TIPARM_2(change_scroll_region, top, bot));\n \t    if (cursor_saved) {\n \t\tNCURSES_PUTP2(\"restore_cursor\", restore_cursor);\n \t    } else {\n@@ -2050,7 +2050,7 @@ NCURSES_SP_NAME(_nc_scrolln) (NCURSES_SP_DCLx\n \t    res = scroll_csr_forward(NCURSES_SP_ARGx n, top, bot, top, bot, blank);\n \n \t    NCURSES_PUTP2(\"change_scroll_region\",\n-\t\t\t  TPARM_2(change_scroll_region, 0, maxy));\n+\t\t\t  TIPARM_2(change_scroll_region, 0, maxy));\n \t    SP_PARM->_cursrow = SP_PARM->_curscol = -1;\n \t}\n \n@@ -2086,7 +2086,7 @@ NCURSES_SP_NAME(_nc_scrolln) (NCURSES_SP_DCLx\n \t\tNCURSES_PUTP2(\"save_cursor\", save_cursor);\n \t    }\n \t    NCURSES_PUTP2(\"change_scroll_region\",\n-\t\t\t  TPARM_2(change_scroll_region, top, bot));\n+\t\t\t  TIPARM_2(change_scroll_region, top, bot));\n \t    if (cursor_saved) {\n \t\tNCURSES_PUTP2(\"restore_cursor\", restore_cursor);\n \t    } else {\n@@ -2097,7 +2097,7 @@ NCURSES_SP_NAME(_nc_scrolln) (NCURSES_SP_DCLx\n \t\t\t\t      -n, top, bot, top, bot, blank);\n \n \t    NCURSES_PUTP2(\"change_scroll_region\",\n-\t\t\t  TPARM_2(change_scroll_region, 0, maxy));\n+\t\t\t  TIPARM_2(change_scroll_region, 0, maxy));\n \t    SP_PARM->_cursrow = SP_PARM->_curscol = -1;\n \t}\n \ndiff --git a/ncurses/widechar/lib_vid_attr.c b/ncurses/widechar/lib_vid_attr.c\nindex e167bebee..2d9531f1b 100644\n--- a/ncurses/widechar/lib_vid_attr.c\n+++ b/ncurses/widechar/lib_vid_attr.c\n@@ -37,7 +37,7 @@\n #define CUR SP_TERMTYPE\n #endif\n \n-MODULE_ID(\"$Id: lib_vid_attr.c,v 1.28 2020/02/02 23:34:34 tom Exp $\")\n+MODULE_ID(\"$Id: lib_vid_attr.c,v 1.30 2020/05/27 23:54:31 tom Exp $\")\n \n #define doPut(mode) \\\n \tTPUTS_TRACE(#mode); \\\n@@ -191,16 +191,16 @@ NCURSES_SP_NAME(vid_puts) (NCURSES_SP_DCLx\n \tif (turn_on || turn_off) {\n \t    TPUTS_TRACE(\"set_attributes\");\n \t    NCURSES_SP_NAME(tputs) (NCURSES_SP_ARGx\n-\t\t\t\t    TPARM_9(set_attributes,\n-\t\t\t\t\t    (newmode & A_STANDOUT) != 0,\n-\t\t\t\t\t    (newmode & A_UNDERLINE) != 0,\n-\t\t\t\t\t    (newmode & A_REVERSE) != 0,\n-\t\t\t\t\t    (newmode & A_BLINK) != 0,\n-\t\t\t\t\t    (newmode & A_DIM) != 0,\n-\t\t\t\t\t    (newmode & A_BOLD) != 0,\n-\t\t\t\t\t    (newmode & A_INVIS) != 0,\n-\t\t\t\t\t    (newmode & A_PROTECT) != 0,\n-\t\t\t\t\t    (newmode & A_ALTCHARSET) != 0),\n+\t\t\t\t    TIPARM_9(set_attributes,\n+\t\t\t\t\t       (newmode & A_STANDOUT) != 0,\n+\t\t\t\t\t       (newmode & A_UNDERLINE) != 0,\n+\t\t\t\t\t       (newmode & A_REVERSE) != 0,\n+\t\t\t\t\t       (newmode & A_BLINK) != 0,\n+\t\t\t\t\t       (newmode & A_DIM) != 0,\n+\t\t\t\t\t       (newmode & A_BOLD) != 0,\n+\t\t\t\t\t       (newmode & A_INVIS) != 0,\n+\t\t\t\t\t       (newmode & A_PROTECT) != 0,\n+\t\t\t\t\t       (newmode & A_ALTCHARSET) != 0),\n \t\t\t\t    1, outc);\n \t    previous_attr &= ALL_BUT_COLOR;\n \t    previous_pair = 0;\n@@ -264,7 +264,6 @@ NCURSES_SP_NAME(vid_puts) (NCURSES_SP_DCLx\n \tTurnOn(A_VERTICAL,\tenter_vertical_hl_mode);\n #endif\n \t/* *INDENT-ON* */\n-\n     }\n \n     if (reverse)\ndiff --git a/package/debian-mingw/changelog b/package/debian-mingw/changelog\nindex 9e844799b..7a9d961d9 100644\n--- a/package/debian-mingw/changelog\n+++ b/package/debian-mingw/changelog\n@@ -1,8 +1,8 @@\n-ncurses6 (6.2+20200523) unstable; urgency=low\n+ncurses6 (6.2+20200531) unstable; urgency=low\n \n   * latest weekly patch\n \n- -- Thomas E. Dickey <dickey@invisible-island.net>  Sat, 23 May 2020 05:35:39 -0400\n+ -- Thomas E. Dickey <dickey@invisible-island.net>  Sun, 31 May 2020 14:56:59 -0400\n \n ncurses6 (5.9-20131005) unstable; urgency=low\n \ndiff --git a/package/debian-mingw64/changelog b/package/debian-mingw64/changelog\nindex 9e844799b..7a9d961d9 100644\n--- a/package/debian-mingw64/changelog\n+++ b/package/debian-mingw64/changelog\n@@ -1,8 +1,8 @@\n-ncurses6 (6.2+20200523) unstable; urgency=low\n+ncurses6 (6.2+20200531) unstable; urgency=low\n \n   * latest weekly patch\n \n- -- Thomas E. Dickey <dickey@invisible-island.net>  Sat, 23 May 2020 05:35:39 -0400\n+ -- Thomas E. Dickey <dickey@invisible-island.net>  Sun, 31 May 2020 14:56:59 -0400\n \n ncurses6 (5.9-20131005) unstable; urgency=low\n \ndiff --git a/package/debian/changelog b/package/debian/changelog\nindex 47a55f774..843c49b86 100644\n--- a/package/debian/changelog\n+++ b/package/debian/changelog\n@@ -1,8 +1,8 @@\n-ncurses6 (6.2+20200523) unstable; urgency=low\n+ncurses6 (6.2+20200531) unstable; urgency=low\n \n   * latest weekly patch\n \n- -- Thomas E. Dickey <dickey@invisible-island.net>  Sat, 23 May 2020 05:35:39 -0400\n+ -- Thomas E. Dickey <dickey@invisible-island.net>  Sun, 31 May 2020 14:56:59 -0400\n \n ncurses6 (5.9-20120608) unstable; urgency=low\n \ndiff --git a/package/mingw-ncurses.nsi b/package/mingw-ncurses.nsi\nindex 634b0df5e..ce1de07ce 100644\n--- a/package/mingw-ncurses.nsi\n+++ b/package/mingw-ncurses.nsi\n@@ -1,4 +1,4 @@\n-; $Id: mingw-ncurses.nsi,v 1.395 2020/05/23 09:35:39 tom Exp $\r\n+; $Id: mingw-ncurses.nsi,v 1.398 2020/05/31 18:56:59 tom Exp $\r\n \r\n ; TODO add examples\r\n ; TODO bump ABI to 6\r\n@@ -10,7 +10,7 @@\n !define VERSION_MAJOR \"6\"\r\n !define VERSION_MINOR \"2\"\r\n !define VERSION_YYYY  \"2020\"\r\n-!define VERSION_MMDD  \"0523\"\r\n+!define VERSION_MMDD  \"0531\"\r\n !define VERSION_PATCH ${VERSION_YYYY}${VERSION_MMDD}\r\n \r\n !define MY_ABI   \"5\"\r\ndiff --git a/package/mingw-ncurses.spec b/package/mingw-ncurses.spec\nindex 40522dd5a..cefaa9b4d 100644\n--- a/package/mingw-ncurses.spec\n+++ b/package/mingw-ncurses.spec\n@@ -3,7 +3,7 @@\n Summary: shared libraries for terminal handling\n Name: mingw32-ncurses6\n Version: 6.2\n-Release: 20200523\n+Release: 20200531\n License: X11\n Group: Development/Libraries\n Source: ncurses-%{version}-%{release}.tgz\ndiff --git a/package/ncurses.map b/package/ncurses.map\nindex 1c400dee5..0b2a1ab2c 100644\n--- a/package/ncurses.map\n+++ b/package/ncurses.map\n@@ -1,4 +1,4 @@\n-# $Id: ncurses.map,v 1.51 2020/02/04 11:44:12 tom Exp $\n+# $Id: ncurses.map,v 1.52 2020/05/27 19:26:59 tom Exp $\n # script for shared library symbol-versioning using ld\n #\n # This file was generated by ncu-mapsyms\n@@ -1206,6 +1206,11 @@ NCURSES_TINFO_6.2.20200212 {\n \t\t_nc_wacs_width;\n \t\tcurses_trace;\n \t\texit_terminfo;\n+} NCURSES_TINFO_6.1.20171230;\n+\n+NCURSES_TINFO_6.2.current {\n+\tglobal:\n+\t\t_nc_tiparm;\n \tlocal:\n \t\t_*;\n-} NCURSES_TINFO_6.1.20171230;\n+} NCURSES_TINFO_6.2.20200212;\ndiff --git a/package/ncurses.spec b/package/ncurses.spec\nindex 9aaac6c71..32bc053c5 100644\n--- a/package/ncurses.spec\n+++ b/package/ncurses.spec\n@@ -1,7 +1,7 @@\n Summary: shared libraries for terminal handling\n Name: ncurses6\n Version: 6.2\n-Release: 20200523\n+Release: 20200531\n License: X11\n Group: Development/Libraries\n Source: ncurses-%{version}-%{release}.tgz\ndiff --git a/package/ncursest.map b/package/ncursest.map\nindex 643dc8e11..ed8f4e191 100644\n--- a/package/ncursest.map\n+++ b/package/ncursest.map\n@@ -1,4 +1,4 @@\n-# $Id: ncursest.map,v 1.49 2020/02/04 11:44:12 tom Exp $\n+# $Id: ncursest.map,v 1.50 2020/05/27 19:29:10 tom Exp $\n # script for shared library symbol-versioning using ld\n #\n # This file was generated by ncu-mapsyms\n@@ -485,9 +485,14 @@ NCURSES_TINFO_6.2.20200212 {\n \t\t_nc_wacs_width;\n \t\tcurses_trace;\n \t\texit_terminfo;\n+} NCURSES_TINFO_6.1.20171230;\n+\n+NCURSES_TINFO_6.2.current {\n+\tglobal:\n+\t\t_nc_tiparm;\n \tlocal:\n \t\t_*;\n-} NCURSES_TINFO_6.1.20171230;\n+} NCURSES_TINFO_6.2.20200212;\n \n NCURSEST_5.7.20081102 {\n \tglobal:\ndiff --git a/package/ncursest.spec b/package/ncursest.spec\nindex 710d6e5ba..b3c4bff12 100644\n--- a/package/ncursest.spec\n+++ b/package/ncursest.spec\n@@ -1,7 +1,7 @@\n Summary: Curses library with POSIX thread support.\n Name: ncursest6\n Version: 6.2\n-Release: 20200523\n+Release: 20200531\n License: X11\n Group: Development/Libraries\n Source: ncurses-%{version}-%{release}.tgz\ndiff --git a/package/ncursestw.map b/package/ncursestw.map\nindex 0c932b934..ff857389e 100644\n--- a/package/ncursestw.map\n+++ b/package/ncursestw.map\n@@ -1,4 +1,4 @@\n-# $Id: ncursestw.map,v 1.51 2020/02/04 11:44:12 tom Exp $\n+# $Id: ncursestw.map,v 1.52 2020/05/27 19:29:32 tom Exp $\n # script for shared library symbol-versioning using ld\n #\n # This file was generated by ncu-mapsyms\n@@ -491,9 +491,14 @@ NCURSES_TINFO_6.2.20200212 {\n \t\t_nc_wacs_width;\n \t\tcurses_trace;\n \t\texit_terminfo;\n+} NCURSES_TINFO_6.1.20171230;\n+\n+NCURSES_TINFO_6.2.current {\n+\tglobal:\n+\t\t_nc_tiparm;\n \tlocal:\n \t\t_*;\n-} NCURSES_TINFO_6.1.20171230;\n+} NCURSES_TINFO_6.2.20200212;\n \n NCURSESTW_5.7.20081102 {\n \tglobal:\ndiff --git a/package/ncursesw.map b/package/ncursesw.map\nindex da68b73c1..021cd5776 100644\n--- a/package/ncursesw.map\n+++ b/package/ncursesw.map\n@@ -1,4 +1,4 @@\n-# $Id: ncursesw.map,v 1.54 2020/02/04 11:44:12 tom Exp $\n+# $Id: ncursesw.map,v 1.55 2020/05/27 19:27:45 tom Exp $\n # script for shared library symbol-versioning using ld\n #\n # This file was generated by ncu-mapsyms\n@@ -485,9 +485,14 @@ NCURSES_TINFO_6.2.20200212 {\n \t\t_nc_wacs_width;\n \t\tcurses_trace;\n \t\texit_terminfo;\n+} NCURSES_TINFO_6.1.20171230;\n+\n+NCURSES_TINFO_6.2.current {\n+\tglobal:\n+\t\t_nc_tiparm;\n \tlocal:\n \t\t_*;\n-} NCURSES_TINFO_6.1.20171230;\n+} NCURSES_TINFO_6.2.20200212;\n \n NCURSESW_5.1.20000708 {\n \tglobal:\ndiff --git a/progs/reset_cmd.c b/progs/reset_cmd.c\nindex 9d23cd05e..2e118ae58 100644\n--- a/progs/reset_cmd.c\n+++ b/progs/reset_cmd.c\n@@ -53,7 +53,7 @@\n #include <sys/ptem.h>\n #endif\n \n-MODULE_ID(\"$Id: reset_cmd.c,v 1.19 2020/02/02 23:34:34 tom Exp $\")\n+MODULE_ID(\"$Id: reset_cmd.c,v 1.21 2020/05/27 23:46:20 tom Exp $\")\n \n /*\n  * SCO defines TIOCGSIZE and the corresponding struct.  Other systems (SunOS,\n@@ -501,16 +501,15 @@ send_init_strings(int fd GCC_UNUSED, TTY * old_settings)\n \t} else\n #if defined(set_lr_margin)\n \tif (VALID_STRING(set_lr_margin)) {\n-\t    need_flush |= sent_string(TPARM_2(set_lr_margin, 0,\n-\t\t\t\t\t      columns - 1));\n+\t    need_flush |= sent_string(TIPARM_2(set_lr_margin, 0, columns - 1));\n \t} else\n #endif\n #if defined(set_left_margin_parm) && defined(set_right_margin_parm)\n \t    if (VALID_STRING(set_left_margin_parm)\n \t\t&& VALID_STRING(set_right_margin_parm)) {\n-\t    need_flush |= sent_string(TPARM_1(set_left_margin_parm, 0));\n-\t    need_flush |= sent_string(TPARM_1(set_right_margin_parm,\n-\t\t\t\t\t      columns - 1));\n+\t    need_flush |= sent_string(TIPARM_1(set_left_margin_parm, 0));\n+\t    need_flush |= sent_string(TIPARM_1(set_right_margin_parm,\n+\t\t\t\t\t       columns - 1));\n \t} else\n #endif\n \t    if (VALID_STRING(set_left_margin)\n@@ -518,8 +517,8 @@ send_init_strings(int fd GCC_UNUSED, TTY * old_settings)\n \t    need_flush |= to_left_margin();\n \t    need_flush |= sent_string(set_left_margin);\n \t    if (VALID_STRING(parm_right_cursor)) {\n-\t\tneed_flush |= sent_string(TPARM_1(parm_right_cursor,\n-\t\t\t\t\t\t  columns - 1));\n+\t\tneed_flush |= sent_string(TIPARM_1(parm_right_cursor,\n+\t\t\t\t\t\t   columns - 1));\n \t    } else {\n \t\tfor (i = 0; i < columns - 1; i++) {\n \t\t    out_char(' ');\ndiff --git a/progs/tabs.c b/progs/tabs.c\nindex 8a3bc108f..0539e8565 100644\n--- a/progs/tabs.c\n+++ b/progs/tabs.c\n@@ -39,7 +39,7 @@\n #include <progs.priv.h>\n #include <tty_settings.h>\n \n-MODULE_ID(\"$Id: tabs.c,v 1.42 2020/02/02 23:34:34 tom Exp $\")\n+MODULE_ID(\"$Id: tabs.c,v 1.45 2020/05/27 23:47:22 tom Exp $\")\n \n static void usage(void) GCC_NORETURN;\n \n@@ -75,7 +75,7 @@ do_tabs(int *tab_list)\n \t    }\n \t}\n \tif (stop <= max_cols) {\n-\t    tputs(tparm(set_tab, stop), 1, putch);\n+\t    tputs(TIPARM_1(set_tab, stop), 1, putch);\n \t    last = stop;\n \t} else {\n \t    break;\ndiff --git a/progs/tic.c b/progs/tic.c\nindex 328bcd6b2..ae172ece9 100644\n--- a/progs/tic.c\n+++ b/progs/tic.c\n@@ -49,7 +49,7 @@\n #include <parametrized.h>\n #include <transform.h>\n \n-MODULE_ID(\"$Id: tic.c,v 1.282 2020/02/02 23:34:34 tom Exp $\")\n+MODULE_ID(\"$Id: tic.c,v 1.286 2020/05/31 21:05:44 tom Exp $\")\n \n #define STDIN_NAME \"<stdin>\"\n \n@@ -1179,6 +1179,14 @@ check_acs(TERMTYPE2 *tp)\n     }\n }\n \n+static char *\n+safe_strdup(const char *value)\n+{\n+    if (value == NULL)\n+\tvalue = \"\";\n+    return strdup(value);\n+}\n+\n static bool\n same_color(NCURSES_CONST char *oldcap, NCURSES_CONST char *newcap, int limit)\n {\n@@ -1189,8 +1197,8 @@ same_color(NCURSES_CONST char *oldcap, NCURSES_CONST char *newcap, int limit)\n \tint n;\n \tint same;\n \tfor (n = same = 0; n < limit; ++n) {\n-\t    char *oldvalue = strdup(TPARM_1(oldcap, n));\n-\t    char *newvalue = strdup(TPARM_1(newcap, n));\n+\t    char *oldvalue = safe_strdup(TIPARM_1(oldcap, n));\n+\t    char *newvalue = safe_strdup(TIPARM_1(newcap, n));\n \t    same += !strcmp(oldvalue, newvalue);\n \t    free(oldvalue);\n \t    free(newvalue);\n@@ -1835,7 +1843,6 @@ expected_params(const char *name)\n \tDATA( \"wingo\",\t\t1 ),\n     };\n     /* *INDENT-ON* */\n-\n #undef DATA\n \n     unsigned n;\n@@ -1910,7 +1917,7 @@ check_params(TERMTYPE2 *tp, const char *name, char *value, int extended)\n     int expected = expected_params(name);\n     int actual = 0;\n     int n;\n-    bool params[NUM_PARM];\n+    bool params[1 + NUM_PARM];\n     char *s = value;\n \n #ifdef set_top_margin_parm\n@@ -1919,7 +1926,7 @@ check_params(TERMTYPE2 *tp, const char *name, char *value, int extended)\n \texpected = 2;\n #endif\n \n-    for (n = 0; n < NUM_PARM; n++)\n+    for (n = 0; n <= NUM_PARM; n++)\n \tparams[n] = FALSE;\n \n     while (*s != 0) {\n@@ -2192,6 +2199,19 @@ check_1_infotocap(const char *name, NCURSES_CONST char *value, int count)\n \tresult = TPARM_3(value, numbers[1], strings[2], strings[3]);\n \tbreak;\n     case Numbers:\n+#define myParam(n) numbers[n]\n+\tresult = TIPARM_9(value,\n+\t\t\t  myParam(1),\n+\t\t\t  myParam(2),\n+\t\t\t  myParam(3),\n+\t\t\t  myParam(4),\n+\t\t\t  myParam(5),\n+\t\t\t  myParam(6),\n+\t\t\t  myParam(7),\n+\t\t\t  myParam(8),\n+\t\t\t  myParam(9));\n+#undef myParam\n+\tbreak;\n     default:\n \t(void) _nc_tparm_analyze(value, p_is_s, &ignored);\n #define myParam(n) (p_is_s[n - 1] != 0 ? ((TPARM_ARG) strings[n]) : numbers[n])\n@@ -2205,6 +2225,7 @@ check_1_infotocap(const char *name, NCURSES_CONST char *value, int count)\n \t\t\t myParam(7),\n \t\t\t myParam(8),\n \t\t\t myParam(9));\n+#undef myParam\n \tbreak;\n     }\n     return strdup(result);\n@@ -2515,16 +2536,16 @@ check_sgr(TERMTYPE2 *tp, char *zero, int num, char *cap, const char *name)\n     char *test;\n \n     _nc_tparm_err = 0;\n-    test = TPARM_9(set_attributes,\n-\t\t   num == 1,\n-\t\t   num == 2,\n-\t\t   num == 3,\n-\t\t   num == 4,\n-\t\t   num == 5,\n-\t\t   num == 6,\n-\t\t   num == 7,\n-\t\t   num == 8,\n-\t\t   num == 9);\n+    test = TIPARM_9(set_attributes,\n+\t\t    num == 1,\n+\t\t    num == 2,\n+\t\t    num == 3,\n+\t\t    num == 4,\n+\t\t    num == 5,\n+\t\t    num == 6,\n+\t\t    num == 7,\n+\t\t    num == 8,\n+\t\t    num == 9);\n     if (test != 0) {\n \tif (PRESENT(cap)) {\n \t    if (!similar_sgr(num, test, cap)) {\n@@ -2695,7 +2716,6 @@ check_conflict(TERMTYPE2 *tp)\n \t\t{ NULL,   NULL },\n \t    };\n \t    /* *INDENT-ON* */\n-\n \t    /*\n \t     * SVr4 curses defines the \"xcurses\" names listed above except for\n \t     * the special cases in the \"shifted\" column.  When using these\n@@ -2973,7 +2993,7 @@ check_termtype(TERMTYPE2 *tp, bool literal)\n \tif (PRESENT(exit_attribute_mode)) {\n \t    zero = strdup(CHECK_SGR(0, exit_attribute_mode));\n \t} else {\n-\t    zero = strdup(TPARM_9(set_attributes, 0, 0, 0, 0, 0, 0, 0, 0, 0));\n+\t    zero = strdup(TIPARM_9(set_attributes, 0, 0, 0, 0, 0, 0, 0, 0, 0));\n \t}\n \tif (_nc_tparm_err)\n \t    _nc_warning(\"stack error in sgr(0) string\");\ndiff --git a/progs/tput.c b/progs/tput.c\nindex 295b83fb8..4bb771478 100644\n--- a/progs/tput.c\n+++ b/progs/tput.c\n@@ -51,7 +51,7 @@\n #include <transform.h>\n #include <tty_settings.h>\n \n-MODULE_ID(\"$Id: tput.c,v 1.81 2020/02/02 23:34:34 tom Exp $\")\n+MODULE_ID(\"$Id: tput.c,v 1.83 2020/05/27 23:47:51 tom Exp $\")\n \n #define PUTS(s)\t\tfputs(s, stdout)\n \n@@ -63,7 +63,7 @@ static bool is_reset = FALSE;\n static bool is_clear = FALSE;\n \n static void\n-quit(int status, const char *fmt,...)\n+quit(int status, const char *fmt, ...)\n {\n     va_list argp;\n \n@@ -251,6 +251,19 @@ tput_cmd(int fd, TTY * saved_settings, bool opt_x, int argc, char *argv[])\n \t\ts = TPARM_3(s, numbers[1], strings[2], strings[3]);\n \t\tbreak;\n \t    case Numbers:\n+#define myParam(n) numbers[n]\n+\t\ts = TIPARM_9(s,\n+\t\t\t     myParam(1),\n+\t\t\t     myParam(2),\n+\t\t\t     myParam(3),\n+\t\t\t     myParam(4),\n+\t\t\t     myParam(5),\n+\t\t\t     myParam(6),\n+\t\t\t     myParam(7),\n+\t\t\t     myParam(8),\n+\t\t\t     myParam(9));\n+#undef myParam\n+\t\tbreak;\n \t    default:\n \t\t(void) _nc_tparm_analyze(s, p_is_s, &ignored);\n #define myParam(n) (p_is_s[n - 1] != 0 ? ((TPARM_ARG) strings[n]) : numbers[n])\n@@ -264,6 +277,7 @@ tput_cmd(int fd, TTY * saved_settings, bool opt_x, int argc, char *argv[])\n \t\t\t    myParam(7),\n \t\t\t    myParam(8),\n \t\t\t    myParam(9));\n+#undef myParam\n \t\tbreak;\n \t    }\n \t}\ndiff --git a/test/configure b/test/configure\nindex 6a19a63bd..41cd8efd1 100755\n--- a/test/configure\n+++ b/test/configure\n@@ -17576,18 +17576,19 @@ fi\n for ac_func in \\\n getopt \\\n gettimeofday \\\n+snprintf \\\n strstr \\\n tsearch \\\n \n do\n as_ac_var=`echo \"ac_cv_func_$ac_func\" | $as_tr_sh`\n-echo \"$as_me:17584: checking for $ac_func\" >&5\n+echo \"$as_me:17585: checking for $ac_func\" >&5\n echo $ECHO_N \"checking for $ac_func... $ECHO_C\" >&6\n if eval \"test \\\"\\${$as_ac_var+set}\\\" = set\"; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 17590 \"configure\"\n+#line 17591 \"configure\"\n #include \"confdefs.h\"\n #define $ac_func autoconf_temporary\n #include <limits.h>\t/* least-intrusive standard header which defines gcc2 __stub macros */\n@@ -17618,16 +17619,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:17621: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:17622: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:17624: \\$? = $ac_status\" >&5\n+  echo \"$as_me:17625: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:17627: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:17628: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:17630: \\$? = $ac_status\" >&5\n+  echo \"$as_me:17631: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   eval \"$as_ac_var=yes\"\n else\n@@ -17637,7 +17638,7 @@ eval \"$as_ac_var=no\"\n fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n fi\n-echo \"$as_me:17640: result: `eval echo '${'$as_ac_var'}'`\" >&5\n+echo \"$as_me:17641: result: `eval echo '${'$as_ac_var'}'`\" >&5\n echo \"${ECHO_T}`eval echo '${'$as_ac_var'}'`\" >&6\n if test `eval echo '${'$as_ac_var'}'` = yes; then\n   cat >>confdefs.h <<EOF\n@@ -17648,14 +17649,14 @@ fi\n done\n \n # use a compile-check to work with ncurses*-config and subdirectory includes\n-echo \"$as_me:17651: checking if we can use termcap.h\" >&5\n+echo \"$as_me:17652: checking if we can use termcap.h\" >&5\n echo $ECHO_N \"checking if we can use termcap.h... $ECHO_C\" >&6\n if test \"${cf_cv_have_termcap_h+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n \n \tcat >conftest.$ac_ext <<_ACEOF\n-#line 17658 \"configure\"\n+#line 17659 \"configure\"\n #include \"confdefs.h\"\n \n #include <curses.h>\n@@ -17676,16 +17677,16 @@ return 0;\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:17679: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:17680: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:17682: \\$? = $ac_status\" >&5\n+  echo \"$as_me:17683: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:17685: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:17686: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:17688: \\$? = $ac_status\" >&5\n+  echo \"$as_me:17689: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_have_termcap_h=yes\n else\n@@ -17695,7 +17696,7 @@ cf_cv_have_termcap_h=no\n fi\n rm -f conftest.$ac_objext conftest.$ac_ext\n fi\n-echo \"$as_me:17698: result: $cf_cv_have_termcap_h\" >&5\n+echo \"$as_me:17699: result: $cf_cv_have_termcap_h\" >&5\n echo \"${ECHO_T}$cf_cv_have_termcap_h\" >&6\n if test \"x$cf_cv_have_termcap_h\" = xyes\n then\n@@ -17705,14 +17706,14 @@ cat >>confdefs.h <<\\EOF\n EOF\n \n else\n-echo \"$as_me:17708: checking if we can use ncurses/termcap.h\" >&5\n+echo \"$as_me:17709: checking if we can use ncurses/termcap.h\" >&5\n echo $ECHO_N \"checking if we can use ncurses/termcap.h... $ECHO_C\" >&6\n if test \"${cf_cv_have_ncurses_termcap_h+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n \n \tcat >conftest.$ac_ext <<_ACEOF\n-#line 17715 \"configure\"\n+#line 17716 \"configure\"\n #include \"confdefs.h\"\n \n #include <ncurses/curses.h>\n@@ -17733,16 +17734,16 @@ return 0;\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:17736: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:17737: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:17739: \\$? = $ac_status\" >&5\n+  echo \"$as_me:17740: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:17742: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:17743: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:17745: \\$? = $ac_status\" >&5\n+  echo \"$as_me:17746: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_have_ncurses_termcap_h=yes\n else\n@@ -17752,7 +17753,7 @@ cf_cv_have_ncurses_termcap_h=no\n fi\n rm -f conftest.$ac_objext conftest.$ac_ext\n fi\n-echo \"$as_me:17755: result: $cf_cv_have_ncurses_termcap_h\" >&5\n+echo \"$as_me:17756: result: $cf_cv_have_ncurses_termcap_h\" >&5\n echo \"${ECHO_T}$cf_cv_have_ncurses_termcap_h\" >&6\n test \"x$cf_cv_have_ncurses_termcap_h\" = xyes &&\n cat >>confdefs.h <<\\EOF\n@@ -17762,7 +17763,7 @@ EOF\n fi\n \n if test \"x$ac_cv_func_getopt\" = xno; then\n-\t{ { echo \"$as_me:17765: error: getopt is required for building programs\" >&5\n+\t{ { echo \"$as_me:17766: error: getopt is required for building programs\" >&5\n echo \"$as_me: error: getopt is required for building programs\" >&2;}\n    { (exit 1); exit 1; }; }\n fi\n@@ -17781,13 +17782,13 @@ wcstombs \\\n \n do\n as_ac_var=`echo \"ac_cv_func_$ac_func\" | $as_tr_sh`\n-echo \"$as_me:17784: checking for $ac_func\" >&5\n+echo \"$as_me:17785: checking for $ac_func\" >&5\n echo $ECHO_N \"checking for $ac_func... $ECHO_C\" >&6\n if eval \"test \\\"\\${$as_ac_var+set}\\\" = set\"; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 17790 \"configure\"\n+#line 17791 \"configure\"\n #include \"confdefs.h\"\n #define $ac_func autoconf_temporary\n #include <limits.h>\t/* least-intrusive standard header which defines gcc2 __stub macros */\n@@ -17818,16 +17819,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:17821: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:17822: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:17824: \\$? = $ac_status\" >&5\n+  echo \"$as_me:17825: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:17827: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:17828: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:17830: \\$? = $ac_status\" >&5\n+  echo \"$as_me:17831: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   eval \"$as_ac_var=yes\"\n else\n@@ -17837,7 +17838,7 @@ eval \"$as_ac_var=no\"\n fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n fi\n-echo \"$as_me:17840: result: `eval echo '${'$as_ac_var'}'`\" >&5\n+echo \"$as_me:17841: result: `eval echo '${'$as_ac_var'}'`\" >&5\n echo \"${ECHO_T}`eval echo '${'$as_ac_var'}'`\" >&6\n if test `eval echo '${'$as_ac_var'}'` = yes; then\n   cat >>confdefs.h <<EOF\n@@ -17849,7 +17850,7 @@ done\n \n fi\n \n-echo \"$as_me:17852: checking definition to turn on extended curses functions\" >&5\n+echo \"$as_me:17853: checking definition to turn on extended curses functions\" >&5\n echo $ECHO_N \"checking definition to turn on extended curses functions... $ECHO_C\" >&6\n if test \"${cf_cv_need_xopen_extension+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -17857,7 +17858,7 @@ else\n \n cf_cv_need_xopen_extension=unknown\n cat >conftest.$ac_ext <<_ACEOF\n-#line 17860 \"configure\"\n+#line 17861 \"configure\"\n #include \"confdefs.h\"\n \n #include <stdlib.h>\n@@ -17890,16 +17891,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:17893: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:17894: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:17896: \\$? = $ac_status\" >&5\n+  echo \"$as_me:17897: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:17899: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:17900: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:17902: \\$? = $ac_status\" >&5\n+  echo \"$as_me:17903: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_need_xopen_extension=none\n else\n@@ -17909,7 +17910,7 @@ cat conftest.$ac_ext >&5\n \tfor cf_try_xopen_extension in _XOPEN_SOURCE_EXTENDED NCURSES_WIDECHAR\n \tdo\n \t\tcat >conftest.$ac_ext <<_ACEOF\n-#line 17912 \"configure\"\n+#line 17913 \"configure\"\n #include \"confdefs.h\"\n \n #define $cf_try_xopen_extension 1\n@@ -17938,16 +17939,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:17941: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:17942: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:17944: \\$? = $ac_status\" >&5\n+  echo \"$as_me:17945: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:17947: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:17948: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:17950: \\$? = $ac_status\" >&5\n+  echo \"$as_me:17951: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_need_xopen_extension=$cf_try_xopen_extension; break\n else\n@@ -17961,7 +17962,7 @@ fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n \n fi\n-echo \"$as_me:17964: result: $cf_cv_need_xopen_extension\" >&5\n+echo \"$as_me:17965: result: $cf_cv_need_xopen_extension\" >&5\n echo \"${ECHO_T}$cf_cv_need_xopen_extension\" >&6\n \n case $cf_cv_need_xopen_extension in\n@@ -17973,7 +17974,7 @@ case $cf_cv_need_xopen_extension in\n \t;;\n esac\n \n-echo \"$as_me:17976: checking for term.h\" >&5\n+echo \"$as_me:17977: checking for term.h\" >&5\n echo $ECHO_N \"checking for term.h... $ECHO_C\" >&6\n if test \"${cf_cv_term_header+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -17994,7 +17995,7 @@ esac\n for cf_header in $cf_header_list\n do\n \tcat >conftest.$ac_ext <<_ACEOF\n-#line 17997 \"configure\"\n+#line 17998 \"configure\"\n #include \"confdefs.h\"\n \n #include <${cf_cv_ncurses_header:-curses.h}>\n@@ -18008,16 +18009,16 @@ WINDOW *x; (void)x\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:18011: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:18012: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18014: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18015: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:18017: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:18018: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18020: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18021: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_term_header=$cf_header\n \t break\n@@ -18036,7 +18037,7 @@ case $cf_cv_term_header in\n \tfor cf_header in ncurses/term.h ncursesw/term.h\n \tdo\n \t\tcat >conftest.$ac_ext <<_ACEOF\n-#line 18039 \"configure\"\n+#line 18040 \"configure\"\n #include \"confdefs.h\"\n \n #include <${cf_cv_ncurses_header:-curses.h}>\n@@ -18054,16 +18055,16 @@ WINDOW *x; (void)x\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:18057: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:18058: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18060: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18061: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:18063: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:18064: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18066: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18067: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_term_header=$cf_header\n \t\t\t break\n@@ -18078,7 +18079,7 @@ rm -f conftest.$ac_objext conftest.$ac_ext\n esac\n \n fi\n-echo \"$as_me:18081: result: $cf_cv_term_header\" >&5\n+echo \"$as_me:18082: result: $cf_cv_term_header\" >&5\n echo \"${ECHO_T}$cf_cv_term_header\" >&6\n \n case $cf_cv_term_header in\n@@ -18105,7 +18106,7 @@ EOF\n \t;;\n esac\n \n-echo \"$as_me:18108: checking for unctrl.h\" >&5\n+echo \"$as_me:18109: checking for unctrl.h\" >&5\n echo $ECHO_N \"checking for unctrl.h... $ECHO_C\" >&6\n if test \"${cf_cv_unctrl_header+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -18126,7 +18127,7 @@ esac\n for cf_header in $cf_header_list\n do\n \tcat >conftest.$ac_ext <<_ACEOF\n-#line 18129 \"configure\"\n+#line 18130 \"configure\"\n #include \"confdefs.h\"\n \n #include <${cf_cv_ncurses_header:-curses.h}>\n@@ -18140,16 +18141,16 @@ WINDOW *x; (void)x\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:18143: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:18144: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18146: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18147: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:18149: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:18150: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18152: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18153: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_unctrl_header=$cf_header\n \t break\n@@ -18162,12 +18163,12 @@ rm -f conftest.$ac_objext conftest.$ac_ext\n done\n \n fi\n-echo \"$as_me:18165: result: $cf_cv_unctrl_header\" >&5\n+echo \"$as_me:18166: result: $cf_cv_unctrl_header\" >&5\n echo \"${ECHO_T}$cf_cv_unctrl_header\" >&6\n \n case $cf_cv_unctrl_header in\n (no)\n-\t{ echo \"$as_me:18170: WARNING: unctrl.h header not found\" >&5\n+\t{ echo \"$as_me:18171: WARNING: unctrl.h header not found\" >&5\n echo \"$as_me: WARNING: unctrl.h header not found\" >&2;}\n \t;;\n esac\n@@ -18256,10 +18257,10 @@ do\n \n cf_tr_func=`echo \"$cf_func\" | sed y%abcdefghijklmnopqrstuvwxyz./-%ABCDEFGHIJKLMNOPQRSTUVWXYZ___%`\n \n-\techo \"$as_me:18259: checking for ${cf_func}\" >&5\n+\techo \"$as_me:18260: checking for ${cf_func}\" >&5\n echo $ECHO_N \"checking for ${cf_func}... $ECHO_C\" >&6\n \n-echo \"${as_me:-configure}:18262: testing ${cf_func} ...\" 1>&5\n+echo \"${as_me:-configure}:18263: testing ${cf_func} ...\" 1>&5\n \n \tif eval \"test \\\"\\${cf_cv_func_$cf_func+set}\\\" = set\"; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -18268,7 +18269,7 @@ else\n \t\teval cf_result='$ac_cv_func_'$cf_func\n \t\tif test \".$cf_result\" != \".no\"; then\n \t\t\tcat >conftest.$ac_ext <<_ACEOF\n-#line 18271 \"configure\"\n+#line 18272 \"configure\"\n #include \"confdefs.h\"\n \n #ifdef HAVE_XCURSES\n@@ -18301,16 +18302,16 @@ if (foo + 1234L > 5678L)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:18304: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:18305: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18307: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18308: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:18310: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:18311: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18313: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18314: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_result=yes\n else\n@@ -18326,7 +18327,7 @@ fi\n \n \t# use the computed/retrieved cache-value:\n \teval 'cf_result=$cf_cv_func_'$cf_func\n-\techo \"$as_me:18329: result: $cf_result\" >&5\n+\techo \"$as_me:18330: result: $cf_result\" >&5\n echo \"${ECHO_T}$cf_result\" >&6\n \tif test $cf_result != no; then\n \t\tcat >>confdefs.h <<EOF\n@@ -18341,10 +18342,10 @@ do\n \n cf_tr_func=`echo \"$cf_func\" | sed y%abcdefghijklmnopqrstuvwxyz./-%ABCDEFGHIJKLMNOPQRSTUVWXYZ___%`\n \n-\techo \"$as_me:18344: checking for ${cf_func}\" >&5\n+\techo \"$as_me:18345: checking for ${cf_func}\" >&5\n echo $ECHO_N \"checking for ${cf_func}... $ECHO_C\" >&6\n \n-echo \"${as_me:-configure}:18347: testing ${cf_func} ...\" 1>&5\n+echo \"${as_me:-configure}:18348: testing ${cf_func} ...\" 1>&5\n \n \tif eval \"test \\\"\\${cf_cv_func_$cf_func+set}\\\" = set\"; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -18353,7 +18354,7 @@ else\n \t\teval cf_result='$ac_cv_func_'$cf_func\n \t\tif test \".$cf_result\" != \".no\"; then\n \t\t\tcat >conftest.$ac_ext <<_ACEOF\n-#line 18356 \"configure\"\n+#line 18357 \"configure\"\n #include \"confdefs.h\"\n \n #ifdef HAVE_XCURSES\n@@ -18386,16 +18387,16 @@ if (foo + 1234L > 5678L)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:18389: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:18390: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18392: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18393: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:18395: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:18396: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18398: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18399: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_result=yes\n else\n@@ -18411,7 +18412,7 @@ fi\n \n \t# use the computed/retrieved cache-value:\n \teval 'cf_result=$cf_cv_func_'$cf_func\n-\techo \"$as_me:18414: result: $cf_result\" >&5\n+\techo \"$as_me:18415: result: $cf_result\" >&5\n echo \"${ECHO_T}$cf_result\" >&6\n \tif test $cf_result != no; then\n \t\tcat >>confdefs.h <<EOF\n@@ -18435,7 +18436,7 @@ then\n \t\t\t\tcf_return=\"return value\"\n \t\t\tfi\n \t\t\tcat >conftest.$ac_ext <<_ACEOF\n-#line 18438 \"configure\"\n+#line 18439 \"configure\"\n #include \"confdefs.h\"\n \n #include <${cf_cv_ncurses_header:-curses.h}>\n@@ -18455,21 +18456,21 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:18458: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:18459: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18461: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18462: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:18464: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:18465: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18467: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18468: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n \n \t\ttest -n \"$verbose\" && echo \"\tprototype $cf_ret func($cf_arg value)\" 1>&6\n \n-echo \"${as_me:-configure}:18472: testing prototype $cf_ret func($cf_arg value) ...\" 1>&5\n+echo \"${as_me:-configure}:18473: testing prototype $cf_ret func($cf_arg value) ...\" 1>&5\n \n \t\tcat >>confdefs.h <<EOF\n #define TPUTS_ARG               $cf_arg\n@@ -18489,14 +18490,14 @@ rm -f conftest.$ac_objext conftest.$ac_ext\n \tdone\n fi\n \n-echo \"$as_me:18492: checking for ncurses extended functions\" >&5\n+echo \"$as_me:18493: checking for ncurses extended functions\" >&5\n echo $ECHO_N \"checking for ncurses extended functions... $ECHO_C\" >&6\n if test \"${cf_cv_ncurses_ext_funcs+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n \n cat >conftest.$ac_ext <<_ACEOF\n-#line 18499 \"configure\"\n+#line 18500 \"configure\"\n #include \"confdefs.h\"\n \n #include <${cf_cv_ncurses_header:-curses.h}>\n@@ -18511,16 +18512,16 @@ int x = NCURSES_EXT_FUNCS\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:18514: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:18515: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18517: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18518: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:18520: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:18521: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18523: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18524: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_ncurses_ext_funcs=defined\n else\n@@ -18528,7 +18529,7 @@ else\n cat conftest.$ac_ext >&5\n \n cat >conftest.$ac_ext <<_ACEOF\n-#line 18531 \"configure\"\n+#line 18532 \"configure\"\n #include \"confdefs.h\"\n \n #include <${cf_cv_ncurses_header:-curses.h}>\n@@ -18553,16 +18554,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:18556: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:18557: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18559: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18560: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:18562: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:18563: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18565: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18566: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_ncurses_ext_funcs=yes\n else\n@@ -18576,7 +18577,7 @@ fi\n rm -f conftest.$ac_objext conftest.$ac_ext\n \n fi\n-echo \"$as_me:18579: result: $cf_cv_ncurses_ext_funcs\" >&5\n+echo \"$as_me:18580: result: $cf_cv_ncurses_ext_funcs\" >&5\n echo \"${ECHO_T}$cf_cv_ncurses_ext_funcs\" >&6\n test \"$cf_cv_ncurses_ext_funcs\" = yes &&\n cat >>confdefs.h <<\\EOF\n@@ -18590,11 +18591,11 @@ then\n \tif test -n \"$cf_cv_ncurses_version\" && test \"x$cf_cv_ncurses_version\" != xno\n \tthen\n \t\tcf_define_xpg5=no\n-\t\techo \"$as_me:18593: checking if _XPG5 should be defined to enable wide-characters\" >&5\n+\t\techo \"$as_me:18594: checking if _XPG5 should be defined to enable wide-characters\" >&5\n echo $ECHO_N \"checking if _XPG5 should be defined to enable wide-characters... $ECHO_C\" >&6\n \n \t\tcat >conftest.$ac_ext <<_ACEOF\n-#line 18597 \"configure\"\n+#line 18598 \"configure\"\n #include \"confdefs.h\"\n \n #include <${cf_cv_ncurses_header:-curses.h}>\n@@ -18607,16 +18608,16 @@ int x = _XPG5\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:18610: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:18611: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18613: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18614: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:18616: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:18617: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18619: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18620: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   :\n else\n@@ -18625,7 +18626,7 @@ cat conftest.$ac_ext >&5\n cf_save_cppflags=\"$CPPFLAGS\"\n \t\t\t CPPFLAGS=\"$CPPFLAGS -D_XPG5\"\n \t\t\t cat >conftest.$ac_ext <<_ACEOF\n-#line 18628 \"configure\"\n+#line 18629 \"configure\"\n #include \"confdefs.h\"\n \n #include <${cf_cv_ncurses_header:-curses.h}>\n@@ -18638,16 +18639,16 @@ int x = _XPG5\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:18641: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:18642: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18644: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18645: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:18647: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:18648: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18650: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18651: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_define_xpg5=yes\n else\n@@ -18658,7 +18659,7 @@ rm -f conftest.$ac_objext conftest.$ac_ext\n \t\t\t CPPFLAGS=\"$cf_save_cppflags\"\n fi\n rm -f conftest.$ac_objext conftest.$ac_ext\n-\t\techo \"$as_me:18661: result: $cf_define_xpg5\" >&5\n+\t\techo \"$as_me:18662: result: $cf_define_xpg5\" >&5\n echo \"${ECHO_T}$cf_define_xpg5\" >&6\n \n \t\tif test \"$cf_define_xpg5\" = yes\n@@ -18667,14 +18668,14 @@ echo \"${ECHO_T}$cf_define_xpg5\" >&6\n \t\tfi\n \tfi\n \n-\techo \"$as_me:18670: checking for wide-character functions\" >&5\n+\techo \"$as_me:18671: checking for wide-character functions\" >&5\n echo $ECHO_N \"checking for wide-character functions... $ECHO_C\" >&6\n if test \"${cf_cv_widechar_funcs+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n \n \tcat >conftest.$ac_ext <<_ACEOF\n-#line 18677 \"configure\"\n+#line 18678 \"configure\"\n #include \"confdefs.h\"\n \n #include <${cf_cv_ncurses_header:-curses.h}>\n@@ -18691,16 +18692,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:18694: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:18695: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18697: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18698: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:18700: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:18701: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18703: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18704: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_widechar_funcs=yes\n else\n@@ -18711,7 +18712,7 @@ fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n \n fi\n-echo \"$as_me:18714: result: $cf_cv_widechar_funcs\" >&5\n+echo \"$as_me:18715: result: $cf_cv_widechar_funcs\" >&5\n echo \"${ECHO_T}$cf_cv_widechar_funcs\" >&6\n \tif test \"$cf_cv_widechar_funcs\" != no ; then\n \n@@ -18732,14 +18733,14 @@ EOF\n \n fi\n \n-echo \"$as_me:18735: checking if $cf_cv_screen library uses pthreads\" >&5\n+echo \"$as_me:18736: checking if $cf_cv_screen library uses pthreads\" >&5\n echo $ECHO_N \"checking if $cf_cv_screen library uses pthreads... $ECHO_C\" >&6\n if test \"${cf_cv_use_pthreads+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n \n cat >conftest.$ac_ext <<_ACEOF\n-#line 18742 \"configure\"\n+#line 18743 \"configure\"\n #include \"confdefs.h\"\n \n #include <${cf_cv_ncurses_header:-curses.h}>\n@@ -18757,16 +18758,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:18760: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:18761: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18763: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18764: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:18766: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:18767: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18769: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18770: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_use_pthreads=yes\n else\n@@ -18777,21 +18778,21 @@ fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n \n fi\n-echo \"$as_me:18780: result: $cf_cv_use_pthreads\" >&5\n+echo \"$as_me:18781: result: $cf_cv_use_pthreads\" >&5\n echo \"${ECHO_T}$cf_cv_use_pthreads\" >&6\n test $cf_cv_use_pthreads = yes &&\n cat >>confdefs.h <<\\EOF\n #define USE_PTHREADS 1\n EOF\n \n-echo \"$as_me:18787: checking if sys/time.h works with sys/select.h\" >&5\n+echo \"$as_me:18788: checking if sys/time.h works with sys/select.h\" >&5\n echo $ECHO_N \"checking if sys/time.h works with sys/select.h... $ECHO_C\" >&6\n if test \"${cf_cv_sys_time_select+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n \n cat >conftest.$ac_ext <<_ACEOF\n-#line 18794 \"configure\"\n+#line 18795 \"configure\"\n #include \"confdefs.h\"\n \n #include <sys/types.h>\n@@ -18811,16 +18812,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:18814: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:18815: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18817: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18818: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:18820: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:18821: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18823: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18824: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_sys_time_select=yes\n else\n@@ -18832,7 +18833,7 @@ rm -f conftest.$ac_objext conftest.$ac_ext\n \n fi\n \n-echo \"$as_me:18835: result: $cf_cv_sys_time_select\" >&5\n+echo \"$as_me:18836: result: $cf_cv_sys_time_select\" >&5\n echo \"${ECHO_T}$cf_cv_sys_time_select\" >&6\n test \"$cf_cv_sys_time_select\" = yes &&\n cat >>confdefs.h <<\\EOF\n@@ -18841,7 +18842,7 @@ EOF\n \n # special check for test/ditto.c\n \n-echo \"$as_me:18844: checking for openpty in -lutil\" >&5\n+echo \"$as_me:18845: checking for openpty in -lutil\" >&5\n echo $ECHO_N \"checking for openpty in -lutil... $ECHO_C\" >&6\n if test \"${ac_cv_lib_util_openpty+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -18849,7 +18850,7 @@ else\n   ac_check_lib_save_LIBS=$LIBS\n LIBS=\"-lutil  $LIBS\"\n cat >conftest.$ac_ext <<_ACEOF\n-#line 18852 \"configure\"\n+#line 18853 \"configure\"\n #include \"confdefs.h\"\n \n /* Override any gcc2 internal prototype to avoid an error.  */\n@@ -18868,16 +18869,16 @@ openpty ();\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:18871: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:18872: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18874: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18875: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:18877: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:18878: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18880: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18881: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   ac_cv_lib_util_openpty=yes\n else\n@@ -18888,7 +18889,7 @@ fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n LIBS=$ac_check_lib_save_LIBS\n fi\n-echo \"$as_me:18891: result: $ac_cv_lib_util_openpty\" >&5\n+echo \"$as_me:18892: result: $ac_cv_lib_util_openpty\" >&5\n echo \"${ECHO_T}$ac_cv_lib_util_openpty\" >&6\n if test $ac_cv_lib_util_openpty = yes; then\n   cf_cv_lib_util=yes\n@@ -18896,7 +18897,7 @@ else\n   cf_cv_lib_util=no\n fi\n \n-echo \"$as_me:18899: checking for openpty header\" >&5\n+echo \"$as_me:18900: checking for openpty header\" >&5\n echo $ECHO_N \"checking for openpty header... $ECHO_C\" >&6\n if test \"${cf_cv_func_openpty+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -18923,7 +18924,7 @@ LIBS=\"$cf_add_libs\"\n \tfor cf_header in pty.h libutil.h util.h\n \tdo\n \tcat >conftest.$ac_ext <<_ACEOF\n-#line 18926 \"configure\"\n+#line 18927 \"configure\"\n #include \"confdefs.h\"\n \n #include <$cf_header>\n@@ -18940,16 +18941,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:18943: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:18944: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18946: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18947: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:18949: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:18950: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18952: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18953: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n \n \t\tcf_cv_func_openpty=$cf_header\n@@ -18967,7 +18968,7 @@ rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n \tLIBS=\"$cf_save_LIBS\"\n \n fi\n-echo \"$as_me:18970: result: $cf_cv_func_openpty\" >&5\n+echo \"$as_me:18971: result: $cf_cv_func_openpty\" >&5\n echo \"${ECHO_T}$cf_cv_func_openpty\" >&6\n \n if test \"$cf_cv_func_openpty\" != no ; then\n@@ -19001,7 +19002,7 @@ TEST_LIBS=\"$cf_add_libs\"\n \tfi\n fi\n \n-echo \"$as_me:19004: checking for function curses_version\" >&5\n+echo \"$as_me:19005: checking for function curses_version\" >&5\n echo $ECHO_N \"checking for function curses_version... $ECHO_C\" >&6\n if test \"${cf_cv_func_curses_version+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -19011,7 +19012,7 @@ if test \"$cross_compiling\" = yes; then\n   cf_cv_func_curses_version=unknown\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 19014 \"configure\"\n+#line 19015 \"configure\"\n #include \"confdefs.h\"\n \n #include <${cf_cv_ncurses_header:-curses.h}>\n@@ -19024,15 +19025,15 @@ int main(void)\n \n _ACEOF\n rm -f conftest$ac_exeext\n-if { (eval echo \"$as_me:19027: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:19028: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19030: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19031: \\$? = $ac_status\" >&5\n   (exit $ac_status); } && { ac_try='./conftest$ac_exeext'\n-  { (eval echo \"$as_me:19032: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:19033: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19035: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19036: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_func_curses_version=yes\n \n@@ -19047,14 +19048,14 @@ rm -f core core.* *.core conftest$ac_exeext conftest.$ac_objext conftest.$ac_ext\n fi\n rm -f core\n fi\n-echo \"$as_me:19050: result: $cf_cv_func_curses_version\" >&5\n+echo \"$as_me:19051: result: $cf_cv_func_curses_version\" >&5\n echo \"${ECHO_T}$cf_cv_func_curses_version\" >&6\n test \"$cf_cv_func_curses_version\" = yes &&\n cat >>confdefs.h <<\\EOF\n #define HAVE_CURSES_VERSION 1\n EOF\n \n-echo \"$as_me:19057: checking for alternate character set array\" >&5\n+echo \"$as_me:19058: checking for alternate character set array\" >&5\n echo $ECHO_N \"checking for alternate character set array... $ECHO_C\" >&6\n if test \"${cf_cv_curses_acs_map+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -19064,7 +19065,7 @@ cf_cv_curses_acs_map=unknown\n for name in acs_map _acs_map __acs_map ${NCURSES_WRAP_PREFIX}acs_map\n do\n cat >conftest.$ac_ext <<_ACEOF\n-#line 19067 \"configure\"\n+#line 19068 \"configure\"\n #include \"confdefs.h\"\n \n #include <${cf_cv_ncurses_header:-curses.h}>\n@@ -19080,16 +19081,16 @@ $name['k'] = ACS_PLUS\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:19083: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:19084: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19086: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19087: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:19089: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:19090: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19092: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19093: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_curses_acs_map=$name; break\n else\n@@ -19100,7 +19101,7 @@ rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n done\n \n fi\n-echo \"$as_me:19103: result: $cf_cv_curses_acs_map\" >&5\n+echo \"$as_me:19104: result: $cf_cv_curses_acs_map\" >&5\n echo \"${ECHO_T}$cf_cv_curses_acs_map\" >&6\n \n test \"$cf_cv_curses_acs_map\" != unknown &&\n@@ -19110,7 +19111,7 @@ EOF\n \n if test \"$cf_enable_widec\" = yes; then\n \n-echo \"$as_me:19113: checking for wide alternate character set array\" >&5\n+echo \"$as_me:19114: checking for wide alternate character set array\" >&5\n echo $ECHO_N \"checking for wide alternate character set array... $ECHO_C\" >&6\n if test \"${cf_cv_curses_wacs_map+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -19120,7 +19121,7 @@ else\n \tfor name in wacs_map _wacs_map __wacs_map _nc_wacs _wacs_char\n \tdo\n \tcat >conftest.$ac_ext <<_ACEOF\n-#line 19123 \"configure\"\n+#line 19124 \"configure\"\n #include \"confdefs.h\"\n \n #ifndef _XOPEN_SOURCE_EXTENDED\n@@ -19136,16 +19137,16 @@ void *foo = &($name['k']); (void)foo\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:19139: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:19140: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19142: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19143: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:19145: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:19146: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19148: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19149: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_curses_wacs_map=$name\n \t break\n@@ -19156,7 +19157,7 @@ fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n \tdone\n fi\n-echo \"$as_me:19159: result: $cf_cv_curses_wacs_map\" >&5\n+echo \"$as_me:19160: result: $cf_cv_curses_wacs_map\" >&5\n echo \"${ECHO_T}$cf_cv_curses_wacs_map\" >&6\n \n test \"$cf_cv_curses_wacs_map\" != unknown &&\n@@ -19164,7 +19165,7 @@ cat >>confdefs.h <<EOF\n #define CURSES_WACS_ARRAY $cf_cv_curses_wacs_map\n EOF\n \n-echo \"$as_me:19167: checking for wide alternate character constants\" >&5\n+echo \"$as_me:19168: checking for wide alternate character constants\" >&5\n echo $ECHO_N \"checking for wide alternate character constants... $ECHO_C\" >&6\n if test \"${cf_cv_curses_wacs_symbols+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -19174,7 +19175,7 @@ cf_cv_curses_wacs_symbols=no\n if test \"$cf_cv_curses_wacs_map\" != unknown\n then\n \tcat >conftest.$ac_ext <<_ACEOF\n-#line 19177 \"configure\"\n+#line 19178 \"configure\"\n #include \"confdefs.h\"\n \n #ifndef _XOPEN_SOURCE_EXTENDED\n@@ -19191,16 +19192,16 @@ cchar_t *foo = WACS_PLUS;\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:19194: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:19195: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19197: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19198: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:19200: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:19201: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19203: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19204: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_curses_wacs_symbols=yes\n else\n@@ -19210,7 +19211,7 @@ fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n else\n \tcat >conftest.$ac_ext <<_ACEOF\n-#line 19213 \"configure\"\n+#line 19214 \"configure\"\n #include \"confdefs.h\"\n \n #ifndef _XOPEN_SOURCE_EXTENDED\n@@ -19226,16 +19227,16 @@ cchar_t *foo = WACS_PLUS; (void)foo\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:19229: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:19230: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19232: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19233: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:19235: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:19236: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19238: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19239: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_curses_wacs_symbols=yes\n else\n@@ -19246,7 +19247,7 @@ rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n fi\n \n fi\n-echo \"$as_me:19249: result: $cf_cv_curses_wacs_symbols\" >&5\n+echo \"$as_me:19250: result: $cf_cv_curses_wacs_symbols\" >&5\n echo \"${ECHO_T}$cf_cv_curses_wacs_symbols\" >&6\n \n test \"$cf_cv_curses_wacs_symbols\" != no &&\n@@ -19256,10 +19257,10 @@ EOF\n \n fi\n \n-echo \"$as_me:19259: checking for type attr_t in ${cf_cv_ncurses_header:-curses.h}\" >&5\n+echo \"$as_me:19260: checking for type attr_t in ${cf_cv_ncurses_header:-curses.h}\" >&5\n echo $ECHO_N \"checking for type attr_t in ${cf_cv_ncurses_header:-curses.h}... $ECHO_C\" >&6\n cat >conftest.$ac_ext <<_ACEOF\n-#line 19262 \"configure\"\n+#line 19263 \"configure\"\n #include \"confdefs.h\"\n \n #ifndef _XOPEN_SOURCE_EXTENDED\n@@ -19277,16 +19278,16 @@ attr_t foo\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:19280: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:19281: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19283: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19284: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:19286: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:19287: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19289: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19290: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_result=yes\n else\n@@ -19295,7 +19296,7 @@ cat conftest.$ac_ext >&5\n cf_result=no\n fi\n rm -f conftest.$ac_objext conftest.$ac_ext\n-echo \"$as_me:19298: result: $cf_result\" >&5\n+echo \"$as_me:19299: result: $cf_result\" >&5\n echo \"${ECHO_T}$cf_result\" >&6\n if test $cf_result = yes ; then\n \n@@ -19316,14 +19317,14 @@ fi\n if test \"$cf_enable_widec\" = yes; then\n \n # This is needed on Tru64 5.0 to declare mbstate_t\n-echo \"$as_me:19319: checking if we must include wchar.h to declare mbstate_t\" >&5\n+echo \"$as_me:19320: checking if we must include wchar.h to declare mbstate_t\" >&5\n echo $ECHO_N \"checking if we must include wchar.h to declare mbstate_t... $ECHO_C\" >&6\n if test \"${cf_cv_mbstate_t+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n \n cat >conftest.$ac_ext <<_ACEOF\n-#line 19326 \"configure\"\n+#line 19327 \"configure\"\n #include \"confdefs.h\"\n \n #include <stdlib.h>\n@@ -19341,23 +19342,23 @@ mbstate_t state\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:19344: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:19345: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19347: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19348: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:19350: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:19351: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19353: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19354: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_mbstate_t=no\n else\n   echo \"$as_me: failed program was:\" >&5\n cat conftest.$ac_ext >&5\n cat >conftest.$ac_ext <<_ACEOF\n-#line 19360 \"configure\"\n+#line 19361 \"configure\"\n #include \"confdefs.h\"\n \n #include <stdlib.h>\n@@ -19376,16 +19377,16 @@ mbstate_t value\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:19379: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:19380: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19382: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19383: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:19385: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:19386: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19388: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19389: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_mbstate_t=yes\n else\n@@ -19397,7 +19398,7 @@ rm -f conftest.$ac_objext conftest.$ac_ext\n fi\n rm -f conftest.$ac_objext conftest.$ac_ext\n fi\n-echo \"$as_me:19400: result: $cf_cv_mbstate_t\" >&5\n+echo \"$as_me:19401: result: $cf_cv_mbstate_t\" >&5\n echo \"${ECHO_T}$cf_cv_mbstate_t\" >&6\n \n if test \"$cf_cv_mbstate_t\" = yes ; then\n@@ -19420,14 +19421,14 @@ if test \"$cf_cv_mbstate_t\" != unknown ; then\n fi\n \n # This is needed on Tru64 5.0 to declare wchar_t\n-echo \"$as_me:19423: checking if we must include wchar.h to declare wchar_t\" >&5\n+echo \"$as_me:19424: checking if we must include wchar.h to declare wchar_t\" >&5\n echo $ECHO_N \"checking if we must include wchar.h to declare wchar_t... $ECHO_C\" >&6\n if test \"${cf_cv_wchar_t+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n \n cat >conftest.$ac_ext <<_ACEOF\n-#line 19430 \"configure\"\n+#line 19431 \"configure\"\n #include \"confdefs.h\"\n \n #include <stdlib.h>\n@@ -19445,23 +19446,23 @@ wchar_t state\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:19448: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:19449: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19451: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19452: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:19454: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:19455: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19457: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19458: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_wchar_t=no\n else\n   echo \"$as_me: failed program was:\" >&5\n cat conftest.$ac_ext >&5\n cat >conftest.$ac_ext <<_ACEOF\n-#line 19464 \"configure\"\n+#line 19465 \"configure\"\n #include \"confdefs.h\"\n \n #include <stdlib.h>\n@@ -19480,16 +19481,16 @@ wchar_t value\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:19483: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:19484: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19486: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19487: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:19489: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:19490: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19492: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19493: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_wchar_t=yes\n else\n@@ -19501,7 +19502,7 @@ rm -f conftest.$ac_objext conftest.$ac_ext\n fi\n rm -f conftest.$ac_objext conftest.$ac_ext\n fi\n-echo \"$as_me:19504: result: $cf_cv_wchar_t\" >&5\n+echo \"$as_me:19505: result: $cf_cv_wchar_t\" >&5\n echo \"${ECHO_T}$cf_cv_wchar_t\" >&6\n \n if test \"$cf_cv_wchar_t\" = yes ; then\n@@ -19524,14 +19525,14 @@ if test \"$cf_cv_wchar_t\" != unknown ; then\n fi\n \n # This is needed on Tru64 5.0 to declare wint_t\n-echo \"$as_me:19527: checking if we must include wchar.h to declare wint_t\" >&5\n+echo \"$as_me:19528: checking if we must include wchar.h to declare wint_t\" >&5\n echo $ECHO_N \"checking if we must include wchar.h to declare wint_t... $ECHO_C\" >&6\n if test \"${cf_cv_wint_t+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n \n cat >conftest.$ac_ext <<_ACEOF\n-#line 19534 \"configure\"\n+#line 19535 \"configure\"\n #include \"confdefs.h\"\n \n #include <stdlib.h>\n@@ -19549,23 +19550,23 @@ wint_t state\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:19552: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:19553: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19555: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19556: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:19558: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:19559: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19561: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19562: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_wint_t=no\n else\n   echo \"$as_me: failed program was:\" >&5\n cat conftest.$ac_ext >&5\n cat >conftest.$ac_ext <<_ACEOF\n-#line 19568 \"configure\"\n+#line 19569 \"configure\"\n #include \"confdefs.h\"\n \n #include <stdlib.h>\n@@ -19584,16 +19585,16 @@ wint_t value\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:19587: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:19588: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19590: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19591: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:19593: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:19594: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19596: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19597: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_wint_t=yes\n else\n@@ -19605,7 +19606,7 @@ rm -f conftest.$ac_objext conftest.$ac_ext\n fi\n rm -f conftest.$ac_objext conftest.$ac_ext\n fi\n-echo \"$as_me:19608: result: $cf_cv_wint_t\" >&5\n+echo \"$as_me:19609: result: $cf_cv_wint_t\" >&5\n echo \"${ECHO_T}$cf_cv_wint_t\" >&6\n \n if test \"$cf_cv_wint_t\" = yes ; then\n@@ -19629,10 +19630,10 @@ fi\n \n \tif test \"$NCURSES_OK_MBSTATE_T\" = 0 ; then\n \n-echo \"$as_me:19632: checking for type mbstate_t in ${cf_cv_ncurses_header:-curses.h}\" >&5\n+echo \"$as_me:19633: checking for type mbstate_t in ${cf_cv_ncurses_header:-curses.h}\" >&5\n echo $ECHO_N \"checking for type mbstate_t in ${cf_cv_ncurses_header:-curses.h}... $ECHO_C\" >&6\n cat >conftest.$ac_ext <<_ACEOF\n-#line 19635 \"configure\"\n+#line 19636 \"configure\"\n #include \"confdefs.h\"\n \n #ifndef _XOPEN_SOURCE_EXTENDED\n@@ -19650,16 +19651,16 @@ mbstate_t foo\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:19653: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:19654: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19656: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19657: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:19659: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:19660: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19662: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19663: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_result=yes\n else\n@@ -19668,7 +19669,7 @@ cat conftest.$ac_ext >&5\n cf_result=no\n fi\n rm -f conftest.$ac_objext conftest.$ac_ext\n-echo \"$as_me:19671: result: $cf_result\" >&5\n+echo \"$as_me:19672: result: $cf_result\" >&5\n echo \"${ECHO_T}$cf_result\" >&6\n if test $cf_result = yes ; then\n \n@@ -19690,10 +19691,10 @@ fi\n \n \tif test \"$NCURSES_OK_WCHAR_T\" = 0 ; then\n \n-echo \"$as_me:19693: checking for type wchar_t in ${cf_cv_ncurses_header:-curses.h}\" >&5\n+echo \"$as_me:19694: checking for type wchar_t in ${cf_cv_ncurses_header:-curses.h}\" >&5\n echo $ECHO_N \"checking for type wchar_t in ${cf_cv_ncurses_header:-curses.h}... $ECHO_C\" >&6\n cat >conftest.$ac_ext <<_ACEOF\n-#line 19696 \"configure\"\n+#line 19697 \"configure\"\n #include \"confdefs.h\"\n \n #ifndef _XOPEN_SOURCE_EXTENDED\n@@ -19711,16 +19712,16 @@ wchar_t foo\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:19714: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:19715: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19717: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19718: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:19720: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:19721: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19723: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19724: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_result=yes\n else\n@@ -19729,7 +19730,7 @@ cat conftest.$ac_ext >&5\n cf_result=no\n fi\n rm -f conftest.$ac_objext conftest.$ac_ext\n-echo \"$as_me:19732: result: $cf_result\" >&5\n+echo \"$as_me:19733: result: $cf_result\" >&5\n echo \"${ECHO_T}$cf_result\" >&6\n if test $cf_result = yes ; then\n \n@@ -19751,10 +19752,10 @@ fi\n \n \tif test \"$NCURSES_OK_WINT_T\" = 0 ; then\n \n-echo \"$as_me:19754: checking for type wint_t in ${cf_cv_ncurses_header:-curses.h}\" >&5\n+echo \"$as_me:19755: checking for type wint_t in ${cf_cv_ncurses_header:-curses.h}\" >&5\n echo $ECHO_N \"checking for type wint_t in ${cf_cv_ncurses_header:-curses.h}... $ECHO_C\" >&6\n cat >conftest.$ac_ext <<_ACEOF\n-#line 19757 \"configure\"\n+#line 19758 \"configure\"\n #include \"confdefs.h\"\n \n #ifndef _XOPEN_SOURCE_EXTENDED\n@@ -19772,16 +19773,16 @@ wint_t foo\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:19775: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:19776: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19778: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19779: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:19781: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:19782: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19784: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19785: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_result=yes\n else\n@@ -19790,7 +19791,7 @@ cat conftest.$ac_ext >&5\n cf_result=no\n fi\n rm -f conftest.$ac_objext conftest.$ac_ext\n-echo \"$as_me:19793: result: $cf_result\" >&5\n+echo \"$as_me:19794: result: $cf_result\" >&5\n echo \"${ECHO_T}$cf_result\" >&6\n if test $cf_result = yes ; then\n \n@@ -19819,11 +19820,11 @@ boolnames \\\n boolfnames \\\n ttytype\n do\n-echo \"$as_me:19822: checking for data $cf_data declaration in ${cf_cv_ncurses_header:-curses.h}\" >&5\n+echo \"$as_me:19823: checking for data $cf_data declaration in ${cf_cv_ncurses_header:-curses.h}\" >&5\n echo $ECHO_N \"checking for data $cf_data declaration in ${cf_cv_ncurses_header:-curses.h}... $ECHO_C\" >&6\n \n cat >conftest.$ac_ext <<_ACEOF\n-#line 19826 \"configure\"\n+#line 19827 \"configure\"\n #include \"confdefs.h\"\n \n #ifdef HAVE_XCURSES\n@@ -19856,16 +19857,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:19859: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:19860: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19862: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19863: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:19865: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:19866: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19868: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19869: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_result=yes\n \n@@ -19875,7 +19876,7 @@ cat conftest.$ac_ext >&5\n cf_result=no\n fi\n rm -f conftest.$ac_objext conftest.$ac_ext\n-echo \"$as_me:19878: result: $cf_result\" >&5\n+echo \"$as_me:19879: result: $cf_result\" >&5\n echo \"${ECHO_T}$cf_result\" >&6\n \n if test $cf_result = yes ; then\n@@ -19887,14 +19888,14 @@ cf_result=`echo \"have_curses_data_$cf_data\" | sed y%abcdefghijklmnopqrstuvwxyz./\n EOF\n \n else\n-\techo \"$as_me:19890: checking for data $cf_data in library\" >&5\n+\techo \"$as_me:19891: checking for data $cf_data in library\" >&5\n echo $ECHO_N \"checking for data $cf_data in library... $ECHO_C\" >&6\n \t# BSD linkers insist on making weak linkage, but resolve at runtime.\n \tif test \"$cross_compiling\" = yes; then\n \n \t# cross-compiling\n \tcat >conftest.$ac_ext <<_ACEOF\n-#line 19897 \"configure\"\n+#line 19898 \"configure\"\n #include \"confdefs.h\"\n \n #ifdef HAVE_XCURSES\n@@ -19933,16 +19934,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:19936: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:19937: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19939: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19940: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:19942: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:19943: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19945: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19946: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_result=yes\n else\n@@ -19954,7 +19955,7 @@ rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n \n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 19957 \"configure\"\n+#line 19958 \"configure\"\n #include \"confdefs.h\"\n \n #ifdef HAVE_XCURSES\n@@ -19986,15 +19987,15 @@ int main(void)\n }\n _ACEOF\n rm -f conftest$ac_exeext\n-if { (eval echo \"$as_me:19989: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:19990: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19992: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19993: \\$? = $ac_status\" >&5\n   (exit $ac_status); } && { ac_try='./conftest$ac_exeext'\n-  { (eval echo \"$as_me:19994: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:19995: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19997: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19998: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_result=yes\n \n@@ -20006,7 +20007,7 @@ cf_result=no\n fi\n rm -f core core.* *.core conftest$ac_exeext conftest.$ac_objext conftest.$ac_ext\n fi\n-\techo \"$as_me:20009: result: $cf_result\" >&5\n+\techo \"$as_me:20010: result: $cf_result\" >&5\n echo \"${ECHO_T}$cf_result\" >&6\n \tif test $cf_result = yes ; then\n \n@@ -20023,7 +20024,7 @@ done\n \n if ( test \"$GCC\" = yes || test \"$GXX\" = yes )\n then\n-echo \"$as_me:20026: checking if you want to turn on gcc warnings\" >&5\n+echo \"$as_me:20027: checking if you want to turn on gcc warnings\" >&5\n echo $ECHO_N \"checking if you want to turn on gcc warnings... $ECHO_C\" >&6\n \n # Check whether --enable-warnings or --disable-warnings was given.\n@@ -20040,7 +20041,7 @@ else\n \twith_warnings=no\n \n fi;\n-echo \"$as_me:20043: result: $with_warnings\" >&5\n+echo \"$as_me:20044: result: $with_warnings\" >&5\n echo \"${ECHO_T}$with_warnings\" >&6\n if test \"$with_warnings\" = \"yes\"\n then\n@@ -20063,10 +20064,10 @@ cat > conftest.i <<EOF\n EOF\n if test \"$GCC\" = yes\n then\n-\t{ echo \"$as_me:20066: checking for $CC __attribute__ directives...\" >&5\n+\t{ echo \"$as_me:20067: checking for $CC __attribute__ directives...\" >&5\n echo \"$as_me: checking for $CC __attribute__ directives...\" >&6;}\n cat > conftest.$ac_ext <<EOF\n-#line 20069 \"${as_me:-configure}\"\n+#line 20070 \"${as_me:-configure}\"\n #include \"confdefs.h\"\n #include \"conftest.h\"\n #include \"conftest.i\"\n@@ -20115,12 +20116,12 @@ EOF\n \t\t\t;;\n \t\tesac\n \n-\t\tif { (eval echo \"$as_me:20118: \\\"$ac_compile\\\"\") >&5\n+\t\tif { (eval echo \"$as_me:20119: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20121: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20122: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; then\n-\t\t\ttest -n \"$verbose\" && echo \"$as_me:20123: result: ... $cf_attribute\" >&5\n+\t\t\ttest -n \"$verbose\" && echo \"$as_me:20124: result: ... $cf_attribute\" >&5\n echo \"${ECHO_T}... $cf_attribute\" >&6\n \t\t\tcat conftest.h >>confdefs.h\n \t\t\tcase $cf_attribute in\n@@ -20198,7 +20199,7 @@ do\n done\n \n cat >conftest.$ac_ext <<_ACEOF\n-#line 20201 \"configure\"\n+#line 20202 \"configure\"\n #include \"confdefs.h\"\n \n #include <stdlib.h>\n@@ -20213,26 +20214,26 @@ String foo = malloc(1); (void)foo\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:20216: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:20217: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20219: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20220: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:20222: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:20223: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20225: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20226: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n \n-echo \"$as_me:20228: checking for X11/Xt const-feature\" >&5\n+echo \"$as_me:20229: checking for X11/Xt const-feature\" >&5\n echo $ECHO_N \"checking for X11/Xt const-feature... $ECHO_C\" >&6\n if test \"${cf_cv_const_x_string+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n \n \tcat >conftest.$ac_ext <<_ACEOF\n-#line 20235 \"configure\"\n+#line 20236 \"configure\"\n #include \"confdefs.h\"\n \n #define _CONST_X_STRING\t/* X11R7.8 (perhaps) */\n@@ -20249,16 +20250,16 @@ String foo = malloc(1); *foo = 0\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:20252: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:20253: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20255: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20256: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:20258: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:20259: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20261: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20262: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n \n \t\t\tcf_cv_const_x_string=no\n@@ -20273,7 +20274,7 @@ fi\n rm -f conftest.$ac_objext conftest.$ac_ext\n \n fi\n-echo \"$as_me:20276: result: $cf_cv_const_x_string\" >&5\n+echo \"$as_me:20277: result: $cf_cv_const_x_string\" >&5\n echo \"${ECHO_T}$cf_cv_const_x_string\" >&6\n \n LIBS=\"$cf_save_LIBS_CF_CONST_X_STRING\"\n@@ -20302,7 +20303,7 @@ fi\n rm -f conftest.$ac_objext conftest.$ac_ext\n  fi\n cat > conftest.$ac_ext <<EOF\n-#line 20305 \"${as_me:-configure}\"\n+#line 20306 \"${as_me:-configure}\"\n int main(int argc, char *argv[]) { return (argv[argc-1] == 0) ; }\n EOF\n if test \"$INTEL_COMPILER\" = yes\n@@ -20318,7 +20319,7 @@ then\n # remark #981: operands are evaluated in unspecified order\n # warning #279: controlling expression is constant\n \n-\t{ echo \"$as_me:20321: checking for $CC warning options...\" >&5\n+\t{ echo \"$as_me:20322: checking for $CC warning options...\" >&5\n echo \"$as_me: checking for $CC warning options...\" >&6;}\n \tcf_save_CFLAGS=\"$CFLAGS\"\n \tEXTRA_CFLAGS=\"-Wall\"\n@@ -20334,12 +20335,12 @@ echo \"$as_me: checking for $CC warning options...\" >&6;}\n \t\twd981\n \tdo\n \t\tCFLAGS=\"$cf_save_CFLAGS $EXTRA_CFLAGS -$cf_opt\"\n-\t\tif { (eval echo \"$as_me:20337: \\\"$ac_compile\\\"\") >&5\n+\t\tif { (eval echo \"$as_me:20338: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20340: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20341: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; then\n-\t\t\ttest -n \"$verbose\" && echo \"$as_me:20342: result: ... -$cf_opt\" >&5\n+\t\t\ttest -n \"$verbose\" && echo \"$as_me:20343: result: ... -$cf_opt\" >&5\n echo \"${ECHO_T}... -$cf_opt\" >&6\n \t\t\tEXTRA_CFLAGS=\"$EXTRA_CFLAGS -$cf_opt\"\n \t\tfi\n@@ -20347,7 +20348,7 @@ echo \"${ECHO_T}... -$cf_opt\" >&6\n \tCFLAGS=\"$cf_save_CFLAGS\"\n elif test \"$GCC\" = yes && test \"$GCC_VERSION\" != \"unknown\"\n then\n-\t{ echo \"$as_me:20350: checking for $CC warning options...\" >&5\n+\t{ echo \"$as_me:20351: checking for $CC warning options...\" >&5\n echo \"$as_me: checking for $CC warning options...\" >&6;}\n \tcf_save_CFLAGS=\"$CFLAGS\"\n \tEXTRA_CFLAGS=\n@@ -20371,12 +20372,12 @@ echo \"$as_me: checking for $CC warning options...\" >&6;}\n \t\tWundef Wno-inline $cf_gcc_warnings $cf_warn_CONST Wno-unknown-pragmas\n \tdo\n \t\tCFLAGS=\"$cf_save_CFLAGS $EXTRA_CFLAGS -$cf_opt\"\n-\t\tif { (eval echo \"$as_me:20374: \\\"$ac_compile\\\"\") >&5\n+\t\tif { (eval echo \"$as_me:20375: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20377: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20378: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; then\n-\t\t\ttest -n \"$verbose\" && echo \"$as_me:20379: result: ... -$cf_opt\" >&5\n+\t\t\ttest -n \"$verbose\" && echo \"$as_me:20380: result: ... -$cf_opt\" >&5\n echo \"${ECHO_T}... -$cf_opt\" >&6\n \t\t\tcase $cf_opt in\n \t\t\t(Winline)\n@@ -20384,7 +20385,7 @@ echo \"${ECHO_T}... -$cf_opt\" >&6\n \t\t\t\t([34].*)\n \t\t\t\t\ttest -n \"$verbose\" && echo \"\tfeature is broken in gcc $GCC_VERSION\" 1>&6\n \n-echo \"${as_me:-configure}:20387: testing feature is broken in gcc $GCC_VERSION ...\" 1>&5\n+echo \"${as_me:-configure}:20388: testing feature is broken in gcc $GCC_VERSION ...\" 1>&5\n \n \t\t\t\t\tcontinue;;\n \t\t\t\tesac\n@@ -20394,7 +20395,7 @@ echo \"${as_me:-configure}:20387: testing feature is broken in gcc $GCC_VERSION .\n \t\t\t\t([12].*)\n \t\t\t\t\ttest -n \"$verbose\" && echo \"\tfeature is broken in gcc $GCC_VERSION\" 1>&6\n \n-echo \"${as_me:-configure}:20397: testing feature is broken in gcc $GCC_VERSION ...\" 1>&5\n+echo \"${as_me:-configure}:20398: testing feature is broken in gcc $GCC_VERSION ...\" 1>&5\n \n \t\t\t\t\tcontinue;;\n \t\t\t\tesac\n@@ -20410,7 +20411,7 @@ rm -rf conftest*\n fi\n fi\n \n-echo \"$as_me:20413: checking if you want to use dmalloc for testing\" >&5\n+echo \"$as_me:20414: checking if you want to use dmalloc for testing\" >&5\n echo $ECHO_N \"checking if you want to use dmalloc for testing... $ECHO_C\" >&6\n \n # Check whether --with-dmalloc or --without-dmalloc was given.\n@@ -20427,7 +20428,7 @@ EOF\n else\n   with_dmalloc=\n fi;\n-echo \"$as_me:20430: result: ${with_dmalloc:-no}\" >&5\n+echo \"$as_me:20431: result: ${with_dmalloc:-no}\" >&5\n echo \"${ECHO_T}${with_dmalloc:-no}\" >&6\n \n case .$with_cflags in\n@@ -20541,23 +20542,23 @@ fi\n esac\n \n if test \"$with_dmalloc\" = yes ; then\n-\techo \"$as_me:20544: checking for dmalloc.h\" >&5\n+\techo \"$as_me:20545: checking for dmalloc.h\" >&5\n echo $ECHO_N \"checking for dmalloc.h... $ECHO_C\" >&6\n if test \"${ac_cv_header_dmalloc_h+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 20550 \"configure\"\n+#line 20551 \"configure\"\n #include \"confdefs.h\"\n #include <dmalloc.h>\n _ACEOF\n-if { (eval echo \"$as_me:20554: \\\"$ac_cpp conftest.$ac_ext\\\"\") >&5\n+if { (eval echo \"$as_me:20555: \\\"$ac_cpp conftest.$ac_ext\\\"\") >&5\n   (eval $ac_cpp conftest.$ac_ext) 2>conftest.er1\n   ac_status=$?\n   egrep -v '^ *\\+' conftest.er1 >conftest.err\n   rm -f conftest.er1\n   cat conftest.err >&5\n-  echo \"$as_me:20560: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20561: \\$? = $ac_status\" >&5\n   (exit $ac_status); } >/dev/null; then\n   if test -s conftest.err; then\n     ac_cpp_err=$ac_c_preproc_warn_flag\n@@ -20576,11 +20577,11 @@ else\n fi\n rm -f conftest.err conftest.$ac_ext\n fi\n-echo \"$as_me:20579: result: $ac_cv_header_dmalloc_h\" >&5\n+echo \"$as_me:20580: result: $ac_cv_header_dmalloc_h\" >&5\n echo \"${ECHO_T}$ac_cv_header_dmalloc_h\" >&6\n if test $ac_cv_header_dmalloc_h = yes; then\n \n-echo \"$as_me:20583: checking for dmalloc_debug in -ldmalloc\" >&5\n+echo \"$as_me:20584: checking for dmalloc_debug in -ldmalloc\" >&5\n echo $ECHO_N \"checking for dmalloc_debug in -ldmalloc... $ECHO_C\" >&6\n if test \"${ac_cv_lib_dmalloc_dmalloc_debug+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -20588,7 +20589,7 @@ else\n   ac_check_lib_save_LIBS=$LIBS\n LIBS=\"-ldmalloc  $LIBS\"\n cat >conftest.$ac_ext <<_ACEOF\n-#line 20591 \"configure\"\n+#line 20592 \"configure\"\n #include \"confdefs.h\"\n \n /* Override any gcc2 internal prototype to avoid an error.  */\n@@ -20607,16 +20608,16 @@ dmalloc_debug ();\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:20610: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:20611: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20613: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20614: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:20616: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:20617: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20619: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20620: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   ac_cv_lib_dmalloc_dmalloc_debug=yes\n else\n@@ -20627,7 +20628,7 @@ fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n LIBS=$ac_check_lib_save_LIBS\n fi\n-echo \"$as_me:20630: result: $ac_cv_lib_dmalloc_dmalloc_debug\" >&5\n+echo \"$as_me:20631: result: $ac_cv_lib_dmalloc_dmalloc_debug\" >&5\n echo \"${ECHO_T}$ac_cv_lib_dmalloc_dmalloc_debug\" >&6\n if test $ac_cv_lib_dmalloc_dmalloc_debug = yes; then\n   cat >>confdefs.h <<EOF\n@@ -20642,7 +20643,7 @@ fi\n \n fi\n \n-echo \"$as_me:20645: checking if you want to use dbmalloc for testing\" >&5\n+echo \"$as_me:20646: checking if you want to use dbmalloc for testing\" >&5\n echo $ECHO_N \"checking if you want to use dbmalloc for testing... $ECHO_C\" >&6\n \n # Check whether --with-dbmalloc or --without-dbmalloc was given.\n@@ -20659,7 +20660,7 @@ EOF\n else\n   with_dbmalloc=\n fi;\n-echo \"$as_me:20662: result: ${with_dbmalloc:-no}\" >&5\n+echo \"$as_me:20663: result: ${with_dbmalloc:-no}\" >&5\n echo \"${ECHO_T}${with_dbmalloc:-no}\" >&6\n \n case .$with_cflags in\n@@ -20773,23 +20774,23 @@ fi\n esac\n \n if test \"$with_dbmalloc\" = yes ; then\n-\techo \"$as_me:20776: checking for dbmalloc.h\" >&5\n+\techo \"$as_me:20777: checking for dbmalloc.h\" >&5\n echo $ECHO_N \"checking for dbmalloc.h... $ECHO_C\" >&6\n if test \"${ac_cv_header_dbmalloc_h+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 20782 \"configure\"\n+#line 20783 \"configure\"\n #include \"confdefs.h\"\n #include <dbmalloc.h>\n _ACEOF\n-if { (eval echo \"$as_me:20786: \\\"$ac_cpp conftest.$ac_ext\\\"\") >&5\n+if { (eval echo \"$as_me:20787: \\\"$ac_cpp conftest.$ac_ext\\\"\") >&5\n   (eval $ac_cpp conftest.$ac_ext) 2>conftest.er1\n   ac_status=$?\n   egrep -v '^ *\\+' conftest.er1 >conftest.err\n   rm -f conftest.er1\n   cat conftest.err >&5\n-  echo \"$as_me:20792: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20793: \\$? = $ac_status\" >&5\n   (exit $ac_status); } >/dev/null; then\n   if test -s conftest.err; then\n     ac_cpp_err=$ac_c_preproc_warn_flag\n@@ -20808,11 +20809,11 @@ else\n fi\n rm -f conftest.err conftest.$ac_ext\n fi\n-echo \"$as_me:20811: result: $ac_cv_header_dbmalloc_h\" >&5\n+echo \"$as_me:20812: result: $ac_cv_header_dbmalloc_h\" >&5\n echo \"${ECHO_T}$ac_cv_header_dbmalloc_h\" >&6\n if test $ac_cv_header_dbmalloc_h = yes; then\n \n-echo \"$as_me:20815: checking for debug_malloc in -ldbmalloc\" >&5\n+echo \"$as_me:20816: checking for debug_malloc in -ldbmalloc\" >&5\n echo $ECHO_N \"checking for debug_malloc in -ldbmalloc... $ECHO_C\" >&6\n if test \"${ac_cv_lib_dbmalloc_debug_malloc+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -20820,7 +20821,7 @@ else\n   ac_check_lib_save_LIBS=$LIBS\n LIBS=\"-ldbmalloc  $LIBS\"\n cat >conftest.$ac_ext <<_ACEOF\n-#line 20823 \"configure\"\n+#line 20824 \"configure\"\n #include \"confdefs.h\"\n \n /* Override any gcc2 internal prototype to avoid an error.  */\n@@ -20839,16 +20840,16 @@ debug_malloc ();\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:20842: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:20843: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20845: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20846: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:20848: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:20849: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20851: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20852: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   ac_cv_lib_dbmalloc_debug_malloc=yes\n else\n@@ -20859,7 +20860,7 @@ fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n LIBS=$ac_check_lib_save_LIBS\n fi\n-echo \"$as_me:20862: result: $ac_cv_lib_dbmalloc_debug_malloc\" >&5\n+echo \"$as_me:20863: result: $ac_cv_lib_dbmalloc_debug_malloc\" >&5\n echo \"${ECHO_T}$ac_cv_lib_dbmalloc_debug_malloc\" >&6\n if test $ac_cv_lib_dbmalloc_debug_malloc = yes; then\n   cat >>confdefs.h <<EOF\n@@ -20874,7 +20875,7 @@ fi\n \n fi\n \n-echo \"$as_me:20877: checking if you want to use valgrind for testing\" >&5\n+echo \"$as_me:20878: checking if you want to use valgrind for testing\" >&5\n echo $ECHO_N \"checking if you want to use valgrind for testing... $ECHO_C\" >&6\n \n # Check whether --with-valgrind or --without-valgrind was given.\n@@ -20891,7 +20892,7 @@ EOF\n else\n   with_valgrind=\n fi;\n-echo \"$as_me:20894: result: ${with_valgrind:-no}\" >&5\n+echo \"$as_me:20895: result: ${with_valgrind:-no}\" >&5\n echo \"${ECHO_T}${with_valgrind:-no}\" >&6\n \n case .$with_cflags in\n@@ -21004,7 +21005,7 @@ fi\n \t;;\n esac\n \n-echo \"$as_me:21007: checking if you want to perform memory-leak testing\" >&5\n+echo \"$as_me:21008: checking if you want to perform memory-leak testing\" >&5\n echo $ECHO_N \"checking if you want to perform memory-leak testing... $ECHO_C\" >&6\n \n # Check whether --enable-leaks or --disable-leaks was given.\n@@ -21014,7 +21015,7 @@ if test \"${enable_leaks+set}\" = set; then\n else\n   : ${with_no_leaks:=no}\n fi;\n-echo \"$as_me:21017: result: $with_no_leaks\" >&5\n+echo \"$as_me:21018: result: $with_no_leaks\" >&5\n echo \"${ECHO_T}$with_no_leaks\" >&6\n \n if test \"$with_no_leaks\" = yes ; then\n@@ -21032,7 +21033,7 @@ fi\n LD_RPATH_OPT=\n if test \"x$cf_cv_enable_rpath\" != xno\n then\n-\techo \"$as_me:21035: checking for an rpath option\" >&5\n+\techo \"$as_me:21036: checking for an rpath option\" >&5\n echo $ECHO_N \"checking for an rpath option... $ECHO_C\" >&6\n \tcase $cf_cv_system_name in\n \t(irix*)\n@@ -21063,12 +21064,12 @@ echo $ECHO_N \"checking for an rpath option... $ECHO_C\" >&6\n \t(*)\n \t\t;;\n \tesac\n-\techo \"$as_me:21066: result: $LD_RPATH_OPT\" >&5\n+\techo \"$as_me:21067: result: $LD_RPATH_OPT\" >&5\n echo \"${ECHO_T}$LD_RPATH_OPT\" >&6\n \n \tcase \"x$LD_RPATH_OPT\" in\n \t(x-R*)\n-\t\techo \"$as_me:21071: checking if we need a space after rpath option\" >&5\n+\t\techo \"$as_me:21072: checking if we need a space after rpath option\" >&5\n echo $ECHO_N \"checking if we need a space after rpath option... $ECHO_C\" >&6\n \t\tcf_save_LIBS=\"$LIBS\"\n \n@@ -21089,7 +21090,7 @@ done\n LIBS=\"$cf_add_libs\"\n \n \t\tcat >conftest.$ac_ext <<_ACEOF\n-#line 21092 \"configure\"\n+#line 21093 \"configure\"\n #include \"confdefs.h\"\n \n int\n@@ -21101,16 +21102,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:21104: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:21105: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21107: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21108: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:21110: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:21111: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21113: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21114: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_rpath_space=no\n else\n@@ -21120,14 +21121,14 @@ cf_rpath_space=yes\n fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n \t\tLIBS=\"$cf_save_LIBS\"\n-\t\techo \"$as_me:21123: result: $cf_rpath_space\" >&5\n+\t\techo \"$as_me:21124: result: $cf_rpath_space\" >&5\n echo \"${ECHO_T}$cf_rpath_space\" >&6\n \t\ttest \"$cf_rpath_space\" = yes && LD_RPATH_OPT=\"$LD_RPATH_OPT \"\n \t\t;;\n \tesac\n fi\n \n-echo \"$as_me:21130: checking if rpath-hack should be disabled\" >&5\n+echo \"$as_me:21131: checking if rpath-hack should be disabled\" >&5\n echo $ECHO_N \"checking if rpath-hack should be disabled... $ECHO_C\" >&6\n \n # Check whether --enable-rpath-hack or --disable-rpath-hack was given.\n@@ -21144,21 +21145,21 @@ else\n \tcf_disable_rpath_hack=no\n \n fi;\n-echo \"$as_me:21147: result: $cf_disable_rpath_hack\" >&5\n+echo \"$as_me:21148: result: $cf_disable_rpath_hack\" >&5\n echo \"${ECHO_T}$cf_disable_rpath_hack\" >&6\n if test \"$cf_disable_rpath_hack\" = no ; then\n \n-echo \"$as_me:21151: checking for updated LDFLAGS\" >&5\n+echo \"$as_me:21152: checking for updated LDFLAGS\" >&5\n echo $ECHO_N \"checking for updated LDFLAGS... $ECHO_C\" >&6\n if test -n \"$LD_RPATH_OPT\" ; then\n-\techo \"$as_me:21154: result: maybe\" >&5\n+\techo \"$as_me:21155: result: maybe\" >&5\n echo \"${ECHO_T}maybe\" >&6\n \n \tfor ac_prog in ldd\n do\n   # Extract the first word of \"$ac_prog\", so it can be a program name with args.\n set dummy $ac_prog; ac_word=$2\n-echo \"$as_me:21161: checking for $ac_word\" >&5\n+echo \"$as_me:21162: checking for $ac_word\" >&5\n echo $ECHO_N \"checking for $ac_word... $ECHO_C\" >&6\n if test \"${ac_cv_prog_cf_ldd_prog+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -21173,7 +21174,7 @@ for ac_dir in $ac_dummy; do\n   test -z \"$ac_dir\" && ac_dir=.\n   $as_executable_p \"$ac_dir/$ac_word\" || continue\n ac_cv_prog_cf_ldd_prog=\"$ac_prog\"\n-echo \"$as_me:21176: found $ac_dir/$ac_word\" >&5\n+echo \"$as_me:21177: found $ac_dir/$ac_word\" >&5\n break\n done\n \n@@ -21181,10 +21182,10 @@ fi\n fi\n cf_ldd_prog=$ac_cv_prog_cf_ldd_prog\n if test -n \"$cf_ldd_prog\"; then\n-  echo \"$as_me:21184: result: $cf_ldd_prog\" >&5\n+  echo \"$as_me:21185: result: $cf_ldd_prog\" >&5\n echo \"${ECHO_T}$cf_ldd_prog\" >&6\n else\n-  echo \"$as_me:21187: result: no\" >&5\n+  echo \"$as_me:21188: result: no\" >&5\n echo \"${ECHO_T}no\" >&6\n fi\n \n@@ -21198,7 +21199,7 @@ test -n \"$cf_ldd_prog\" || cf_ldd_prog=\"no\"\n \t\tcf_rpath_oops=\n \n cat >conftest.$ac_ext <<_ACEOF\n-#line 21201 \"configure\"\n+#line 21202 \"configure\"\n #include \"confdefs.h\"\n #include <stdio.h>\n int\n@@ -21210,16 +21211,16 @@ printf(\"Hello\");\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:21213: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:21214: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21216: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21217: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:21219: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:21220: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21222: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21223: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_rpath_oops=`$cf_ldd_prog conftest$ac_exeext | fgrep ' not found' | sed -e 's% =>.*$%%' |sort | uniq`\n \t\t cf_rpath_list=`$cf_ldd_prog conftest$ac_exeext | fgrep / | sed -e 's%^.*[ \t]/%/%' -e 's%/[^/][^/]*$%%' |sort | uniq`\n@@ -21247,7 +21248,7 @@ rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n \t\t\t\t\tthen\n \t\t\t\t\t\ttest -n \"$verbose\" && echo \"\t...adding -L$cf_rpath_dir/lib to LDFLAGS for $cf_rpath_src\" 1>&6\n \n-echo \"${as_me:-configure}:21250: testing ...adding -L$cf_rpath_dir/lib to LDFLAGS for $cf_rpath_src ...\" 1>&5\n+echo \"${as_me:-configure}:21251: testing ...adding -L$cf_rpath_dir/lib to LDFLAGS for $cf_rpath_src ...\" 1>&5\n \n \t\t\t\t\t\tLDFLAGS=\"$LDFLAGS -L$cf_rpath_dir/lib\"\n \t\t\t\t\t\tbreak\n@@ -21259,11 +21260,11 @@ echo \"${as_me:-configure}:21250: testing ...adding -L$cf_rpath_dir/lib to LDFLAG\n \n \ttest -n \"$verbose\" && echo \"\t...checking EXTRA_LDFLAGS $EXTRA_LDFLAGS\" 1>&6\n \n-echo \"${as_me:-configure}:21262: testing ...checking EXTRA_LDFLAGS $EXTRA_LDFLAGS ...\" 1>&5\n+echo \"${as_me:-configure}:21263: testing ...checking EXTRA_LDFLAGS $EXTRA_LDFLAGS ...\" 1>&5\n \n test -n \"$verbose\" && echo \"\t...checking LDFLAGS $LDFLAGS\" 1>&6\n \n-echo \"${as_me:-configure}:21266: testing ...checking LDFLAGS $LDFLAGS ...\" 1>&5\n+echo \"${as_me:-configure}:21267: testing ...checking LDFLAGS $LDFLAGS ...\" 1>&5\n \n cf_rpath_dst=\n for cf_rpath_src in $LDFLAGS\n@@ -21300,7 +21301,7 @@ do\n \t\t\tthen\n \t\t\t\ttest -n \"$verbose\" && echo \"\t...Filter $cf_rpath_src ->$cf_rpath_tmp\" 1>&6\n \n-echo \"${as_me:-configure}:21303: testing ...Filter $cf_rpath_src ->$cf_rpath_tmp ...\" 1>&5\n+echo \"${as_me:-configure}:21304: testing ...Filter $cf_rpath_src ->$cf_rpath_tmp ...\" 1>&5\n \n \t\t\t\tEXTRA_LDFLAGS=\"$cf_rpath_tmp $EXTRA_LDFLAGS\"\n \t\t\tfi\n@@ -21313,11 +21314,11 @@ LDFLAGS=$cf_rpath_dst\n \n test -n \"$verbose\" && echo \"\t...checked LDFLAGS $LDFLAGS\" 1>&6\n \n-echo \"${as_me:-configure}:21316: testing ...checked LDFLAGS $LDFLAGS ...\" 1>&5\n+echo \"${as_me:-configure}:21317: testing ...checked LDFLAGS $LDFLAGS ...\" 1>&5\n \n test -n \"$verbose\" && echo \"\t...checking LIBS $LIBS\" 1>&6\n \n-echo \"${as_me:-configure}:21320: testing ...checking LIBS $LIBS ...\" 1>&5\n+echo \"${as_me:-configure}:21321: testing ...checking LIBS $LIBS ...\" 1>&5\n \n cf_rpath_dst=\n for cf_rpath_src in $LIBS\n@@ -21354,7 +21355,7 @@ do\n \t\t\tthen\n \t\t\t\ttest -n \"$verbose\" && echo \"\t...Filter $cf_rpath_src ->$cf_rpath_tmp\" 1>&6\n \n-echo \"${as_me:-configure}:21357: testing ...Filter $cf_rpath_src ->$cf_rpath_tmp ...\" 1>&5\n+echo \"${as_me:-configure}:21358: testing ...Filter $cf_rpath_src ->$cf_rpath_tmp ...\" 1>&5\n \n \t\t\t\tEXTRA_LDFLAGS=\"$cf_rpath_tmp $EXTRA_LDFLAGS\"\n \t\t\tfi\n@@ -21367,14 +21368,14 @@ LIBS=$cf_rpath_dst\n \n test -n \"$verbose\" && echo \"\t...checked LIBS $LIBS\" 1>&6\n \n-echo \"${as_me:-configure}:21370: testing ...checked LIBS $LIBS ...\" 1>&5\n+echo \"${as_me:-configure}:21371: testing ...checked LIBS $LIBS ...\" 1>&5\n \n \ttest -n \"$verbose\" && echo \"\t...checked EXTRA_LDFLAGS $EXTRA_LDFLAGS\" 1>&6\n \n-echo \"${as_me:-configure}:21374: testing ...checked EXTRA_LDFLAGS $EXTRA_LDFLAGS ...\" 1>&5\n+echo \"${as_me:-configure}:21375: testing ...checked EXTRA_LDFLAGS $EXTRA_LDFLAGS ...\" 1>&5\n \n else\n-\techo \"$as_me:21377: result: no\" >&5\n+\techo \"$as_me:21378: result: no\" >&5\n echo \"${ECHO_T}no\" >&6\n fi\n \n@@ -21464,7 +21465,7 @@ DEFS=-DHAVE_CONFIG_H\n : ${CONFIG_STATUS=./config.status}\n ac_clean_files_save=$ac_clean_files\n ac_clean_files=\"$ac_clean_files $CONFIG_STATUS\"\n-{ echo \"$as_me:21467: creating $CONFIG_STATUS\" >&5\n+{ echo \"$as_me:21468: creating $CONFIG_STATUS\" >&5\n echo \"$as_me: creating $CONFIG_STATUS\" >&6;}\n cat >$CONFIG_STATUS <<_ACEOF\n #! $SHELL\n@@ -21640,7 +21641,7 @@ cat >>$CONFIG_STATUS <<\\EOF\n     echo \"$ac_cs_version\"; exit 0 ;;\n   --he | --h)\n     # Conflict between --help and --header\n-    { { echo \"$as_me:21643: error: ambiguous option: $1\n+    { { echo \"$as_me:21644: error: ambiguous option: $1\n Try \\`$0 --help' for more information.\" >&5\n echo \"$as_me: error: ambiguous option: $1\n Try \\`$0 --help' for more information.\" >&2;}\n@@ -21659,7 +21660,7 @@ Try \\`$0 --help' for more information.\" >&2;}\n     ac_need_defaults=false;;\n \n   # This is an error.\n-  -*) { { echo \"$as_me:21662: error: unrecognized option: $1\n+  -*) { { echo \"$as_me:21663: error: unrecognized option: $1\n Try \\`$0 --help' for more information.\" >&5\n echo \"$as_me: error: unrecognized option: $1\n Try \\`$0 --help' for more information.\" >&2;}\n@@ -21709,7 +21710,7 @@ do\n   \"Makefile\" ) CONFIG_FILES=\"$CONFIG_FILES Makefile\" ;;\n   \"default\" ) CONFIG_COMMANDS=\"$CONFIG_COMMANDS default\" ;;\n   \"ncurses_cfg.h\" ) CONFIG_HEADERS=\"$CONFIG_HEADERS ncurses_cfg.h:ncurses_tst.hin\" ;;\n-  *) { { echo \"$as_me:21712: error: invalid argument: $ac_config_target\" >&5\n+  *) { { echo \"$as_me:21713: error: invalid argument: $ac_config_target\" >&5\n echo \"$as_me: error: invalid argument: $ac_config_target\" >&2;}\n    { (exit 1); exit 1; }; };;\n   esac\n@@ -22008,7 +22009,7 @@ done; }\n   esac\n \n   if test x\"$ac_file\" != x-; then\n-    { echo \"$as_me:22011: creating $ac_file\" >&5\n+    { echo \"$as_me:22012: creating $ac_file\" >&5\n echo \"$as_me: creating $ac_file\" >&6;}\n     rm -f \"$ac_file\"\n   fi\n@@ -22026,7 +22027,7 @@ echo \"$as_me: creating $ac_file\" >&6;}\n       -) echo $tmp/stdin ;;\n       [\\\\/$]*)\n          # Absolute (can't be DOS-style, as IFS=:)\n-         test -f \"$f\" || { { echo \"$as_me:22029: error: cannot find input file: $f\" >&5\n+         test -f \"$f\" || { { echo \"$as_me:22030: error: cannot find input file: $f\" >&5\n echo \"$as_me: error: cannot find input file: $f\" >&2;}\n    { (exit 1); exit 1; }; }\n          echo $f;;\n@@ -22039,7 +22040,7 @@ echo \"$as_me: error: cannot find input file: $f\" >&2;}\n            echo $srcdir/$f\n          else\n            # /dev/null tree\n-           { { echo \"$as_me:22042: error: cannot find input file: $f\" >&5\n+           { { echo \"$as_me:22043: error: cannot find input file: $f\" >&5\n echo \"$as_me: error: cannot find input file: $f\" >&2;}\n    { (exit 1); exit 1; }; }\n          fi;;\n@@ -22055,7 +22056,7 @@ cat >>$CONFIG_STATUS <<\\EOF\n       if test -n \"$ac_seen\"; then\n         ac_used=`grep '@datarootdir@' $ac_item`\n         if test -z \"$ac_used\"; then\n-          { echo \"$as_me:22058: WARNING: datarootdir was used implicitly but not set:\n+          { echo \"$as_me:22059: WARNING: datarootdir was used implicitly but not set:\n $ac_seen\" >&5\n echo \"$as_me: WARNING: datarootdir was used implicitly but not set:\n $ac_seen\" >&2;}\n@@ -22064,7 +22065,7 @@ $ac_seen\" >&2;}\n       fi\n       ac_seen=`grep '${datarootdir}' $ac_item`\n       if test -n \"$ac_seen\"; then\n-        { echo \"$as_me:22067: WARNING: datarootdir was used explicitly but not set:\n+        { echo \"$as_me:22068: WARNING: datarootdir was used explicitly but not set:\n $ac_seen\" >&5\n echo \"$as_me: WARNING: datarootdir was used explicitly but not set:\n $ac_seen\" >&2;}\n@@ -22101,7 +22102,7 @@ s,@INSTALL@,$ac_INSTALL,;t t\n             ac_init=`egrep '[ \t]*'$ac_name'[ \t]*=' $ac_file`\n             if test -z \"$ac_init\"; then\n               ac_seen=`echo \"$ac_seen\" |sed -e 's,^,'$ac_file':,'`\n-              { echo \"$as_me:22104: WARNING: Variable $ac_name is used but was not set:\n+              { echo \"$as_me:22105: WARNING: Variable $ac_name is used but was not set:\n $ac_seen\" >&5\n echo \"$as_me: WARNING: Variable $ac_name is used but was not set:\n $ac_seen\" >&2;}\n@@ -22112,7 +22113,7 @@ $ac_seen\" >&2;}\n     egrep -n '@[A-Z_][A-Z_0-9]+@' $ac_file >>$tmp/out\n     if test -s $tmp/out; then\n       ac_seen=`sed -e 's,^,'$ac_file':,' < $tmp/out`\n-      { echo \"$as_me:22115: WARNING: Some variables may not be substituted:\n+      { echo \"$as_me:22116: WARNING: Some variables may not be substituted:\n $ac_seen\" >&5\n echo \"$as_me: WARNING: Some variables may not be substituted:\n $ac_seen\" >&2;}\n@@ -22161,7 +22162,7 @@ for ac_file in : $CONFIG_HEADERS; do test \"x$ac_file\" = x: && continue\n   * )   ac_file_in=$ac_file.in ;;\n   esac\n \n-  test x\"$ac_file\" != x- && { echo \"$as_me:22164: creating $ac_file\" >&5\n+  test x\"$ac_file\" != x- && { echo \"$as_me:22165: creating $ac_file\" >&5\n echo \"$as_me: creating $ac_file\" >&6;}\n \n   # First look for the input files in the build tree, otherwise in the\n@@ -22172,7 +22173,7 @@ echo \"$as_me: creating $ac_file\" >&6;}\n       -) echo $tmp/stdin ;;\n       [\\\\/$]*)\n          # Absolute (can't be DOS-style, as IFS=:)\n-         test -f \"$f\" || { { echo \"$as_me:22175: error: cannot find input file: $f\" >&5\n+         test -f \"$f\" || { { echo \"$as_me:22176: error: cannot find input file: $f\" >&5\n echo \"$as_me: error: cannot find input file: $f\" >&2;}\n    { (exit 1); exit 1; }; }\n          echo $f;;\n@@ -22185,7 +22186,7 @@ echo \"$as_me: error: cannot find input file: $f\" >&2;}\n            echo $srcdir/$f\n          else\n            # /dev/null tree\n-           { { echo \"$as_me:22188: error: cannot find input file: $f\" >&5\n+           { { echo \"$as_me:22189: error: cannot find input file: $f\" >&5\n echo \"$as_me: error: cannot find input file: $f\" >&2;}\n    { (exit 1); exit 1; }; }\n          fi;;\n@@ -22243,7 +22244,7 @@ cat >>$CONFIG_STATUS <<\\EOF\n   rm -f $tmp/in\n   if test x\"$ac_file\" != x-; then\n     if cmp -s $ac_file $tmp/config.h 2>/dev/null; then\n-      { echo \"$as_me:22246: $ac_file is unchanged\" >&5\n+      { echo \"$as_me:22247: $ac_file is unchanged\" >&5\n echo \"$as_me: $ac_file is unchanged\" >&6;}\n     else\n       ac_dir=`$as_expr X\"$ac_file\" : 'X\\(.*[^/]\\)//*[^/][^/]*/*$' \\| \\\ndiff --git a/test/configure.in b/test/configure.in\nindex 87757d041..59ff30fe5 100644\n--- a/test/configure.in\n+++ b/test/configure.in\n@@ -29,7 +29,7 @@ dnl***************************************************************************\n dnl\n dnl Author: Thomas E. Dickey 1996-on\n dnl\n-dnl $Id: configure.in,v 1.158 2020/03/08 14:12:23 tom Exp $\n+dnl $Id: configure.in,v 1.159 2020/05/30 00:13:37 tom Exp $\n dnl This is a simple configuration-script for the ncurses test programs that\n dnl allows the test-directory to be separately configured against a reference\n dnl system (i.e., sysvr4 curses)\n@@ -256,6 +256,7 @@ CF_GETOPT_HEADER\n AC_CHECK_FUNCS( \\\n getopt \\\n gettimeofday \\\n+snprintf \\\n strstr \\\n tsearch \\\n )\ndiff --git a/test/dots.c b/test/dots.c\nindex 11fc1cfef..94d90a13f 100644\n--- a/test/dots.c\n+++ b/test/dots.c\n@@ -30,7 +30,7 @@\n /*\n  * Author: Thomas E. Dickey <dickey@clark.net> 1999\n  *\n- * $Id: dots.c,v 1.39 2020/05/10 00:31:03 tom Exp $\n+ * $Id: dots.c,v 1.40 2020/05/29 23:04:02 tom Exp $\n  *\n  * A simple demo of the terminfo interface.\n  */\n@@ -214,7 +214,8 @@ main(int argc,\n \t\ttputs(tparm2(set_a_foreground, z), 1, outc);\n \t    } else {\n \t\ttputs(tparm2(set_a_background, z), 1, outc);\n-\t\tnapms(s_option);\n+\t\tif (s_option)\n+\t\t    napms(s_option);\n \t    }\n \t} else if (VALID_STRING(exit_attribute_mode)\n \t\t   && VALID_STRING(enter_reverse_mode)) {\n@@ -222,7 +223,8 @@ main(int argc,\n \t\touts((ranf() > 0.6)\n \t\t     ? enter_reverse_mode\n \t\t     : exit_attribute_mode);\n-\t\tnapms(s_option);\n+\t\tif (s_option)\n+\t\t    napms(s_option);\n \t    }\n \t}\n \toutc(p);\ndiff --git a/test/dots_curses.c b/test/dots_curses.c\nindex 4754e98ab..e30a24ae3 100644\n--- a/test/dots_curses.c\n+++ b/test/dots_curses.c\n@@ -30,7 +30,7 @@\n /*\n  * Author: Thomas E. Dickey\n  *\n- * $Id: dots_curses.c,v 1.19 2020/05/10 00:31:59 tom Exp $\n+ * $Id: dots_curses.c,v 1.20 2020/05/29 23:04:02 tom Exp $\n  *\n  * A simple demo of the curses interface used for comparison with termcap.\n  */\n@@ -206,7 +206,8 @@ main(int argc, char *argv[])\n \t\tattron(COLOR_PAIR(mypair(fg, bg)));\n \t    } else {\n \t\tset_colors(fg, bg = z);\n-\t\tnapms(s_option);\n+\t\tif (s_option)\n+\t\t    napms(s_option);\n \t    }\n \t} else {\n \t    if (ranf() <= 0.01) {\n@@ -215,7 +216,8 @@ main(int argc, char *argv[])\n \t\t} else {\n \t\t    attroff(A_REVERSE);\n \t\t}\n-\t\tnapms(s_option);\n+\t\tif (s_option)\n+\t\t    napms(s_option);\n \t    }\n \t}\n \tAddCh(p);\ndiff --git a/test/dots_mvcur.c b/test/dots_mvcur.c\nindex 76176642d..a032124c1 100644\n--- a/test/dots_mvcur.c\n+++ b/test/dots_mvcur.c\n@@ -30,7 +30,7 @@\n /*\n  * Author: Thomas E. Dickey - 2007\n  *\n- * $Id: dots_mvcur.c,v 1.25 2020/05/10 00:32:11 tom Exp $\n+ * $Id: dots_mvcur.c,v 1.26 2020/05/29 23:04:02 tom Exp $\n  *\n  * A simple demo of the terminfo interface, and mvcur.\n  */\n@@ -228,7 +228,8 @@ main(int argc GCC_UNUSED,\n \t\ttputs(tparm2(set_a_foreground, z), 1, outc);\n \t    } else {\n \t\ttputs(tparm2(set_a_background, z), 1, outc);\n-\t\tnapms(s_option);\n+\t\tif (s_option)\n+\t\t    napms(s_option);\n \t    }\n \t} else if (VALID_STRING(exit_attribute_mode)\n \t\t   && VALID_STRING(enter_reverse_mode)) {\n@@ -236,7 +237,8 @@ main(int argc GCC_UNUSED,\n \t\touts((ranf() > 0.6)\n \t\t     ? enter_reverse_mode\n \t\t     : exit_attribute_mode);\n-\t\tnapms(s_option);\n+\t\tif (s_option)\n+\t\t    napms(s_option);\n \t    }\n \t}\n \toutc(p);\ndiff --git a/test/dots_termcap.c b/test/dots_termcap.c\nindex 0fc1a89e1..52749c754 100644\n--- a/test/dots_termcap.c\n+++ b/test/dots_termcap.c\n@@ -30,7 +30,7 @@\n /*\n  * Author: Thomas E. Dickey\n  *\n- * $Id: dots_termcap.c,v 1.23 2020/05/10 00:32:22 tom Exp $\n+ * $Id: dots_termcap.c,v 1.24 2020/05/29 23:04:02 tom Exp $\n  *\n  * A simple demo of the termcap interface.\n  */\n@@ -297,7 +297,8 @@ main(int argc, char *argv[])\n \t\ttputs(tgoto(t_AF, 0, z), 1, outc);\n \t    } else {\n \t\ttputs(tgoto(t_AB, 0, z), 1, outc);\n-\t\tmy_napms(s_option);\n+\t\tif (s_option)\n+\t\t    my_napms(s_option);\n \t    }\n \t} else if (VALID_STRING(t_me)\n \t\t   && VALID_STRING(t_mr)) {\n@@ -305,7 +306,8 @@ main(int argc, char *argv[])\n \t\touts((ranf() > 0.6)\n \t\t     ? t_mr\n \t\t     : t_me);\n-\t\tmy_napms(s_option);\n+\t\tif (s_option)\n+\t\t    my_napms(s_option);\n \t    }\n \t}\n \toutc(p);\ndiff --git a/test/dots_xcurses.c b/test/dots_xcurses.c\nindex a2aa8b926..d8fe80319 100644\n--- a/test/dots_xcurses.c\n+++ b/test/dots_xcurses.c\n@@ -30,7 +30,7 @@\n /*\n  * Author: Thomas E. Dickey\n  *\n- * $Id: dots_xcurses.c,v 1.22 2020/05/10 00:32:33 tom Exp $\n+ * $Id: dots_xcurses.c,v 1.23 2020/05/29 23:04:02 tom Exp $\n  *\n  * A simple demo of the wide-curses interface used for comparison with termcap.\n  */\n@@ -244,7 +244,8 @@ main(int argc, char *argv[])\n \t\tset_colors(fg = z, bg);\n \t    } else {\n \t\tset_colors(fg, bg = z);\n-\t\tnapms(s_option);\n+\t\tif (s_option)\n+\t\t    napms(s_option);\n \t    }\n \t} else {\n \t    if (ranf() <= 0.01) {\n@@ -253,7 +254,8 @@ main(int argc, char *argv[])\n \t\t} else {\n \t\t    attr_off(WA_REVERSE, NULL);\n \t\t}\n-\t\tnapms(s_option);\n+\t\tif (s_option)\n+\t\t    napms(s_option);\n \t    }\n \t}\n \twch[0] = (wchar_t) p;\ndiff --git a/test/modules b/test/modules\nindex 7fb9b1794..524a60004 100644\n--- a/test/modules\n+++ b/test/modules\n@@ -1,4 +1,4 @@\n-# $Id: modules,v 1.72 2020/03/21 16:09:48 tom Exp $\n+# $Id: modules,v 1.73 2020/05/29 23:27:44 tom Exp $\n ##############################################################################\n # Copyright 2018-2019,2020 Thomas E. Dickey                                  #\n # Copyright 1998-2016,2017 Free Software Foundation, Inc.                    #\n@@ -107,6 +107,7 @@ test_opaque\tprogs\t\t$(srcdir)\t$(HEADER_DEPS)\n test_setupterm\tprogs\t\t$(srcdir)\t$(HEADER_DEPS)\n test_sgr\tprogs\t\t$(srcdir)\t$(HEADER_DEPS)\n test_termattrs\tprogs\t\t$(srcdir)\t$(HEADER_DEPS)\n+test_tparm\tprogs\t\t$(srcdir)\t$(HEADER_DEPS)\n test_vid_puts\tprogs\t\t$(srcdir)\t$(HEADER_DEPS)\n test_vidputs\tprogs\t\t$(srcdir)\t$(HEADER_DEPS)\n testaddch\tprogs\t\t$(srcdir)\t$(HEADER_DEPS)\ndiff --git a/test/programs b/test/programs\nindex f6a48f3a6..b9faf99de 100644\n--- a/test/programs\n+++ b/test/programs\n@@ -1,4 +1,4 @@\n-# $Id: programs,v 1.46 2020/03/21 15:55:22 tom Exp $\n+# $Id: programs,v 1.47 2020/05/29 23:27:58 tom Exp $\n ##############################################################################\n # Copyright 2018-2019,2020 Thomas E. Dickey                                  #\n # Copyright 2006-2016,2017 Free Software Foundation, Inc.                    #\n@@ -102,6 +102,7 @@ test_opaque\t$(LDFLAGS_CURSES)\t$(LOCAL_LIBS)\ttest_opaque\n test_setupterm\t$(LDFLAGS_CURSES)\t$(LOCAL_LIBS)\ttest_setupterm\n test_sgr\t$(LDFLAGS_TINFO)\t$(LOCAL_LIBS)\ttest_sgr\n test_termattrs\t$(LDFLAGS_CURSES)\t$(LOCAL_LIBS)\ttest_termattrs\n+test_tparm\t$(LDFLAGS_TINFO)\t$(LOCAL_LIBS)\ttest_tparm\n test_vid_puts\t$(LDFLAGS_CURSES)\t$(LOCAL_LIBS)\ttest_vid_puts\n test_vidputs\t$(LDFLAGS_CURSES)\t$(LOCAL_LIBS)\ttest_vidputs\n testaddch\t$(LDFLAGS_CURSES)\t$(LOCAL_LIBS)\ttestaddch\ndiff --git a/test/test_tparm.c b/test/test_tparm.c\nnew file mode 100644\nindex 000000000..40ffc4fb1\n--- /dev/null\n+++ b/test/test_tparm.c\n@@ -0,0 +1,388 @@\n+/****************************************************************************\n+ * Copyright 2020 Thomas E. Dickey                                          *\n+ *                                                                          *\n+ * Permission is hereby granted, free of charge, to any person obtaining a  *\n+ * copy of this software and associated documentation files (the            *\n+ * \"Software\"), to deal in the Software without restriction, including      *\n+ * without limitation the rights to use, copy, modify, merge, publish,      *\n+ * distribute, distribute with modifications, sublicense, and/or sell       *\n+ * copies of the Software, and to permit persons to whom the Software is    *\n+ * furnished to do so, subject to the following conditions:                 *\n+ *                                                                          *\n+ * The above copyright notice and this permission notice shall be included  *\n+ * in all copies or substantial portions of the Software.                   *\n+ *                                                                          *\n+ * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS  *\n+ * OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF               *\n+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.   *\n+ * IN NO EVENT SHALL THE ABOVE COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,   *\n+ * DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR    *\n+ * OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR    *\n+ * THE USE OR OTHER DEALINGS IN THE SOFTWARE.                               *\n+ *                                                                          *\n+ * Except as contained in this notice, the name(s) of the above copyright   *\n+ * holders shall not be used in advertising or otherwise to promote the     *\n+ * sale, use or other dealings in this Software without prior written       *\n+ * authorization.                                                           *\n+ ****************************************************************************/\n+\n+/*\n+ * Author: Thomas E. Dickey\n+ *\n+ * $Id: test_tparm.c,v 1.4 2020/05/31 00:51:32 tom Exp $\n+ *\n+ * Exercise tparm, either for all possible capabilities with fixed parameters,\n+ * or one capability with all possible parameters.\n+ *\n+ * TODO: incorporate tic.h and _nc_tparm_analyze\n+ * TODO: optionally test tiparm\n+ * TODO: add checks/logic to handle \"%s\" in tparm\n+ */\n+#define USE_TINFO\n+#include <test.priv.h>\n+\n+static void failed(const char *) GCC_NORETURN;\n+\n+static void\n+failed(const char *msg)\n+{\n+    fprintf(stderr, \"%s\\n\", msg);\n+    ExitProgram(EXIT_FAILURE);\n+}\n+\n+#if HAVE_TIGETSTR\n+\n+static int a_opt;\n+static int v_opt;\n+\n+static int\n+isNumeric(char *source)\n+{\n+    char *next = 0;\n+    long value = strtol(source, &next, 0);\n+    int result = (next == 0 || next == source || *next != '\\0') ? 0 : 1;\n+    (void) value;\n+    return result;\n+}\n+\n+static char *\n+validate(const char *name)\n+{\n+    char *value = tigetstr(name);\n+    if (!VALID_STRING(value)) {\n+\tif (v_opt > 1) {\n+\t    printf(\"? %s %s\\n\",\n+\t\t   (value == ABSENT_STRING)\n+\t\t   ? \"absent\"\n+\t\t   : \"cancel\",\n+\t\t   name);\n+\t}\n+\tvalue = 0;\n+    }\n+    return value;\n+}\n+\n+static int\n+increment(int *all_parms, int *num_parms, int len_parms, int end_parms)\n+{\n+    int rc = 0;\n+    int n;\n+\n+    if (len_parms > 9)\n+\tlen_parms = 9;\n+\n+    if (end_parms < len_parms) {\n+\tif (all_parms[end_parms]++ >= num_parms[end_parms]) {\n+\t    all_parms[end_parms] = 0;\n+\t    increment(all_parms, num_parms, len_parms, end_parms + 1);\n+\t}\n+    }\n+    for (n = 0; n < len_parms; ++n) {\n+\tif (all_parms[n] != 0) {\n+\t    rc = 1;\n+\t    break;\n+\t}\n+    }\n+    /* return 1 until the vector resets to all 0's */\n+    return rc;\n+}\n+\n+static void\n+test_tparm(const char *name, int *number)\n+{\n+    char *format = tigetstr(name);\n+    if ((format = validate(name)) != 0) {\n+\tchar *result = tparm(format,\n+\t\t\t     number[0],\n+\t\t\t     number[1],\n+\t\t\t     number[2],\n+\t\t\t     number[3],\n+\t\t\t     number[4],\n+\t\t\t     number[5],\n+\t\t\t     number[6],\n+\t\t\t     number[7],\n+\t\t\t     number[8]);\n+\tif (v_opt > 1)\n+\t    printf(\".. %2d = %2d %2d %2d %2d %2d %2d %2d %2d %2d %s\\n\",\n+\t\t   result != 0 ? (int) strlen(result) : -1,\n+\t\t   number[0],\n+\t\t   number[1],\n+\t\t   number[2],\n+\t\t   number[3],\n+\t\t   number[4],\n+\t\t   number[5],\n+\t\t   number[6],\n+\t\t   number[7],\n+\t\t   number[8],\n+\t\t   name);\n+    }\n+}\n+\n+static void\n+usage(void)\n+{\n+    static const char *msg[] =\n+    {\n+\t\"Usage: test_tparm [options] [capability] [value1 [value2 [...]]]\",\n+\t\"\",\n+\t\"Print all distinct combinations of given capability.\",\n+\t\"\",\n+\t\"Options:\",\n+\t\" -T TERM  override $TERM; this may be a comma-separated list or \\\"-\\\"\",\n+\t\"          to read a list from standard-input\",\n+\t\" -a       if capability is given, test all combinations of values\",\n+\t\" -r NUM   repeat tests NUM times\",\n+\t\" -v       show values and results\",\n+    };\n+    unsigned n;\n+    for (n = 0; n < SIZEOF(msg); ++n) {\n+\tfprintf(stderr, \"%s\\n\", msg[n]);\n+    }\n+    ExitProgram(EXIT_FAILURE);\n+}\n+\n+#define PLURAL(n) n, (n != 1) ? \"s\" : \"\"\n+#define COLONS(n) (n >= 1) ? \":\" : \"\"\n+\n+int\n+main(int argc, char *argv[])\n+{\n+    int n;\n+    int r_run, t_run, n_run;\n+    char *old_term = getenv(\"TERM\");\n+    int r_opt = 1;\n+    char *t_opt = 0;\n+    int len_names = 0;\t\t/* cur # of items in all_names[] */\n+    int use_names = 10;\t\t/* max # of items in all_names[] */\n+    char **all_names = typeCalloc(char *, use_names);\n+    int all_parms[10];\t\t/* workspace for \"-a\" option */\n+    int len_terms = 0;\t\t/* cur # of items in all_terms[] */\n+    int use_terms = 10;\t\t/* max # of items in all_terms[] */\n+    char **all_terms = typeCalloc(char *, use_terms);\n+    int len_parms = 0;\t\t/* cur # of items in num_parms[], str_parms[] */\n+    int use_parms = argc + 10;\t/* max # of items in num_parms[], str_parms[] */\n+    int *num_parms = typeCalloc(int, use_parms);\n+    char **str_parms = typeCalloc(char *, use_parms);\n+\n+    if (all_names == 0 || all_terms == 0 || num_parms == 0 || str_parms == 0)\n+\tfailed(\"no memory\");\n+\n+    while ((n = getopt(argc, argv, \"T:ar:v\")) != -1) {\n+\tswitch (n) {\n+\tcase 'T':\n+\t    t_opt = optarg;\n+\t    break;\n+\tcase 'a':\n+\t    ++a_opt;\n+\t    break;\n+\tcase 'r':\n+\t    r_opt = atoi(optarg);\n+\t    break;\n+\tcase 'v':\n+\t    ++v_opt;\n+\t    break;\n+\tdefault:\n+\t    usage();\n+\t    break;\n+\t}\n+    }\n+\n+    /*\n+     * If there is a nonnumeric parameter after the options, use that as the\n+     * capability name.\n+     */\n+    if (optind < argc) {\n+\tif (!isNumeric(argv[optind])) {\n+\t    all_names[len_names++] = strdup(argv[optind++]);\n+\t}\n+    }\n+\n+    /*\n+     * Any remaining arguments must be possible parameter values.  If numeric,\n+     * and \"-a\" is not set, use those as the maximum values within which the\n+     * test parameters should vary.\n+     */\n+    while (optind < argc) {\n+\tif (isNumeric(argv[optind])) {\n+\t    char *dummy = 0;\n+\t    long value = strtol(argv[optind], &dummy, 0);\n+\t    num_parms[len_parms] = (int) value;\n+\t}\n+\tstr_parms[len_parms] = argv[optind];\n+\t++optind;\n+\t++len_parms;\n+    }\n+    for (n = len_parms; n < use_parms; ++n) {\n+\tstatic char dummy[1];\n+\tstr_parms[n] = dummy;\n+    }\n+    if (v_opt) {\n+\tprintf(\"%d parameter%s%s\\n\", PLURAL(len_parms), COLONS(len_parms));\n+\tfor (n = 0; n < len_parms; ++n) {\n+\t    printf(\" %d: %d (%s)\\n\", n + 1, num_parms[n], str_parms[n]);\n+\t}\n+    }\n+\n+    /*\n+     * Make a list of values for $TERM.  Accept \"-\" for standard input to\n+     * simplify scripting a check of the whole database.\n+     */\n+    old_term = strdup((old_term == 0) ? \"unknown\" : old_term);\n+    if (t_opt != 0) {\n+\tif (!strcmp(t_opt, \"-\")) {\n+\t    char buffer[BUFSIZ];\n+\t    while (fgets(buffer, sizeof(buffer) - 1, stdin) != 0) {\n+\t\tchar *s = buffer;\n+\t\tchar *t;\n+\t\twhile (isspace(UChar(s[0])))\n+\t\t    ++s;\n+\t\tt = s + strlen(s);\n+\t\twhile (t != s && isspace(UChar(t[-1])))\n+\t\t    *--t = '\\0';\n+\t\ts = strdup(s);\n+\t\tif (len_terms + 2 >= use_terms) {\n+\t\t    use_terms *= 2;\n+\t\t    all_terms = typeRealloc(char *, use_terms, all_terms);\n+\t\t    if (all_terms == 0)\n+\t\t\tfailed(\"no memory: all_terms\");\n+\t\t}\n+\t\tall_terms[len_terms++] = s;\n+\t    }\n+\t} else {\n+\t    char *s = t_opt;\n+\t    char *t;\n+\t    while ((t = strtok(s, \",\")) != 0) {\n+\t\ts = 0;\n+\t\tif (len_terms + 2 >= use_terms) {\n+\t\t    use_terms *= 2;\n+\t\t    all_terms = typeRealloc(char *, use_terms, all_terms);\n+\t\t    if (all_terms == 0)\n+\t\t\tfailed(\"no memory: all_terms\");\n+\t\t}\n+\t\tall_terms[len_terms++] = strdup(t);\n+\t    }\n+\t}\n+    } else {\n+\tall_terms[len_terms++] = strdup(old_term);\n+    }\n+    all_terms[len_terms] = 0;\n+    if (v_opt) {\n+\tprintf(\"%d term%s:\\n\", PLURAL(len_terms));\n+\tfor (n = 0; n < len_terms; ++n) {\n+\t    printf(\" %d: %s\\n\", n + 1, all_terms[n]);\n+\t}\n+    }\n+\n+    /*\n+     * If no capability name was selected, use the predefined list of string\n+     * capabilities.\n+     *\n+     * TODO: To address the \"other\" systems which do not follow SVr4,\n+     * just use the output from infocmp on $TERM.\n+     */\n+    if (len_names == 0) {\n+#if defined(HAVE_CURSES_DATA_BOOLNAMES) || defined(DECL_CURSES_DATA_BOOLNAMES)\n+\tfor (n = 0; strnames[n] != 0; ++n) {\n+\t    if (len_names + 2 >= use_names) {\n+\t\tuse_names *= 2;\n+\t\tall_names = typeRealloc(char *, use_names, all_names);\n+\t\tif (all_names == 0) {\n+\t\t    failed(\"no memory: all_names\");\n+\t\t}\n+\t    }\n+\t    all_names[len_names++] = strdup(strnames[n]);\n+\t}\n+#else\n+\tall_names[len_names++] = strdup(\"cup\");\n+\tall_names[len_names++] = strdup(\"sgr\");\n+#endif\n+    }\n+    all_names[len_names] = 0;\n+    if (v_opt) {\n+\tprintf(\"%d name%s%s\\n\", PLURAL(len_names), COLONS(len_names));\n+\tfor (n = 0; n < len_names; ++n) {\n+\t    printf(\" %d: %s\\n\", n + 1, all_names[n]);\n+\t}\n+    }\n+\n+    if (r_opt <= 0)\n+\tr_opt = 1;\n+\n+    for (r_run = 0; r_run < r_opt; ++r_run) {\n+\tfor (t_run = 0; t_run < len_terms; ++t_run) {\n+\t    int errs;\n+\n+\t    if (setupterm(all_terms[t_run], fileno(stdout), &errs) != OK) {\n+\t\tprintf(\"** skipping %s (errs:%d)\\n\", all_terms[t_run], errs);\n+\t    }\n+\n+\t    if (v_opt)\n+\t\tprintf(\"** testing %s\\n\", all_terms[t_run]);\n+\t    if (len_names == 1) {\n+\t\tif (a_opt) {\n+\t\t    /* for each combination of values */\n+\t\t    memset(all_parms, 0, sizeof(all_parms));\n+\t\t    do {\n+\t\t\ttest_tparm(all_names[0], all_parms);\n+\t\t    }\n+\t\t    while (increment(all_parms, num_parms, len_parms, 0));\n+\t\t} else {\n+\t\t    /* for the given values */\n+\t\t    test_tparm(all_names[0], num_parms);\n+\t\t}\n+\t    } else {\n+\t\tfor (n_run = 0; n_run < len_names; ++n_run) {\n+\t\t    test_tparm(all_names[n_run], num_parms);\n+\t\t}\n+\t    }\n+\t    if (cur_term != 0) {\n+\t\tdel_curterm(cur_term);\n+\t    } else {\n+\t\tprintf(\"? no cur_term\\n\");\n+\t    }\n+\t}\n+    }\n+#if NO_LEAKS\n+    for (n = 0; n < len_names; ++n) {\n+\tfree(all_names[n]);\n+    }\n+    free(all_names);\n+    free(old_term);\n+    for (n = 0; n < len_terms; ++n) {\n+\tfree(all_terms[n]);\n+    }\n+    free(all_terms);\n+    free(num_parms);\n+    free(str_parms);\n+#endif\n+\n+    ExitProgram(EXIT_SUCCESS);\n+}\n+\n+#else /* !HAVE_TIGETSTR */\n+int\n+main(int argc GCC_UNUSED, char *argv[]GCC_UNUSED)\n+{\n+    failed(\"This program requires the terminfo functions such as tigetstr\");\n+}\n+#endif /* HAVE_TIGETSTR */\n"
        ],
        "func_after": []
    },
    {
        "idx": 200831,
        "project": "tor",
        "commit_id": "00fffbc1a15e2696a89c721d0c94dc333ff419ef",
        "project_url": "https://github.com/torproject/tor",
        "commit_url": "https://gitweb.torproject.org/tor.git/commitdiff/00fffbc1a15e2696a89c721d0c94dc333ff419ef",
        "commit_message": "Don't give the Guard flag to relays without the CVE-2011-2768 fix",
        "target": 1,
        "irrelevant": 0,
        "func_before": "set_routerstatus_from_routerinfo(routerstatus_t *rs,\n                                 routerinfo_t *ri, time_t now,\n                                 int naming, int listbadexits,\n                                 int listbaddirs, int vote_on_hsdirs)\n{\n  int unstable_version =\n    !tor_version_as_new_as(ri->platform,\"0.1.1.16-rc-cvs\");\n  memset(rs, 0, sizeof(routerstatus_t));\n\n  rs->is_authority =\n    router_digest_is_trusted_dir(ri->cache_info.identity_digest);\n\n  /* Already set by compute_performance_thresholds. */\n  rs->is_exit = ri->is_exit;\n  rs->is_stable = ri->is_stable =\n    router_is_active(ri, now) &&\n    !dirserv_thinks_router_is_unreliable(now, ri, 1, 0) &&\n    !unstable_version;\n  rs->is_fast = ri->is_fast =\n    router_is_active(ri, now) &&\n    !dirserv_thinks_router_is_unreliable(now, ri, 0, 1);\n  rs->is_running = ri->is_running; /* computed above */\n\n  if (naming) {\n    uint32_t name_status = dirserv_get_name_status(\n                         ri->cache_info.identity_digest, ri->nickname);\n    rs->is_named = (naming && (name_status & FP_NAMED)) ? 1 : 0;\n    rs->is_unnamed = (naming && (name_status & FP_UNNAMED)) ? 1 : 0;\n  }\n  rs->is_valid = ri->is_valid;\n\n  if (rs->is_fast &&\n      (router_get_advertised_bandwidth(ri) >= BANDWIDTH_TO_GUARANTEE_GUARD ||\n       router_get_advertised_bandwidth(ri) >=\n                              MIN(guard_bandwidth_including_exits,\n                                  guard_bandwidth_excluding_exits))) {\n    long tk = rep_hist_get_weighted_time_known(\n                                      ri->cache_info.identity_digest, now);\n    double wfu = rep_hist_get_weighted_fractional_uptime(\n                                      ri->cache_info.identity_digest, now);\n    rs->is_possible_guard = (wfu >= guard_wfu && tk >= guard_tk) ? 1 : 0;\n  } else {\n    rs->is_possible_guard = 0;\n  }\n  rs->is_bad_directory = listbaddirs && ri->is_bad_directory;\n  rs->is_bad_exit = listbadexits && ri->is_bad_exit;\n  ri->is_hs_dir = dirserv_thinks_router_is_hs_dir(ri, now);\n  rs->is_hs_dir = vote_on_hsdirs && ri->is_hs_dir;\n  rs->is_v2_dir = ri->dir_port != 0;\n\n  if (!strcasecmp(ri->nickname, UNNAMED_ROUTER_NICKNAME))\n    rs->is_named = rs->is_unnamed = 0;\n\n  rs->published_on = ri->cache_info.published_on;\n  memcpy(rs->identity_digest, ri->cache_info.identity_digest, DIGEST_LEN);\n  memcpy(rs->descriptor_digest, ri->cache_info.signed_descriptor_digest,\n         DIGEST_LEN);\n  rs->addr = ri->addr;\n  strlcpy(rs->nickname, ri->nickname, sizeof(rs->nickname));\n  rs->or_port = ri->or_port;\n  rs->dir_port = ri->dir_port;\n}",
        "func_hash": 318178419664162766552129781692369632852,
        "file_name": "dirserv.c",
        "file_hash": 144814081099750966253037063350589014941,
        "cwe": [
            "CWE-264"
        ],
        "cve": "CVE-2011-2768",
        "cve_desc": "Tor before 0.2.2.34, when configured as a client or bridge, sends a TLS certificate chain as part of an outgoing OR connection, which allows remote relays to bypass intended anonymity properties by reading this chain and then determining the set of entry guards that the client or bridge had selected.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2011-2768",
        "func_name": "set_routerstatus_from_routerinfo",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 200895,
        "project": "vim",
        "commit_id": "d6c67629ed05aae436164eec474832daf8ba7420",
        "project_url": "https://github.com/vim/vim",
        "commit_url": "https://github.com/vim/vim/commit/d6c67629ed05aae436164eec474832daf8ba7420",
        "commit_message": "patch 9.0.0260: using freed memory when using 'quickfixtextfunc' recursively\n\nProblem:    Using freed memory when using 'quickfixtextfunc' recursively.\nSolution:   Do not allow for recursion.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "call_qftf_func(qf_list_T *qfl, int qf_winid, long start_idx, long end_idx)\n{\n    callback_T\t*cb = &qftf_cb;\n    list_T\t*qftf_list = NULL;\n\n    // If 'quickfixtextfunc' is set, then use the user-supplied function to get\n    // the text to display. Use the local value of 'quickfixtextfunc' if it is\n    // set.\n    if (qfl->qf_qftf_cb.cb_name != NULL)\n\tcb = &qfl->qf_qftf_cb;\n    if (cb->cb_name != NULL)\n    {\n\ttypval_T\targs[1];\n\tdict_T\t\t*d;\n\ttypval_T\trettv;\n\n\t// create the dict argument\n\tif ((d = dict_alloc_lock(VAR_FIXED)) == NULL)\n\t    return NULL;\n\tdict_add_number(d, \"quickfix\", (long)IS_QF_LIST(qfl));\n\tdict_add_number(d, \"winid\", (long)qf_winid);\n\tdict_add_number(d, \"id\", (long)qfl->qf_id);\n\tdict_add_number(d, \"start_idx\", start_idx);\n\tdict_add_number(d, \"end_idx\", end_idx);\n\t++d->dv_refcount;\n\targs[0].v_type = VAR_DICT;\n\targs[0].vval.v_dict = d;\n\n\tqftf_list = NULL;\n\tif (call_callback(cb, 0, &rettv, 1, args) != FAIL)\n\t{\n\t    if (rettv.v_type == VAR_LIST)\n\t    {\n\t\tqftf_list = rettv.vval.v_list;\n\t\tqftf_list->lv_refcount++;\n\t    }\n\t    clear_tv(&rettv);\n\t}\n\tdict_unref(d);\n    }\n\n    return qftf_list;\n}",
        "func_hash": 339333086271181560510428879683096773754,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2022-2982",
        "cve_desc": "Use After Free in GitHub repository vim/vim prior to 9.0.0260.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-2982",
        "func_name": "call_qftf_func",
        "diff": [
            "diff --git a/src/quickfix.c b/src/quickfix.c\nindex 54ae07df53d4f..6af62e8dfe56d 100644\n--- a/src/quickfix.c\n+++ b/src/quickfix.c\n@@ -4674,6 +4674,11 @@ call_qftf_func(qf_list_T *qfl, int qf_winid, long start_idx, long end_idx)\n {\n     callback_T\t*cb = &qftf_cb;\n     list_T\t*qftf_list = NULL;\n+    static int\trecursive = FALSE;\n+\n+    if (recursive)\n+\treturn NULL;  // this doesn't work properly recursively\n+    recursive = TRUE;\n \n     // If 'quickfixtextfunc' is set, then use the user-supplied function to get\n     // the text to display. Use the local value of 'quickfixtextfunc' if it is\n@@ -4688,7 +4693,10 @@ call_qftf_func(qf_list_T *qfl, int qf_winid, long start_idx, long end_idx)\n \n \t// create the dict argument\n \tif ((d = dict_alloc_lock(VAR_FIXED)) == NULL)\n+\t{\n+\t    recursive = FALSE;\n \t    return NULL;\n+\t}\n \tdict_add_number(d, \"quickfix\", (long)IS_QF_LIST(qfl));\n \tdict_add_number(d, \"winid\", (long)qf_winid);\n \tdict_add_number(d, \"id\", (long)qfl->qf_id);\n@@ -4711,6 +4719,7 @@ call_qftf_func(qf_list_T *qfl, int qf_winid, long start_idx, long end_idx)\n \tdict_unref(d);\n     }\n \n+    recursive = FALSE;\n     return qftf_list;\n }\n \ndiff --git a/src/testdir/test_quickfix.vim b/src/testdir/test_quickfix.vim\nindex 94651af819423..762fa8d8d0e3c 100644\n--- a/src/testdir/test_quickfix.vim\n+++ b/src/testdir/test_quickfix.vim\n@@ -6351,4 +6351,17 @@ func Test_qflist_statusmsg()\n   %bw!\n endfunc\n \n+func Test_quickfixtextfunc_recursive()\n+  func s:QFTfunc(o)\n+    cgete '0'\n+  endfunc\n+  copen\n+  let &quickfixtextfunc = 's:QFTfunc'\n+  cex \"\"\n+\n+  let &quickfixtextfunc = ''\n+  cclose\n+endfunc\n+\n+\n \" vim: shiftwidth=2 sts=2 expandtab\ndiff --git a/src/version.c b/src/version.c\nindex b1943bb161571..02c20f03f6026 100644\n--- a/src/version.c\n+++ b/src/version.c\n@@ -731,6 +731,8 @@ static char *(features[]) =\n \n static int included_patches[] =\n {   /* Add new patch number below this line */\n+/**/\n+    260,\n /**/\n     259,\n /**/\n"
        ],
        "func_after": []
    },
    {
        "idx": 200934,
        "project": "libvirt",
        "commit_id": "524de6cc35d3b222f0e940bb0fd027f5482572c5",
        "project_url": "https://github.com/libvirt/libvirt",
        "commit_url": "https://github.com/libvirt/libvirt/commit/524de6cc35d3b222f0e940bb0fd027f5482572c5",
        "commit_message": "virstoragetest: testBackingParse: Use VIR_DOMAIN_DEF_FORMAT_SECURE when formatting xml\n\nWe want to format even the secure information in tests.\n\nSigned-off-by: Peter Krempa <pkrempa@redhat.com>\nReviewed-by: Erik Skultety <eskultet@redhat.com>",
        "target": 1,
        "irrelevant": 0,
        "func_before": "testBackingParse(const void *args)\n{\n    const struct testBackingParseData *data = args;\n    g_auto(virBuffer) buf = VIR_BUFFER_INITIALIZER;\n    g_autofree char *xml = NULL;\n    g_autoptr(virStorageSource) src = NULL;\n    int rc;\n    int erc = data->rv;\n\n    /* expect failure return code with NULL expected data */\n    if (!data->expect)\n        erc = -1;\n\n    if ((rc = virStorageSourceNewFromBackingAbsolute(data->backing, &src)) != erc) {\n        fprintf(stderr, \"expected return value '%d' actual '%d'\\n\", erc, rc);\n        return -1;\n    }\n\n    if (!src)\n        return 0;\n\n    if (src && !data->expect) {\n        fprintf(stderr, \"parsing of backing store string '%s' should \"\n                        \"have failed\\n\", data->backing);\n        return -1;\n    }\n\n    if (virDomainDiskSourceFormat(&buf, src, \"source\", 0, false, 0, true, NULL) < 0 ||\n        !(xml = virBufferContentAndReset(&buf))) {\n        fprintf(stderr, \"failed to format disk source xml\\n\");\n        return -1;\n    }\n\n    if (STRNEQ(xml, data->expect)) {\n        fprintf(stderr, \"\\n backing store string '%s'\\n\"\n                        \"expected storage source xml:\\n%s\\n\"\n                        \"actual storage source xml:\\n%s\\n\",\n                        data->backing, data->expect, xml);\n        return -1;\n    }\n\n    return 0;\n}",
        "func_hash": 11097234962036893945341293376039418410,
        "file_name": "virstoragetest.c",
        "file_hash": 229136922246575533938843249875631381172,
        "cwe": [
            "CWE-212"
        ],
        "cve": "CVE-2020-14301",
        "cve_desc": "An information disclosure vulnerability was found in libvirt in versions before 6.3.0. HTTP cookies used to access network-based disks were saved in the XML dump of the guest domain. This flaw allows an attacker to access potentially sensitive information in the domain configuration via the `dumpxml` command.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2020-14301",
        "func_name": "testBackingParse",
        "diff": [
            "diff --git a/tests/virstoragetest.c b/tests/virstoragetest.c\nindex 6e8ebeba134..6d2b21c25f3 100644\n--- a/tests/virstoragetest.c\n+++ b/tests/virstoragetest.c\n@@ -594,6 +594,7 @@ testBackingParse(const void *args)\n     g_autoptr(virStorageSource) src = NULL;\n     int rc;\n     int erc = data->rv;\n+    unsigned int xmlformatflags = VIR_DOMAIN_DEF_FORMAT_SECURE;\n \n     /* expect failure return code with NULL expected data */\n     if (!data->expect)\n@@ -613,7 +614,7 @@ testBackingParse(const void *args)\n         return -1;\n     }\n \n-    if (virDomainDiskSourceFormat(&buf, src, \"source\", 0, false, 0, true, NULL) < 0 ||\n+    if (virDomainDiskSourceFormat(&buf, src, \"source\", 0, false, xmlformatflags, true, NULL) < 0 ||\n         !(xml = virBufferContentAndReset(&buf))) {\n         fprintf(stderr, \"failed to format disk source xml\\n\");\n         return -1;\n"
        ],
        "func_after": []
    },
    {
        "idx": 200976,
        "project": "vim",
        "commit_id": "395bd1f6d3edc9f7edb5d1f2d7deaf5a9e3ab93c",
        "project_url": "https://github.com/vim/vim",
        "commit_url": "https://github.com/vim/vim/commit/395bd1f6d3edc9f7edb5d1f2d7deaf5a9e3ab93c",
        "commit_message": "patch 8.2.4956: reading past end of line with \"gf\" in Visual block mode\n\nProblem:    Reading past end of line with \"gf\" in Visual block mode.\nSolution:   Do not include the NUL in the length.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "get_visual_text(\n    cmdarg_T\t*cap,\n    char_u\t**pp,\t    // return: start of selected text\n    int\t\t*lenp)\t    // return: length of selected text\n{\n    if (VIsual_mode != 'V')\n\tunadjust_for_sel();\n    if (VIsual.lnum != curwin->w_cursor.lnum)\n    {\n\tif (cap != NULL)\n\t    clearopbeep(cap->oap);\n\treturn FAIL;\n    }\n    if (VIsual_mode == 'V')\n    {\n\t*pp = ml_get_curline();\n\t*lenp = (int)STRLEN(*pp);\n    }\n    else\n    {\n\tif (LT_POS(curwin->w_cursor, VIsual))\n\t{\n\t    *pp = ml_get_pos(&curwin->w_cursor);\n\t    *lenp = VIsual.col - curwin->w_cursor.col + 1;\n\t}\n\telse\n\t{\n\t    *pp = ml_get_pos(&VIsual);\n\t    *lenp = curwin->w_cursor.col - VIsual.col + 1;\n\t}\n\tif (**pp == NUL)\n\t    *lenp = 0;\n\tif (has_mbyte && *lenp > 0)\n\t    // Correct the length to include all bytes of the last character.\n\t    *lenp += (*mb_ptr2len)(*pp + (*lenp - 1)) - 1;\n    }\n    reset_VIsual_and_resel();\n    return OK;\n}",
        "func_hash": 284497166738290361019440448049627151253,
        "file_name": "normal.c",
        "file_hash": null,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2022-1720",
        "cve_desc": "Buffer Over-read in function grab_file_name in GitHub repository vim/vim prior to 8.2.4956. This vulnerability is capable of crashing the software, memory modification, and possible remote execution.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-1720",
        "func_name": "get_visual_text",
        "diff": [
            "diff --git a/src/normal.c b/src/normal.c\nindex 1baf68a1453aee..bc3e29e1abaa13 100644\n--- a/src/normal.c\n+++ b/src/normal.c\n@@ -3671,9 +3671,16 @@ get_visual_text(\n \t}\n \tif (**pp == NUL)\n \t    *lenp = 0;\n-\tif (has_mbyte && *lenp > 0)\n-\t    // Correct the length to include all bytes of the last character.\n-\t    *lenp += (*mb_ptr2len)(*pp + (*lenp - 1)) - 1;\n+\tif (*lenp > 0)\n+\t{\n+\t    if (has_mbyte)\n+\t\t// Correct the length to include all bytes of the last\n+\t\t// character.\n+\t\t*lenp += (*mb_ptr2len)(*pp + (*lenp - 1)) - 1;\n+\t    else if ((*pp)[*lenp - 1] == NUL)\n+\t\t// Do not include a trailing NUL.\n+\t\t*lenp -= 1;\n+\t}\n     }\n     reset_VIsual_and_resel();\n     return OK;\ndiff --git a/src/testdir/test_gf.vim b/src/testdir/test_gf.vim\nindex 3602ba010e8c42..1b3b139810eca8 100644\n--- a/src/testdir/test_gf.vim\n+++ b/src/testdir/test_gf.vim\n@@ -138,6 +138,21 @@ func Test_gf_visual()\n   call assert_equal('Xtest_gf_visual', bufname('%'))\n   call assert_equal(3, getcurpos()[1])\n \n+  \" do not include the NUL at the end \n+  call writefile(['x'], 'X')\n+  let save_enc = &enc\n+  for enc in ['latin1', 'utf-8']\n+    exe \"set enc=\" .. enc\n+    new\n+    call setline(1, 'X')\n+    set nomodified\n+    exe \"normal \\<C-V>$gf\"\n+    call assert_equal('X', bufname())\n+    bwipe!\n+  endfor\n+  let &enc = save_enc\n+  call delete('X')\n+\n   \" line number in visual area is used for file name\n   if has('unix')\n     bwipe!\ndiff --git a/src/version.c b/src/version.c\nindex 62e2b0af69411f..821f3680e2fb5d 100644\n--- a/src/version.c\n+++ b/src/version.c\n@@ -746,6 +746,8 @@ static char *(features[]) =\n \n static int included_patches[] =\n {   /* Add new patch number below this line */\n+/**/\n+    4956,\n /**/\n     4955,\n /**/\n"
        ],
        "func_after": []
    },
    {
        "idx": 201006,
        "project": "linux",
        "commit_id": "2a8859f373b0a86f0ece8ec8312607eacf12485d",
        "project_url": "https://github.com/torvalds/linux",
        "commit_url": "https://github.com/torvalds/linux/commit/2a8859f373b0a86f0ece8ec8312607eacf12485d",
        "commit_message": "KVM: x86/mmu: do compare-and-exchange of gPTE via the user address\n\nFNAME(cmpxchg_gpte) is an inefficient mess.  It is at least decent if it\ncan go through get_user_pages_fast(), but if it cannot then it tries to\nuse memremap(); that is not just terribly slow, it is also wrong because\nit assumes that the VM_PFNMAP VMA is contiguous.\n\nThe right way to do it would be to do the same thing as\nhva_to_pfn_remapped() does since commit add6a0cd1c5b (\"KVM: MMU: try to\nfix up page faults before giving up\", 2016-07-05), using follow_pte()\nand fixup_user_fault() to determine the correct address to use for\nmemremap().  To do this, one could for example extract hva_to_pfn()\nfor use outside virt/kvm/kvm_main.c.  But really there is no reason to\ndo that either, because there is already a perfectly valid address to\ndo the cmpxchg() on, only it is a userspace address.  That means doing\nuser_access_begin()/user_access_end() and writing the code in assembly\nto handle exceptions correctly.  Worse, the guest PTE can be 8-byte\neven on i686 so there is the extra complication of using cmpxchg8b to\naccount for.  But at least it is an efficient mess.\n\n(Thanks to Linus for suggesting improvement on the inline assembly).\n\nReported-by: Qiuhao Li <qiuhao@sysec.org>\nReported-by: Gaoning Pan <pgn@zju.edu.cn>\nReported-by: Yongkang Jia <kangel@zju.edu.cn>\nReported-by: syzbot+6cde2282daa792c49ab8@syzkaller.appspotmail.com\nDebugged-by: Tadeusz Struk <tadeusz.struk@linaro.org>\nTested-by: Maxim Levitsky <mlevitsk@redhat.com>\nCc: stable@vger.kernel.org\nFixes: bd53cb35a3e9 (\"X86/KVM: Handle PFNs outside of kernel reach when touching GPTEs\")\nSigned-off-by: Paolo Bonzini <pbonzini@redhat.com>",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static int FNAME(cmpxchg_gpte)(struct kvm_vcpu *vcpu, struct kvm_mmu *mmu,\n\t\t\t       pt_element_t __user *ptep_user, unsigned index,\n\t\t\t       pt_element_t orig_pte, pt_element_t new_pte)\n{\n\tint npages;\n\tpt_element_t ret;\n\tpt_element_t *table;\n\tstruct page *page;\n\n\tnpages = get_user_pages_fast((unsigned long)ptep_user, 1, FOLL_WRITE, &page);\n\tif (likely(npages == 1)) {\n\t\ttable = kmap_atomic(page);\n\t\tret = CMPXCHG(&table[index], orig_pte, new_pte);\n\t\tkunmap_atomic(table);\n\n\t\tkvm_release_page_dirty(page);\n\t} else {\n\t\tstruct vm_area_struct *vma;\n\t\tunsigned long vaddr = (unsigned long)ptep_user & PAGE_MASK;\n\t\tunsigned long pfn;\n\t\tunsigned long paddr;\n\n\t\tmmap_read_lock(current->mm);\n\t\tvma = find_vma_intersection(current->mm, vaddr, vaddr + PAGE_SIZE);\n\t\tif (!vma || !(vma->vm_flags & VM_PFNMAP)) {\n\t\t\tmmap_read_unlock(current->mm);\n\t\t\treturn -EFAULT;\n\t\t}\n\t\tpfn = ((vaddr - vma->vm_start) >> PAGE_SHIFT) + vma->vm_pgoff;\n\t\tpaddr = pfn << PAGE_SHIFT;\n\t\ttable = memremap(paddr, PAGE_SIZE, MEMREMAP_WB);\n\t\tif (!table) {\n\t\t\tmmap_read_unlock(current->mm);\n\t\t\treturn -EFAULT;\n\t\t}\n\t\tret = CMPXCHG(&table[index], orig_pte, new_pte);\n\t\tmemunmap(table);\n\t\tmmap_read_unlock(current->mm);\n\t}\n\n\treturn (ret != orig_pte);\n}",
        "func_hash": 328878992778449870831639903805721619554,
        "file_name": "paging_tmpl.h",
        "file_hash": 99223665847947661027332128453448877347,
        "cwe": [
            "CWE-416"
        ],
        "cve": "CVE-2022-1158",
        "cve_desc": "A flaw was found in KVM. When updating a guest's page table entry, vm_pgoff was improperly used as the offset to get the page's pfn. As vaddr and vm_pgoff are controllable by user-mode processes, this flaw allows unprivileged local users on the host to write outside the userspace region and potentially corrupt the kernel, resulting in a denial of service condition.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-1158",
        "func_name": "FNAME",
        "diff": [
            "diff --git a/arch/x86/kvm/mmu/paging_tmpl.h b/arch/x86/kvm/mmu/paging_tmpl.h\nindex 8621188b46df5a..01fee5f67ac370 100644\n--- a/arch/x86/kvm/mmu/paging_tmpl.h\n+++ b/arch/x86/kvm/mmu/paging_tmpl.h\n@@ -34,9 +34,8 @@\n \t#define PT_HAVE_ACCESSED_DIRTY(mmu) true\n \t#ifdef CONFIG_X86_64\n \t#define PT_MAX_FULL_LEVELS PT64_ROOT_MAX_LEVEL\n-\t#define CMPXCHG cmpxchg\n+\t#define CMPXCHG \"cmpxchgq\"\n \t#else\n-\t#define CMPXCHG cmpxchg64\n \t#define PT_MAX_FULL_LEVELS 2\n \t#endif\n #elif PTTYPE == 32\n@@ -52,7 +51,7 @@\n \t#define PT_GUEST_DIRTY_SHIFT PT_DIRTY_SHIFT\n \t#define PT_GUEST_ACCESSED_SHIFT PT_ACCESSED_SHIFT\n \t#define PT_HAVE_ACCESSED_DIRTY(mmu) true\n-\t#define CMPXCHG cmpxchg\n+\t#define CMPXCHG \"cmpxchgl\"\n #elif PTTYPE == PTTYPE_EPT\n \t#define pt_element_t u64\n \t#define guest_walker guest_walkerEPT\n@@ -65,7 +64,9 @@\n \t#define PT_GUEST_DIRTY_SHIFT 9\n \t#define PT_GUEST_ACCESSED_SHIFT 8\n \t#define PT_HAVE_ACCESSED_DIRTY(mmu) ((mmu)->ept_ad)\n-\t#define CMPXCHG cmpxchg64\n+\t#ifdef CONFIG_X86_64\n+\t#define CMPXCHG \"cmpxchgq\"\n+\t#endif\n \t#define PT_MAX_FULL_LEVELS PT64_ROOT_MAX_LEVEL\n #else\n \t#error Invalid PTTYPE value\n@@ -147,43 +148,36 @@ static int FNAME(cmpxchg_gpte)(struct kvm_vcpu *vcpu, struct kvm_mmu *mmu,\n \t\t\t       pt_element_t __user *ptep_user, unsigned index,\n \t\t\t       pt_element_t orig_pte, pt_element_t new_pte)\n {\n-\tint npages;\n-\tpt_element_t ret;\n-\tpt_element_t *table;\n-\tstruct page *page;\n-\n-\tnpages = get_user_pages_fast((unsigned long)ptep_user, 1, FOLL_WRITE, &page);\n-\tif (likely(npages == 1)) {\n-\t\ttable = kmap_atomic(page);\n-\t\tret = CMPXCHG(&table[index], orig_pte, new_pte);\n-\t\tkunmap_atomic(table);\n-\n-\t\tkvm_release_page_dirty(page);\n-\t} else {\n-\t\tstruct vm_area_struct *vma;\n-\t\tunsigned long vaddr = (unsigned long)ptep_user & PAGE_MASK;\n-\t\tunsigned long pfn;\n-\t\tunsigned long paddr;\n-\n-\t\tmmap_read_lock(current->mm);\n-\t\tvma = find_vma_intersection(current->mm, vaddr, vaddr + PAGE_SIZE);\n-\t\tif (!vma || !(vma->vm_flags & VM_PFNMAP)) {\n-\t\t\tmmap_read_unlock(current->mm);\n-\t\t\treturn -EFAULT;\n-\t\t}\n-\t\tpfn = ((vaddr - vma->vm_start) >> PAGE_SHIFT) + vma->vm_pgoff;\n-\t\tpaddr = pfn << PAGE_SHIFT;\n-\t\ttable = memremap(paddr, PAGE_SIZE, MEMREMAP_WB);\n-\t\tif (!table) {\n-\t\t\tmmap_read_unlock(current->mm);\n-\t\t\treturn -EFAULT;\n-\t\t}\n-\t\tret = CMPXCHG(&table[index], orig_pte, new_pte);\n-\t\tmemunmap(table);\n-\t\tmmap_read_unlock(current->mm);\n-\t}\n+\tsigned char r;\n \n-\treturn (ret != orig_pte);\n+\tif (!user_access_begin(ptep_user, sizeof(pt_element_t)))\n+\t\treturn -EFAULT;\n+\n+#ifdef CMPXCHG\n+\tasm volatile(\"1:\" LOCK_PREFIX CMPXCHG \" %[new], %[ptr]\\n\"\n+\t\t     \"setnz %b[r]\\n\"\n+\t\t     \"2:\"\n+\t\t     _ASM_EXTABLE_TYPE_REG(1b, 2b, EX_TYPE_EFAULT_REG, %k[r])\n+\t\t     : [ptr] \"+m\" (*ptep_user),\n+\t\t       [old] \"+a\" (orig_pte),\n+\t\t       [r] \"=q\" (r)\n+\t\t     : [new] \"r\" (new_pte)\n+\t\t     : \"memory\");\n+#else\n+\tasm volatile(\"1:\" LOCK_PREFIX \"cmpxchg8b %[ptr]\\n\"\n+\t\t     \"setnz %b[r]\\n\"\n+\t\t     \"2:\"\n+\t\t     _ASM_EXTABLE_TYPE_REG(1b, 2b, EX_TYPE_EFAULT_REG, %k[r])\n+\t\t     : [ptr] \"+m\" (*ptep_user),\n+\t\t       [old] \"+A\" (orig_pte),\n+\t\t       [r] \"=q\" (r)\n+\t\t     : [new_lo] \"b\" ((u32)new_pte),\n+\t\t       [new_hi] \"c\" ((u32)(new_pte >> 32))\n+\t\t     : \"memory\");\n+#endif\n+\n+\tuser_access_end();\n+\treturn r;\n }\n \n static bool FNAME(prefetch_invalid_gpte)(struct kvm_vcpu *vcpu,\n"
        ],
        "func_after": []
    },
    {
        "idx": 201007,
        "project": "pjproject",
        "commit_id": "560a1346f87aabe126509bb24930106dea292b00",
        "project_url": "https://github.com/pjsip/pjproject",
        "commit_url": "https://github.com/pjsip/pjproject/commit/560a1346f87aabe126509bb24930106dea292b00",
        "commit_message": "Merge pull request from GHSA-f5qg-pqcg-765m",
        "target": 1,
        "irrelevant": 1,
        "func_before": "static int print_media_desc(const pjmedia_sdp_media *m, char *buf, pj_size_t len)\n{\n    char *p = buf;\n    char *end = buf+len;\n    unsigned i;\n    int printed;\n\n    /* check length for the \"m=\" line. */\n    if (len < (pj_size_t)m->desc.media.slen+m->desc.transport.slen+12+24) {\n\treturn -1;\n    }\n    *p++ = 'm';\t    /* m= */\n    *p++ = '=';\n    pj_memcpy(p, m->desc.media.ptr, m->desc.media.slen);\n    p += m->desc.media.slen;\n    *p++ = ' ';\n    printed = pj_utoa(m->desc.port, p);\n    p += printed;\n    if (m->desc.port_count > 1) {\n\t*p++ = '/';\n\tprinted = pj_utoa(m->desc.port_count, p);\n\tp += printed;\n    }\n    *p++ = ' ';\n    pj_memcpy(p, m->desc.transport.ptr, m->desc.transport.slen);\n    p += m->desc.transport.slen;\n    for (i=0; i<m->desc.fmt_count; ++i) {\n\t*p++ = ' ';\n\tpj_memcpy(p, m->desc.fmt[i].ptr, m->desc.fmt[i].slen);\n\tp += m->desc.fmt[i].slen;\n    }\n    *p++ = '\\r';\n    *p++ = '\\n';\n\n    /* print connection info, if present. */\n    if (m->conn) {\n\tprinted = print_connection_info(m->conn, p, (int)(end-p));\n\tif (printed < 0) {\n\t    return -1;\n\t}\n\tp += printed;\n    }\n    \n    /* print optional bandwidth info. */\n    for (i=0; i<m->bandw_count; ++i) {\n\tprinted = (int)print_bandw(m->bandw[i], p, end-p);\n\tif (printed < 0) {\n\t    return -1;\n\t}\n\tp += printed;\n    }\n\n    /* print attributes. */\n    for (i=0; i<m->attr_count; ++i) {\n\tprinted = (int)print_attr(m->attr[i], p, end-p);\n\tif (printed < 0) {\n\t    return -1;\n\t}\n\tp += printed;\n    }\n\n    return (int)(p-buf);\n}",
        "func_hash": 243109353869436532488614405590479215364,
        "file_name": "sdp.c",
        "file_hash": 204440288713003047579803744169338279171,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2022-24764",
        "cve_desc": "PJSIP is a free and open source multimedia communication library written in C. Versions 2.12 and prior contain a stack buffer overflow vulnerability that affects PJSUA2 users or users that call the API `pjmedia_sdp_print(), pjmedia_sdp_media_print()`. Applications that do not use PJSUA2 and do not directly call `pjmedia_sdp_print()` or `pjmedia_sdp_media_print()` should not be affected. A patch is available on the `master` branch of the `pjsip/pjproject` GitHub repository. There are currently no known workarounds.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-24764",
        "func_name": "print_media_desc",
        "diff": [
            "diff --git a/pjmedia/src/pjmedia/sdp.c b/pjmedia/src/pjmedia/sdp.c\nindex 31446b5424..3905c2f525 100644\n--- a/pjmedia/src/pjmedia/sdp.c\n+++ b/pjmedia/src/pjmedia/sdp.c\n@@ -733,12 +733,21 @@ static int print_media_desc(const pjmedia_sdp_media *m, char *buf, pj_size_t len\n     pj_memcpy(p, m->desc.transport.ptr, m->desc.transport.slen);\n     p += m->desc.transport.slen;\n     for (i=0; i<m->desc.fmt_count; ++i) {\n-\t*p++ = ' ';\n-\tpj_memcpy(p, m->desc.fmt[i].ptr, m->desc.fmt[i].slen);\n-\tp += m->desc.fmt[i].slen;\n+\tif (end-p > m->desc.fmt[i].slen) {\n+\t    *p++ = ' ';\n+\t    pj_memcpy(p, m->desc.fmt[i].ptr, m->desc.fmt[i].slen);\n+\t    p += m->desc.fmt[i].slen;\n+\t} else {\n+\t    return -1;\n+\t}\n+    }\n+\n+    if (end-p >= 2) {\n+\t*p++ = '\\r';\n+\t*p++ = '\\n';\n+    } else {\n+\treturn -1;\n     }\n-    *p++ = '\\r';\n-    *p++ = '\\n';\n \n     /* print connection info, if present. */\n     if (m->conn) {\n"
        ],
        "func_after": []
    },
    {
        "idx": 201343,
        "project": "linux",
        "commit_id": "a3727a8bac0a9e77c70820655fd8715523ba3db7",
        "project_url": "https://github.com/torvalds/linux",
        "commit_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=a3727a8bac0a9e77c70820655fd8715523ba3db7",
        "commit_message": "selinux,smack: fix subjective/objective credential use mixups\n\nJann Horn reported a problem with commit eb1231f73c4d (\"selinux:\nclarify task subjective and objective credentials\") where some LSM\nhooks were attempting to access the subjective credentials of a task\nother than the current task.  Generally speaking, it is not safe to\naccess another task's subjective credentials and doing so can cause\na number of problems.\n\nFurther, while looking into the problem, I realized that Smack was\nsuffering from a similar problem brought about by a similar commit\n1fb057dcde11 (\"smack: differentiate between subjective and objective\ntask credentials\").\n\nThis patch addresses this problem by restoring the use of the task's\nobjective credentials in those cases where the task is other than the\ncurrent executing task.  Not only does this resolve the problem\nreported by Jann, it is arguably the correct thing to do in these\ncases.\n\nCc: stable@vger.kernel.org\nFixes: eb1231f73c4d (\"selinux: clarify task subjective and objective credentials\")\nFixes: 1fb057dcde11 (\"smack: differentiate between subjective and objective task credentials\")\nReported-by: Jann Horn <jannh@google.com>\nAcked-by: Eric W. Biederman <ebiederm@xmission.com>\nAcked-by: Casey Schaufler <casey@schaufler-ca.com>\nSigned-off-by: Paul Moore <paul@paul-moore.com>",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static int selinux_ptrace_traceme(struct task_struct *parent)\n{\n\treturn avc_has_perm(&selinux_state,\n\t\t\t    task_sid_subj(parent), task_sid_obj(current),\n\t\t\t    SECCLASS_PROCESS, PROCESS__PTRACE, NULL);\n}",
        "func_hash": 244235637020461368565337014513482216980,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-416"
        ],
        "cve": "CVE-2021-43057",
        "cve_desc": "An issue was discovered in the Linux kernel before 5.14.8. A use-after-free in selinux_ptrace_traceme (aka the SELinux handler for PTRACE_TRACEME) could be used by local attackers to cause memory corruption and escalate privileges, aka CID-a3727a8bac0a. This occurs because of an attempt to access the subjective credentials of another task.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-43057",
        "func_name": "selinux_ptrace_traceme",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 201353,
        "project": "wireless-drivers",
        "commit_id": "8b51dc7291473093c821195c4b6af85fadedbc2f",
        "project_url": "https://git.kernel.org/pub/scm/linux/kernel/git/kvalo/wireless-drivers",
        "commit_url": "https://git.kernel.org/pub/scm/linux/kernel/git/kvalo/wireless-drivers.git/commit/?id=8b51dc7291473093c821195c4b6af85fadedbc2f",
        "commit_message": "rsi: fix a double free bug in rsi_91x_deinit()\n\n`dev` (struct rsi_91x_usbdev *) field of adapter\n(struct rsi_91x_usbdev *) is allocated  and initialized in\n`rsi_init_usb_interface`. If any error is detected in information\nread from the device side,  `rsi_init_usb_interface` will be\nfreed. However, in the higher level error handling code in\n`rsi_probe`, if error is detected, `rsi_91x_deinit` is called\nagain, in which `dev` will be freed again, resulting double free.\n\nThis patch fixes the double free by removing the free operation on\n`dev` in `rsi_init_usb_interface`, because `rsi_91x_deinit` is also\nused in `rsi_disconnect`, in that code path, the `dev` field is not\n (and thus needs to be) freed.\n\nThis bug was found in v4.19, but is also present in the latest version\nof kernel. Fixes CVE-2019-15504.\n\nReported-by: Hui Peng <benquike@gmail.com>\nReported-by: Mathias Payer <mathias.payer@nebelwelt.net>\nSigned-off-by: Hui Peng <benquike@gmail.com>\nReviewed-by: Guenter Roeck <linux@roeck-us.net>\nSigned-off-by: Kalle Valo <kvalo@codeaurora.org>",
        "target": 1,
        "irrelevant": 1,
        "func_before": "static int rsi_init_usb_interface(struct rsi_hw *adapter,\n\t\t\t\t  struct usb_interface *pfunction)\n{\n\tstruct rsi_91x_usbdev *rsi_dev;\n\tint status;\n\n\trsi_dev = kzalloc(sizeof(*rsi_dev), GFP_KERNEL);\n\tif (!rsi_dev)\n\t\treturn -ENOMEM;\n\n\tadapter->rsi_dev = rsi_dev;\n\trsi_dev->usbdev = interface_to_usbdev(pfunction);\n\trsi_dev->priv = (void *)adapter;\n\n\tif (rsi_find_bulk_in_and_out_endpoints(pfunction, adapter)) {\n\t\tstatus = -EINVAL;\n\t\tgoto fail_eps;\n\t}\n\n\tadapter->device = &pfunction->dev;\n\tusb_set_intfdata(pfunction, adapter);\n\n\trsi_dev->tx_buffer = kmalloc(2048, GFP_KERNEL);\n\tif (!rsi_dev->tx_buffer) {\n\t\tstatus = -ENOMEM;\n\t\tgoto fail_eps;\n\t}\n\n\tif (rsi_usb_init_rx(adapter)) {\n\t\trsi_dbg(ERR_ZONE, \"Failed to init RX handle\\n\");\n\t\tstatus = -ENOMEM;\n\t\tgoto fail_rx;\n\t}\n\n\trsi_dev->tx_blk_size = 252;\n\tadapter->block_size = rsi_dev->tx_blk_size;\n\n\t/* Initializing function callbacks */\n\tadapter->check_hw_queue_status = rsi_usb_check_queue_status;\n\tadapter->determine_event_timeout = rsi_usb_event_timeout;\n\tadapter->rsi_host_intf = RSI_HOST_INTF_USB;\n\tadapter->host_intf_ops = &usb_host_intf_ops;\n\n#ifdef CONFIG_RSI_DEBUGFS\n\t/* In USB, one less than the MAX_DEBUGFS_ENTRIES entries is required */\n\tadapter->num_debugfs_entries = (MAX_DEBUGFS_ENTRIES - 1);\n#endif\n\n\trsi_dbg(INIT_ZONE, \"%s: Enabled the interface\\n\", __func__);\n\treturn 0;\n\nfail_rx:\n\tkfree(rsi_dev->tx_buffer);\n\nfail_eps:\n\tkfree(rsi_dev);\n\n\treturn status;\n}",
        "func_hash": 38914523915054214786919182237560230029,
        "file_name": "rsi_91x_usb.c",
        "file_hash": 337775591275050809530599688018008269692,
        "cwe": [
            "CWE-415"
        ],
        "cve": "CVE-2019-15504",
        "cve_desc": "drivers/net/wireless/rsi/rsi_91x_usb.c in the Linux kernel through 5.2.9 has a Double Free via crafted USB device traffic (which may be remote via usbip or usbredir).",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2019-15504",
        "func_name": "rsi_init_usb_interface",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 201382,
        "project": "gerbv",
        "commit_id": "672214abb47a802fc000125996e6e0a46c623a4e",
        "project_url": "https://github.com/gerbv/gerbv",
        "commit_url": "https://github.com/gerbv/gerbv/commit/672214abb47a802fc000125996e6e0a46c623a4e",
        "commit_message": "Add test to demonstrate buffer overrun",
        "target": 1,
        "irrelevant": 0,
        "func_before": "drill_parse_T_code(gerb_file_t *fd, drill_state_t *state,\n\t\t\tgerbv_image_t *image, ssize_t file_line)\n{\n    int tool_num;\n    gboolean done = FALSE;\n    int temp;\n    double size;\n    gerbv_drill_stats_t *stats = image->drill_stats;\n    gerbv_aperture_t *apert;\n    gchar *tmps;\n    gchar *string;\n\n    dprintf(\"---> entering %s()...\\n\", __FUNCTION__);\n\n    /* Sneak a peek at what's hiding after the 'T'. Ugly fix for\n       broken headers from Orcad, which is crap */\n    temp = gerb_fgetc(fd);\n    dprintf(\"  Found a char '%s' (0x%02x) after the T\\n\",\n\t    gerbv_escape_char(temp), temp);\n    \n    /* might be a tool tool change stop switch on/off*/\n    if((temp == 'C') && ((fd->ptr + 2) < fd->datalen)){\n    \tif(gerb_fgetc(fd) == 'S'){\n    \t    if (gerb_fgetc(fd) == 'T' ){\n    \t  \tfd->ptr -= 4;\n    \t  \ttmps = get_line(fd++);\n    \t  \tgerbv_stats_printf(stats->error_list, GERBV_MESSAGE_NOTE, -1,\n\t\t\t_(\"Tool change stop switch found \\\"%s\\\" \"\n\t\t\t    \"at line %ld in file \\\"%s\\\"\"),\n\t\t\ttmps, file_line, fd->filename);\n\t  \tg_free (tmps);\n\n\t  \treturn -1;\n\t    }\n\t    gerb_ungetc(fd);\n\t}\n\tgerb_ungetc(fd);\n    }\n\n    if( !(isdigit(temp) != 0 || temp == '+' || temp =='-') ) {\n\tif(temp != EOF) {\n\t    gerbv_stats_printf(stats->error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t   _(\"OrCAD bug: Junk text found in place of tool definition\"));\n\t    tmps = get_line(fd);\n\t    gerbv_stats_printf(stats->error_list, GERBV_MESSAGE_WARNING, -1,\n\t\t    _(\"Junk text \\\"%s\\\" \"\n\t\t\t\"at line %ld in file \\\"%s\\\"\"),\n\t\t    tmps, file_line, fd->filename);\n\t    g_free (tmps);\n\t    gerbv_stats_printf(stats->error_list, GERBV_MESSAGE_WARNING, -1,\n\t\t\t\t  _(\"Ignoring junk text\"));\n\t}\n\treturn -1;\n    }\n    gerb_ungetc(fd);\n\n    tool_num = (int) gerb_fgetint(fd, NULL);\n    dprintf (\"  Handling tool T%d at line %ld\\n\", tool_num, file_line);\n\n    if (tool_num == 0) \n\treturn tool_num; /* T00 is a command to unload the drill */\n\n    if (tool_num < TOOL_MIN || tool_num >= TOOL_MAX) {\n\tgerbv_stats_printf(stats->error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t_(\"Out of bounds drill number %d \"\n\t\t    \"at line %ld in file \\\"%s\\\"\"),\n\t\ttool_num, file_line, fd->filename);\n    }\n\n    /* Set the current tool to the correct one */\n    state->current_tool = tool_num;\n    apert = image->aperture[tool_num];\n\n    /* Check for a size definition */\n    temp = gerb_fgetc(fd);\n\n    /* This bit of code looks for a tool definition by scanning for strings\n     * of form TxxC, TxxF, TxxS.  */\n    while (!done) {\n\tswitch((char)temp) {\n\tcase 'C':\n\t    size = read_double(fd, state->header_number_format, GERBV_OMIT_ZEROS_TRAILING, state->decimals);\n\t    dprintf (\"  Read a size of %g\\n\", size);\n\n\t    if (state->unit == GERBV_UNIT_MM) {\n\t\tsize /= 25.4;\n\t    } else if(size >= 4.0) {\n\t\t/* If the drill size is >= 4 inches, assume that this\n\t\t   must be wrong and that the units are mils.\n\t\t   The limit being 4 inches is because the smallest drill\n\t\t   I've ever seen used is 0,3mm(about 12mil). Half of that\n\t\t   seemed a bit too small a margin, so a third it is */\n\n\t\tgerbv_stats_printf(stats->error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t\t_(\"Read a drill of diameter %g inches \"\n\t\t\t    \"at line %ld in file \\\"%s\\\"\"),\n\t\t\t    size, file_line, fd->filename);\n\t\tgerbv_stats_printf(stats->error_list, GERBV_MESSAGE_WARNING, -1,\n\t\t\t_(\"Assuming units are mils\"));\n\t\tsize /= 1000.0;\n\t    }\n\n\t    if (size <= 0. || size >= 10000.) {\n\t\tgerbv_stats_printf(stats->error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t\t_(\"Unreasonable drill size %g found for drill %d \"\n\t\t\t    \"at line %ld in file \\\"%s\\\"\"),\n\t\t\t    size, tool_num, file_line, fd->filename);\n\t    } else {\n\t\tif (apert != NULL) {\n\t\t    /* allow a redefine of a tool only if the new definition is exactly the same.\n\t\t     * This avoid lots of spurious complaints with the output of some cad\n\t\t     * tools while keeping complaints if there is a true problem\n\t\t     */\n\t\t    if (apert->parameter[0] != size\n\t\t    ||  apert->type != GERBV_APTYPE_CIRCLE\n\t\t    ||  apert->nuf_parameters != 1\n\t\t    ||  apert->unit != GERBV_UNIT_INCH) {\n\n\t\t\tgerbv_stats_printf(stats->error_list,\n\t\t\t\tGERBV_MESSAGE_ERROR, -1,\n\t\t\t\t_(\"Found redefinition of drill %d \"\n\t\t\t\t\"at line %ld in file \\\"%s\\\"\"),\n\t\t\t\ttool_num, file_line, fd->filename);\n\t\t    }\n\t\t} else {\n\t\t    apert = image->aperture[tool_num] =\n\t\t\t\t\t\tg_new0(gerbv_aperture_t, 1);\n\t\t    if (apert == NULL)\n\t\t\tGERB_FATAL_ERROR(\"malloc tool failed in %s()\",\n\t\t\t\t\t__FUNCTION__);\n\n\t\t    /* There's really no way of knowing what unit the tools\n\t\t       are defined in without sneaking a peek in the rest of\n\t\t       the file first. That's done in drill_guess_format() */\n\t\t    apert->parameter[0] = size;\n\t\t    apert->type = GERBV_APTYPE_CIRCLE;\n\t\t    apert->nuf_parameters = 1;\n\t\t    apert->unit = GERBV_UNIT_INCH;\n\t\t}\n\t    }\n\t    \n\t    /* Add the tool whose definition we just found into the list\n\t     * of tools for this layer used to generate statistics. */\n\t    stats = image->drill_stats;\n\t    string = g_strdup_printf(\"%s\", (state->unit == GERBV_UNIT_MM ? _(\"mm\") : _(\"inch\")));\n\t    drill_stats_add_to_drill_list(stats->drill_list, \n\t\t\t\t\t  tool_num, \n\t\t\t\t\t  state->unit == GERBV_UNIT_MM ? size*25.4 : size, \n\t\t\t\t\t  string);\n\t    g_free(string);\n\t    break;\n\n\tcase 'F':\n\tcase 'S' :\n\t    /* Silently ignored. They're not important. */\n\t    gerb_fgetint(fd, NULL);\n\t    break;\n\n\tdefault:\n\t    /* Stop when finding anything but what's expected\n\t       (and put it back) */\n\t    gerb_ungetc(fd);\n\t    done = TRUE;\n\t    break;\n\t}  /* switch((char)temp) */\n\n\ttemp = gerb_fgetc(fd);\n\tif (EOF == temp) {\n\t    gerbv_stats_printf(stats->error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t    _(\"Unexpected EOF encountered in header of \"\n\t\t\t\"drill file \\\"%s\\\"\"), fd->filename);\n\n\t/* Restore new line character for processing */\n\tif ('\\n' == temp || '\\r' == temp)\n\t    gerb_ungetc(fd);\n\t}\n    }   /* while(!done) */  /* Done looking at tool definitions */\n\n    /* Catch the tools that aren't defined.\n       This isn't strictly a good thing, but at least something is shown */\n    if (apert == NULL) {\n        double dia;\n\n\tapert = image->aperture[tool_num] = g_new0(gerbv_aperture_t, 1);\n\tif (apert == NULL)\n\t    GERB_FATAL_ERROR(\"malloc tool failed in %s()\", __FUNCTION__);\n\n        /* See if we have the tool table */\n        dia = gerbv_get_tool_diameter(tool_num);\n        if (dia <= 0) {\n            /*\n             * There is no tool. So go out and make some.\n             * This size calculation is, of course, totally bogus.\n             */\n            dia = (double)(16 + 8 * tool_num) / 1000;\n            /*\n             * Oooh, this is sooo ugly. But some CAD systems seem to always\n             * use T00 at the end of the file while others that don't have\n             * tool definitions inside the file never seem to use T00 at all.\n             */\n            if (tool_num != 0) {\n\t\tgerbv_stats_printf(stats->error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t\t_(\"Tool %02d used without being defined \"\n\t\t\t    \"at line %ld in file \\\"%s\\\"\"),\n\t\t\ttool_num, file_line, fd->filename);\n\t\tgerbv_stats_printf(stats->error_list, GERBV_MESSAGE_WARNING, -1,\n\t\t\t_(\"Setting a default size of %g\\\"\"), dia);\n            }\n\t}\n\n\tapert->type = GERBV_APTYPE_CIRCLE;\n\tapert->nuf_parameters = 1;\n\tapert->parameter[0] = dia;\n\n\t/* Add the tool whose definition we just found into the list\n\t * of tools for this layer used to generate statistics. */\n\tif (tool_num != 0) {  /* Only add non-zero tool nums.  \n\t\t\t       * Zero = unload command. */\n\t    stats = image->drill_stats;\n\t    string = g_strdup_printf(\"%s\", \n\t\t\t\t     (state->unit == GERBV_UNIT_MM ? _(\"mm\") : _(\"inch\")));\n\t    drill_stats_add_to_drill_list(stats->drill_list, \n\t\t\t\t\t  tool_num, \n\t\t\t\t\t  state->unit == GERBV_UNIT_MM ? dia*25.4 : dia,\n\t\t\t\t\t  string);\n\t    g_free(string);\n\t}\n    } /* if(image->aperture[tool_num] == NULL) */\t\n    \n    dprintf(\"<----  ...leaving %s()\\n\", __FUNCTION__);\n\n    return tool_num;\n} /* drill_parse_T_code() */",
        "func_hash": 185752158214328372341115505036759500651,
        "file_name": "drill.c",
        "file_hash": 62463866492734341751893387181625909179,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2021-40391",
        "cve_desc": "An out-of-bounds write vulnerability exists in the drill format T-code tool number functionality of Gerbv 2.7.0, dev (commit b5f1eacd), and the forked version of Gerbv (commit 71493260). A specially-crafted drill file can lead to code execution. An attacker can provide a malicious file to trigger this vulnerability.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-40391",
        "func_name": "drill_parse_T_code",
        "diff": [
            "diff --git a/src/drill.c b/src/drill.c\nindex c571b3b5..7e1e24f6 100644\n--- a/src/drill.c\n+++ b/src/drill.c\n@@ -1116,6 +1116,7 @@ drill_parse_T_code(gerb_file_t *fd, drill_state_t *state,\n \t\t_(\"Out of bounds drill number %d \"\n \t\t    \"at line %ld in file \\\"%s\\\"\"),\n \t\ttool_num, file_line, fd->filename);\n+\treturn -1;\n     }\n \n     /* Set the current tool to the correct one */\ndiff --git a/test/golden/out-of-bounds-drill-tool.png b/test/golden/out-of-bounds-drill-tool.png\nnew file mode 100644\nindex 00000000..9015ba79\nBinary files /dev/null and b/test/golden/out-of-bounds-drill-tool.png differ\ndiff --git a/test/inputs/test-out-of-bounds-drill-tool.exc b/test/inputs/test-out-of-bounds-drill-tool.exc\nnew file mode 100644\nindex 00000000..2ec8bcca\n--- /dev/null\n+++ b/test/inputs/test-out-of-bounds-drill-tool.exc\n@@ -0,0 +1,10 @@\n+G90\r\n+M72\r\n+M48\r\n+T10950C0.12345\r\n+%\r\n+G90\r\n+M72\r\n+M48\r\n+%\r\n+M30\r\ndiff --git a/test/run_valgrind_tests.sh b/test/run_valgrind_tests.sh\nindex ba522078..f805849f 100755\n--- a/test/run_valgrind_tests.sh\n+++ b/test/run_valgrind_tests.sh\n@@ -1,2 +1,2 @@\n #!/bin/sh\n-./run_tests.sh --valgrind example_cslk\n+./run_tests.sh --valgrind example_cslk out-of-bounds-drill-tool\ndiff --git a/test/tests.list b/test/tests.list\nindex 787444de..031a98e6 100644\n--- a/test/tests.list\n+++ b/test/tests.list\n@@ -194,3 +194,6 @@ test-drill-trailing-zero-suppression | test-drill-trailing-zero-suppression.exc\n \n # Test \"G85\" drilled slot\n test-drill-slot-drilled-g85 | test-drill-slot-drilled-g85.exc\n+\n+# Out of bounds drill tool\n+out-of-bounds-drill-tool | test-out-of-bounds-drill-tool.exc\n"
        ],
        "func_after": []
    },
    {
        "idx": 201384,
        "project": "vim",
        "commit_id": "34f8117dec685ace52cd9e578e2729db278163fc",
        "project_url": "https://github.com/vim/vim",
        "commit_url": "https://github.com/vim/vim/commit/34f8117dec685ace52cd9e578e2729db278163fc",
        "commit_message": "patch 8.2.4397: crash when using many composing characters in error message\n\nProblem:    Crash when using many composing characters in error message.\nSolution:   Use mb_cptr2char_adv() instead of mb_ptr2char_adv().",
        "target": 1,
        "irrelevant": 0,
        "func_before": "ga_concat_shorten_esc(garray_T *gap, char_u *str)\n{\n    char_u  *p;\n    char_u  *s;\n    int\t    c;\n    int\t    clen;\n    char_u  buf[NUMBUFLEN];\n    int\t    same_len;\n\n    if (str == NULL)\n    {\n\tga_concat(gap, (char_u *)\"NULL\");\n\treturn;\n    }\n\n    for (p = str; *p != NUL; ++p)\n    {\n\tsame_len = 1;\n\ts = p;\n\tc = mb_ptr2char_adv(&s);\n\tclen = s - p;\n\twhile (*s != NUL && c == mb_ptr2char(s))\n\t{\n\t    ++same_len;\n\t    s += clen;\n\t}\n\tif (same_len > 20)\n\t{\n\t    ga_concat(gap, (char_u *)\"\\\\[\");\n\t    ga_concat_esc(gap, p, clen);\n\t    ga_concat(gap, (char_u *)\" occurs \");\n\t    vim_snprintf((char *)buf, NUMBUFLEN, \"%d\", same_len);\n\t    ga_concat(gap, buf);\n\t    ga_concat(gap, (char_u *)\" times]\");\n\t    p = s - 1;\n\t}\n\telse\n\t    ga_concat_esc(gap, p, clen);\n    }\n}",
        "func_hash": 50963215449221402235184881814854547880,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2022-0629",
        "cve_desc": "Stack-based Buffer Overflow in GitHub repository vim/vim prior to 8.2.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-0629",
        "func_name": "ga_concat_shorten_esc",
        "diff": [
            "diff --git a/src/testdir/test_assert.vim b/src/testdir/test_assert.vim\nindex 8987f3f8dfcd3c..27b2d73fbfc80f 100644\n--- a/src/testdir/test_assert.vim\n+++ b/src/testdir/test_assert.vim\n@@ -53,6 +53,14 @@ func Test_assert_equal()\n   call assert_equal(\"\\b\\e\\f\\n\\t\\r\\\\\\x01\\x7f\", 'x')\n   call assert_match('Expected ''\\\\b\\\\e\\\\f\\\\n\\\\t\\\\r\\\\\\\\\\\\x01\\\\x7f'' but got ''x''', v:errors[0])\n   call remove(v:errors, 0)\n+\n+  \" many composing characters are handled properly\n+  call setline(1, ' ')\n+  norm 100gr\u0740\n+  call assert_equal(1, getline(1))\n+  call assert_match(\"Expected 1 but got '.* occurs 100 times]'\", v:errors[0])\n+  call remove(v:errors, 0)\n+  bwipe!\n endfunc\n \n func Test_assert_equal_dict()\ndiff --git a/src/testing.c b/src/testing.c\nindex 448c01c1e9648b..48ba14d2cafd5d 100644\n--- a/src/testing.c\n+++ b/src/testing.c\n@@ -101,7 +101,7 @@ ga_concat_shorten_esc(garray_T *gap, char_u *str)\n     {\n \tsame_len = 1;\n \ts = p;\n-\tc = mb_ptr2char_adv(&s);\n+\tc = mb_cptr2char_adv(&s);\n \tclen = s - p;\n \twhile (*s != NUL && c == mb_ptr2char(s))\n \t{\ndiff --git a/src/version.c b/src/version.c\nindex fb1b8476e1a6c7..b4983661cadcce 100644\n--- a/src/version.c\n+++ b/src/version.c\n@@ -750,6 +750,8 @@ static char *(features[]) =\n \n static int included_patches[] =\n {   /* Add new patch number below this line */\n+/**/\n+    4397,\n /**/\n     4396,\n /**/\n"
        ],
        "func_after": []
    },
    {
        "idx": 201451,
        "project": "ImageMagick6",
        "commit_id": "e6ea5876e0228165ee3abc6e959aa174cee06680",
        "project_url": "https://github.com/ImageMagick/ImageMagick6",
        "commit_url": "https://github.com/ImageMagick/ImageMagick6/commit/e6ea5876e0228165ee3abc6e959aa174cee06680",
        "commit_message": "https://github.com/ImageMagick/ImageMagick/issues/4988",
        "target": 1,
        "irrelevant": 1,
        "func_before": "static Image *ReadCINImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n#define MonoColorType  1\n#define RGBColorType  3\n\n  char\n    property[MaxTextExtent];\n\n  CINInfo\n    cin;\n\n  Image\n    *image;\n\n  MagickBooleanType\n    status;\n\n  MagickOffsetType\n    offset;\n\n  QuantumInfo\n    *quantum_info;\n\n  QuantumType\n    quantum_type;\n\n  ssize_t\n    i;\n\n  PixelPacket\n    *q;\n\n  size_t\n    extent,\n    length;\n\n  ssize_t\n    count,\n    y;\n\n  unsigned char\n    magick[4],\n    *pixels;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  image=AcquireImage(image_info);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    File information.\n  */\n  offset=0;\n  count=ReadBlob(image,4,magick);\n  offset+=count;\n  if ((count != 4) ||\n      ((LocaleNCompare((char *) magick,\"\\200\\052\\137\\327\",4) != 0)))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  memset(&cin,0,sizeof(cin));\n  image->endian=(magick[0] == 0x80) && (magick[1] == 0x2a) &&\n    (magick[2] == 0x5f) && (magick[3] == 0xd7) ? MSBEndian : LSBEndian;\n  cin.file.image_offset=ReadBlobLong(image);\n  offset+=4;\n  cin.file.generic_length=ReadBlobLong(image);\n  offset+=4;\n  cin.file.industry_length=ReadBlobLong(image);\n  offset+=4;\n  cin.file.user_length=ReadBlobLong(image);\n  offset+=4;\n  cin.file.file_size=ReadBlobLong(image);\n  offset+=4;\n  offset+=ReadBlob(image,sizeof(cin.file.version),(unsigned char *)\n    cin.file.version);\n  (void) CopyMagickString(property,cin.file.version,sizeof(cin.file.version));\n  (void) SetImageProperty(image,\"dpx:file.version\",property);\n  offset+=ReadBlob(image,sizeof(cin.file.filename),(unsigned char *)\n    cin.file.filename);\n  (void) CopyMagickString(property,cin.file.filename,sizeof(cin.file.filename));\n  (void) SetImageProperty(image,\"dpx:file.filename\",property);\n  offset+=ReadBlob(image,sizeof(cin.file.create_date),(unsigned char *)\n    cin.file.create_date);\n  (void) CopyMagickString(property,cin.file.create_date,\n    sizeof(cin.file.create_date));\n  (void) SetImageProperty(image,\"dpx:file.create_date\",property);\n  offset+=ReadBlob(image,sizeof(cin.file.create_time),(unsigned char *)\n    cin.file.create_time);\n  (void) CopyMagickString(property,cin.file.create_time,\n     sizeof(cin.file.create_time));\n  (void) SetImageProperty(image,\"dpx:file.create_time\",property);\n  offset+=ReadBlob(image,sizeof(cin.file.reserve),(unsigned char *)\n    cin.file.reserve);\n  /*\n    Image information.\n  */\n  cin.image.orientation=(unsigned char) ReadBlobByte(image);\n  offset++;\n  if (cin.image.orientation != (unsigned char) (~0))\n    (void) FormatImageProperty(image,\"dpx:image.orientation\",\"%d\",\n      cin.image.orientation);\n  switch (cin.image.orientation)\n  {\n    default:\n    case 0: image->orientation=TopLeftOrientation; break;\n    case 1: image->orientation=TopRightOrientation; break;\n    case 2: image->orientation=BottomLeftOrientation; break;\n    case 3: image->orientation=BottomRightOrientation; break;\n    case 4: image->orientation=LeftTopOrientation; break;\n    case 5: image->orientation=RightTopOrientation; break;\n    case 6: image->orientation=LeftBottomOrientation; break;\n    case 7: image->orientation=RightBottomOrientation; break;\n  }\n  cin.image.number_channels=(unsigned char) ReadBlobByte(image);\n  offset++;\n  offset+=ReadBlob(image,sizeof(cin.image.reserve1),(unsigned char *)\n    cin.image.reserve1);\n  for (i=0; i < 8; i++)\n  {\n    cin.image.channel[i].designator[0]=(unsigned char) ReadBlobByte(image);\n    offset++;\n    cin.image.channel[i].designator[1]=(unsigned char) ReadBlobByte(image);\n    offset++;\n    cin.image.channel[i].bits_per_pixel=(unsigned char) ReadBlobByte(image);\n    offset++;\n    cin.image.channel[i].reserve=(unsigned char) ReadBlobByte(image);\n    offset++;\n    cin.image.channel[i].pixels_per_line=ReadBlobLong(image);\n    offset+=4;\n    cin.image.channel[i].lines_per_image=ReadBlobLong(image);\n    offset+=4;\n    cin.image.channel[i].min_data=ReadBlobFloat(image);\n    offset+=4;\n    cin.image.channel[i].min_quantity=ReadBlobFloat(image);\n    offset+=4;\n    cin.image.channel[i].max_data=ReadBlobFloat(image);\n    offset+=4;\n    cin.image.channel[i].max_quantity=ReadBlobFloat(image);\n    offset+=4;\n  }\n  cin.image.white_point[0]=ReadBlobFloat(image);\n  offset+=4;\n  if (IsFloatDefined(cin.image.white_point[0]) != MagickFalse)\n    image->chromaticity.white_point.x=cin.image.white_point[0];\n  cin.image.white_point[1]=ReadBlobFloat(image);\n  offset+=4;\n  if (IsFloatDefined(cin.image.white_point[1]) != MagickFalse)\n    image->chromaticity.white_point.y=cin.image.white_point[1];\n  cin.image.red_primary_chromaticity[0]=ReadBlobFloat(image);\n  offset+=4;\n  if (IsFloatDefined(cin.image.red_primary_chromaticity[0]) != MagickFalse)\n    image->chromaticity.red_primary.x=cin.image.red_primary_chromaticity[0];\n  cin.image.red_primary_chromaticity[1]=ReadBlobFloat(image);\n  offset+=4;\n  if (IsFloatDefined(cin.image.red_primary_chromaticity[1]) != MagickFalse)\n    image->chromaticity.red_primary.y=cin.image.red_primary_chromaticity[1];\n  cin.image.green_primary_chromaticity[0]=ReadBlobFloat(image);\n  offset+=4;\n  if (IsFloatDefined(cin.image.green_primary_chromaticity[0]) != MagickFalse)\n    image->chromaticity.red_primary.x=cin.image.green_primary_chromaticity[0];\n  cin.image.green_primary_chromaticity[1]=ReadBlobFloat(image);\n  offset+=4;\n  if (IsFloatDefined(cin.image.green_primary_chromaticity[1]) != MagickFalse)\n    image->chromaticity.green_primary.y=cin.image.green_primary_chromaticity[1];\n  cin.image.blue_primary_chromaticity[0]=ReadBlobFloat(image);\n  offset+=4;\n  if (IsFloatDefined(cin.image.blue_primary_chromaticity[0]) != MagickFalse)\n    image->chromaticity.blue_primary.x=cin.image.blue_primary_chromaticity[0];\n  cin.image.blue_primary_chromaticity[1]=ReadBlobFloat(image);\n  offset+=4;\n  if (IsFloatDefined(cin.image.blue_primary_chromaticity[1]) != MagickFalse)\n    image->chromaticity.blue_primary.y=cin.image.blue_primary_chromaticity[1];\n  offset+=ReadBlob(image,sizeof(cin.image.label),(unsigned char *)\n    cin.image.label);\n  (void) CopyMagickString(property,cin.image.label,sizeof(cin.image.label));\n  (void) SetImageProperty(image,\"dpx:image.label\",property);\n  offset+=ReadBlob(image,sizeof(cin.image.reserve),(unsigned char *)\n    cin.image.reserve);\n  /*\n    Image data format information.\n  */\n  cin.data_format.interleave=(unsigned char) ReadBlobByte(image);\n  offset++;\n  cin.data_format.packing=(unsigned char) ReadBlobByte(image);\n  offset++;\n  cin.data_format.sign=(unsigned char) ReadBlobByte(image);\n  offset++;\n  cin.data_format.sense=(unsigned char) ReadBlobByte(image);\n  offset++;\n  cin.data_format.line_pad=ReadBlobLong(image);\n  offset+=4;\n  cin.data_format.channel_pad=ReadBlobLong(image);\n  offset+=4;\n  offset+=ReadBlob(image,sizeof(cin.data_format.reserve),(unsigned char *)\n    cin.data_format.reserve);\n  /*\n    Image origination information.\n  */\n  cin.origination.x_offset=ReadBlobSignedLong(image);\n  offset+=4;\n  if ((size_t) cin.origination.x_offset != ~0UL)\n    (void) FormatImageProperty(image,\"dpx:origination.x_offset\",\"%.20g\",\n      (double) cin.origination.x_offset);\n  cin.origination.y_offset=(ssize_t) ReadBlobLong(image);\n  offset+=4;\n  if ((size_t) cin.origination.y_offset != ~0UL)\n    (void) FormatImageProperty(image,\"dpx:origination.y_offset\",\"%.20g\",\n      (double) cin.origination.y_offset);\n  offset+=ReadBlob(image,sizeof(cin.origination.filename),(unsigned char *)\n    cin.origination.filename);\n  (void) CopyMagickString(property,cin.origination.filename,\n    sizeof(cin.origination.filename));\n  (void) SetImageProperty(image,\"dpx:origination.filename\",property);\n  offset+=ReadBlob(image,sizeof(cin.origination.create_date),(unsigned char *)\n    cin.origination.create_date);\n  (void) CopyMagickString(property,cin.origination.create_date,\n    sizeof(cin.origination.create_date));\n  (void) SetImageProperty(image,\"dpx:origination.create_date\",property);\n  offset+=ReadBlob(image,sizeof(cin.origination.create_time),(unsigned char *)\n    cin.origination.create_time);\n  (void) CopyMagickString(property,cin.origination.create_time,\n    sizeof(cin.origination.create_time));\n  (void) SetImageProperty(image,\"dpx:origination.create_time\",property);\n  offset+=ReadBlob(image,sizeof(cin.origination.device),(unsigned char *)\n    cin.origination.device);\n  (void) CopyMagickString(property,cin.origination.device,\n    sizeof(cin.origination.device));\n  (void) SetImageProperty(image,\"dpx:origination.device\",property);\n  offset+=ReadBlob(image,sizeof(cin.origination.model),(unsigned char *)\n    cin.origination.model);\n  (void) CopyMagickString(property,cin.origination.model,\n    sizeof(cin.origination.model));\n  (void) SetImageProperty(image,\"dpx:origination.model\",property);\n  (void) memset(cin.origination.serial,0,\n    sizeof(cin.origination.serial));\n  offset+=ReadBlob(image,sizeof(cin.origination.serial),(unsigned char *)\n    cin.origination.serial);\n  (void) CopyMagickString(property,cin.origination.serial,\n    sizeof(cin.origination.serial));\n  (void) SetImageProperty(image,\"dpx:origination.serial\",property);\n  cin.origination.x_pitch=ReadBlobFloat(image);\n  offset+=4;\n  cin.origination.y_pitch=ReadBlobFloat(image);\n  offset+=4;\n  cin.origination.gamma=ReadBlobFloat(image);\n  offset+=4;\n  if (IsFloatDefined(cin.origination.gamma) != MagickFalse)\n    image->gamma=cin.origination.gamma;\n  offset+=ReadBlob(image,sizeof(cin.origination.reserve),(unsigned char *)\n    cin.origination.reserve);\n  if ((cin.file.image_offset > 2048) && (cin.file.user_length != 0))\n    {\n      int\n        c;\n\n      /*\n        Image film information.\n      */\n      cin.film.id=ReadBlobByte(image);\n      offset++;\n      c=cin.film.id;\n      if (c != ~0)\n        (void) FormatImageProperty(image,\"dpx:film.id\",\"%d\",cin.film.id);\n      cin.film.type=ReadBlobByte(image);\n      offset++;\n      c=cin.film.type;\n      if (c != ~0)\n        (void) FormatImageProperty(image,\"dpx:film.type\",\"%d\",cin.film.type);\n      cin.film.offset=ReadBlobByte(image);\n      offset++;\n      c=cin.film.offset;\n      if (c != ~0)\n        (void) FormatImageProperty(image,\"dpx:film.offset\",\"%d\",\n          cin.film.offset);\n      cin.film.reserve1=ReadBlobByte(image);\n      offset++;\n      cin.film.prefix=ReadBlobLong(image);\n      offset+=4;\n      if (cin.film.prefix != ~0UL)\n        (void) FormatImageProperty(image,\"dpx:film.prefix\",\"%.20g\",(double)\n          cin.film.prefix);\n      cin.film.count=ReadBlobLong(image);\n      offset+=4;\n      offset+=ReadBlob(image,sizeof(cin.film.format),(unsigned char *)\n        cin.film.format);\n      (void) CopyMagickString(property,cin.film.format,\n        sizeof(cin.film.format));\n      (void) SetImageProperty(image,\"dpx:film.format\",property);\n      cin.film.frame_position=ReadBlobLong(image);\n      offset+=4;\n      if (cin.film.frame_position != ~0UL)\n        (void) FormatImageProperty(image,\"dpx:film.frame_position\",\"%.20g\",\n          (double) cin.film.frame_position);\n      cin.film.frame_rate=ReadBlobFloat(image);\n      offset+=4;\n      if (IsFloatDefined(cin.film.frame_rate) != MagickFalse)\n        (void) FormatImageProperty(image,\"dpx:film.frame_rate\",\"%g\",\n          cin.film.frame_rate);\n      offset+=ReadBlob(image,sizeof(cin.film.frame_id),(unsigned char *)\n        cin.film.frame_id);\n      (void) CopyMagickString(property,cin.film.frame_id,\n        sizeof(cin.film.frame_id));\n      (void) SetImageProperty(image,\"dpx:film.frame_id\",property);\n      offset+=ReadBlob(image,sizeof(cin.film.slate_info),(unsigned char *)\n        cin.film.slate_info);\n      (void) CopyMagickString(property,cin.film.slate_info,\n        sizeof(cin.film.slate_info));\n      (void) SetImageProperty(image,\"dpx:film.slate_info\",property);\n      offset+=ReadBlob(image,sizeof(cin.film.reserve),(unsigned char *)\n        cin.film.reserve);\n    }\n  if ((cin.file.image_offset > 2048) && (cin.file.user_length != 0))\n    {\n      StringInfo\n        *profile;\n\n      /*\n        User defined data.\n      */\n      if (cin.file.user_length > GetBlobSize(image))\n        ThrowReaderException(CorruptImageError,\"InsufficientImageDataInFile\");\n      profile=BlobToStringInfo((const void *) NULL,cin.file.user_length);\n      if (profile == (StringInfo *) NULL)\n        ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n      offset+=ReadBlob(image,GetStringInfoLength(profile),\n        GetStringInfoDatum(profile));\n      (void) SetImageProfile(image,\"dpx:user.data\",profile);\n      profile=DestroyStringInfo(profile);\n    }\n  image->depth=cin.image.channel[0].bits_per_pixel;\n  image->columns=cin.image.channel[0].pixels_per_line;\n  image->rows=cin.image.channel[0].lines_per_image;\n  if (image_info->ping != MagickFalse)\n    {\n      (void) CloseBlob(image);\n      return(image);\n    }\n  if (((MagickSizeType) image->columns*image->rows/8) > GetBlobSize(image))\n    ThrowReaderException(CorruptImageError,\"InsufficientImageDataInFile\");\n  for ( ; offset < (MagickOffsetType) cin.file.image_offset; offset++)\n  {\n    int\n      c;\n\n    c=ReadBlobByte(image);\n    if (c == EOF)\n      break;\n  }\n  if (offset < (MagickOffsetType) cin.file.image_offset)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  status=SetImageExtent(image,image->columns,image->rows);\n  if (status == MagickFalse)\n    {\n      InheritException(exception,&image->exception);\n      return(DestroyImageList(image));\n    }\n  (void) SetImageBackgroundColor(image);\n  /*\n    Convert CIN raster image to pixel packets.\n  */\n  quantum_info=AcquireQuantumInfo(image_info,image);\n  if (quantum_info == (QuantumInfo *) NULL)\n    ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n  SetQuantumQuantum(quantum_info,32);\n  SetQuantumPack(quantum_info,MagickFalse);\n  quantum_type=RGBQuantum;\n  extent=GetQuantumExtent(image,quantum_info,quantum_type);\n  (void) extent;\n  length=GetBytesPerRow(image->columns,3,image->depth,MagickTrue);\n  if (cin.image.number_channels == 1)\n    {\n      quantum_type=GrayQuantum;\n      length=GetBytesPerRow(image->columns,1,image->depth,MagickTrue);\n    }\n  status=SetQuantumPad(image,quantum_info,0);\n  pixels=GetQuantumPixels(quantum_info);\n  for (y=0; y < (ssize_t) image->rows; y++)\n  {\n    const void\n      *stream;\n\n    q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n    if (q == (PixelPacket *) NULL)\n      break;\n    stream=ReadBlobStream(image,length,pixels,&count);\n    if (count != (ssize_t) length)\n      break;\n    (void) ImportQuantumPixels(image,(CacheView *) NULL,quantum_info,\n      quantum_type,(unsigned char *) stream,exception);\n    if (SyncAuthenticPixels(image,exception) == MagickFalse)\n      break;\n    if (image->previous == (Image *) NULL)\n      {\n        status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n          image->rows);\n        if (status == MagickFalse)\n          break;\n      }\n  }\n  SetQuantumImageType(image,quantum_type);\n  quantum_info=DestroyQuantumInfo(quantum_info);\n  if (EOFBlob(image) != MagickFalse)\n    ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n      image->filename);\n  SetImageColorspace(image,LogColorspace);\n  (void) CloseBlob(image);\n  return(GetFirstImageInList(image));\n}",
        "func_hash": 230911711267539175049972905344313345647,
        "file_name": "cin.c",
        "file_hash": 249228869233078232834553857521337694406,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2022-28463",
        "cve_desc": "ImageMagick 7.1.0-27 is vulnerable to Buffer Overflow.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-28463",
        "func_name": "ReadCINImage",
        "diff": [
            "diff --git a/coders/cin.c b/coders/cin.c\nindex 854b59758a..13e3cfe75b 100644\n--- a/coders/cin.c\n+++ b/coders/cin.c\n@@ -451,6 +451,8 @@ static Image *ReadCINImage(const ImageInfo *image_info,ExceptionInfo *exception)\n   image->endian=(magick[0] == 0x80) && (magick[1] == 0x2a) &&\n     (magick[2] == 0x5f) && (magick[3] == 0xd7) ? MSBEndian : LSBEndian;\n   cin.file.image_offset=ReadBlobLong(image);\n+  if (cin.file.image_offset < 712)\n+    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n   offset+=4;\n   cin.file.generic_length=ReadBlobLong(image);\n   offset+=4;\n"
        ],
        "func_after": []
    },
    {
        "idx": 201872,
        "project": "gnutls",
        "commit_id": "20a98e817713764b9df5306286091df1b61190d9",
        "project_url": "http://git.savannah.gnu.org/cgit/gnutls",
        "commit_url": "https://gitlab.com/gnutls/gnutls/commit/20a98e817713764b9df5306286091df1b61190d9",
        "commit_message": "handshake: check inappropriate fallback against the configured max version\n\nThat allows to operate on a server which is explicitly configured to\nutilize earlier than TLS 1.2 versions.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "_gnutls_server_select_suite(gnutls_session_t session, uint8_t * data,\n\t\t\t    unsigned int datalen)\n{\n\tint ret;\n\tunsigned int i, j, cipher_suites_size;\n\tsize_t pk_algos_size;\n\tuint8_t cipher_suites[MAX_CIPHERSUITE_SIZE];\n\tint retval;\n\tgnutls_pk_algorithm_t pk_algos[MAX_ALGOS];\t/* will hold the pk algorithms\n\t\t\t\t\t\t\t * supported by the peer.\n\t\t\t\t\t\t\t */\n\n\tfor (i = 0; i < datalen; i += 2) {\n\t\t/* TLS_RENEGO_PROTECTION_REQUEST = { 0x00, 0xff } */\n\t\tif (session->internals.priorities.sr != SR_DISABLED &&\n\t\t    data[i] == GNUTLS_RENEGO_PROTECTION_REQUEST_MAJOR &&\n\t\t    data[i + 1] == GNUTLS_RENEGO_PROTECTION_REQUEST_MINOR) {\n\t\t\t_gnutls_handshake_log\n\t\t\t    (\"HSK[%p]: Received safe renegotiation CS\\n\",\n\t\t\t     session);\n\t\t\tretval = _gnutls_ext_sr_recv_cs(session);\n\t\t\tif (retval < 0) {\n\t\t\t\tgnutls_assert();\n\t\t\t\treturn retval;\n\t\t\t}\n\t\t}\n\n\t\t/* TLS_FALLBACK_SCSV */\n\t\tif (data[i] == GNUTLS_FALLBACK_SCSV_MAJOR &&\n\t\t    data[i + 1] == GNUTLS_FALLBACK_SCSV_MINOR) {\n\t\t\t_gnutls_handshake_log\n\t\t\t    (\"HSK[%p]: Received fallback CS\\n\",\n\t\t\t     session);\n\n\t\t\tif (gnutls_protocol_get_version(session) !=\n\t\t\t    GNUTLS_TLS_VERSION_MAX)\n\t\t\t\treturn GNUTLS_E_INAPPROPRIATE_FALLBACK;\n\t\t}\n\t}\n\n\tpk_algos_size = MAX_ALGOS;\n\tret =\n\t    server_find_pk_algos_in_ciphersuites(data, datalen, pk_algos,\n\t\t\t\t\t\t &pk_algos_size);\n\tif (ret < 0)\n\t\treturn gnutls_assert_val(ret);\n\n\tret =\n\t    _gnutls_supported_ciphersuites(session, cipher_suites,\n\t\t\t\t\t   sizeof(cipher_suites));\n\tif (ret < 0)\n\t\treturn gnutls_assert_val(ret);\n\n\tcipher_suites_size = ret;\n\n\t/* Here we remove any ciphersuite that does not conform\n\t * the certificate requested, or to the\n\t * authentication requested (e.g. SRP).\n\t */\n\tret =\n\t    _gnutls_remove_unwanted_ciphersuites(session, cipher_suites,\n\t\t\t\t\t\t cipher_suites_size,\n\t\t\t\t\t\t pk_algos, pk_algos_size);\n\tif (ret <= 0) {\n\t\tgnutls_assert();\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t\telse\n\t\t\treturn GNUTLS_E_UNKNOWN_CIPHER_SUITE;\n\t}\n\n\tcipher_suites_size = ret;\n\n\t/* Data length should be zero mod 2 since\n\t * every ciphersuite is 2 bytes. (this check is needed\n\t * see below).\n\t */\n\tif (datalen % 2 != 0) {\n\t\tgnutls_assert();\n\t\treturn GNUTLS_E_UNEXPECTED_PACKET_LENGTH;\n\t}\n\n\tmemset(session->security_parameters.cipher_suite, 0, 2);\n\n\tretval = GNUTLS_E_UNKNOWN_CIPHER_SUITE;\n\n\t_gnutls_handshake_log\n\t    (\"HSK[%p]: Requested cipher suites[size: %d]: \\n\", session,\n\t     (int) datalen);\n\n\tif (session->internals.priorities.server_precedence == 0) {\n\t\tfor (j = 0; j < datalen; j += 2) {\n\t\t\t_gnutls_handshake_log(\"\\t0x%.2x, 0x%.2x %s\\n\",\n\t\t\t\t\t      data[j], data[j + 1],\n\t\t\t\t\t      _gnutls_cipher_suite_get_name\n\t\t\t\t\t      (&data[j]));\n\t\t\tfor (i = 0; i < cipher_suites_size; i += 2) {\n\t\t\t\tif (memcmp(&cipher_suites[i], &data[j], 2)\n\t\t\t\t    == 0) {\n\t\t\t\t\t_gnutls_handshake_log\n\t\t\t\t\t    (\"HSK[%p]: Selected cipher suite: %s\\n\",\n\t\t\t\t\t     session,\n\t\t\t\t\t     _gnutls_cipher_suite_get_name\n\t\t\t\t\t     (&data[j]));\n\t\t\t\t\tmemcpy(session->\n\t\t\t\t\t       security_parameters.\n\t\t\t\t\t       cipher_suite,\n\t\t\t\t\t       &cipher_suites[i], 2);\n\t\t\t\t\t_gnutls_epoch_set_cipher_suite\n\t\t\t\t\t    (session, EPOCH_NEXT,\n\t\t\t\t\t     session->security_parameters.\n\t\t\t\t\t     cipher_suite);\n\n\n\t\t\t\t\tretval = 0;\n\t\t\t\t\tgoto finish;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t} else {\t\t/* server selects */\n\n\t\tfor (i = 0; i < cipher_suites_size; i += 2) {\n\t\t\tfor (j = 0; j < datalen; j += 2) {\n\t\t\t\tif (memcmp(&cipher_suites[i], &data[j], 2)\n\t\t\t\t    == 0) {\n\t\t\t\t\t_gnutls_handshake_log\n\t\t\t\t\t    (\"HSK[%p]: Selected cipher suite: %s\\n\",\n\t\t\t\t\t     session,\n\t\t\t\t\t     _gnutls_cipher_suite_get_name\n\t\t\t\t\t     (&data[j]));\n\t\t\t\t\tmemcpy(session->\n\t\t\t\t\t       security_parameters.\n\t\t\t\t\t       cipher_suite,\n\t\t\t\t\t       &cipher_suites[i], 2);\n\t\t\t\t\t_gnutls_epoch_set_cipher_suite\n\t\t\t\t\t    (session, EPOCH_NEXT,\n\t\t\t\t\t     session->security_parameters.\n\t\t\t\t\t     cipher_suite);\n\n\n\t\t\t\t\tretval = 0;\n\t\t\t\t\tgoto finish;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n      finish:\n\n\tif (retval != 0) {\n\t\tgnutls_assert();\n\t\treturn retval;\n\t}\n\n\t/* check if the credentials (username, public key etc.) are ok\n\t */\n\tif (_gnutls_get_kx_cred\n\t    (session,\n\t     _gnutls_cipher_suite_get_kx_algo(session->security_parameters.\n\t\t\t\t\t      cipher_suite)) == NULL) {\n\t\tgnutls_assert();\n\t\treturn GNUTLS_E_INSUFFICIENT_CREDENTIALS;\n\t}\n\n\n\t/* set the mod_auth_st to the appropriate struct\n\t * according to the KX algorithm. This is needed since all the\n\t * handshake functions are read from there;\n\t */\n\tsession->internals.auth_struct =\n\t    _gnutls_kx_auth_struct(_gnutls_cipher_suite_get_kx_algo\n\t\t\t\t   (session->security_parameters.\n\t\t\t\t    cipher_suite));\n\tif (session->internals.auth_struct == NULL) {\n\n\t\t_gnutls_handshake_log\n\t\t    (\"HSK[%p]: Cannot find the appropriate handler for the KX algorithm\\n\",\n\t\t     session);\n\t\tgnutls_assert();\n\t\treturn GNUTLS_E_INTERNAL_ERROR;\n\t}\n\n\treturn 0;\n\n}",
        "func_hash": 43939075651028590089831343195417108850,
        "file_name": "gnutls_handshake.c",
        "file_hash": 33222600436004333309471609542396279978,
        "cwe": [
            "CWE-310"
        ],
        "cve": "CVE-2014-3566",
        "cve_desc": "The SSL protocol 3.0, as used in OpenSSL through 1.0.1i and other products, uses nondeterministic CBC padding, which makes it easier for man-in-the-middle attackers to obtain cleartext data via a padding-oracle attack, aka the \"POODLE\" issue.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2014-3566",
        "func_name": "_gnutls_server_select_suite",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 217254,
        "project": "ardour",
        "commit_id": "96daa4036a425ff3f23a7dfcba57bfb0f942bec6",
        "project_url": "https://github.com/Ardour/ardour",
        "commit_url": "https://github.com/Ardour/ardour/commit/96daa4036a425ff3f23a7dfcba57bfb0f942bec6",
        "commit_message": "fix apparent free-ordering issue reported in #7926",
        "target": 1,
        "irrelevant": 1,
        "func_before": "static XMLSharedNodeList* find_impl(xmlXPathContext* ctxt, const string& xpath)\n{\n\txmlXPathObject* result = xmlXPathEval((const xmlChar*)xpath.c_str(), ctxt);\n\n\tif (!result) {\n\t\txmlXPathFreeContext(ctxt);\n\t\txmlFreeDoc(ctxt->doc);\n\n\t\tthrow XMLException(\"Invalid XPath: \" + xpath);\n\t}\n\n\tif (result->type != XPATH_NODESET) {\n\t\txmlXPathFreeObject(result);\n\t\txmlXPathFreeContext(ctxt);\n\t\txmlFreeDoc(ctxt->doc);\n\n\t\tthrow XMLException(\"Only nodeset result types are supported.\");\n\t}\n\n\txmlNodeSet* nodeset = result->nodesetval;\n\tXMLSharedNodeList* nodes = new XMLSharedNodeList();\n\tif (nodeset) {\n\t\tfor (int i = 0; i < nodeset->nodeNr; ++i) {\n\t\t\tXMLNode* node = readnode(nodeset->nodeTab[i]);\n\t\t\tnodes->push_back(boost::shared_ptr<XMLNode>(node));\n\t\t}\n\t} else {\n\t\t// return empty set\n\t}\n\n\txmlXPathFreeObject(result);\n\n\treturn nodes;\n}",
        "func_hash": 302360056702262366271807964609080091494,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-416"
        ],
        "cve": "CVE-2020-22617",
        "cve_desc": "Ardour v5.12 contains a use-after-free vulnerability in the component ardour/libs/pbd/xml++.cc when using xmlFreeDoc and xmlXPathFreeContext.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2020-22617",
        "func_name": "find_impl",
        "diff": [
            "diff --git a/libs/pbd/xml++.cc b/libs/pbd/xml++.cc\nindex 598a7684b3e..e09af7602be 100644\n--- a/libs/pbd/xml++.cc\n+++ b/libs/pbd/xml++.cc\n@@ -770,16 +770,16 @@ static XMLSharedNodeList* find_impl(xmlXPathContext* ctxt, const string& xpath)\n \txmlXPathObject* result = xmlXPathEval((const xmlChar*)xpath.c_str(), ctxt);\n \n \tif (!result) {\n-\t\txmlXPathFreeContext(ctxt);\n \t\txmlFreeDoc(ctxt->doc);\n+\t\txmlXPathFreeContext(ctxt);\n \n \t\tthrow XMLException(\"Invalid XPath: \" + xpath);\n \t}\n \n \tif (result->type != XPATH_NODESET) {\n \t\txmlXPathFreeObject(result);\n-\t\txmlXPathFreeContext(ctxt);\n \t\txmlFreeDoc(ctxt->doc);\n+\t\txmlXPathFreeContext(ctxt);\n \n \t\tthrow XMLException(\"Only nodeset result types are supported.\");\n \t}\n"
        ],
        "func_after": []
    },
    {
        "idx": 217321,
        "project": "jsish",
        "commit_id": "858da537bde4de9d8c92466d5a866505310bc328",
        "project_url": "https://github.com/pcmacdon/jsish",
        "commit_url": "https://github.com/pcmacdon/jsish/commit/858da537bde4de9d8c92466d5a866505310bc328",
        "commit_message": "Release \"3.0.8\": Address Array alloc sizing issues from issue \"integer overflow and buffer overflow #5\".\n\nFossilOrigin-Name: 8c46a1d465b358110dcfb271721d35fe843a1b52f2fa24ccc10094eb8aaf6fe4",
        "target": 1,
        "irrelevant": 1,
        "func_before": "int Jsi_ObjArraySizer(Jsi_Interp *interp, Jsi_Obj *obj, uint len)\n{\n    int nsiz = len + 1, mod = ALLOC_MOD_SIZE;\n    assert(obj->isarrlist);\n    if (mod>1)\n        nsiz = nsiz + ((mod-1) - (nsiz + mod - 1)%mod);\n    if (nsiz > MAX_ARRAY_LIST) {\n        Jsi_LogError(\"array size too large\");\n        return 0;\n    }\n    if (len >= obj->arrMaxSize) {\n        int oldsz = (nsiz-obj->arrMaxSize);\n        obj->arr = (Jsi_Value**)Jsi_Realloc(obj->arr, nsiz*sizeof(Jsi_Value*));\n        memset(obj->arr+obj->arrMaxSize, 0, oldsz*sizeof(Jsi_Value*));\n        obj->arrMaxSize = nsiz;\n    }\n    if (len>obj->arrCnt)\n        obj->arrCnt = len;\n    return nsiz;\n}",
        "func_hash": 158587304886223234141585164472175789365,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-190"
        ],
        "cve": "CVE-2020-22874",
        "cve_desc": "Integer overflow vulnerability in function Jsi_ObjArraySizer in jsish before 3.0.8, allows remote attackers to execute arbitrary code.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2020-22874",
        "func_name": "Jsi_ObjArraySizer",
        "diff": [
            "diff --git a/md/Reference.md b/md/Reference.md\nindex f8313ea..a99d36c 100644\n--- a/md/Reference.md\n+++ b/md/Reference.md\n@@ -600,7 +600,7 @@ Otherwise waits until the sub-interp is idle, to make call and return result.</t\n <tr><td>lockTimeout</td><td><i>INT</i></td><td>Thread time-out for mutex lock acquires (milliseconds).</td><td><i></i></td></tr>\n <tr><td>logOpts</td><td><i><a href='#logOptsOptions'>options</a></i></td><td>Options for log output to add file/line/time.</td><td><i></i></td></tr>\n <tr><td>maxDepth</td><td><i>INT</i></td><td>Depth limit of recursive function calls (1000).</td><td><i></i></td></tr>\n-<tr><td>maxArrayList</td><td><i>INT</i></td><td>Maximum array convertable to list (100000).</td><td><i></i></td></tr>\n+<tr><td>maxArrayList</td><td><i>UINT</i></td><td>Maximum array convertable to list (100000).</td><td><i></i></td></tr>\n <tr><td>maxIncDepth</td><td><i>INT</i></td><td>Maximum allowed source/require nesting depth (50).</td><td><i></i></td></tr>\n <tr><td>maxInterpDepth</td><td><i>INT</i></td><td>Maximum nested subinterp create depth (10).</td><td><i></i></td></tr>\n <tr><td>maxUserObjs</td><td><i>INT</i></td><td>Maximum number of 'new' object calls, eg. File, RegExp, etc.</td><td><i></i></td></tr>\ndiff --git a/src/jsi.h b/src/jsi.h\nindex ba55da4..8a0b178 100644\n--- a/src/jsi.h\n+++ b/src/jsi.h\n@@ -4,7 +4,7 @@\n \n #define JSI_VERSION_MAJOR   3\n #define JSI_VERSION_MINOR   0\n-#define JSI_VERSION_RELEASE 7\n+#define JSI_VERSION_RELEASE 8\n \n #define JSI_VERSION (JSI_VERSION_MAJOR + ((Jsi_Number)JSI_VERSION_MINOR/100.0) + ((Jsi_Number)JSI_VERSION_RELEASE/10000.0))\n \ndiff --git a/src/jsiArray.c b/src/jsiArray.c\nindex 298ec75..64f9555 100644\n--- a/src/jsiArray.c\n+++ b/src/jsiArray.c\n@@ -267,7 +267,7 @@ static Jsi_RC jsi_ArrayFlatSub(Jsi_Interp *interp, Jsi_Obj* nobj, Jsi_Value *arr\n             rc = jsi_ArrayFlatSub(interp, nobj, t , depth-1);\n         else if (!Jsi_ValueIsUndef(interp, t))\n             Jsi_ObjArrayAdd(interp, nobj, t);\n-        if ((++n + clen)>interp->maxArrayList)\n+        if ((uint)(++n + clen)>interp->maxArrayList)\n             return Jsi_LogError(\"array size exceeded\");\n     }\n     return rc;\ndiff --git a/src/jsiCData.c b/src/jsiCData.c\nindex 4dbc91e..0bb82d9 100644\n--- a/src/jsiCData.c\n+++ b/src/jsiCData.c\n@@ -1276,8 +1276,8 @@ static Jsi_RC CDataStructDefineCmd(Jsi_Interp *interp, Jsi_Value *args, Jsi_Valu\n             sf->flags |= JSI_OPT_BITSET_ENUM;\n         }\n         if (sf->arrSize) {\n-            if (sf->arrSize>MAX_ARRAY_LIST) {\n-                rc = Jsi_LogError(\"array size too big: %d >= %d\", sf->arrSize, MAX_ARRAY_LIST);\n+            if (sf->arrSize>interp->maxArrayList) {\n+                rc = Jsi_LogError(\"array size too big: %d >= %d\", sf->arrSize, interp->maxArrayList);\n                 goto bail;\n             }\n             if (sf->bits || isEnum) {\ndiff --git a/src/jsiInt.h b/src/jsiInt.h\nindex 03fa347..87cb6eb 100644\n--- a/src/jsiInt.h\n+++ b/src/jsiInt.h\n@@ -1259,7 +1259,7 @@ struct Jsi_Interp {\n     Jsi_Value *Top_object;\n     Jsi_ScopeStrs *scopes[JSI_MAX_SCOPE];\n     int cur_scope;\n-    int maxArrayList;\n+    uint maxArrayList;\n     int delRBCnt;\n     Jsi_Func *activeFunc;  // Currently active function call.\n     Jsi_Func *prevActiveFunc;  // Prev active function call.\ndiff --git a/src/jsiInterp.c b/src/jsiInterp.c\nindex 508f62f..133a74e 100644\n--- a/src/jsiInterp.c\n+++ b/src/jsiInterp.c\n@@ -100,7 +100,7 @@ static Jsi_OptionSpec InterpOptions[] = {\n     JSI_OPT(INT,   Jsi_Interp, lockTimeout, .help=\"Thread time-out for mutex lock acquires (milliseconds)\" ),\n     JSI_OPT(CUSTOM,Jsi_Interp, logOpts,     .help=\"Options for log output to add file/line/time\", .flags=0, .custom=Jsi_Opt_SwitchSuboption, .data=jsi_InterpLogOptions),\n     JSI_OPT(INT,   Jsi_Interp, maxDepth,    .help=\"Depth limit of recursive function calls (1000)\", .flags=JSI_OPT_LOCKSAFE),\n-    JSI_OPT(INT,   Jsi_Interp, maxArrayList,.help=\"Maximum array convertable to list (100000)\", .flags=JSI_OPT_LOCKSAFE),\n+    JSI_OPT(UINT,  Jsi_Interp, maxArrayList,.help=\"Maximum array convertable to list (100000)\", .flags=JSI_OPT_LOCKSAFE),\n     JSI_OPT(INT,   Jsi_Interp, maxIncDepth, .help=\"Maximum allowed source/require nesting depth (50)\", .flags=JSI_OPT_LOCKSAFE),\n     JSI_OPT(INT,   Jsi_Interp, maxInterpDepth,.help=\"Maximum nested subinterp create depth (10)\", .flags=JSI_OPT_LOCKSAFE),\n     JSI_OPT(INT,   Jsi_Interp, maxUserObjs, .help=\"Maximum number of 'new' object calls, eg. File, RegExp, etc\", .flags=JSI_OPT_LOCKSAFE ),\n@@ -1146,6 +1146,7 @@ static Jsi_Interp* jsi_InterpNew(Jsi_Interp *parent, Jsi_Value *opts, Jsi_Interp\n     }\n     interp->maxDepth = JSI_MAX_EVAL_DEPTH;\n     interp->maxIncDepth = JSI_MAX_INCLUDE_DEPTH;\n+    interp->maxArrayList = MAX_ARRAY_LIST;\n     interp->typeWarnMax = 50;\n     interp->subOpts.dblPrec = __DBL_DECIMAL_DIG__-1;\n     interp->subOpts.prompt = \"$ \";\n@@ -1482,7 +1483,6 @@ static Jsi_Interp* jsi_InterpNew(Jsi_Interp *parent, Jsi_Value *opts, Jsi_Interp\n #endif\n     if (interp->typeCheck.all|interp->typeCheck.parse|interp->typeCheck.funcsig)\n         interp->staticFuncsTbl = Jsi_HashNew(interp, JSI_KEYS_STRING, NULL);\n-    interp->maxArrayList = MAX_ARRAY_LIST;\n     if (!jsiIntData.isInit) {\n         jsiIntData.isInit = 1;\n         jsi_InitValue(interp, 0);\ndiff --git a/src/jsiObj.c b/src/jsiObj.c\nindex eae81de..7a11f49 100644\n--- a/src/jsiObj.c\n+++ b/src/jsiObj.c\n@@ -76,7 +76,7 @@ static Jsi_RC ObjListifyCallback(Jsi_Tree *tree, Jsi_TreeEntry *hPtr, void *data\n         if (!cp || !isdigit(*cp))\n             return JSI_OK;\n         n = (int)strtol(cp, &ep, 0);\n-        if (n<0 || n >= interp->maxArrayList)\n+        if (n<0 || (uint)n >= interp->maxArrayList)\n             return JSI_OK;\n         hPtr->f.bits.isarrlist = 1;\n         if (Jsi_ObjArraySizer(interp, obj, n) <= 0) \n@@ -414,12 +414,12 @@ int Jsi_ObjDecrRefCount(Jsi_Interp *interp, Jsi_Obj *obj)  {\n \n int Jsi_ObjArraySizer(Jsi_Interp *interp, Jsi_Obj *obj, uint len)\n {\n-    int nsiz = len + 1, mod = ALLOC_MOD_SIZE;\n+    uint nsiz = len + 1, mod = ALLOC_MOD_SIZE;\n     assert(obj->isarrlist);\n     if (mod>1)\n         nsiz = nsiz + ((mod-1) - (nsiz + mod - 1)%mod);\n-    if (nsiz > MAX_ARRAY_LIST) {\n-        Jsi_LogError(\"array size too large\");\n+    if (len >= interp->maxArrayList || nsiz > interp->maxArrayList) {\n+        Jsi_LogError(\"array size too big: %u >= %u\", len, interp->maxArrayList);\n         return 0;\n     }\n     if (len >= obj->arrMaxSize) {\ndiff --git a/src/jsiValue.c b/src/jsiValue.c\nindex a9fa8a2..c520084 100644\n--- a/src/jsiValue.c\n+++ b/src/jsiValue.c\n@@ -1036,7 +1036,7 @@ Jsi_Value *jsi_ValueObjKeyAssign(Jsi_Interp *interp, Jsi_Value *target, Jsi_Valu\n     }\n     /* TODO: array[\"1\"] also extern the length of array */\n     \n-    if (arrayindex >= 0 && arrayindex < MAX_ARRAY_LIST &&\n+    if (arrayindex >= 0 && (uint)arrayindex < interp->maxArrayList &&\n         target->vt == JSI_VT_OBJECT && target->d.obj->arr) {\n         return jsi_ObjArraySetDup(interp, target->d.obj, value, arrayindex);\n     }\n@@ -1373,7 +1373,7 @@ Jsi_RC Jsi_ValueInsertArray(Jsi_Interp *interp, Jsi_Value *target, int key, Jsi_\n     Jsi_Obj *obj = target->d.obj;\n     \n     if (obj->isarrlist) {\n-        if (key >= 0 && key < interp->maxArrayList) {\n+        if (key >= 0 && (uint)key < interp->maxArrayList) {\n             Jsi_ObjArraySet(interp, obj, val, key);\n             return JSI_OK;\n         }\ndiff --git a/tools/protos.jsi b/tools/protos.jsi\nindex 76d21d1..f2c4608 100755\n--- a/tools/protos.jsi\n+++ b/tools/protos.jsi\n@@ -1,4 +1,4 @@\n-//JSI Command Prototypes: version 3.0.6\n+//JSI Command Prototypes: version 3.0.8\n throw(\"NOT EXECUTABLE: USE FILE IN GEANY EDITOR FOR CMD LINE COMPLETION + GOTO TAG\");\n \n var Array = function(cmd,args) {};\ndiff --git a/www/reference.wiki b/www/reference.wiki\nindex 2b11595..51f6cdb 100644\n--- a/www/reference.wiki\n+++ b/www/reference.wiki\n@@ -633,7 +633,7 @@ Otherwise waits until the sub-interp is idle, to make call and return result.</t\n <tr><td>lockTimeout</td><td><i>INT</i></td><td>Thread time-out for mutex lock acquires (milliseconds).</td><td><i></i></td></tr>\n <tr><td>logOpts</td><td><i><a href='#logOptsOptions'>options</a></i></td><td>Options for log output to add file/line/time.</td><td><i></i></td></tr>\n <tr><td>maxDepth</td><td><i>INT</i></td><td>Depth limit of recursive function calls (1000).</td><td><i></i></td></tr>\n-<tr><td>maxArrayList</td><td><i>INT</i></td><td>Maximum array convertable to list (100000).</td><td><i></i></td></tr>\n+<tr><td>maxArrayList</td><td><i>UINT</i></td><td>Maximum array convertable to list (100000).</td><td><i></i></td></tr>\n <tr><td>maxIncDepth</td><td><i>INT</i></td><td>Maximum allowed source/require nesting depth (50).</td><td><i></i></td></tr>\n <tr><td>maxInterpDepth</td><td><i>INT</i></td><td>Maximum nested subinterp create depth (10).</td><td><i></i></td></tr>\n <tr><td>maxUserObjs</td><td><i>INT</i></td><td>Maximum number of 'new' object calls, eg. File, RegExp, etc.</td><td><i></i></td></tr>\n"
        ],
        "func_after": []
    },
    {
        "idx": 217457,
        "project": "spnego-http-auth-nginx-module",
        "commit_id": "a06f9efca373e25328b1c53639a48decd0854570",
        "project_url": "https://github.com/stnoonan/spnego-http-auth-nginx-module",
        "commit_url": "https://github.com/stnoonan/spnego-http-auth-nginx-module/commit/a06f9efca373e25328b1c53639a48decd0854570",
        "commit_message": "Check basic auth result against != NGX_OK rather than == NGX_DECLINED\n\nThis corrects the error handling case when ngx_http_auth_spnego_basic is called with a bad configuration or bad username. These cases return NGX_ERROR, which allowed basic auth to proceed.\n\nThanks to Prakapovich Pavel aka Flyguy.by for pointing this out.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "ngx_http_auth_spnego_handler(\n        ngx_http_request_t * r)\n{\n    ngx_int_t ret = NGX_DECLINED;\n    ngx_http_auth_spnego_ctx_t *ctx;\n    ngx_http_auth_spnego_loc_conf_t *alcf;\n\n    alcf = ngx_http_get_module_loc_conf(r, ngx_http_auth_spnego_module);\n\n    if (alcf->protect == 0) {\n        return NGX_DECLINED;\n    }\n\n    ctx = ngx_http_get_module_ctx(r, ngx_http_auth_spnego_module);\n    if (NULL == ctx) {\n        ctx = ngx_palloc(r->pool, sizeof(ngx_http_auth_spnego_ctx_t));\n        if (NULL == ctx) {\n            return NGX_HTTP_INTERNAL_SERVER_ERROR;\n        }\n        ctx->token.len = 0;\n        ctx->token.data = NULL;\n        ctx->head = 0;\n        ctx->ret = NGX_HTTP_UNAUTHORIZED;\n        ngx_http_set_ctx(r, ctx, ngx_http_auth_spnego_module);\n    }\n\n    spnego_debug3(\"SSO auth handling IN: token.len=%d, head=%d, ret=%d\",\n            ctx->token.len, ctx->head, ctx->ret);\n\n    if (ctx->token.len && ctx->head) {\n        spnego_debug1(\"Found token and head, returning %d\", ctx->ret);\n        return ctx->ret;\n    }\n\n    if (NULL != r->headers_in.user.data) {\n        spnego_debug0(\"User header set\");\n        return NGX_OK;\n    }\n\n    spnego_debug0(\"Begin auth\");\n\n    if (alcf->allow_basic) {\n        spnego_debug0(\"Detect basic auth\");\n        ret = ngx_http_auth_basic_user(r);\n        if (NGX_OK == ret) {\n            spnego_debug0(\"Basic auth credentials supplied by client\");\n            /* If basic auth is enabled and basic creds are supplied\n             * attempt basic auth.  If we attempt basic auth, we do\n             * not fall through to real SPNEGO */\n            if (NGX_DECLINED == ngx_http_auth_spnego_basic(r, ctx, alcf)) {\n                spnego_debug0(\"Basic auth failed\");\n                if (NGX_ERROR == ngx_http_auth_spnego_headers_basic_only(r, ctx, alcf)) {\n                    spnego_debug0(\"Error setting headers\");\n                    return (ctx->ret = NGX_HTTP_INTERNAL_SERVER_ERROR);\n                }\n                return (ctx->ret = NGX_HTTP_UNAUTHORIZED);\n            }\n\n            if (!ngx_spnego_authorized_principal(r, &r->headers_in.user, alcf)) {\n                spnego_debug0(\"User not authorized\");\n                return (ctx->ret = NGX_HTTP_FORBIDDEN);\n            }\n\n            spnego_debug0(\"Basic auth succeeded\");\n            return (ctx->ret = NGX_OK);\n        }\n    }\n\n    /* Basic auth either disabled or not supplied by client */\n    spnego_debug0(\"Detect SPNEGO token\");\n    ret = ngx_http_auth_spnego_token(r, ctx);\n    if (NGX_OK == ret) {\n        spnego_debug0(\"Client sent a reasonable Negotiate header\");\n        ret = ngx_http_auth_spnego_auth_user_gss(r, ctx, alcf);\n        if (NGX_ERROR == ret) {\n            spnego_debug0(\"GSSAPI failed\");\n            return (ctx->ret = NGX_HTTP_INTERNAL_SERVER_ERROR);\n        }\n        /* There are chances that client knows about Negotiate\n         * but doesn't support GSSAPI. We could attempt to fall\n         * back to basic here... */\n        if (NGX_DECLINED == ret) {\n            spnego_debug0(\"GSSAPI failed\");\n            if(!alcf->allow_basic) {\n                return (ctx->ret = NGX_HTTP_FORBIDDEN);\n            }\n            if (NGX_ERROR == ngx_http_auth_spnego_headers_basic_only(r, ctx, alcf)) {\n                spnego_debug0(\"Error setting headers\");\n                return (ctx->ret = NGX_HTTP_INTERNAL_SERVER_ERROR);\n            }\n            return (ctx->ret = NGX_HTTP_UNAUTHORIZED);\n        }\n\n        if (!ngx_spnego_authorized_principal(r, &r->headers_in.user, alcf)) {\n            spnego_debug0(\"User not authorized\");\n            return (ctx->ret = NGX_HTTP_FORBIDDEN);\n        }\n\n        spnego_debug0(\"GSSAPI auth succeeded\");\n    }\n\n    ngx_str_t *token_out_b64 = NULL;\n    switch(ret) {\n        case NGX_DECLINED: /* DECLINED, but not yet FORBIDDEN */\n            ctx->ret = NGX_HTTP_UNAUTHORIZED;\n            break;\n        case NGX_OK:\n            ctx->ret = NGX_OK;\n            token_out_b64 = &ctx->token_out_b64;\n            break;\n        case NGX_ERROR:\n        default:\n            ctx->ret = NGX_HTTP_INTERNAL_SERVER_ERROR;\n            break;\n    }\n\n    if (NGX_ERROR == ngx_http_auth_spnego_headers(r, ctx, token_out_b64, alcf)) {\n        spnego_debug0(\"Error setting headers\");\n        ctx->ret = NGX_HTTP_INTERNAL_SERVER_ERROR;\n    }\n\n    spnego_debug3(\"SSO auth handling OUT: token.len=%d, head=%d, ret=%d\",\n            ctx->token.len, ctx->head, ctx->ret);\n    return ctx->ret;\n}",
        "func_hash": 315404812195750248230966628792775317523,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-287"
        ],
        "cve": "CVE-2021-21335",
        "cve_desc": "In the SPNEGO HTTP Authentication Module for nginx (spnego-http-auth-nginx-module) before version 1.1.1 basic Authentication can be bypassed using a malformed username. This affects users of spnego-http-auth-nginx-module that have enabled basic authentication. This is fixed in version 1.1.1 of spnego-http-auth-nginx-module. As a workaround, one may disable basic authentication.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-21335",
        "func_name": "ngx_http_auth_spnego_handler",
        "diff": [
            "diff --git a/ngx_http_auth_spnego_module.c b/ngx_http_auth_spnego_module.c\nindex 97c0b44..25683f2 100644\n--- a/ngx_http_auth_spnego_module.c\n+++ b/ngx_http_auth_spnego_module.c\n@@ -1043,7 +1043,7 @@ ngx_http_auth_spnego_handler(\n             /* If basic auth is enabled and basic creds are supplied\n              * attempt basic auth.  If we attempt basic auth, we do\n              * not fall through to real SPNEGO */\n-            if (NGX_DECLINED == ngx_http_auth_spnego_basic(r, ctx, alcf)) {\n+            if (NGX_OK != ngx_http_auth_spnego_basic(r, ctx, alcf)) {\n                 spnego_debug0(\"Basic auth failed\");\n                 if (NGX_ERROR == ngx_http_auth_spnego_headers_basic_only(r, ctx, alcf)) {\n                     spnego_debug0(\"Error setting headers\");\n"
        ],
        "func_after": []
    },
    {
        "idx": 217514,
        "project": "skiboot",
        "commit_id": "5be38b672c1410e2f10acd3ad2eecfdc81d5daf7",
        "project_url": "https://github.com/open-power/skiboot",
        "commit_url": "https://github.com/open-power/skiboot/commit/5be38b672c1410e2f10acd3ad2eecfdc81d5daf7",
        "commit_message": "secvar: fix endian conversion\n\nunpack_timestamp() calls le32_to_cpu() for endian conversion of\nuint16_t \"year\" value. This patch fixes the code to use le16_to_cpu().\n\nSigned-off-by: Nayna Jain <nayna@linux.ibm.com>\nReviewed-by: Daniel Axtens <dja@axtens.net>\nSigned-off-by: Vasant Hegde <hegdevasant@linux.vnet.ibm.com>",
        "target": 1,
        "irrelevant": 1,
        "func_before": "static uint64_t unpack_timestamp(const struct efi_time *timestamp)\n{\n\tuint64_t val = 0;\n\tuint16_t year = le32_to_cpu(timestamp->year);\n\n\t/* pad1, nanosecond, timezone, daylight and pad2 are meant to be zero */\n\tval |= ((uint64_t) timestamp->pad1 & 0xFF) << 0;\n\tval |= ((uint64_t) timestamp->second & 0xFF) << (1*8);\n\tval |= ((uint64_t) timestamp->minute & 0xFF) << (2*8);\n\tval |= ((uint64_t) timestamp->hour & 0xFF) << (3*8);\n\tval |= ((uint64_t) timestamp->day & 0xFF) << (4*8);\n\tval |= ((uint64_t) timestamp->month & 0xFF) << (5*8);\n\tval |= ((uint64_t) year) << (6*8);\n\n\treturn val;\n}",
        "func_hash": 311038473946488653732481318478780397503,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-681"
        ],
        "cve": "CVE-2021-36357",
        "cve_desc": "An issue was discovered in OpenPOWER 2.6 firmware. unpack_timestamp() calls le32_to_cpu() for endian conversion of a uint16_t \"year\" value, resulting in a type mismatch that can truncate a higher integer value to a smaller one, and bypass a timestamp check. The fix is to use the right endian conversion function.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-36357",
        "func_name": "unpack_timestamp",
        "diff": [
            "diff --git a/libstb/secvar/backend/edk2-compat-process.c b/libstb/secvar/backend/edk2-compat-process.c\nindex 244f23403fe0..037c1b492734 100644\n--- a/libstb/secvar/backend/edk2-compat-process.c\n+++ b/libstb/secvar/backend/edk2-compat-process.c\n@@ -370,7 +370,7 @@ int update_timestamp(const char *key, const struct efi_time *timestamp, char *la\n static uint64_t unpack_timestamp(const struct efi_time *timestamp)\n {\n \tuint64_t val = 0;\n-\tuint16_t year = le32_to_cpu(timestamp->year);\n+\tuint16_t year = le16_to_cpu(timestamp->year);\n \n \t/* pad1, nanosecond, timezone, daylight and pad2 are meant to be zero */\n \tval |= ((uint64_t) timestamp->pad1 & 0xFF) << 0;\n"
        ],
        "func_after": []
    },
    {
        "idx": 194963,
        "project": "ImageMagick6",
        "commit_id": "dc070da861a015d3c97488fdcca6063b44d47a7b",
        "project_url": "https://github.com/ImageMagick/ImageMagick6",
        "commit_url": "https://github.com/ImageMagick/ImageMagick6/commit/dc070da861a015d3c97488fdcca6063b44d47a7b",
        "commit_message": "https://github.com/ImageMagick/ImageMagick/pull/5034",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static MagickBooleanType GetEXIFProperty(const Image *image,\n  const char *property)\n{\n#define MaxDirectoryStack  16\n#define EXIF_DELIMITER  \"\\n\"\n#define EXIF_NUM_FORMATS  12\n#define EXIF_FMT_BYTE  1\n#define EXIF_FMT_STRING  2\n#define EXIF_FMT_USHORT  3\n#define EXIF_FMT_ULONG  4\n#define EXIF_FMT_URATIONAL  5\n#define EXIF_FMT_SBYTE  6\n#define EXIF_FMT_UNDEFINED  7\n#define EXIF_FMT_SSHORT  8\n#define EXIF_FMT_SLONG  9\n#define EXIF_FMT_SRATIONAL  10\n#define EXIF_FMT_SINGLE  11\n#define EXIF_FMT_DOUBLE  12\n#define TAG_EXIF_OFFSET  0x8769\n#define TAG_GPS_OFFSET  0x8825\n#define TAG_INTEROP_OFFSET  0xa005\n\n#define EXIFMultipleValues(size,format,arg) \\\n{ \\\n   ssize_t \\\n     component; \\\n \\\n   size_t \\\n     length; \\\n \\\n   unsigned char \\\n     *p1; \\\n \\\n   length=0; \\\n   p1=p; \\\n   for (component=0; component < components; component++) \\\n   { \\\n     length+=FormatLocaleString(buffer+length,MaxTextExtent-length, \\\n       format\", \",arg); \\\n     if (length >= (MaxTextExtent-1)) \\\n       length=MaxTextExtent-1; \\\n     p1+=size; \\\n   } \\\n   if (length > 1) \\\n     buffer[length-2]='\\0'; \\\n   value=AcquireString(buffer); \\\n}\n\n#define EXIFMultipleFractions(size,format,arg1,arg2) \\\n{ \\\n   ssize_t \\\n     component; \\\n \\\n   size_t \\\n     length; \\\n \\\n   unsigned char \\\n     *p1; \\\n \\\n   length=0; \\\n   p1=p; \\\n   for (component=0; component < components; component++) \\\n   { \\\n     length+=FormatLocaleString(buffer+length,MaxTextExtent-length, \\\n       format\", \",(arg1),(arg2)); \\\n     if (length >= (MaxTextExtent-1)) \\\n       length=MaxTextExtent-1; \\\n     p1+=size; \\\n   } \\\n   if (length > 1) \\\n     buffer[length-2]='\\0'; \\\n   value=AcquireString(buffer); \\\n}\n\n  typedef struct _DirectoryInfo\n  {\n    const unsigned char\n      *directory;\n\n    size_t\n      entry;\n\n    ssize_t\n      offset;\n  } DirectoryInfo;\n\n  typedef struct _TagInfo\n  {\n    size_t\n      tag;\n\n    const char\n      description[36];\n  } TagInfo;\n\n  static const TagInfo\n    EXIFTag[] =\n    {\n      {  0x001, \"exif:InteroperabilityIndex\" },\n      {  0x002, \"exif:InteroperabilityVersion\" },\n      {  0x100, \"exif:ImageWidth\" },\n      {  0x101, \"exif:ImageLength\" },\n      {  0x102, \"exif:BitsPerSample\" },\n      {  0x103, \"exif:Compression\" },\n      {  0x106, \"exif:PhotometricInterpretation\" },\n      {  0x10a, \"exif:FillOrder\" },\n      {  0x10d, \"exif:DocumentName\" },\n      {  0x10e, \"exif:ImageDescription\" },\n      {  0x10f, \"exif:Make\" },\n      {  0x110, \"exif:Model\" },\n      {  0x111, \"exif:StripOffsets\" },\n      {  0x112, \"exif:Orientation\" },\n      {  0x115, \"exif:SamplesPerPixel\" },\n      {  0x116, \"exif:RowsPerStrip\" },\n      {  0x117, \"exif:StripByteCounts\" },\n      {  0x11a, \"exif:XResolution\" },\n      {  0x11b, \"exif:YResolution\" },\n      {  0x11c, \"exif:PlanarConfiguration\" },\n      {  0x11d, \"exif:PageName\" },\n      {  0x11e, \"exif:XPosition\" },\n      {  0x11f, \"exif:YPosition\" },\n      {  0x118, \"exif:MinSampleValue\" },\n      {  0x119, \"exif:MaxSampleValue\" },\n      {  0x120, \"exif:FreeOffsets\" },\n      {  0x121, \"exif:FreeByteCounts\" },\n      {  0x122, \"exif:GrayResponseUnit\" },\n      {  0x123, \"exif:GrayResponseCurve\" },\n      {  0x124, \"exif:T4Options\" },\n      {  0x125, \"exif:T6Options\" },\n      {  0x128, \"exif:ResolutionUnit\" },\n      {  0x12d, \"exif:TransferFunction\" },\n      {  0x131, \"exif:Software\" },\n      {  0x132, \"exif:DateTime\" },\n      {  0x13b, \"exif:Artist\" },\n      {  0x13e, \"exif:WhitePoint\" },\n      {  0x13f, \"exif:PrimaryChromaticities\" },\n      {  0x140, \"exif:ColorMap\" },\n      {  0x141, \"exif:HalfToneHints\" },\n      {  0x142, \"exif:TileWidth\" },\n      {  0x143, \"exif:TileLength\" },\n      {  0x144, \"exif:TileOffsets\" },\n      {  0x145, \"exif:TileByteCounts\" },\n      {  0x14a, \"exif:SubIFD\" },\n      {  0x14c, \"exif:InkSet\" },\n      {  0x14d, \"exif:InkNames\" },\n      {  0x14e, \"exif:NumberOfInks\" },\n      {  0x150, \"exif:DotRange\" },\n      {  0x151, \"exif:TargetPrinter\" },\n      {  0x152, \"exif:ExtraSample\" },\n      {  0x153, \"exif:SampleFormat\" },\n      {  0x154, \"exif:SMinSampleValue\" },\n      {  0x155, \"exif:SMaxSampleValue\" },\n      {  0x156, \"exif:TransferRange\" },\n      {  0x157, \"exif:ClipPath\" },\n      {  0x158, \"exif:XClipPathUnits\" },\n      {  0x159, \"exif:YClipPathUnits\" },\n      {  0x15a, \"exif:Indexed\" },\n      {  0x15b, \"exif:JPEGTables\" },\n      {  0x15f, \"exif:OPIProxy\" },\n      {  0x200, \"exif:JPEGProc\" },\n      {  0x201, \"exif:JPEGInterchangeFormat\" },\n      {  0x202, \"exif:JPEGInterchangeFormatLength\" },\n      {  0x203, \"exif:JPEGRestartInterval\" },\n      {  0x205, \"exif:JPEGLosslessPredictors\" },\n      {  0x206, \"exif:JPEGPointTransforms\" },\n      {  0x207, \"exif:JPEGQTables\" },\n      {  0x208, \"exif:JPEGDCTables\" },\n      {  0x209, \"exif:JPEGACTables\" },\n      {  0x211, \"exif:YCbCrCoefficients\" },\n      {  0x212, \"exif:YCbCrSubSampling\" },\n      {  0x213, \"exif:YCbCrPositioning\" },\n      {  0x214, \"exif:ReferenceBlackWhite\" },\n      {  0x2bc, \"exif:ExtensibleMetadataPlatform\" },\n      {  0x301, \"exif:Gamma\" },\n      {  0x302, \"exif:ICCProfileDescriptor\" },\n      {  0x303, \"exif:SRGBRenderingIntent\" },\n      {  0x320, \"exif:ImageTitle\" },\n      {  0x5001, \"exif:ResolutionXUnit\" },\n      {  0x5002, \"exif:ResolutionYUnit\" },\n      {  0x5003, \"exif:ResolutionXLengthUnit\" },\n      {  0x5004, \"exif:ResolutionYLengthUnit\" },\n      {  0x5005, \"exif:PrintFlags\" },\n      {  0x5006, \"exif:PrintFlagsVersion\" },\n      {  0x5007, \"exif:PrintFlagsCrop\" },\n      {  0x5008, \"exif:PrintFlagsBleedWidth\" },\n      {  0x5009, \"exif:PrintFlagsBleedWidthScale\" },\n      {  0x500A, \"exif:HalftoneLPI\" },\n      {  0x500B, \"exif:HalftoneLPIUnit\" },\n      {  0x500C, \"exif:HalftoneDegree\" },\n      {  0x500D, \"exif:HalftoneShape\" },\n      {  0x500E, \"exif:HalftoneMisc\" },\n      {  0x500F, \"exif:HalftoneScreen\" },\n      {  0x5010, \"exif:JPEGQuality\" },\n      {  0x5011, \"exif:GridSize\" },\n      {  0x5012, \"exif:ThumbnailFormat\" },\n      {  0x5013, \"exif:ThumbnailWidth\" },\n      {  0x5014, \"exif:ThumbnailHeight\" },\n      {  0x5015, \"exif:ThumbnailColorDepth\" },\n      {  0x5016, \"exif:ThumbnailPlanes\" },\n      {  0x5017, \"exif:ThumbnailRawBytes\" },\n      {  0x5018, \"exif:ThumbnailSize\" },\n      {  0x5019, \"exif:ThumbnailCompressedSize\" },\n      {  0x501a, \"exif:ColorTransferFunction\" },\n      {  0x501b, \"exif:ThumbnailData\" },\n      {  0x5020, \"exif:ThumbnailImageWidth\" },\n      {  0x5021, \"exif:ThumbnailImageHeight\" },\n      {  0x5022, \"exif:ThumbnailBitsPerSample\" },\n      {  0x5023, \"exif:ThumbnailCompression\" },\n      {  0x5024, \"exif:ThumbnailPhotometricInterp\" },\n      {  0x5025, \"exif:ThumbnailImageDescription\" },\n      {  0x5026, \"exif:ThumbnailEquipMake\" },\n      {  0x5027, \"exif:ThumbnailEquipModel\" },\n      {  0x5028, \"exif:ThumbnailStripOffsets\" },\n      {  0x5029, \"exif:ThumbnailOrientation\" },\n      {  0x502a, \"exif:ThumbnailSamplesPerPixel\" },\n      {  0x502b, \"exif:ThumbnailRowsPerStrip\" },\n      {  0x502c, \"exif:ThumbnailStripBytesCount\" },\n      {  0x502d, \"exif:ThumbnailResolutionX\" },\n      {  0x502e, \"exif:ThumbnailResolutionY\" },\n      {  0x502f, \"exif:ThumbnailPlanarConfig\" },\n      {  0x5030, \"exif:ThumbnailResolutionUnit\" },\n      {  0x5031, \"exif:ThumbnailTransferFunction\" },\n      {  0x5032, \"exif:ThumbnailSoftwareUsed\" },\n      {  0x5033, \"exif:ThumbnailDateTime\" },\n      {  0x5034, \"exif:ThumbnailArtist\" },\n      {  0x5035, \"exif:ThumbnailWhitePoint\" },\n      {  0x5036, \"exif:ThumbnailPrimaryChromaticities\" },\n      {  0x5037, \"exif:ThumbnailYCbCrCoefficients\" },\n      {  0x5038, \"exif:ThumbnailYCbCrSubsampling\" },\n      {  0x5039, \"exif:ThumbnailYCbCrPositioning\" },\n      {  0x503A, \"exif:ThumbnailRefBlackWhite\" },\n      {  0x503B, \"exif:ThumbnailCopyRight\" },\n      {  0x5090, \"exif:LuminanceTable\" },\n      {  0x5091, \"exif:ChrominanceTable\" },\n      {  0x5100, \"exif:FrameDelay\" },\n      {  0x5101, \"exif:LoopCount\" },\n      {  0x5110, \"exif:PixelUnit\" },\n      {  0x5111, \"exif:PixelPerUnitX\" },\n      {  0x5112, \"exif:PixelPerUnitY\" },\n      {  0x5113, \"exif:PaletteHistogram\" },\n      {  0x1000, \"exif:RelatedImageFileFormat\" },\n      {  0x1001, \"exif:RelatedImageLength\" },\n      {  0x1002, \"exif:RelatedImageWidth\" },\n      {  0x800d, \"exif:ImageID\" },\n      {  0x80e3, \"exif:Matteing\" },\n      {  0x80e4, \"exif:DataType\" },\n      {  0x80e5, \"exif:ImageDepth\" },\n      {  0x80e6, \"exif:TileDepth\" },\n      {  0x828d, \"exif:CFARepeatPatternDim\" },\n      {  0x828e, \"exif:CFAPattern2\" },\n      {  0x828f, \"exif:BatteryLevel\" },\n      {  0x8298, \"exif:Copyright\" },\n      {  0x829a, \"exif:ExposureTime\" },\n      {  0x829d, \"exif:FNumber\" },\n      {  0x83bb, \"exif:IPTC/NAA\" },\n      {  0x84e3, \"exif:IT8RasterPadding\" },\n      {  0x84e5, \"exif:IT8ColorTable\" },\n      {  0x8649, \"exif:ImageResourceInformation\" },\n      {  0x8769, \"exif:ExifOffset\" },  /* specs as \"Exif IFD Pointer\"? */\n      {  0x8773, \"exif:InterColorProfile\" },\n      {  0x8822, \"exif:ExposureProgram\" },\n      {  0x8824, \"exif:SpectralSensitivity\" },\n      {  0x8825, \"exif:GPSInfo\" }, /* specs as \"GPSInfo IFD Pointer\"? */\n      {  0x8827, \"exif:PhotographicSensitivity\" },\n      {  0x8828, \"exif:OECF\" },\n      {  0x8829, \"exif:Interlace\" },      \n      {  0x882a, \"exif:TimeZoneOffset\" },\n      {  0x882b, \"exif:SelfTimerMode\" },\n      {  0x8830, \"exif:SensitivityType\" },\n      {  0x8831, \"exif:StandardOutputSensitivity\" },\n      {  0x8832, \"exif:RecommendedExposureIndex\" },\n      {  0x8833, \"exif:ISOSpeed\" },\n      {  0x8834, \"exif:ISOSpeedLatitudeyyy\" },\n      {  0x8835, \"exif:ISOSpeedLatitudezzz\" },\n      {  0x9000, \"exif:ExifVersion\" },\n      {  0x9003, \"exif:DateTimeOriginal\" },\n      {  0x9004, \"exif:DateTimeDigitized\" },\n      {  0x9010, \"exif:OffsetTime\" },\n      {  0x9011, \"exif:OffsetTimeOriginal\" },\n      {  0x9012, \"exif:OffsetTimeDigitized\" },\n      {  0x9101, \"exif:ComponentsConfiguration\" },\n      {  0x9102, \"exif:CompressedBitsPerPixel\" },\n      {  0x9201, \"exif:ShutterSpeedValue\" },\n      {  0x9202, \"exif:ApertureValue\" },\n      {  0x9203, \"exif:BrightnessValue\" },\n      {  0x9204, \"exif:ExposureBiasValue\" },\n      {  0x9205, \"exif:MaxApertureValue\" },\n      {  0x9206, \"exif:SubjectDistance\" },\n      {  0x9207, \"exif:MeteringMode\" },\n      {  0x9208, \"exif:LightSource\" },\n      {  0x9209, \"exif:Flash\" },\n      {  0x920a, \"exif:FocalLength\" },\n      {  0x920b, \"exif:FlashEnergy\" },\n      {  0x920c, \"exif:SpatialFrequencyResponse\" },\n      {  0x920d, \"exif:Noise\" },\n      {  0x9214, \"exif:SubjectArea\" },\n      {  0x9290, \"exif:SubSecTime\" },\n      {  0x9291, \"exif:SubSecTimeOriginal\" },\n      {  0x9292, \"exif:SubSecTimeDigitized\" },    \n      {  0x9211, \"exif:ImageNumber\" },\n      {  0x9212, \"exif:SecurityClassification\" },\n      {  0x9213, \"exif:ImageHistory\" },\n      {  0x9214, \"exif:SubjectArea\" },\n      {  0x9215, \"exif:ExposureIndex\" },\n      {  0x9216, \"exif:TIFF-EPStandardID\" },\n      {  0x927c, \"exif:MakerNote\" },\n      {  0x9286, \"exif:UserComment\" },\n      {  0x9290, \"exif:SubSecTime\" },\n      {  0x9291, \"exif:SubSecTimeOriginal\" },\n      {  0x9292, \"exif:SubSecTimeDigitized\" },    \n      {  0x9400, \"exif:Temperature\" },\n      {  0x9401, \"exif:Humidity\" },\n      {  0x9402, \"exif:Pressure\" },\n      {  0x9403, \"exif:WaterDepth\" },\n      {  0x9404, \"exif:Acceleration\" },\n      {  0x9405, \"exif:CameraElevationAngle\" },    \n      {  0x9C9b, \"exif:WinXP-Title\" },\n      {  0x9C9c, \"exif:WinXP-Comments\" },\n      {  0x9C9d, \"exif:WinXP-Author\" },\n      {  0x9C9e, \"exif:WinXP-Keywords\" },\n      {  0x9C9f, \"exif:WinXP-Subject\" },      \n      {  0xa000, \"exif:FlashPixVersion\" },\n      {  0xa001, \"exif:ColorSpace\" },\n      {  0xa002, \"exif:PixelXDimension\" },\n      {  0xa003, \"exif:PixelYDimension\" },\n      {  0xa004, \"exif:RelatedSoundFile\" },\n      {  0xa005, \"exif:InteroperabilityOffset\" },\n      {  0xa20b, \"exif:FlashEnergy\" },\n      {  0xa20c, \"exif:SpatialFrequencyResponse\" },\n      {  0xa20d, \"exif:Noise\" },\n      {  0xa20e, \"exif:FocalPlaneXResolution\" },\n      {  0xa20f, \"exif:FocalPlaneYResolution\" },\n      {  0xa210, \"exif:FocalPlaneResolutionUnit\" },\n      {  0xa214, \"exif:SubjectLocation\" },\n      {  0xa215, \"exif:ExposureIndex\" },\n      {  0xa216, \"exif:TIFF/EPStandardID\" },\n      {  0xa217, \"exif:SensingMethod\" },\n      {  0xa300, \"exif:FileSource\" },\n      {  0xa301, \"exif:SceneType\" },\n      {  0xa302, \"exif:CFAPattern\" },\n      {  0xa401, \"exif:CustomRendered\" },\n      {  0xa402, \"exif:ExposureMode\" },\n      {  0xa403, \"exif:WhiteBalance\" },\n      {  0xa404, \"exif:DigitalZoomRatio\" },\n      {  0xa405, \"exif:FocalLengthIn35mmFilm\" },\n      {  0xa406, \"exif:SceneCaptureType\" },\n      {  0xa407, \"exif:GainControl\" },\n      {  0xa408, \"exif:Contrast\" },\n      {  0xa409, \"exif:Saturation\" },\n      {  0xa40a, \"exif:Sharpness\" },\n      {  0xa40b, \"exif:DeviceSettingDescription\" },\n      {  0xa40c, \"exif:SubjectDistanceRange\" },\n      {  0xa420, \"exif:ImageUniqueID\" },\n      {  0xa430, \"exif:CameraOwnerName\" },\n      {  0xa431, \"exif:BodySerialNumber\" },\n      {  0xa432, \"exif:LensSpecification\" },\n      {  0xa433, \"exif:LensMake\" },\n      {  0xa434, \"exif:LensModel\" },\n      {  0xa435, \"exif:LensSerialNumber\" },\n      {  0xc4a5, \"exif:PrintImageMatching\" },\n      {  0xa500, \"exif:Gamma\" },\n      {  0xc640, \"exif:CR2Slice\" },\n      { 0x10000, \"exif:GPSVersionID\" },\n      { 0x10001, \"exif:GPSLatitudeRef\" },\n      { 0x10002, \"exif:GPSLatitude\" },\n      { 0x10003, \"exif:GPSLongitudeRef\" },\n      { 0x10004, \"exif:GPSLongitude\" },\n      { 0x10005, \"exif:GPSAltitudeRef\" },\n      { 0x10006, \"exif:GPSAltitude\" },\n      { 0x10007, \"exif:GPSTimeStamp\" },\n      { 0x10008, \"exif:GPSSatellites\" },\n      { 0x10009, \"exif:GPSStatus\" },\n      { 0x1000a, \"exif:GPSMeasureMode\" },\n      { 0x1000b, \"exif:GPSDop\" },\n      { 0x1000c, \"exif:GPSSpeedRef\" },\n      { 0x1000d, \"exif:GPSSpeed\" },\n      { 0x1000e, \"exif:GPSTrackRef\" },\n      { 0x1000f, \"exif:GPSTrack\" },\n      { 0x10010, \"exif:GPSImgDirectionRef\" },\n      { 0x10011, \"exif:GPSImgDirection\" },\n      { 0x10012, \"exif:GPSMapDatum\" },\n      { 0x10013, \"exif:GPSDestLatitudeRef\" },\n      { 0x10014, \"exif:GPSDestLatitude\" },\n      { 0x10015, \"exif:GPSDestLongitudeRef\" },\n      { 0x10016, \"exif:GPSDestLongitude\" },\n      { 0x10017, \"exif:GPSDestBearingRef\" },\n      { 0x10018, \"exif:GPSDestBearing\" },\n      { 0x10019, \"exif:GPSDestDistanceRef\" },\n      { 0x1001a, \"exif:GPSDestDistance\" },\n      { 0x1001b, \"exif:GPSProcessingMethod\" },\n      { 0x1001c, \"exif:GPSAreaInformation\" },\n      { 0x1001d, \"exif:GPSDateStamp\" },\n      { 0x1001e, \"exif:GPSDifferential\" },\n      { 0x1001f, \"exif:GPSHPositioningError\" },\n      { 0x00000, \"\" }\n    };  /* http://www.cipa.jp/std/documents/e/DC-008-Translation-2016-E.pdf */\n\n  const StringInfo\n    *profile;\n\n  const unsigned char\n    *directory,\n    *exif;\n\n  DirectoryInfo\n    directory_stack[MaxDirectoryStack];\n\n  EndianType\n    endian;\n\n  MagickBooleanType\n    status;\n\n  ssize_t\n    i;\n\n  size_t\n    entry,\n    length,\n    number_entries,\n    tag,\n    tag_value;\n\n  SplayTreeInfo\n    *exif_resources;\n\n  ssize_t\n    all,\n    id,\n    level,\n    offset,\n    tag_offset;\n\n  static int\n    tag_bytes[] = {0, 1, 1, 2, 4, 8, 1, 1, 2, 4, 8, 4, 8};\n\n  /*\n    If EXIF data exists, then try to parse the request for a tag.\n  */\n  profile=GetImageProfile(image,\"exif\");\n  if (profile == (const StringInfo *) NULL)\n    return(MagickFalse);\n  if ((property == (const char *) NULL) || (*property == '\\0'))\n    return(MagickFalse);\n  while (isspace((int) ((unsigned char) *property)) != 0)\n    property++;\n  if (strlen(property) <= 5)\n    return(MagickFalse);\n  all=0;\n  tag=(~0UL);\n  switch (*(property+5))\n  {\n    case '*':\n    {\n      /*\n        Caller has asked for all the tags in the EXIF data.\n      */\n      tag=0;\n      all=1; /* return the data in description=value format */\n      break;\n    }\n    case '!':\n    {\n      tag=0;\n      all=2; /* return the data in tagid=value format */\n      break;\n    }\n    case '#':\n    case '@':\n    {\n      int\n        c;\n\n      size_t\n        n;\n\n      /*\n        Check for a hex based tag specification first.\n      */\n      tag=(*(property+5) == '@') ? 1UL : 0UL;\n      property+=6;\n      n=strlen(property);\n      if (n != 4)\n        return(MagickFalse);\n      /*\n        Parse tag specification as a hex number.\n      */\n      n/=4;\n      do\n      {\n        for (i=(ssize_t) n-1L; i >= 0; i--)\n        {\n          c=(*property++);\n          tag<<=4;\n          if ((c >= '0') && (c <= '9'))\n            tag|=(c-'0');\n          else\n            if ((c >= 'A') && (c <= 'F'))\n              tag|=(c-('A'-10));\n            else\n              if ((c >= 'a') && (c <= 'f'))\n                tag|=(c-('a'-10));\n              else\n                return(MagickFalse);\n        }\n      } while (*property != '\\0');\n      break;\n    }\n    default:\n    {\n      /*\n        Try to match the text with a tag name instead.\n      */\n      for (i=0; ; i++)\n      {\n        if (EXIFTag[i].tag == 0)\n          break;\n        if (LocaleCompare(EXIFTag[i].description,property) == 0)\n          {\n            tag=(size_t) EXIFTag[i].tag;\n            break;\n          }\n      }\n      break;\n    }\n  }\n  if (tag == (~0UL))\n    return(MagickFalse);\n  length=GetStringInfoLength(profile);\n  if (length < 6)\n    return(MagickFalse);\n  exif=GetStringInfoDatum(profile);\n  while (length != 0)\n  {\n    if (ReadPropertyByte(&exif,&length) != 0x45)\n      continue;\n    if (ReadPropertyByte(&exif,&length) != 0x78)\n      continue;\n    if (ReadPropertyByte(&exif,&length) != 0x69)\n      continue;\n    if (ReadPropertyByte(&exif,&length) != 0x66)\n      continue;\n    if (ReadPropertyByte(&exif,&length) != 0x00)\n      continue;\n    if (ReadPropertyByte(&exif,&length) != 0x00)\n      continue;\n    break;\n  }\n  if (length < 16)\n    return(MagickFalse);\n  id=(ssize_t) ReadPropertySignedShort(LSBEndian,exif);\n  endian=LSBEndian;\n  if (id == 0x4949)\n    endian=LSBEndian;\n  else\n    if (id == 0x4D4D)\n      endian=MSBEndian;\n    else\n      return(MagickFalse);\n  if (ReadPropertyUnsignedShort(endian,exif+2) != 0x002a)\n    return(MagickFalse);\n  /*\n    This the offset to the first IFD.\n  */\n  offset=(ssize_t) ReadPropertySignedLong(endian,exif+4);\n  if ((offset < 0) || (size_t) offset >= length)\n    return(MagickFalse);\n  /*\n    Set the pointer to the first IFD and follow it were it leads.\n  */\n  status=MagickFalse;\n  directory=exif+offset;\n  level=0;\n  entry=0;\n  tag_offset=0;\n  exif_resources=NewSplayTree((int (*)(const void *,const void *)) NULL,\n    (void *(*)(void *)) NULL,(void *(*)(void *)) NULL);\n  do\n  {\n    /*\n      If there is anything on the stack then pop it off.\n    */\n    if (level > 0)\n      {\n        level--;\n        directory=directory_stack[level].directory;\n        entry=directory_stack[level].entry;\n        tag_offset=directory_stack[level].offset;\n      }\n    if ((directory < exif) || (directory > (exif+length-2)))\n      break;\n    /*\n      Determine how many entries there are in the current IFD.\n    */\n    number_entries=(size_t) ReadPropertyUnsignedShort(endian,directory);\n    for ( ; entry < number_entries; entry++)\n    {\n      unsigned char\n        *p,\n        *q;\n\n      size_t\n        format;\n\n      ssize_t\n        number_bytes,\n        components;\n\n      q=(unsigned char *) (directory+(12*entry)+2);\n      if (q > (exif+length-12))\n        break;  /* corrupt EXIF */\n      if (GetValueFromSplayTree(exif_resources,q) == q)\n        break;\n      (void) AddValueToSplayTree(exif_resources,q,q);\n      tag_value=(size_t) ReadPropertyUnsignedShort(endian,q)+tag_offset;\n      format=(size_t) ReadPropertyUnsignedShort(endian,q+2);\n      if (format >= (sizeof(tag_bytes)/sizeof(*tag_bytes)))\n        break;\n      if (format == 0)\n        break;  /* corrupt EXIF */\n      components=(ssize_t) ReadPropertySignedLong(endian,q+4);\n      if (components < 0)\n        break;  /* corrupt EXIF */\n      number_bytes=(size_t) components*tag_bytes[format];\n      if (number_bytes < components)\n        break;  /* prevent overflow */\n      if (number_bytes <= 4)\n        p=q+8;\n      else\n        {\n          ssize_t\n            dir_offset;\n\n          /*\n            The directory entry contains an offset.\n          */\n          dir_offset=(ssize_t) ReadPropertySignedLong(endian,q+8);\n          if ((dir_offset < 0) || (size_t) dir_offset >= length)\n            continue;\n          if (((size_t) dir_offset+number_bytes) < (size_t) dir_offset)\n            continue;  /* prevent overflow */\n          if (((size_t) dir_offset+number_bytes) > length)\n            continue;\n          p=(unsigned char *) (exif+dir_offset);\n        }\n      if ((all != 0) || (tag == (size_t) tag_value))\n        {\n          char\n            buffer[MaxTextExtent],\n            *value;\n\n          if ((p < exif) || (p > (exif+length-tag_bytes[format])))\n            break;\n          value=(char *) NULL;\n          *buffer='\\0';\n          switch (format)\n          {\n            case EXIF_FMT_BYTE:\n            case EXIF_FMT_UNDEFINED:\n            {\n              value=(char *) NULL;\n              if (~((size_t) number_bytes) >= 1)\n                value=(char *) AcquireQuantumMemory((size_t) number_bytes+1UL,\n                  sizeof(*value));\n              if (value != (char *) NULL)\n                {\n                  for (i=0; i < (ssize_t) number_bytes; i++)\n                  {\n                    value[i]='.';\n                    if (isprint((int) p[i]) != 0) \n                      value[i]=(char) p[i];\n                  }\n                  value[i]='\\0';\n                }\n              break;\n            }\n            case EXIF_FMT_SBYTE:\n            {\n              EXIFMultipleValues(1,\"%.20g\",(double) (*(signed char *) p1));\n              break;\n            }\n            case EXIF_FMT_SSHORT:\n            {\n              EXIFMultipleValues(2,\"%hd\",ReadPropertySignedShort(endian,p1));\n              break;\n            }\n            case EXIF_FMT_USHORT:\n            {\n              EXIFMultipleValues(2,\"%hu\",ReadPropertyUnsignedShort(endian,p1));\n              break;\n            }\n            case EXIF_FMT_ULONG:\n            {\n              EXIFMultipleValues(4,\"%.20g\",(double)\n                ReadPropertyUnsignedLong(endian,p1));\n              break;\n            }\n            case EXIF_FMT_SLONG:\n            {\n              EXIFMultipleValues(4,\"%.20g\",(double)\n                ReadPropertySignedLong(endian,p1));\n              break;\n            }\n            case EXIF_FMT_URATIONAL:\n            {\n              EXIFMultipleFractions(8,\"%.20g/%.20g\",(double)\n                ReadPropertyUnsignedLong(endian,p1),(double)\n                ReadPropertyUnsignedLong(endian,p1+4));\n              break;\n            }\n            case EXIF_FMT_SRATIONAL:\n            {\n              EXIFMultipleFractions(8,\"%.20g/%.20g\",(double)\n                ReadPropertySignedLong(endian,p1),(double)\n                ReadPropertySignedLong(endian,p1+4));\n              break;\n            }\n            case EXIF_FMT_SINGLE:\n            {\n              EXIFMultipleValues(4,\"%f\",(double) *(float *) p1);\n              break;\n            }\n            case EXIF_FMT_DOUBLE:\n            {\n              EXIFMultipleValues(8,\"%f\",*(double *) p1);\n              break;\n            }\n            case EXIF_FMT_STRING:\n            default:\n            {\n              if ((p < exif) || (p > (exif+length-number_bytes)))\n                break;\n              value=(char *) NULL;\n              if (~((size_t) number_bytes) >= 1)\n                value=(char *) AcquireQuantumMemory((size_t) number_bytes+1UL,\n                  sizeof(*value));\n              if (value != (char *) NULL)\n                {\n                  ssize_t\n                    i;\n\n                  for (i=0; i < (ssize_t) number_bytes; i++)\n                  {\n                    value[i]='.';\n                    if ((isprint((int) p[i]) != 0) || (p[i] == '\\0'))\n                      value[i]=(char) p[i];\n                  }\n                  value[i]='\\0';\n                }\n              break;\n            }\n          }\n          if (value != (char *) NULL)\n            {\n              char\n                *key;\n\n              const char\n                *p;\n\n              key=AcquireString(property);\n              switch (all)\n              {\n                case 1:\n                {\n                  const char\n                    *description;\n\n                  ssize_t\n                    i;\n\n                  description=\"unknown\";\n                  for (i=0; ; i++)\n                  {\n                    if (EXIFTag[i].tag == 0)\n                      break;\n                    if (EXIFTag[i].tag == tag_value)\n                      {\n                        description=EXIFTag[i].description;\n                        break;\n                      }\n                  }\n                  (void) FormatLocaleString(key,MaxTextExtent,\"%s\",\n                    description);\n                  if (level == 2)\n                    (void) SubstituteString(&key,\"exif:\",\"exif:thumbnail:\");\n                  break;\n                }\n                case 2:\n                {\n                  if (tag_value < 0x10000)\n                    (void) FormatLocaleString(key,MaxTextExtent,\"#%04lx\",\n                      (unsigned long) tag_value);\n                  else\n                    if (tag_value < 0x20000)\n                      (void) FormatLocaleString(key,MaxTextExtent,\"@%04lx\",\n                        (unsigned long) (tag_value & 0xffff));\n                    else\n                      (void) FormatLocaleString(key,MaxTextExtent,\"unknown\");\n                  break;\n                }\n                default:\n                {\n                  if (level == 2)\n                    (void) SubstituteString(&key,\"exif:\",\"exif:thumbnail:\");\n                }\n              }\n              p=(const char *) NULL;\n              if (image->properties != (void *) NULL)\n                p=(const char *) GetValueFromSplayTree((SplayTreeInfo *)\n                  image->properties,key);\n              if (p == (const char *) NULL)\n                (void) SetImageProperty((Image *) image,key,value);\n              value=DestroyString(value);\n              key=DestroyString(key);\n              status=MagickTrue;\n            }\n        }\n        if ((tag_value == TAG_EXIF_OFFSET) ||\n            (tag_value == TAG_INTEROP_OFFSET) || (tag_value == TAG_GPS_OFFSET))\n          {\n            ssize_t\n              offset;\n\n            offset=(ssize_t) ReadPropertySignedLong(endian,p);\n            if (((size_t) offset < length) && (level < (MaxDirectoryStack-2)))\n              {\n                ssize_t\n                  tag_offset1;\n\n                tag_offset1=(ssize_t) ((tag_value == TAG_GPS_OFFSET) ? 0x10000 :\n                  0);\n                directory_stack[level].directory=directory;\n                entry++;\n                directory_stack[level].entry=entry;\n                directory_stack[level].offset=tag_offset;\n                level++;\n                /*\n                  Check for duplicate tag.\n                */\n                for (i=0; i < level; i++)\n                  if (directory_stack[i].directory == (exif+tag_offset1))\n                    break;\n                if (i < level)\n                  break;  /* duplicate tag */\n                directory_stack[level].directory=exif+offset;\n                directory_stack[level].offset=tag_offset1;\n                directory_stack[level].entry=0;\n                level++;\n                if ((directory+2+(12*number_entries)+4) > (exif+length))\n                  break;\n                offset=(ssize_t) ReadPropertySignedLong(endian,directory+2+(12*\n                  number_entries));\n                if ((offset != 0) && ((size_t) offset < length) &&\n                    (level < (MaxDirectoryStack-2)))\n                  {\n                    directory_stack[level].directory=exif+offset;\n                    directory_stack[level].entry=0;\n                    directory_stack[level].offset=tag_offset1;\n                    level++;\n                  }\n              }\n            break;\n          }\n    }\n  } while (level > 0);\n  exif_resources=DestroySplayTree(exif_resources);\n  return(status);\n}",
        "func_hash": 292096308156704952246887123009503225331,
        "file_name": "property.c",
        "file_hash": 122751008107964047346147343124174074065,
        "cwe": [
            "CWE-704"
        ],
        "cve": "CVE-2022-32547",
        "cve_desc": "In ImageMagick, there is load of misaligned address for type 'double', which requires 8 byte alignment and for type 'float', which requires 4 byte alignment at MagickCore/property.c. Whenever crafted or untrusted input is processed by ImageMagick, this causes a negative impact to application availability or other problems related to undefined behavior.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-32547",
        "func_name": "GetEXIFProperty",
        "diff": [
            "diff --git a/magick/property.c b/magick/property.c\nindex 2d80493dd2..bfc689466d 100644\n--- a/magick/property.c\n+++ b/magick/property.c\n@@ -1526,12 +1526,14 @@ static MagickBooleanType GetEXIFProperty(const Image *image,\n             }\n             case EXIF_FMT_SINGLE:\n             {\n-              EXIFMultipleValues(4,\"%f\",(double) *(float *) p1);\n+              EXIFMultipleValues(4,\"%.20g\",(double)\n+                ReadPropertySignedLong(endian,p1));\n               break;\n             }\n             case EXIF_FMT_DOUBLE:\n             {\n-              EXIFMultipleValues(8,\"%f\",*(double *) p1);\n+              EXIFMultipleValues(8,\"%.20g\",(double)\n+                ReadPropertySignedLong(endian,p1));\n               break;\n             }\n             case EXIF_FMT_STRING:\n"
        ],
        "func_after": []
    },
    {
        "idx": 194989,
        "project": "ImageMagick6",
        "commit_id": "450949ed017f009b399c937cf362f0058eacc5fa",
        "project_url": "https://github.com/ImageMagick/ImageMagick6",
        "commit_url": "https://github.com/ImageMagick/ImageMagick6/commit/450949ed017f009b399c937cf362f0058eacc5fa",
        "commit_message": "Pull request: https://github.com/ImageMagick/ImageMagick/pull/4963",
        "target": 1,
        "irrelevant": 1,
        "func_before": "static MagickBooleanType ReadPSDChannelPixels(Image *image,\n  const size_t channels,const ssize_t row,const ssize_t type,\n  const unsigned char *pixels,ExceptionInfo *exception)\n{\n  Quantum\n    pixel;\n\n  const unsigned char\n    *p;\n\n  IndexPacket\n    *indexes;\n\n  PixelPacket\n    *q;\n\n  ssize_t\n    x;\n\n  size_t\n    packet_size;\n\n  unsigned short\n    nibble;\n\n  p=pixels;\n  q=GetAuthenticPixels(image,0,row,image->columns,1,exception);\n  if (q == (PixelPacket *) NULL)\n    return MagickFalse;\n  indexes=GetAuthenticIndexQueue(image);\n  packet_size=GetPSDPacketSize(image);\n  for (x=0; x < (ssize_t) image->columns; x++)\n  {\n    if (packet_size == 1)\n      pixel=ScaleCharToQuantum(*p++);\n    else\n      if (packet_size == 2)\n        {\n          p=PushShortPixel(MSBEndian,p,&nibble);\n          pixel=ScaleShortToQuantum(nibble);\n        }\n      else\n        {\n          MagickFloatType\n            nibble;\n\n          p=PushFloatPixel(MSBEndian,p,&nibble);\n          pixel=ClampToQuantum((MagickRealType)QuantumRange*nibble);\n        }\n    if (image->depth > 1)\n      {\n        SetPSDPixel(image,channels,type,packet_size,pixel,q,indexes,x);\n        q++;\n      }\n    else\n      {\n        ssize_t\n          bit,\n          number_bits;\n\n        number_bits=(ssize_t) image->columns-x;\n        if (number_bits > 8)\n          number_bits=8;\n        for (bit=0; bit < number_bits; bit++)\n        {\n          SetPSDPixel(image,channels,type,packet_size,(((unsigned char) pixel)\n            & (0x01 << (7-bit))) != 0 ? 0 : QuantumRange,q++,indexes,x++);\n        }\n        if (x != (ssize_t) image->columns)\n          x--;\n        continue;\n      }\n  }\n  return(SyncAuthenticPixels(image,exception));\n}",
        "func_hash": 50584299779312396054491404176852470969,
        "file_name": "psd.c",
        "file_hash": 159316916509494023086155162326374999236,
        "cwe": [
            "CWE-190"
        ],
        "cve": "CVE-2022-32545",
        "cve_desc": "A vulnerability was found in ImageMagick, causing an outside the range of representable values of type 'unsigned char' at coders/psd.c, when crafted or untrusted input is processed. This leads to a negative impact to application availability or other problems related to undefined behavior.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-32545",
        "func_name": "ReadPSDChannelPixels",
        "diff": [
            "diff --git a/coders/emf.c b/coders/emf.c\nindex 39c0ac726b..efc92c303f 100644\n--- a/coders/emf.c\n+++ b/coders/emf.c\n@@ -411,7 +411,8 @@ static HENHMETAFILE ReadEnhMetaFile(const char *path,ssize_t *width,\n     }\n   ReadFile(hFile,pBits,dwSize,&dwSize,NULL);\n   CloseHandle(hFile);\n-  if (((PAPMHEADER) pBits)->dwKey != 0x9ac6cdd7l)\n+  if (((PAPMHEADER) pBits)->dwKey != 0x9ac6cdd7l ||\n+      (((PAPMHEADER) pBits)->wInch == 0))\n     {\n       pBits=(BYTE *) DestroyString((char *) pBits);\n       return((HENHMETAFILE) NULL);\ndiff --git a/coders/psd.c b/coders/psd.c\nindex 19d36f0a0e..eedcf3782d 100644\n--- a/coders/psd.c\n+++ b/coders/psd.c\n@@ -1048,8 +1048,9 @@ static MagickBooleanType ReadPSDChannelPixels(Image *image,\n           number_bits=8;\n         for (bit=0; bit < number_bits; bit++)\n         {\n-          SetPSDPixel(image,channels,type,packet_size,(((unsigned char) pixel)\n-            & (0x01 << (7-bit))) != 0 ? 0 : QuantumRange,q++,indexes,x++);\n+          SetPSDPixel(image,channels,type,packet_size,\n+            (((unsigned char) ((ssize_t) pixel)) & (0x01 << (7-bit))) != 0 ? 0 :\n+            QuantumRange,q++,indexes,x++);\n         }\n         if (x != (ssize_t) image->columns)\n           x--;\ndiff --git a/magick/widget.c b/magick/widget.c\nindex 96fb7cd8df..dea54667d5 100644\n--- a/magick/widget.c\n+++ b/magick/widget.c\n@@ -7861,6 +7861,8 @@ MagickExport int XMenuWidget(Display *display,XWindows *windows,\n             break;\n           }\n         state&=(~InactiveWidgetState);\n+        if (selection_info.height == 0)\n+          break;\n         id=(event.xbutton.y-top_offset)/(int) selection_info.height;\n         selection_info.id=id;\n         if ((id < 0) || (id >= (int) number_selections))\n@@ -7914,6 +7916,8 @@ MagickExport int XMenuWidget(Display *display,XWindows *windows,\n         if (event.xcrossing.state == 0)\n           break;\n         state&=(~InactiveWidgetState);\n+        if (selection_info.height == 0)\n+          break;\n         id=((event.xcrossing.y-top_offset)/(int) selection_info.height);\n         if ((selection_info.id >= 0) &&\n             (selection_info.id < (int) number_selections))\n@@ -8000,6 +8004,8 @@ MagickExport int XMenuWidget(Display *display,XWindows *windows,\n           break;\n         if (state & InactiveWidgetState)\n           break;\n+        if (selection_info.height == 0)\n+          break;\n         id=(event.xmotion.y-top_offset)/(int) selection_info.height;\n         if ((selection_info.id >= 0) &&\n             (selection_info.id < (int) number_selections))\ndiff --git a/wand/animate.c b/wand/animate.c\nindex 0f70436108..adc84d8679 100644\n--- a/wand/animate.c\n+++ b/wand/animate.c\n@@ -1143,7 +1143,10 @@ WandExport MagickBooleanType AnimateImageCommand(ImageInfo *image_info,\n             if (i == (ssize_t) argc)\n               ThrowAnimateException(OptionError,\"MissingArgument\",option);\n             if (XRemoteCommand(display,resource_info.window_id,argv[i]) != 0)\n-              return(MagickFalse);\n+              {\n+                DestroyAnimate();\n+                return(MagickFalse);\n+              }\n             i--;\n             break;\n           }\ndiff --git a/wand/display.c b/wand/display.c\nindex b7b9ed932d..27abafa1b5 100644\n--- a/wand/display.c\n+++ b/wand/display.c\n@@ -1491,7 +1491,10 @@ WandExport MagickBooleanType DisplayImageCommand(ImageInfo *image_info,\n             if (i == (ssize_t) argc)\n               ThrowDisplayException(OptionError,\"MissingArgument\",option);\n             if (XRemoteCommand(display,resource_info.window_id,argv[i]) != 0)\n-              return(MagickFalse);\n+              {\n+                DestroyDisplay();\n+                return(MagickFalse);\n+              }\n             i--;\n             break;\n           }\n"
        ],
        "func_after": []
    },
    {
        "idx": 194994,
        "project": "tensorflow",
        "commit_id": "c79ccba517dbb1a0ccb9b01ee3bd2a63748b60dd",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/c79ccba517dbb1a0ccb9b01ee3bd2a63748b60dd",
        "commit_message": "Fix memory leak when a graph node is invalid.\n\nIf a graph node is invalid but a kernel is created then we set the kernel back to `nullptr` but we forget to delete it. Hence, we get a memory leak.\n\nPiperOrigin-RevId: 408968108\nChange-Id: I1d8a9d0d8988ed5e08be8b9f2004ce1b4cd11b7c",
        "target": 1,
        "irrelevant": 0,
        "func_before": "Status ImmutableExecutorState::Initialize(const Graph& graph) {\n  TF_RETURN_IF_ERROR(gview_.Initialize(&graph));\n\n  // Build the information about frames in this subgraph.\n  ControlFlowInfo cf_info;\n  TF_RETURN_IF_ERROR(BuildControlFlowInfo(&graph, &cf_info));\n\n  for (auto& it : cf_info.unique_frame_names) {\n    EnsureFrameInfo(it)->nodes =\n        absl::make_unique<std::vector<const NodeItem*>>();\n  }\n  root_frame_info_ = frame_info_[\"\"].get();\n\n  pending_ids_.resize(gview_.num_nodes());\n\n  // Preprocess every node in the graph to create an instance of op\n  // kernel for each node.\n  requires_control_flow_ = false;\n  for (const Node* n : graph.nodes()) {\n    if (IsSink(n)) continue;\n    if (IsSwitch(n) || IsMerge(n) || IsEnter(n) || IsExit(n)) {\n      requires_control_flow_ = true;\n    } else if (IsRecv(n)) {\n      // A Recv node from a different device may produce dead tensors from\n      // non-local control-flow nodes.\n      //\n      // TODO(mrry): Track whether control flow was present in the\n      // pre-partitioned graph, and enable the caller (e.g.\n      // `DirectSession`) to relax this constraint.\n      string send_device;\n      string recv_device;\n      TF_RETURN_IF_ERROR(GetNodeAttr(n->attrs(), \"send_device\", &send_device));\n      TF_RETURN_IF_ERROR(GetNodeAttr(n->attrs(), \"recv_device\", &recv_device));\n      if (send_device != recv_device) {\n        requires_control_flow_ = true;\n      }\n    }\n\n    const int id = n->id();\n    const string& frame_name = cf_info.frame_names[id];\n    FrameInfo* frame_info = EnsureFrameInfo(frame_name);\n\n    NodeItem* item = gview_.node(id);\n    item->node_id = id;\n\n    item->input_start = frame_info->total_inputs;\n    frame_info->total_inputs += n->num_inputs();\n\n    Status s = params_.create_kernel(n->properties(), &item->kernel);\n    if (!s.ok()) {\n      item->kernel = nullptr;\n      s = AttachDef(s, *n);\n      return s;\n    }\n    CHECK(item->kernel);\n    item->kernel_is_async = (item->kernel->AsAsync() != nullptr);\n    item->is_merge = IsMerge(n);\n    item->is_any_consumer_merge_or_control_trigger = false;\n    for (const Node* consumer : n->out_nodes()) {\n      if (IsMerge(consumer) || IsControlTrigger(consumer)) {\n        item->is_any_consumer_merge_or_control_trigger = true;\n        break;\n      }\n    }\n    const Tensor* const_tensor = item->kernel->const_tensor();\n    if (const_tensor) {\n      // Hold onto a shallow copy of the constant tensor in `*this` so that the\n      // reference count does not drop to 1. This prevents the constant tensor\n      // from being forwarded, and its buffer reused.\n      const_tensors_.emplace_back(*const_tensor);\n    }\n    item->const_tensor = const_tensor;\n    item->is_noop = (item->kernel->type_string_view() == \"NoOp\");\n    item->is_enter = IsEnter(n);\n    if (item->is_enter) {\n      bool is_constant_enter;\n      TF_RETURN_IF_ERROR(\n          GetNodeAttr(n->attrs(), \"is_constant\", &is_constant_enter));\n      item->is_constant_enter = is_constant_enter;\n\n      string frame_name;\n      TF_RETURN_IF_ERROR(GetNodeAttr(n->attrs(), \"frame_name\", &frame_name));\n      FrameInfo* frame_info = frame_info_[frame_name].get();\n\n      int parallel_iterations;\n      TF_RETURN_IF_ERROR(\n          GetNodeAttr(n->attrs(), \"parallel_iterations\", &parallel_iterations));\n\n      if (frame_info->parallel_iterations == -1) {\n        frame_info->parallel_iterations = parallel_iterations;\n      } else if (frame_info->parallel_iterations != parallel_iterations) {\n        LOG(WARNING) << \"Loop frame \\\"\" << frame_name\n                     << \"\\\" had two different values for parallel_iterations: \"\n                     << frame_info->parallel_iterations << \" vs. \"\n                     << parallel_iterations << \".\";\n      }\n\n      if (enter_frame_info_.size() <= id) {\n        enter_frame_info_.resize(id + 1);\n      }\n      enter_frame_info_[id] = frame_info;\n    } else {\n      item->is_constant_enter = false;\n    }\n    item->is_exit = IsExit(n);\n    item->is_control_trigger = IsControlTrigger(n);\n    item->is_source = IsSource(n);\n    item->is_enter_exit_or_next_iter =\n        (IsEnter(n) || IsExit(n) || IsNextIteration(n));\n    item->is_transfer_node = IsTransferNode(n);\n    item->is_initialization_op = IsInitializationOp(n);\n    item->is_recv_or_switch = IsRecv(n) || IsSwitch(n);\n    item->is_next_iteration = IsNextIteration(n);\n    item->is_distributed_communication = IsDistributedCommunication(n);\n\n    // Compute the maximum values we'll store for this node in the\n    // pending counts data structure, and allocate a handle in\n    // that frame's pending counts data structure that has enough\n    // space to store these maximal count values.\n    size_t max_pending, max_dead;\n    GetMaxPendingCounts(n, &max_pending, &max_dead);\n    pending_ids_[id] =\n        frame_info->pending_counts_layout.CreateHandle(max_pending, max_dead);\n\n    // See if this node is a root node, and if so, add item to root_nodes_.\n    if (n->in_edges().empty()) {\n      root_nodes_.push_back(item);\n    }\n\n    // Initialize static information about the frames in the graph.\n    frame_info->nodes->push_back(item);\n    if (item->is_enter) {\n      string enter_name;\n      TF_RETURN_IF_ERROR(GetNodeAttr(n->attrs(), \"frame_name\", &enter_name));\n      EnsureFrameInfo(enter_name)->input_count++;\n    }\n\n    // Record information about whether each output of the op is used.\n    std::unique_ptr<bool[]> outputs_required(new bool[n->num_outputs()]);\n    std::fill(&outputs_required[0], &outputs_required[n->num_outputs()], false);\n    int32_t unused_outputs = n->num_outputs();\n    for (const Edge* e : n->out_edges()) {\n      if (IsSink(e->dst())) continue;\n      if (e->src_output() >= 0) {\n        if (!outputs_required[e->src_output()]) {\n          --unused_outputs;\n          outputs_required[e->src_output()] = true;\n        }\n      }\n    }\n    if (unused_outputs > 0) {\n      for (int i = 0; i < n->num_outputs(); ++i) {\n        if (!outputs_required[i]) {\n          metrics::RecordUnusedOutput(n->type_string());\n        }\n      }\n      item->outputs_required = std::move(outputs_required);\n    }\n  }\n\n  // Rewrite each `EdgeInfo::input_slot` member to refer directly to the input\n  // location.\n  for (const Node* n : graph.nodes()) {\n    if (IsSink(n)) continue;\n    const int id = n->id();\n    NodeItem* item = gview_.node(id);\n\n    for (EdgeInfo& e : item->mutable_output_edges()) {\n      const int dst_id = e.dst_id;\n      NodeItem* dst_item = gview_.node(dst_id);\n      e.input_slot += dst_item->input_start;\n    }\n  }\n\n  // Initialize PendingCounts only after pending_ids_[node.id] is initialized\n  // for all nodes.\n  InitializePending(&graph, cf_info);\n  return gview_.SetAllocAttrs(&graph, params_.device);\n}",
        "func_hash": 105248557138287586060572648585871722551,
        "file_name": "immutable_executor_state.cc",
        "file_hash": 234046012522402227954780787024760975669,
        "cwe": [
            "CWE-401"
        ],
        "cve": "CVE-2022-23578",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. If a graph node is invalid, TensorFlow can leak memory in the implementation of `ImmutableExecutorState::Initialize`. Here, we set `item->kernel` to `nullptr` but it is a simple `OpKernel*` pointer so the memory that was previously allocated to it would leak. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23578",
        "func_name": "ImmutableExecutorState::Initialize",
        "diff": [
            "diff --git a/tensorflow/core/common_runtime/immutable_executor_state.cc b/tensorflow/core/common_runtime/immutable_executor_state.cc\nindex 1f728334e2b7ee..25822540f024ae 100644\n--- a/tensorflow/core/common_runtime/immutable_executor_state.cc\n+++ b/tensorflow/core/common_runtime/immutable_executor_state.cc\n@@ -131,6 +131,7 @@ Status ImmutableExecutorState::Initialize(const Graph& graph) {\n \n     Status s = params_.create_kernel(n->properties(), &item->kernel);\n     if (!s.ok()) {\n+      params_.delete_kernel(item->kernel);\n       item->kernel = nullptr;\n       s = AttachDef(s, *n);\n       return s;\n"
        ],
        "func_after": []
    },
    {
        "idx": 194996,
        "project": "tensorflow",
        "commit_id": "4f38b1ac8e42727e18a2f0bde06d3bee8e77b250",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/4f38b1ac8e42727e18a2f0bde06d3bee8e77b250",
        "commit_message": "Prevent null dereference read in `GetInitOp`.\n\nWe have a map of maps. We test that the key exists in the first map but then we don't have any validation that this also means the second map has the needed key. In the scenarios where this is not the case, we'll dereference a nullptr, if we don't have this check\n\nPiperOrigin-RevId: 408739325\nChange-Id: If9bb7ed759aba1f3b56a34913f209508dbaf65ce",
        "target": 1,
        "irrelevant": 1,
        "func_before": "Status GetInitOp(const string& export_dir, const MetaGraphDef& meta_graph_def,\n                 string* init_op_name) {\n  const auto& sig_def_map = meta_graph_def.signature_def();\n  const auto& init_op_sig_it =\n      meta_graph_def.signature_def().find(kSavedModelInitOpSignatureKey);\n  if (init_op_sig_it != sig_def_map.end()) {\n    *init_op_name = init_op_sig_it->second.outputs()\n                        .find(kSavedModelInitOpSignatureKey)\n                        ->second.name();\n    return Status::OK();\n  }\n\n  const auto& collection_def_map = meta_graph_def.collection_def();\n  string init_op_collection_key;\n  if (collection_def_map.find(kSavedModelMainOpKey) !=\n      collection_def_map.end()) {\n    init_op_collection_key = kSavedModelMainOpKey;\n  } else {\n    init_op_collection_key = kSavedModelLegacyInitOpKey;\n  }\n\n  const auto init_op_it = collection_def_map.find(init_op_collection_key);\n  if (init_op_it != collection_def_map.end()) {\n    if (init_op_it->second.node_list().value_size() != 1) {\n      return errors::FailedPrecondition(\n          strings::StrCat(\"Expected exactly one main op in : \", export_dir));\n    }\n    *init_op_name = init_op_it->second.node_list().value(0);\n  }\n  return Status::OK();\n}",
        "func_hash": 90320046309155279319769139363770698236,
        "file_name": "loader_util.cc",
        "file_hash": 223638670651747648145854147173893848422,
        "cwe": [
            "CWE-476"
        ],
        "cve": "CVE-2022-23577",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The implementation of `GetInitOp` is vulnerable to a crash caused by dereferencing a null pointer. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23577",
        "func_name": "GetInitOp",
        "diff": [
            "diff --git a/tensorflow/cc/saved_model/loader_util.cc b/tensorflow/cc/saved_model/loader_util.cc\nindex 100cae2291333f..411dc41fd44837 100644\n--- a/tensorflow/cc/saved_model/loader_util.cc\n+++ b/tensorflow/cc/saved_model/loader_util.cc\n@@ -34,9 +34,14 @@ Status GetInitOp(const string& export_dir, const MetaGraphDef& meta_graph_def,\n   const auto& init_op_sig_it =\n       meta_graph_def.signature_def().find(kSavedModelInitOpSignatureKey);\n   if (init_op_sig_it != sig_def_map.end()) {\n-    *init_op_name = init_op_sig_it->second.outputs()\n-                        .find(kSavedModelInitOpSignatureKey)\n-                        ->second.name();\n+    const auto& sig_def_outputs = init_op_sig_it->second.outputs();\n+    const auto& sig_def_outputs_it =\n+        sig_def_outputs.find(kSavedModelInitOpSignatureKey);\n+    if (sig_def_outputs_it == sig_def_outputs.end()) {\n+      return errors::FailedPrecondition(\"Could not find output \",\n+                                        kSavedModelInitOpSignatureKey);\n+    }\n+    *init_op_name = sig_def_outputs_it->second.name();\n     return Status::OK();\n   }\n \n"
        ],
        "func_after": []
    },
    {
        "idx": 194998,
        "project": "tensorflow",
        "commit_id": "240655511cd3e701155f944a972db71b6c0b1bb6",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/240655511cd3e701155f944a972db71b6c0b1bb6",
        "commit_message": "Eliminate `CHECK`-fails from `IsSimplifiableReshape` via `MakeShape(<invalid shape>)`\n\nPiperOrigin-RevId: 409166738\nChange-Id: I7f0a3590b8acae3f3e3e2fe636e1f5ef285693cf",
        "target": 1,
        "irrelevant": 0,
        "func_before": "Status ConstantFolding::IsSimplifiableReshape(\n    const NodeDef& node, const GraphProperties& properties) const {\n  if (!IsReshape(node)) {\n    return errors::Internal(\"Node \", node.name(), \" is not a Reshape node\");\n  }\n  if (2 > node.input_size()) {\n    return errors::Internal(\"Node \", node.name(),\n                            \" must have at most 2 inputs but has \",\n                            node.input_size());\n  }\n  const NodeDef* new_shape = node_map_->GetNode(node.input(1));\n  if (!IsReallyConstant(*new_shape)) {\n    return errors::Internal(\"Node \", node.name(), \" has shape \",\n                            new_shape->DebugString(),\n                            \" which is not a constant\");\n  }\n  TensorVector outputs;\n  auto outputs_cleanup = gtl::MakeCleanup([&outputs] {\n    for (const auto& output : outputs) {\n      delete output.tensor;\n    }\n  });\n\n  Status s = EvaluateNode(*new_shape, TensorVector(), &outputs);\n  if (!s.ok()) {\n    return errors::Internal(\"Could not evaluate node \", node.name());\n  }\n  if (outputs.size() != 1) {\n    return errors::Internal(\"Node \", node.name(),\n                            \" must have exactly 1 output but has \",\n                            outputs.size());\n  }\n\n  const std::vector<OpInfo::TensorProperties>& props =\n      properties.GetInputProperties(node.name());\n  if (props.empty()) {\n    return errors::Internal(\"Node \", node.name(), \" has no properties\");\n  }\n  const OpInfo::TensorProperties& prop = props[0];\n  if (prop.dtype() == DT_INVALID) {\n    return errors::Internal(\"Node \", node.name(), \" has property \",\n                            prop.DebugString(), \" with invalid dtype\");\n  }\n  const PartialTensorShape shape(prop.shape());\n  if (!shape.IsFullyDefined()) {\n    return errors::Internal(\"Node \", node.name(), \" has property \",\n                            prop.DebugString(), \" with shape \",\n                            shape.DebugString(), \" which is not fully defined\");\n  }\n\n  PartialTensorShape new_dims;\n  if (outputs[0]->dtype() == DT_INT32) {\n    std::vector<int32> shp;\n    for (int i = 0; i < outputs[0]->NumElements(); ++i) {\n      int32_t dim = outputs[0]->flat<int32>()(i);\n      shp.push_back(dim);\n    }\n    TF_CHECK_OK(TensorShapeUtils::MakeShape(shp, &new_dims));\n  } else {\n    std::vector<int64_t> shp;\n    for (int i = 0; i < outputs[0]->NumElements(); ++i) {\n      int64_t dim = outputs[0]->flat<int64_t>()(i);\n      shp.push_back(dim);\n    }\n    TF_CHECK_OK(TensorShapeUtils::MakeShape(shp, &new_dims));\n  }\n\n  if (!shape.IsCompatibleWith(new_dims)) {\n    return errors::Internal(\"Expected shape \", shape.DebugString(),\n                            \"to be compatible with \", new_dims.DebugString());\n  }\n\n  return Status::OK();\n}",
        "func_hash": 122664089420988233915419567191040959656,
        "file_name": "constant_folding.cc",
        "file_hash": 35061507297230918846503076104140700863,
        "cwe": [
            "CWE-617"
        ],
        "cve": "CVE-2022-23581",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The Grappler optimizer in TensorFlow can be used to cause a denial of service by altering a `SavedModel` such that `IsSimplifiableReshape` would trigger `CHECK` failures. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23581",
        "func_name": "ConstantFolding::IsSimplifiableReshape",
        "diff": [
            "diff --git a/tensorflow/core/grappler/optimizers/constant_folding.cc b/tensorflow/core/grappler/optimizers/constant_folding.cc\nindex a2050899f60726..d5fadb311a75cc 100644\n--- a/tensorflow/core/grappler/optimizers/constant_folding.cc\n+++ b/tensorflow/core/grappler/optimizers/constant_folding.cc\n@@ -1741,14 +1741,16 @@ Status ConstantFolding::IsSimplifiableReshape(\n       int32_t dim = outputs[0]->flat<int32>()(i);\n       shp.push_back(dim);\n     }\n-    TF_CHECK_OK(TensorShapeUtils::MakeShape(shp, &new_dims));\n+    s = TensorShapeUtils::MakeShape(shp, &new_dims);\n+    if (!s.ok()) return s;\n   } else {\n     std::vector<int64_t> shp;\n     for (int i = 0; i < outputs[0]->NumElements(); ++i) {\n       int64_t dim = outputs[0]->flat<int64_t>()(i);\n       shp.push_back(dim);\n     }\n-    TF_CHECK_OK(TensorShapeUtils::MakeShape(shp, &new_dims));\n+    s = TensorShapeUtils::MakeShape(shp, &new_dims);\n+    if (!s.ok()) return s;\n   }\n \n   if (!shape.IsCompatibleWith(new_dims)) {\n"
        ],
        "func_after": []
    },
    {
        "idx": 195017,
        "project": "gpac",
        "commit_id": "ad18ece95fa064efc0995c4ab2c985f77fb166ec",
        "project_url": "https://github.com/gpac/gpac",
        "commit_url": "https://github.com/gpac/gpac/commit/ad18ece95fa064efc0995c4ab2c985f77fb166ec",
        "commit_message": "fixed #1904",
        "target": 1,
        "irrelevant": 1,
        "func_before": "u32 GetHintFormat(GF_TrackBox *trak)\n{\n\tGF_HintMediaHeaderBox *hmhd = (GF_HintMediaHeaderBox *)trak->Media->information->InfoHeader;\n\tif (hmhd->type != GF_ISOM_BOX_TYPE_HMHD)\n\t\treturn 0;\n\t\t\n\tif (!hmhd || !hmhd->subType) {\n\t\tGF_Box *a = (GF_Box *)gf_list_get(trak->Media->information->sampleTable->SampleDescription->child_boxes, 0);\n\t\tif (!hmhd) return a ? a->type : 0;\n\t\tif (a) hmhd->subType = a->type;\n\t\treturn hmhd->subType;\n\t}\n\treturn hmhd->subType;\n}",
        "func_hash": 91218268849686441388880855658517990203,
        "file_name": "hint_track.c",
        "file_hash": 60176895274654779679144452624639678766,
        "cwe": [
            "CWE-476"
        ],
        "cve": "CVE-2021-40576",
        "cve_desc": "The binary MP4Box in Gpac 1.0.1 has a null pointer dereference vulnerability in the gf_isom_get_payt_count function in hint_track.c, which allows attackers to cause a denial of service.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-40576",
        "func_name": "GetHintFormat",
        "diff": [
            "diff --git a/src/isomedia/hint_track.c b/src/isomedia/hint_track.c\nindex 304aa2cd8c..385e746257 100644\n--- a/src/isomedia/hint_track.c\n+++ b/src/isomedia/hint_track.c\n@@ -43,7 +43,7 @@ Bool IsHintTrack(GF_TrackBox *trak)\n u32 GetHintFormat(GF_TrackBox *trak)\n {\n \tGF_HintMediaHeaderBox *hmhd = (GF_HintMediaHeaderBox *)trak->Media->information->InfoHeader;\n-\tif (hmhd->type != GF_ISOM_BOX_TYPE_HMHD)\n+\tif (!hmhd || (hmhd->type != GF_ISOM_BOX_TYPE_HMHD))\n \t\treturn 0;\n \t\t\n \tif (!hmhd || !hmhd->subType) {\n"
        ],
        "func_after": []
    },
    {
        "idx": 195019,
        "project": "tensorflow",
        "commit_id": "6b5adc0877de832b2a7c189532dbbbc64622eeb6",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/6b5adc0877de832b2a7c189532dbbbc64622eeb6",
        "commit_message": "Prevent `CHECK`-fail when building reference tensor.\n\nThe tensor constructor does not allow reference dtypes, as these should not show up explicitly. However, when passed these invalid types instead of building an invalid object the constructor crashes via a `CHECK`-fail. We have a static builder that properly handles this case but is not applicable given current usage.\n\nInstead, before calling the constructor, we can check that the dtype is not a reference type and return an error otherwise, given that the dtype is user controlled so malicious users can trigger denial of service.\n\nPiperOrigin-RevId: 409662503\nChange-Id: I5892f831fde7f276cd7ab34519cf6b8061c71a59",
        "target": 1,
        "irrelevant": 0,
        "func_before": "Status ConstantFolding::EvaluateOneFoldable(const NodeDef& node,\n                                            std::vector<NodeDef>* outputs,\n                                            bool* result_too_large) {\n  TensorVector inputs;\n  TensorVector output_tensors;\n  auto inputs_cleanup = gtl::MakeCleanup([&inputs, &output_tensors] {\n    for (const auto& input : inputs) {\n      delete input.tensor;\n    }\n    for (const auto& output : output_tensors) {\n      if (output.tensor) {\n        delete output.tensor;\n      }\n    }\n  });\n\n  size_t total_inputs_size = 0;\n  for (const auto& input : node.input()) {\n    const TensorId input_tensor = ParseTensorName(input);\n    if (input_tensor.index() < 0) {\n      // Control dependency\n      break;\n    }\n    const NodeDef* input_node = node_map_->GetNode(input);\n    if (!IsReallyConstant(*input_node)) {\n      return Status(error::INVALID_ARGUMENT,\n                    strings::StrCat(\"Can't fold \", node.name(), \", its \", input,\n                                    \" isn't constant\"));\n    }\n    TF_RETURN_IF_ERROR(CheckAttrExists(*input_node, \"value\"));\n    const TensorProto& raw_val = input_node->attr().at(\"value\").tensor();\n    if (raw_val.dtype() == DT_INVALID) {\n      return Status(\n          error::INVALID_ARGUMENT,\n          strings::StrCat(\"A tensor in the input node, with TensorId of \",\n                          input_tensor.ToString(),\n                          \" has a dtype of DT_INVALID.\"));\n    }\n    Tensor* value = new Tensor(raw_val.dtype(), raw_val.tensor_shape());\n    if (!value->FromProto(raw_val)) {\n      delete (value);\n      return errors::InvalidArgument(\"Unable to make Tensor from proto for \",\n                                     node.name(), \" with shape \",\n                                     raw_val.tensor_shape().DebugString());\n    }\n    inputs.emplace_back(value);\n    total_inputs_size += value->TotalBytes();\n  }\n\n  TF_RETURN_IF_ERROR(EvaluateNode(node, inputs, &output_tensors));\n  if (output_tensors.empty()) {\n    return Status(error::INVALID_ARGUMENT, \"Expected at least one output.\");\n  }\n\n  outputs->resize(output_tensors.size());\n  for (size_t i = 0; i < output_tensors.size(); i++) {\n    string node_name = OptimizedNodeName(node, \"-folded\");\n    if (output_tensors.size() > 1) {\n      node_name = strings::StrCat(node_name, \"-\", i);\n    }\n    if (output_tensors[i].tensor) {\n      Status s = CreateNodeDef(node_name, output_tensors[i], &outputs->at(i),\n                               total_inputs_size);\n      if (!s.ok()) {\n        *result_too_large = true;\n        return s;\n      }\n    } else {\n      // Create an empty NodeDef to identify dead outputs (e.g. the output of a\n      // switch that's not selected by the switch predicate).\n      outputs->at(i) = NodeDef();\n    }\n  }\n  return Status::OK();\n}",
        "func_hash": 33937240667530924395323323412961833143,
        "file_name": "constant_folding.cc",
        "file_hash": 221573695858123615640237954647315751120,
        "cwe": [
            "CWE-617"
        ],
        "cve": "CVE-2022-23588",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. A malicious user can cause a denial of service by altering a `SavedModel` such that Grappler optimizer would attempt to build a tensor using a reference `dtype`. This would result in a crash due to a `CHECK`-fail in the `Tensor` constructor as reference types are not allowed. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23588",
        "func_name": "ConstantFolding::EvaluateOneFoldable",
        "diff": [
            "diff --git a/tensorflow/core/grappler/optimizers/constant_folding.cc b/tensorflow/core/grappler/optimizers/constant_folding.cc\nindex d5fadb311a75cc..281806be20259f 100644\n--- a/tensorflow/core/grappler/optimizers/constant_folding.cc\n+++ b/tensorflow/core/grappler/optimizers/constant_folding.cc\n@@ -1363,6 +1363,11 @@ Status ConstantFolding::EvaluateOneFoldable(const NodeDef& node,\n                           input_tensor.ToString(),\n                           \" has a dtype of DT_INVALID.\"));\n     }\n+    if (IsRefType(raw_val.dtype())) {\n+      return errors::InvalidArgument(\n+          \"Not allowed to construct a tensor with reference dtype, got \",\n+          DataTypeString(raw_val.dtype()));\n+    }\n     Tensor* value = new Tensor(raw_val.dtype(), raw_val.tensor_shape());\n     if (!value->FromProto(raw_val)) {\n       delete (value);\n"
        ],
        "func_after": []
    },
    {
        "idx": 195022,
        "project": "glewlwyd",
        "commit_id": "125281f1c0d4b6a8b49f7e55a757205a2ef01fbe",
        "project_url": "https://github.com/babelouest/glewlwyd",
        "commit_url": "https://github.com/babelouest/glewlwyd/commit/125281f1c0d4b6a8b49f7e55a757205a2ef01fbe",
        "commit_message": "Fix update session when auth fail",
        "target": 1,
        "irrelevant": 0,
        "func_before": "int callback_glewlwyd_user_auth (const struct _u_request * request, struct _u_response * response, void * user_data) {\n  struct config_elements * config = (struct config_elements *)user_data;\n  json_t * j_param = ulfius_get_json_body_request(request, NULL), * j_result = NULL;\n  const char * ip_source = get_ip_source(request);\n  char * issued_for = get_client_hostname(request);\n  char * session_uid, expires[129];\n  time_t now;\n  struct tm ts;\n  \n  time(&now);\n  now += GLEWLWYD_DEFAULT_SESSION_EXPIRATION_COOKIE;\n  gmtime_r(&now, &ts);\n  strftime(expires, 128, \"%a, %d %b %Y %T %Z\", &ts);\n  if (j_param != NULL) {\n    if (json_string_length(json_object_get(j_param, \"username\"))) {\n      if (json_object_get(j_param, \"scheme_type\") == NULL || 0 == o_strcmp(json_string_value(json_object_get(j_param, \"scheme_type\")), \"password\")) {\n        if (json_string_length(json_object_get(j_param, \"password\"))) {\n          j_result = auth_check_user_credentials(config, json_string_value(json_object_get(j_param, \"username\")), json_string_value(json_object_get(j_param, \"password\")));\n          if (check_result_value(j_result, G_OK)) {\n            if ((session_uid = get_session_id(config, request)) == NULL) {\n              session_uid = generate_session_id();\n            }\n            if (user_session_update(config, session_uid, u_map_get_case(request->map_header, \"user-agent\"), issued_for, json_string_value(json_object_get(j_param, \"username\")), NULL, 1) != G_OK) {\n              y_log_message(Y_LOG_LEVEL_ERROR, \"callback_glewlwyd_user_auth - Error user_session_update (1)\");\n              response->status = 500;\n            } else {\n              ulfius_add_cookie_to_response(response, config->session_key, session_uid, expires, 0, config->cookie_domain, \"/\", config->cookie_secure, 0);\n              y_log_message(Y_LOG_LEVEL_INFO, \"Event - User '%s' authenticated with password\", json_string_value(json_object_get(j_param, \"username\")));\n            }\n            o_free(session_uid);\n            glewlwyd_metrics_increment_counter_va(config, GLWD_METRICS_AUTH_USER_VALID, 1, NULL);\n            glewlwyd_metrics_increment_counter_va(config, GLWD_METRICS_AUTH_USER_VALID_SCHEME, 1, \"scheme_type\", \"password\", NULL);\n          } else {\n            if (check_result_value(j_result, G_ERROR_UNAUTHORIZED)) {\n              y_log_message(Y_LOG_LEVEL_WARNING, \"Security - Authorization invalid for username %s at IP Address %s\", json_string_value(json_object_get(j_param, \"username\")), ip_source);\n            }\n            if ((session_uid = get_session_id(config, request)) != NULL && user_session_update(config, session_uid, u_map_get_case(request->map_header, \"user-agent\"), issued_for, json_string_value(json_object_get(j_param, \"username\")), NULL, 1) != G_OK) {\n              y_log_message(Y_LOG_LEVEL_ERROR, \"callback_glewlwyd_user_auth - Error user_session_update (2)\");\n            }\n            o_free(session_uid);\n            response->status = 401;\n            glewlwyd_metrics_increment_counter_va(config, GLWD_METRICS_AUTH_USER_INVALID, 1, NULL);\n            glewlwyd_metrics_increment_counter_va(config, GLWD_METRICS_AUTH_USER_INVALID_SCHEME, 1, \"scheme_type\", \"password\", NULL);\n          }\n          json_decref(j_result);\n        } else if (json_object_get(j_param, \"password\") != NULL && !json_is_string(json_object_get(j_param, \"password\"))) {\n          ulfius_set_string_body_response(response, 400, \"password must be a string\");\n        } else {\n          session_uid = get_session_id(config, request);\n          j_result = get_users_for_session(config, session_uid);\n          if (check_result_value(j_result, G_OK)) {\n            // Refresh username to set as default\n            if (user_session_update(config, u_map_get(request->map_cookie, config->session_key), u_map_get_case(request->map_header, \"user-agent\"), issued_for, json_string_value(json_object_get(j_param, \"username\")), NULL, 0) != G_OK) {\n              y_log_message(Y_LOG_LEVEL_ERROR, \"callback_glewlwyd_user_auth - Error user_session_update (3)\");\n              response->status = 500;\n            } else {\n              ulfius_add_cookie_to_response(response, config->session_key, session_uid, expires, 0, config->cookie_domain, \"/\", config->cookie_secure, 0);\n            }\n          } else if (check_result_value(j_result, G_ERROR_NOT_FOUND)) {\n            response->status = 401;\n          } else {\n            y_log_message(Y_LOG_LEVEL_ERROR, \"callback_glewlwyd_user_auth - Error get_users_for_session\");\n            response->status = 500;\n          }\n          o_free(session_uid);\n          json_decref(j_result);\n        }\n      } else {\n        if (json_string_length(json_object_get(j_param, \"scheme_type\")) && json_string_length(json_object_get(j_param, \"scheme_name\")) && json_is_object(json_object_get(j_param, \"value\"))) {\n          j_result = auth_check_user_scheme(config, json_string_value(json_object_get(j_param, \"scheme_type\")), json_string_value(json_object_get(j_param, \"scheme_name\")), json_string_value(json_object_get(j_param, \"username\")), json_object_get(j_param, \"value\"), request);\n          if (check_result_value(j_result, G_ERROR_PARAM)) {\n            ulfius_set_string_body_response(response, 400, \"bad scheme response\");\n          } else if (check_result_value(j_result, G_ERROR_UNAUTHORIZED)) {\n            y_log_message(Y_LOG_LEVEL_WARNING, \"Security - Authorization invalid for username %s at IP Address %s\", json_string_value(json_object_get(j_param, \"username\")), ip_source);\n            response->status = 401;\n            glewlwyd_metrics_increment_counter_va(config, GLWD_METRICS_AUTH_USER_INVALID, 1, NULL);\n            glewlwyd_metrics_increment_counter_va(config, GLWD_METRICS_AUTH_USER_INVALID_SCHEME, 1, \"scheme_type\", json_string_value(json_object_get(j_param, \"scheme_type\")), \"scheme_name\", json_string_value(json_object_get(j_param, \"scheme_name\")), NULL);\n          } else if (check_result_value(j_result, G_ERROR_NOT_FOUND)) {\n            response->status = 404;\n          } else if (check_result_value(j_result, G_OK)) {\n            if ((session_uid = get_session_id(config, request)) == NULL) {\n              session_uid = generate_session_id();\n            }\n            if (user_session_update(config, session_uid, u_map_get_case(request->map_header, \"user-agent\"), issued_for, json_string_value(json_object_get(j_param, \"username\")), json_string_value(json_object_get(j_param, \"scheme_name\")), 1) != G_OK) {\n              y_log_message(Y_LOG_LEVEL_ERROR, \"callback_glewlwyd_user_auth - Error user_session_update (4)\");\n              response->status = 500;\n            } else {\n              ulfius_add_cookie_to_response(response, config->session_key, session_uid, expires, 0, config->cookie_domain, \"/\", config->cookie_secure, 0);\n              y_log_message(Y_LOG_LEVEL_INFO, \"Event - User '%s' authenticated with scheme '%s/%s'\", json_string_value(json_object_get(j_param, \"username\")), json_string_value(json_object_get(j_param, \"scheme_type\")), json_string_value(json_object_get(j_param, \"scheme_name\")));\n            }\n            o_free(session_uid);\n            glewlwyd_metrics_increment_counter_va(config, GLWD_METRICS_AUTH_USER_VALID, 1, NULL);\n            glewlwyd_metrics_increment_counter_va(config, GLWD_METRICS_AUTH_USER_VALID_SCHEME, 1, \"scheme_type\", json_string_value(json_object_get(j_param, \"scheme_type\")), \"scheme_name\", json_string_value(json_object_get(j_param, \"scheme_name\")), NULL);\n          } else {\n            y_log_message(Y_LOG_LEVEL_ERROR, \"callback_glewlwyd_user_auth - Error auth_check_user_scheme\");\n            response->status = 500;\n          }\n          json_decref(j_result);\n        } else {\n          ulfius_set_string_body_response(response, 400, \"scheme_type, scheme_name and value are mandatory\");\n        }\n      }\n    } else {\n      if (json_string_length(json_object_get(j_param, \"scheme_type\")) && json_string_length(json_object_get(j_param, \"scheme_name\")) && json_is_object(json_object_get(j_param, \"value\"))) {\n        j_result = auth_check_identify_scheme(config, json_string_value(json_object_get(j_param, \"scheme_type\")), json_string_value(json_object_get(j_param, \"scheme_name\")), json_object_get(j_param, \"value\"), request);\n        if (check_result_value(j_result, G_ERROR_PARAM)) {\n          ulfius_set_string_body_response(response, 400, \"bad scheme response\");\n        } else if (check_result_value(j_result, G_ERROR_UNAUTHORIZED)) {\n          y_log_message(Y_LOG_LEVEL_WARNING, \"Security - Authorization invalid for username <UNKNOWN> at IP Address %s\", ip_source);\n          response->status = 401;\n        } else if (check_result_value(j_result, G_ERROR_NOT_FOUND)) {\n          response->status = 404;\n        } else if (check_result_value(j_result, G_OK)) {\n          if ((session_uid = get_session_id(config, request)) == NULL) {\n            session_uid = generate_session_id();\n          }\n          if (user_session_update(config, session_uid, u_map_get_case(request->map_header, \"user-agent\"), issued_for, json_string_value(json_object_get(j_result, \"username\")), json_string_value(json_object_get(j_param, \"scheme_name\")), 1) != G_OK) {\n            y_log_message(Y_LOG_LEVEL_ERROR, \"callback_glewlwyd_user_auth - Error user_session_update (4)\");\n            response->status = 500;\n          } else {\n            ulfius_add_cookie_to_response(response, config->session_key, session_uid, expires, 0, config->cookie_domain, \"/\", config->cookie_secure, 0);\n            y_log_message(Y_LOG_LEVEL_INFO, \"Event - User '%s' authenticated with scheme '%s/%s'\", json_string_value(json_object_get(j_result, \"username\")), json_string_value(json_object_get(j_param, \"scheme_type\")), json_string_value(json_object_get(j_param, \"scheme_name\")));\n          }\n          o_free(session_uid);\n        } else {\n          y_log_message(Y_LOG_LEVEL_ERROR, \"callback_glewlwyd_user_auth - Error auth_check_user_scheme\");\n          response->status = 500;\n        }\n        json_decref(j_result);\n      } else {\n        ulfius_set_string_body_response(response, 400, \"username is mandatory\");\n      }\n    }\n  } else {\n    ulfius_set_string_body_response(response, 400, \"Input parameters must be in JSON format\");\n  }\n  json_decref(j_param);\n  o_free(issued_for);\n\n  return U_CALLBACK_CONTINUE;\n}",
        "func_hash": 236114269060053642565806917047085397848,
        "file_name": "webservice.c",
        "file_hash": 249878395356016662912854745569339968395,
        "cwe": [
            "CWE-287"
        ],
        "cve": "CVE-2021-45379",
        "cve_desc": "Glewlwyd 2.0.0, fixed in 2.6.1 is affected by an incorrect access control vulnerability. One user can attempt to log in as another user without its password.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-45379",
        "func_name": "callback_glewlwyd_user_auth",
        "diff": [
            "diff --git a/src/webservice.c b/src/webservice.c\nindex 15ab937be..58e0a3ab0 100644\n--- a/src/webservice.c\n+++ b/src/webservice.c\n@@ -278,10 +278,6 @@ int callback_glewlwyd_user_auth (const struct _u_request * request, struct _u_re\n             if (check_result_value(j_result, G_ERROR_UNAUTHORIZED)) {\n               y_log_message(Y_LOG_LEVEL_WARNING, \"Security - Authorization invalid for username %s at IP Address %s\", json_string_value(json_object_get(j_param, \"username\")), ip_source);\n             }\n-            if ((session_uid = get_session_id(config, request)) != NULL && user_session_update(config, session_uid, u_map_get_case(request->map_header, \"user-agent\"), issued_for, json_string_value(json_object_get(j_param, \"username\")), NULL, 1) != G_OK) {\n-              y_log_message(Y_LOG_LEVEL_ERROR, \"callback_glewlwyd_user_auth - Error user_session_update (2)\");\n-            }\n-            o_free(session_uid);\n             response->status = 401;\n             glewlwyd_metrics_increment_counter_va(config, GLWD_METRICS_AUTH_USER_INVALID, 1, NULL);\n             glewlwyd_metrics_increment_counter_va(config, GLWD_METRICS_AUTH_USER_INVALID_SCHEME, 1, \"scheme_type\", \"password\", NULL);\n"
        ],
        "func_after": []
    },
    {
        "idx": 195023,
        "project": "tensorflow",
        "commit_id": "a68f68061e263a88321c104a6c911fe5598050a8",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/a68f68061e263a88321c104a6c911fe5598050a8",
        "commit_message": "Replace faulty overflow check with a builder for `TensorShape`.\n\nPrevents an integer overflow that was not caught before.\n\nPiperOrigin-RevId: 415381595\nChange-Id: I76585ddedc912bd9f4a390aeafa8e2ced1a28863",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext* context) override {\n    const Tensor* input_indices;\n    const Tensor* input_values;\n    const Tensor* input_shape;\n    SparseTensorsMap* map;\n\n    OP_REQUIRES_OK(context, context->input(\"sparse_indices\", &input_indices));\n    OP_REQUIRES_OK(context, context->input(\"sparse_values\", &input_values));\n    OP_REQUIRES_OK(context, context->input(\"sparse_shape\", &input_shape));\n    OP_REQUIRES_OK(context, GetMap(context, true /* is_writing */, &map));\n\n    OP_REQUIRES(context, TensorShapeUtils::IsMatrix(input_indices->shape()),\n                errors::InvalidArgument(\n                    \"Input indices should be a matrix but received shape \",\n                    input_indices->shape().DebugString()));\n    OP_REQUIRES(context, TensorShapeUtils::IsVector(input_values->shape()),\n                errors::InvalidArgument(\n                    \"Input values should be a vector but received shape \",\n                    input_values->shape().DebugString()));\n    OP_REQUIRES(context, TensorShapeUtils::IsVector(input_shape->shape()),\n                errors::InvalidArgument(\n                    \"Input shape should be a vector but received shape \",\n                    input_shape->shape().DebugString()));\n    OP_REQUIRES(\n        context,\n        input_values->shape().dim_size(0) == input_indices->shape().dim_size(0),\n        errors::InvalidArgument(\n            \"Number of values must match first dimension of indices. \", \"Got \",\n            input_values->shape().dim_size(0),\n            \" values, indices shape: \", input_indices->shape().DebugString()));\n    OP_REQUIRES(\n        context,\n        input_shape->shape().dim_size(0) == input_indices->shape().dim_size(1),\n        errors::InvalidArgument(\n            \"Number of dimensions must match second dimension of indices. \",\n            \"Got \", input_shape->shape().dim_size(0),\n            \" dimensions, indices shape: \",\n            input_indices->shape().DebugString()));\n\n    int rank = input_shape->NumElements();\n\n    OP_REQUIRES(\n        context, rank > 1,\n        errors::InvalidArgument(\n            \"Rank of input SparseTensor should be > 1, but saw rank: \", rank));\n\n    auto input_shape_vec = input_shape->vec<int64_t>();\n    int new_num_elements = 1;\n    bool overflow_ocurred = false;\n    for (int i = 0; i < input_shape_vec.size(); i++) {\n      new_num_elements =\n          MultiplyWithoutOverflow(new_num_elements, input_shape_vec(i));\n      if (new_num_elements < 0) {\n        overflow_ocurred = true;\n        break;\n      }\n    }\n\n    OP_REQUIRES(\n        context, !overflow_ocurred,\n        errors::Internal(\"Encountered overflow from large input shape.\"));\n\n    TensorShape tensor_input_shape(input_shape_vec);\n    gtl::InlinedVector<int64_t, 8> std_order(rank);\n    std::iota(std_order.begin(), std_order.end(), 0);\n    SparseTensor input_st;\n    OP_REQUIRES_OK(context, SparseTensor::Create(*input_indices, *input_values,\n                                                 tensor_input_shape, std_order,\n                                                 &input_st));\n\n    const int64_t N = input_shape_vec(0);\n\n    Tensor sparse_handles(DT_INT64, TensorShape({N}));\n    auto sparse_handles_t = sparse_handles.vec<int64_t>();\n\n    OP_REQUIRES_OK(context, input_st.IndicesValid());\n\n    // We can generate the output shape proto string now, for all\n    // minibatch entries.\n    TensorShape output_shape;\n    OP_REQUIRES_OK(context, TensorShapeUtils::MakeShape(\n                                input_shape_vec.data() + 1,\n                                input_shape->NumElements() - 1, &output_shape));\n\n    // Get groups by minibatch dimension\n    std::unordered_set<int64_t> visited;\n    sparse::GroupIterable minibatch = input_st.group({0});\n    for (const auto& subset : minibatch) {\n      const int64_t b = subset.group()[0];\n      visited.insert(b);\n      OP_REQUIRES(\n          context, b > -1 && b < N,\n          errors::InvalidArgument(\n              \"Received unexpected column 0 value in input SparseTensor: \", b,\n              \" < 0 or >= N (= \", N, \")\"));\n\n      const auto indices = subset.indices();\n      const auto values = subset.values<T>();\n      const int64_t num_entries = values.size();\n\n      Tensor output_indices = Tensor(DT_INT64, {num_entries, rank - 1});\n      Tensor output_values = Tensor(DataTypeToEnum<T>::value, {num_entries});\n\n      auto output_indices_t = output_indices.matrix<int64_t>();\n      auto output_values_t = output_values.vec<T>();\n\n      for (int i = 0; i < num_entries; ++i) {\n        for (int d = 1; d < rank; ++d) {\n          output_indices_t(i, d - 1) = indices(i, d);\n        }\n        output_values_t(i) = values(i);\n      }\n\n      SparseTensor st_i;\n      OP_REQUIRES_OK(context,\n                     SparseTensor::Create(output_indices, output_values,\n                                          output_shape, &st_i));\n      int64_t handle;\n      OP_REQUIRES_OK(context, map->AddSparseTensor(context, st_i, &handle));\n      sparse_handles_t(b) = handle;\n    }\n\n    // Fill in any gaps; we must provide an empty ST for batch entries\n    // the grouper didn't find.\n    if (visited.size() < N) {\n      Tensor empty_indices(DT_INT64, {0, rank - 1});\n      Tensor empty_values(DataTypeToEnum<T>::value, {0});\n      SparseTensor empty_st;\n      OP_REQUIRES_OK(context, SparseTensor::Create(empty_indices, empty_values,\n                                                   output_shape, &empty_st));\n\n      for (int64_t b = 0; b < N; ++b) {\n        // We skipped this batch entry.\n        if (visited.find(b) == visited.end()) {\n          int64_t handle;\n          OP_REQUIRES_OK(context,\n                         map->AddSparseTensor(context, empty_st, &handle));\n          sparse_handles_t(b) = handle;\n        }\n      }\n    }\n\n    context->set_output(0, sparse_handles);\n  }",
        "func_hash": 160387063214720131730960354923232758630,
        "file_name": "sparse_tensors_map_ops.cc",
        "file_hash": 224775123349374780251651202891389866533,
        "cwe": [
            "CWE-190"
        ],
        "cve": "CVE-2022-23568",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The implementation of `AddManySparseToTensorsMap` is vulnerable to an integer overflow which results in a `CHECK`-fail when building new `TensorShape` objects (so, an assert failure based denial of service). We are missing some validation on the shapes of the input tensors as well as directly constructing a large `TensorShape` with user-provided dimensions. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23568",
        "func_name": "Compute",
        "diff": [
            "diff --git a/tensorflow/core/kernels/sparse_tensors_map_ops.cc b/tensorflow/core/kernels/sparse_tensors_map_ops.cc\nindex 5fa690743b05c1..b486a2b4dc3c92 100644\n--- a/tensorflow/core/kernels/sparse_tensors_map_ops.cc\n+++ b/tensorflow/core/kernels/sparse_tensors_map_ops.cc\n@@ -263,22 +263,10 @@ class AddManySparseToTensorsMapOp : public SparseTensorAccessingOp {\n             \"Rank of input SparseTensor should be > 1, but saw rank: \", rank));\n \n     auto input_shape_vec = input_shape->vec<int64_t>();\n-    int new_num_elements = 1;\n-    bool overflow_ocurred = false;\n-    for (int i = 0; i < input_shape_vec.size(); i++) {\n-      new_num_elements =\n-          MultiplyWithoutOverflow(new_num_elements, input_shape_vec(i));\n-      if (new_num_elements < 0) {\n-        overflow_ocurred = true;\n-        break;\n-      }\n-    }\n-\n-    OP_REQUIRES(\n-        context, !overflow_ocurred,\n-        errors::Internal(\"Encountered overflow from large input shape.\"));\n \n-    TensorShape tensor_input_shape(input_shape_vec);\n+    TensorShape tensor_input_shape;\n+    OP_REQUIRES_OK(context, TensorShape::BuildTensorShape(input_shape_vec,\n+                                                          &tensor_input_shape));\n     gtl::InlinedVector<int64_t, 8> std_order(rank);\n     std::iota(std_order.begin(), std_order.end(), 0);\n     SparseTensor input_st;\n"
        ],
        "func_after": []
    },
    {
        "idx": 195026,
        "project": "linux",
        "commit_id": "ab0fc21bc7105b54bafd85bd8b82742f9e68898a",
        "project_url": "https://github.com/torvalds/linux",
        "commit_url": "https://github.com/torvalds/linux/commit/ab0fc21bc7105b54bafd85bd8b82742f9e68898a",
        "commit_message": "Revert \"NFSv4: Handle the special Linux file open access mode\"\n\nThis reverts commit 44942b4e457beda00981f616402a1a791e8c616e.\n\nAfter secondly opening a file with O_ACCMODE|O_DIRECT flags,\nnfs4_valid_open_stateid() will dereference NULL nfs4_state when lseek().\n\nReproducer:\n  1. mount -t nfs -o vers=4.2 $server_ip:/ /mnt/\n  2. fd = open(\"/mnt/file\", O_ACCMODE|O_DIRECT|O_CREAT)\n  3. close(fd)\n  4. fd = open(\"/mnt/file\", O_ACCMODE|O_DIRECT)\n  5. lseek(fd)\n\nReported-by: Lyu Tao <tao.lyu@epfl.ch>\nSigned-off-by: ChenXiaoSong <chenxiaosong2@huawei.com>\nSigned-off-by: Trond Myklebust <trond.myklebust@hammerspace.com>",
        "target": 1,
        "irrelevant": 0,
        "func_before": "nfs4_file_open(struct inode *inode, struct file *filp)\n{\n\tstruct nfs_open_context *ctx;\n\tstruct dentry *dentry = file_dentry(filp);\n\tstruct dentry *parent = NULL;\n\tstruct inode *dir;\n\tunsigned openflags = filp->f_flags;\n\tstruct iattr attr;\n\tint err;\n\n\t/*\n\t * If no cached dentry exists or if it's negative, NFSv4 handled the\n\t * opens in ->lookup() or ->create().\n\t *\n\t * We only get this far for a cached positive dentry.  We skipped\n\t * revalidation, so handle it here by dropping the dentry and returning\n\t * -EOPENSTALE.  The VFS will retry the lookup/create/open.\n\t */\n\n\tdprintk(\"NFS: open file(%pd2)\\n\", dentry);\n\n\terr = nfs_check_flags(openflags);\n\tif (err)\n\t\treturn err;\n\n\tif ((openflags & O_ACCMODE) == 3)\n\t\treturn nfs_open(inode, filp);\n\n\t/* We can't create new files here */\n\topenflags &= ~(O_CREAT|O_EXCL);\n\n\tparent = dget_parent(dentry);\n\tdir = d_inode(parent);\n\n\tctx = alloc_nfs_open_context(file_dentry(filp), filp->f_mode, filp);\n\terr = PTR_ERR(ctx);\n\tif (IS_ERR(ctx))\n\t\tgoto out;\n\n\tattr.ia_valid = ATTR_OPEN;\n\tif (openflags & O_TRUNC) {\n\t\tattr.ia_valid |= ATTR_SIZE;\n\t\tattr.ia_size = 0;\n\t\tfilemap_write_and_wait(inode->i_mapping);\n\t}\n\n\tinode = NFS_PROTO(dir)->open_context(dir, ctx, openflags, &attr, NULL);\n\tif (IS_ERR(inode)) {\n\t\terr = PTR_ERR(inode);\n\t\tswitch (err) {\n\t\tdefault:\n\t\t\tgoto out_put_ctx;\n\t\tcase -ENOENT:\n\t\tcase -ESTALE:\n\t\tcase -EISDIR:\n\t\tcase -ENOTDIR:\n\t\tcase -ELOOP:\n\t\t\tgoto out_drop;\n\t\t}\n\t}\n\tif (inode != d_inode(dentry))\n\t\tgoto out_drop;\n\n\tnfs_file_set_open_context(filp, ctx);\n\tnfs_fscache_open_file(inode, filp);\n\terr = 0;\n\nout_put_ctx:\n\tput_nfs_open_context(ctx);\nout:\n\tdput(parent);\n\treturn err;\n\nout_drop:\n\td_drop(dentry);\n\terr = -EOPENSTALE;\n\tgoto out_put_ctx;\n}",
        "func_hash": 67846125552854891508125900978071958871,
        "file_name": "nfs4file.c",
        "file_hash": 109456154040292488452120321326967957719,
        "cwe": [
            "CWE-909"
        ],
        "cve": "CVE-2022-24448",
        "cve_desc": "An issue was discovered in fs/nfs/dir.c in the Linux kernel before 5.16.5. If an application sets the O_DIRECTORY flag, and tries to open a regular file, nfs_atomic_open() performs a regular lookup. If a regular file is found, ENOTDIR should occur, but the server instead returns uninitialized data in the file descriptor.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-24448",
        "func_name": "nfs4_file_open",
        "diff": [
            "diff --git a/fs/nfs/inode.c b/fs/nfs/inode.c\nindex e51d86707fcace..e72900c059ee58 100644\n--- a/fs/nfs/inode.c\n+++ b/fs/nfs/inode.c\n@@ -1180,7 +1180,6 @@ int nfs_open(struct inode *inode, struct file *filp)\n \tnfs_fscache_open_file(inode, filp);\n \treturn 0;\n }\n-EXPORT_SYMBOL_GPL(nfs_open);\n \n /*\n  * This function is called whenever some part of NFS notices that\ndiff --git a/fs/nfs/nfs4file.c b/fs/nfs/nfs4file.c\nindex d258933cf8c881..f336d0a4190e5c 100644\n--- a/fs/nfs/nfs4file.c\n+++ b/fs/nfs/nfs4file.c\n@@ -51,7 +51,7 @@ nfs4_file_open(struct inode *inode, struct file *filp)\n \t\treturn err;\n \n \tif ((openflags & O_ACCMODE) == 3)\n-\t\treturn nfs_open(inode, filp);\n+\t\topenflags--;\n \n \t/* We can't create new files here */\n \topenflags &= ~(O_CREAT|O_EXCL);\n"
        ],
        "func_after": []
    },
    {
        "idx": 195028,
        "project": "tensorflow",
        "commit_id": "ab51e5b813573dc9f51efa335aebcf2994125ee9",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/ab51e5b813573dc9f51efa335aebcf2994125ee9",
        "commit_message": "Prevent memory leak in decoding PNG images.\n\nPiperOrigin-RevId: 409300653\nChange-Id: I6182124c545989cef80cefd439b659095920763b",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void DecodePngV2(OpKernelContext* context, StringPiece input) {\n    int channel_bits = (data_type_ == DataType::DT_UINT8) ? 8 : 16;\n    png::DecodeContext decode;\n    OP_REQUIRES(\n        context, png::CommonInitDecode(input, channels_, channel_bits, &decode),\n        errors::InvalidArgument(\"Invalid PNG. Failed to initialize decoder.\"));\n\n    // Verify that width and height are not too large:\n    // - verify width and height don't overflow int.\n    // - width can later be multiplied by channels_ and sizeof(uint16), so\n    //   verify single dimension is not too large.\n    // - verify when width and height are multiplied together, there are a few\n    //   bits to spare as well.\n    const int width = static_cast<int>(decode.width);\n    const int height = static_cast<int>(decode.height);\n    const int64_t total_size =\n        static_cast<int64_t>(width) * static_cast<int64_t>(height);\n    if (width != static_cast<int64_t>(decode.width) || width <= 0 ||\n        width >= (1LL << 27) || height != static_cast<int64_t>(decode.height) ||\n        height <= 0 || height >= (1LL << 27) || total_size >= (1LL << 29)) {\n      OP_REQUIRES(context, false,\n                  errors::InvalidArgument(\"PNG size too large for int: \",\n                                          decode.width, \" by \", decode.height));\n    }\n\n    Tensor* output = nullptr;\n    // By the existing API, we support decoding PNG with `DecodeGif` op.\n    // We need to make sure to return 4-D shapes when using `DecodeGif`.\n    if (op_type_ == \"DecodeGif\") {\n      OP_REQUIRES_OK(\n          context,\n          context->allocate_output(\n              0, TensorShape({1, height, width, decode.channels}), &output));\n    } else {\n      OP_REQUIRES_OK(\n          context,\n          context->allocate_output(\n              0, TensorShape({height, width, decode.channels}), &output));\n    }\n\n    if (op_type_ == \"DecodeBmp\") {\n      // TODO(b/171060723): Only DecodeBmp as op_type_ is not acceptable here\n      // because currently `decode_(jpeg|png|gif)` ops can decode any one of\n      // jpeg, png or gif but not bmp. Similarly, `decode_bmp` cannot decode\n      // anything but bmp formats. This behavior needs to be revisited. For more\n      // details, please refer to the bug.\n      OP_REQUIRES(context, false,\n                  errors::InvalidArgument(\n                      \"Trying to decode PNG format using DecodeBmp op. Use \"\n                      \"`decode_png` or `decode_image` instead.\"));\n    } else if (op_type_ == \"DecodeAndCropJpeg\") {\n      OP_REQUIRES(context, false,\n                  errors::InvalidArgument(\n                      \"DecodeAndCropJpeg operation can run on JPEG only, but \"\n                      \"detected PNG.\"));\n    }\n\n    if (data_type_ == DataType::DT_UINT8) {\n      OP_REQUIRES(\n          context,\n          png::CommonFinishDecode(\n              reinterpret_cast<png_bytep>(output->flat<uint8>().data()),\n              decode.channels * width * sizeof(uint8), &decode),\n          errors::InvalidArgument(\"Invalid PNG data, size \", input.size()));\n    } else if (data_type_ == DataType::DT_UINT16) {\n      OP_REQUIRES(\n          context,\n          png::CommonFinishDecode(\n              reinterpret_cast<png_bytep>(output->flat<uint16>().data()),\n              decode.channels * width * sizeof(uint16), &decode),\n          errors::InvalidArgument(\"Invalid PNG data, size \", input.size()));\n    } else if (data_type_ == DataType::DT_FLOAT) {\n      // `png::CommonFinishDecode` does not support `float`. First allocate\n      // uint16 buffer for the image and decode in uint16 (lossless). Wrap the\n      // buffer in `unique_ptr` so that we don't forget to delete the buffer.\n      std::unique_ptr<uint16[]> buffer(\n          new uint16[height * width * decode.channels]);\n      OP_REQUIRES(\n          context,\n          png::CommonFinishDecode(reinterpret_cast<png_bytep>(buffer.get()),\n                                  decode.channels * width * sizeof(uint16),\n                                  &decode),\n          errors::InvalidArgument(\"Invalid PNG data, size \", input.size()));\n\n      // Convert uint16 image data to desired data type.\n      // Use eigen threadpooling to speed up the copy operation.\n      const auto& device = context->eigen_device<Eigen::ThreadPoolDevice>();\n      TTypes<uint16, 3>::UnalignedConstTensor buf(buffer.get(), height, width,\n                                                  decode.channels);\n      float scale = 1. / std::numeric_limits<uint16>::max();\n      // Fill output tensor with desired dtype.\n      output->tensor<float, 3>().device(device) = buf.cast<float>() * scale;\n    }\n  }",
        "func_hash": 67814436772398534036630434647873886403,
        "file_name": "decode_image_op.cc",
        "file_hash": 283519422605879710361255065504339887165,
        "cwe": [
            "CWE-401"
        ],
        "cve": "CVE-2022-23585",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. When decoding PNG images TensorFlow can produce a memory leak if the image is invalid. After calling `png::CommonInitDecode(..., &decode)`, the `decode` value contains allocated buffers which can only be freed by calling `png::CommonFreeDecode(&decode)`. However, several error case in the function implementation invoke the `OP_REQUIRES` macro which immediately terminates the execution of the function, without allowing for the memory free to occur. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23585",
        "func_name": "DecodePngV2",
        "diff": [
            "diff --git a/tensorflow/core/kernels/image/decode_image_op.cc b/tensorflow/core/kernels/image/decode_image_op.cc\nindex eef98dd2d83400..ee0ae957203b37 100644\n--- a/tensorflow/core/kernels/image/decode_image_op.cc\n+++ b/tensorflow/core/kernels/image/decode_image_op.cc\n@@ -18,6 +18,8 @@ limitations under the License.\n #include <cstdint>\n #include <memory>\n \n+#include \"tensorflow/core/lib/gtl/cleanup.h\"\n+\n #define EIGEN_USE_THREADS\n \n #include \"absl/strings/escaping.h\"\n@@ -326,6 +328,16 @@ class DecodeImageV2Op : public OpKernel {\n         context, png::CommonInitDecode(input, channels_, channel_bits, &decode),\n         errors::InvalidArgument(\"Invalid PNG. Failed to initialize decoder.\"));\n \n+    // If we reach this point, then there is data in `decode` which must be\n+    // freed by the time we end execution in this function. We cannot call\n+    // `png::CommonFreeDecode()` before an `OP_REQUIRES` because if\n+    // `OP_REQUIRES` constraint is satisfied then the data would be freed\n+    // prematurely. Instead, let's use a `Cleanup` object.\n+    auto cleanup = gtl::MakeCleanup([&decode]() {\n+      std::cerr << \"Cleanup called...\\n\";\n+      png::CommonFreeDecode(&decode);\n+    });\n+\n     // Verify that width and height are not too large:\n     // - verify width and height don't overflow int.\n     // - width can later be multiplied by channels_ and sizeof(uint16), so\n"
        ],
        "func_after": []
    },
    {
        "idx": 195029,
        "project": "tensorflow",
        "commit_id": "c99d98cd189839dcf51aee94e7437b54b31f8abd",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/c99d98cd189839dcf51aee94e7437b54b31f8abd",
        "commit_message": "Handle invalid inputs instead of crashing.\n\nPiperOrigin-RevId: 409549744\nChange-Id: I7f5935b34b53f7e426a5462fcc027bdbf5dcda24",
        "target": 1,
        "irrelevant": 0,
        "func_before": "void Node::RunForwardTypeInference() {\n  VLOG(4) << \"Forward type inference: \" << props_->node_def.DebugString();\n\n  if (props_->fwd_type_fn == nullptr) {\n    return;\n  }\n\n  std::vector<Node*> input_nodes(props_->input_types.size(), nullptr);\n  std::vector<int> input_idx(props_->input_types.size(), 0);\n  for (const auto& edge : in_edges_) {\n    if (edge->IsControlEdge()) {\n      continue;\n    }\n    DCHECK(edge->dst_input() < input_nodes.size()) << DebugString();\n    int i = edge->dst_input();\n    input_nodes.at(i) = edge->src();\n    input_idx.at(i) = edge->src_output();\n  }\n\n  // Note: technically, we could use a very generic type when some of the inputs\n  // are unknown. But there is an expectation that a node will have complete\n  // inputs soon, so updating intermediate types is largely unnecessary.\n\n  for (const auto* node : input_nodes) {\n    if (node == nullptr) {\n      // Incomplete inputs, bail.\n      ClearTypeInfo();\n      return;\n    }\n  }\n\n  static FullTypeDef* no_type = new FullTypeDef();\n\n  std::vector<std::reference_wrapper<const FullTypeDef>> input_types;\n  for (int i = 0; i < input_nodes.size(); i++) {\n    const auto* node = input_nodes[i];\n    if (node->def().has_experimental_type()) {\n      const auto& node_t = node->def().experimental_type();\n      if (node_t.type_id() != TFT_UNSET) {\n        int ix = input_idx[i];\n        DCHECK(ix < node_t.args_size())\n            << \"input \" << i << \" should have an output \" << ix\n            << \" but instead only has \" << node_t.args_size()\n            << \" outputs: \" << node_t.DebugString();\n        input_types.emplace_back(node_t.args(ix));\n      } else {\n        input_types.emplace_back(*no_type);\n      }\n    } else {\n      // Incomplete inputs, bail.\n      ClearTypeInfo();\n      return;\n    }\n  }\n\n  const auto infer_type = props_->fwd_type_fn(input_types);\n  const FullTypeDef infer_typedef = infer_type.ValueOrDie();\n  if (infer_typedef.type_id() != TFT_UNSET) {\n    MaybeCopyOnWrite();\n    *(props_->node_def.mutable_experimental_type()) = infer_typedef;\n  }\n}",
        "func_hash": 285691869172413131662679092330979772991,
        "file_name": "graph.cc",
        "file_hash": 172099243927919341591512227523808328051,
        "cwe": [
            "CWE-125"
        ],
        "cve": "CVE-2022-23592",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. TensorFlow's type inference can cause a heap out of bounds read as the bounds checking is done in a `DCHECK` (which is a no-op during production). An attacker can control the `input_idx` variable such that `ix` would be larger than the number of values in `node_t.args`. The fix will be included in TensorFlow 2.8.0. This is the only affected version.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23592",
        "func_name": "Node::RunForwardTypeInference",
        "diff": [
            "diff --git a/tensorflow/core/graph/graph.cc b/tensorflow/core/graph/graph.cc\nindex 2e3703b66030f4..4af258a203813d 100644\n--- a/tensorflow/core/graph/graph.cc\n+++ b/tensorflow/core/graph/graph.cc\n@@ -222,10 +222,16 @@ void Node::RunForwardTypeInference() {\n       const auto& node_t = node->def().experimental_type();\n       if (node_t.type_id() != TFT_UNSET) {\n         int ix = input_idx[i];\n-        DCHECK(ix < node_t.args_size())\n-            << \"input \" << i << \" should have an output \" << ix\n-            << \" but instead only has \" << node_t.args_size()\n-            << \" outputs: \" << node_t.DebugString();\n+        if (ix >= node_t.args_size()) {\n+          LOG(WARNING) << name() << \" has bad type information: input \" << i\n+                       << \" should have an output \" << ix\n+                       << \" but instead only has \" << node_t.args_size()\n+                       << \" outputs: \" << node_t.DebugString()\n+                       << \"\\nThis indicates either \"\n+                          \"a bug in op registration or a corrupted graph.\";\n+          ClearTypeInfo();\n+          return;\n+        }\n         input_types.emplace_back(node_t.args(ix));\n       } else {\n         input_types.emplace_back(*no_type);\n"
        ],
        "func_after": []
    },
    {
        "idx": 195037,
        "project": "tensorflow",
        "commit_id": "b51b82fe65ebace4475e3c54eb089c18a4403f1c",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/b51b82fe65ebace4475e3c54eb089c18a4403f1c",
        "commit_message": "Add missing validation to `AddManySparseToTensorsMap`.\n\nSparse tensors have a set of requirements for the 3 components and not all of them were checked.\n\nPiperOrigin-RevId: 415358027\nChange-Id: I96cbb672999cd1da772c22fabbd15507e32e12dc",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext* context) override {\n    const Tensor* input_indices;\n    const Tensor* input_values;\n    const Tensor* input_shape;\n    SparseTensorsMap* map;\n\n    OP_REQUIRES_OK(context, context->input(\"sparse_indices\", &input_indices));\n    OP_REQUIRES_OK(context, context->input(\"sparse_values\", &input_values));\n    OP_REQUIRES_OK(context, context->input(\"sparse_shape\", &input_shape));\n    OP_REQUIRES_OK(context, GetMap(context, true /* is_writing */, &map));\n\n    OP_REQUIRES(context, TensorShapeUtils::IsMatrix(input_indices->shape()),\n                errors::InvalidArgument(\n                    \"Input indices should be a matrix but received shape \",\n                    input_indices->shape().DebugString()));\n\n    OP_REQUIRES(context, TensorShapeUtils::IsVector(input_values->shape()),\n                errors::InvalidArgument(\n                    \"Input values should be a vector but received shape \",\n                    input_values->shape().DebugString()));\n\n    OP_REQUIRES(context, TensorShapeUtils::IsVector(input_shape->shape()),\n                errors::InvalidArgument(\n                    \"Input shape should be a vector but received shape \",\n                    input_shape->shape().DebugString()));\n\n    int rank = input_shape->NumElements();\n\n    OP_REQUIRES(\n        context, rank > 1,\n        errors::InvalidArgument(\n            \"Rank of input SparseTensor should be > 1, but saw rank: \", rank));\n\n    auto input_shape_vec = input_shape->vec<int64_t>();\n    int new_num_elements = 1;\n    bool overflow_ocurred = false;\n    for (int i = 0; i < input_shape_vec.size(); i++) {\n      new_num_elements =\n          MultiplyWithoutOverflow(new_num_elements, input_shape_vec(i));\n      if (new_num_elements < 0) {\n        overflow_ocurred = true;\n        break;\n      }\n    }\n\n    OP_REQUIRES(\n        context, !overflow_ocurred,\n        errors::Internal(\"Encountered overflow from large input shape.\"));\n\n    TensorShape tensor_input_shape(input_shape_vec);\n    gtl::InlinedVector<int64_t, 8> std_order(rank);\n    std::iota(std_order.begin(), std_order.end(), 0);\n    SparseTensor input_st;\n    OP_REQUIRES_OK(context, SparseTensor::Create(*input_indices, *input_values,\n                                                 tensor_input_shape, std_order,\n                                                 &input_st));\n\n    const int64_t N = input_shape_vec(0);\n\n    Tensor sparse_handles(DT_INT64, TensorShape({N}));\n    auto sparse_handles_t = sparse_handles.vec<int64_t>();\n\n    OP_REQUIRES_OK(context, input_st.IndicesValid());\n\n    // We can generate the output shape proto string now, for all\n    // minibatch entries.\n    TensorShape output_shape;\n    OP_REQUIRES_OK(context, TensorShapeUtils::MakeShape(\n                                input_shape_vec.data() + 1,\n                                input_shape->NumElements() - 1, &output_shape));\n\n    // Get groups by minibatch dimension\n    std::unordered_set<int64_t> visited;\n    sparse::GroupIterable minibatch = input_st.group({0});\n    for (const auto& subset : minibatch) {\n      const int64_t b = subset.group()[0];\n      visited.insert(b);\n      OP_REQUIRES(\n          context, b > -1 && b < N,\n          errors::InvalidArgument(\n              \"Received unexpected column 0 value in input SparseTensor: \", b,\n              \" < 0 or >= N (= \", N, \")\"));\n\n      const auto indices = subset.indices();\n      const auto values = subset.values<T>();\n      const int64_t num_entries = values.size();\n\n      Tensor output_indices = Tensor(DT_INT64, {num_entries, rank - 1});\n      Tensor output_values = Tensor(DataTypeToEnum<T>::value, {num_entries});\n\n      auto output_indices_t = output_indices.matrix<int64_t>();\n      auto output_values_t = output_values.vec<T>();\n\n      for (int i = 0; i < num_entries; ++i) {\n        for (int d = 1; d < rank; ++d) {\n          output_indices_t(i, d - 1) = indices(i, d);\n        }\n        output_values_t(i) = values(i);\n      }\n\n      SparseTensor st_i;\n      OP_REQUIRES_OK(context,\n                     SparseTensor::Create(output_indices, output_values,\n                                          output_shape, &st_i));\n      int64_t handle;\n      OP_REQUIRES_OK(context, map->AddSparseTensor(context, st_i, &handle));\n      sparse_handles_t(b) = handle;\n    }\n\n    // Fill in any gaps; we must provide an empty ST for batch entries\n    // the grouper didn't find.\n    if (visited.size() < N) {\n      Tensor empty_indices(DT_INT64, {0, rank - 1});\n      Tensor empty_values(DataTypeToEnum<T>::value, {0});\n      SparseTensor empty_st;\n      OP_REQUIRES_OK(context, SparseTensor::Create(empty_indices, empty_values,\n                                                   output_shape, &empty_st));\n\n      for (int64_t b = 0; b < N; ++b) {\n        // We skipped this batch entry.\n        if (visited.find(b) == visited.end()) {\n          int64_t handle;\n          OP_REQUIRES_OK(context,\n                         map->AddSparseTensor(context, empty_st, &handle));\n          sparse_handles_t(b) = handle;\n        }\n      }\n    }\n\n    context->set_output(0, sparse_handles);\n  }",
        "func_hash": 171961580694281680039206916179435077047,
        "file_name": "sparse_tensors_map_ops.cc",
        "file_hash": 190320072369250411027996685136568189736,
        "cwe": [
            "CWE-190"
        ],
        "cve": "CVE-2022-23568",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The implementation of `AddManySparseToTensorsMap` is vulnerable to an integer overflow which results in a `CHECK`-fail when building new `TensorShape` objects (so, an assert failure based denial of service). We are missing some validation on the shapes of the input tensors as well as directly constructing a large `TensorShape` with user-provided dimensions. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23568",
        "func_name": "Compute",
        "diff": [
            "diff --git a/tensorflow/core/kernels/sparse_tensors_map_ops.cc b/tensorflow/core/kernels/sparse_tensors_map_ops.cc\nindex 04efed5fd90c75..5fa690743b05c1 100644\n--- a/tensorflow/core/kernels/sparse_tensors_map_ops.cc\n+++ b/tensorflow/core/kernels/sparse_tensors_map_ops.cc\n@@ -231,16 +231,29 @@ class AddManySparseToTensorsMapOp : public SparseTensorAccessingOp {\n                 errors::InvalidArgument(\n                     \"Input indices should be a matrix but received shape \",\n                     input_indices->shape().DebugString()));\n-\n     OP_REQUIRES(context, TensorShapeUtils::IsVector(input_values->shape()),\n                 errors::InvalidArgument(\n                     \"Input values should be a vector but received shape \",\n                     input_values->shape().DebugString()));\n-\n     OP_REQUIRES(context, TensorShapeUtils::IsVector(input_shape->shape()),\n                 errors::InvalidArgument(\n                     \"Input shape should be a vector but received shape \",\n                     input_shape->shape().DebugString()));\n+    OP_REQUIRES(\n+        context,\n+        input_values->shape().dim_size(0) == input_indices->shape().dim_size(0),\n+        errors::InvalidArgument(\n+            \"Number of values must match first dimension of indices. \", \"Got \",\n+            input_values->shape().dim_size(0),\n+            \" values, indices shape: \", input_indices->shape().DebugString()));\n+    OP_REQUIRES(\n+        context,\n+        input_shape->shape().dim_size(0) == input_indices->shape().dim_size(1),\n+        errors::InvalidArgument(\n+            \"Number of dimensions must match second dimension of indices. \",\n+            \"Got \", input_shape->shape().dim_size(0),\n+            \" dimensions, indices shape: \",\n+            input_indices->shape().DebugString()));\n \n     int rank = input_shape->NumElements();\n \n"
        ],
        "func_after": []
    },
    {
        "idx": 195038,
        "project": "mruby",
        "commit_id": "27d1e0132a0804581dca28df042e7047fd27eaa8",
        "project_url": "https://github.com/mruby/mruby",
        "commit_url": "https://github.com/mruby/mruby/commit/27d1e0132a0804581dca28df042e7047fd27eaa8",
        "commit_message": "array.c: fix `mrb_ary_shift_m` initialization bug.\n\nThe `ARY_PTR` and `ARY_LEN` may be modified in `mrb_get_args`.",
        "target": 1,
        "irrelevant": 1,
        "func_before": "mrb_ary_shift_m(mrb_state *mrb, mrb_value self)\n{\n  struct RArray *a = mrb_ary_ptr(self);\n  mrb_int len = ARY_LEN(a);\n  mrb_int n;\n  mrb_value val;\n\n  if (mrb_get_args(mrb, \"|i\", &n) == 0) {\n    return mrb_ary_shift(mrb, self);\n  };\n  ary_modify_check(mrb, a);\n  if (len == 0 || n == 0) return mrb_ary_new(mrb);\n  if (n < 0) mrb_raise(mrb, E_ARGUMENT_ERROR, \"negative array shift\");\n  if (n > len) n = len;\n  val = mrb_ary_new_from_values(mrb, n, ARY_PTR(a));\n  if (ARY_SHARED_P(a)) {\n  L_SHIFT:\n    a->as.heap.ptr+=n;\n    a->as.heap.len-=n;\n    return val;\n  }\n  if (len > ARY_SHIFT_SHARED_MIN) {\n    ary_make_shared(mrb, a);\n    goto L_SHIFT;\n  }\n  else if (len == n) {\n    ARY_SET_LEN(a, 0);\n  }\n  else {\n    mrb_value *ptr = ARY_PTR(a);\n    mrb_int size = len-n;\n\n    while (size--) {\n      *ptr = *(ptr+n);\n      ++ptr;\n    }\n    ARY_SET_LEN(a, len-n);\n  }\n  return val;\n}",
        "func_hash": 88987793594626442814152795226896894437,
        "file_name": "array.c",
        "file_hash": 131985777969528154957566525214352537878,
        "cwe": [
            "CWE-476"
        ],
        "cve": "CVE-2021-4188",
        "cve_desc": "mruby is vulnerable to NULL Pointer Dereference",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-4188",
        "func_name": "mrb_ary_shift_m",
        "diff": [
            "diff --git a/src/array.c b/src/array.c\nindex c100591ebe..1a95b75c93 100644\n--- a/src/array.c\n+++ b/src/array.c\n@@ -581,14 +581,16 @@ mrb_ary_shift(mrb_state *mrb, mrb_value self)\n static mrb_value\n mrb_ary_shift_m(mrb_state *mrb, mrb_value self)\n {\n-  struct RArray *a = mrb_ary_ptr(self);\n-  mrb_int len = ARY_LEN(a);\n   mrb_int n;\n-  mrb_value val;\n \n   if (mrb_get_args(mrb, \"|i\", &n) == 0) {\n     return mrb_ary_shift(mrb, self);\n-  };\n+  }\n+\n+  struct RArray *a = mrb_ary_ptr(self);\n+  mrb_int len = ARY_LEN(a);\n+  mrb_value val;\n+\n   ary_modify_check(mrb, a);\n   if (len == 0 || n == 0) return mrb_ary_new(mrb);\n   if (n < 0) mrb_raise(mrb, E_ARGUMENT_ERROR, \"negative array shift\");\n"
        ],
        "func_after": []
    },
    {
        "idx": 195039,
        "project": "tensorflow",
        "commit_id": "e7f497570abb6b4ae5af4970620cd880e4c0c904",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/e7f497570abb6b4ae5af4970620cd880e4c0c904",
        "commit_message": "Fix segfault on OOM in Conv2D.\n\nPiperOrigin-RevId: 404655317\nChange-Id: I33588dbd3f5d0fef980e3c908bf5515a9ee09ce7",
        "target": 1,
        "irrelevant": 1,
        "func_before": "  void operator()(OpKernelContext* ctx, const Tensor& input,\n                  const Tensor& filter, int row_stride, int col_stride,\n                  int row_dilation, int col_dilation, const Padding& padding,\n                  const std::vector<int64_t>& explicit_paddings, Tensor* output,\n                  TensorFormat data_format) {\n    DCHECK(data_format == FORMAT_NHWC)\n        << \"Grouped conv implementation only \"\n           \"supports NHWC tensor format for now.\";\n\n    const int64_t in_depth = input.dim_size(3);\n    const int64_t patch_depth = filter.dim_size(2);\n    const int64_t num_groups = in_depth / patch_depth;\n\n    // Shuffle input/filter tensors to have group as a leading dimension.\n    std::array<int64_t, 5> shuffle({3, 0, 1, 2, 4});\n\n    // Compute pre shuffle dimemnsions.\n    auto pre_shuffle = [&](const Tensor& tensor) -> std::array<int64, 5> {\n      return {tensor.dim_size(0), tensor.dim_size(1), tensor.dim_size(2),\n              num_groups, tensor.dim_size(3) / num_groups};\n    };\n\n    // Compute post shuffle dimemnsions.\n    auto post_shuffle = [&](const Tensor& tensor) -> std::array<int64, 5> {\n      return {num_groups, tensor.dim_size(0), tensor.dim_size(1),\n              tensor.dim_size(2), tensor.dim_size(3) / num_groups};\n    };\n\n    auto& device = ctx->eigen_device<CPUDevice>();\n\n    absl::BlockingCounter shuffles_completed(2);\n    auto on_shuffled = [&]() { shuffles_completed.DecrementCount(); };\n\n    // Shuffle input into temporary tensor.\n    Tensor input_shuffled(input.dtype(), TensorShape(post_shuffle(input)));\n    input_shuffled.tensor<T, 5>().device(device, on_shuffled) =\n        input.shaped<T, 5>(pre_shuffle(input)).shuffle(shuffle);\n\n    // Shuffle filter into temporary tensor.\n    Tensor filter_shuffled(filter.dtype(), TensorShape(post_shuffle(filter)));\n    filter_shuffled.tensor<T, 5>().device(device, on_shuffled) =\n        filter.shaped<T, 5>(pre_shuffle(filter)).shuffle(shuffle);\n\n    // Wait for the completion of input/filter shuffles.\n    shuffles_completed.Wait();\n\n    // Write group convolution results into temporary output tensor.\n    Tensor output_shuffled(output->dtype(), TensorShape(post_shuffle(*output)));\n\n    for (int64_t i = 0; i < num_groups; ++i) {\n      // TODO(ezhulenev): Run this loop using `parallelFor` (regular parallelFor\n      // will lead to deadlock, SpatialConvolution has to use async Eigen\n      // assignment). This requires small changes to Eigen to support async\n      // exeuction for tensor chipping operation.\n\n      // TODO(ezhulenev): Grouped convolution should also support 1x1 filter\n      // optimization.\n\n      auto input_slice = input_shuffled.tensor<T, 5>().template chip<0>(i);\n      auto filter_slice = filter_shuffled.tensor<T, 5>().template chip<0>(i);\n      auto output_slice = output_shuffled.tensor<T, 5>().template chip<0>(i);\n\n      if (padding == EXPLICIT) {\n        functor::SpatialConvolution<CPUDevice, T>()(\n            ctx->eigen_device<CPUDevice>(), output_slice, input_slice,\n            filter_slice, row_stride, col_stride, row_dilation, col_dilation,\n            static_cast<int>(explicit_paddings[2]),\n            static_cast<int>(explicit_paddings[3]),\n            static_cast<int>(explicit_paddings[4]),\n            static_cast<int>(explicit_paddings[5]));\n      } else {\n        functor::SpatialConvolution<CPUDevice, T>()(\n            ctx->eigen_device<CPUDevice>(), output_slice, input_slice,\n            filter_slice, row_stride, col_stride, row_dilation, col_dilation,\n            BrainPadding2EigenPadding(padding));\n      }\n    }\n\n    // Shuffle temporary output back into pre-shuffled shape.\n    std::array<int64_t, 5> rev_shuffle({1, 2, 3, 0, 4});\n    output->shaped<T, 5>(pre_shuffle(*output)).device(device) =\n        output_shuffled.tensor<T, 5>().shuffle(rev_shuffle);\n  }",
        "func_hash": 257618220779157714024325768166416151732,
        "file_name": "conv_ops.cc",
        "file_hash": 252300068611383622428481854806618645318,
        "cwe": [
            "CWE-354"
        ],
        "cve": "CVE-2021-41206",
        "cve_desc": "TensorFlow is an open source platform for machine learning. In affected versions several TensorFlow operations are missing validation for the shapes of the tensor arguments involved in the call. Depending on the API, this can result in undefined behavior and segfault or `CHECK`-fail related crashes but in some scenarios writes and reads from heap populated arrays are also possible. We have discovered these issues internally via tooling while working on improving/testing GPU op determinism. As such, we don't have reproducers and there will be multiple fixes for these issues. These fixes will be included in TensorFlow 2.7.0. We will also cherrypick these commits on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-41206",
        "func_name": "operator",
        "diff": [
            "diff --git a/tensorflow/core/kernels/conv_ops.cc b/tensorflow/core/kernels/conv_ops.cc\nindex 94926358675fb2..67418151a1cf2d 100644\n--- a/tensorflow/core/kernels/conv_ops.cc\n+++ b/tensorflow/core/kernels/conv_ops.cc\n@@ -183,12 +183,18 @@ struct LaunchGrouped {\n     auto on_shuffled = [&]() { shuffles_completed.DecrementCount(); };\n \n     // Shuffle input into temporary tensor.\n-    Tensor input_shuffled(input.dtype(), TensorShape(post_shuffle(input)));\n+    Tensor input_shuffled;\n+    OP_REQUIRES_OK(\n+        ctx, ctx->allocate_temp(input.dtype(), TensorShape(post_shuffle(input)),\n+                                &input_shuffled));\n     input_shuffled.tensor<T, 5>().device(device, on_shuffled) =\n         input.shaped<T, 5>(pre_shuffle(input)).shuffle(shuffle);\n \n     // Shuffle filter into temporary tensor.\n-    Tensor filter_shuffled(filter.dtype(), TensorShape(post_shuffle(filter)));\n+    Tensor filter_shuffled;\n+    OP_REQUIRES_OK(ctx, ctx->allocate_temp(filter.dtype(),\n+                                           TensorShape(post_shuffle(filter)),\n+                                           &filter_shuffled));\n     filter_shuffled.tensor<T, 5>().device(device, on_shuffled) =\n         filter.shaped<T, 5>(pre_shuffle(filter)).shuffle(shuffle);\n \n@@ -196,7 +202,10 @@ struct LaunchGrouped {\n     shuffles_completed.Wait();\n \n     // Write group convolution results into temporary output tensor.\n-    Tensor output_shuffled(output->dtype(), TensorShape(post_shuffle(*output)));\n+    Tensor output_shuffled;\n+    OP_REQUIRES_OK(ctx, ctx->allocate_temp(output->dtype(),\n+                                           TensorShape(post_shuffle(*output)),\n+                                           &output_shuffled));\n \n     for (int64_t i = 0; i < num_groups; ++i) {\n       // TODO(ezhulenev): Run this loop using `parallelFor` (regular parallelFor\n"
        ],
        "func_after": []
    },
    {
        "idx": 195040,
        "project": "tensorflow",
        "commit_id": "e21af685e1828f7ca65038307df5cc06de4479e8",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/e21af685e1828f7ca65038307df5cc06de4479e8",
        "commit_message": "Fix Null-pointer dereference in BuildXlaCompilationCache\n\nIf ConfigProto is not used, then use the default settings which is to allow all devices.\n\nPiperOrigin-RevId: 420391800\nChange-Id: I88161ad7042990aef678e77b597a2fb2c8f815be",
        "target": 1,
        "irrelevant": 1,
        "func_before": "Status BuildXlaCompilationCache(DeviceBase* device, FunctionLibraryRuntime* flr,\n                                const XlaPlatformInfo& platform_info,\n                                XlaCompilationCache** cache) {\n  if (platform_info.xla_device_metadata()) {\n    *cache = new XlaCompilationCache(\n        platform_info.xla_device_metadata()->client(),\n        platform_info.xla_device_metadata()->jit_device_type());\n    return Status::OK();\n  }\n\n  auto platform =\n      se::MultiPlatformManager::PlatformWithId(platform_info.platform_id());\n  if (!platform.ok()) {\n    return platform.status();\n  }\n\n  StatusOr<xla::Compiler*> compiler_for_platform =\n      xla::Compiler::GetForPlatform(platform.ValueOrDie());\n  if (!compiler_for_platform.ok()) {\n    // In some rare cases (usually in unit tests with very small clusters) we\n    // may end up transforming an XLA cluster with at least one GPU operation\n    // (which would normally force the cluster to be compiled using XLA:GPU)\n    // into an XLA cluster with no GPU operations (i.e. containing only CPU\n    // operations).  Such a cluster can fail compilation (in way that\n    // MarkForCompilation could not have detected) if the CPU JIT is not linked\n    // in.\n    //\n    // So bail out of _XlaCompile in this case, and let the executor handle the\n    // situation for us.\n    const Status& status = compiler_for_platform.status();\n    if (status.code() == error::NOT_FOUND) {\n      return errors::Unimplemented(\"Could not find compiler for platform \",\n                                   platform.ValueOrDie()->Name(), \": \",\n                                   status.ToString());\n    }\n  }\n\n  xla::LocalClientOptions client_options;\n  client_options.set_platform(platform.ValueOrDie());\n  client_options.set_intra_op_parallelism_threads(\n      device->tensorflow_cpu_worker_threads()->num_threads);\n\n  string allowed_gpus =\n      flr->config_proto()->gpu_options().visible_device_list();\n  TF_ASSIGN_OR_RETURN(absl::optional<std::set<int>> gpu_ids,\n                      ParseVisibleDeviceList(allowed_gpus));\n  client_options.set_allowed_devices(gpu_ids);\n\n  auto client = xla::ClientLibrary::GetOrCreateLocalClient(client_options);\n  if (!client.ok()) {\n    return client.status();\n  }\n  const XlaOpRegistry::DeviceRegistration* registration;\n  if (!XlaOpRegistry::GetCompilationDevice(platform_info.device_type().type(),\n                                           &registration)) {\n    return errors::InvalidArgument(\"No JIT device registered for \",\n                                   platform_info.device_type().type());\n  }\n  *cache = new XlaCompilationCache(\n      client.ValueOrDie(), DeviceType(registration->compilation_device_name));\n  return Status::OK();\n}",
        "func_hash": 179065639871904945359341382009364285020,
        "file_name": "xla_platform_info.cc",
        "file_hash": 171804916137745205288117058026592469555,
        "cwe": [
            "CWE-476"
        ],
        "cve": "CVE-2022-23595",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. When building an XLA compilation cache, if default settings are used, TensorFlow triggers a null pointer dereference. In the default scenario, all devices are allowed, so `flr->config_proto` is `nullptr`. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23595",
        "func_name": "BuildXlaCompilationCache",
        "diff": [
            "diff --git a/tensorflow/compiler/jit/xla_platform_info.cc b/tensorflow/compiler/jit/xla_platform_info.cc\nindex 8b20c9169c3e90..96d6e27d36a7ee 100644\n--- a/tensorflow/compiler/jit/xla_platform_info.cc\n+++ b/tensorflow/compiler/jit/xla_platform_info.cc\n@@ -82,11 +82,13 @@ Status BuildXlaCompilationCache(DeviceBase* device, FunctionLibraryRuntime* flr,\n   client_options.set_intra_op_parallelism_threads(\n       device->tensorflow_cpu_worker_threads()->num_threads);\n \n-  string allowed_gpus =\n-      flr->config_proto()->gpu_options().visible_device_list();\n-  TF_ASSIGN_OR_RETURN(absl::optional<std::set<int>> gpu_ids,\n-                      ParseVisibleDeviceList(allowed_gpus));\n-  client_options.set_allowed_devices(gpu_ids);\n+  if (flr->config_proto()) {\n+    string allowed_gpus =\n+        flr->config_proto()->gpu_options().visible_device_list();\n+    TF_ASSIGN_OR_RETURN(absl::optional<std::set<int>> gpu_ids,\n+                        ParseVisibleDeviceList(allowed_gpus));\n+    client_options.set_allowed_devices(gpu_ids);\n+  }\n \n   auto client = xla::ClientLibrary::GetOrCreateLocalClient(client_options);\n   if (!client.ok()) {\n"
        ],
        "func_after": []
    },
    {
        "idx": 195055,
        "project": "tensorflow",
        "commit_id": "2b7100d6cdff36aa21010a82269bc05a6d1cc74a",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/2b7100d6cdff36aa21010a82269bc05a6d1cc74a",
        "commit_message": "Cleanup and remove duplicate validation in `SparseCount`.\n\nWe have valdiation that is duplicated, checking different conditions, in different formats and failing to capture all cases. This should fix all the previous bugs.\n\nPiperOrigin-RevId: 414886981\nChange-Id: Ibf0bba0beb057b76d505324bb9487565daf95f01",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext* context) override {\n    const Tensor& indices = context->input(0);\n    const Tensor& values = context->input(1);\n    const Tensor& shape = context->input(2);\n    const Tensor& weights = context->input(3);\n    bool use_weights = weights.NumElements() > 0;\n\n    OP_REQUIRES(context, TensorShapeUtils::IsMatrix(indices.shape()),\n                errors::InvalidArgument(\n                    \"Input indices must be a 2-dimensional tensor. Got: \",\n                    indices.shape().DebugString()));\n\n    if (use_weights) {\n      OP_REQUIRES(\n          context, weights.shape() == values.shape(),\n          errors::InvalidArgument(\n              \"Weights and values must have the same shape. Weight shape: \",\n              weights.shape().DebugString(),\n              \"; values shape: \", values.shape().DebugString()));\n    }\n\n    OP_REQUIRES(context, shape.NumElements() != 0,\n                errors::InvalidArgument(\n                    \"The shape argument requires at least one element.\"));\n\n    bool is_1d = shape.NumElements() == 1;\n    auto shape_vector = shape.flat<int64_t>();\n    int num_batches = is_1d ? 1 : shape_vector(0);\n    int num_values = values.NumElements();\n\n    for (int b = 0; b < shape_vector.size(); b++) {\n      OP_REQUIRES(context, shape_vector(b) >= 0,\n                  errors::InvalidArgument(\n                      \"Elements in dense_shape must be >= 0. Instead got:\",\n                      shape.DebugString()));\n    }\n\n    OP_REQUIRES(context, num_values == indices.shape().dim_size(0),\n                errors::InvalidArgument(\n                    \"Number of values must match first dimension of indices.\",\n                    \"Got \", num_values,\n                    \" values, indices shape: \", indices.shape().DebugString()));\n\n    const auto indices_values = indices.matrix<int64_t>();\n    const auto values_values = values.flat<T>();\n    const auto weight_values = weights.flat<W>();\n\n    auto per_batch_counts = BatchedMap<W>(num_batches);\n\n    T max_value = 0;\n\n    OP_REQUIRES(context, num_values <= indices.shape().dim_size(0),\n                errors::InvalidArgument(\n                    \"The first dimension of indices must be equal to or \"\n                    \"greather than number of values. ( \",\n                    indices.shape().dim_size(0), \" vs. \", num_values, \" )\"));\n    OP_REQUIRES(context, indices.shape().dim_size(1) > 0,\n                errors::InvalidArgument(\"The second dimension of indices must \"\n                                        \"be greater than 0. Received: \",\n                                        indices.shape().dim_size(1)));\n\n    for (int idx = 0; idx < num_values; ++idx) {\n      int batch = is_1d ? 0 : indices_values(idx, 0);\n      if (batch >= num_batches) {\n        OP_REQUIRES(context, batch < num_batches,\n                    errors::InvalidArgument(\n                        \"Indices value along the first dimension must be \",\n                        \"lower than the first index of the shape.\", \"Got \",\n                        batch, \" as batch and \", num_batches,\n                        \" as the first dimension of the shape.\"));\n      }\n      const auto& value = values_values(idx);\n      if (value >= 0 && (maxlength_ <= 0 || value < maxlength_)) {\n        if (binary_output_) {\n          per_batch_counts[batch][value] = 1;\n        } else if (use_weights) {\n          per_batch_counts[batch][value] += weight_values(idx);\n        } else {\n          per_batch_counts[batch][value]++;\n        }\n        if (value > max_value) {\n          max_value = value;\n        }\n      }\n    }\n\n    int num_output_values = GetOutputSize(max_value, maxlength_, minlength_);\n    OP_REQUIRES_OK(context, OutputSparse<W>(per_batch_counts, num_output_values,\n                                            is_1d, context));\n  }",
        "func_hash": 115744370413617881150207979427400512016,
        "file_name": "count_ops.cc",
        "file_hash": 290832582717285970119064032382621433475,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2022-21740",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The implementation of `SparseCountSparseOutput` is vulnerable to a heap overflow. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-21740",
        "func_name": "Compute",
        "diff": [
            "diff --git a/tensorflow/core/kernels/count_ops.cc b/tensorflow/core/kernels/count_ops.cc\nindex 5330c36361e5e6..1f99e0783e26f6 100644\n--- a/tensorflow/core/kernels/count_ops.cc\n+++ b/tensorflow/core/kernels/count_ops.cc\n@@ -185,6 +185,27 @@ class SparseCount : public OpKernel {\n                 errors::InvalidArgument(\n                     \"Input indices must be a 2-dimensional tensor. Got: \",\n                     indices.shape().DebugString()));\n+    OP_REQUIRES(context, TensorShapeUtils::IsVector(values.shape()),\n+                errors::InvalidArgument(\"Input values must be a vector. Got: \",\n+                                        values.shape().DebugString()));\n+    OP_REQUIRES(context, TensorShapeUtils::IsVector(shape.shape()),\n+                errors::InvalidArgument(\"Input shape must be a vector. Got: \",\n+                                        shape.shape().DebugString()));\n+    OP_REQUIRES(context,\n+                values.shape().dim_size(0) == indices.shape().dim_size(0),\n+                errors::InvalidArgument(\n+                    \"Number of values must match first dimension of indices.\",\n+                    \"Got \", values.shape().dim_size(0),\n+                    \" values, indices shape: \", indices.shape().DebugString()));\n+    OP_REQUIRES(\n+        context, shape.shape().dim_size(0) == indices.shape().dim_size(1),\n+        errors::InvalidArgument(\n+            \"Number of dimensions must match second dimension of indices.\",\n+            \"Got \", shape.shape().dim_size(0),\n+            \" dimensions, indices shape: \", indices.shape().DebugString()));\n+    OP_REQUIRES(context, shape.NumElements() > 0,\n+                errors::InvalidArgument(\n+                    \"The shape argument requires at least one element.\"));\n \n     if (use_weights) {\n       OP_REQUIRES(\n@@ -195,28 +216,11 @@ class SparseCount : public OpKernel {\n               \"; values shape: \", values.shape().DebugString()));\n     }\n \n-    OP_REQUIRES(context, shape.NumElements() != 0,\n-                errors::InvalidArgument(\n-                    \"The shape argument requires at least one element.\"));\n-\n     bool is_1d = shape.NumElements() == 1;\n     auto shape_vector = shape.flat<int64_t>();\n     int num_batches = is_1d ? 1 : shape_vector(0);\n     int num_values = values.NumElements();\n \n-    for (int b = 0; b < shape_vector.size(); b++) {\n-      OP_REQUIRES(context, shape_vector(b) >= 0,\n-                  errors::InvalidArgument(\n-                      \"Elements in dense_shape must be >= 0. Instead got:\",\n-                      shape.DebugString()));\n-    }\n-\n-    OP_REQUIRES(context, num_values == indices.shape().dim_size(0),\n-                errors::InvalidArgument(\n-                    \"Number of values must match first dimension of indices.\",\n-                    \"Got \", num_values,\n-                    \" values, indices shape: \", indices.shape().DebugString()));\n-\n     const auto indices_values = indices.matrix<int64_t>();\n     const auto values_values = values.flat<T>();\n     const auto weight_values = weights.flat<W>();\n@@ -225,16 +229,6 @@ class SparseCount : public OpKernel {\n \n     T max_value = 0;\n \n-    OP_REQUIRES(context, num_values <= indices.shape().dim_size(0),\n-                errors::InvalidArgument(\n-                    \"The first dimension of indices must be equal to or \"\n-                    \"greather than number of values. ( \",\n-                    indices.shape().dim_size(0), \" vs. \", num_values, \" )\"));\n-    OP_REQUIRES(context, indices.shape().dim_size(1) > 0,\n-                errors::InvalidArgument(\"The second dimension of indices must \"\n-                                        \"be greater than 0. Received: \",\n-                                        indices.shape().dim_size(1)));\n-\n     for (int idx = 0; idx < num_values; ++idx) {\n       int batch = is_1d ? 0 : indices_values(idx, 0);\n       if (batch >= num_batches) {\n"
        ],
        "func_after": []
    },
    {
        "idx": 195056,
        "project": "tensorflow",
        "commit_id": "8c6f391a2282684a25cbfec7687bd5d35261a209",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/8c6f391a2282684a25cbfec7687bd5d35261a209",
        "commit_message": "[lite] Add check for bias_size is zero to avoid division by zero. This shouldn't happen for properly converted models. Just safety check\n\nPiperOrigin-RevId: 416383645\nChange-Id: If8e508bf696ae8ecfb927e69c139a8ccf7fe60cb",
        "target": 1,
        "irrelevant": 0,
        "func_before": "inline void BiasAndClamp(float clamp_min, float clamp_max, int bias_size,\n                         const float* bias_data, int array_size,\n                         float* array_data) {\n  // Note: see b/132215220: in May 2019 we thought it would be OK to replace\n  // this with the Eigen one-liner:\n  //   return (array.colwise() + bias).cwiseMin(clamp_max).cwiseMin(clamp_max).\n  // This turned out to severely regress performance: +4ms (i.e. 8%) on\n  // MobileNet v2 / 1.0 / 224. So we keep custom NEON code for now.\n  TFLITE_DCHECK_EQ((array_size % bias_size), 0);\n#ifdef USE_NEON\n  float* array_ptr = array_data;\n  float* array_end_ptr = array_ptr + array_size;\n  const auto clamp_min_vec = vdupq_n_f32(clamp_min);\n  const auto clamp_max_vec = vdupq_n_f32(clamp_max);\n  for (; array_ptr != array_end_ptr; array_ptr += bias_size) {\n    int i = 0;\n    for (; i <= bias_size - 16; i += 16) {\n      auto b0 = vld1q_f32(bias_data + i);\n      auto b1 = vld1q_f32(bias_data + i + 4);\n      auto b2 = vld1q_f32(bias_data + i + 8);\n      auto b3 = vld1q_f32(bias_data + i + 12);\n      auto a0 = vld1q_f32(array_ptr + i);\n      auto a1 = vld1q_f32(array_ptr + i + 4);\n      auto a2 = vld1q_f32(array_ptr + i + 8);\n      auto a3 = vld1q_f32(array_ptr + i + 12);\n      auto x0 = vaddq_f32(a0, b0);\n      auto x1 = vaddq_f32(a1, b1);\n      auto x2 = vaddq_f32(a2, b2);\n      auto x3 = vaddq_f32(a3, b3);\n      x0 = vmaxq_f32(clamp_min_vec, x0);\n      x1 = vmaxq_f32(clamp_min_vec, x1);\n      x2 = vmaxq_f32(clamp_min_vec, x2);\n      x3 = vmaxq_f32(clamp_min_vec, x3);\n      x0 = vminq_f32(clamp_max_vec, x0);\n      x1 = vminq_f32(clamp_max_vec, x1);\n      x2 = vminq_f32(clamp_max_vec, x2);\n      x3 = vminq_f32(clamp_max_vec, x3);\n      vst1q_f32(array_ptr + i, x0);\n      vst1q_f32(array_ptr + i + 4, x1);\n      vst1q_f32(array_ptr + i + 8, x2);\n      vst1q_f32(array_ptr + i + 12, x3);\n    }\n    for (; i <= bias_size - 4; i += 4) {\n      auto b = vld1q_f32(bias_data + i);\n      auto a = vld1q_f32(array_ptr + i);\n      auto x = vaddq_f32(a, b);\n      x = vmaxq_f32(clamp_min_vec, x);\n      x = vminq_f32(clamp_max_vec, x);\n      vst1q_f32(array_ptr + i, x);\n    }\n    for (; i < bias_size; i++) {\n      array_ptr[i] = ActivationFunctionWithMinMax(array_ptr[i] + bias_data[i],\n                                                  clamp_min, clamp_max);\n    }\n  }\n#else  // not NEON\n  for (int array_offset = 0; array_offset < array_size;\n       array_offset += bias_size) {\n    for (int i = 0; i < bias_size; i++) {\n      array_data[array_offset + i] = ActivationFunctionWithMinMax(\n          array_data[array_offset + i] + bias_data[i], clamp_min, clamp_max);\n    }\n  }\n#endif\n}",
        "func_hash": 154263320578941255259441922880599149557,
        "file_name": "common.h",
        "file_hash": 11373796702176609664888229687660280569,
        "cwe": [
            "CWE-369"
        ],
        "cve": "CVE-2022-23557",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. An attacker can craft a TFLite model that would trigger a division by zero in `BiasAndClamp` implementation. There is no check that the `bias_size` is non zero. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23557",
        "func_name": "BiasAndClamp",
        "diff": [
            "diff --git a/tensorflow/lite/kernels/internal/common.h b/tensorflow/lite/kernels/internal/common.h\nindex 38fa9167fd9da0..5e8778f183ec33 100644\n--- a/tensorflow/lite/kernels/internal/common.h\n+++ b/tensorflow/lite/kernels/internal/common.h\n@@ -75,6 +75,7 @@ float ActivationFunction(float x) {\n inline void BiasAndClamp(float clamp_min, float clamp_max, int bias_size,\n                          const float* bias_data, int array_size,\n                          float* array_data) {\n+  if (bias_size == 0) return;\n   // Note: see b/132215220: in May 2019 we thought it would be OK to replace\n   // this with the Eigen one-liner:\n   //   return (array.colwise() + bias).cwiseMin(clamp_max).cwiseMin(clamp_max).\n"
        ],
        "func_after": []
    },
    {
        "idx": 195059,
        "project": "tensorflow",
        "commit_id": "92dba16749fae36c246bec3f9ba474d9ddeb7662",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/92dba16749fae36c246bec3f9ba474d9ddeb7662",
        "commit_message": "Prevent a null-pointer dereference / `CHECK`-fail in grappler.\n\nPiperOrigin-RevId: 409187354\nChange-Id: I369c249cca32e6c56ec193f0ebbf2f2768fc7d43",
        "target": 1,
        "irrelevant": 0,
        "func_before": "bool DependencyOptimizer::SafeToRemoveIdentity(const NodeDef& node) const {\n  if (!IsIdentity(node) && !IsIdentityN(node)) {\n    return true;\n  }\n\n  if (nodes_to_preserve_.find(node.name()) != nodes_to_preserve_.end()) {\n    return false;\n  }\n  if (!fetch_nodes_known_) {\n    // The output values of this node may be needed.\n    return false;\n  }\n\n  if (node.input_size() < 1) {\n    // Node lacks input, is invalid\n    return false;\n  }\n\n  const NodeDef* input = node_map_->GetNode(NodeName(node.input(0)));\n  CHECK(input != nullptr) << \"node = \" << node.name()\n                          << \" input = \" << node.input(0);\n  // Don't remove Identity nodes corresponding to Variable reads or following\n  // Recv.\n  if (IsVariable(*input) || IsRecv(*input)) {\n    return false;\n  }\n  for (const auto& consumer : node_map_->GetOutputs(node.name())) {\n    if (node.input_size() > 1 && (IsRetval(*consumer) || IsMerge(*consumer))) {\n      return false;\n    }\n    if (IsSwitch(*input)) {\n      for (const string& consumer_input : consumer->input()) {\n        if (consumer_input == AsControlDependency(node.name())) {\n          return false;\n        }\n      }\n    }\n  }\n  return true;\n}",
        "func_hash": 61147310262209694276783937154772465535,
        "file_name": "dependency_optimizer.cc",
        "file_hash": 98916752340112642333125918775752240620,
        "cwe": [
            "CWE-617"
        ],
        "cve": "CVE-2022-23579",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The Grappler optimizer in TensorFlow can be used to cause a denial of service by altering a `SavedModel` such that `SafeToRemoveIdentity` would trigger `CHECK` failures. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23579",
        "func_name": "DependencyOptimizer::SafeToRemoveIdentity",
        "diff": [
            "diff --git a/tensorflow/core/grappler/optimizers/dependency_optimizer.cc b/tensorflow/core/grappler/optimizers/dependency_optimizer.cc\nindex aadea833a4fc48..bfd98a58a77718 100644\n--- a/tensorflow/core/grappler/optimizers/dependency_optimizer.cc\n+++ b/tensorflow/core/grappler/optimizers/dependency_optimizer.cc\n@@ -75,8 +75,10 @@ bool DependencyOptimizer::SafeToRemoveIdentity(const NodeDef& node) const {\n   }\n \n   const NodeDef* input = node_map_->GetNode(NodeName(node.input(0)));\n-  CHECK(input != nullptr) << \"node = \" << node.name()\n-                          << \" input = \" << node.input(0);\n+  if (input == nullptr) {\n+    VLOG(1) << \"node = \" << node.name() << \" input = \" << node.input(0);\n+    return false;\n+  }\n   // Don't remove Identity nodes corresponding to Variable reads or following\n   // Recv.\n   if (IsVariable(*input) || IsRecv(*input)) {\n"
        ],
        "func_after": []
    },
    {
        "idx": 195063,
        "project": "gpac",
        "commit_id": "5f2c2a16d30229b6241f02fa28e3d6b810d64858",
        "project_url": "https://github.com/gpac/gpac",
        "commit_url": "https://github.com/gpac/gpac/commit/5f2c2a16d30229b6241f02fa28e3d6b810d64858",
        "commit_message": "fixed #1905",
        "target": 1,
        "irrelevant": 0,
        "func_before": "GF_Err mpgviddmx_process(GF_Filter *filter)\n{\n\tGF_MPGVidDmxCtx *ctx = gf_filter_get_udta(filter);\n\tGF_FilterPacket *pck, *dst_pck;\n\tu64 byte_offset;\n\ts64 vosh_start = -1;\n\ts64 vosh_end = -1;\n\tGF_Err e;\n\tchar *data;\n\tu8 *start;\n\tu32 pck_size;\n\ts32 remain;\n\n\t//always reparse duration\n\tif (!ctx->duration.num)\n\t\tmpgviddmx_check_dur(filter, ctx);\n\n\tpck = gf_filter_pid_get_packet(ctx->ipid);\n\tif (!pck) {\n\t\tif (gf_filter_pid_is_eos(ctx->ipid)) {\n\t\t\tmpgviddmx_enqueue_or_dispatch(ctx, NULL, GF_TRUE, GF_TRUE);\n\t\t\tif (ctx->opid)\n\t\t\t\tgf_filter_pid_set_eos(ctx->opid);\n\t\t\tif (ctx->src_pck) gf_filter_pck_unref(ctx->src_pck);\n\t\t\tctx->src_pck = NULL;\n\t\t\treturn GF_EOS;\n\t\t}\n\t\treturn GF_OK;\n\t}\n\n\tdata = (char *) gf_filter_pck_get_data(pck, &pck_size);\n\tbyte_offset = gf_filter_pck_get_byte_offset(pck);\n\n\tstart = data;\n\tremain = pck_size;\n\n\t//input pid sets some timescale - we flushed pending data , update cts\n\tif (!ctx->resume_from && ctx->timescale) {\n\t\tu64 ts = gf_filter_pck_get_cts(pck);\n\t\tif (ts != GF_FILTER_NO_TS) {\n\t\t\tif (!ctx->cts || !ctx->recompute_cts)\n\t\t\t\tctx->cts = ts;\n\t\t}\n\t\tts = gf_filter_pck_get_dts(pck);\n\t\tif (ts != GF_FILTER_NO_TS) {\n\t\t\tif (!ctx->dts || !ctx->recompute_cts)\n\t\t\t\tctx->dts = ts;\n\n\t\t\tif (!ctx->prev_dts) ctx->prev_dts = ts;\n\t\t\telse if (ctx->prev_dts != ts) {\n\t\t\t\tu64 diff = ts;\n\t\t\t\tdiff -= ctx->prev_dts;\n\t\t\t\tif (!ctx->cur_fps.den) ctx->cur_fps.den = (u32) diff;\n\t\t\t\telse if (ctx->cur_fps.den > diff)\n\t\t\t\t\tctx->cur_fps.den = (u32) diff;\n\t\t\t}\n\t\t}\n\t\tgf_filter_pck_get_framing(pck, &ctx->input_is_au_start, &ctx->input_is_au_end);\n\t\t//this will force CTS recomput of each frame\n\t\tif (ctx->recompute_cts) ctx->input_is_au_start = GF_FALSE;\n\t\tif (ctx->src_pck) gf_filter_pck_unref(ctx->src_pck);\n\t\tctx->src_pck = pck;\n\t\tgf_filter_pck_ref_props(&ctx->src_pck);\n\t}\n\n\t//we stored some data to find the complete vosh, aggregate this packet with current one\n\tif (!ctx->resume_from && ctx->hdr_store_size) {\n\t\tif (ctx->hdr_store_alloc < ctx->hdr_store_size + pck_size) {\n\t\t\tctx->hdr_store_alloc = ctx->hdr_store_size + pck_size;\n\t\t\tctx->hdr_store = gf_realloc(ctx->hdr_store, sizeof(char)*ctx->hdr_store_alloc);\n\t\t}\n\t\tmemcpy(ctx->hdr_store + ctx->hdr_store_size, data, sizeof(char)*pck_size);\n\t\tif (byte_offset != GF_FILTER_NO_BO) {\n\t\t\tif (byte_offset >= ctx->hdr_store_size)\n\t\t\t\tbyte_offset -= ctx->hdr_store_size;\n\t\t\telse\n\t\t\t\tbyte_offset = GF_FILTER_NO_BO;\n\t\t}\n\t\tctx->hdr_store_size += pck_size;\n\t\tstart = data = ctx->hdr_store;\n\t\tremain = pck_size = ctx->hdr_store_size;\n\t}\n\n\tif (ctx->resume_from) {\n\t\tif (gf_filter_pid_would_block(ctx->opid))\n\t\t\treturn GF_OK;\n\n\t\t//resume from data copied internally\n\t\tif (ctx->hdr_store_size) {\n\t\t\tassert(ctx->resume_from <= ctx->hdr_store_size);\n\t\t\tstart = data = ctx->hdr_store + ctx->resume_from;\n\t\t\tremain = pck_size = ctx->hdr_store_size - ctx->resume_from;\n\t\t} else {\n\t\t\tassert(remain >= (s32) ctx->resume_from);\n\t\t\tstart += ctx->resume_from;\n\t\t\tremain -= ctx->resume_from;\n\t\t}\n\t\tctx->resume_from = 0;\n\t}\n\n\tif (!ctx->bs) {\n\t\tctx->bs = gf_bs_new(start, remain, GF_BITSTREAM_READ);\n\t} else {\n\t\tgf_bs_reassign_buffer(ctx->bs, start, remain);\n\t}\n\tif (!ctx->vparser) {\n\t\tctx->vparser = gf_m4v_parser_bs_new(ctx->bs, ctx->is_mpg12);\n\t}\n\n\n\twhile (remain) {\n\t\tBool full_frame;\n\t\tu8 *pck_data;\n\t\ts32 current;\n\t\tu8 sc_type, forced_sc_type=0;\n\t\tBool sc_type_forced = GF_FALSE;\n\t\tBool skip_pck = GF_FALSE;\n\t\tu8 ftype;\n\t\tu32 tinc;\n\t\tu64 size=0;\n\t\tu64 fstart;\n\t\tBool is_coded;\n\t\tu32 bytes_from_store = 0;\n\t\tu32 hdr_offset = 0;\n\t\tBool copy_last_bytes = GF_FALSE;\n\n\t\t//not enough bytes to parse start code\n\t\tif (remain<5) {\n\t\t\tmemcpy(ctx->hdr_store, start, remain);\n\t\t\tctx->bytes_in_header = remain;\n\t\t\tbreak;\n\t\t}\n\t\tcurrent = -1;\n\n\t\t//we have some potential bytes of a start code in the store, copy some more bytes and check if valid start code.\n\t\t//if not, dispatch these bytes as continuation of the data\n\t\tif (ctx->bytes_in_header) {\n\n\t\t\tmemcpy(ctx->hdr_store + ctx->bytes_in_header, start, 8 - ctx->bytes_in_header);\n\t\t\tcurrent = mpgviddmx_next_start_code(ctx->hdr_store, 8);\n\n\t\t\t//no start code in stored buffer\n\t\t\tif ((current<0) || (current >= (s32) ctx->bytes_in_header) )  {\n\t\t\t\tif (ctx->opid) {\n\t\t\t\t\tdst_pck = gf_filter_pck_new_alloc(ctx->opid, ctx->bytes_in_header, &pck_data);\n\t\t\t\t\tif (!dst_pck) return GF_OUT_OF_MEM;\n\n\t\t\t\t\tif (ctx->src_pck) gf_filter_pck_merge_properties(ctx->src_pck, dst_pck);\n\t\t\t\t\tgf_filter_pck_set_cts(dst_pck, GF_FILTER_NO_TS);\n\t\t\t\t\tgf_filter_pck_set_dts(dst_pck, GF_FILTER_NO_TS);\n\t\t\t\t\tmemcpy(pck_data, ctx->hdr_store, ctx->bytes_in_header);\n\t\t\t\t\tgf_filter_pck_set_framing(dst_pck, GF_FALSE, GF_FALSE);\n\n\t\t\t\t\tif (byte_offset != GF_FILTER_NO_BO) {\n\t\t\t\t\t\tgf_filter_pck_set_byte_offset(dst_pck, byte_offset - ctx->bytes_in_header);\n\t\t\t\t\t}\n\n\t\t\t\t\tmpgviddmx_enqueue_or_dispatch(ctx, dst_pck, GF_FALSE, GF_FALSE);\n\t\t\t\t}\n\n\t\t\t\tif (current<0) current = -1;\n\t\t\t\telse current -= ctx->bytes_in_header;\n\t\t\t\tctx->bytes_in_header = 0;\n\t\t\t} else {\n\t\t\t\t//we have a valid start code, check which byte in our store or in the packet payload is the start code type\n\t\t\t\t//and remember its location to reinit the parser from there\n\t\t\t\thdr_offset = 4 - ctx->bytes_in_header + current;\n\t\t\t\t//bytes still to dispatch\n\t\t\t\tbytes_from_store = ctx->bytes_in_header;\n\t\t\t\tctx->bytes_in_header = 0;\n\t\t\t\tif (!hdr_offset) {\n\t\t\t\t\tforced_sc_type = ctx->hdr_store[current+3];\n\t\t\t\t} else {\n\t\t\t\t\tforced_sc_type = start[hdr_offset-1];\n\t\t\t\t}\n\t\t\t\tsc_type_forced = GF_TRUE;\n\t\t\t}\n\t\t}\n\t\t//no starcode in store, look for startcode in packet\n\t\tif (current == -1) {\n\t\t\t//locate next start code\n\t\t\tcurrent = mpgviddmx_next_start_code(start, remain);\n\t\t\t//no start code, dispatch the block\n\t\t\tif (current<0) {\n\t\t\t\tu8 b3, b2, b1;\n\t\t\t\tif (! ctx->frame_started) {\n\t\t\t\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_MEDIA, (\"[MPGVid] no start code in block and no frame started, discarding data\\n\" ));\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tsize = remain;\n\t\t\t\tb3 = start[remain-3];\n\t\t\t\tb2 = start[remain-2];\n\t\t\t\tb1 = start[remain-1];\n\t\t\t\t//we may have a startcode at the end of the packet, store it and don't dispatch the last 3 bytes !\n\t\t\t\tif (!b1 || !b2 || !b3) {\n\t\t\t\t\tcopy_last_bytes = GF_TRUE;\n\t\t\t\t\tassert(size >= 3);\n\t\t\t\t\tsize -= 3;\n\t\t\t\t\tctx->bytes_in_header = 3;\n\t\t\t\t}\n\n\t\t\t\tdst_pck = gf_filter_pck_new_alloc(ctx->opid, (u32) size, &pck_data);\n\t\t\t\tif (!dst_pck) return GF_OUT_OF_MEM;\n\n\t\t\t\tif (ctx->src_pck) gf_filter_pck_merge_properties(ctx->src_pck, dst_pck);\n\t\t\t\tmemcpy(pck_data, start, (size_t) size);\n\t\t\t\tgf_filter_pck_set_framing(dst_pck, GF_FALSE, GF_FALSE);\n\t\t\t\tgf_filter_pck_set_cts(dst_pck, GF_FILTER_NO_TS);\n\t\t\t\tgf_filter_pck_set_dts(dst_pck, GF_FILTER_NO_TS);\n\n\t\t\t\tif (byte_offset != GF_FILTER_NO_BO) {\n\t\t\t\t\tgf_filter_pck_set_byte_offset(dst_pck, byte_offset);\n\t\t\t\t}\n\n\t\t\t\tmpgviddmx_enqueue_or_dispatch(ctx, dst_pck, GF_FALSE, GF_FALSE);\n\t\t\t\tif (copy_last_bytes) {\n\t\t\t\t\tmemcpy(ctx->hdr_store, start+remain-3, 3);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tassert(current>=0);\n\n\t\t//if we are in the middle of parsing the vosh, skip over bytes remaining from previous obj not parsed\n\t\tif ((vosh_start>=0) && current) {\n\t\t\tassert(remain>=current);\n\t\t\tstart += current;\n\t\t\tremain -= current;\n\t\t\tcurrent = 0;\n\t\t}\n\t\t//also skip if no output pid\n\t\tif (!ctx->opid && current) {\n\t\t\tassert(remain>=current);\n\t\t\tstart += current;\n\t\t\tremain -= current;\n\t\t\tcurrent = 0;\n\t\t}\n\t\t//dispatch remaining bytes\n\t\tif (current>0) {\n\t\t\t//flush remaining\n\t\t\tdst_pck = gf_filter_pck_new_alloc(ctx->opid, current, &pck_data);\n\t\t\tif (!dst_pck) return GF_OUT_OF_MEM;\n\n\t\t\tif (ctx->src_pck) gf_filter_pck_merge_properties(ctx->src_pck, dst_pck);\n\t\t\tgf_filter_pck_set_cts(dst_pck, GF_FILTER_NO_TS);\n\t\t\tgf_filter_pck_set_dts(dst_pck, GF_FILTER_NO_TS);\n\t\t\tgf_filter_pck_set_framing(dst_pck, GF_FALSE, GF_TRUE);\n\t\t\t//bytes were partly in store, partly in packet\n\t\t\tif (bytes_from_store) {\n\t\t\t\tif (byte_offset != GF_FILTER_NO_BO) {\n\t\t\t\t\tgf_filter_pck_set_byte_offset(dst_pck, byte_offset - bytes_from_store);\n\t\t\t\t}\n\t\t\t\tassert(bytes_from_store>=(u32) current);\n\t\t\t\tbytes_from_store -= current;\n\t\t\t\tmemcpy(pck_data, ctx->hdr_store, current);\n\t\t\t} else {\n\t\t\t\t//bytes were only in packet\n\t\t\t\tif (byte_offset != GF_FILTER_NO_BO) {\n\t\t\t\t\tgf_filter_pck_set_byte_offset(dst_pck, byte_offset);\n\t\t\t\t}\n\t\t\t\tmemcpy(pck_data, start, current);\n\t\t\t\tassert(remain>=current);\n\t\t\t\tstart += current;\n\t\t\t\tremain -= current;\n\t\t\t\tcurrent = 0;\n\t\t\t}\n\t\t\tgf_filter_pck_set_carousel_version(dst_pck, 1);\n\n\t\t\tmpgviddmx_enqueue_or_dispatch(ctx, dst_pck, GF_FALSE, GF_FALSE);\n\t\t}\n\n\t\t//parse headers\n\n\t\t//we have a start code loaded, eg the data packet does not have a full start code at the beginning\n\t\tif (sc_type_forced) {\n\t\t\tgf_bs_reassign_buffer(ctx->bs, start + hdr_offset, remain - hdr_offset);\n\t\t\tsc_type = forced_sc_type;\n\t\t} else {\n\t\t\tgf_bs_reassign_buffer(ctx->bs, start, remain);\n\t\t\tgf_bs_read_int(ctx->bs, 24);\n\t\t\tsc_type = gf_bs_read_int(ctx->bs, 8);\n\t\t}\n\n\t\tif (ctx->is_mpg12) {\n\t\t\tswitch (sc_type) {\n\t\t\tcase M2V_SEQ_START_CODE:\n\t\t\tcase M2V_EXT_START_CODE:\n\t\t\t\tgf_bs_reassign_buffer(ctx->bs, start, remain);\n\t\t\t\te = gf_m4v_parse_config(ctx->vparser, &ctx->dsi);\n\t\t\t\t//not enough data, accumulate until we can parse the full header\n\t\t\t\tif (e==GF_EOS) {\n\t\t\t\t\tif (vosh_start<0) vosh_start = 0;\n\t\t\t\t\tif (data == ctx->hdr_store) {\n\t\t\t\t\t\tmemmove(ctx->hdr_store, start, remain);\n\t\t\t\t\t\tctx->hdr_store_size = remain;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tif (ctx->hdr_store_alloc < ctx->hdr_store_size + pck_size - vosh_start) {\n\t\t\t\t\t\t\tctx->hdr_store_alloc = (u32) (ctx->hdr_store_size + pck_size - vosh_start);\n\t\t\t\t\t\t\tctx->hdr_store = gf_realloc(ctx->hdr_store, sizeof(char)*ctx->hdr_store_alloc);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tmemcpy(ctx->hdr_store + ctx->hdr_store_size, data + vosh_start, (size_t) (pck_size - vosh_start) );\n\t\t\t\t\t\tctx->hdr_store_size += pck_size - (u32) vosh_start;\n\t\t\t\t\t}\n\t\t\t\t\tgf_filter_pid_drop_packet(ctx->ipid);\n\t\t\t\t\treturn GF_OK;\n\t\t\t\t} else if (e != GF_OK) {\n\t\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_MEDIA, (\"[MPGVid] Failed to parse VOS header: %s\\n\", gf_error_to_string(e) ));\n\t\t\t\t} else {\n\t\t\t\t\tmpgviddmx_check_pid(filter, ctx, 0, NULL);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase M2V_PIC_START_CODE:\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t} else {\n\t\t\tu8 PL;\n\t\t\tswitch (sc_type) {\n\t\t\tcase M4V_VOS_START_CODE:\n\t\t\t\tctx->dsi.VideoPL = (u8) gf_bs_read_u8(ctx->bs);\n\t\t\t\tvosh_start = start - (u8 *)data;\n\t\t\t\tskip_pck = GF_TRUE;\n\t\t\t\tassert(remain>=5);\n\t\t\t\tstart += 5;\n\t\t\t\tremain -= 5;\n\t\t\t\tbreak;\n\t\t\tcase M4V_VOL_START_CODE:\n\t\t\t\tgf_bs_reassign_buffer(ctx->bs, start, remain);\n\t\t\t\tPL = ctx->dsi.VideoPL;\n\t\t\t\te = gf_m4v_parse_config(ctx->vparser, &ctx->dsi);\n\t\t\t\tctx->dsi.VideoPL = PL;\n\t\t\t\t//not enough data, accumulate until we can parse the full header\n\t\t\t\tif (e==GF_EOS) {\n\t\t\t\t\tif (vosh_start<0) vosh_start = 0;\n\t\t\t\t\tif (data == ctx->hdr_store) {\n\t\t\t\t\t\tmemmove(ctx->hdr_store, start, remain);\n\t\t\t\t\t\tctx->hdr_store_size = remain;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tif (ctx->hdr_store_alloc < ctx->hdr_store_size + pck_size - vosh_start) {\n\t\t\t\t\t\t\tctx->hdr_store_alloc = (u32) (ctx->hdr_store_size + pck_size - (u32) vosh_start);\n\t\t\t\t\t\t\tctx->hdr_store = gf_realloc(ctx->hdr_store, sizeof(char)*ctx->hdr_store_alloc);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tmemcpy(ctx->hdr_store + ctx->hdr_store_size, data + vosh_start, (size_t) (pck_size - vosh_start) );\n\t\t\t\t\t\tctx->hdr_store_size += pck_size - (u32) vosh_start;\n\t\t\t\t\t}\n\t\t\t\t\tgf_filter_pid_drop_packet(ctx->ipid);\n\t\t\t\t\treturn GF_OK;\n\t\t\t\t} else if (e != GF_OK) {\n\t\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_MEDIA, (\"[MPGVid] Failed to parse VOS header: %s\\n\", gf_error_to_string(e) ));\n\t\t\t\t} else {\n\t\t\t\t\tu32 obj_size = (u32) gf_m4v_get_object_start(ctx->vparser);\n\t\t\t\t\tif (vosh_start<0) vosh_start = 0;\n\t\t\t\t\tvosh_end = start - (u8 *)data + obj_size;\n\t\t\t\t\tvosh_end -= vosh_start;\n\t\t\t\t\tmpgviddmx_check_pid(filter, ctx,(u32)  vosh_end, data+vosh_start);\n\t\t\t\t\tskip_pck = GF_TRUE;\n\t\t\t\t\tassert(remain>=(s32) obj_size);\n\t\t\t\t\tstart += obj_size;\n\t\t\t\t\tremain -= obj_size;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase M4V_VOP_START_CODE:\n\t\t\tcase M4V_GOV_START_CODE:\n\t\t\t\tbreak;\n\n\t\t\tcase M4V_VO_START_CODE:\n\t\t\tcase M4V_VISOBJ_START_CODE:\n\t\t\tdefault:\n\t\t\t\tif (vosh_start>=0) {\n\t\t\t\t\tskip_pck = GF_TRUE;\n\t\t\t\t\tassert(remain>=4);\n\t\t\t\t\tstart += 4;\n\t\t\t\t\tremain -= 4;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif (skip_pck) {\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (!ctx->opid) {\n\t\t\tassert(remain>=4);\n\t\t\tstart += 4;\n\t\t\tremain -= 4;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (!ctx->is_playing) {\n\t\t\tctx->resume_from = (u32) ((char *)start -  (char *)data);\n\t\t\treturn GF_OK;\n\t\t}\n\t\t//at this point, we no longer reaggregate packets\n\t\tctx->hdr_store_size = 0;\n\n\t\tif (ctx->in_seek) {\n\t\t\tu64 nb_frames_at_seek = (u64) (ctx->start_range * ctx->cur_fps.num);\n\t\t\tif (ctx->cts + ctx->cur_fps.den >= nb_frames_at_seek) {\n\t\t\t\t//u32 samples_to_discard = (ctx->cts + ctx->dts_inc) - nb_samples_at_seek;\n\t\t\t\tctx->in_seek = GF_FALSE;\n\t\t\t}\n\t\t}\n\t\t//may happen that after all our checks, only 4 bytes are left, continue to store these 4 bytes\n\t\tif (remain<5)\n\t\t\tcontinue;\n\n\t\t//good to go\n\t\tgf_m4v_parser_reset(ctx->vparser, sc_type_forced ? forced_sc_type + 1 : 0);\n\t\tsize = 0;\n\t\te = gf_m4v_parse_frame(ctx->vparser, &ctx->dsi, &ftype, &tinc, &size, &fstart, &is_coded);\n\t\t//true if we strip VO and VISOBJ assert(!fstart);\n\n\t\t//we skipped bytes already in store + end of start code present in packet, so the size of the first object\n\t\t//needs adjustement\n\t\tif (bytes_from_store) {\n\t\t\tsize += bytes_from_store + hdr_offset;\n\t\t}\n\n\t\tif ((e == GF_EOS) && !ctx->input_is_au_end) {\n\t\t\tu8 b3 = start[remain-3];\n\t\t\tu8 b2 = start[remain-2];\n\t\t\tu8 b1 = start[remain-1];\n\n\t\t\t//we may have a startcode at the end of the packet, store it and don't dispatch the last 3 bytes !\n\t\t\tif (!b1 || !b2 || !b3) {\n\t\t\t\tcopy_last_bytes = GF_TRUE;\n\t\t\t\tassert(size >= 3);\n\t\t\t\tsize -= 3;\n\t\t\t\tctx->bytes_in_header = 3;\n\t\t\t}\n\t\t\tfull_frame = GF_FALSE;\n\t\t} else {\n\t\t\tfull_frame = GF_TRUE;\n\t\t}\n\n\t\tif (!is_coded) {\n\t\t\t/*if prev is B and we're parsing a packed bitstream discard n-vop*/\n\t\t\tif (ctx->forced_packed && ctx->b_frames) {\n\t\t\t\tctx->is_packed = GF_TRUE;\n\t\t\t\tassert(remain>=size);\n\t\t\t\tstart += size;\n\t\t\t\tremain -= (s32) size;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\t/*policy is to import at variable frame rate, skip*/\n\t\t\tif (ctx->vfr) {\n\t\t\t\tctx->is_vfr = GF_TRUE;\n\t\t\t\tmpgviddmx_update_time(ctx);\n\t\t\t\tassert(remain>=size);\n\t\t\t\tstart += size;\n\t\t\t\tremain -= (s32) size;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\t/*policy is to keep non coded frame (constant frame rate), add*/\n\t\t}\n\n\t\tif (ftype==2) {\n\t\t\t//count number of B-frames since last ref\n\t\t\tctx->b_frames++;\n\t\t\tctx->nb_b++;\n\t\t} else {\n\t\t\t//flush all pending packets\n\t\t\tmpgviddmx_enqueue_or_dispatch(ctx, NULL, GF_TRUE, GF_FALSE);\n\t\t\t//remeber the CTS of the last ref\n\t\t\tctx->last_ref_cts = ctx->cts;\n\t\t\tif (ctx->max_b < ctx->b_frames) ctx->max_b = ctx->b_frames;\n\t\t\t\n\t\t\tctx->b_frames = 0;\n\t\t\tif (ftype)\n\t\t\t\tctx->nb_p++;\n\t\t\telse\n\t\t\t\tctx->nb_i++;\n\t\t}\n\t\tctx->nb_frames++;\n\n\t\tdst_pck = gf_filter_pck_new_alloc(ctx->opid, (u32) size, &pck_data);\n\t\tif (!dst_pck) return GF_OUT_OF_MEM;\n\n\t\tif (ctx->src_pck) gf_filter_pck_merge_properties(ctx->src_pck, dst_pck);\n\t\t//bytes come from both our store and the data packet\n\t\tif (bytes_from_store) {\n\t\t\tmemcpy(pck_data, ctx->hdr_store+current, bytes_from_store);\n\t\t\tassert(size >= bytes_from_store);\n\t\t\tsize -= bytes_from_store;\n\t\t\tif (byte_offset != GF_FILTER_NO_BO) {\n\t\t\t\tgf_filter_pck_set_byte_offset(dst_pck, byte_offset - bytes_from_store);\n\t\t\t}\n\t\t\tmemcpy(pck_data + bytes_from_store, start, (size_t) size);\n\t\t} else {\n\t\t\t//bytes only come the data packet\n\t\t\tmemcpy(pck_data, start, (size_t) size);\n\t\t\tif (byte_offset != GF_FILTER_NO_BO) {\n\t\t\t\tgf_filter_pck_set_byte_offset(dst_pck, byte_offset + start - (u8 *) data);\n\t\t\t}\n\t\t}\n\t\tassert(pck_data[0] == 0);\n\t\tassert(pck_data[1] == 0);\n\t\tassert(pck_data[2] == 0x01);\n\n\t\tgf_filter_pck_set_framing(dst_pck, GF_TRUE, (full_frame || ctx->input_is_au_end) ? GF_TRUE : GF_FALSE);\n\t\tgf_filter_pck_set_cts(dst_pck, ctx->cts);\n\t\tgf_filter_pck_set_dts(dst_pck, ctx->dts);\n\t\tif (ctx->input_is_au_start) {\n\t\t\tctx->input_is_au_start = GF_FALSE;\n\t\t} else {\n\t\t\t//we use the carousel flag temporarly to indicate the cts must be recomputed\n\t\t\tgf_filter_pck_set_carousel_version(dst_pck, 1);\n\t\t}\n\t\tgf_filter_pck_set_sap(dst_pck, ftype ? GF_FILTER_SAP_NONE : GF_FILTER_SAP_1);\n\t\tgf_filter_pck_set_duration(dst_pck, ctx->cur_fps.den);\n\t\tif (ctx->in_seek) gf_filter_pck_set_seek_flag(dst_pck, GF_TRUE);\n\t\tctx->frame_started = GF_TRUE;\n\n\t\tmpgviddmx_enqueue_or_dispatch(ctx, dst_pck, GF_FALSE, GF_FALSE);\n\n\t\tmpgviddmx_update_time(ctx);\n\n\t\tif (!full_frame) {\n\t\t\tif (copy_last_bytes) {\n\t\t\t\tmemcpy(ctx->hdr_store, start+remain-3, 3);\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\tassert(remain>=size);\n\t\tstart += size;\n\t\tremain -= (s32) size;\n\t}\n\tgf_filter_pid_drop_packet(ctx->ipid);\n\n\treturn GF_OK;\n}",
        "func_hash": 49630978088913986571244550780083545600,
        "file_name": "reframe_mpgvid.c",
        "file_hash": 148306570807841160156662867455353144265,
        "cwe": [
            "CWE-476"
        ],
        "cve": "CVE-2021-40575",
        "cve_desc": "The binary MP4Box in Gpac 1.0.1 has a null pointer dereference vulnerability in the mpgviddmx_process function in reframe_mpgvid.c, which allows attackers to cause a denial of service. This vulnerability is possibly due to an incomplete fix for CVE-2021-40566.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-40575",
        "func_name": "mpgviddmx_process",
        "diff": [
            "diff --git a/src/filters/reframe_mpgvid.c b/src/filters/reframe_mpgvid.c\nindex 328db28551..85d4faa4cb 100644\n--- a/src/filters/reframe_mpgvid.c\n+++ b/src/filters/reframe_mpgvid.c\n@@ -784,8 +784,14 @@ GF_Err mpgviddmx_process(GF_Filter *filter)\n \t\t\tmpgviddmx_enqueue_or_dispatch(ctx, dst_pck, GF_FALSE, GF_FALSE);\n \t\t}\n \n-\t\t//parse headers\n+\t\t//not enough bytes to parse start code\n+\t\tif (remain<5) {\n+\t\t\tmemcpy(ctx->hdr_store, start, remain);\n+\t\t\tctx->bytes_in_header = remain;\n+\t\t\tbreak;\n+\t\t}\n \n+\t\t//parse headers\n \t\t//we have a start code loaded, eg the data packet does not have a full start code at the beginning\n \t\tif (sc_type_forced) {\n \t\t\tgf_bs_reassign_buffer(ctx->bs, start + hdr_offset, remain - hdr_offset);\n"
        ],
        "func_after": []
    },
    {
        "idx": 216728,
        "project": "graphviz",
        "commit_id": "839085f8026afd6f6920a0c31ad2a9d880d97932",
        "project_url": "https://gitlab.com/graphviz/graphviz",
        "commit_url": "https://gitlab.com/graphviz/graphviz/commit/839085f8026afd6f6920a0c31ad2a9d880d97932",
        "commit_message": "attempted fix for null pointer deference on malformed input",
        "target": 1,
        "irrelevant": 1,
        "func_before": "Agraph_t *agroot(void* obj)\n{\n    switch (AGTYPE(obj)) {\n    case AGINEDGE:\n    case AGOUTEDGE:\n\treturn ((Agedge_t *) obj)->node->root;\n    case AGNODE:\n\treturn ((Agnode_t *) obj)->root;\n    case AGRAPH:\n\treturn ((Agraph_t *) obj)->root;\n    default:\t\t\t/* actually can't occur if only 2 bit tags */\n\tagerr(AGERR, \"agroot of a bad object\");\n\treturn NILgraph;\n    }\n}",
        "func_hash": 275284791948548661260832026527731938206,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-476"
        ],
        "cve": "CVE-2019-11023",
        "cve_desc": "The agroot() function in cgraph\\obj.c in libcgraph.a in Graphviz 2.39.20160612.1140 has a NULL pointer dereference, as demonstrated by graphml2gv.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2019-11023",
        "func_name": "agroot",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 216799,
        "project": "core",
        "commit_id": "fb246611e62ad8c5a95b0ca180a63f17aa34b0d8",
        "project_url": "https://github.com/LibreOffice/core",
        "commit_url": "https://github.com/dovecot/core/commit/fb246611e62ad8c5a95b0ca180a63f17aa34b0d8",
        "commit_message": "lib-ntlm: Check buffer length on responses\n\nAdd missing check for buffer length.\n\nIf this is not checked, it is possible to send message which\ncauses read past buffer bug.\n\nBroken in c7480644202e5451fbed448508ea29a25cffc99c",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static bool ntlmssp_check_buffer(const struct ntlmssp_buffer *buffer,\n\t\t\t\t size_t data_size, const char **error)\n{\n\tuint32_t offset = read_le32(&buffer->offset);\n\tuint16_t length = read_le16(&buffer->length);\n\tuint16_t space = read_le16(&buffer->space);\n\n\t/* Empty buffer is ok */\n\tif (length == 0 && space == 0)\n\t\treturn TRUE;\n\n\tif (offset >= data_size) {\n\t\t*error = \"buffer offset out of bounds\";\n\t\treturn FALSE;\n\t}\n\n\tif (offset + space > data_size) {\n\t\t*error = \"buffer end out of bounds\";\n\t\treturn FALSE;\n\t}\n\n\treturn TRUE;\n}",
        "func_hash": 209828353012389088506060342960975963748,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-125"
        ],
        "cve": "CVE-2020-12673",
        "cve_desc": "In Dovecot before 2.3.11.3, sending a specially formatted NTLM request will crash the auth service because of an out-of-bounds read.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2020-12673",
        "func_name": "ntlmssp_check_buffer",
        "diff": [
            "diff --git a/src/lib-ntlm/ntlm-message.c b/src/lib-ntlm/ntlm-message.c\nindex 160b9f918c..a29413b47e 100644\n--- a/src/lib-ntlm/ntlm-message.c\n+++ b/src/lib-ntlm/ntlm-message.c\n@@ -184,6 +184,11 @@ static bool ntlmssp_check_buffer(const struct ntlmssp_buffer *buffer,\n \tif (length == 0 && space == 0)\n \t\treturn TRUE;\n \n+\tif (length > data_size) {\n+\t\t*error = \"buffer length out of bounds\";\n+\t\treturn FALSE;\n+\t}\n+\n \tif (offset >= data_size) {\n \t\t*error = \"buffer offset out of bounds\";\n \t\treturn FALSE;\n"
        ],
        "func_after": []
    },
    {
        "idx": 216803,
        "project": "gnuplot",
        "commit_id": "052cbd17c3cbbc602ee080b2617d32a8417d7563",
        "project_url": "https://github.com/gnuplot/gnuplot",
        "commit_url": "https://github.com/gnuplot/gnuplot/commit/052cbd17c3cbbc602ee080b2617d32a8417d7563",
        "commit_message": "successive failures of \"set print <foo>\" could cause double-free\nBug #2312",
        "target": 1,
        "irrelevant": 1,
        "func_before": "print_set_output(char *name, TBOOLEAN datablock, TBOOLEAN append_p)\n{\n    if (print_out && print_out != stderr && print_out != stdout) {\n#ifdef PIPES\n\tif (print_out_name[0] == '|') {\n\t    if (0 > pclose(print_out))\n\t\tperror(print_out_name);\n\t} else\n#endif\n\t    if (0 > fclose(print_out))\n\t\tperror(print_out_name);\n    }\n\n    free(print_out_name);\n    print_out_name = NULL;\n    print_out_var = NULL;\n\n    if (! name) {\n\tprint_out = stderr;\n\treturn;\n    }\n\n    if (strcmp(name, \"-\") == 0) {\n\tprint_out = stdout;\n\treturn;\n    }\n\n#ifdef PIPES\n    if (name[0] == '|') {\n\trestrict_popen();\n\tprint_out = popen(name + 1, \"w\");\n\tif (!print_out)\n\t    perror(name);\n\telse\n\t    print_out_name = name;\n\treturn;\n    }\n#endif\n\n    if (!datablock) {\n\tprint_out = fopen(name, append_p ? \"a\" : \"w\");\n\tif (!print_out) {\n\t    perror(name);\n\t    return;\n\t}\n    } else {\n\tprint_out_var = add_udv_by_name(name);\n\tif (!append_p)\n\t    gpfree_datablock(&print_out_var->udv_value);\n\t/* If this is not an existing datablock to be appended */\n\t/* then make it a new empty datablock */\n\tif (print_out_var->udv_value.type != DATABLOCK) {\n\t    free_value(&print_out_var->udv_value);\n\t    print_out_var->udv_value.type = DATABLOCK;\n\t    print_out_var->udv_value.v.data_array = NULL;\n\t}\n    }\n\n    print_out_name = name;\n}",
        "func_hash": 328916832716321363528711493757918252280,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-415"
        ],
        "cve": "CVE-2020-25559",
        "cve_desc": "gnuplot 5.5 is affected by double free when executing print_set_output. This may result in context-dependent arbitrary code execution.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2020-25559",
        "func_name": "print_set_output",
        "diff": [
            "diff --git a/src/command.c b/src/command.c\nindex c6a923b5a..9701de995 100644\n--- a/src/command.c\n+++ b/src/command.c\n@@ -1914,6 +1914,7 @@ print_set_output(char *name, TBOOLEAN datablock, TBOOLEAN append_p)\n #endif\n \t    if (0 > fclose(print_out))\n \t\tperror(print_out_name);\n+\tprint_out = stderr;\n     }\n \n     free(print_out_name);\n"
        ],
        "func_after": []
    },
    {
        "idx": 216804,
        "project": "gnuplot",
        "commit_id": "963c7df3e0c5266efff260d0dff757dfe03d3632",
        "project_url": "https://github.com/gnuplot/gnuplot",
        "commit_url": "https://github.com/gnuplot/gnuplot/commit/963c7df3e0c5266efff260d0dff757dfe03d3632",
        "commit_message": "Better error handling for faulty font syntax\n\nA missing close-quote in an enhanced text font specification could\ncause a segfault.\nBug #2303",
        "target": 1,
        "irrelevant": 0,
        "func_before": "enhanced_recursion(\n    const char *p,\n    TBOOLEAN brace,\n    char *fontname,\n    double fontsize,\n    double base,\n    TBOOLEAN widthflag,\n    TBOOLEAN showflag,\n    int overprint)\n{\n    TBOOLEAN wasitalic, wasbold;\n\n    /* Keep track of the style of the font passed in at this recursion level */\n    wasitalic = (strstr(fontname, \":Italic\") != NULL);\n    wasbold = (strstr(fontname, \":Bold\") != NULL);\n\n    FPRINTF((stderr, \"RECURSE WITH \\\"%s\\\", %d %s %.1f %.1f %d %d %d\",\n\t\tp, brace, fontname, fontsize, base, widthflag, showflag, overprint));\n\n    /* Start each recursion with a clean string */\n    (term->enhanced_flush)();\n\n    if (base + fontsize > enhanced_max_height) {\n\tenhanced_max_height = base + fontsize;\n\tENH_DEBUG((\"Setting max height to %.1f\\n\", enhanced_max_height));\n    }\n\n    if (base < enhanced_min_height) {\n\tenhanced_min_height = base;\n\tENH_DEBUG((\"Setting min height to %.1f\\n\", enhanced_min_height));\n    }\n\n    while (*p) {\n\tdouble shift;\n\n\t/*\n\t * EAM Jun 2009 - treating bytes one at a time does not work for multibyte\n\t * encodings, including utf-8. If we hit a byte with the high bit set, test\n\t * whether it starts a legal UTF-8 sequence and if so copy the whole thing.\n\t * Other multibyte encodings are still a problem.\n\t * Gnuplot's other defined encodings are all single-byte; for those we\n\t * really do want to treat one byte at a time.\n\t */\n\tif ((*p & 0x80) && (encoding == S_ENC_DEFAULT || encoding == S_ENC_UTF8)) {\n\t    unsigned long utf8char;\n\t    const char *nextchar = p;\n\n\t    (term->enhanced_open)(fontname, fontsize, base, widthflag, showflag, overprint);\n\t    if (utf8toulong(&utf8char, &nextchar)) {\t/* Legal UTF8 sequence */\n\t\twhile (p < nextchar)\n\t\t    (term->enhanced_writec)(*p++);\n\t\tp--;\n\t    } else {\t\t\t\t\t/* Some other multibyte encoding? */\n\t\t(term->enhanced_writec)(*p);\n\t    }\n/* shige : for Shift_JIS */\n\t} else if ((*p & 0x80) && (encoding == S_ENC_SJIS)) {\n\t    (term->enhanced_open)(fontname, fontsize, base, widthflag, showflag, overprint);\n\t    (term->enhanced_writec)(*(p++));\n\t    (term->enhanced_writec)(*p);\n\t} else\n\n\tswitch (*p) {\n\tcase '}'  :\n\t    /*{{{  deal with it*/\n\t    if (brace)\n\t\treturn (p);\n\n\t    int_warn(NO_CARET, \"enhanced text parser - spurious }\");\n\t    break;\n\t    /*}}}*/\n\n\tcase '_'  :\n\tcase '^'  :\n\t    /*{{{  deal with super/sub script*/\n\t    shift = (*p == '^') ? 0.5 : -0.3;\n\t    (term->enhanced_flush)();\n\t    p = enhanced_recursion(p + 1, FALSE, fontname, fontsize * 0.8,\n\t\t\t      base + shift * fontsize, widthflag,\n\t\t\t      showflag, overprint);\n\t    break;\n\t    /*}}}*/\n\tcase '{'  :\n\t    {\n\t\tTBOOLEAN isitalic = FALSE, isbold = FALSE, isnormal = FALSE;\n\t\tconst char *start_of_fontname = NULL;\n\t\tconst char *end_of_fontname = NULL;\n\t\tchar *localfontname = NULL;\n\t\tchar ch;\n\t\tdouble f = fontsize, ovp;\n\n\t\t/* Mar 2014 - this will hold \"fontfamily{:Italic}{:Bold}\" */\n\t\tchar *styledfontname = NULL;\n\n\t\t/*{{{  recurse (possibly with a new font) */\n\n\t\tENH_DEBUG((\"Dealing with {\\n\"));\n\n\t\t/* 30 Sep 2016:  Remove incorrect whitespace-eating loop going */\n\t\t/* waaay back to 31-May-2000 */        /* while (*++p == ' '); */\n\t\t++p;\n\t\t/* get vertical offset (if present) for overprinted text */\n\t\tif (overprint == 2) {\n\t\t    char *end;\n\t\t    ovp = strtod(p,&end);\n\t\t    p = end;\n\t\t    if (term->flags & TERM_IS_POSTSCRIPT)\n\t\t\tbase = ovp*f;\n\t\t    else\n\t\t\tbase += ovp*f;\n\t\t}\n\t\t--p;\n\n\t\tif (*++p == '/') {\n\t\t    /* then parse a fontname, optional fontsize */\n\t\t    while (*++p == ' ')\n\t\t\t;       /* do nothing */\n\t\t    if (*p=='-') {\n\t\t\twhile (*++p == ' ')\n\t\t\t    ;   /* do nothing */\n\t\t    }\n\t\t    start_of_fontname = p;\n\n\t\t    /* Allow font name to be in quotes.\n\t\t     * This makes it possible to handle font names containing spaces.\n\t\t     */\n\t\t    if (*p == '\\'' || *p == '\"') {\n\t\t\t++p;\n\t\t\twhile (*p != '\\0' && *p != '}' && *p != *start_of_fontname)\n\t\t\t    ++p;\n\t\t\tif (*p != *start_of_fontname) {\n\t\t\t    int_warn(NO_CARET, \"cannot interpret font name %s\", start_of_fontname);\n\t\t\t    p = start_of_fontname;\n\t\t\t}\n\t\t\tstart_of_fontname++;\n\t\t\tend_of_fontname = p++;\n\t\t\tch = *p;\n\t\t    } else {\n\n\t\t    /* Normal unquoted font name */\n\t\t\twhile ((ch = *p) > ' ' && ch != '=' && ch != '*' && ch != '}' && ch != ':')\n\t\t\t    ++p;\n\t\t\tend_of_fontname = p;\n\t\t    }\n\n\t\t    do {\n\t\t\tif (ch == '=') {\n\t\t\t    /* get optional font size */\n\t\t\t    char *end;\n\t\t\t    p++;\n\t\t\t    ENH_DEBUG((\"Calling strtod(\\\"%s\\\") ...\", p));\n\t\t\t    f = strtod(p, &end);\n\t\t\t    p = end;\n\t\t\t    ENH_DEBUG((\"Returned %.1f and \\\"%s\\\"\\n\", f, p));\n\n\t\t\t    if (f == 0)\n\t\t\t\tf = fontsize;\n\t\t\t    else\n\t\t\t\tf *= enhanced_fontscale;  /* remember the scaling */\n\n\t\t\t    ENH_DEBUG((\"Font size %.1f\\n\", f));\n\t\t\t} else if (ch == '*') {\n\t\t\t    /* get optional font size scale factor */\n\t\t\t    char *end;\n\t\t\t    p++;\n\t\t\t    ENH_DEBUG((\"Calling strtod(\\\"%s\\\") ...\", p));\n\t\t\t    f = strtod(p, &end);\n\t\t\t    p = end;\n\t\t\t    ENH_DEBUG((\"Returned %.1f and \\\"%s\\\"\\n\", f, p));\n\n\t\t\t    if (f)\n\t\t\t\tf *= fontsize;  /* apply the scale factor */\n\t\t\t    else\n\t\t\t\tf = fontsize;\n\n\t\t\t    ENH_DEBUG((\"Font size %.1f\\n\", f));\n\t\t\t} else if (ch == ':') {\n\t\t\t    /* get optional style markup attributes */\n\t\t\t    p++;\n\t\t\t    if (!strncmp(p,\"Bold\",4))\n\t\t\t\tisbold = TRUE;\n\t\t\t    if (!strncmp(p,\"Italic\",6))\n\t\t\t\tisitalic = TRUE;\n\t\t\t    if (!strncmp(p,\"Normal\",6))\n\t\t\t\tisnormal = TRUE;\n\t\t\t    while (isalpha((unsigned char)*p)) {p++;}\n\t\t\t}\n\t\t    } while (((ch = *p) == '=') || (ch == ':') || (ch == '*'));\n\n\t\t    if (ch == '}')\n\t\t\tint_warn(NO_CARET,\"bad syntax in enhanced text string\");\n\n\t\t    if (*p == ' ')\t/* Eat up a single space following a font spec */\n\t\t\t++p;\n\t\t    if (!start_of_fontname || (start_of_fontname == end_of_fontname)) {\n\t\t\t/* Use the font name passed in to us */\n\t\t\tlocalfontname = gp_strdup(fontname);\n\t\t    } else {\n\t\t\t/* We found a new font name {/Font ...} */\n\t\t\tint len = end_of_fontname - start_of_fontname;\n\t\t\tlocalfontname = gp_alloc(len+1,\"localfontname\");\n\t\t\tstrncpy(localfontname, start_of_fontname, len);\n\t\t\tlocalfontname[len] = '\\0';\n\t\t    }\n\t\t}\n\t\t/*}}}*/\n\n\t\t/* Collect cumulative style markup before passing it in the font name */\n\t\tisitalic = (wasitalic || isitalic) && !isnormal;\n\t\tisbold = (wasbold || isbold) && !isnormal;\n\n\t\tstyledfontname = stylefont(localfontname ? localfontname : fontname,\n\t\t\t\t\t    isbold, isitalic);\n\n\t\tp = enhanced_recursion(p, TRUE, styledfontname, f, base,\n\t\t\t\t  widthflag, showflag, overprint);\n\n\t\t(term->enhanced_flush)();\n\n\t\tfree(styledfontname);\n\t\tfree(localfontname);\n\n\t\tbreak;\n\t    } /* case '{' */\n\tcase '@' :\n\t    /*{{{  phantom box - prints next 'char', then restores currentpoint */\n\t    (term->enhanced_flush)();\n\t    (term->enhanced_open)(fontname, fontsize, base, widthflag, showflag, 3);\n\t    p = enhanced_recursion(++p, FALSE, fontname, fontsize, base,\n\t\t\t      widthflag, showflag, overprint);\n\t    (term->enhanced_open)(fontname, fontsize, base, widthflag, showflag, 4);\n\t    break;\n\t    /*}}}*/\n\n\tcase '&' :\n\t    /*{{{  character skip - skips space equal to length of character(s) */\n\t    (term->enhanced_flush)();\n\n\t    p = enhanced_recursion(++p, FALSE, fontname, fontsize, base,\n\t\t\t      widthflag, FALSE, overprint);\n\t    break;\n\t    /*}}}*/\n\n\tcase '~' :\n\t    /*{{{ overprinted text */\n\t    /* the second string is overwritten on the first, centered\n\t     * horizontally on the first and (optionally) vertically\n\t     * shifted by an amount specified (as a fraction of the\n\t     * current fontsize) at the beginning of the second string\n\n\t     * Note that in this implementation neither the under- nor\n\t     * overprinted string can contain syntax that would result\n\t     * in additional recursions -- no subscripts,\n\t     * superscripts, or anything else, with the exception of a\n\t     * font definition at the beginning of the text */\n\n\t    (term->enhanced_flush)();\n\t    p = enhanced_recursion(++p, FALSE, fontname, fontsize, base,\n\t\t\t      widthflag, showflag, 1);\n\t    (term->enhanced_flush)();\n\t    if (!*p)\n\t        break;\n\t    p = enhanced_recursion(++p, FALSE, fontname, fontsize, base,\n\t\t\t      FALSE, showflag, 2);\n\n\t    overprint = 0;   /* may not be necessary, but just in case . . . */\n\t    break;\n\t    /*}}}*/\n\n\tcase '('  :\n\tcase ')'  :\n\t    /*{{{  an escape and print it */\n\t    /* special cases */\n\t    (term->enhanced_open)(fontname, fontsize, base, widthflag, showflag, overprint);\n\t    if (term->flags & TERM_IS_POSTSCRIPT)\n\t\t(term->enhanced_writec)('\\\\');\n\t    (term->enhanced_writec)(*p);\n\t    break;\n\t    /*}}}*/\n\n\tcase '\\\\'  :\n\t    /*{{{  various types of escape sequences, some context-dependent */\n\t    (term->enhanced_open)(fontname, fontsize, base, widthflag, showflag, overprint);\n\n\t    /*     Unicode represented as \\U+hhhhh where hhhhh is hexadecimal code point.\n\t     *     For UTF-8 encoding we translate hhhhh to a UTF-8 byte sequence and\n\t     *     output the bytes one by one.\n\t     */\n\t    if (p[1] == 'U' && p[2] == '+') {\n\t\tif (encoding == S_ENC_UTF8) {\n\t\t    uint32_t codepoint;\n\t\t    unsigned char utf8char[8];\n\t\t    int i, length;\n\n\t\t    sscanf(&(p[3]), \"%5x\", &codepoint);\n\t\t    length = ucs4toutf8(codepoint, utf8char);\n\t\t    p += (codepoint > 0xFFFF) ? 7 : 6;\n\t\t    for (i=0; i<length; i++)\n\t\t\t(term->enhanced_writec)(utf8char[i]);\n\t\t    break;\n\t\t}\n\n\t    /*     FIXME: non-utf8 environments not yet supported.\n\t     *     Note that some terminals may have an alternative way to handle unicode\n\t     *     escape sequences that is not dependent on encoding.\n\t     *     E.g. svg and html output could convert to xml sequences &#xhhhh;\n\t     *     For these cases we must retain the leading backslash so that the\n\t     *     unicode escape sequence can be recognized by the terminal driver.\n\t     */\n\t\t(term->enhanced_writec)(p[0]);\n\t\tbreak;\n\t    }\n\n\t    /* Enhanced mode always uses \\xyz as an octal character representation\n\t     * but each terminal type must give us the actual output format wanted.\n\t     * pdf.trm wants the raw character code, which is why we use strtol();\n\t     * most other terminal types want some variant of \"\\\\%o\".\n\t     */\n\t    if (p[1] >= '0' && p[1] <= '7') {\n\t\tchar *e, escape[16], octal[4] = {'\\0','\\0','\\0','\\0'};\n\n\t\toctal[0] = *(++p);\n\t\tif (p[1] >= '0' && p[1] <= '7') {\n\t\t    octal[1] = *(++p);\n\t\t    if (p[1] >= '0' && p[1] <= '7')\n\t\t\toctal[2] = *(++p);\n\t\t}\n\t\tsprintf(escape, enhanced_escape_format, strtol(octal,NULL,8));\n\t\tfor (e=escape; *e; e++) {\n\t\t    (term->enhanced_writec)(*e);\n\t\t}\n\t\tbreak;\n\t    }\n\n\t    /* This was the original (prior to version 4) enhanced text code specific\n\t     * to the reserved characters of PostScript.\n\t     */\n\t    if (term->flags & TERM_IS_POSTSCRIPT) {\n\t\tif (p[1]=='\\\\' || p[1]=='(' || p[1]==')') {\n\t\t    (term->enhanced_writec)('\\\\');\n\t\t} else if (strchr(\"^_@&~{}\",p[1]) == NULL) {\n\t\t    (term->enhanced_writec)('\\\\');\n\t\t    (term->enhanced_writec)('\\\\');\n\t\t    break;\n\t\t}\n\t    }\n\n\t    /* Step past the backslash character in the input stream */\n\t    ++p;\n\n\t    /* HBB: Avoid broken output if there's a \\ exactly at the end of the line */\n\t    if (*p == '\\0') {\n\t\tint_warn(NO_CARET, \"enhanced text parser -- spurious backslash\");\n\t\tbreak;\n\t    }\n\n\t    /* SVG requires an escaped '&' to be passed as something else */\n\t    /* FIXME: terminal-dependent code does not belong here */\n\t    if (*p == '&' && encoding == S_ENC_DEFAULT && !strcmp(term->name, \"svg\")) {\n\t\t(term->enhanced_writec)('\\376');\n\t\tbreak;\n\t    }\n\n\t    /* print the character following the backslash */\n\t    (term->enhanced_writec)(*p);\n\t    break;\n\t    /*}}}*/\n\n\tdefault:\n\t    /*{{{  print it */\n\t    (term->enhanced_open)(fontname, fontsize, base, widthflag, showflag, overprint);\n\t    (term->enhanced_writec)(*p);\n\t    /*}}}*/\n\t} /* switch (*p) */\n\n\t/* like TeX, we only do one character in a recursion, unless it's\n\t * in braces\n\t */\n\n\tif (!brace) {\n\t    (term->enhanced_flush)();\n\t    return(p);  /* the ++p in the outer copy will increment us */\n\t}\n\n\tif (*p) /* only not true if { not terminated, I think */\n\t    ++p;\n    } /* while (*p) */\n\n    (term->enhanced_flush)();\n    return p;\n}",
        "func_hash": 220071254976249587289701639503776454504,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2020-25412",
        "cve_desc": "com_line() in command.c in gnuplot 5.4 leads to an out-of-bounds-write from strncpy() that may lead to arbitrary code execution.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2020-25412",
        "func_name": "enhanced_recursion",
        "diff": [
            "diff --git a/src/term.c b/src/term.c\nindex fb99a9a6f..7fd46fa04 100644\n--- a/src/term.c\n+++ b/src/term.c\n@@ -2175,7 +2175,7 @@ enhanced_recursion(\n \t\t\t    ++p;\n \t\t\tif (*p != *start_of_fontname) {\n \t\t\t    int_warn(NO_CARET, \"cannot interpret font name %s\", start_of_fontname);\n-\t\t\t    p = start_of_fontname;\n+\t\t\t    p = start_of_fontname + 1;\n \t\t\t}\n \t\t\tstart_of_fontname++;\n \t\t\tend_of_fontname = p++;\n"
        ],
        "func_after": []
    },
    {
        "idx": 216904,
        "project": "server",
        "commit_id": "2e7891080667c59ac80f788eef4d59d447595772",
        "project_url": "https://github.com/MariaDB/server",
        "commit_url": "https://github.com/MariaDB/server/commit/2e7891080667c59ac80f788eef4d59d447595772",
        "commit_message": "MDEV-25635 Assertion failure when pushing from HAVING into WHERE of view\n\nThis bug could manifest itself after pushing a where condition over a\nmergeable derived table / view / CTE DT into a grouping view / derived\ntable / CTE V whose item list contained set functions with constant\narguments such as MIN(2), SUM(1) etc. In such cases the field references\nused in the condition pushed into the view V that correspond set functions\nare wrapped into Item_direct_view_ref wrappers. Due to a wrong implementation\nof the virtual method const_item() for the class Item_direct_view_ref the\nwrapped set functions with constant arguments could be erroneously taken\nfor constant items. This could lead to a wrong result set returned by the\nmain select query in 10.2. In 10.4 where a possibility of pushing condition\nfrom HAVING into WHERE had been added this could cause a crash.\n\nApproved by Sergey Petrunya <sergey.petrunya@mariadb.com>",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  bool const_item() const { return used_tables() == 0; }",
        "func_hash": 52700246065121489756672133081907986383,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-617"
        ],
        "cve": "CVE-2021-46666",
        "cve_desc": "MariaDB before 10.6.2 allows an application crash because of mishandling of a pushdown from a HAVING clause to a WHERE clause.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-46666",
        "func_name": "const_item",
        "diff": [
            "diff --git a/mysql-test/r/derived_cond_pushdown.result b/mysql-test/r/derived_cond_pushdown.result\nindex 25237aa11a98d..28532ae88a437 100644\n--- a/mysql-test/r/derived_cond_pushdown.result\n+++ b/mysql-test/r/derived_cond_pushdown.result\n@@ -10634,4 +10634,43 @@ m\n 7\n drop view v1;\n drop table t1;\n+#\n+# MDEV-25635: pushdown into grouping view using aggregate functions\n+#             with constant arguments via a mergeable derived table\n+#\n+create table t1 (a int);\n+insert into t1 values (3), (7), (1), (3), (7), (7), (3);\n+create view v1 as select a, sum(1) as f, sum(1) as g from t1 group by a;\n+select * from v1;\n+a\tf\tg\n+1\t1\t1\n+3\t3\t3\n+7\t3\t3\n+select * from (select * from v1) as dt where a=f and a=g;\n+a\tf\tg\n+1\t1\t1\n+3\t3\t3\n+explain extended select * from (select * from v1) as dt where a=f and a=g;\n+id\tselect_type\ttable\ttype\tpossible_keys\tkey\tkey_len\tref\trows\tfiltered\tExtra\n+1\tPRIMARY\t<derived3>\tALL\tNULL\tNULL\tNULL\tNULL\t7\t100.00\tUsing where\n+3\tDERIVED\tt1\tALL\tNULL\tNULL\tNULL\tNULL\t7\t100.00\tUsing temporary; Using filesort\n+Warnings:\n+Note\t1003\tselect `v1`.`a` AS `a`,`v1`.`f` AS `f`,`v1`.`g` AS `g` from `test`.`v1` where `v1`.`a` = `v1`.`f` and `v1`.`a` = `v1`.`g`\n+create view v2 as select a, min(1) as f, min(1) as g from t1 group by a;\n+select * from v2;\n+a\tf\tg\n+1\t1\t1\n+3\t1\t1\n+7\t1\t1\n+select * from (select * from v2) as dt where a=f and a=g;\n+a\tf\tg\n+1\t1\t1\n+explain extended select * from (select * from v2) as dt where a=f and a=g;\n+id\tselect_type\ttable\ttype\tpossible_keys\tkey\tkey_len\tref\trows\tfiltered\tExtra\n+1\tPRIMARY\t<derived3>\tALL\tNULL\tNULL\tNULL\tNULL\t7\t100.00\tUsing where\n+3\tDERIVED\tt1\tALL\tNULL\tNULL\tNULL\tNULL\t7\t100.00\tUsing temporary; Using filesort\n+Warnings:\n+Note\t1003\tselect `v2`.`a` AS `a`,`v2`.`f` AS `f`,`v2`.`g` AS `g` from `test`.`v2` where `v2`.`f` = `v2`.`a` and `v2`.`g` = `v2`.`a`\n+drop view v1,v2;\n+drop table t1;\n # End of 10.2 tests\ndiff --git a/mysql-test/t/derived_cond_pushdown.test b/mysql-test/t/derived_cond_pushdown.test\nindex 31b49047bf1b8..58f38ac1e5aa9 100644\n--- a/mysql-test/t/derived_cond_pushdown.test\n+++ b/mysql-test/t/derived_cond_pushdown.test\n@@ -2212,4 +2212,29 @@ select * from v1 where m > 0;\n drop view v1;\n drop table t1;\n \n+--echo #\n+--echo # MDEV-25635: pushdown into grouping view using aggregate functions\n+--echo #             with constant arguments via a mergeable derived table\n+--echo #\n+\n+create table t1 (a int);\n+insert into t1 values (3), (7), (1), (3), (7), (7), (3);\n+\n+create view v1 as select a, sum(1) as f, sum(1) as g from t1 group by a;\n+select * from v1;\n+let $q1=\n+select * from (select * from v1) as dt where a=f and a=g;\n+eval $q1;\n+eval explain extended $q1;\n+\n+create view v2 as select a, min(1) as f, min(1) as g from t1 group by a;\n+select * from v2;\n+let $q2=\n+select * from (select * from v2) as dt where a=f and a=g;\n+eval $q2;\n+eval explain extended $q2;\n+\n+drop view v1,v2;\n+drop table t1;\n+\n --echo # End of 10.2 tests\ndiff --git a/sql/item.h b/sql/item.h\nindex c94709c733e3b..76be66d2a7c6c 100644\n--- a/sql/item.h\n+++ b/sql/item.h\n@@ -4952,7 +4952,10 @@ class Item_direct_view_ref :public Item_direct_ref\n   table_map used_tables() const;\n   void update_used_tables();\n   table_map not_null_tables() const;\n-  bool const_item() const { return used_tables() == 0; }\n+  bool const_item() const\n+  {\n+    return (*ref)->const_item() && (null_ref_table == NO_NULL_TABLE);\n+  }\n   TABLE *get_null_ref_table() const { return null_ref_table; }\n   bool walk(Item_processor processor, bool walk_subquery, void *arg)\n   { \n"
        ],
        "func_after": []
    },
    {
        "idx": 216967,
        "project": "server",
        "commit_id": "0beed9b5e933f0ff79b3bb346524f7a451d14e38",
        "project_url": "https://github.com/MariaDB/server",
        "commit_url": "https://github.com/MariaDB/server/commit/0beed9b5e933f0ff79b3bb346524f7a451d14e38",
        "commit_message": "MDEV-28097 use-after-free when WHERE has subquery with an outer reference in HAVING\n\nwhen resolving WHERE and ON clauses, do not look in\nSELECT list/aliases.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "int setup_conds(THD *thd, TABLE_LIST *tables, List<TABLE_LIST> &leaves,\n                COND **conds)\n{\n  SELECT_LEX *select_lex= thd->lex->current_select;\n  TABLE_LIST *table= NULL;\t// For HP compilers\n  /*\n    it_is_update set to TRUE when tables of primary SELECT_LEX (SELECT_LEX\n    which belong to LEX, i.e. most up SELECT) will be updated by\n    INSERT/UPDATE/LOAD\n    NOTE: using this condition helps to prevent call of prepare_check_option()\n    from subquery of VIEW, because tables of subquery belongs to VIEW\n    (see condition before prepare_check_option() call)\n  */\n  bool it_is_update= (select_lex == thd->lex->first_select_lex()) &&\n    thd->lex->which_check_option_applicable();\n  bool save_is_item_list_lookup= select_lex->is_item_list_lookup;\n  TABLE_LIST *derived= select_lex->master_unit()->derived;\n  DBUG_ENTER(\"setup_conds\");\n\n  select_lex->is_item_list_lookup= 0;\n\n  thd->column_usage= MARK_COLUMNS_READ;\n  DBUG_PRINT(\"info\", (\"thd->column_usage: %d\", thd->column_usage));\n  select_lex->cond_count= 0;\n  select_lex->between_count= 0;\n  select_lex->max_equal_elems= 0;\n\n  for (table= tables; table; table= table->next_local)\n  {\n    if (select_lex == thd->lex->first_select_lex() &&\n        select_lex->first_cond_optimization &&\n        table->merged_for_insert &&\n        table->prepare_where(thd, conds, FALSE))\n      goto err_no_arena;\n  }\n\n  if (*conds)\n  {\n    thd->where=\"where clause\";\n    DBUG_EXECUTE(\"where\",\n                 print_where(*conds,\n                             \"WHERE in setup_conds\",\n                             QT_ORDINARY););\n    /*\n      Wrap alone field in WHERE clause in case it will be outer field of subquery\n      which need persistent pointer on it, but conds could be changed by optimizer\n    */\n    if ((*conds)->type() == Item::FIELD_ITEM && !derived)\n      wrap_ident(thd, conds);\n    (*conds)->mark_as_condition_AND_part(NO_JOIN_NEST);\n    if ((*conds)->fix_fields_if_needed_for_bool(thd, conds))\n      goto err_no_arena;\n  }\n\n  /*\n    Apply fix_fields() to all ON clauses at all levels of nesting,\n    including the ones inside view definitions.\n  */\n  if (setup_on_expr(thd, tables, it_is_update))\n    goto err_no_arena;\n\n  if (!thd->stmt_arena->is_conventional())\n  {\n    /*\n      We are in prepared statement preparation code => we should store\n      WHERE clause changing for next executions.\n\n      We do this ON -> WHERE transformation only once per PS/SP statement.\n    */\n    select_lex->where= *conds;\n  }\n  thd->lex->current_select->is_item_list_lookup= save_is_item_list_lookup;\n  DBUG_RETURN(thd->is_error());\n\nerr_no_arena:\n  select_lex->is_item_list_lookup= save_is_item_list_lookup;\n  DBUG_RETURN(1);\n}",
        "func_hash": 244305677857068716399838865539882516778,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-416"
        ],
        "cve": "CVE-2022-27455",
        "cve_desc": "MariaDB Server v10.6.3 and below was discovered to contain an use-after-free in the component my_wildcmp_8bit_impl at /strings/ctype-simple.c.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-27455",
        "func_name": "setup_conds",
        "diff": [
            "diff --git a/mysql-test/main/having.result b/mysql-test/main/having.result\nindex 8800402dc356f..b4ca607ec8483 100644\n--- a/mysql-test/main/having.result\n+++ b/mysql-test/main/having.result\n@@ -279,11 +279,7 @@ select t1.col1 as tmp_col from t1\n where t1.col2 in \n (select t2.col2 from t2 \n group by t2.col1, t2.col2 having tmp_col <= 10);\n-tmp_col\n-10\n-10\n-10\n-10\n+ERROR 42S22: Unknown column 'tmp_col' in 'having clause'\n select t1.col1 from t1\n where t1.col2 in \n (select t2.col2 from t2 \ndiff --git a/mysql-test/main/having.test b/mysql-test/main/having.test\nindex b3b128684a34b..3f4e8a8e71009 100644\n--- a/mysql-test/main/having.test\n+++ b/mysql-test/main/having.test\n@@ -249,7 +249,8 @@ where t1.col2 in\n        group by t2.col1, t2.col2 having t1.col1 <= 10);\n \n # the having column is resolved in the SELECT clause of the outer query -\n-# error in ANSI, works with MySQL extension\n+# error in ANSI\n+--error ER_BAD_FIELD_ERROR\n select t1.col1 as tmp_col from t1\n where t1.col2 in \n       (select t2.col2 from t2 \ndiff --git a/mysql-test/main/subselect_innodb.result b/mysql-test/main/subselect_innodb.result\nindex ae22329f62a83..467ed218198b9 100644\n--- a/mysql-test/main/subselect_innodb.result\n+++ b/mysql-test/main/subselect_innodb.result\n@@ -667,5 +667,17 @@ execute stmt;\n a\tb\n drop table t1,t2;\n #\n+# MDEV-28097 use-after-free when WHERE has subquery with an outer reference in HAVING\n+#\n+create table t1 (a text(60) not null) engine=innodb;\n+insert into t1 values ('1'),('0');\n+select distinct a from t1 where '' in (select 'x' like a having a like a);\n+a\n+1\n+0\n+Warnings:\n+Warning\t1292\tTruncated incorrect DOUBLE value: ''\n+drop table t1;\n+#\n # End of 10.4 tests\n #\ndiff --git a/mysql-test/main/subselect_innodb.test b/mysql-test/main/subselect_innodb.test\nindex e767891c8db76..8ff3a5acf7d18 100644\n--- a/mysql-test/main/subselect_innodb.test\n+++ b/mysql-test/main/subselect_innodb.test\n@@ -658,6 +658,14 @@ execute stmt;\n \n drop table t1,t2;\n \n+--echo #\n+--echo # MDEV-28097 use-after-free when WHERE has subquery with an outer reference in HAVING\n+--echo #\n+create table t1 (a text(60) not null) engine=innodb;\n+insert into t1 values ('1'),('0');\n+select distinct a from t1 where '' in (select 'x' like a having a like a);\n+drop table t1;\n+\n --echo #\n --echo # End of 10.4 tests\n --echo #\ndiff --git a/sql/sql_base.cc b/sql/sql_base.cc\nindex 14b97b4366098..ef7a075e30401 100644\n--- a/sql/sql_base.cc\n+++ b/sql/sql_base.cc\n@@ -8398,9 +8398,11 @@ int setup_conds(THD *thd, TABLE_LIST *tables, List<TABLE_LIST> &leaves,\n     thd->lex->which_check_option_applicable();\n   bool save_is_item_list_lookup= select_lex->is_item_list_lookup;\n   TABLE_LIST *derived= select_lex->master_unit()->derived;\n+  bool save_resolve_in_select_list= select_lex->context.resolve_in_select_list;\n   DBUG_ENTER(\"setup_conds\");\n \n   select_lex->is_item_list_lookup= 0;\n+  select_lex->context.resolve_in_select_list= false;\n \n   thd->column_usage= MARK_COLUMNS_READ;\n   DBUG_PRINT(\"info\", (\"thd->column_usage: %d\", thd->column_usage));\n@@ -8453,6 +8455,7 @@ int setup_conds(THD *thd, TABLE_LIST *tables, List<TABLE_LIST> &leaves,\n     select_lex->where= *conds;\n   }\n   thd->lex->current_select->is_item_list_lookup= save_is_item_list_lookup;\n+  select_lex->context.resolve_in_select_list= save_resolve_in_select_list;\n   DBUG_RETURN(thd->is_error());\n \n err_no_arena:\n"
        ],
        "func_after": []
    },
    {
        "idx": 216983,
        "project": "qemu",
        "commit_id": "418ade7849ce7641c0f7333718caf5091a02fd4c",
        "project_url": "https://github.com/bonzini/qemu",
        "commit_url": "https://github.com/qemu/qemu/commit/418ade7849ce7641c0f7333718caf5091a02fd4c",
        "commit_message": "softmmu: Always initialize xlat in address_space_translate_for_iotlb\n\nThe bug is an uninitialized memory read, along the translate_fail\npath, which results in garbage being read from iotlb_to_section,\nwhich can lead to a crash in io_readx/io_writex.\n\nThe bug may be fixed by writing any value with zero\nin ~TARGET_PAGE_MASK, so that the call to iotlb_to_section using\nthe xlat'ed address returns io_mem_unassigned, as desired by the\ntranslate_fail path.\n\nIt is most useful to record the original physical page address,\nwhich will eventually be logged by memory_region_access_valid\nwhen the access is rejected by unassigned_mem_accepts.\n\nResolves: https://gitlab.com/qemu-project/qemu/-/issues/1065\nSigned-off-by: Richard Henderson <richard.henderson@linaro.org>\nReviewed-by: Peter Maydell <peter.maydell@linaro.org>\nMessage-Id: <20220621153829.366423-1-richard.henderson@linaro.org>",
        "target": 1,
        "irrelevant": 0,
        "func_before": "address_space_translate_for_iotlb(CPUState *cpu, int asidx, hwaddr addr,\n                                  hwaddr *xlat, hwaddr *plen,\n                                  MemTxAttrs attrs, int *prot)\n{\n    MemoryRegionSection *section;\n    IOMMUMemoryRegion *iommu_mr;\n    IOMMUMemoryRegionClass *imrc;\n    IOMMUTLBEntry iotlb;\n    int iommu_idx;\n    AddressSpaceDispatch *d =\n        qatomic_rcu_read(&cpu->cpu_ases[asidx].memory_dispatch);\n\n    for (;;) {\n        section = address_space_translate_internal(d, addr, &addr, plen, false);\n\n        iommu_mr = memory_region_get_iommu(section->mr);\n        if (!iommu_mr) {\n            break;\n        }\n\n        imrc = memory_region_get_iommu_class_nocheck(iommu_mr);\n\n        iommu_idx = imrc->attrs_to_index(iommu_mr, attrs);\n        tcg_register_iommu_notifier(cpu, iommu_mr, iommu_idx);\n        /* We need all the permissions, so pass IOMMU_NONE so the IOMMU\n         * doesn't short-cut its translation table walk.\n         */\n        iotlb = imrc->translate(iommu_mr, addr, IOMMU_NONE, iommu_idx);\n        addr = ((iotlb.translated_addr & ~iotlb.addr_mask)\n                | (addr & iotlb.addr_mask));\n        /* Update the caller's prot bits to remove permissions the IOMMU\n         * is giving us a failure response for. If we get down to no\n         * permissions left at all we can give up now.\n         */\n        if (!(iotlb.perm & IOMMU_RO)) {\n            *prot &= ~(PAGE_READ | PAGE_EXEC);\n        }\n        if (!(iotlb.perm & IOMMU_WO)) {\n            *prot &= ~PAGE_WRITE;\n        }\n\n        if (!*prot) {\n            goto translate_fail;\n        }\n\n        d = flatview_to_dispatch(address_space_to_flatview(iotlb.target_as));\n    }\n\n    assert(!memory_region_is_iommu(section->mr));\n    *xlat = addr;\n    return section;\n\ntranslate_fail:\n    return &d->map.sections[PHYS_SECTION_UNASSIGNED];\n}",
        "func_hash": 119842489623736981380410642519747422328,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-908"
        ],
        "cve": "CVE-2022-35414",
        "cve_desc": "softmmu/physmem.c in QEMU through 7.0.0 can perform an uninitialized read on the translate_fail path, leading to an io_readx or io_writex crash. NOTE: a third party states that the Non-virtualization Use Case in the qemu.org reference applies here, i.e., \"Bugs affecting the non-virtualization use case are not considered security bugs at this time.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-35414",
        "func_name": "address_space_translate_for_iotlb",
        "diff": [
            "diff --git a/softmmu/physmem.c b/softmmu/physmem.c\nindex fb16be57a6c6..dc3c3e5f2e70 100644\n--- a/softmmu/physmem.c\n+++ b/softmmu/physmem.c\n@@ -669,7 +669,7 @@ void tcg_iommu_init_notifier_list(CPUState *cpu)\n \n /* Called from RCU critical section */\n MemoryRegionSection *\n-address_space_translate_for_iotlb(CPUState *cpu, int asidx, hwaddr addr,\n+address_space_translate_for_iotlb(CPUState *cpu, int asidx, hwaddr orig_addr,\n                                   hwaddr *xlat, hwaddr *plen,\n                                   MemTxAttrs attrs, int *prot)\n {\n@@ -678,6 +678,7 @@ address_space_translate_for_iotlb(CPUState *cpu, int asidx, hwaddr addr,\n     IOMMUMemoryRegionClass *imrc;\n     IOMMUTLBEntry iotlb;\n     int iommu_idx;\n+    hwaddr addr = orig_addr;\n     AddressSpaceDispatch *d =\n         qatomic_rcu_read(&cpu->cpu_ases[asidx].memory_dispatch);\n \n@@ -722,6 +723,16 @@ address_space_translate_for_iotlb(CPUState *cpu, int asidx, hwaddr addr,\n     return section;\n \n translate_fail:\n+    /*\n+     * We should be given a page-aligned address -- certainly\n+     * tlb_set_page_with_attrs() does so.  The page offset of xlat\n+     * is used to index sections[], and PHYS_SECTION_UNASSIGNED = 0.\n+     * The page portion of xlat will be logged by memory_region_access_valid()\n+     * when this memory access is rejected, so use the original untranslated\n+     * physical address.\n+     */\n+    assert((orig_addr & ~TARGET_PAGE_MASK) == 0);\n+    *xlat = orig_addr;\n     return &d->map.sections[PHYS_SECTION_UNASSIGNED];\n }\n \n"
        ],
        "func_after": []
    },
    {
        "idx": 217129,
        "project": "bootstrap-dht",
        "commit_id": "e809ea80e3527e32c40756eddd8b2ae44bc3af1a",
        "project_url": "https://github.com/bittorrent/bootstrap-dht",
        "commit_url": "https://github.com/bittorrent/bootstrap-dht/commit/e809ea80e3527e32c40756eddd8b2ae44bc3af1a",
        "commit_message": "Check for out-of-bounds bencoded lengths before advancing buffer pointer",
        "target": 1,
        "irrelevant": 0,
        "func_before": "\tint lazy_bdecode(char const* start, char const* end, lazy_entry& ret\n\t\t, error_code& ec, int* error_pos, int depth_limit, int item_limit)\n\t{\n\t\tchar const* const orig_start = start;\n\t\tret.clear();\n\t\tif (start == end) return 0;\n\n\t\tstd::vector<lazy_entry*> stack;\n\n\t\tstack.push_back(&ret);\n\t\twhile (start <= end)\n\t\t{\n\t\t\tif (stack.empty()) break; // done!\n\n\t\t\tlazy_entry* top = stack.back();\n\n\t\t\tif (int(stack.size()) > depth_limit) TORRENT_FAIL_BDECODE(bdecode_errors::depth_exceeded);\n\t\t\tif (start >= end) TORRENT_FAIL_BDECODE(bdecode_errors::unexpected_eof);\n\t\t\tchar t = *start;\n\t\t\t++start;\n\t\t\tif (start >= end && t != 'e') TORRENT_FAIL_BDECODE(bdecode_errors::unexpected_eof);\n\n\t\t\tswitch (top->type())\n\t\t\t{\n\t\t\t\tcase lazy_entry::dict_t:\n\t\t\t\t{\n\t\t\t\t\tif (t == 'e')\n\t\t\t\t\t{\n\t\t\t\t\t\ttop->set_end(start);\n\t\t\t\t\t\tstack.pop_back();\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t\tif (!numeric(t)) TORRENT_FAIL_BDECODE(bdecode_errors::expected_string);\n\t\t\t\t\tboost::int64_t len = t - '0';\n\t\t\t\t\tbdecode_errors::error_code_enum e = bdecode_errors::no_error;\n\t\t\t\t\tstart = parse_int(start, end, ':', len, e);\n\t\t\t\t\tif (e)\n\t\t\t\t\t\tTORRENT_FAIL_BDECODE(e);\n\n\t\t\t\t\tif (start + len + 1 > end)\n\t\t\t\t\t\tTORRENT_FAIL_BDECODE(bdecode_errors::unexpected_eof);\n\n\t\t\t\t\tif (len < 0)\n\t\t\t\t\t\tTORRENT_FAIL_BDECODE(bdecode_errors::overflow);\n\n\t\t\t\t\t++start;\n\t\t\t\t\tif (start == end) TORRENT_FAIL_BDECODE(bdecode_errors::unexpected_eof);\n\t\t\t\t\tlazy_entry* ent = top->dict_append(start);\n\t\t\t\t\tif (ent == 0) TORRENT_FAIL_BDECODE(boost::system::errc::not_enough_memory);\n\t\t\t\t\tstart += len;\n\t\t\t\t\tif (start >= end) TORRENT_FAIL_BDECODE(bdecode_errors::unexpected_eof);\n\t\t\t\t\tstack.push_back(ent);\n\t\t\t\t\tt = *start;\n\t\t\t\t\t++start;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tcase lazy_entry::list_t:\n\t\t\t\t{\n\t\t\t\t\tif (t == 'e')\n\t\t\t\t\t{\n\t\t\t\t\t\ttop->set_end(start);\n\t\t\t\t\t\tstack.pop_back();\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t\tlazy_entry* ent = top->list_append();\n\t\t\t\t\tif (ent == 0) TORRENT_FAIL_BDECODE(boost::system::errc::not_enough_memory);\n\t\t\t\t\tstack.push_back(ent);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tdefault: break;\n\t\t\t}\n\n\t\t\t--item_limit;\n\t\t\tif (item_limit <= 0) TORRENT_FAIL_BDECODE(bdecode_errors::limit_exceeded);\n\n\t\t\ttop = stack.back();\n\t\t\tswitch (t)\n\t\t\t{\n\t\t\t\tcase 'd':\n\t\t\t\t\ttop->construct_dict(start - 1);\n\t\t\t\t\tcontinue;\n\t\t\t\tcase 'l':\n\t\t\t\t\ttop->construct_list(start - 1);\n\t\t\t\t\tcontinue;\n\t\t\t\tcase 'i':\n\t\t\t\t{\n\t\t\t\t\tchar const* int_start = start;\n\t\t\t\t\tstart = find_char(start, end, 'e');\n\t\t\t\t\ttop->construct_int(int_start, start - int_start);\n\t\t\t\t\tif (start == end) TORRENT_FAIL_BDECODE(bdecode_errors::unexpected_eof);\n\t\t\t\t\tTORRENT_ASSERT(*start == 'e');\n\t\t\t\t\t++start;\n\t\t\t\t\tstack.pop_back();\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tdefault:\n\t\t\t\t{\n\t\t\t\t\tif (!numeric(t))\n\t\t\t\t\t\tTORRENT_FAIL_BDECODE(bdecode_errors::expected_value);\n\n\t\t\t\t\tboost::int64_t len = t - '0';\n\t\t\t\t\tbdecode_errors::error_code_enum e = bdecode_errors::no_error;\n\t\t\t\t\tstart = parse_int(start, end, ':', len, e);\n\t\t\t\t\tif (e)\n\t\t\t\t\t\tTORRENT_FAIL_BDECODE(e);\n\t\t\t\t\tif (start + len + 1 > end)\n\t\t\t\t\t\tTORRENT_FAIL_BDECODE(bdecode_errors::unexpected_eof);\n\t\t\t\t\tif (len < 0)\n\t\t\t\t\t\tTORRENT_FAIL_BDECODE(bdecode_errors::overflow);\n\n\t\t\t\t\t++start;\n\t\t\t\t\ttop->construct_string(start, int(len));\n\t\t\t\t\tstack.pop_back();\n\t\t\t\t\tstart += len;\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn 0;\n\t\t}\n\t\treturn 0;\n\t}",
        "func_hash": 26854422676906062381139387440560031690,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-20"
        ],
        "cve": "CVE-2015-5685",
        "cve_desc": "The lazy_bdecode function in BitTorrent DHT bootstrap server (bootstrap-dht ) allows remote attackers to execute arbitrary code via a crafted packet, related to \"improper indexing.\"",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2015-5685",
        "func_name": "lazy_bdecode",
        "diff": [
            "diff --git a/lazy_bdecode.cpp b/lazy_bdecode.cpp\nindex 0f7b292..fe6cb67 100644\n--- a/lazy_bdecode.cpp\n+++ b/lazy_bdecode.cpp\n@@ -150,7 +150,9 @@ namespace libtorrent\n \t\t\t\t\tif (e)\n \t\t\t\t\t\tTORRENT_FAIL_BDECODE(e);\n \n-\t\t\t\t\tif (start + len + 1 > end)\n+\t\t\t\t\t// remaining buffer size excluding ':'\n+\t\t\t\t\tconst ptrdiff_t buff_size = end - start - 1;\n+\t\t\t\t\tif (len > buff_size)\n \t\t\t\t\t\tTORRENT_FAIL_BDECODE(bdecode_errors::unexpected_eof);\n \n \t\t\t\t\tif (len < 0)\n@@ -216,12 +218,16 @@ namespace libtorrent\n \t\t\t\t\tstart = parse_int(start, end, ':', len, e);\n \t\t\t\t\tif (e)\n \t\t\t\t\t\tTORRENT_FAIL_BDECODE(e);\n-\t\t\t\t\tif (start + len + 1 > end)\n+\n+\t\t\t\t\t// remaining buffer size excluding ':'\n+\t\t\t\t\tconst ptrdiff_t buff_size = end - start - 1;\n+\t\t\t\t\tif (len > buff_size)\n \t\t\t\t\t\tTORRENT_FAIL_BDECODE(bdecode_errors::unexpected_eof);\n \t\t\t\t\tif (len < 0)\n \t\t\t\t\t\tTORRENT_FAIL_BDECODE(bdecode_errors::overflow);\n \n \t\t\t\t\t++start;\n+\t\t\t\t\tif (start == end) TORRENT_FAIL_BDECODE(bdecode_errors::unexpected_eof);\n \t\t\t\t\ttop->construct_string(start, int(len));\n \t\t\t\t\tstack.pop_back();\n \t\t\t\t\tstart += len;\n"
        ],
        "func_after": []
    },
    {
        "idx": 217131,
        "project": "gd-libgd",
        "commit_id": "47eb44b2e90ca88a08dca9f9a1aa9041e9587f43",
        "project_url": "https://bitbucket.org/libgd/gd-libgd",
        "commit_url": "https://bitbucket.org/libgd/gd-libgd/commits/47eb44b2e90ca88a08dca9f9a1aa9041e9587f43",
        "commit_message": "Fix possible buffer read overflow\ndetected by -fsanitize=address, thanks to Jan Bee",
        "target": 1,
        "irrelevant": 1,
        "func_before": "GetCode_(gdIOCtx *fd, CODE_STATIC_DATA *scd, int code_size, int flag, int *ZeroDataBlockP)\n{\n\tint i, j, ret;\n\tunsigned char count;\n\n\tif(flag) {\n\t\tscd->curbit = 0;\n\t\tscd->lastbit = 0;\n\t\tscd->last_byte = 0;\n\t\tscd->done = FALSE;\n\t\treturn 0;\n\t}\n\n\tif((scd->curbit + code_size) >= scd->lastbit) {\n\t\tif(scd->done) {\n\t\t\tif(scd->curbit >= scd->lastbit) {\n\t\t\t\t/* Oh well */\n\t\t\t}\n\t\t\treturn -1;\n\t\t}\n\n\t\tscd->buf[0] = scd->buf[scd->last_byte - 2];\n\t\tscd->buf[1] = scd->buf[scd->last_byte - 1];\n\n\t\tif((count = GetDataBlock(fd, &scd->buf[2], ZeroDataBlockP)) <= 0) {\n\t\t\tscd->done = TRUE;\n\t\t}\n\n\t\tscd->last_byte = 2 + count;\n\t\tscd->curbit = (scd->curbit - scd->lastbit) + 16;\n\t\tscd->lastbit = (2 + count) * 8;\n\t}\n\n\tret = 0;\n\tfor (i = scd->curbit, j = 0; j < code_size; ++i, ++j) {\n\t\tret |= ((scd->buf[i / 8] & (1 << (i % 8))) != 0) << j;\n\t}\n\n\tscd->curbit += code_size;\n\n\treturn ret;\n}",
        "func_hash": 193987119857378962206988893625754622033,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-119"
        ],
        "cve": "CVE-2014-9709",
        "cve_desc": "The GetCode_ function in gd_gif_in.c in GD 2.1.1 and earlier, as used in PHP before 5.5.21 and 5.6.x before 5.6.5, allows remote attackers to cause a denial of service (buffer over-read and application crash) via a crafted GIF image that is improperly handled by the gdImageCreateFromGif function.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2014-9709",
        "func_name": "GetCode_",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 217231,
        "project": "opaque",
        "commit_id": "5ddda15d89f5ac82f4416208c5319ace4aecdc36",
        "project_url": "https://github.com/ucbrise/opaque",
        "commit_url": "https://github.com/ucbrise/opaque/commit/5ddda15d89f5ac82f4416208c5319ace4aecdc36",
        "commit_message": "Check that ecall [user_check] pointers and ocall_malloc result pointer are outside enclave (#67)\n\nThis should reduce the enclave's attack surface by preventing an attacker from invoking ecalls on or triggering unexpected writes to arbitrary enclave memory, which could potentially leak information about that memory or lead to incorrect results.\n\nFixes #36. Fixes #66.",
        "target": 1,
        "irrelevant": 1,
        "func_before": "void ocall_malloc(size_t size, uint8_t **ret) {\n  *ret = static_cast<uint8_t *>(malloc(size));\n}",
        "func_hash": 206657736615012684702820705282863743646,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2018-20742",
        "cve_desc": "An issue was discovered in UC Berkeley RISE Opaque before 2018-12-01. There is no boundary check on ocall_malloc. The return value could be a pointer to enclave memory. It could cause an arbitrary enclave memory write.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2018-20742",
        "func_name": "ocall_malloc",
        "diff": [
            "diff --git a/src/enclave/App/App.cpp b/src/enclave/App/App.cpp\nindex 66dcbbd49b..5d680c2ddd 100644\n--- a/src/enclave/App/App.cpp\n+++ b/src/enclave/App/App.cpp\n@@ -357,7 +357,7 @@ void ocall_print_string(const char *str)\n   fflush(stdout);\n }\n \n-void ocall_malloc(size_t size, uint8_t **ret) {\n+void unsafe_ocall_malloc(size_t size, uint8_t **ret) {\n   *ret = static_cast<uint8_t *>(malloc(size));\n }\n \ndiff --git a/src/enclave/Enclave/Enclave.cpp b/src/enclave/Enclave/Enclave.cpp\nindex bca6918e47..b78a2645fe 100644\n--- a/src/enclave/Enclave/Enclave.cpp\n+++ b/src/enclave/Enclave/Enclave.cpp\n@@ -10,6 +10,7 @@\n #include \"Project.h\"\n #include \"Sort.h\"\n #include \"isv_enclave.h\"\n+#include \"sgx_lfence.h\"\n #include \"util.h\"\n \n // This file contains definitions of the ecalls declared in Enclave.edl. Errors originating within\n@@ -19,6 +20,11 @@\n \n void ecall_encrypt(uint8_t *plaintext, uint32_t plaintext_length,\n                    uint8_t *ciphertext, uint32_t cipher_length) {\n+  // Guard against encrypting or overwriting enclave memory\n+  assert(sgx_is_outside_enclave(plaintext, plaintext_length) == 1);\n+  assert(sgx_is_outside_enclave(ciphertext, cipher_length) == 1);\n+  sgx_lfence();\n+\n   try {\n     // IV (12 bytes) + ciphertext + mac (16 bytes)\n     assert(cipher_length >= plaintext_length + SGX_AESGCM_IV_SIZE + SGX_AESGCM_MAC_SIZE);\n@@ -33,6 +39,10 @@ void ecall_encrypt(uint8_t *plaintext, uint32_t plaintext_length,\n void ecall_project(uint8_t *condition, size_t condition_length,\n                    uint8_t *input_rows, size_t input_rows_length,\n                    uint8_t **output_rows, size_t *output_rows_length) {\n+  // Guard against operating on arbitrary enclave memory\n+  assert(sgx_is_outside_enclave(input_rows, input_rows_length) == 1);\n+  sgx_lfence();\n+\n   try {\n     project(condition, condition_length,\n             input_rows, input_rows_length,\n@@ -45,6 +55,10 @@ void ecall_project(uint8_t *condition, size_t condition_length,\n void ecall_filter(uint8_t *condition, size_t condition_length,\n                   uint8_t *input_rows, size_t input_rows_length,\n                   uint8_t **output_rows, size_t *output_rows_length) {\n+  // Guard against operating on arbitrary enclave memory\n+  assert(sgx_is_outside_enclave(input_rows, input_rows_length) == 1);\n+  sgx_lfence();\n+\n   try {\n     filter(condition, condition_length,\n            input_rows, input_rows_length,\n@@ -56,6 +70,10 @@ void ecall_filter(uint8_t *condition, size_t condition_length,\n \n void ecall_sample(uint8_t *input_rows, size_t input_rows_length,\n                   uint8_t **output_rows, size_t *output_rows_length) {\n+  // Guard against operating on arbitrary enclave memory\n+  assert(sgx_is_outside_enclave(input_rows, input_rows_length) == 1);\n+  sgx_lfence();\n+\n   try {\n     sample(input_rows, input_rows_length,\n            output_rows, output_rows_length);\n@@ -68,6 +86,10 @@ void ecall_find_range_bounds(uint8_t *sort_order, size_t sort_order_length,\n                              uint32_t num_partitions,\n                              uint8_t *input_rows, size_t input_rows_length,\n                              uint8_t **output_rows, size_t *output_rows_length) {\n+  // Guard against operating on arbitrary enclave memory\n+  assert(sgx_is_outside_enclave(input_rows, input_rows_length) == 1);\n+  sgx_lfence();\n+\n   try {\n     find_range_bounds(sort_order, sort_order_length,\n                       num_partitions,\n@@ -83,6 +105,11 @@ void ecall_partition_for_sort(uint8_t *sort_order, size_t sort_order_length,\n                               uint8_t *input_rows, size_t input_rows_length,\n                               uint8_t *boundary_rows, size_t boundary_rows_length,\n                               uint8_t **output_partitions, size_t *output_partition_lengths) {\n+  // Guard against operating on arbitrary enclave memory\n+  assert(sgx_is_outside_enclave(input_rows, input_rows_length) == 1);\n+  assert(sgx_is_outside_enclave(boundary_rows, boundary_rows_length) == 1);\n+  sgx_lfence();\n+\n   try {\n     partition_for_sort(sort_order, sort_order_length,\n                        num_partitions,\n@@ -97,6 +124,10 @@ void ecall_partition_for_sort(uint8_t *sort_order, size_t sort_order_length,\n void ecall_external_sort(uint8_t *sort_order, size_t sort_order_length,\n                          uint8_t *input_rows, size_t input_rows_length,\n                          uint8_t **output_rows, size_t *output_rows_length) {\n+  // Guard against operating on arbitrary enclave memory\n+  assert(sgx_is_outside_enclave(input_rows, input_rows_length) == 1);\n+  sgx_lfence();\n+\n   try {\n     external_sort(sort_order, sort_order_length,\n                   input_rows, input_rows_length,\n@@ -109,6 +140,10 @@ void ecall_external_sort(uint8_t *sort_order, size_t sort_order_length,\n void ecall_scan_collect_last_primary(uint8_t *join_expr, size_t join_expr_length,\n                                      uint8_t *input_rows, size_t input_rows_length,\n                                      uint8_t **output_rows, size_t *output_rows_length) {\n+  // Guard against operating on arbitrary enclave memory\n+  assert(sgx_is_outside_enclave(input_rows, input_rows_length) == 1);\n+  sgx_lfence();\n+\n   try {\n     scan_collect_last_primary(join_expr, join_expr_length,\n                               input_rows, input_rows_length,\n@@ -122,6 +157,11 @@ void ecall_non_oblivious_sort_merge_join(uint8_t *join_expr, size_t join_expr_le\n                                          uint8_t *input_rows, size_t input_rows_length,\n                                          uint8_t *join_row, size_t join_row_length,\n                                          uint8_t **output_rows, size_t *output_rows_length) {\n+  // Guard against operating on arbitrary enclave memory\n+  assert(sgx_is_outside_enclave(input_rows, input_rows_length) == 1);\n+  assert(sgx_is_outside_enclave(join_row, join_row_length) == 1);\n+  sgx_lfence();\n+\n   try {\n     non_oblivious_sort_merge_join(join_expr, join_expr_length,\n                                   input_rows, input_rows_length,\n@@ -138,6 +178,10 @@ void ecall_non_oblivious_aggregate_step1(\n   uint8_t **first_row, size_t *first_row_length,\n   uint8_t **last_group, size_t *last_group_length,\n   uint8_t **last_row, size_t *last_row_length) {\n+  // Guard against operating on arbitrary enclave memory\n+  assert(sgx_is_outside_enclave(input_rows, input_rows_length) == 1);\n+  sgx_lfence();\n+\n   try {\n     non_oblivious_aggregate_step1(\n       agg_op, agg_op_length,\n@@ -157,6 +201,13 @@ void ecall_non_oblivious_aggregate_step2(\n   uint8_t *prev_partition_last_group, size_t prev_partition_last_group_length,\n   uint8_t *prev_partition_last_row, size_t prev_partition_last_row_length,\n   uint8_t **output_rows, size_t *output_rows_length) {\n+  // Guard against operating on arbitrary enclave memory\n+  assert(sgx_is_outside_enclave(input_rows, input_rows_length) == 1);\n+  assert(sgx_is_outside_enclave(next_partition_first_row, next_partition_first_row_length) == 1);\n+  assert(sgx_is_outside_enclave(prev_partition_last_group, prev_partition_last_group_length) == 1);\n+  assert(sgx_is_outside_enclave(prev_partition_last_row, prev_partition_last_row_length) == 1);\n+  sgx_lfence();\n+\n   try {\n     non_oblivious_aggregate_step2(\n       agg_op, agg_op_length,\ndiff --git a/src/enclave/Enclave/Enclave.edl b/src/enclave/Enclave/Enclave.edl\nindex abd2d7f183..d8acfc796b 100644\n--- a/src/enclave/Enclave/Enclave.edl\n+++ b/src/enclave/Enclave/Enclave.edl\n@@ -88,7 +88,18 @@ enclave {\n \n   untrusted {\n     void ocall_print_string([in, string] const char *str);\n-    void ocall_malloc(size_t size, [out] uint8_t **ret);\n+\n+    /**\n+     * Allocate memory outside of the enclave and return the pointer in `ret`.\n+     *\n+     * Before dereferencing the resulting pointer, the caller must check whether it is actually\n+     * outside the enclave using `sgx_is_outside_enclave()`. Otherwise, an attacker could cause the\n+     * enclave to perform unexpected operations on its own memory. The function `ocall_malloc()`\n+     * wraps this function with such a bounds check and most callers should use that function\n+     * instead.\n+     */\n+    void unsafe_ocall_malloc(size_t size, [out] uint8_t **ret);\n+\n     void ocall_free([user_check] uint8_t *buf);\n     void ocall_exit(int exit_code);\n     void ocall_throw([in, string] const char *message);\ndiff --git a/src/enclave/Enclave/util.cpp b/src/enclave/Enclave/util.cpp\nindex 3f514e9d32..ed86392873 100644\n--- a/src/enclave/Enclave/util.cpp\n+++ b/src/enclave/Enclave/util.cpp\n@@ -4,6 +4,7 @@\n #include <cstdio>\n \n #include \"Enclave_t.h\"\n+#include \"sgx_lfence.h\"\n \n int printf(const char *fmt, ...) {\n   char buf[BUFSIZ] = {'\\0'};\n@@ -38,6 +39,14 @@ void exit(int exit_code) {\n   ocall_exit(exit_code);\n }\n \n+void ocall_malloc(size_t size, uint8_t **ret) {\n+  unsafe_ocall_malloc(size, ret);\n+\n+  // Guard against overwriting enclave memory\n+  assert(sgx_is_outside_enclave(*ret, size) == 1);\n+  sgx_lfence();\n+}\n+\n void print_bytes(uint8_t *ptr, uint32_t len) {\n   for (uint32_t i = 0; i < len; i++) {\n     printf(\"%u\", *(ptr + i));\ndiff --git a/src/enclave/Enclave/util.h b/src/enclave/Enclave/util.h\nindex 22bf0f4371..b4e0b52327 100644\n--- a/src/enclave/Enclave/util.h\n+++ b/src/enclave/Enclave/util.h\n@@ -18,6 +18,14 @@ namespace std {\n     using ::exit;\n }\n \n+/**\n+ * Allocate memory outside of the enclave and return the pointer in `ret`.\n+ *\n+ * This is a checked wrapper around `unsafe_ocall_malloc`. The resulting pointer is safe to write\n+ * to.\n+ */\n+void ocall_malloc(size_t size, uint8_t **ret);\n+\n std::string string_format(const std::string &fmt, ...);\n \n void print_bytes(uint8_t *ptr, uint32_t len);\n"
        ],
        "func_after": []
    },
    {
        "idx": 217234,
        "project": "univention-corporate-server",
        "commit_id": "a28053045bd2e778c50ed1acaf4e52e1e34f6e34",
        "project_url": "https://github.com/univention/univention-corporate-server",
        "commit_url": "https://github.com/univention/univention-corporate-server/commit/a28053045bd2e778c50ed1acaf4e52e1e34f6e34",
        "commit_message": "Bug #48427 UDN: Forbid vulnerable GET_DN for VERSION >= 3\n\nUDL using PROTOCOL_3 must no longer use GET_DN but WAIT_DN - if it is\nstill used this is a protocol violation. UDL simply will not get an\nanswer.\n\nWhen UCRV 'notifier/protocol/version is set to 3, any old client still\nusing PROTOCOL_2 will get rejected while negotiating the protocol\nversion, so it is asserted that \"version >= network_procotol_version\".",
        "target": 1,
        "irrelevant": 0,
        "func_before": "int data_on_connection(int fd, callback_remove_handler remove)\n{\n\tint nread;\n\tchar *network_packet;\n\tchar network_line[8192];\n\tchar *p;\n\tunsigned long id;\n\n\tchar string[1024];\n\tunsigned long msg_id = UINT32_MAX;\n\tenum network_protocol version = network_client_get_version(fd);\n\n\tioctl(fd, FIONREAD, &nread);\n\n\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_ALL, \"new connection data = %d\\n\",nread);\n\n\tif(nread == 0)\n\t{\n\t\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_PROCESS, \"%d failed, got 0 close connection to listener \", fd);\n\t\tclose(fd);\n\t\tFD_CLR(fd, &readfds);\n\t\tremove(fd);\n\t\tnetwork_client_dump ();\n\t\treturn 0;\n\t}\n\n\n\tif ( nread >= 8192 ) {\n\n\t\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_ERROR, \"%d failed, more than 8192 close connection to listener \", fd);\n\t\tclose(fd);\n\t\tFD_CLR(fd, &readfds);\n\t\tremove(fd);\n\n\t\treturn 0;\n\t}\n\n\t/* read the whole package */\n\tnetwork_packet=malloc((nread+1) * sizeof(char));\n\tread(fd, network_packet, nread);\n\tnetwork_packet[nread]='\\0';\n\n\tmemset(network_line, 0, 8192);\n\tp=network_packet;\n\tp_sem(sem_id);\n\n\twhile ( get_network_line(p, network_line) ) {\n\n\t\tif ( strlen(network_line) > 0 ) {\n\t\t\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_ALL, \"line = [%s]\",network_line);\n\t\t}\n\n\t\t\n\t\tif ( !strncmp(network_line, \"MSGID: \", strlen(\"MSGID: \")) ) {\n\t\t\t/* read message id  */\n\n\t\t\tmsg_id=strtoul(&(network_line[strlen(\"MSGID: \")]), NULL, 10);\n\n\t\t\tp+=strlen(network_line);\n\n\n\t\t} else if ( !strncmp(network_line, \"Version: \", strlen(\"Version: \")) ) {\n\t\t\tchar *head = network_line, *end;\n\n\t\t\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_ALL, \"RECV: VERSION\");\n\n\t\t\tversion = strtoul(head + 9, &end, 10);\n\t\t\tif (!head[9] || *end)\n\t\t\t\tgoto failed;\n\n\t\t\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_ALL, \"VERSION=%d\", version);\n\n\t\t\tif (version < network_procotol_version) {\n\t\t\t\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_PROCESS, \"Forbidden VERSION=%d < %d, close connection to listener\", version, network_procotol_version);\n\t\t\t\tgoto close;\n\t\t\t} else if (version >= PROTOCOL_LAST) {\n\t\t\t\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_PROCESS, \"Future VERSION=%d\", version);\n\t\t\t\tversion = PROTOCOL_LAST - 1;\n\t\t\t}\n\t\t\tnetwork_client_set_version(fd, version);\n\t\t\t\n\t\t\t/* reset message id */\n\t\t\tmsg_id = UINT32_MAX;\n\n\t\t\tp+=strlen(network_line);\n\n\n\t\t} else if ( !strncmp(network_line, \"Capabilities: \", strlen(\"Capabilities: \")) ) {\n\n\t\t\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_ALL, \"RECV: Capabilities\");\n\n\t\t\tif ( version > PROTOCOL_UNKNOWN ) {\n\n\t\t\t\tmemset(string, 0, sizeof(string));\n\t\t\t\t\n\t\t\t\tsnprintf(string, sizeof(string), \"Version: %d\\nCapabilities: \\n\\n\", version);\n\n\t\t\t\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_ALL, \"SEND: %s\", string);\n\n\t\t\t\twrite(fd, string, strlen(string));\n\n\t\t\t} else {\n\t\t\t\t\n\t\t\t\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_ALL, \"Capabilities recv, but no version line\");\n\t\t\t\t\n\t\t\t}\n\n\t\t\tp+=strlen(network_line);\n\n\n\t\t} else if ( !strncmp(network_line, \"GET_DN \", strlen(\"GET_DN \")) && msg_id != UINT32_MAX && network_client_get_version(fd) > 0) {\n\n\t\t\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_ALL, \"RECV: GET_DN\");\n\n\t\t\tid=strtoul(&(network_line[strlen(\"GET_DN \")]), NULL, 10);\n\n\t\t\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_ALL, \"id: %ld\",id);\n\n\t\t\tif ( id <= notify_last_id.id) {\n\n\t\t\t\tchar *dn_string = NULL;\n\n\t\t\t\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_ALL, \"try to read %ld from cache\", id);\n\n\t\t\t\t/* try to read from cache */\n\t\t\t\tif ( (dn_string = notifier_cache_get(id)) == NULL ) {\n\n\t\t\t\t\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_ALL, \"%ld not found in cache\", id);\n\n\t\t\t\t\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_ALL, \"%ld get one dn\", id);\n\n\t\t\t\t\t/* read from transaction file, because not in cache */\n\t\t\t\t\tif( (dn_string=notify_transcation_get_one_dn ( id )) == NULL ) {\n\n\t\t\t\t\t\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_ALL, \"%ld failed \", id);\n\t\t\t\t\t\t/* TODO: maybe close connection? */\n\n\t\t\t\t\t\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_ERROR, \"%d failed, close connection to listener \", fd);\n\t\t\t\t\t\tclose(fd);\n\t\t\t\t\t\tFD_CLR(fd, &readfds);\n\t\t\t\t\t\tremove(fd);\n\n\t\t\t\t\t\treturn 0;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif ( dn_string != NULL ) {\n\n\t\t\t\t\tsnprintf(string, sizeof(string), \"MSGID: %ld\\n%s\\n\\n\",msg_id,dn_string);\n\n\t\t\t\t\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_ALL, \"--> %d: [%s]\",fd, string);\n\n\t\t\t\t\twrite(fd, string, strlen(string));\n\n\t\t\t\t\tfree(dn_string);\n\n\t\t\t\t}\n\n\n\t\t\t} else {\n\t\t\t\t/* set wanted id */\n\n\t\t\t\tnetwork_client_set_next_id(fd, id);\n\t\t\t\tnetwork_client_set_msg_id(fd, msg_id);\n\n\t\t\t}\n\n\t\t\tp+=strlen(network_line)+1;\n\t\t\tmsg_id = UINT32_MAX;\n\n\t\t} else if (!strncmp(p, \"WAIT_ID \", 8) && msg_id != UINT32_MAX && version >= PROTOCOL_3) {\n\t\t\tchar *head = network_line, *end;\n\t\t\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_ALL, \"RECV: WAIT_ID\");\n\t\t\tid = strtoul(head + 8, &end, 10);\n\t\t\tif (!head[8] || *end)\n\t\t\t\tgoto failed;\n\t\t\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_ALL, \"id: %ld\", id);\n\n\t\t\tif (id <= notify_last_id.id) {\n\t\t\t\tsnprintf(string, sizeof(string), \"MSGID: %ld\\n%ld\\n\\n\", msg_id, notify_last_id.id);\n\t\t\t\twrite(fd, string, strlen(string));\n\t\t\t} else {\n\t\t\t\t/* set wanted id */\n\t\t\t\tnetwork_client_set_next_id(fd, id);\n\t\t\t\tnetwork_client_set_msg_id(fd, msg_id);\n\t\t\t}\n\n\t\t\tp += strlen(network_line) + 1;\n\t\t\tmsg_id = UINT32_MAX;\n\n\t\t} else if ( !strncmp(network_line, \"GET_ID\", strlen(\"GET_ID\")) && msg_id != UINT32_MAX  && network_client_get_version(fd) > 0) {\n\n\t\t\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_ALL, \"RECV: GET_ID\");\n\n\t\t\tmemset(string, 0, sizeof(string));\n\n\t\t\tsnprintf(string, sizeof(string), \"MSGID: %ld\\n%ld\\n\\n\",msg_id,notify_last_id.id);\n\n\t\t\twrite(fd, string, strlen(string));\n\n\t\t\tp+=strlen(network_line)+1;\n\t\t\tmsg_id = UINT32_MAX;\n\n\n\t\t} else if ( !strncmp(network_line, \"GET_SCHEMA_ID\", strlen(\"GET_SCHEMA_ID\")) && msg_id != UINT32_MAX  && network_client_get_version(fd) > 0) {\n\n\t\t\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_ALL, \"RECV: GET_SCHEMA_ID\");\n\n\t\t\tmemset(string, 0, sizeof(string));\n\n\t\t\tsnprintf(string, sizeof(string), \"MSGID: %ld\\n%ld\\n\\n\",msg_id,SCHEMA_ID);\n\n\t\t\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_ALL, \"--> %d: [%s]\",fd, string);\n\n\t\t\twrite(fd, string, strlen(string));\n\n\t\t\tp+=strlen(network_line)+1;\n\t\t\tmsg_id = UINT32_MAX;\n\n\n\t\t} else if ( !strncmp(network_line, \"ALIVE\", strlen(\"ALIVE\")) && msg_id != UINT32_MAX  && network_client_get_version(fd) > 0) {\n\n\t\t\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_ALL, \"RECV: ALIVE\");\n\n\t\t\tsnprintf(string, sizeof(string), \"MSGID: %ld\\nOKAY\\n\\n\",msg_id);\n\n\t\t\twrite(fd, string, strlen(string));\n\n\t\t\tp+=strlen(network_line)+1;\n\t\t\tmsg_id = UINT32_MAX;\n\n\t\t} else {\n\n\t\t\tp+=strlen(network_line);\n\n\t\t\tif (strlen(network_line) == 0 ) {\n\t\t\t\tp+=1;\n \t\t\t} else {\n\t\t\t\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_ERROR, \"Drop package [%s]\", network_line);\n\t\t\t}\n\n\t\t}\n\t}\n\tv_sem(sem_id);\n\n\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_ALL, \"END Package\");\n\t\n\n\tnetwork_client_dump ();\n\n\treturn 0;\n\nfailed:\n\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_PROCESS, \"Failed parsing [%s]\", p);\nclose:\n\tclose(fd);\n\tFD_CLR(fd, &readfds);\n\tremove(fd);\n\treturn 0;\n}",
        "func_hash": 26417302945123183266379996857046132142,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-200"
        ],
        "cve": "CVE-2019-1010283",
        "cve_desc": "Univention Corporate Server univention-directory-notifier 12.0.1-3 and earlier is affected by: CWE-213: Intentional Information Exposure. The impact is: Loss of Confidentiality. The component is: function data_on_connection() in src/callback.c. The attack vector is: network connectivity. The fixed version is: 12.0.1-4 and later.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2019-1010283",
        "func_name": "data_on_connection",
        "diff": [
            "diff --git a/management/univention-directory-notifier/debian/changelog b/management/univention-directory-notifier/debian/changelog\nindex 80faf0fff8b..963a9b34b41 100644\n--- a/management/univention-directory-notifier/debian/changelog\n+++ b/management/univention-directory-notifier/debian/changelog\n@@ -1,3 +1,9 @@\n+univention-directory-notifier (12.0.1-11) unstable; urgency=low\n+\n+  * Bug #48427: Forbid vulnerable GET_DN for VERSION >= 3\n+\n+ -- Philipp Hahn <hahn@univention.de>  Wed, 13 Feb 2019 10:23:12 +0100\n+\n univention-directory-notifier (12.0.1-10) unstable; urgency=low\n \n   * Bug #48427: Change import limits\ndiff --git a/management/univention-directory-notifier/src/callback.c b/management/univention-directory-notifier/src/callback.c\nindex 151e50e7ce6..9c6e80401a9 100644\n--- a/management/univention-directory-notifier/src/callback.c\n+++ b/management/univention-directory-notifier/src/callback.c\n@@ -199,7 +199,7 @@ int data_on_connection(int fd, callback_remove_handler remove)\n \t\t\tp+=strlen(network_line);\n \n \n-\t\t} else if ( !strncmp(network_line, \"GET_DN \", strlen(\"GET_DN \")) && msg_id != UINT32_MAX && network_client_get_version(fd) > 0) {\n+\t\t} else if ( !strncmp(network_line, \"GET_DN \", strlen(\"GET_DN \")) && msg_id != UINT32_MAX && version > PROTOCOL_UNKNOWN && version < PROTOCOL_3) {\n \n \t\t\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_ALL, \"RECV: GET_DN\");\n \n"
        ],
        "func_after": []
    },
    {
        "idx": 217238,
        "project": "serenity",
        "commit_id": "48fbf6a88d4822a1e5470cf08f29464511bd72c1",
        "project_url": "https://github.com/SerenityOS/serenity",
        "commit_url": "https://github.com/SerenityOS/serenity/commit/48fbf6a88d4822a1e5470cf08f29464511bd72c1",
        "commit_message": "LibCrypto: Don't copy the prime test candidates\n\nThis was copying a bunch of bigints for no reason.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static bool MR_primality_test(UnsignedBigInteger n, const Vector<UnsignedBigInteger, 256>& tests)\n{\n    // Written using Wikipedia:\n    // https://en.wikipedia.org/wiki/Miller%E2%80%93Rabin_primality_test#Miller%E2%80%93Rabin_test\n    ASSERT(!(n < 4));\n    auto predecessor = n.minus({ 1 });\n    auto d = predecessor;\n    size_t r = 0;\n\n    {\n        auto div_result = d.divided_by(2);\n        while (div_result.remainder == 0) {\n            d = div_result.quotient;\n            div_result = d.divided_by(2);\n            ++r;\n        }\n    }\n    if (r == 0) {\n        // n - 1 is odd, so n was even. But there is only one even prime:\n        return n == 2;\n    }\n\n    for (auto a : tests) {\n        // Technically: ASSERT(2 <= a && a <= n - 2)\n        ASSERT(a < n);\n        auto x = ModularPower(a, d, n);\n        if (x == 1 || x == predecessor)\n            continue;\n        bool skip_this_witness = false;\n        // r \u2212 1 iterations.\n        for (size_t i = 0; i < r - 1; ++i) {\n            x = ModularPower(x, 2, n);\n            if (x == predecessor) {\n                skip_this_witness = true;\n                break;\n            }\n        }\n        if (skip_this_witness)\n            continue;\n        return false; // \"composite\"\n    }\n\n    return true; // \"probably prime\"\n}",
        "func_hash": 209495948576285830185728169492009901118,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-120"
        ],
        "cve": "CVE-2021-27343",
        "cve_desc": "SerenityOS Unspecified is affected by: Buffer Overflow. The impact is: obtain sensitive information (context-dependent). The component is: /Userland/Libraries/LibCrypto/ASN1/DER.h Crypto::der_decode_sequence() function. The attack vector is: Parsing RSA Key ASN.1.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-27343",
        "func_name": "MR_primality_test",
        "diff": [
            "diff --git a/Userland/Libraries/LibCrypto/NumberTheory/ModularFunctions.cpp b/Userland/Libraries/LibCrypto/NumberTheory/ModularFunctions.cpp\nindex 2bc7445701d7b4..ecccd2c60e8847 100644\n--- a/Userland/Libraries/LibCrypto/NumberTheory/ModularFunctions.cpp\n+++ b/Userland/Libraries/LibCrypto/NumberTheory/ModularFunctions.cpp\n@@ -258,7 +258,7 @@ static bool MR_primality_test(UnsignedBigInteger n, const Vector<UnsignedBigInte\n         return n == 2;\n     }\n \n-    for (auto a : tests) {\n+    for (auto& a : tests) {\n         // Technically: ASSERT(2 <= a && a <= n - 2)\n         ASSERT(a < n);\n         auto x = ModularPower(a, d, n);\n"
        ],
        "func_after": []
    },
    {
        "idx": 217239,
        "project": "serenity",
        "commit_id": "c9f25bca048443e317f1994ba9b106f2386688c3",
        "project_url": "https://github.com/SerenityOS/serenity",
        "commit_url": "https://github.com/SerenityOS/serenity/commit/c9f25bca048443e317f1994ba9b106f2386688c3",
        "commit_message": "LibTextCodec: Make UTF16BEDecoder read only up to an even offset\n\nReading up to the end of the input string of odd length results in\nan out-of-bounds read",
        "target": 1,
        "irrelevant": 1,
        "func_before": "String UTF16BEDecoder::to_utf8(const StringView& input)\n{\n    StringBuilder builder(input.length() / 2);\n    for (size_t i = 0; i < input.length(); i += 2) {\n        u16 code_point = (input[i] << 8) | input[i + 1];\n        builder.append_code_point(code_point);\n    }\n    return builder.to_string();\n}",
        "func_hash": 185746559055129378339300492275239703317,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-120"
        ],
        "cve": "CVE-2021-28874",
        "cve_desc": "SerenityOS fixed as of c9f25bca048443e317f1994ba9b106f2386688c3 contains a buffer overflow vulnerability in LibTextCode through opening a crafted file.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-28874",
        "func_name": "UTF16BEDecoder::to_utf8",
        "diff": [
            "diff --git a/Userland/Libraries/LibTextCodec/Decoder.cpp b/Userland/Libraries/LibTextCodec/Decoder.cpp\nindex 26fced65244cc0..b075a818704727 100644\n--- a/Userland/Libraries/LibTextCodec/Decoder.cpp\n+++ b/Userland/Libraries/LibTextCodec/Decoder.cpp\n@@ -183,7 +183,8 @@ String UTF8Decoder::to_utf8(const StringView& input)\n String UTF16BEDecoder::to_utf8(const StringView& input)\n {\n     StringBuilder builder(input.length() / 2);\n-    for (size_t i = 0; i < input.length(); i += 2) {\n+    size_t utf16_length = input.length() - (input.length() % 2);\n+    for (size_t i = 0; i < utf16_length; i += 2) {\n         u16 code_point = (input[i] << 8) | input[i + 1];\n         builder.append_code_point(code_point);\n     }\n"
        ],
        "func_after": []
    },
    {
        "idx": 217240,
        "project": "serenity",
        "commit_id": "4317db7498eaa5a37068052bb0310fbc6a5f78e4",
        "project_url": "https://github.com/SerenityOS/serenity",
        "commit_url": "https://github.com/SerenityOS/serenity/commit/4317db7498eaa5a37068052bb0310fbc6a5f78e4",
        "commit_message": "LibArchive: Make bounds checks stricter in the Zip parser\n\nWe now also check we have enough space in the incoming buffer for the\nvarious signatures and optional (length specified) fields. This helps\nprevents a possible heap overflow read.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "    bool read(ReadonlyBytes buffer)\n    {\n        auto fields_size = sizeof(CentralDirectoryRecord) - (sizeof(u8*) * 3);\n        if (buffer.size() < fields_size)\n            return false;\n        if (memcmp(buffer.data(), central_directory_record_signature, sizeof(central_directory_record_signature)) != 0)\n            return false;\n        memcpy(reinterpret_cast<void*>(&made_by_version), buffer.data() + sizeof(central_directory_record_signature), fields_size);\n        name = buffer.data() + sizeof(central_directory_record_signature) + fields_size;\n        extra_data = name + name_length;\n        comment = extra_data + extra_data_length;\n        return true;\n    }",
        "func_hash": 338559769760382772800704932805932220486,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-120"
        ],
        "cve": "CVE-2021-30045",
        "cve_desc": "SerenityOS 2021-03-27 contains a buffer overflow vulnerability in the EndOfCentralDirectory::read() function.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-30045",
        "func_name": "read",
        "diff": [
            "diff --git a/Userland/Libraries/LibArchive/Zip.h b/Userland/Libraries/LibArchive/Zip.h\nindex ac835b8bfae64b..66a25acf726ef8 100644\n--- a/Userland/Libraries/LibArchive/Zip.h\n+++ b/Userland/Libraries/LibArchive/Zip.h\n@@ -52,11 +52,13 @@ struct [[gnu::packed]] EndOfCentralDirectory {\n     bool read(ReadonlyBytes buffer)\n     {\n         auto fields_size = sizeof(EndOfCentralDirectory) - sizeof(u8*);\n-        if (buffer.size() < fields_size)\n+        if (buffer.size() < sizeof(end_of_central_directory_signature) + fields_size)\n             return false;\n         if (memcmp(buffer.data(), end_of_central_directory_signature, sizeof(end_of_central_directory_signature)) != 0)\n             return false;\n         memcpy(reinterpret_cast<void*>(&disk_number), buffer.data() + sizeof(end_of_central_directory_signature), fields_size);\n+        if (buffer.size() < sizeof(end_of_central_directory_signature) + fields_size + comment_length)\n+            return false;\n         comment = buffer.data() + sizeof(end_of_central_directory_signature) + fields_size;\n         return true;\n     }\n@@ -101,11 +103,13 @@ struct [[gnu::packed]] CentralDirectoryRecord {\n     bool read(ReadonlyBytes buffer)\n     {\n         auto fields_size = sizeof(CentralDirectoryRecord) - (sizeof(u8*) * 3);\n-        if (buffer.size() < fields_size)\n+        if (buffer.size() < sizeof(central_directory_record_signature) + fields_size)\n             return false;\n         if (memcmp(buffer.data(), central_directory_record_signature, sizeof(central_directory_record_signature)) != 0)\n             return false;\n         memcpy(reinterpret_cast<void*>(&made_by_version), buffer.data() + sizeof(central_directory_record_signature), fields_size);\n+        if (buffer.size() < sizeof(end_of_central_directory_signature) + fields_size + comment_length + name_length + extra_data_length)\n+            return false;\n         name = buffer.data() + sizeof(central_directory_record_signature) + fields_size;\n         extra_data = name + name_length;\n         comment = extra_data + extra_data_length;\n@@ -165,11 +169,13 @@ struct [[gnu::packed]] LocalFileHeader {\n     bool read(ReadonlyBytes buffer)\n     {\n         auto fields_size = sizeof(LocalFileHeader) - (sizeof(u8*) * 3);\n-        if (buffer.size() < fields_size)\n+        if (buffer.size() < sizeof(local_file_header_signature) + fields_size)\n             return false;\n         if (memcmp(buffer.data(), local_file_header_signature, sizeof(local_file_header_signature)) != 0)\n             return false;\n         memcpy(reinterpret_cast<void*>(&minimum_version), buffer.data() + sizeof(local_file_header_signature), fields_size);\n+        if (buffer.size() < sizeof(end_of_central_directory_signature) + fields_size + name_length + extra_data_length + compressed_size)\n+            return false;\n         name = buffer.data() + sizeof(local_file_header_signature) + fields_size;\n         extra_data = name + name_length;\n         compressed_data = extra_data + extra_data_length;\n"
        ],
        "func_after": []
    },
    {
        "idx": 217241,
        "project": "serenity",
        "commit_id": "4317db7498eaa5a37068052bb0310fbc6a5f78e4",
        "project_url": "https://github.com/SerenityOS/serenity",
        "commit_url": "https://github.com/SerenityOS/serenity/commit/4317db7498eaa5a37068052bb0310fbc6a5f78e4",
        "commit_message": "LibArchive: Make bounds checks stricter in the Zip parser\n\nWe now also check we have enough space in the incoming buffer for the\nvarious signatures and optional (length specified) fields. This helps\nprevents a possible heap overflow read.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "    bool read(ReadonlyBytes buffer)\n    {\n        auto fields_size = sizeof(LocalFileHeader) - (sizeof(u8*) * 3);\n        if (buffer.size() < fields_size)\n            return false;\n        if (memcmp(buffer.data(), local_file_header_signature, sizeof(local_file_header_signature)) != 0)\n            return false;\n        memcpy(reinterpret_cast<void*>(&minimum_version), buffer.data() + sizeof(local_file_header_signature), fields_size);\n        name = buffer.data() + sizeof(local_file_header_signature) + fields_size;\n        extra_data = name + name_length;\n        compressed_data = extra_data + extra_data_length;\n        return true;\n    }",
        "func_hash": 189502346137609023414840536827945179408,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-120"
        ],
        "cve": "CVE-2021-30045",
        "cve_desc": "SerenityOS 2021-03-27 contains a buffer overflow vulnerability in the EndOfCentralDirectory::read() function.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-30045",
        "func_name": "read",
        "diff": [
            "diff --git a/Userland/Libraries/LibArchive/Zip.h b/Userland/Libraries/LibArchive/Zip.h\nindex ac835b8bfae64b..66a25acf726ef8 100644\n--- a/Userland/Libraries/LibArchive/Zip.h\n+++ b/Userland/Libraries/LibArchive/Zip.h\n@@ -52,11 +52,13 @@ struct [[gnu::packed]] EndOfCentralDirectory {\n     bool read(ReadonlyBytes buffer)\n     {\n         auto fields_size = sizeof(EndOfCentralDirectory) - sizeof(u8*);\n-        if (buffer.size() < fields_size)\n+        if (buffer.size() < sizeof(end_of_central_directory_signature) + fields_size)\n             return false;\n         if (memcmp(buffer.data(), end_of_central_directory_signature, sizeof(end_of_central_directory_signature)) != 0)\n             return false;\n         memcpy(reinterpret_cast<void*>(&disk_number), buffer.data() + sizeof(end_of_central_directory_signature), fields_size);\n+        if (buffer.size() < sizeof(end_of_central_directory_signature) + fields_size + comment_length)\n+            return false;\n         comment = buffer.data() + sizeof(end_of_central_directory_signature) + fields_size;\n         return true;\n     }\n@@ -101,11 +103,13 @@ struct [[gnu::packed]] CentralDirectoryRecord {\n     bool read(ReadonlyBytes buffer)\n     {\n         auto fields_size = sizeof(CentralDirectoryRecord) - (sizeof(u8*) * 3);\n-        if (buffer.size() < fields_size)\n+        if (buffer.size() < sizeof(central_directory_record_signature) + fields_size)\n             return false;\n         if (memcmp(buffer.data(), central_directory_record_signature, sizeof(central_directory_record_signature)) != 0)\n             return false;\n         memcpy(reinterpret_cast<void*>(&made_by_version), buffer.data() + sizeof(central_directory_record_signature), fields_size);\n+        if (buffer.size() < sizeof(end_of_central_directory_signature) + fields_size + comment_length + name_length + extra_data_length)\n+            return false;\n         name = buffer.data() + sizeof(central_directory_record_signature) + fields_size;\n         extra_data = name + name_length;\n         comment = extra_data + extra_data_length;\n@@ -165,11 +169,13 @@ struct [[gnu::packed]] LocalFileHeader {\n     bool read(ReadonlyBytes buffer)\n     {\n         auto fields_size = sizeof(LocalFileHeader) - (sizeof(u8*) * 3);\n-        if (buffer.size() < fields_size)\n+        if (buffer.size() < sizeof(local_file_header_signature) + fields_size)\n             return false;\n         if (memcmp(buffer.data(), local_file_header_signature, sizeof(local_file_header_signature)) != 0)\n             return false;\n         memcpy(reinterpret_cast<void*>(&minimum_version), buffer.data() + sizeof(local_file_header_signature), fields_size);\n+        if (buffer.size() < sizeof(end_of_central_directory_signature) + fields_size + name_length + extra_data_length + compressed_size)\n+            return false;\n         name = buffer.data() + sizeof(local_file_header_signature) + fields_size;\n         extra_data = name + name_length;\n         compressed_data = extra_data + extra_data_length;\n"
        ],
        "func_after": []
    },
    {
        "idx": 217242,
        "project": "serenity",
        "commit_id": "4317db7498eaa5a37068052bb0310fbc6a5f78e4",
        "project_url": "https://github.com/SerenityOS/serenity",
        "commit_url": "https://github.com/SerenityOS/serenity/commit/4317db7498eaa5a37068052bb0310fbc6a5f78e4",
        "commit_message": "LibArchive: Make bounds checks stricter in the Zip parser\n\nWe now also check we have enough space in the incoming buffer for the\nvarious signatures and optional (length specified) fields. This helps\nprevents a possible heap overflow read.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "    bool read(ReadonlyBytes buffer)\n    {\n        auto fields_size = sizeof(EndOfCentralDirectory) - sizeof(u8*);\n        if (buffer.size() < fields_size)\n            return false;\n        if (memcmp(buffer.data(), end_of_central_directory_signature, sizeof(end_of_central_directory_signature)) != 0)\n            return false;\n        memcpy(reinterpret_cast<void*>(&disk_number), buffer.data() + sizeof(end_of_central_directory_signature), fields_size);\n        comment = buffer.data() + sizeof(end_of_central_directory_signature) + fields_size;\n        return true;\n    }",
        "func_hash": 68370273513077950337347122851874612690,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-120"
        ],
        "cve": "CVE-2021-30045",
        "cve_desc": "SerenityOS 2021-03-27 contains a buffer overflow vulnerability in the EndOfCentralDirectory::read() function.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-30045",
        "func_name": "read",
        "diff": [
            "diff --git a/Userland/Libraries/LibArchive/Zip.h b/Userland/Libraries/LibArchive/Zip.h\nindex ac835b8bfae64b..66a25acf726ef8 100644\n--- a/Userland/Libraries/LibArchive/Zip.h\n+++ b/Userland/Libraries/LibArchive/Zip.h\n@@ -52,11 +52,13 @@ struct [[gnu::packed]] EndOfCentralDirectory {\n     bool read(ReadonlyBytes buffer)\n     {\n         auto fields_size = sizeof(EndOfCentralDirectory) - sizeof(u8*);\n-        if (buffer.size() < fields_size)\n+        if (buffer.size() < sizeof(end_of_central_directory_signature) + fields_size)\n             return false;\n         if (memcmp(buffer.data(), end_of_central_directory_signature, sizeof(end_of_central_directory_signature)) != 0)\n             return false;\n         memcpy(reinterpret_cast<void*>(&disk_number), buffer.data() + sizeof(end_of_central_directory_signature), fields_size);\n+        if (buffer.size() < sizeof(end_of_central_directory_signature) + fields_size + comment_length)\n+            return false;\n         comment = buffer.data() + sizeof(end_of_central_directory_signature) + fields_size;\n         return true;\n     }\n@@ -101,11 +103,13 @@ struct [[gnu::packed]] CentralDirectoryRecord {\n     bool read(ReadonlyBytes buffer)\n     {\n         auto fields_size = sizeof(CentralDirectoryRecord) - (sizeof(u8*) * 3);\n-        if (buffer.size() < fields_size)\n+        if (buffer.size() < sizeof(central_directory_record_signature) + fields_size)\n             return false;\n         if (memcmp(buffer.data(), central_directory_record_signature, sizeof(central_directory_record_signature)) != 0)\n             return false;\n         memcpy(reinterpret_cast<void*>(&made_by_version), buffer.data() + sizeof(central_directory_record_signature), fields_size);\n+        if (buffer.size() < sizeof(end_of_central_directory_signature) + fields_size + comment_length + name_length + extra_data_length)\n+            return false;\n         name = buffer.data() + sizeof(central_directory_record_signature) + fields_size;\n         extra_data = name + name_length;\n         comment = extra_data + extra_data_length;\n@@ -165,11 +169,13 @@ struct [[gnu::packed]] LocalFileHeader {\n     bool read(ReadonlyBytes buffer)\n     {\n         auto fields_size = sizeof(LocalFileHeader) - (sizeof(u8*) * 3);\n-        if (buffer.size() < fields_size)\n+        if (buffer.size() < sizeof(local_file_header_signature) + fields_size)\n             return false;\n         if (memcmp(buffer.data(), local_file_header_signature, sizeof(local_file_header_signature)) != 0)\n             return false;\n         memcpy(reinterpret_cast<void*>(&minimum_version), buffer.data() + sizeof(local_file_header_signature), fields_size);\n+        if (buffer.size() < sizeof(end_of_central_directory_signature) + fields_size + name_length + extra_data_length + compressed_size)\n+            return false;\n         name = buffer.data() + sizeof(local_file_header_signature) + fields_size;\n         extra_data = name + name_length;\n         compressed_data = extra_data + extra_data_length;\n"
        ],
        "func_after": []
    },
    {
        "idx": 217244,
        "project": "mbed-coap",
        "commit_id": "4647a68e364401e81dbd370728127d844f221d93",
        "project_url": "https://github.com/mjurczak/mbed-coap",
        "commit_url": "https://github.com/mjurczak/mbed-coap/commit/4647a68e364401e81dbd370728127d844f221d93",
        "commit_message": "Implemented measures to prevent memory leaks in sn_coap_parser_options_parse().\n\nAdded a helper uint16_t addition function with overflow detection. The function is used when calculating the extended length and option delta. The overlow detection is needed to avoid wrap-around of option number or length.\nAdditional checks in options using sn_coap_parser_options_parse_multiple_options() have been implemented to avoid overwriting of pointers pointing to previously allocated memory.",
        "target": 1,
        "irrelevant": 1,
        "func_before": "static int8_t sn_coap_parser_options_parse(struct coap_s *handle, uint8_t **packet_data_pptr, sn_coap_hdr_s *dst_coap_msg_ptr, uint8_t *packet_data_start_ptr, uint16_t packet_len)\n{\n    uint8_t previous_option_number = 0;\n    int8_t  ret_status             = 0;\n    uint16_t message_left          = sn_coap_parser_move_packet_ptr(packet_data_pptr,\n                                                                    packet_data_start_ptr,\n                                                                    packet_len,\n                                                                    0);\n\n    /*  Parse token, if exists  */\n    dst_coap_msg_ptr->token_len = *packet_data_start_ptr & COAP_HEADER_TOKEN_LENGTH_MASK;\n\n    if (dst_coap_msg_ptr->token_len) {\n        int8_t ptr_check_result;\n        if ((dst_coap_msg_ptr->token_len > 8) || dst_coap_msg_ptr->token_ptr) {\n            tr_error(\"sn_coap_parser_options_parse - token not valid!\");\n            return -1;\n        }\n\n        ptr_check_result = sn_coap_parser_check_packet_ptr(*packet_data_pptr, packet_data_start_ptr, packet_len, dst_coap_msg_ptr->token_len);\n        if (0 != ptr_check_result) {\n            tr_error(\"sn_coap_parser_options_parse - **packet_data_pptr overflow !\");\n            return -1;\n        }\n\n        dst_coap_msg_ptr->token_ptr = sn_coap_protocol_malloc_copy(handle, *packet_data_pptr, dst_coap_msg_ptr->token_len);\n\n        if (dst_coap_msg_ptr->token_ptr == NULL) {\n            tr_error(\"sn_coap_parser_options_parse - failed to allocate token!\");\n            return -1;\n        }\n\n        message_left = sn_coap_parser_move_packet_ptr(packet_data_pptr,\n                                                      packet_data_start_ptr,\n                                                      packet_len,\n                                                      dst_coap_msg_ptr->token_len);\n    }\n\n    /* Loop all Options */\n    while (message_left && (**packet_data_pptr != 0xff)) {\n        /* Get option length WITHOUT extensions */\n        uint16_t option_len = (**packet_data_pptr & 0x0F);\n        /* Get option number WITHOUT extensions */\n        uint16_t  option_number = (**packet_data_pptr >> COAP_OPTIONS_OPTION_NUMBER_SHIFT);\n\n        message_left = sn_coap_parser_move_packet_ptr(packet_data_pptr, packet_data_start_ptr, packet_len, 1);\n\n        int8_t    option_parse_result;\n        /* Add possible option delta extension */\n        option_parse_result = parse_ext_option(&option_number,\n                                                packet_data_pptr,\n                                                packet_data_start_ptr,\n                                                packet_len,\n                                                &message_left);\n        if (option_parse_result != 0) {\n            return -1;\n        }\n        /* Add previous option to option delta and get option number */\n        option_number += previous_option_number;\n\n        /* Add possible option length extension to resolve full length of the option */\n        option_parse_result = parse_ext_option(&option_len,\n                                                packet_data_pptr,\n                                                packet_data_start_ptr,\n                                                packet_len,\n                                                &message_left);\n        if (option_parse_result != 0) {\n            return -1;\n        }\n\n        /* * * Parse option itself * * */\n        /* Some options are handled independently in own functions */\n        previous_option_number = option_number;\n        /* Allocate options_list_ptr if needed */\n        switch (option_number) {\n            case COAP_OPTION_MAX_AGE:\n            case COAP_OPTION_PROXY_URI:\n            case COAP_OPTION_ETAG:\n            case COAP_OPTION_URI_HOST:\n            case COAP_OPTION_LOCATION_PATH:\n            case COAP_OPTION_URI_PORT:\n            case COAP_OPTION_LOCATION_QUERY:\n            case COAP_OPTION_OBSERVE:\n            case COAP_OPTION_URI_QUERY:\n            case COAP_OPTION_BLOCK2:\n            case COAP_OPTION_BLOCK1:\n            case COAP_OPTION_ACCEPT:\n            case COAP_OPTION_SIZE1:\n            case COAP_OPTION_SIZE2:\n                if (sn_coap_parser_alloc_options(handle, dst_coap_msg_ptr) == NULL) {\n                    tr_error(\"sn_coap_parser_options_parse - failed to allocate options!\");\n                    return -1;\n                }\n                break;\n        }\n\n        if (message_left < option_len){\n            /* packet_data_pptr would overflow! */\n            tr_error(\"sn_coap_parser_options_parse - **packet_data_pptr would overflow when parsing options!\");\n            return -1;\n        }\n\n        /* Parse option */\n        switch (option_number) {\n            case COAP_OPTION_CONTENT_FORMAT:\n                if ((option_len > 2) || (dst_coap_msg_ptr->content_format != COAP_CT_NONE)) {\n                    tr_error(\"sn_coap_parser_options_parse - COAP_OPTION_CONTENT_FORMAT not valid!\");\n                    return -1;\n                }\n                dst_coap_msg_ptr->content_format = (sn_coap_content_format_e) sn_coap_parser_options_parse_uint(packet_data_pptr, option_len);\n                break;\n\n            case COAP_OPTION_MAX_AGE:\n                if (option_len > 4) {\n                    tr_error(\"sn_coap_parser_options_parse - COAP_OPTION_MAX_AGE not valid!\");\n                    return -1;\n                }\n                dst_coap_msg_ptr->options_list_ptr->max_age = sn_coap_parser_options_parse_uint(packet_data_pptr, option_len);\n                break;\n\n            case COAP_OPTION_PROXY_URI:\n                if ((option_len > 1034) || (option_len < 1) || dst_coap_msg_ptr->options_list_ptr->proxy_uri_ptr) {\n                    tr_error(\"sn_coap_parser_options_parse - COAP_OPTION_PROXY_URI not valid!\");\n                    return -1;\n                }\n                dst_coap_msg_ptr->options_list_ptr->proxy_uri_len = option_len;\n                dst_coap_msg_ptr->options_list_ptr->proxy_uri_ptr = sn_coap_protocol_malloc_copy(handle, *packet_data_pptr, option_len);\n\n                if (dst_coap_msg_ptr->options_list_ptr->proxy_uri_ptr == NULL) {\n                    tr_error(\"sn_coap_parser_options_parse - COAP_OPTION_PROXY_URI allocation failed!\");\n                    return -1;\n                }\n                message_left = sn_coap_parser_move_packet_ptr(packet_data_pptr, packet_data_start_ptr, packet_len, option_len);\n                break;\n\n            case COAP_OPTION_ETAG:\n                /* This is managed independently because User gives this option in one character table */\n                ret_status = sn_coap_parser_options_parse_multiple_options(handle, packet_data_pptr,\n                             message_left,\n                             &dst_coap_msg_ptr->options_list_ptr->etag_ptr,\n                             (uint16_t *)&dst_coap_msg_ptr->options_list_ptr->etag_len,\n                             COAP_OPTION_ETAG, option_len);\n                if (ret_status < 0) {\n                    tr_error(\"sn_coap_parser_options_parse - COAP_OPTION_ETAG not valid!\");\n                    return -1;\n                }\n                break;\n\n            case COAP_OPTION_URI_HOST:\n                if ((option_len > 255) || (option_len < 1) || dst_coap_msg_ptr->options_list_ptr->uri_host_ptr) {\n                    tr_error(\"sn_coap_parser_options_parse - COAP_OPTION_URI_HOST not valid!\");\n                    return -1;\n                }\n                dst_coap_msg_ptr->options_list_ptr->uri_host_len = option_len;\n                dst_coap_msg_ptr->options_list_ptr->uri_host_ptr = sn_coap_protocol_malloc_copy(handle, *packet_data_pptr, option_len);\n\n                if (dst_coap_msg_ptr->options_list_ptr->uri_host_ptr == NULL) {\n                    tr_error(\"sn_coap_parser_options_parse - COAP_OPTION_URI_HOST allocation failed!\");\n                    return -1;\n                }\n                message_left = sn_coap_parser_move_packet_ptr(packet_data_pptr, packet_data_start_ptr, packet_len, option_len);\n                break;\n\n            case COAP_OPTION_LOCATION_PATH:\n                if (dst_coap_msg_ptr->options_list_ptr->location_path_ptr) {\n                    tr_error(\"sn_coap_parser_options_parse - COAP_OPTION_LOCATION_PATH exists!\");\n                    return -1;\n                }\n                /* This is managed independently because User gives this option in one character table */\n                ret_status = sn_coap_parser_options_parse_multiple_options(handle, packet_data_pptr, message_left,\n                             &dst_coap_msg_ptr->options_list_ptr->location_path_ptr, &dst_coap_msg_ptr->options_list_ptr->location_path_len,\n                             COAP_OPTION_LOCATION_PATH, option_len);\n                if (ret_status <0) {\n                    tr_error(\"sn_coap_parser_options_parse - COAP_OPTION_LOCATION_PATH not valid!\");\n                    return -1;\n                }\n                break;\n\n            case COAP_OPTION_URI_PORT:\n                if ((option_len > 2) || dst_coap_msg_ptr->options_list_ptr->uri_port != COAP_OPTION_URI_PORT_NONE) {\n                    tr_error(\"sn_coap_parser_options_parse - COAP_OPTION_URI_PORT not valid!\");\n                    return -1;\n                }\n                dst_coap_msg_ptr->options_list_ptr->uri_port = sn_coap_parser_options_parse_uint(packet_data_pptr, option_len);\n                break;\n\n            case COAP_OPTION_LOCATION_QUERY:\n                ret_status = sn_coap_parser_options_parse_multiple_options(handle, packet_data_pptr, message_left,\n                             &dst_coap_msg_ptr->options_list_ptr->location_query_ptr, &dst_coap_msg_ptr->options_list_ptr->location_query_len,\n                             COAP_OPTION_LOCATION_QUERY, option_len);\n                if (ret_status < 0) {\n                    tr_error(\"sn_coap_parser_options_parse - COAP_OPTION_LOCATION_QUERY not valid!\");\n                    return -1;\n                }\n\n                break;\n\n            case COAP_OPTION_URI_PATH:\n                ret_status = sn_coap_parser_options_parse_multiple_options(handle, packet_data_pptr, message_left,\n                             &dst_coap_msg_ptr->uri_path_ptr, &dst_coap_msg_ptr->uri_path_len,\n                             COAP_OPTION_URI_PATH, option_len);\n                if (ret_status < 0) {\n                    tr_error(\"sn_coap_parser_options_parse - COAP_OPTION_URI_PATH not valid!\");\n                    return -1;\n                }\n                break;\n\n            case COAP_OPTION_OBSERVE:\n                if ((option_len > 2) || dst_coap_msg_ptr->options_list_ptr->observe != COAP_OBSERVE_NONE) {\n                    tr_error(\"sn_coap_parser_options_parse - COAP_OPTION_OBSERVE not valid!\");\n                    return -1;\n                }\n                dst_coap_msg_ptr->options_list_ptr->observe = sn_coap_parser_options_parse_uint(packet_data_pptr, option_len);\n                break;\n\n            case COAP_OPTION_URI_QUERY:\n                ret_status = sn_coap_parser_options_parse_multiple_options(handle, packet_data_pptr, message_left,\n                             &dst_coap_msg_ptr->options_list_ptr->uri_query_ptr, &dst_coap_msg_ptr->options_list_ptr->uri_query_len,\n                             COAP_OPTION_URI_QUERY, option_len);\n                if (ret_status < 0) {\n                    tr_error(\"sn_coap_parser_options_parse - COAP_OPTION_URI_QUERY not valid!\");\n                    return -1;\n                }\n                break;\n\n            case COAP_OPTION_BLOCK2:\n                if ((option_len > 3) || dst_coap_msg_ptr->options_list_ptr->block2 != COAP_OPTION_BLOCK_NONE) {\n                    tr_error(\"sn_coap_parser_options_parse - COAP_OPTION_BLOCK2 not valid!\");\n                    return -1;\n                }\n                dst_coap_msg_ptr->options_list_ptr->block2 = sn_coap_parser_options_parse_uint(packet_data_pptr, option_len);\n                break;\n\n            case COAP_OPTION_BLOCK1:\n                if ((option_len > 3) || dst_coap_msg_ptr->options_list_ptr->block1 != COAP_OPTION_BLOCK_NONE) {\n                    tr_error(\"sn_coap_parser_options_parse - COAP_OPTION_BLOCK1 not valid!\");\n                    return -1;\n                }\n                dst_coap_msg_ptr->options_list_ptr->block1 = sn_coap_parser_options_parse_uint(packet_data_pptr, option_len);\n                break;\n\n            case COAP_OPTION_ACCEPT:\n                if ((option_len > 2) || (dst_coap_msg_ptr->options_list_ptr->accept != COAP_CT_NONE)) {\n                    tr_error(\"sn_coap_parser_options_parse - COAP_OPTION_ACCEPT not valid!\");\n                    return -1;\n                }\n                dst_coap_msg_ptr->options_list_ptr->accept = (sn_coap_content_format_e) sn_coap_parser_options_parse_uint(packet_data_pptr, option_len);\n                break;\n\n            case COAP_OPTION_SIZE1:\n                if ((option_len > 4) || dst_coap_msg_ptr->options_list_ptr->use_size1) {\n                    tr_error(\"sn_coap_parser_options_parse - COAP_OPTION_SIZE1 not valid!\");\n                    return -1;\n                }\n                dst_coap_msg_ptr->options_list_ptr->use_size1 = true;\n                dst_coap_msg_ptr->options_list_ptr->size1 = sn_coap_parser_options_parse_uint(packet_data_pptr, option_len);\n                break;\n\n            case COAP_OPTION_SIZE2:\n                if ((option_len > 4) || dst_coap_msg_ptr->options_list_ptr->use_size2) {\n                    tr_error(\"sn_coap_parser_options_parse - COAP_OPTION_SIZE2 not valid!\");\n                    return -1;\n                }\n                dst_coap_msg_ptr->options_list_ptr->use_size2 = true;\n                dst_coap_msg_ptr->options_list_ptr->size2 = sn_coap_parser_options_parse_uint(packet_data_pptr, option_len);\n                break;\n\n            default:\n                tr_error(\"sn_coap_parser_options_parse - unknown option!\");\n                return -1;\n        }\n\n        /* Check for overflow */\n        if ((*packet_data_pptr - packet_data_start_ptr) > packet_len) {\n            return -1;\n        }\n        message_left = sn_coap_parser_move_packet_ptr(packet_data_pptr,\n                                                      packet_data_start_ptr,\n                                                      packet_len,\n                                                      0);\n    }\n    return 0;\n}",
        "func_hash": 118765562002679695778933862391394313057,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-401"
        ],
        "cve": "CVE-2020-12887",
        "cve_desc": "Memory leaks were discovered in the CoAP library in Arm Mbed OS 5.15.3 when using the Arm mbed-coap library 5.1.5. The CoAP parser is responsible for parsing received CoAP packets. The function sn_coap_parser_options_parse() parses the CoAP option number field of all options present in the input packet. Each option number is calculated as a sum of the previous option number and a delta of the current option. The delta and the previous option number are expressed as unsigned 16-bit integers. Due to lack of overflow detection, it is possible to craft a packet that wraps the option number around and results in the same option number being processed again in a single packet. Certain options allocate memory by calling a memory allocation function. In the cases of COAP_OPTION_URI_QUERY, COAP_OPTION_URI_PATH, COAP_OPTION_LOCATION_QUERY, and COAP_OPTION_ETAG, there is no check on whether memory has already been allocated, which in conjunction with the option number integer overflow may lead to multiple assignments of allocated memory to a single pointer. This has been demonstrated to lead to memory leak by buffer orphaning. As a result, the memory is never freed.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2020-12887",
        "func_name": "sn_coap_parser_options_parse",
        "diff": [
            "diff --git a/source/sn_coap_parser.c b/source/sn_coap_parser.c\nindex d222de4e..a2577cd8 100644\n--- a/source/sn_coap_parser.c\n+++ b/source/sn_coap_parser.c\n@@ -260,6 +260,29 @@ static uint32_t sn_coap_parser_options_parse_uint(uint8_t **packet_data_pptr, ui\n     return value;\n }\n \n+/**\n+ * \\brief Add u16 integers with overflow detection\n+ *\n+ * \\param a            first term of addition\n+ * \\param b            second term of addion\n+ * \\param result       pointer to the result variable\n+ *\n+ * \\return Return 0 if there was no overflow, -1 otherwise\n+ */\n+static int8_t sn_coap_parser_add_u16_limit(uint16_t a, uint16_t b, uint16_t *result)\n+{\n+    uint16_t c;\n+\n+    c = a + b;\n+    if (c < a || c < b)\n+    {\n+        return -1;\n+    }\n+\n+    *result = c;\n+\n+    return 0;\n+}\n \n /**\n  * \\brief Performs data packet pointer boundary check\n@@ -397,11 +420,15 @@ static int8_t parse_ext_option(uint16_t *dst, uint8_t **packet_data_pptr, uint8_\n             return -1;\n         }\n         else {\n-                option_number += option_ext;\n-                *message_left = sn_coap_parser_move_packet_ptr(packet_data_pptr,\n-                                                               packet_data_start_ptr,\n-                                                               packet_len,\n-                                                               1);\n+            if(sn_coap_parser_add_u16_limit(option_number, option_ext, &option_number) != 0)\n+            {\n+                return -1;\n+            }\n+\n+            *message_left = sn_coap_parser_move_packet_ptr(packet_data_pptr,\n+                                                            packet_data_start_ptr,\n+                                                            packet_len,\n+                                                            1);\n         }\n     } else if (option_number == 14) {\n             int8_t read_result = sn_coap_parser_read_packet_u16(&option_number,\n@@ -414,11 +441,15 @@ static int8_t parse_ext_option(uint16_t *dst, uint8_t **packet_data_pptr, uint8_\n                 return -1;\n             }\n             else {\n-            option_number += 269;\n-            *message_left = sn_coap_parser_move_packet_ptr(packet_data_pptr,\n-                                                           packet_data_start_ptr,\n-                                                           packet_len,\n-                                                           2);\n+                if(sn_coap_parser_add_u16_limit(option_number, 269, &option_number) != 0)\n+                {\n+                    return -1;\n+                }\n+\n+                *message_left = sn_coap_parser_move_packet_ptr(packet_data_pptr,\n+                                                            packet_data_start_ptr,\n+                                                            packet_len,\n+                                                            2);\n             }\n     }\n     /* Option number 15 reserved for payload marker. This is handled as a error! */\n@@ -499,7 +530,10 @@ static int8_t sn_coap_parser_options_parse(struct coap_s *handle, uint8_t **pack\n             return -1;\n         }\n         /* Add previous option to option delta and get option number */\n-        option_number += previous_option_number;\n+        if(sn_coap_parser_add_u16_limit(option_number, previous_option_number, &option_number) != 0)\n+        {\n+            return -1;\n+        }\n \n         /* Add possible option length extension to resolve full length of the option */\n         option_parse_result = parse_ext_option(&option_len,\n@@ -577,6 +611,11 @@ static int8_t sn_coap_parser_options_parse(struct coap_s *handle, uint8_t **pack\n                 break;\n \n             case COAP_OPTION_ETAG:\n+                if (dst_coap_msg_ptr->options_list_ptr->etag_ptr)\n+                {\n+                    tr_error(\"sn_coap_parser_options_parse - COAP_OPTION_ETAG exists!\");\n+                    return -1;\n+                }\n                 /* This is managed independently because User gives this option in one character table */\n                 ret_status = sn_coap_parser_options_parse_multiple_options(handle, packet_data_pptr,\n                              message_left,\n@@ -628,6 +667,11 @@ static int8_t sn_coap_parser_options_parse(struct coap_s *handle, uint8_t **pack\n                 break;\n \n             case COAP_OPTION_LOCATION_QUERY:\n+                if (dst_coap_msg_ptr->options_list_ptr->location_query_ptr)\n+                {\n+                    tr_error(\"sn_coap_parser_options_parse - COAP_OPTION_LOCATION_QUERY exists!\");\n+                    return -1;\n+                }\n                 ret_status = sn_coap_parser_options_parse_multiple_options(handle, packet_data_pptr, message_left,\n                              &dst_coap_msg_ptr->options_list_ptr->location_query_ptr, &dst_coap_msg_ptr->options_list_ptr->location_query_len,\n                              COAP_OPTION_LOCATION_QUERY, option_len);\n@@ -639,6 +683,11 @@ static int8_t sn_coap_parser_options_parse(struct coap_s *handle, uint8_t **pack\n                 break;\n \n             case COAP_OPTION_URI_PATH:\n+                if (dst_coap_msg_ptr->uri_path_ptr)\n+                {\n+                    tr_error(\"sn_coap_parser_options_parse - COAP_OPTION_URI_PATH exists!\");\n+                    return -1;\n+                }\n                 ret_status = sn_coap_parser_options_parse_multiple_options(handle, packet_data_pptr, message_left,\n                              &dst_coap_msg_ptr->uri_path_ptr, &dst_coap_msg_ptr->uri_path_len,\n                              COAP_OPTION_URI_PATH, option_len);\n"
        ],
        "func_after": []
    },
    {
        "idx": 217248,
        "project": "phosphor-host-ipmid",
        "commit_id": "b265455a2518ece7c004b43c144199ec980fc620",
        "project_url": "https://github.com/openbmc/phosphor-host-ipmid",
        "commit_url": "https://github.com/openbmc/phosphor-host-ipmid/commit/b265455a2518ece7c004b43c144199ec980fc620",
        "commit_message": "Use more restrictive permissions on /etc/ipmi-pass\n\nThis forces the permissions on /etc/ipmi-pass to be 0600 or RW only by\nowner. This is to prevent non-owners from reading the file, even though\nit is obfuscated to make it harder for ipmi passwords to leak.\n\nTested: change ipmi passwords and see that the /etc/ipmi-pass file has\n        0600 permissions.\n\nChange-Id: I4be0b8a65f98ced031493f7767879eb054e1ee84\nSigned-off-by: Vernon Mauery <vernon.mauery@linux.intel.com>",
        "target": 1,
        "irrelevant": 0,
        "func_before": "int PasswdMgr::updatePasswdSpecialFile(const std::string& userName,\n                                       const std::string& newUserName)\n{\n    phosphor::user::shadow::Lock lock();\n\n    size_t bytesWritten = 0;\n    size_t inBytesLen = 0;\n    size_t isUsrFound = false;\n    const EVP_CIPHER* cipher = EVP_aes_128_cbc();\n    std::vector<uint8_t> dataBuf;\n\n    // Read the encrypted file and get the file data\n    // Check user existance and return if not exist.\n    if (readPasswdFileData(dataBuf) != 0)\n    {\n        log<level::DEBUG>(\"Error in reading the encrypted pass file\");\n        return -EIO;\n    }\n\n    if (dataBuf.size() != 0)\n    {\n        inBytesLen =\n            dataBuf.size() + newUserName.size() + EVP_CIPHER_block_size(cipher);\n    }\n\n    std::vector<uint8_t> inBytes(inBytesLen);\n    if (inBytesLen != 0)\n    {\n        char* outPtr = reinterpret_cast<char*>(dataBuf.data());\n        char* nToken = NULL;\n        char* linePtr = strtok_r(outPtr, \"\\n\", &nToken);\n        while (linePtr != NULL)\n        {\n            size_t userEPos = 0;\n\n            std::string lineStr(linePtr);\n            if ((userEPos = lineStr.find(\":\")) != std::string::npos)\n            {\n                if (userName.compare(lineStr.substr(0, userEPos)) == 0)\n                {\n                    isUsrFound = true;\n                    if (!newUserName.empty())\n                    {\n                        bytesWritten += std::snprintf(\n                            reinterpret_cast<char*>(&inBytes[0]) + bytesWritten,\n                            (inBytesLen - bytesWritten), \"%s%s\\n\",\n                            newUserName.c_str(),\n                            lineStr.substr(userEPos, lineStr.size()).data());\n                    }\n                }\n                else\n                {\n                    bytesWritten += std::snprintf(\n                        reinterpret_cast<char*>(&inBytes[0]) + bytesWritten,\n                        (inBytesLen - bytesWritten), \"%s\\n\", lineStr.data());\n                }\n            }\n            linePtr = strtok_r(NULL, \"\\n\", &nToken);\n        }\n        inBytesLen = bytesWritten;\n    }\n    if (!isUsrFound)\n    {\n        log<level::DEBUG>(\"User doesn't exist\");\n        return 0;\n    }\n\n    // Read the key buff from key file\n    std::array<uint8_t, maxKeySize> keyBuff;\n    std::ifstream keyFile(encryptKeyFileName, std::ios::in | std::ios::binary);\n    if (!keyFile.good())\n    {\n        log<level::DEBUG>(\"Error in opening encryption key file\");\n        return -EIO;\n    }\n    keyFile.read(reinterpret_cast<char*>(keyBuff.data()), keyBuff.size());\n    if (keyFile.fail())\n    {\n        log<level::DEBUG>(\"Error in reading encryption key file\");\n        return -EIO;\n    }\n    keyFile.close();\n\n    // Read the original passwd file mode\n    struct stat st = {};\n    if (stat(passwdFileName, &st) != 0)\n    {\n        log<level::DEBUG>(\"Error in getting password file fstat()\");\n        return -EIO;\n    }\n\n    // Create temporary file for write\n    std::string pwdFile(passwdFileName);\n    std::vector<char> tempFileName(pwdFile.begin(), pwdFile.end());\n    std::vector<char> fileTemplate = {'_', '_', 'X', 'X', 'X',\n                                      'X', 'X', 'X', '\\0'};\n    tempFileName.insert(tempFileName.end(), fileTemplate.begin(),\n                        fileTemplate.end());\n    int fd = mkstemp((char*)tempFileName.data());\n    if (fd == -1)\n    {\n        log<level::DEBUG>(\"Error creating temp file\");\n        return -EIO;\n    }\n\n    std::string strTempFileName(tempFileName.data());\n    // Open the temp file for writing from provided fd\n    // By \"true\", remove it at exit if still there.\n    // This is needed to cleanup the temp file at exception\n    phosphor::user::File temp(fd, strTempFileName, \"w\", true);\n    if ((temp)() == NULL)\n    {\n        close(fd);\n        log<level::DEBUG>(\"Error creating temp file\");\n        return -EIO;\n    }\n\n    // Set the file mode as of actual ipmi-pass file.\n    if (fchmod(fileno((temp)()), st.st_mode) < 0)\n    {\n        log<level::DEBUG>(\"Error setting fchmod for temp file\");\n        return -EIO;\n    }\n\n    const EVP_MD* digest = EVP_sha256();\n    size_t hashLen = EVP_MD_block_size(digest);\n    std::vector<uint8_t> hash(hashLen);\n    size_t ivLen = EVP_CIPHER_iv_length(cipher);\n    std::vector<uint8_t> iv(ivLen);\n    std::array<uint8_t, EVP_MAX_KEY_LENGTH> key;\n    size_t keyLen = key.size();\n    std::array<uint8_t, EVP_MAX_MD_SIZE> mac;\n    size_t macLen = mac.size();\n\n    // Create random hash and generate hash key which will be used for\n    // encryption.\n    if (RAND_bytes(hash.data(), hashLen) != 1)\n    {\n        log<level::DEBUG>(\"Hash genertion failed, bailing out\");\n        return -EIO;\n    }\n    if (NULL == HMAC(digest, keyBuff.data(), keyBuff.size(), hash.data(),\n                     hashLen, key.data(),\n                     reinterpret_cast<unsigned int*>(&keyLen)))\n    {\n        log<level::DEBUG>(\"Failed to create MAC for authentication\");\n        return -EIO;\n    }\n\n    // Generate IV values\n    if (RAND_bytes(iv.data(), ivLen) != 1)\n    {\n        log<level::DEBUG>(\"UV genertion failed, bailing out\");\n        return -EIO;\n    }\n\n    // Encrypt the input data\n    std::vector<uint8_t> outBytes(inBytesLen + EVP_MAX_BLOCK_LENGTH);\n    size_t outBytesLen = 0;\n    if (inBytesLen != 0)\n    {\n        if (encryptDecryptData(true, EVP_aes_128_cbc(), key.data(), keyLen,\n                               iv.data(), ivLen, inBytes.data(), inBytesLen,\n                               mac.data(), &macLen, outBytes.data(),\n                               &outBytesLen) != 0)\n        {\n            log<level::DEBUG>(\"Error while encrypting the data\");\n            return -EIO;\n        }\n        outBytes[outBytesLen] = 0;\n    }\n    OPENSSL_cleanse(key.data(), keyLen);\n\n    // Update the meta password structure.\n    MetaPassStruct metaData = {META_PASSWD_SIG, {0, 0}, 0, 0, 0, 0, 0};\n    metaData.hashSize = hashLen;\n    metaData.ivSize = ivLen;\n    metaData.dataSize = bytesWritten;\n    metaData.padSize = outBytesLen - bytesWritten;\n    metaData.macSize = macLen;\n\n    if (fwrite(&metaData, 1, sizeof(metaData), (temp)()) != sizeof(metaData))\n    {\n        log<level::DEBUG>(\"Error in writing meta data\");\n        return -EIO;\n    }\n\n    if (fwrite(&hash[0], 1, hashLen, (temp)()) != hashLen)\n    {\n        log<level::DEBUG>(\"Error in writing hash data\");\n        return -EIO;\n    }\n\n    if (fwrite(&iv[0], 1, ivLen, (temp)()) != ivLen)\n    {\n        log<level::DEBUG>(\"Error in writing IV data\");\n        return -EIO;\n    }\n\n    if (fwrite(&outBytes[0], 1, outBytesLen, (temp)()) != outBytesLen)\n    {\n        log<level::DEBUG>(\"Error in writing encrypted data\");\n        return -EIO;\n    }\n\n    if (fwrite(&mac[0], 1, macLen, (temp)()) != macLen)\n    {\n        log<level::DEBUG>(\"Error in writing MAC data\");\n        return -EIO;\n    }\n\n    if (fflush((temp)()))\n    {\n        log<level::DEBUG>(\n            \"File fflush error while writing entries to special file\");\n        return -EIO;\n    }\n\n    OPENSSL_cleanse(iv.data(), ivLen);\n\n    // Rename the tmp  file to actual file\n    if (std::rename(strTempFileName.data(), passwdFileName) != 0)\n    {\n        log<level::DEBUG>(\"Failed to rename tmp file to ipmi-pass\");\n        return -EIO;\n    }\n\n    return 0;\n}",
        "func_hash": 308411431480407804964577791887753101427,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-276"
        ],
        "cve": "CVE-2020-14156",
        "cve_desc": "user_channel/passwd_mgr.cpp in OpenBMC phosphor-host-ipmid before 2020-04-03 does not ensure that /etc/ipmi-pass has strong file permissions.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2020-14156",
        "func_name": "PasswdMgr::updatePasswdSpecialFile",
        "diff": [
            "diff --git a/user_channel/passwd_mgr.cpp b/user_channel/passwd_mgr.cpp\nindex 66bdef0d8..5e0b30da6 100644\n--- a/user_channel/passwd_mgr.cpp\n+++ b/user_channel/passwd_mgr.cpp\n@@ -444,8 +444,8 @@ int PasswdMgr::updatePasswdSpecialFile(const std::string& userName,\n         return -EIO;\n     }\n \n-    // Set the file mode as of actual ipmi-pass file.\n-    if (fchmod(fileno((temp)()), st.st_mode) < 0)\n+    // Set the file mode as read-write for owner only\n+    if (fchmod(fileno((temp)()), S_IRUSR | S_IWUSR) < 0)\n     {\n         log<level::DEBUG>(\"Error setting fchmod for temp file\");\n         return -EIO;\n"
        ],
        "func_after": []
    },
    {
        "idx": 217249,
        "project": "bsdiff4",
        "commit_id": "49a4cee2feef7deaf9d89e5e793a8824930284d7",
        "project_url": "https://github.com/ilanschnell/bsdiff4",
        "commit_url": "https://github.com/ilanschnell/bsdiff4/commit/49a4cee2feef7deaf9d89e5e793a8824930284d7",
        "commit_message": "apply patch from Robert Scott to fix - shifting some bounds checking",
        "target": 1,
        "irrelevant": 1,
        "func_before": "static PyObject* patch(PyObject* self, PyObject* args)\n{\n    char *origData, *newData, *diffBlock, *extraBlock, *diffPtr, *extraPtr;\n    Py_ssize_t origDataLength, newDataLength, diffBlockLength, extraBlockLength;\n    PyObject *controlTuples, *tuple, *results;\n    off_t oldpos, newpos, x, y, z;\n    int i, j, numTuples;\n\n    if (!PyArg_ParseTuple(args, \"s#nO!s#s#\",\n                          &origData, &origDataLength, &newDataLength,\n                          &PyList_Type, &controlTuples,\n                          &diffBlock, &diffBlockLength,\n                          &extraBlock, &extraBlockLength))\n        return NULL;\n\n    /* allocate the memory for the new data */\n    newData = PyMem_Malloc(newDataLength + 1);\n    if (!newData)\n        return PyErr_NoMemory();\n\n    oldpos = 0;\n    newpos = 0;\n    diffPtr = diffBlock;\n    extraPtr = extraBlock;\n    numTuples = PyList_GET_SIZE(controlTuples);\n    for (i = 0; i < numTuples; i++) {\n        tuple = PyList_GET_ITEM(controlTuples, i);\n        if (!PyTuple_Check(tuple)) {\n            PyMem_Free(newData);\n            PyErr_SetString(PyExc_TypeError, \"expecting tuple\");\n            return NULL;\n        }\n        if (PyTuple_GET_SIZE(tuple) != 3) {\n            PyMem_Free(newData);\n            PyErr_SetString(PyExc_TypeError, \"expecting tuple of size 3\");\n            return NULL;\n        }\n        x = PyLong_AsLong(PyTuple_GET_ITEM(tuple, 0));\n        y = PyLong_AsLong(PyTuple_GET_ITEM(tuple, 1));\n        z = PyLong_AsLong(PyTuple_GET_ITEM(tuple, 2));\n        if (newpos + x > newDataLength ||\n                diffPtr + x > diffBlock + diffBlockLength ||\n                extraPtr + y > extraBlock + extraBlockLength) {\n            PyMem_Free(newData);\n            PyErr_SetString(PyExc_ValueError, \"corrupt patch (overflow)\");\n            return NULL;\n        }\n        memcpy(newData + newpos, diffPtr, x);\n        diffPtr += x;\n        for (j = 0; j < x; j++)\n            if ((oldpos + j >= 0) && (oldpos + j < origDataLength))\n                newData[newpos + j] += origData[oldpos + j];\n        newpos += x;\n        oldpos += x;\n        memcpy(newData + newpos, extraPtr, y);\n        extraPtr += y;\n        newpos += y;\n        oldpos += z;\n    }\n\n    /* confirm that a valid patch was applied */\n    if (newpos != newDataLength ||\n            diffPtr != diffBlock + diffBlockLength ||\n            extraPtr != extraBlock + extraBlockLength) {\n        PyMem_Free(newData);\n        PyErr_SetString(PyExc_ValueError, \"corrupt patch (underflow)\");\n        return NULL;\n    }\n\n    results = PyBytes_FromStringAndSize(newData, newDataLength);\n    PyMem_Free(newData);\n    return results;\n}",
        "func_hash": 35777879312070160535442824993398419892,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2020-15904",
        "cve_desc": "A buffer overflow in the patching routine of bsdiff4 before 1.2.0 allows an attacker to write to heap memory (beyond allocated bounds) via a crafted patch file.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2020-15904",
        "func_name": "patch",
        "diff": [
            "diff --git a/bsdiff4/core.c b/bsdiff4/core.c\nindex 91be7f8..11b6806 100644\n--- a/bsdiff4/core.c\n+++ b/bsdiff4/core.c\n@@ -431,8 +431,7 @@ static PyObject* patch(PyObject* self, PyObject* args)\n         y = PyLong_AsLong(PyTuple_GET_ITEM(tuple, 1));\n         z = PyLong_AsLong(PyTuple_GET_ITEM(tuple, 2));\n         if (newpos + x > newDataLength ||\n-                diffPtr + x > diffBlock + diffBlockLength ||\n-                extraPtr + y > extraBlock + extraBlockLength) {\n+                diffPtr + x > diffBlock + diffBlockLength) {\n             PyMem_Free(newData);\n             PyErr_SetString(PyExc_ValueError, \"corrupt patch (overflow)\");\n             return NULL;\n@@ -444,6 +443,12 @@ static PyObject* patch(PyObject* self, PyObject* args)\n                 newData[newpos + j] += origData[oldpos + j];\n         newpos += x;\n         oldpos += x;\n+        if (newpos + y > newDataLength ||\n+                extraPtr + y > extraBlock + extraBlockLength) {\n+            PyMem_Free(newData);\n+            PyErr_SetString(PyExc_ValueError, \"corrupt patch (overflow)\");\n+            return NULL;\n+        }\n         memcpy(newData + newpos, extraPtr, y);\n         extraPtr += y;\n         newpos += y;\n"
        ],
        "func_after": []
    },
    {
        "idx": 217253,
        "project": "gilcc",
        "commit_id": "803969389ca9c06237075a7f8eeb1a19e6651759",
        "project_url": "https://github.com/trgil/gilcc",
        "commit_url": "https://github.com/trgil/gilcc/commit/803969389ca9c06237075a7f8eeb1a19e6651759",
        "commit_message": "Fix parser tmp-buffer overflow issue",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static int src_parser_trans_stage_1_2_3(const int tmp_fd, const char *src, const struct trans_config cfg)\n{\n    struct parser_buf pbuf = {\n        .f_indx = 0,\n        .tmp_indx = 0,\n        .f_read_size = 0\n    };\n\n    int write_count = 0;\n    int src_fd;\n    int p_state = P_STATE_CODE;\n\n    src_fd = open(src, O_RDONLY);\n    if (src_fd == -1) {\n        fprintf(stderr, \"**Error: Could not open source file: %s.\\n\", src);\n        return -1;\n    }\n\n    while (p_buf_refill(&pbuf, src_fd) > 0) {\n\n        while (PBUF_F_REMD(pbuf)) {\n\n            switch (p_state) {\n            case P_STATE_COMMENT_C:\n\n                switch (PBUF_F_CHAR(pbuf)) {\n                case '*':\n                    p_buf_push_tmp_char(&pbuf, '*');\n                    continue;\n\n                case '/':\n                    if (pbuf.tmp_indx && (PBUF_TMP_PREV_CHAR(pbuf) == '*')) {\n                        pbuf.tmp_indx--;\n                        p_state = P_STATE_CODE;\n                    }\n                    break;\n\n                default:\n                    if (pbuf.tmp_indx && (PBUF_TMP_PREV_CHAR(pbuf) == '*'))\n                        pbuf.tmp_indx--;\n                    break;\n                }\n\n                pbuf.f_indx++;\n\n            case P_STATE_CODE:\n            default:\n\n                /* TODO: add trigraph support */\n\n                switch (PBUF_F_CHAR(pbuf)) {\n                case ' ':\n                case '\\t':\n                    if (pbuf.tmp_indx &&\n                            (PBUF_TMP_PREV_CHAR(pbuf) == ' ' || PBUF_TMP_PREV_CHAR(pbuf) == '\\t' ||\n                             PBUF_TMP_PREV_CHAR(pbuf) == '\\n'))\n                        pbuf.f_indx++;\n                    else\n                        p_buf_push_tmp_char(&pbuf, ' ');\n\n                    continue;\n\n                case '\\r':\n                case '\\n':\n                    if (pbuf.tmp_indx &&\n                            (PBUF_TMP_PREV_CHAR(pbuf) == ' ' || PBUF_TMP_PREV_CHAR(pbuf) == '\\t' ||\n                             PBUF_TMP_PREV_CHAR(pbuf) == '\\n')) {\n                        pbuf.f_indx++;\n                    } else if (pbuf.tmp_indx && \n                            (PBUF_TMP_PREV_CHAR(pbuf) == '\\\\')) {\n                        pbuf.tmp_indx--;\n                        pbuf.f_indx++;\n                    } else {\n                        p_buf_push_tmp_char(&pbuf, '\\n');\n                    }\n\n                    continue;\n\n                case '\\\\':\n                    p_buf_push_tmp_char(&pbuf, '\\\\');\n                    continue;\n\n                case '/':\n                    p_buf_push_tmp_char(&pbuf, '/');\n                    continue;\n\n                case '*':\n                    if (pbuf.tmp_indx &&\n                            (PBUF_TMP_PREV_CHAR(pbuf) == '/')) {\n                        pbuf.tmp_indx--;\n                        pbuf.f_indx++;\n                        p_state = P_STATE_COMMENT_C;\n                        continue;\n                    }\n\n                default:\n                    break;\n                }\n\n                /* TODO: check return values */\n                p_buf_write_tmp(&pbuf, tmp_fd);\n                p_buf_write_f_char(&pbuf, tmp_fd);\n            }\n        }\n    }\n\n    p_buf_write_tmp(&pbuf, tmp_fd);\n    return 0;\n}",
        "func_hash": 143425032595184974590291153741115718450,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-120"
        ],
        "cve": "CVE-2020-21572",
        "cve_desc": "Buffer overflow vulnerability in function src_parser_trans_stage_1_2_3 trgil gilcc before commit 803969389ca9c06237075a7f8eeb1a19e6651759, allows attackers to cause a denial of service.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2020-21572",
        "func_name": "src_parser_trans_stage_1_2_3",
        "diff": [
            "diff --git a/src/src_parser.c b/src/src_parser.c\nindex 321c336..262ae5d 100644\n--- a/src/src_parser.c\n+++ b/src/src_parser.c\n@@ -171,7 +171,7 @@ static int src_parser_trans_stage_1_2_3(const int tmp_fd, const char *src, const\n                             (PBUF_TMP_PREV_CHAR(pbuf) == ' ' || PBUF_TMP_PREV_CHAR(pbuf) == '\\t' ||\n                              PBUF_TMP_PREV_CHAR(pbuf) == '\\n')) {\n                         pbuf.f_indx++;\n-                    } else if (pbuf.tmp_indx && \n+                    } else if (pbuf.tmp_indx &&\n                             (PBUF_TMP_PREV_CHAR(pbuf) == '\\\\')) {\n                         pbuf.tmp_indx--;\n                         pbuf.f_indx++;\n@@ -182,10 +182,12 @@ static int src_parser_trans_stage_1_2_3(const int tmp_fd, const char *src, const\n                     continue;\n \n                 case '\\\\':\n+                    p_buf_write_tmp(&pbuf, tmp_fd);\n                     p_buf_push_tmp_char(&pbuf, '\\\\');\n                     continue;\n \n                 case '/':\n+                    p_buf_write_tmp(&pbuf, tmp_fd);\n                     p_buf_push_tmp_char(&pbuf, '/');\n                     continue;\n \n"
        ],
        "func_after": []
    },
    {
        "idx": 195067,
        "project": "tensorflow",
        "commit_id": "8a513cec4bec15961fbfdedcaa5376522980455c",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/8a513cec4bec15961fbfdedcaa5376522980455c",
        "commit_message": "Prevent null dereference read in `SpecializeType()`\n\nFor some adversarial protos, the attribute for a key might not exist.\n\nPiperOrigin-RevId: 408382090\nChange-Id: Ie7eabe532c9ff280fce5dce1f6cdb93c76c2e040",
        "target": 1,
        "irrelevant": 0,
        "func_before": "StatusOr<FullTypeDef> SpecializeType(const AttrSlice& attrs,\n                                     const OpDef& op_def) {\n  FullTypeDef ft;\n  ft.set_type_id(TFT_PRODUCT);\n\n  for (int i = 0; i < op_def.output_arg_size(); i++) {\n    auto* t = ft.add_args();\n\n    *t = op_def.output_arg(i).experimental_full_type();\n\n    // Resolve dependent types. The convention for op registrations is to use\n    // attributes as type variables.\n    // See https://www.tensorflow.org/guide/create_op#type_polymorphism.\n    // Once the op signature can be defined entirely in FullType, this\n    // convention can be deprecated.\n    //\n    // Note: While this code performs some basic verifications, it generally\n    // assumes consistent op defs and attributes. If more complete\n    // verifications are needed, they should be done by separately, and in a\n    // way that can be reused for type inference.\n    for (int j = 0; j < t->args_size(); j++) {\n      auto* arg = t->mutable_args(i);\n      if (arg->type_id() == TFT_VAR) {\n        const auto* attr = attrs.Find(arg->s());\n        DCHECK(attr != nullptr);\n        if (attr->value_case() == AttrValue::kList) {\n          const auto& attr_list = attr->list();\n          arg->set_type_id(TFT_PRODUCT);\n          for (int i = 0; i < attr_list.type_size(); i++) {\n            map_dtype_to_tensor(attr_list.type(i), arg->add_args());\n          }\n\n        } else if (attr->value_case() == AttrValue::kType) {\n          map_dtype_to_tensor(attr->type(), arg);\n\n        } else {\n          return Status(error::UNIMPLEMENTED,\n                        absl::StrCat(\"unknown attribute type\",\n                                     attrs.DebugString(), \" key=\", arg->s()));\n        }\n\n        arg->clear_s();\n      }\n    }\n  }\n\n  return ft;\n}",
        "func_hash": 61628354902568849889482519012959401120,
        "file_name": "full_type_util.cc",
        "file_hash": 62085073442308348539645082851768736733,
        "cwe": [
            "CWE-617"
        ],
        "cve": "CVE-2022-23570",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. When decoding a tensor from protobuf, TensorFlow might do a null-dereference if attributes of some mutable arguments to some operations are missing from the proto. This is guarded by a `DCHECK`. However, `DCHECK` is a no-op in production builds and an assertion failure in debug builds. In the first case execution proceeds to the dereferencing of the null pointer, whereas in the second case it results in a crash due to the assertion failure. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, and TensorFlow 2.6.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23570",
        "func_name": "SpecializeType",
        "diff": [
            "diff --git a/tensorflow/core/framework/full_type_util.cc b/tensorflow/core/framework/full_type_util.cc\nindex 5d2b33c3099341..e0d8ca0721c850 100644\n--- a/tensorflow/core/framework/full_type_util.cc\n+++ b/tensorflow/core/framework/full_type_util.cc\n@@ -22,6 +22,7 @@ limitations under the License.\n #include \"tensorflow/core/framework/op_def.pb.h\"\n #include \"tensorflow/core/framework/types.h\"\n #include \"tensorflow/core/platform/statusor.h\"\n+#include \"tensorflow/core/protobuf/error_codes.pb.h\"\n \n namespace tensorflow {\n \n@@ -102,7 +103,11 @@ StatusOr<FullTypeDef> SpecializeType(const AttrSlice& attrs,\n       auto* arg = t->mutable_args(i);\n       if (arg->type_id() == TFT_VAR) {\n         const auto* attr = attrs.Find(arg->s());\n-        DCHECK(attr != nullptr);\n+        if (attr == nullptr) {\n+          return Status(\n+              error::INVALID_ARGUMENT,\n+              absl::StrCat(\"Could not find an attribute for key \", arg->s()));\n+        }\n         if (attr->value_case() == AttrValue::kList) {\n           const auto& attr_list = attr->list();\n           arg->set_type_id(TFT_PRODUCT);\n"
        ],
        "func_after": []
    },
    {
        "idx": 195069,
        "project": "gpac",
        "commit_id": "f1ae01d745200a258cdf62622f71754c37cb6c30",
        "project_url": "https://github.com/gpac/gpac",
        "commit_url": "https://github.com/gpac/gpac/commit/f1ae01d745200a258cdf62622f71754c37cb6c30",
        "commit_message": "fixed #1900",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static s32 svc_parse_slice(GF_BitStream *bs, AVCState *avc, AVCSliceInfo *si)\n{\n\ts32 pps_id;\n\n\t/*s->current_picture.reference= h->nal_ref_idc != 0;*/\n\tgf_bs_read_ue_log(bs, \"first_mb_in_slice\");\n\tsi->slice_type = gf_bs_read_ue_log(bs, \"slice_type\");\n\tif (si->slice_type > 9) return -1;\n\n\tpps_id = gf_bs_read_ue_log(bs, \"pps_id\");\n\tif (pps_id > 255)\n\t\treturn -1;\n\tsi->pps = &avc->pps[pps_id];\n\tsi->pps->id = pps_id;\n\tif (!si->pps->slice_group_count)\n\t\treturn -2;\n\tsi->sps = &avc->sps[si->pps->sps_id + GF_SVC_SSPS_ID_SHIFT];\n\tif (!si->sps->log2_max_frame_num)\n\t\treturn -2;\n\n\tsi->frame_num = gf_bs_read_int_log(bs, si->sps->log2_max_frame_num, \"frame_num\");\n\n\tsi->field_pic_flag = 0;\n\tif (si->sps->frame_mbs_only_flag) {\n\t\t/*s->picture_structure= PICT_FRAME;*/\n\t}\n\telse {\n\t\tsi->field_pic_flag = gf_bs_read_int_log(bs, 1, \"field_pic_flag\");\n\t\tif (si->field_pic_flag) si->bottom_field_flag = gf_bs_read_int_log(bs, 1, \"bottom_field_flag\");\n\t}\n\tif (si->nal_unit_type == GF_AVC_NALU_IDR_SLICE || si->NalHeader.idr_pic_flag)\n\t\tsi->idr_pic_id = gf_bs_read_ue_log(bs, \"idr_pic_id\");\n\n\tif (si->sps->poc_type == 0) {\n\t\tsi->poc_lsb = gf_bs_read_int_log(bs, si->sps->log2_max_poc_lsb, \"poc_lsb\");\n\t\tif (si->pps->pic_order_present && !si->field_pic_flag) {\n\t\t\tsi->delta_poc_bottom = gf_bs_read_se_log(bs, \"delta_poc_bottom\");\n\t\t}\n\t}\n\telse if ((si->sps->poc_type == 1) && !si->sps->delta_pic_order_always_zero_flag) {\n\t\tsi->delta_poc[0] = gf_bs_read_se_log(bs, \"delta_poc0\");\n\t\tif ((si->pps->pic_order_present == 1) && !si->field_pic_flag)\n\t\t\tsi->delta_poc[1] = gf_bs_read_se_log(bs, \"delta_poc1\");\n\t}\n\tif (si->pps->redundant_pic_cnt_present) {\n\t\tsi->redundant_pic_cnt = gf_bs_read_ue_log(bs, \"redundant_pic_cnt\");\n\t}\n\treturn 0;\n}",
        "func_hash": 32918828304584753556059241288811637938,
        "file_name": "av_parsers.c",
        "file_hash": 168517587328341017594269375399465893964,
        "cwe": [
            "CWE-120"
        ],
        "cve": "CVE-2021-40568",
        "cve_desc": "A buffer overflow vulnerability exists in Gpac through 1.0.1 via a malformed MP4 file in the svc_parse_slice function in av_parsers.c, which allows attackers to cause a denial of service, even code execution and escalation of privileges.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-40568",
        "func_name": "svc_parse_slice",
        "diff": [
            "diff --git a/src/media_tools/av_parsers.c b/src/media_tools/av_parsers.c\nindex 2a819da12c..96d2797420 100644\n--- a/src/media_tools/av_parsers.c\n+++ b/src/media_tools/av_parsers.c\n@@ -4690,20 +4690,23 @@ u32 gf_bs_read_ue_log_idx3(GF_BitStream *bs, const char *fname, s32 idx1, s32 id\n \tu32 bits = 0;\n \tfor (code=0; !code; nb_lead++) {\n \t\tif (nb_lead>=32) {\n-\t\t\t//gf_bs_read_int keeps returning 0 on EOS, so if no more bits available, rbsp was truncated otherwise code is broken in rbsp)\n-\t\t\t//we only test once nb_lead>=32 to avoid testing at each bit read\n-\t\t\tif (!gf_bs_available(bs)) {\n-\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CODING, (\"[Core] exp-golomb read failed, not enough bits in bitstream !\\n\"));\n-\t\t\t} else {\n-\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CODING, (\"[Core] corrupted exp-golomb code, %d leading zeros, max 31 allowed !\\n\", nb_lead));\n-\t\t\t}\n-\t\t\treturn 0;\n+\t\t\tbreak;\n \t\t}\n-\n \t\tcode = gf_bs_read_int(bs, 1);\n \t\tbits++;\n \t}\n \n+\tif (nb_lead>=32) {\n+\t\t//gf_bs_read_int keeps returning 0 on EOS, so if no more bits available, rbsp was truncated otherwise code is broken in rbsp)\n+\t\t//we only test once nb_lead>=32 to avoid testing at each bit read\n+\t\tif (!gf_bs_available(bs)) {\n+\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CODING, (\"[Core] exp-golomb read failed, not enough bits in bitstream !\\n\"));\n+\t\t} else {\n+\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CODING, (\"[Core] corrupted exp-golomb code, %d leading zeros, max 31 allowed !\\n\", nb_lead));\n+\t\t}\n+\t\treturn 0;\n+\t}\n+\n \tif (nb_lead) {\n \t\tu32 leads=1;\n \t\tval = gf_bs_read_int(bs, nb_lead);\n@@ -5785,7 +5788,7 @@ static s32 svc_parse_slice(GF_BitStream *bs, AVCState *avc, AVCSliceInfo *si)\n \tif (si->slice_type > 9) return -1;\n \n \tpps_id = gf_bs_read_ue_log(bs, \"pps_id\");\n-\tif (pps_id > 255)\n+\tif ((pps_id<0) || (pps_id > 255))\n \t\treturn -1;\n \tsi->pps = &avc->pps[pps_id];\n \tsi->pps->id = pps_id;\n"
        ],
        "func_after": []
    },
    {
        "idx": 195073,
        "project": "tensorflow",
        "commit_id": "e746adbfcfee15e9cfdb391ff746c765b99bdf9b",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/e746adbfcfee15e9cfdb391ff746c765b99bdf9b",
        "commit_message": "Prevent use after free in `DecodePng` kernel.\n\nWe are cleaning up the memory in `decode` and then we are using an `OP_REQUIRES` to check an invariant on the `decode` data.\n\nPiperOrigin-RevId: 409299145\nChange-Id: I4eb93aaca52483eb202e89b78df07fbb2f6cb254",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void DecodePngV2(OpKernelContext* context, StringPiece input) {\n    int channel_bits = (data_type_ == DataType::DT_UINT8) ? 8 : 16;\n    png::DecodeContext decode;\n    OP_REQUIRES(\n        context, png::CommonInitDecode(input, channels_, channel_bits, &decode),\n        errors::InvalidArgument(\"Invalid PNG. Failed to initialize decoder.\"));\n\n    // Verify that width and height are not too large:\n    // - verify width and height don't overflow int.\n    // - width can later be multiplied by channels_ and sizeof(uint16), so\n    //   verify single dimension is not too large.\n    // - verify when width and height are multiplied together, there are a few\n    //   bits to spare as well.\n    const int width = static_cast<int>(decode.width);\n    const int height = static_cast<int>(decode.height);\n    const int64_t total_size =\n        static_cast<int64_t>(width) * static_cast<int64_t>(height);\n    if (width != static_cast<int64_t>(decode.width) || width <= 0 ||\n        width >= (1LL << 27) || height != static_cast<int64_t>(decode.height) ||\n        height <= 0 || height >= (1LL << 27) || total_size >= (1LL << 29)) {\n      png::CommonFreeDecode(&decode);\n      OP_REQUIRES(context, false,\n                  errors::InvalidArgument(\"PNG size too large for int: \",\n                                          decode.width, \" by \", decode.height));\n    }\n\n    Tensor* output = nullptr;\n    Status status;\n    // By the existing API, we support decoding PNG with `DecodeGif` op.\n    // We need to make sure to return 4-D shapes when using `DecodeGif`.\n    if (op_type_ == \"DecodeGif\") {\n      status = context->allocate_output(\n          0, TensorShape({1, height, width, decode.channels}), &output);\n    } else {\n      status = context->allocate_output(\n          0, TensorShape({height, width, decode.channels}), &output);\n    }\n\n    if (op_type_ == \"DecodeBmp\") {\n      // TODO(b/171060723): Only DecodeBmp as op_type_ is not acceptable here\n      // because currently `decode_(jpeg|png|gif)` ops can decode any one of\n      // jpeg, png or gif but not bmp. Similarly, `decode_bmp` cannot decode\n      // anything but bmp formats. This behavior needs to be revisited. For more\n      // details, please refer to the bug.\n      OP_REQUIRES(context, false,\n                  errors::InvalidArgument(\n                      \"Trying to decode PNG format using DecodeBmp op. Use \"\n                      \"`decode_png` or `decode_image` instead.\"));\n    } else if (op_type_ == \"DecodeAndCropJpeg\") {\n      OP_REQUIRES(context, false,\n                  errors::InvalidArgument(\n                      \"DecodeAndCropJpeg operation can run on JPEG only, but \"\n                      \"detected PNG.\"));\n    }\n\n    if (!status.ok()) png::CommonFreeDecode(&decode);\n    OP_REQUIRES_OK(context, status);\n\n    if (data_type_ == DataType::DT_UINT8) {\n      OP_REQUIRES(\n          context,\n          png::CommonFinishDecode(\n              reinterpret_cast<png_bytep>(output->flat<uint8>().data()),\n              decode.channels * width * sizeof(uint8), &decode),\n          errors::InvalidArgument(\"Invalid PNG data, size \", input.size()));\n    } else if (data_type_ == DataType::DT_UINT16) {\n      OP_REQUIRES(\n          context,\n          png::CommonFinishDecode(\n              reinterpret_cast<png_bytep>(output->flat<uint16>().data()),\n              decode.channels * width * sizeof(uint16), &decode),\n          errors::InvalidArgument(\"Invalid PNG data, size \", input.size()));\n    } else if (data_type_ == DataType::DT_FLOAT) {\n      // `png::CommonFinishDecode` does not support `float`. First allocate\n      // uint16 buffer for the image and decode in uint16 (lossless). Wrap the\n      // buffer in `unique_ptr` so that we don't forget to delete the buffer.\n      std::unique_ptr<uint16[]> buffer(\n          new uint16[height * width * decode.channels]);\n      OP_REQUIRES(\n          context,\n          png::CommonFinishDecode(reinterpret_cast<png_bytep>(buffer.get()),\n                                  decode.channels * width * sizeof(uint16),\n                                  &decode),\n          errors::InvalidArgument(\"Invalid PNG data, size \", input.size()));\n\n      // Convert uint16 image data to desired data type.\n      // Use eigen threadpooling to speed up the copy operation.\n      const auto& device = context->eigen_device<Eigen::ThreadPoolDevice>();\n      TTypes<uint16, 3>::UnalignedConstTensor buf(buffer.get(), height, width,\n                                                  decode.channels);\n      float scale = 1. / std::numeric_limits<uint16>::max();\n      // Fill output tensor with desired dtype.\n      output->tensor<float, 3>().device(device) = buf.cast<float>() * scale;\n    }\n  }",
        "func_hash": 20785520030401878119367159260444796492,
        "file_name": "decode_image_op.cc",
        "file_hash": 250237771010213788823348212493793467085,
        "cwe": [
            "CWE-416"
        ],
        "cve": "CVE-2022-23584",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. A malicious user can cause a use after free behavior when decoding PNG images. After `png::CommonFreeDecode(&decode)` gets called, the values of `decode.width` and `decode.height` are in an unspecified state. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23584",
        "func_name": "DecodePngV2",
        "diff": [
            "diff --git a/tensorflow/core/kernels/image/decode_image_op.cc b/tensorflow/core/kernels/image/decode_image_op.cc\nindex 4573b4db0f46ca..a0345b7e0b79b0 100644\n--- a/tensorflow/core/kernels/image/decode_image_op.cc\n+++ b/tensorflow/core/kernels/image/decode_image_op.cc\n@@ -339,7 +339,6 @@ class DecodeImageV2Op : public OpKernel {\n     if (width != static_cast<int64_t>(decode.width) || width <= 0 ||\n         width >= (1LL << 27) || height != static_cast<int64_t>(decode.height) ||\n         height <= 0 || height >= (1LL << 27) || total_size >= (1LL << 29)) {\n-      png::CommonFreeDecode(&decode);\n       OP_REQUIRES(context, false,\n                   errors::InvalidArgument(\"PNG size too large for int: \",\n                                           decode.width, \" by \", decode.height));\n"
        ],
        "func_after": []
    },
    {
        "idx": 195074,
        "project": "gpac",
        "commit_id": "a69b567b8c95c72f9560c873c5ab348be058f340",
        "project_url": "https://github.com/gpac/gpac",
        "commit_url": "https://github.com/gpac/gpac/commit/a69b567b8c95c72f9560c873c5ab348be058f340",
        "commit_message": "fixed #1895",
        "target": 1,
        "irrelevant": 0,
        "func_before": "GF_AV1Config *gf_odf_av1_cfg_read_bs_size(GF_BitStream *bs, u32 size)\n{\n#ifndef GPAC_DISABLE_AV_PARSERS\n\tAV1State state;\n\tu8 reserved;\n\tGF_AV1Config *cfg;\n\n\tif (!size) size = (u32) gf_bs_available(bs);\n\tif (!size) return NULL;\n\n\tcfg = gf_odf_av1_cfg_new();\n\tgf_av1_init_state(&state);\n\tstate.config = cfg;\n\n\tcfg->marker = gf_bs_read_int(bs, 1);\n\tcfg->version = gf_bs_read_int(bs, 7);\n\tcfg->seq_profile = gf_bs_read_int(bs, 3);\n\tcfg->seq_level_idx_0 = gf_bs_read_int(bs, 5);\n\tcfg->seq_tier_0 = gf_bs_read_int(bs, 1);\n\tcfg->high_bitdepth = gf_bs_read_int(bs, 1);\n\tcfg->twelve_bit = gf_bs_read_int(bs, 1);\n\tcfg->monochrome = gf_bs_read_int(bs, 1);\n\tcfg->chroma_subsampling_x = gf_bs_read_int(bs, 1);\n\tcfg->chroma_subsampling_y = gf_bs_read_int(bs, 1);\n\tcfg->chroma_sample_position = gf_bs_read_int(bs, 2);\n\n\treserved = gf_bs_read_int(bs, 3);\n\tif (reserved != 0 || cfg->marker != 1 || cfg->version != 1) {\n\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_CONTAINER, (\"[AV1] wrong avcC reserved %d / marker %d / version %d expecting 0 1 1\\n\", reserved, cfg->marker, cfg->version));\n\t\tgf_odf_av1_cfg_del(cfg);\n\t\treturn NULL;\n\t}\n\tcfg->initial_presentation_delay_present = gf_bs_read_int(bs, 1);\n\tif (cfg->initial_presentation_delay_present) {\n\t\tcfg->initial_presentation_delay_minus_one = gf_bs_read_int(bs, 4);\n\t} else {\n\t\t/*reserved = */gf_bs_read_int(bs, 4);\n\t\tcfg->initial_presentation_delay_minus_one = 0;\n\t}\n\tsize -= 4;\n\n\twhile (size) {\n\t\tu64 pos, obu_size;\n\t\tObuType obu_type;\n\t\tGF_AV1_OBUArrayEntry *a;\n\n\t\tpos = gf_bs_get_position(bs);\n\t\tobu_size = 0;\n\t\tif (gf_av1_parse_obu(bs, &obu_type, &obu_size, NULL, &state) != GF_OK) {\n\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[AV1] could not parse AV1 OBU at position \"LLU\". Leaving parsing.\\n\", pos));\n\t\t\tbreak;\n\t\t}\n\t\tassert(obu_size == gf_bs_get_position(bs) - pos);\n\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_CONTAINER, (\"[AV1] parsed AV1 OBU type=%u size=\"LLU\" at position \"LLU\".\\n\", obu_type, obu_size, pos));\n\n\t\tif (!av1_is_obu_header(obu_type)) {\n\t\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_CONTAINER, (\"[AV1] AV1 unexpected OBU type=%u size=\"LLU\" found at position \"LLU\". Forwarding.\\n\", pos));\n\t\t}\n\t\tGF_SAFEALLOC(a, GF_AV1_OBUArrayEntry);\n\t\tif (!a) break;\n\t\ta->obu = gf_malloc((size_t)obu_size);\n\t\tif (!a->obu) {\n\t\t\tgf_free(a);\n\t\t\tbreak;\n\t\t}\n\t\tgf_bs_seek(bs, pos);\n\t\tgf_bs_read_data(bs, (char *) a->obu, (u32)obu_size);\n\t\ta->obu_length = obu_size;\n\t\ta->obu_type = obu_type;\n\t\tgf_list_add(cfg->obu_array, a);\n\n\t\tif (size<obu_size) {\n\t\t\tGF_LOG(GF_LOG_WARNING, GF_LOG_CONTAINER, (\"[AV1] AV1 config misses %d bytes to fit the entire OBU\\n\", obu_size - size));\n\t\t\tbreak;\n\t\t}\n\t\tsize -= (u32) obu_size;\n\t}\n\tgf_av1_reset_state(& state, GF_TRUE);\n\treturn cfg;\n#else\n\treturn NULL;\n#endif\n}",
        "func_hash": 270972574846681061752900592460657064315,
        "file_name": "descriptors.c",
        "file_hash": 100253523943266503998746709370742625478,
        "cwe": [
            "CWE-415"
        ],
        "cve": "CVE-2021-40571",
        "cve_desc": "The binary MP4Box in Gpac 1.0.1 has a double-free vulnerability in the ilst_box_read function in box_code_apple.c, which allows attackers to cause a denial of service, even code execution and escalation of privileges.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-40571",
        "func_name": "gf_odf_av1_cfg_read_bs_size",
        "diff": [
            "diff --git a/src/odf/descriptors.c b/src/odf/descriptors.c\nindex afc623729e..c1970e820b 100644\n--- a/src/odf/descriptors.c\n+++ b/src/odf/descriptors.c\n@@ -1613,6 +1613,7 @@ GF_AV1Config *gf_odf_av1_cfg_read_bs_size(GF_BitStream *bs, u32 size)\n \t\tsize -= (u32) obu_size;\n \t}\n \tgf_av1_reset_state(& state, GF_TRUE);\n+\tgf_bs_align(bs);\n \treturn cfg;\n #else\n \treturn NULL;\n"
        ],
        "func_after": []
    },
    {
        "idx": 195082,
        "project": "linux",
        "commit_id": "c7dfa4009965a9b2d7b329ee970eb8da0d32f0bc",
        "project_url": "https://github.com/torvalds/linux",
        "commit_url": "https://github.com/torvalds/linux/commit/c7dfa4009965a9b2d7b329ee970eb8da0d32f0bc",
        "commit_message": "KVM: nSVM: always intercept VMLOAD/VMSAVE when nested (CVE-2021-3656)\n\nIf L1 disables VMLOAD/VMSAVE intercepts, and doesn't enable\nVirtual VMLOAD/VMSAVE (currently not supported for the nested hypervisor),\nthen VMLOAD/VMSAVE must operate on the L1 physical memory, which is only\npossible by making L0 intercept these instructions.\n\nFailure to do so allowed the nested guest to run VMLOAD/VMSAVE unintercepted,\nand thus read/write portions of the host physical memory.\n\nFixes: 89c8a4984fc9 (\"KVM: SVM: Enable Virtual VMLOAD VMSAVE feature\")\n\nSuggested-by: Paolo Bonzini <pbonzini@redhat.com>\nSigned-off-by: Maxim Levitsky <mlevitsk@redhat.com>\nSigned-off-by: Paolo Bonzini <pbonzini@redhat.com>",
        "target": 1,
        "irrelevant": 0,
        "func_before": "void recalc_intercepts(struct vcpu_svm *svm)\n{\n\tstruct vmcb_control_area *c, *h, *g;\n\tunsigned int i;\n\n\tvmcb_mark_dirty(svm->vmcb, VMCB_INTERCEPTS);\n\n\tif (!is_guest_mode(&svm->vcpu))\n\t\treturn;\n\n\tc = &svm->vmcb->control;\n\th = &svm->vmcb01.ptr->control;\n\tg = &svm->nested.ctl;\n\n\tfor (i = 0; i < MAX_INTERCEPT; i++)\n\t\tc->intercepts[i] = h->intercepts[i];\n\n\tif (g->int_ctl & V_INTR_MASKING_MASK) {\n\t\t/* We only want the cr8 intercept bits of L1 */\n\t\tvmcb_clr_intercept(c, INTERCEPT_CR8_READ);\n\t\tvmcb_clr_intercept(c, INTERCEPT_CR8_WRITE);\n\n\t\t/*\n\t\t * Once running L2 with HF_VINTR_MASK, EFLAGS.IF does not\n\t\t * affect any interrupt we may want to inject; therefore,\n\t\t * interrupt window vmexits are irrelevant to L0.\n\t\t */\n\t\tvmcb_clr_intercept(c, INTERCEPT_VINTR);\n\t}\n\n\t/* We don't want to see VMMCALLs from a nested guest */\n\tvmcb_clr_intercept(c, INTERCEPT_VMMCALL);\n\n\tfor (i = 0; i < MAX_INTERCEPT; i++)\n\t\tc->intercepts[i] |= g->intercepts[i];\n\n\t/* If SMI is not intercepted, ignore guest SMI intercept as well  */\n\tif (!intercept_smi)\n\t\tvmcb_clr_intercept(c, INTERCEPT_SMI);\n}",
        "func_hash": 308018010909685377463219146239861290533,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-862"
        ],
        "cve": "CVE-2021-3656",
        "cve_desc": "A flaw was found in the KVM's AMD code for supporting SVM nested virtualization. The flaw occurs when processing the VMCB (virtual machine control block) provided by the L1 guest to spawn/handle a nested guest (L2). Due to improper validation of the \"virt_ext\" field, this issue could allow a malicious L1 to disable both VMLOAD/VMSAVE intercepts and VLS (Virtual VMLOAD/VMSAVE) for the L2 guest. As a result, the L2 guest would be allowed to read/write physical pages of the host, resulting in a crash of the entire system, leak of sensitive data or potential guest-to-host escape.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-3656",
        "func_name": "recalc_intercepts",
        "diff": [
            "diff --git a/arch/x86/kvm/svm/nested.c b/arch/x86/kvm/svm/nested.c\nindex 28381ca5221c00..e5515477c30a61 100644\n--- a/arch/x86/kvm/svm/nested.c\n+++ b/arch/x86/kvm/svm/nested.c\n@@ -158,6 +158,9 @@ void recalc_intercepts(struct vcpu_svm *svm)\n \t/* If SMI is not intercepted, ignore guest SMI intercept as well  */\n \tif (!intercept_smi)\n \t\tvmcb_clr_intercept(c, INTERCEPT_SMI);\n+\n+\tvmcb_set_intercept(c, INTERCEPT_VMLOAD);\n+\tvmcb_set_intercept(c, INTERCEPT_VMSAVE);\n }\n \n static void copy_vmcb_control_area(struct vmcb_control_area *dst,\n"
        ],
        "func_after": []
    },
    {
        "idx": 195083,
        "project": "tensorflow",
        "commit_id": "5b491cd5e41ad63735161cec9c2a568172c8b6a3",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/5b491cd5e41ad63735161cec9c2a568172c8b6a3",
        "commit_message": "Validate `proto.dtype()` before calling `set_dtype()`.\n\nThis prevents a `DCHECK`-fail when the proto contains an invalid dtype for a tensor shape with 0 elements or for an incomplete tensor shape.\n\nPiperOrigin-RevId: 408369083\nChange-Id: Ia21a3e3d62a90d642a4561f08f3b543e5ad00c46",
        "target": 1,
        "irrelevant": 0,
        "func_before": "bool Tensor::FromProto(Allocator* a, const TensorProto& proto) {\n  CHECK_NOTNULL(a);\n  TensorBuffer* p = nullptr;\n  if (!TensorShape::IsValid(proto.tensor_shape())) return false;\n  if (proto.dtype() == DT_INVALID) return false;\n  TensorShape shape(proto.tensor_shape());\n  const int64_t N = shape.num_elements();\n  if (N > 0 && proto.dtype()) {\n    bool dtype_error = false;\n    if (!proto.tensor_content().empty()) {\n      const auto& content = proto.tensor_content();\n      CASES_WITH_DEFAULT(proto.dtype(), p = Helper<T>::Decode(a, content, N),\n                         dtype_error = true, dtype_error = true);\n    } else {\n      CASES_WITH_DEFAULT(proto.dtype(), p = FromProtoField<T>(a, proto, N),\n                         dtype_error = true, dtype_error = true);\n    }\n    if (dtype_error || p == nullptr) return false;\n  }\n  shape_ = shape;\n  set_dtype(proto.dtype());\n  UnrefIfNonNull(buf_);\n  buf_ = p;\n  // TODO(misard) add tracking of which kernels and steps are calling\n  // FromProto.\n  if (MemoryLoggingEnabled() && buf_ != nullptr && buf_->data() != nullptr) {\n    LogMemory::RecordTensorAllocation(\"Unknown (from Proto)\",\n                                      LogMemory::UNKNOWN_STEP_ID, *this);\n  }\n  return true;\n}",
        "func_hash": 112719252128622113589892906952570683457,
        "file_name": "tensor.cc",
        "file_hash": 289613009517546867193769314060658742037,
        "cwe": [
            "CWE-617"
        ],
        "cve": "CVE-2022-23571",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. When decoding a tensor from protobuf, a TensorFlow process can encounter cases where a `CHECK` assertion is invalidated based on user controlled arguments, if the tensors have an invalid `dtype` and 0 elements or an invalid shape. This allows attackers to cause denial of services in TensorFlow processes. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23571",
        "func_name": "Tensor::FromProto",
        "diff": [
            "diff --git a/tensorflow/core/framework/tensor.cc b/tensorflow/core/framework/tensor.cc\nindex 8ae9fd0051652c..c7a08ee0808043 100644\n--- a/tensorflow/core/framework/tensor.cc\n+++ b/tensorflow/core/framework/tensor.cc\n@@ -983,6 +983,15 @@ bool Tensor::FromProto(Allocator* a, const TensorProto& proto) {\n                          dtype_error = true, dtype_error = true);\n     }\n     if (dtype_error || p == nullptr) return false;\n+  } else {\n+    // Handle the case of empty tensors (N = 0) or tensors with incomplete shape\n+    // (N = -1). All other values of `shape.num_elements()` should be invalid by\n+    // construction.\n+    // Here, we just need to validate that the `proto.dtype()` value is valid.\n+    bool dtype_error = false;\n+    CASES_WITH_DEFAULT(proto.dtype(), break, dtype_error = true,\n+                       dtype_error = true);\n+    if (dtype_error) return false;\n   }\n   shape_ = shape;\n   set_dtype(proto.dtype());\n"
        ],
        "func_after": []
    },
    {
        "idx": 195085,
        "project": "flatpak",
        "commit_id": "89ae9fe74c6d445bb1b3a40e568d77cf5de47e48",
        "project_url": "https://github.com/flatpak/flatpak",
        "commit_url": "https://github.com/flatpak/flatpak/commit/89ae9fe74c6d445bb1b3a40e568d77cf5de47e48",
        "commit_message": "run: Add cross-references for some other seccomp syscall filters\n\nSigned-off-by: Simon McVittie <smcv@collabora.com>",
        "target": 1,
        "irrelevant": 0,
        "func_before": "setup_seccomp (FlatpakBwrap   *bwrap,\n               const char     *arch,\n               gulong          allowed_personality,\n               FlatpakRunFlags run_flags,\n               GError        **error)\n{\n  gboolean multiarch = (run_flags & FLATPAK_RUN_FLAG_MULTIARCH) != 0;\n  gboolean devel = (run_flags & FLATPAK_RUN_FLAG_DEVEL) != 0;\n\n  __attribute__((cleanup (cleanup_seccomp))) scmp_filter_ctx seccomp = NULL;\n\n  /**** BEGIN NOTE ON CODE SHARING\n   *\n   * There are today a number of different Linux container\n   * implementations.  That will likely continue for long into the\n   * future.  But we can still try to share code, and it's important\n   * to do so because it affects what library and application writers\n   * can do, and we should support code portability between different\n   * container tools.\n   *\n   * This syscall blocklist is copied from linux-user-chroot, which was in turn\n   * clearly influenced by the Sandstorm.io blocklist.\n   *\n   * If you make any changes here, I suggest sending the changes along\n   * to other sandbox maintainers.  Using the libseccomp list is also\n   * an appropriate venue:\n   * https://groups.google.com/forum/#!forum/libseccomp\n   *\n   * A non-exhaustive list of links to container tooling that might\n   * want to share this blocklist:\n   *\n   *  https://github.com/sandstorm-io/sandstorm\n   *    in src/sandstorm/supervisor.c++\n   *  https://github.com/flatpak/flatpak.git\n   *    in common/flatpak-run.c\n   *  https://git.gnome.org/browse/linux-user-chroot\n   *    in src/setup-seccomp.c\n   *\n   **** END NOTE ON CODE SHARING\n   */\n  struct\n  {\n    int                  scall;\n    int                  errnum;\n    struct scmp_arg_cmp *arg;\n  } syscall_blocklist[] = {\n    /* Block dmesg */\n    {SCMP_SYS (syslog), EPERM},\n    /* Useless old syscall */\n    {SCMP_SYS (uselib), EPERM},\n    /* Don't allow disabling accounting */\n    {SCMP_SYS (acct), EPERM},\n    /* 16-bit code is unnecessary in the sandbox, and modify_ldt is a\n       historic source of interesting information leaks. */\n    {SCMP_SYS (modify_ldt), EPERM},\n    /* Don't allow reading current quota use */\n    {SCMP_SYS (quotactl), EPERM},\n\n    /* Don't allow access to the kernel keyring */\n    {SCMP_SYS (add_key), EPERM},\n    {SCMP_SYS (keyctl), EPERM},\n    {SCMP_SYS (request_key), EPERM},\n\n    /* Scary VM/NUMA ops */\n    {SCMP_SYS (move_pages), EPERM},\n    {SCMP_SYS (mbind), EPERM},\n    {SCMP_SYS (get_mempolicy), EPERM},\n    {SCMP_SYS (set_mempolicy), EPERM},\n    {SCMP_SYS (migrate_pages), EPERM},\n\n    /* Don't allow subnamespace setups: */\n    {SCMP_SYS (unshare), EPERM},\n    {SCMP_SYS (mount), EPERM},\n    {SCMP_SYS (pivot_root), EPERM},\n#if defined(__s390__) || defined(__s390x__) || defined(__CRIS__)\n    /* Architectures with CONFIG_CLONE_BACKWARDS2: the child stack\n     * and flags arguments are reversed so the flags come second */\n    {SCMP_SYS (clone), EPERM, &SCMP_A1 (SCMP_CMP_MASKED_EQ, CLONE_NEWUSER, CLONE_NEWUSER)},\n#else\n    /* Normally the flags come first */\n    {SCMP_SYS (clone), EPERM, &SCMP_A0 (SCMP_CMP_MASKED_EQ, CLONE_NEWUSER, CLONE_NEWUSER)},\n#endif\n\n    /* Don't allow faking input to the controlling tty (CVE-2017-5226) */\n    {SCMP_SYS (ioctl), EPERM, &SCMP_A1 (SCMP_CMP_MASKED_EQ, 0xFFFFFFFFu, (int) TIOCSTI)},\n  };\n\n  struct\n  {\n    int                  scall;\n    int                  errnum;\n    struct scmp_arg_cmp *arg;\n  } syscall_nondevel_blocklist[] = {\n    /* Profiling operations; we expect these to be done by tools from outside\n     * the sandbox.  In particular perf has been the source of many CVEs.\n     */\n    {SCMP_SYS (perf_event_open), EPERM},\n    /* Don't allow you to switch to bsd emulation or whatnot */\n    {SCMP_SYS (personality), EPERM, &SCMP_A0 (SCMP_CMP_NE, allowed_personality)},\n    {SCMP_SYS (ptrace), EPERM}\n  };\n  /* Blocklist all but unix, inet, inet6 and netlink */\n  struct\n  {\n    int             family;\n    FlatpakRunFlags flags_mask;\n  } socket_family_allowlist[] = {\n    /* NOTE: Keep in numerical order */\n    { AF_UNSPEC, 0 },\n    { AF_LOCAL, 0 },\n    { AF_INET, 0 },\n    { AF_INET6, 0 },\n    { AF_NETLINK, 0 },\n    { AF_CAN, FLATPAK_RUN_FLAG_CANBUS },\n    { AF_BLUETOOTH, FLATPAK_RUN_FLAG_BLUETOOTH },\n  };\n  int last_allowed_family;\n  int i, r;\n  g_auto(GLnxTmpfile) seccomp_tmpf  = { 0, };\n\n  seccomp = seccomp_init (SCMP_ACT_ALLOW);\n  if (!seccomp)\n    return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Initialize seccomp failed\"));\n\n  if (arch != NULL)\n    {\n      uint32_t arch_id = 0;\n      const uint32_t *extra_arches = NULL;\n\n      if (strcmp (arch, \"i386\") == 0)\n        {\n          arch_id = SCMP_ARCH_X86;\n        }\n      else if (strcmp (arch, \"x86_64\") == 0)\n        {\n          arch_id = SCMP_ARCH_X86_64;\n          extra_arches = seccomp_x86_64_extra_arches;\n        }\n      else if (strcmp (arch, \"arm\") == 0)\n        {\n          arch_id = SCMP_ARCH_ARM;\n        }\n#ifdef SCMP_ARCH_AARCH64\n      else if (strcmp (arch, \"aarch64\") == 0)\n        {\n          arch_id = SCMP_ARCH_AARCH64;\n          extra_arches = seccomp_aarch64_extra_arches;\n        }\n#endif\n\n      /* We only really need to handle arches on multiarch systems.\n       * If only one arch is supported the default is fine */\n      if (arch_id != 0)\n        {\n          /* This *adds* the target arch, instead of replacing the\n             native one. This is not ideal, because we'd like to only\n             allow the target arch, but we can't really disallow the\n             native arch at this point, because then bubblewrap\n             couldn't continue running. */\n          r = seccomp_arch_add (seccomp, arch_id);\n          if (r < 0 && r != -EEXIST)\n            return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to add architecture to seccomp filter\"));\n\n          if (multiarch && extra_arches != NULL)\n            {\n              for (i = 0; extra_arches[i] != 0; i++)\n                {\n                  r = seccomp_arch_add (seccomp, extra_arches[i]);\n                  if (r < 0 && r != -EEXIST)\n                    return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to add multiarch architecture to seccomp filter\"));\n                }\n            }\n        }\n    }\n\n  /* TODO: Should we filter the kernel keyring syscalls in some way?\n   * We do want them to be used by desktop apps, but they could also perhaps\n   * leak system stuff or secrets from other apps.\n   */\n\n  for (i = 0; i < G_N_ELEMENTS (syscall_blocklist); i++)\n    {\n      int scall = syscall_blocklist[i].scall;\n      int errnum = syscall_blocklist[i].errnum;\n\n      g_return_val_if_fail (errnum == EPERM || errnum == ENOSYS, FALSE);\n\n      if (syscall_blocklist[i].arg)\n        r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (errnum), scall, 1, *syscall_blocklist[i].arg);\n      else\n        r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (errnum), scall, 0);\n      if (r < 0 && r == -EFAULT /* unknown syscall */)\n        return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to block syscall %d\"), scall);\n    }\n\n  if (!devel)\n    {\n      for (i = 0; i < G_N_ELEMENTS (syscall_nondevel_blocklist); i++)\n        {\n          int scall = syscall_nondevel_blocklist[i].scall;\n          int errnum = syscall_nondevel_blocklist[i].errnum;\n\n          g_return_val_if_fail (errnum == EPERM || errnum == ENOSYS, FALSE);\n\n          if (syscall_nondevel_blocklist[i].arg)\n            r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (errnum), scall, 1, *syscall_nondevel_blocklist[i].arg);\n          else\n            r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (errnum), scall, 0);\n\n          if (r < 0 && r == -EFAULT /* unknown syscall */)\n            return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to block syscall %d\"), scall);\n        }\n    }\n\n  /* Socket filtering doesn't work on e.g. i386, so ignore failures here\n   * However, we need to user seccomp_rule_add_exact to avoid libseccomp doing\n   * something else: https://github.com/seccomp/libseccomp/issues/8 */\n  last_allowed_family = -1;\n  for (i = 0; i < G_N_ELEMENTS (socket_family_allowlist); i++)\n    {\n      int family = socket_family_allowlist[i].family;\n      int disallowed;\n\n      if (socket_family_allowlist[i].flags_mask != 0 &&\n          (socket_family_allowlist[i].flags_mask & run_flags) != socket_family_allowlist[i].flags_mask)\n        continue;\n\n      for (disallowed = last_allowed_family + 1; disallowed < family; disallowed++)\n        {\n          /* Blocklist the in-between valid families */\n          seccomp_rule_add_exact (seccomp, SCMP_ACT_ERRNO (EAFNOSUPPORT), SCMP_SYS (socket), 1, SCMP_A0 (SCMP_CMP_EQ, disallowed));\n        }\n      last_allowed_family = family;\n    }\n  /* Blocklist the rest */\n  seccomp_rule_add_exact (seccomp, SCMP_ACT_ERRNO (EAFNOSUPPORT), SCMP_SYS (socket), 1, SCMP_A0 (SCMP_CMP_GE, last_allowed_family + 1));\n\n  if (!glnx_open_anonymous_tmpfile_full (O_RDWR | O_CLOEXEC, \"/tmp\", &seccomp_tmpf, error))\n    return FALSE;\n\n  if (seccomp_export_bpf (seccomp, seccomp_tmpf.fd) != 0)\n    return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to export bpf\"));\n\n  lseek (seccomp_tmpf.fd, 0, SEEK_SET);\n\n  flatpak_bwrap_add_args_data_fd (bwrap,\n                                  \"--seccomp\", glnx_steal_fd (&seccomp_tmpf.fd), NULL);\n\n  return TRUE;\n}",
        "func_hash": 317270177478890809263706599611102789156,
        "file_name": "flatpak-run.c",
        "file_hash": 181541557775990000611012968168262998381,
        "cwe": [
            "CWE-20"
        ],
        "cve": "CVE-2021-41133",
        "cve_desc": "Flatpak is a system for building, distributing, and running sandboxed desktop applications on Linux. In versions prior to 1.10.4 and 1.12.0, Flatpak apps with direct access to AF_UNIX sockets such as those used by Wayland, Pipewire or pipewire-pulse can trick portals and other host-OS services into treating the Flatpak app as though it was an ordinary, non-sandboxed host-OS process. They can do this by manipulating the VFS using recent mount-related syscalls that are not blocked by Flatpak's denylist seccomp filter, in order to substitute a crafted `/.flatpak-info` or make that file disappear entirely. Flatpak apps that act as clients for AF_UNIX sockets such as those used by Wayland, Pipewire or pipewire-pulse can escalate the privileges that the corresponding services will believe the Flatpak app has. Note that protocols that operate entirely over the D-Bus session bus (user bus), system bus or accessibility bus are not affected by this. This is due to the use of a proxy process `xdg-dbus-proxy`, whose VFS cannot be manipulated by the Flatpak app, when interacting with these buses. Patches exist for versions 1.10.4 and 1.12.0, and as of time of publication, a patch for version 1.8.2 is being planned. There are no workarounds aside from upgrading to a patched version.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-41133",
        "func_name": "setup_seccomp",
        "diff": [
            "diff --git a/common/flatpak-run.c b/common/flatpak-run.c\nindex 7817ff94f0..ff6403d393 100644\n--- a/common/flatpak-run.c\n+++ b/common/flatpak-run.c\n@@ -2892,6 +2892,10 @@ setup_seccomp (FlatpakBwrap   *bwrap,\n    *  https://git.gnome.org/browse/linux-user-chroot\n    *    in src/setup-seccomp.c\n    *\n+   * Other useful resources:\n+   * https://github.com/systemd/systemd/blob/HEAD/src/shared/seccomp-util.c\n+   * https://github.com/moby/moby/blob/HEAD/profiles/seccomp/default.json\n+   *\n    **** END NOTE ON CODE SHARING\n    */\n   struct\n"
        ],
        "func_after": []
    },
    {
        "idx": 195091,
        "project": "tensorflow",
        "commit_id": "35f0fabb4c178253a964d7aabdbb15c6a398b69a",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/35f0fabb4c178253a964d7aabdbb15c6a398b69a",
        "commit_message": "Avoid Segfault for scalar shapes.\n\nCalling tensor::FromElementsOp with an empty vector of elements and no type\ncauses a segfault. We need to let the FromElementsOp know which scalar type it\nshould have.\nAlso add back the DynamicBroadcastInDimOp canonicalization patterns, which\npreviously prevented this bug from happening.\nAdd a regression test that demonstrates the bug.\n\nPiperOrigin-RevId: 417561444\nChange-Id: I6d1d6cfb71aabbad6102422625a00bbe253ac95a",
        "target": 1,
        "irrelevant": 0,
        "func_before": "llvm::Optional<Value> simplifyBroadcast(ShapeComponentAnalysis& analysis,\n                                        ValueRange shapes, Location loc,\n                                        OpBuilder* builder) {\n  // First find the input shape with the largest rank.\n  SmallVector<ArrayRef<ShapeComponentAnalysis::SymbolicExpr>> shapes_found;\n  size_t maxRank = 0;\n  for (const auto &shape : llvm::enumerate(shapes)) {\n    auto found_shape = analysis.GetValueInfo(shape.value());\n    if (!found_shape) return {};\n    shapes_found.push_back(*found_shape);\n    maxRank = std::max(maxRank, found_shape->size());\n  }\n\n  SmallVector<const ShapeComponentAnalysis::SymbolicExpr*> joined_dimensions(\n      maxRank);\n  SmallVector<std::pair<Value, int64_t>> shape_and_rank_for_dim(maxRank);\n  for (const auto &shape : llvm::enumerate(shapes_found)) {\n    for (const auto &dim : llvm::enumerate(llvm::reverse(shape.value()))) {\n      // 1 dimensions don't contribute to the final result.\n      if (dim.value().isConstant(1)) continue;\n      // If it's not a 1 dimension it will be present in the result. Remember\n      // where it came from.\n      auto index = maxRank - dim.index() - 1;\n      if (!joined_dimensions[index]) {\n        joined_dimensions[index] = &dim.value();\n        shape_and_rank_for_dim[index] =\n            std::make_pair(shapes[shape.index()], shape.value().size());\n        continue;\n      }\n      // Bail if the dimensions are neither equal nor 1.\n      if (*joined_dimensions[index] != dim.value()) return {};\n    }\n  }\n  // If the output is the same as one of the inputs just return that.\n  if (llvm::is_splat(shape_and_rank_for_dim) &&\n      shape_and_rank_for_dim[0].first) {\n    return shape_and_rank_for_dim[0].first;\n  }\n  // Otherwise rematerialize the shape from the pieces we have.\n  SmallVector<Value> elements;\n  for (int i = 0; i != maxRank; ++i) {\n    // 1 dimensions are filtered above, recreate the constant.\n    if (!shape_and_rank_for_dim[i].first) {\n      auto one = builder->getIntegerAttr(\n          shapes[0].getType().cast<RankedTensorType>().getElementType(), 1);\n      elements.push_back(builder->create<ConstantOp>(loc, one));\n      continue;\n    }\n    // Extract from one of the shapes, accounting for the reverse indexing\n    // performed by broadcast.\n    Value index = builder->create<ConstantIndexOp>(\n        loc, i - maxRank + shape_and_rank_for_dim[i].second);\n    elements.push_back(builder->create<tensor::ExtractOp>(\n        loc, shape_and_rank_for_dim[i].first, index));\n  }\n  return Value(builder->create<tensor::FromElementsOp>(loc, elements));\n}",
        "func_hash": 84683486121098934971147990908524528886,
        "file_name": "tf_cpurt_symbolic_shape_optimization.cc",
        "file_hash": 183860206963562900623001205261417288221,
        "cwe": [
            "CWE-754"
        ],
        "cve": "CVE-2022-23593",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The `simplifyBroadcast` function in the MLIR-TFRT infrastructure in TensorFlow is vulnerable to a segfault (hence, denial of service), if called with scalar shapes. If all shapes are scalar, then `maxRank` is 0, so we build an empty `SmallVector`. The fix will be included in TensorFlow 2.8.0. This is the only affected version.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23593",
        "func_name": "simplifyBroadcast",
        "diff": [
            "diff --git a/tensorflow/compiler/mlir/tfrt/jit/transforms/tf_cpurt_symbolic_shape_optimization.cc b/tensorflow/compiler/mlir/tfrt/jit/transforms/tf_cpurt_symbolic_shape_optimization.cc\nindex 628141a6cd4615..0a8fc42e80a7cd 100644\n--- a/tensorflow/compiler/mlir/tfrt/jit/transforms/tf_cpurt_symbolic_shape_optimization.cc\n+++ b/tensorflow/compiler/mlir/tfrt/jit/transforms/tf_cpurt_symbolic_shape_optimization.cc\n@@ -157,6 +157,10 @@ llvm::Optional<Value> simplifyBroadcast(ShapeComponentAnalysis& analysis,\n     shapes_found.push_back(*found_shape);\n     maxRank = std::max(maxRank, found_shape->size());\n   }\n+  if (maxRank == 0) {\n+    return Value(builder->create<tensor::FromElementsOp>(\n+        loc, shapes[0].getType(), SmallVector<Value>()));\n+  }\n \n   SmallVector<const ShapeComponentAnalysis::SymbolicExpr*> joined_dimensions(\n       maxRank);\ndiff --git a/tensorflow/compiler/mlir/tfrt/python_tests/regression_tests/scalar_broadcast.mlir b/tensorflow/compiler/mlir/tfrt/python_tests/regression_tests/scalar_broadcast.mlir\nnew file mode 100644\nindex 00000000000000..33b785ee6fb19d\n--- /dev/null\n+++ b/tensorflow/compiler/mlir/tfrt/python_tests/regression_tests/scalar_broadcast.mlir\n@@ -0,0 +1,11 @@\n+builtin.func @test(%V__0 : tensor<i1> { python_test_attrs.static_type = tensor<i1> }, %V__1 : tensor<f32> { python_test_attrs.static_type = tensor<f32> }, %V__2 : tensor<f32> { python_test_attrs.static_type = tensor<f32> }) -> tensor<f32> {\n+  %0 = \"tf.Cast\"(%V__0) : (tensor<i1>) -> tensor<i1>\n+  %1 = \"tf.Selu\"(%V__2) : (tensor<f32>) -> tensor<f32>\n+  %2 = \"tf.NextAfter\"(%1, %V__2) : (tensor<f32>, tensor<f32>) -> tensor<f32>\n+  %3 = \"tf.Elu\"(%2) : (tensor<f32>) -> tensor<f32>\n+  %4 = \"tf.Cosh\"(%3) : (tensor<f32>) -> tensor<f32>\n+  %5 = \"tf.Elu\"(%4) : (tensor<f32>) -> tensor<f32>\n+  %6 = \"tf.Div\"(%V__1, %5) : (tensor<f32>, tensor<f32>) -> tensor<f32>\n+  %7 = \"tf.Select\"(%0, %6, %V__1) : (tensor<i1>, tensor<f32>, tensor<f32>) -> tensor<f32>\n+  return %7 : tensor<f32>\n+}\n\\ No newline at end of file\n"
        ],
        "func_after": []
    },
    {
        "idx": 195092,
        "project": "hermes",
        "commit_id": "55e1b2343f4deb1a1b5726cfe1e23b2068217ff2",
        "project_url": "https://github.com/facebook/hermes",
        "commit_url": "https://github.com/facebook/hermes/commit/55e1b2343f4deb1a1b5726cfe1e23b2068217ff2",
        "commit_message": "Handle typeof applied to empty in InstSimplify\n\nSummary:\nDo not simplify `typeof` if it is applied to an invalid type. This\nhandles a case like the one in the added test, where `typeof` is called\non a literal empty in unreachable code.\n\nReviewed By: kodafb\n\nDifferential Revision: D31000173\n\nfbshipit-source-id: 2d7f69cbcc9c1bb0a916585c07171089444c85dc",
        "target": 1,
        "irrelevant": 0,
        "func_before": "Literal *hermes::evalUnaryOperator(\n    UnaryOperatorInst::OpKind kind,\n    IRBuilder &builder,\n    Literal *operand) {\n  switch (kind) {\n    case UnaryOperatorInst::OpKind::MinusKind:\n      // Negate constant integers.\n      switch (operand->getKind()) {\n        case ValueKind::LiteralNumberKind:\n          if (auto *literalNum = llvh::dyn_cast<LiteralNumber>(operand)) {\n            auto V = -literalNum->getValue();\n            return builder.getLiteralNumber(V);\n          }\n          break;\n        case ValueKind::LiteralUndefinedKind:\n          return builder.getLiteralNaN();\n        case ValueKind::LiteralBoolKind:\n          if (evalIsTrue(builder, operand)) {\n            return builder.getLiteralNumber(-1);\n          } else { // evalIsFalse(operand)\n            return builder.getLiteralNegativeZero();\n          }\n        case ValueKind::LiteralNullKind:\n          return builder.getLiteralNegativeZero();\n        default:\n          break;\n      }\n      break;\n    case UnaryOperatorInst::OpKind::TypeofKind:\n      switch (operand->getKind()) {\n        case ValueKind::GlobalObjectKind:\n        case ValueKind::LiteralNullKind:\n          return builder.getLiteralString(\"object\");\n        case ValueKind::LiteralUndefinedKind:\n          return builder.getLiteralString(\"undefined\");\n        case ValueKind::LiteralBoolKind:\n          return builder.getLiteralString(\"boolean\");\n        case ValueKind::LiteralNumberKind:\n          return builder.getLiteralString(\"number\");\n        case ValueKind::LiteralStringKind:\n          return builder.getLiteralString(\"string\");\n        default:\n          llvm_unreachable(\"Invalid literal kind.\");\n      }\n      break;\n\n    case UnaryOperatorInst::OpKind::BangKind:\n      if (evalIsTrue(builder, operand)) {\n        return builder.getLiteralBool(false);\n      }\n      if (evalIsFalse(builder, operand)) {\n        return builder.getLiteralBool(true);\n      }\n      break;\n\n    case UnaryOperatorInst::OpKind::VoidKind:\n      return builder.getLiteralUndefined();\n\n    default:\n      break;\n  }\n\n  return nullptr;\n}",
        "func_hash": 318397569222892175642900890058916302083,
        "file_name": "IREval.cpp",
        "file_hash": 25640608993938735880507555687030796129,
        "cwe": [
            "CWE-843"
        ],
        "cve": "CVE-2021-24045",
        "cve_desc": "A type confusion vulnerability could be triggered when resolving the \"typeof\" unary operator in Facebook Hermes prior to v0.10.0. Note that this is only exploitable if the application using Hermes permits evaluation of untrusted JavaScript. Hence, most React Native applications are not affected.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-24045",
        "func_name": "hermes::evalUnaryOperator",
        "diff": [
            "diff --git a/lib/IR/IREval.cpp b/lib/IR/IREval.cpp\nindex a07efd66dcb..3ddb40d74b0 100644\n--- a/lib/IR/IREval.cpp\n+++ b/lib/IR/IREval.cpp\n@@ -107,7 +107,7 @@ Literal *hermes::evalUnaryOperator(\n         case ValueKind::LiteralStringKind:\n           return builder.getLiteralString(\"string\");\n         default:\n-          llvm_unreachable(\"Invalid literal kind.\");\n+          break;\n       }\n       break;\n \ndiff --git a/test/hermes/tdz-check.js b/test/hermes/tdz-check.js\nindex 0533c1c49d7..fa82b26e8fb 100644\n--- a/test/hermes/tdz-check.js\n+++ b/test/hermes/tdz-check.js\n@@ -45,3 +45,8 @@ test(() => {\n     return x;\n });\n //CHECK-NEXT: caught ReferenceError: accessing an uninitialized variable\n+\n+test(() => {\n+    const foo = print(foo, typeof foo)\n+});\n+//CHECK-NEXT: caught ReferenceError: accessing an uninitialized variable\n"
        ],
        "func_after": []
    },
    {
        "idx": 195095,
        "project": "e2guardian",
        "commit_id": "eae46a7e2a57103aadca903c4a24cca94dc502a2",
        "project_url": "https://github.com/e2guardian/e2guardian",
        "commit_url": "https://github.com/e2guardian/e2guardian/commit/eae46a7e2a57103aadca903c4a24cca94dc502a2",
        "commit_message": "Fix bug #707 cert hostnames not being checked\n- only happened when openssl v1.1 is used",
        "target": 1,
        "irrelevant": 1,
        "func_before": "int Socket::startSslClient(const std::string &certificate_path, String hostname)\n{\n    if (isssl) {\n        stopSsl();\n    }\n\n    ERR_clear_error();\n#if OPENSSL_VERSION_NUMBER < 0x10100000L\n    ctx = SSL_CTX_new(SSLv23_client_method());\n#else\n    ctx = SSL_CTX_new(TLS_client_method());\n#endif\n\n    if (ctx == NULL) {\n#ifdef NETDEBUG\n        std::cout << thread_id << \"Error ssl context is null (check that openssl has been inited)\" << std::endl;\n#endif\n        log_ssl_errors(\"Error ssl context is null for %s\", hostname.c_str());\n        return -1;\n    }\n\n    //set the timeout for the ssl session\n    if (SSL_CTX_set_timeout(ctx, 130l) < 1) {\n            SSL_CTX_free(ctx);\n            ctx = NULL;\n        return -1;\n    }\n\n    //load certs\n    ERR_clear_error();\n    if (certificate_path.length()) {\n        if (!SSL_CTX_load_verify_locations(ctx, NULL, certificate_path.c_str())) {\n#ifdef NETDEBUG\n            std::cout << thread_id << \"couldnt load certificates\" << std::endl;\n#endif\n            log_ssl_errors(\"couldnt load certificates from %s\", certificate_path.c_str());\n            //tidy up\n            SSL_CTX_free(ctx);\n            ctx = NULL;\n            return -2;\n        }\n    } else if (!SSL_CTX_set_default_verify_paths(ctx)) //use default if no certPpath given\n    {\n#ifdef NETDEBUG\n        std::cout << thread_id << \"couldnt load certificates\" << std::endl;\n#endif\n            log_ssl_errors(\"couldnt load default certificates for %s\", hostname.c_str());\n        //tidy up\n        SSL_CTX_free(ctx);\n        ctx = NULL;\n        return -2;\n    }\n\n    // add validation params\n    ERR_clear_error();\n    X509_VERIFY_PARAM *x509_param = X509_VERIFY_PARAM_new();\n    if (!x509_param) {\n        log_ssl_errors(\"couldnt add validation params for %s\", hostname.c_str());\n        //X509_VERIFY_PARAM_free(x509_param);\n            SSL_CTX_free(ctx);\n            ctx = NULL;\n        return -2;\n    }\n\n    ERR_clear_error();\n    if (!X509_VERIFY_PARAM_set_flags(x509_param, X509_V_FLAG_TRUSTED_FIRST)) {\n        log_ssl_errors(\"couldnt add validation params for %s\", hostname.c_str());\n        X509_VERIFY_PARAM_free(x509_param);\n            SSL_CTX_free(ctx);\n            ctx = NULL;\n        return -2;\n    }\n\n    ERR_clear_error();\n    if (!SSL_CTX_set1_param(ctx, x509_param)) {\n        log_ssl_errors(\"couldnt add validation params for %s\", hostname.c_str());\n        X509_VERIFY_PARAM_free(x509_param);\n            SSL_CTX_free(ctx);\n            ctx = NULL;\n        return -2;\n    }\n\n    X509_VERIFY_PARAM_free(x509_param);     // try not freeing this as SSL_CTX_free seems to be ring to free it\n\n    //hand socket over to ssl lib\n    ERR_clear_error();\n    ssl = SSL_new(ctx);\n    SSL_set_options(ssl, SSL_OP_ALL);\n    SSL_set_mode(ssl, SSL_MODE_AUTO_RETRY);\n    SSL_set_connect_state(ssl);\n\n    //fcntl(this->getFD() ,F_SETFL, O_NONBLOCK); // blocking mode used currently\n    SSL_set_fd(ssl, this->getFD());\n    SSL_set_tlsext_host_name(ssl, hostname.c_str());\n\n    //make io non blocking as select wont tell us if we can do a read without blocking\n    //BIO_set_nbio(SSL_get_rbio(ssl),1l);  // blocking mode used currently\n    //BIO_set_nbio(SSL_get_wbio(ssl),1l); // blocking mode used currently\n    ERR_clear_error();\n    int rc = SSL_connect(ssl);\n    if (rc < 0) {\n        log_ssl_errors(\"ssl_connect failed to %s\", hostname.c_str());\n#ifdef NETDEBUG\n        std::cout << thread_id << \"ssl_connect failed with error \" << SSL_get_error(ssl, rc) << std::endl;\n#endif\n        // tidy up\n        SSL_free(ssl);\n        ssl = NULL;\n        SSL_CTX_free(ctx);\n        ctx = NULL;\n        return -3;\n    }\n\n    //should be safer to do this last as nothing will ever try to use a ssl socket that isnt fully setup\n    isssl = true;\n    issslserver = false;\n    return 0;\n}",
        "func_hash": 285364534121786496260977042144971081331,
        "file_name": "Socket.cpp",
        "file_hash": 283084154597152068392957992825637904487,
        "cwe": [
            "CWE-295"
        ],
        "cve": "CVE-2021-44273",
        "cve_desc": "e2guardian v5.4.x <= v5.4.3r is affected by missing SSL certificate validation in the SSL MITM engine. In standalone mode (i.e., acting as a proxy or a transparent proxy), with SSL MITM enabled, e2guardian, if built with OpenSSL v1.1.x, did not validate hostnames in certificates of the web servers that it connected to, and thus was itself vulnerable to MITM attacks.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-44273",
        "func_name": "Socket::startSslClient",
        "diff": [
            "diff --git a/src/Socket.cpp b/src/Socket.cpp\nindex 6ef9619c..2b687ef5 100644\n--- a/src/Socket.cpp\n+++ b/src/Socket.cpp\n@@ -377,6 +377,10 @@ int Socket::startSslClient(const std::string &certificate_path, String hostname)\n     //fcntl(this->getFD() ,F_SETFL, O_NONBLOCK); // blocking mode used currently\n     SSL_set_fd(ssl, this->getFD());\n     SSL_set_tlsext_host_name(ssl, hostname.c_str());\n+#if OPENSSL_VERSION_NUMBER < 0x10100000L\n+#else\n+  X509_VERIFY_PARAM_set1_host(SSL_get0_param(ssl),hostname.c_str(),0);\n+#endif\n \n     //make io non blocking as select wont tell us if we can do a read without blocking\n     //BIO_set_nbio(SSL_get_rbio(ssl),1l);  // blocking mode used currently\n"
        ],
        "func_after": []
    },
    {
        "idx": 195216,
        "project": "tensorflow",
        "commit_id": "3d89911481ba6ebe8c88c1c0b595412121e6c645",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/3d89911481ba6ebe8c88c1c0b595412121e6c645",
        "commit_message": "Eliminate `CHECK`-fail from `function.cc`.\n\nPiperOrigin-RevId: 409414744\nChange-Id: Ic854e12ab2edb88b165d32e2d632c4ee654d71ad",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  Status BuildInputArgIndex(const OpDef::ArgDef& arg_def, AttrSlice attr_values,\n                            const FunctionDef::ArgAttrs* arg_attrs,\n                            bool ints_on_device,\n                            int64_t resource_arg_unique_id) {\n    bool is_type_list;\n    DataTypeVector dtypes;\n    TF_RETURN_IF_ERROR(\n        ArgNumType(attr_values, arg_def, &is_type_list, &dtypes));\n    CHECK_GE(dtypes.size(), size_t{1});\n    int arg_index = result_.nodes.size();\n    TF_RETURN_IF_ERROR(\n        AddItem(arg_def.name(), {true, arg_index, 0, is_type_list, dtypes}));\n    // Creates dtypes.size() nodes in the graph.\n    for (size_t i = 0; i < dtypes.size(); ++i) {\n      TF_RETURN_IF_ERROR(AddItem(strings::StrCat(arg_def.name(), \":\", i),\n                                 {true, arg_index, 0, false, {dtypes[i]}}));\n      DCHECK_EQ(arg_index, result_.nodes.size());\n      string name = arg_def.name();\n      if (dtypes.size() > 1) {\n        strings::StrAppend(&name, \"_\", i);\n      }\n      NodeDef* gnode = AddNode(name);\n      if (ints_on_device && dtypes[i] == DataType::DT_INT32) {\n        gnode->set_op(FunctionLibraryDefinition::kDeviceArgOp);\n      } else {\n        gnode->set_op(FunctionLibraryDefinition::kArgOp);\n      }\n      DataType dtype = arg_def.is_ref() ? MakeRefType(dtypes[i]) : dtypes[i];\n      AddAttr(\"T\", dtype, gnode);\n      AddAttr(\"index\", arg_index, gnode);\n      if (resource_arg_unique_id >= 0) {\n        AddAttr(\"_resource_arg_unique_id\", resource_arg_unique_id, gnode);\n      }\n      if (arg_attrs) {\n        for (const auto& arg_attr : arg_attrs->attr()) {\n          AddAttr(arg_attr.first, arg_attr.second, gnode->mutable_attr());\n        }\n      }\n      result_.arg_types.push_back(dtypes[i]);\n      ++arg_index;\n    }\n    return Status::OK();\n  }",
        "func_hash": 195029536653628646842978253954389653589,
        "file_name": "function.cc",
        "file_hash": 203653418997522182482043276556638340074,
        "cwe": [
            "CWE-617"
        ],
        "cve": "CVE-2022-23586",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. A malicious user can cause a denial of service by altering a `SavedModel` such that assertions in `function.cc` would be falsified and crash the Python interpreter. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23586",
        "func_name": "BuildInputArgIndex",
        "diff": [
            "diff --git a/tensorflow/core/framework/function.cc b/tensorflow/core/framework/function.cc\nindex 41b8d446149694..492d9d54fe60eb 100644\n--- a/tensorflow/core/framework/function.cc\n+++ b/tensorflow/core/framework/function.cc\n@@ -181,7 +181,9 @@ class FunctionInstantiationHelper {\n     DataTypeVector dtypes;\n     TF_RETURN_IF_ERROR(\n         ArgNumType(attr_values, arg_def, &is_type_list, &dtypes));\n-    CHECK_GE(dtypes.size(), size_t{1});\n+    if (dtypes.size() < size_t{1}) {\n+      return errors::Internal(\"Expected a list of at least one dtype\");\n+    }\n     int arg_index = result_.nodes.size();\n     TF_RETURN_IF_ERROR(\n         AddItem(arg_def.name(), {true, arg_index, 0, is_type_list, dtypes}));\n"
        ],
        "func_after": []
    },
    {
        "idx": 195218,
        "project": "mruby",
        "commit_id": "0849a2885f81cfd82134992c06df3ccd59052ac7",
        "project_url": "https://github.com/mruby/mruby",
        "commit_url": "https://github.com/mruby/mruby/commit/0849a2885f81cfd82134992c06df3ccd59052ac7",
        "commit_message": "codegen.c: stack position may be wrong on assignments.\n\nWhen `[]=` access includes keyword arguments.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "gen_assignment(codegen_scope *s, node *tree, node *rhs, int sp, int val)\n{\n  int idx;\n  int type = nint(tree->car);\n\n  switch (type) {\n  case NODE_GVAR:\n  case NODE_ARG:\n  case NODE_LVAR:\n  case NODE_IVAR:\n  case NODE_CVAR:\n  case NODE_CONST:\n  case NODE_NIL:\n  case NODE_MASGN:\n    if (rhs) {\n      codegen(s, rhs, VAL);\n      pop();\n      sp = cursp();\n    }\n    break;\n\n  case NODE_COLON2:\n  case NODE_CALL:\n  case NODE_SCALL:\n    /* keep evaluation order */\n    break;\n\n  case NODE_NVAR:\n    codegen_error(s, \"Can't assign to numbered parameter\");\n    break;\n\n  default:\n    codegen_error(s, \"unknown lhs\");\n    break;\n  }\n\n  tree = tree->cdr;\n  switch (type) {\n  case NODE_GVAR:\n    gen_setxv(s, OP_SETGV, sp, nsym(tree), val);\n    break;\n  case NODE_ARG:\n  case NODE_LVAR:\n    idx = lv_idx(s, nsym(tree));\n    if (idx > 0) {\n      if (idx != sp) {\n        gen_move(s, idx, sp, val);\n      }\n      break;\n    }\n    else {                      /* upvar */\n      gen_setupvar(s, sp, nsym(tree));\n    }\n    break;\n  case NODE_IVAR:\n    gen_setxv(s, OP_SETIV, sp, nsym(tree), val);\n    break;\n  case NODE_CVAR:\n    gen_setxv(s, OP_SETCV, sp, nsym(tree), val);\n    break;\n  case NODE_CONST:\n    gen_setxv(s, OP_SETCONST, sp, nsym(tree), val);\n    break;\n  case NODE_COLON2:\n    if (sp) {\n      gen_move(s, cursp(), sp, 0);\n    }\n    sp = cursp();\n    push();\n    codegen(s, tree->car, VAL);\n    if (rhs) {\n      codegen(s, rhs, VAL); pop();\n      gen_move(s, sp, cursp(), 0);\n    }\n    pop_n(2);\n    idx = new_sym(s, nsym(tree->cdr));\n    genop_2(s, OP_SETMCNST, sp, idx);\n    break;\n\n  case NODE_CALL:\n  case NODE_SCALL:\n    {\n      int noself = 0, safe = (type == NODE_SCALL), skip = 0, top, call, n = 0;\n      mrb_sym mid = nsym(tree->cdr->car);\n\n      top = cursp();\n      if (val || sp == cursp()) {\n        push();                   /* room for retval */\n      }\n      call = cursp();\n      if (!tree->car) {\n        noself = 1;\n        push();\n      }\n      else {\n        codegen(s, tree->car, VAL); /* receiver */\n      }\n      if (safe) {\n        int recv = cursp()-1;\n        gen_move(s, cursp(), recv, 1);\n        skip = genjmp2_0(s, OP_JMPNIL, cursp(), val);\n      }\n      tree = tree->cdr->cdr->car;\n      if (tree) {\n        if (tree->car) {            /* positional arguments */\n          n = gen_values(s, tree->car, VAL, (tree->cdr->car)?13:14);\n          if (n < 0) {              /* variable length */\n            n = 15;\n            push();\n          }\n        }\n        if (tree->cdr->car) {       /* keyword arguments */\n          gen_hash(s, tree->cdr->car->cdr, VAL, 0);\n          if (n < 14) {\n            n++;\n            push();\n          }\n          else {\n            pop();\n            genop_2(s, OP_ARYPUSH, cursp(), 1);\n          }\n        }\n      }\n      if (rhs) {\n        codegen(s, rhs, VAL);\n        pop();\n      }\n      else {\n        gen_move(s, cursp(), sp, 0);\n      }\n      if (val) {\n        gen_move(s, top, cursp(), 1);\n      }\n      if (n < 14) {\n        n++;\n      }\n      else {\n        pop();\n        genop_2(s, OP_ARYPUSH, cursp(), 1);\n      }\n      s->sp = call;\n      if (mid == MRB_OPSYM_2(s->mrb, aref) && n == 2) {\n        genop_1(s, OP_SETIDX, cursp());\n      }\n      else {\n        genop_3(s, noself ? OP_SSEND : OP_SEND, cursp(), new_sym(s, attrsym(s, mid)), n);\n      }\n      if (safe) {\n        dispatch(s, skip);\n      }\n      s->sp = top;\n    }\n    break;\n\n  case NODE_MASGN:\n    gen_vmassignment(s, tree->car, sp, val);\n    break;\n\n  /* splat without assignment */\n  case NODE_NIL:\n    break;\n\n  default:\n    codegen_error(s, \"unknown lhs\");\n    break;\n  }\n  if (val) push();\n}",
        "func_hash": 12667856709713500812869636396145269639,
        "file_name": "codegen.c",
        "file_hash": 19439930809958148904555588093451410064,
        "cwe": [
            "CWE-125"
        ],
        "cve": "CVE-2022-0525",
        "cve_desc": "Out-of-bounds Read in Homebrew mruby prior to 3.2.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-0525",
        "func_name": "gen_assignment",
        "diff": [
            "diff --git a/mrbgems/mruby-compiler/core/codegen.c b/mrbgems/mruby-compiler/core/codegen.c\nindex 4a9fb9aeb0..86f88b6e64 100644\n--- a/mrbgems/mruby-compiler/core/codegen.c\n+++ b/mrbgems/mruby-compiler/core/codegen.c\n@@ -1865,15 +1865,21 @@ gen_assignment(codegen_scope *s, node *tree, node *rhs, int sp, int val)\n           }\n         }\n         if (tree->cdr->car) {       /* keyword arguments */\n+          if (n == 14) {\n+            pop_n(n);\n+            genop_2(s, OP_ARRAY, cursp(), n);\n+            push();\n+            n = 15;\n+          }\n           gen_hash(s, tree->cdr->car->cdr, VAL, 0);\n           if (n < 14) {\n             n++;\n-            push();\n           }\n           else {\n-            pop();\n+            pop_n(2);\n             genop_2(s, OP_ARYPUSH, cursp(), 1);\n           }\n+          push();\n         }\n       }\n       if (rhs) {\n"
        ],
        "func_after": []
    },
    {
        "idx": 195220,
        "project": "tmate-ssh-server",
        "commit_id": "1c020d1f5ca462f5b150b46a027aaa1bbe3c9596",
        "project_url": "https://github.com/tmate-io/tmate-ssh-server",
        "commit_url": "https://github.com/tmate-io/tmate-ssh-server/commit/1c020d1f5ca462f5b150b46a027aaa1bbe3c9596",
        "commit_message": "Harden /tmp/tmate directory\n\nSuggested by Matthias Gerstner",
        "target": 1,
        "irrelevant": 0,
        "func_before": "int main(int argc, char **argv, char **envp)\n{\n\tint opt;\n\n\twhile ((opt = getopt(argc, argv, \"b:h:k:p:q:w:z:xv\")) != -1) {\n\t\tswitch (opt) {\n\t\tcase 'b':\n\t\t\ttmate_settings->bind_addr = xstrdup(optarg);\n\t\t\tbreak;\n\t\tcase 'h':\n\t\t\ttmate_settings->tmate_host = xstrdup(optarg);\n\t\t\tbreak;\n\t\tcase 'k':\n\t\t\ttmate_settings->keys_dir = xstrdup(optarg);\n\t\t\tbreak;\n\t\tcase 'p':\n\t\t\ttmate_settings->ssh_port = atoi(optarg);\n\t\t\tbreak;\n\t\tcase 'q':\n\t\t\ttmate_settings->ssh_port_advertized = atoi(optarg);\n\t\t\tbreak;\n\t\tcase 'w':\n\t\t\ttmate_settings->websocket_hostname = xstrdup(optarg);\n\t\t\tbreak;\n\t\tcase 'z':\n\t\t\ttmate_settings->websocket_port = atoi(optarg);\n\t\t\tbreak;\n\t\tcase 'x':\n\t\t\ttmate_settings->use_proxy_protocol = true;\n\t\t\tbreak;\n\t\tcase 'v':\n\t\t\ttmate_settings->log_level++;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tusage();\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\tinit_logging(tmate_settings->log_level);\n\n\tsetup_locale();\n\n\tif (!tmate_settings->tmate_host)\n\t\ttmate_settings->tmate_host = get_full_hostname();\n\n\tcmdline = *argv;\n\tcmdline_end = *envp;\n\n\ttmate_preload_trace_lib();\n\ttmate_catch_sigsegv();\n\ttmate_init_rand();\n\n\tif ((mkdir(TMATE_WORKDIR, 0701)             < 0 && errno != EEXIST) ||\n\t    (mkdir(TMATE_WORKDIR \"/sessions\", 0703) < 0 && errno != EEXIST) ||\n\t    (mkdir(TMATE_WORKDIR \"/jail\", 0700)     < 0 && errno != EEXIST))\n\t\ttmate_fatal(\"Cannot prepare session in \" TMATE_WORKDIR);\n\n\t/* The websocket server needs to access the /session dir to rename sockets */\n\tif ((chmod(TMATE_WORKDIR, 0701)             < 0) ||\n\t    (chmod(TMATE_WORKDIR \"/sessions\", 0703) < 0) ||\n\t    (chmod(TMATE_WORKDIR \"/jail\", 0700)     < 0))\n\t\ttmate_fatal(\"Cannot prepare session in \" TMATE_WORKDIR);\n\n\ttmate_ssh_server_main(tmate_session,\n\t\t\t      tmate_settings->keys_dir, tmate_settings->bind_addr, tmate_settings->ssh_port);\n\treturn 0;\n}",
        "func_hash": 154027151645284385944526585123822701001,
        "file_name": "tmate-main.c",
        "file_hash": 280350825550794138629823084137678566150,
        "cwe": [
            "CWE-362"
        ],
        "cve": "CVE-2021-44512",
        "cve_desc": "World-writable permissions on the /tmp/tmate/sessions directory in tmate-ssh-server 2.3.0 allow a local attacker to compromise the integrity of session handling, or obtain the read-write session ID from a read-only session symlink in this directory.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-44512",
        "func_name": "main",
        "diff": [
            "diff --git a/tmate-main.c b/tmate-main.c\nindex 86560ecb..69f33209 100644\n--- a/tmate-main.c\n+++ b/tmate-main.c\n@@ -98,6 +98,24 @@ static void setup_locale(void)\n \ttzset();\n }\n \n+static int check_owned_directory_mode(const char *path, mode_t expected_mode)\n+{\n+\tstruct stat stat;\n+\tif (lstat(path, &stat))\n+\t\treturn -1;\n+\n+\tif (!S_ISDIR(stat.st_mode))\n+\t\treturn -1;\n+\n+\tif (stat.st_uid != getuid())\n+\t\treturn -1;\n+\n+\tif ((stat.st_mode & 07777) != expected_mode)\n+\t\treturn -1;\n+\n+\treturn 0;\n+}\n+\n int main(int argc, char **argv, char **envp)\n {\n \tint opt;\n@@ -151,17 +169,22 @@ int main(int argc, char **argv, char **envp)\n \ttmate_catch_sigsegv();\n \ttmate_init_rand();\n \n-\tif ((mkdir(TMATE_WORKDIR, 0701)             < 0 && errno != EEXIST) ||\n-\t    (mkdir(TMATE_WORKDIR \"/sessions\", 0703) < 0 && errno != EEXIST) ||\n+\tif ((mkdir(TMATE_WORKDIR, 0700)             < 0 && errno != EEXIST) ||\n+\t    (mkdir(TMATE_WORKDIR \"/sessions\", 0700) < 0 && errno != EEXIST) ||\n \t    (mkdir(TMATE_WORKDIR \"/jail\", 0700)     < 0 && errno != EEXIST))\n \t\ttmate_fatal(\"Cannot prepare session in \" TMATE_WORKDIR);\n \n-\t/* The websocket server needs to access the /session dir to rename sockets */\n-\tif ((chmod(TMATE_WORKDIR, 0701)             < 0) ||\n-\t    (chmod(TMATE_WORKDIR \"/sessions\", 0703) < 0) ||\n+\tif ((chmod(TMATE_WORKDIR, 0700)             < 0) ||\n+\t    (chmod(TMATE_WORKDIR \"/sessions\", 0700) < 0) ||\n \t    (chmod(TMATE_WORKDIR \"/jail\", 0700)     < 0))\n \t\ttmate_fatal(\"Cannot prepare session in \" TMATE_WORKDIR);\n \n+\tif (check_owned_directory_mode(TMATE_WORKDIR, 0700) ||\n+\t    check_owned_directory_mode(TMATE_WORKDIR \"/sessions\", 0700) ||\n+\t    check_owned_directory_mode(TMATE_WORKDIR \"/jail\", 0700))\n+\t\ttmate_fatal(TMATE_WORKDIR \" and subdirectories has incorrect ownership/mode. \"\n+\t\t\t    \"Try deleting \" TMATE_WORKDIR \" and try again\");\n+\n \ttmate_ssh_server_main(tmate_session,\n \t\t\t      tmate_settings->keys_dir, tmate_settings->bind_addr, tmate_settings->ssh_port);\n \treturn 0;\n"
        ],
        "func_after": []
    },
    {
        "idx": 195230,
        "project": "pjproject",
        "commit_id": "f74c1fc22b760d2a24369aa72c74c4a9ab985859",
        "project_url": "https://github.com/pjsip/pjproject",
        "commit_url": "https://github.com/pjsip/pjproject/commit/f74c1fc22b760d2a24369aa72c74c4a9ab985859",
        "commit_message": "Merge pull request from GHSA-r374-qrwv-86hh",
        "target": 1,
        "irrelevant": 1,
        "func_before": "void pjmedia_rtcp_xr_rx_rtcp_xr( pjmedia_rtcp_xr_session *sess,\n\t\t\t\t const void *pkt,\n\t\t\t\t pj_size_t size)\n{\n    const pjmedia_rtcp_xr_pkt\t      *rtcp_xr = (pjmedia_rtcp_xr_pkt*) pkt;\n    const pjmedia_rtcp_xr_rb_rr_time  *rb_rr_time = NULL;\n    const pjmedia_rtcp_xr_rb_dlrr     *rb_dlrr = NULL;\n    const pjmedia_rtcp_xr_rb_stats    *rb_stats = NULL;\n    const pjmedia_rtcp_xr_rb_voip_mtc *rb_voip_mtc = NULL;\n    const pjmedia_rtcp_xr_rb_header   *rb_hdr = (pjmedia_rtcp_xr_rb_header*) \n\t\t\t\t\t\trtcp_xr->buf;\n    unsigned pkt_len, rb_len;\n\n    if (rtcp_xr->common.pt != RTCP_XR)\n\treturn;\n\n    pkt_len = pj_ntohs((pj_uint16_t)rtcp_xr->common.length);\n\n    if ((pkt_len + 1) > (size / 4))\n\treturn;\n\n    /* Parse report rpt_types */\n    while ((pj_int32_t*)rb_hdr < (pj_int32_t*)pkt + pkt_len)\n    {\t\n\trb_len = pj_ntohs((pj_uint16_t)rb_hdr->length);\n\n\t/* Just skip any block with length == 0 (no report content) */\n\tif (rb_len) {\n\t    switch (rb_hdr->bt) {\n\t\tcase BT_RR_TIME:\n\t\t    rb_rr_time = (pjmedia_rtcp_xr_rb_rr_time*) rb_hdr;\n\t\t    break;\n\t\tcase BT_DLRR:\n\t\t    rb_dlrr = (pjmedia_rtcp_xr_rb_dlrr*) rb_hdr;\n\t\t    break;\n\t\tcase BT_STATS:\n\t\t    rb_stats = (pjmedia_rtcp_xr_rb_stats*) rb_hdr;\n\t\t    break;\n\t\tcase BT_VOIP_METRICS:\n\t\t    rb_voip_mtc = (pjmedia_rtcp_xr_rb_voip_mtc*) rb_hdr;\n\t\t    break;\n\t\tdefault:\n\t\t    break;\n\t    }\n\t}\n\trb_hdr = (pjmedia_rtcp_xr_rb_header*)\n\t\t ((pj_int32_t*)rb_hdr + rb_len + 1);\n    }\n\n    /* Receiving RR Time */\n    if (rb_rr_time) {\n\t/* Save LRR from NTP timestamp of the RR time block report */\n\tsess->rx_lrr = ((pj_ntohl(rb_rr_time->ntp_sec) & 0x0000FFFF) << 16) | \n\t\t       ((pj_ntohl(rb_rr_time->ntp_frac) >> 16) & 0xFFFF);\n\n\t/* Calculate RR arrival time for DLRR */\n\tpj_get_timestamp(&sess->rx_lrr_time);\n\n\tTRACE_((sess->name, \"Rx RTCP SR: ntp_ts=%p\", sess->rx_lrr,\n\t       (pj_uint32_t)(sess->rx_lrr_time.u64*65536/\n\t\t\t     sess->rtcp_session->ts_freq.u64)));\n    }\n\n    /* Receiving DLRR */\n    if (rb_dlrr) {\n\tpj_uint32_t lrr, now, dlrr;\n\tpj_uint64_t eedelay;\n\tpjmedia_rtcp_ntp_rec ntp;\n\n\t/* LRR is the middle 32bit of NTP. It has 1/65536 second \n\t * resolution \n\t */\n\tlrr = pj_ntohl(rb_dlrr->item.lrr);\n\n\t/* DLRR is delay since LRR, also in 1/65536 resolution */\n\tdlrr = pj_ntohl(rb_dlrr->item.dlrr);\n\n\t/* Get current time, and convert to 1/65536 resolution */\n\tpjmedia_rtcp_get_ntp_time(sess->rtcp_session, &ntp);\n\tnow = ((ntp.hi & 0xFFFF) << 16) + (ntp.lo >> 16);\n\n\t/* End-to-end delay is (now-lrr-dlrr) */\n\teedelay = now - lrr - dlrr;\n\n\t/* Convert end to end delay to usec (keeping the calculation in\n         * 64bit space)::\n\t *   sess->ee_delay = (eedelay * 1000) / 65536;\n\t */\n\tif (eedelay < 4294) {\n\t    eedelay = (eedelay * 1000000) >> 16;\n\t} else {\n\t    eedelay = (eedelay * 1000) >> 16;\n\t    eedelay *= 1000;\n\t}\n\n\tTRACE_((sess->name, \"Rx RTCP XR DLRR: lrr=%p, dlrr=%p (%d:%03dms), \"\n\t\t\t   \"now=%p, rtt=%p\",\n\t\tlrr, dlrr, dlrr/65536, (dlrr%65536)*1000/65536,\n\t\tnow, (pj_uint32_t)eedelay));\n\t\n\t/* Only save calculation if \"now\" is greater than lrr, or\n\t * otherwise rtt will be invalid \n\t */\n\tif (now-dlrr >= lrr) {\n\t    unsigned rtt = (pj_uint32_t)eedelay;\n\t    \n\t    /* Check that eedelay value really makes sense. \n\t     * We allow up to 30 seconds RTT!\n\t     */\n\t    if (eedelay <= 30 * 1000 * 1000UL) {\n\t\t/* \"Normalize\" rtt value that is exceptionally high.\n\t\t * For such values, \"normalize\" the rtt to be three times\n\t\t * the average value.\n\t\t */\n\t\tif (rtt>((unsigned)sess->stat.rtt.mean*3) && sess->stat.rtt.n!=0)\n\t\t{\n\t\t    unsigned orig_rtt = rtt;\n\t\t    rtt = (unsigned)sess->stat.rtt.mean*3;\n\t\t    PJ_LOG(5,(sess->name, \n\t\t\t      \"RTT value %d usec is normalized to %d usec\",\n\t\t\t      orig_rtt, rtt));\n\t\t}\n    \t\n\t\tTRACE_((sess->name, \"RTCP RTT is set to %d usec\", rtt));\n\t\tpj_math_stat_update(&sess->stat.rtt, rtt);\n\t    }\n\t} else {\n\t    PJ_LOG(5, (sess->name, \"Internal RTCP NTP clock skew detected: \"\n\t\t\t\t   \"lrr=%p, now=%p, dlrr=%p (%d:%03dms), \"\n\t\t\t\t   \"diff=%d\",\n\t\t\t\t   lrr, now, dlrr, dlrr/65536,\n\t\t\t\t   (dlrr%65536)*1000/65536,\n\t\t\t\t   dlrr-(now-lrr)));\n\t}\n    }\n\n    /* Receiving Statistics Summary */\n    if (rb_stats) {\n\tpj_uint8_t flags = rb_stats->header.specific;\n\n\tpj_bzero(&sess->stat.tx.stat_sum, sizeof(sess->stat.tx.stat_sum));\n\n\t/* Range of packets sequence reported in this blocks */\n\tsess->stat.tx.stat_sum.begin_seq = pj_ntohs(rb_stats->begin_seq);\n\tsess->stat.tx.stat_sum.end_seq   = pj_ntohs(rb_stats->end_seq);\n\n\t/* Get flags of valid fields */\n\tsess->stat.tx.stat_sum.l = (flags & (1 << 7)) != 0;\n\tsess->stat.tx.stat_sum.d = (flags & (1 << 6)) != 0;\n\tsess->stat.tx.stat_sum.j = (flags & (1 << 5)) != 0;\n\tsess->stat.tx.stat_sum.t = (flags & (3 << 3)) != 0;\n\n\t/* Fetch the reports info */\n\tif (sess->stat.tx.stat_sum.l) {\n\t    sess->stat.tx.stat_sum.lost = pj_ntohl(rb_stats->lost);\n\t}\n\n\tif (sess->stat.tx.stat_sum.d) {\n\t    sess->stat.tx.stat_sum.dup = pj_ntohl(rb_stats->dup);\n\t}\n\n\tif (sess->stat.tx.stat_sum.j) {\n\t    sess->stat.tx.stat_sum.jitter.min = pj_ntohl(rb_stats->jitter_min);\n\t    sess->stat.tx.stat_sum.jitter.max = pj_ntohl(rb_stats->jitter_max);\n\t    sess->stat.tx.stat_sum.jitter.mean= pj_ntohl(rb_stats->jitter_mean);\n\t    pj_math_stat_set_stddev(&sess->stat.tx.stat_sum.jitter, \n\t\t\t\t    pj_ntohl(rb_stats->jitter_dev));\n\t}\n\n\tif (sess->stat.tx.stat_sum.t) {\n\t    sess->stat.tx.stat_sum.toh.min = rb_stats->toh_min;\n\t    sess->stat.tx.stat_sum.toh.max = rb_stats->toh_max;\n\t    sess->stat.tx.stat_sum.toh.mean= rb_stats->toh_mean;\n\t    pj_math_stat_set_stddev(&sess->stat.tx.stat_sum.toh, \n\t\t\t\t    pj_ntohl(rb_stats->toh_dev));\n\t}\n\n\tpj_gettimeofday(&sess->stat.tx.stat_sum.update);\n    }\n\n    /* Receiving VoIP Metrics */\n    if (rb_voip_mtc) {\n\tsess->stat.tx.voip_mtc.loss_rate = rb_voip_mtc->loss_rate;\n\tsess->stat.tx.voip_mtc.discard_rate = rb_voip_mtc->discard_rate;\n\tsess->stat.tx.voip_mtc.burst_den = rb_voip_mtc->burst_den;\n\tsess->stat.tx.voip_mtc.gap_den = rb_voip_mtc->gap_den;\n\tsess->stat.tx.voip_mtc.burst_dur = pj_ntohs(rb_voip_mtc->burst_dur);\n\tsess->stat.tx.voip_mtc.gap_dur = pj_ntohs(rb_voip_mtc->gap_dur);\n\tsess->stat.tx.voip_mtc.rnd_trip_delay = \n\t\t\t\t\tpj_ntohs(rb_voip_mtc->rnd_trip_delay);\n\tsess->stat.tx.voip_mtc.end_sys_delay = \n\t\t\t\t\tpj_ntohs(rb_voip_mtc->end_sys_delay);\n\t/* signal & noise level encoded in two's complement form */\n\tsess->stat.tx.voip_mtc.signal_lvl = (pj_int8_t)\n\t\t\t\t    ((rb_voip_mtc->signal_lvl > 127)?\n\t\t\t\t     ((int)rb_voip_mtc->signal_lvl - 256) : \n\t\t\t\t     rb_voip_mtc->signal_lvl);\n\tsess->stat.tx.voip_mtc.noise_lvl  = (pj_int8_t)\n\t\t\t\t    ((rb_voip_mtc->noise_lvl > 127)?\n\t\t\t\t     ((int)rb_voip_mtc->noise_lvl - 256) : \n\t\t\t\t     rb_voip_mtc->noise_lvl);\n\tsess->stat.tx.voip_mtc.rerl = rb_voip_mtc->rerl;\n\tsess->stat.tx.voip_mtc.gmin = rb_voip_mtc->gmin;\n\tsess->stat.tx.voip_mtc.r_factor = rb_voip_mtc->r_factor;\n\tsess->stat.tx.voip_mtc.ext_r_factor = rb_voip_mtc->ext_r_factor;\n\tsess->stat.tx.voip_mtc.mos_lq = rb_voip_mtc->mos_lq;\n\tsess->stat.tx.voip_mtc.mos_cq = rb_voip_mtc->mos_cq;\n\tsess->stat.tx.voip_mtc.rx_config = rb_voip_mtc->rx_config;\n\tsess->stat.tx.voip_mtc.jb_nom = pj_ntohs(rb_voip_mtc->jb_nom);\n\tsess->stat.tx.voip_mtc.jb_max = pj_ntohs(rb_voip_mtc->jb_max);\n\tsess->stat.tx.voip_mtc.jb_abs_max = pj_ntohs(rb_voip_mtc->jb_abs_max);\n\n\tpj_gettimeofday(&sess->stat.tx.voip_mtc.update);\n    }\n}",
        "func_hash": 128531615202269817130665554219664776865,
        "file_name": "rtcp_xr.c",
        "file_hash": 114410540091951766279707779044798368853,
        "cwe": [
            "CWE-125"
        ],
        "cve": "CVE-2021-43845",
        "cve_desc": "PJSIP is a free and open source multimedia communication library. In version 2.11.1 and prior, if incoming RTCP XR message contain block, the data field is not checked against the received packet size, potentially resulting in an out-of-bound read access. This affects all users that use PJMEDIA and RTCP XR. A malicious actor can send a RTCP XR message with an invalid packet size.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-43845",
        "func_name": "pjmedia_rtcp_xr_rx_rtcp_xr",
        "diff": [
            "diff --git a/pjmedia/src/pjmedia/rtcp_xr.c b/pjmedia/src/pjmedia/rtcp_xr.c\nindex 44927063b1..f554698a20 100644\n--- a/pjmedia/src/pjmedia/rtcp_xr.c\n+++ b/pjmedia/src/pjmedia/rtcp_xr.c\n@@ -436,16 +436,32 @@ void pjmedia_rtcp_xr_rx_rtcp_xr( pjmedia_rtcp_xr_session *sess,\n \tif (rb_len) {\n \t    switch (rb_hdr->bt) {\n \t\tcase BT_RR_TIME:\n-\t\t    rb_rr_time = (pjmedia_rtcp_xr_rb_rr_time*) rb_hdr;\n+\t\t    if ((char*)rb_hdr + sizeof(*rb_rr_time) <=\n+\t\t\t(char*)pkt + size) \n+\t\t    {\n+\t\t\trb_rr_time = (pjmedia_rtcp_xr_rb_rr_time*)rb_hdr;\n+\t\t    }\n \t\t    break;\n \t\tcase BT_DLRR:\n-\t\t    rb_dlrr = (pjmedia_rtcp_xr_rb_dlrr*) rb_hdr;\n+\t\t    if ((char*)rb_hdr + sizeof(*rb_dlrr) <=\n+\t\t\t(char*)pkt + size)\n+\t\t    {\n+\t\t\trb_dlrr = (pjmedia_rtcp_xr_rb_dlrr*)rb_hdr;\n+\t\t    }\n \t\t    break;\n \t\tcase BT_STATS:\n-\t\t    rb_stats = (pjmedia_rtcp_xr_rb_stats*) rb_hdr;\n+\t\t    if ((char*)rb_hdr + sizeof(*rb_stats) <=\n+\t\t\t(char*)pkt + size)\n+\t\t    {\n+\t\t\trb_stats = (pjmedia_rtcp_xr_rb_stats*)rb_hdr;\n+\t\t    }\n \t\t    break;\n \t\tcase BT_VOIP_METRICS:\n-\t\t    rb_voip_mtc = (pjmedia_rtcp_xr_rb_voip_mtc*) rb_hdr;\n+\t\t    if ((char*)rb_hdr + sizeof(*rb_voip_mtc) <=\n+\t\t\t(char*)pkt + size)\n+\t\t    {\n+\t\t\trb_voip_mtc = (pjmedia_rtcp_xr_rb_voip_mtc*)rb_hdr;\n+\t\t    }\n \t\t    break;\n \t\tdefault:\n \t\t    break;\n"
        ],
        "func_after": []
    },
    {
        "idx": 195231,
        "project": "gpac",
        "commit_id": "893fb99b606eebfae46cde151846a980e689039b",
        "project_url": "https://github.com/gpac/gpac",
        "commit_url": "https://github.com/gpac/gpac/commit/893fb99b606eebfae46cde151846a980e689039b",
        "commit_message": "fixed #1902",
        "target": 1,
        "irrelevant": 1,
        "func_before": "s32 gf_avc_parse_nalu(GF_BitStream *bs, AVCState *avc)\n{\n\tu8 idr_flag;\n\ts32 slice, ret;\n\tu32 nal_hdr;\n\tAVCSliceInfo n_state;\n\n\tgf_bs_enable_emulation_byte_removal(bs, GF_TRUE);\n\n\tnal_hdr = gf_bs_read_u8(bs);\n\n\tslice = 0;\n\tmemcpy(&n_state, &avc->s_info, sizeof(AVCSliceInfo));\n\tavc->last_nal_type_parsed = n_state.nal_unit_type = nal_hdr & 0x1F;\n\tn_state.nal_ref_idc = (nal_hdr >> 5) & 0x3;\n\n\tidr_flag = 0;\n\n\tswitch (n_state.nal_unit_type) {\n\tcase GF_AVC_NALU_ACCESS_UNIT:\n\tcase GF_AVC_NALU_END_OF_SEQ:\n\tcase GF_AVC_NALU_END_OF_STREAM:\n\t\tret = 1;\n\t\tbreak;\n\n\tcase GF_AVC_NALU_SVC_SLICE:\n\t\tSVC_ReadNal_header_extension(bs, &n_state.NalHeader);\n\t\t// slice buffer - read the info and compare.\n\t\t/*ret = */svc_parse_slice(bs, avc, &n_state);\n\t\tif (avc->s_info.nal_ref_idc) {\n\t\t\tn_state.poc_lsb_prev = avc->s_info.poc_lsb;\n\t\t\tn_state.poc_msb_prev = avc->s_info.poc_msb;\n\t\t}\n\t\tavc_compute_poc(&n_state);\n\n\t\tif (avc->s_info.poc != n_state.poc) {\n\t\t\tmemcpy(&avc->s_info, &n_state, sizeof(AVCSliceInfo));\n\t\t\treturn 1;\n\t\t}\n\t\tmemcpy(&avc->s_info, &n_state, sizeof(AVCSliceInfo));\n\t\treturn 0;\n\n\tcase GF_AVC_NALU_SVC_PREFIX_NALU:\n\t\tSVC_ReadNal_header_extension(bs, &n_state.NalHeader);\n\t\treturn 0;\n\n\tcase GF_AVC_NALU_IDR_SLICE:\n\tcase GF_AVC_NALU_NON_IDR_SLICE:\n\tcase GF_AVC_NALU_DP_A_SLICE:\n\tcase GF_AVC_NALU_DP_B_SLICE:\n\tcase GF_AVC_NALU_DP_C_SLICE:\n\t\tslice = 1;\n\t\t/* slice buffer - read the info and compare.*/\n\t\tret = avc_parse_slice(bs, avc, idr_flag, &n_state);\n\t\tif (ret < 0) return ret;\n\t\tret = 0;\n\t\tif (\n\t\t\t((avc->s_info.nal_unit_type > GF_AVC_NALU_IDR_SLICE) || (avc->s_info.nal_unit_type < GF_AVC_NALU_NON_IDR_SLICE))\n\t\t\t&& (avc->s_info.nal_unit_type != GF_AVC_NALU_SVC_SLICE)\n\t\t\t) {\n\t\t\tbreak;\n\t\t}\n\t\tif (avc->s_info.frame_num != n_state.frame_num) {\n\t\t\tret = 1;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (avc->s_info.field_pic_flag != n_state.field_pic_flag) {\n\t\t\tret = 1;\n\t\t\tbreak;\n\t\t}\n\t\tif ((avc->s_info.nal_ref_idc != n_state.nal_ref_idc) &&\n\t\t\t(!avc->s_info.nal_ref_idc || !n_state.nal_ref_idc)) {\n\t\t\tret = 1;\n\t\t\tbreak;\n\t\t}\n\t\tassert(avc->s_info.sps);\n\n\t\tif (avc->s_info.sps->poc_type == n_state.sps->poc_type) {\n\t\t\tif (!avc->s_info.sps->poc_type) {\n\t\t\t\tif (!n_state.bottom_field_flag && (avc->s_info.poc_lsb != n_state.poc_lsb)) {\n\t\t\t\t\tret = 1;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tif (avc->s_info.delta_poc_bottom != n_state.delta_poc_bottom) {\n\t\t\t\t\tret = 1;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\telse if (avc->s_info.sps->poc_type == 1) {\n\t\t\t\tif (avc->s_info.delta_poc[0] != n_state.delta_poc[0]) {\n\t\t\t\t\tret = 1;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tif (avc->s_info.delta_poc[1] != n_state.delta_poc[1]) {\n\t\t\t\t\tret = 1;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif (n_state.nal_unit_type == GF_AVC_NALU_IDR_SLICE) {\n\t\t\tif (avc->s_info.nal_unit_type != GF_AVC_NALU_IDR_SLICE) { /*IdrPicFlag differs in value*/\n\t\t\t\tret = 1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\telse if (avc->s_info.idr_pic_id != n_state.idr_pic_id) { /*both IDR and idr_pic_id differs*/\n\t\t\t\tret = 1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tbreak;\n\tcase GF_AVC_NALU_SEQ_PARAM:\n\t\tavc->last_ps_idx = gf_avc_read_sps_bs_internal(bs, avc, 0, NULL, nal_hdr);\n\t\tif (avc->last_ps_idx < 0) return -1;\n\t\treturn 0;\n\n\tcase GF_AVC_NALU_PIC_PARAM:\n\t\tavc->last_ps_idx = gf_avc_read_pps_bs_internal(bs, avc, nal_hdr);\n\t\tif (avc->last_ps_idx < 0) return -1;\n\t\treturn 0;\n\tcase GF_AVC_NALU_SVC_SUBSEQ_PARAM:\n\t\tavc->last_ps_idx = gf_avc_read_sps_bs_internal(bs, avc, 1, NULL, nal_hdr);\n\t\tif (avc->last_ps_idx < 0) return -1;\n\t\treturn 0;\n\tcase GF_AVC_NALU_SEQ_PARAM_EXT:\n\t\tavc->last_ps_idx = (s32) gf_bs_read_ue(bs);\n\t\tif (avc->last_ps_idx < 0) return -1;\n\t\treturn 0;\n\n\tcase GF_AVC_NALU_SEI:\n\tcase GF_AVC_NALU_FILLER_DATA:\n\t\treturn 0;\n\n\tdefault:\n\t\tif (avc->s_info.nal_unit_type <= GF_AVC_NALU_IDR_SLICE) ret = 1;\n\t\t//To detect change of AU when multiple sps and pps in stream\n\t\telse if ((nal_hdr & 0x1F) == GF_AVC_NALU_SEI && avc->s_info.nal_unit_type == GF_AVC_NALU_SVC_SLICE)\n\t\t\tret = 1;\n\t\telse if ((nal_hdr & 0x1F) == GF_AVC_NALU_SEQ_PARAM && avc->s_info.nal_unit_type == GF_AVC_NALU_SVC_SLICE)\n\t\t\tret = 1;\n\t\telse\n\t\t\tret = 0;\n\t\tbreak;\n\t}\n\n\t/* save _prev values */\n\tif (ret && avc->s_info.sps) {\n\t\tn_state.frame_num_offset_prev = avc->s_info.frame_num_offset;\n\t\tif ((avc->s_info.sps->poc_type != 2) || (avc->s_info.nal_ref_idc != 0))\n\t\t\tn_state.frame_num_prev = avc->s_info.frame_num;\n\t\tif (avc->s_info.nal_ref_idc) {\n\t\t\tn_state.poc_lsb_prev = avc->s_info.poc_lsb;\n\t\t\tn_state.poc_msb_prev = avc->s_info.poc_msb;\n\t\t}\n\t}\n\tif (slice)\n\t\tavc_compute_poc(&n_state);\n\tmemcpy(&avc->s_info, &n_state, sizeof(AVCSliceInfo));\n\treturn ret;\n}",
        "func_hash": 99100226875075764129164909998725433232,
        "file_name": "av_parsers.c",
        "file_hash": 168517587328341017594269375399465893964,
        "cwe": [
            "CWE-476"
        ],
        "cve": "CVE-2021-40565",
        "cve_desc": "A Segmentation fault caused by a null pointer dereference vulnerability exists in Gpac through 1.0.1 via the gf_avc_parse_nalu function in av_parsers.c when using mp4box, which causes a denial of service.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-40565",
        "func_name": "gf_avc_parse_nalu",
        "diff": [
            "diff --git a/src/media_tools/av_parsers.c b/src/media_tools/av_parsers.c\nindex 96d2797420..1ab1a5373f 100644\n--- a/src/media_tools/av_parsers.c\n+++ b/src/media_tools/av_parsers.c\n@@ -6113,7 +6113,8 @@ s32 gf_avc_parse_nalu(GF_BitStream *bs, AVCState *avc)\n \t\t\tret = 1;\n \t\t\tbreak;\n \t\t}\n-\t\tassert(avc->s_info.sps);\n+\t\tif (!avc->s_info.sps)\n+\t\t\treturn -1;\n \n \t\tif (avc->s_info.sps->poc_type == n_state.sps->poc_type) {\n \t\t\tif (!avc->s_info.sps->poc_type) {\n"
        ],
        "func_after": []
    },
    {
        "idx": 195233,
        "project": "tensorflow",
        "commit_id": "97282c6d0d34476b6ba033f961590b783fa184cd",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/97282c6d0d34476b6ba033f961590b783fa184cd",
        "commit_message": "Prevent a crash due to heap OOB write in grappler.\n\nPiperOrigin-RevId: 408318417\nChange-Id: If095feb8c001e3a8ac4a85b7387b81e8309df47d",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  Status SetUnknownShape(const NodeDef* node, int output_port) {\n    shape_inference::ShapeHandle shape =\n        GetUnknownOutputShape(node, output_port);\n    InferenceContext* ctx = GetContext(node);\n    if (ctx == nullptr) {\n      return errors::InvalidArgument(\"Missing context\");\n    }\n    ctx->set_output(output_port, shape);\n    return Status::OK();\n  }",
        "func_hash": 128649942367020682781968122888762734954,
        "file_name": "graph_properties.cc",
        "file_hash": 2473148557397819170260688514824580473,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2022-23566",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. TensorFlow is vulnerable to a heap OOB write in `Grappler`. The `set_output` function writes to an array at the specified index. Hence, this gives a malicious user a write primitive. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23566",
        "func_name": "SetUnknownShape",
        "diff": [
            "diff --git a/tensorflow/core/grappler/costs/graph_properties.cc b/tensorflow/core/grappler/costs/graph_properties.cc\nindex 51a2cd080c5445..3cc12173ba10c5 100644\n--- a/tensorflow/core/grappler/costs/graph_properties.cc\n+++ b/tensorflow/core/grappler/costs/graph_properties.cc\n@@ -1134,7 +1134,12 @@ class SymbolicShapeRefiner {\n         GetUnknownOutputShape(node, output_port);\n     InferenceContext* ctx = GetContext(node);\n     if (ctx == nullptr) {\n-      return errors::InvalidArgument(\"Missing context\");\n+      return errors::InvalidArgument(\"SetUnknownShape: Missing context\");\n+    }\n+    if (output_port < 0 || output_port >= ctx->num_outputs()) {\n+      return errors::InvalidArgument(\n+          \"SetUnknownShape: output_port must be in [0, \", ctx->num_outputs(),\n+          \") but was \", output_port);\n     }\n     ctx->set_output(output_port, shape);\n     return Status::OK();\n"
        ],
        "func_after": []
    },
    {
        "idx": 195234,
        "project": "tensorflow",
        "commit_id": "dcc21c7bc972b10b6fb95c2fb0f4ab5a59680ec2",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/dcc21c7bc972b10b6fb95c2fb0f4ab5a59680ec2",
        "commit_message": "Eliminate debug `CHECK`-fail from `function.cc`\n\nPiperOrigin-RevId: 409416119\nChange-Id: I8376ee464d434e9b970ff0ad49edfdaa2a273cfe",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  Status BuildInputArgIndex(const OpDef::ArgDef& arg_def, AttrSlice attr_values,\n                            const FunctionDef::ArgAttrs* arg_attrs,\n                            bool ints_on_device,\n                            int64_t resource_arg_unique_id) {\n    bool is_type_list;\n    DataTypeVector dtypes;\n    TF_RETURN_IF_ERROR(\n        ArgNumType(attr_values, arg_def, &is_type_list, &dtypes));\n    if (dtypes.size() < size_t{1}) {\n      return errors::Internal(\"Expected a list of at least one dtype\");\n    }\n    int arg_index = result_.nodes.size();\n    TF_RETURN_IF_ERROR(\n        AddItem(arg_def.name(), {true, arg_index, 0, is_type_list, dtypes}));\n    // Creates dtypes.size() nodes in the graph.\n    for (size_t i = 0; i < dtypes.size(); ++i) {\n      TF_RETURN_IF_ERROR(AddItem(strings::StrCat(arg_def.name(), \":\", i),\n                                 {true, arg_index, 0, false, {dtypes[i]}}));\n      DCHECK_EQ(arg_index, result_.nodes.size());\n      string name = arg_def.name();\n      if (dtypes.size() > 1) {\n        strings::StrAppend(&name, \"_\", i);\n      }\n      NodeDef* gnode = AddNode(name);\n      if (ints_on_device && dtypes[i] == DataType::DT_INT32) {\n        gnode->set_op(FunctionLibraryDefinition::kDeviceArgOp);\n      } else {\n        gnode->set_op(FunctionLibraryDefinition::kArgOp);\n      }\n      DataType dtype = arg_def.is_ref() ? MakeRefType(dtypes[i]) : dtypes[i];\n      AddAttr(\"T\", dtype, gnode);\n      AddAttr(\"index\", arg_index, gnode);\n      if (resource_arg_unique_id >= 0) {\n        AddAttr(\"_resource_arg_unique_id\", resource_arg_unique_id, gnode);\n      }\n      if (arg_attrs) {\n        for (const auto& arg_attr : arg_attrs->attr()) {\n          AddAttr(arg_attr.first, arg_attr.second, gnode->mutable_attr());\n        }\n      }\n      result_.arg_types.push_back(dtypes[i]);\n      ++arg_index;\n    }\n    return Status::OK();\n  }",
        "func_hash": 149416980820983113024454385523610384435,
        "file_name": "function.cc",
        "file_hash": 275755455359751936167516531130081059449,
        "cwe": [
            "CWE-617"
        ],
        "cve": "CVE-2022-23586",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. A malicious user can cause a denial of service by altering a `SavedModel` such that assertions in `function.cc` would be falsified and crash the Python interpreter. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23586",
        "func_name": "BuildInputArgIndex",
        "diff": [
            "diff --git a/tensorflow/core/framework/function.cc b/tensorflow/core/framework/function.cc\nindex 492d9d54fe60eb..b8318ef346ae08 100644\n--- a/tensorflow/core/framework/function.cc\n+++ b/tensorflow/core/framework/function.cc\n@@ -191,7 +191,11 @@ class FunctionInstantiationHelper {\n     for (size_t i = 0; i < dtypes.size(); ++i) {\n       TF_RETURN_IF_ERROR(AddItem(strings::StrCat(arg_def.name(), \":\", i),\n                                  {true, arg_index, 0, false, {dtypes[i]}}));\n-      DCHECK_EQ(arg_index, result_.nodes.size());\n+      if (arg_index != result_.nodes.size()) {\n+        return errors::Internal(\n+            \"Expected arg_index to be equal to the number of nodes in result.\",\n+            \" Got \", arg_index, \" and \", result_.nodes.size());\n+      }\n       string name = arg_def.name();\n       if (dtypes.size() > 1) {\n         strings::StrAppend(&name, \"_\", i);\n"
        ],
        "func_after": []
    },
    {
        "idx": 195237,
        "project": "ImageMagick",
        "commit_id": "f221ea0fa3171f0f4fdf74ac9d81b203b9534c23",
        "project_url": "https://github.com/ImageMagick/ImageMagick",
        "commit_url": "https://github.com/ImageMagick/ImageMagick/commit/f221ea0fa3171f0f4fdf74ac9d81b203b9534c23",
        "commit_message": "Fixes #4985: 4e+26 is outside the range of representable values of type 'unsigned long' at coders/pcl.c:299 (#4986)\n\n* fix Division by zero in XMenuWidget() of MagickCore/widget.c\n\n* Fix memory leak in AnimateImageCommand() of MagickWand/animate.c and DisplayImageCommand() of MagickWand/display.c\n\n* fix Division by zero in ReadEnhMetaFile() of coders/emf.c\n\n* Resolve conflicts\n\n* fix issue: outside the range of representable values of type 'unsigned char' at coders/psd.c:1025\n\n* fix error: 4e+26 is outside the range of representable values of type 'unsigned long' at coders/pcl.c:299\n\nCo-authored-by: zhailiangliang <zhailiangliang@loongson.cn>",
        "target": 1,
        "irrelevant": 1,
        "func_before": "static Image *ReadPCLImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n#define CropBox  \"CropBox\"\n#define DeviceCMYK  \"DeviceCMYK\"\n#define MediaBox  \"MediaBox\"\n#define RenderPCLText  \"  Rendering PCL...  \"\n\n  char\n    command[MagickPathExtent],\n    *density,\n    filename[MagickPathExtent],\n    geometry[MagickPathExtent],\n    *options,\n    input_filename[MagickPathExtent];\n\n  const DelegateInfo\n    *delegate_info;\n\n  Image\n    *image,\n    *next_image;\n\n  ImageInfo\n    *read_info;\n\n  MagickBooleanType\n    cmyk,\n    status;\n\n  PointInfo\n    delta;\n\n  RectangleInfo\n    bounding_box,\n    page;\n\n  char\n    *p;\n\n  ssize_t\n    c;\n\n  SegmentInfo\n    bounds;\n\n  size_t\n    height,\n    width;\n\n  ssize_t\n    count;\n\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  /*\n    Open image file.\n  */\n  image=AcquireImage(image_info,exception);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  status=AcquireUniqueSymbolicLink(image_info->filename,input_filename);\n  if (status == MagickFalse)\n    {\n      ThrowFileException(exception,FileOpenError,\"UnableToCreateTemporaryFile\",\n        image_info->filename);\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    Set the page density.\n  */\n  delta.x=DefaultResolution;\n  delta.y=DefaultResolution;\n  if ((image->resolution.x == 0.0) || (image->resolution.y == 0.0))\n    {\n      GeometryInfo\n        geometry_info;\n\n      MagickStatusType\n        flags;\n\n      flags=ParseGeometry(PSDensityGeometry,&geometry_info);\n      if ((flags & RhoValue) != 0)\n        image->resolution.x=geometry_info.rho;\n      image->resolution.y=image->resolution.x;\n      if ((flags & SigmaValue) != 0)\n        image->resolution.y=geometry_info.sigma;\n    }\n  /*\n    Determine page geometry from the PCL media box.\n  */\n  cmyk=image->colorspace == CMYKColorspace ? MagickTrue : MagickFalse;\n  count=0;\n  (void) memset(&bounding_box,0,sizeof(bounding_box));\n  (void) memset(&bounds,0,sizeof(bounds));\n  (void) memset(&page,0,sizeof(page));\n  (void) memset(command,0,sizeof(command));\n  p=command;\n  for (c=ReadBlobByte(image); c != EOF; c=ReadBlobByte(image))\n  {\n    if (image_info->page != (char *) NULL)\n      continue;\n    /*\n      Note PCL elements.\n    */\n    *p++=(char) c;\n    if ((c != (int) '/') && (c != '\\n') &&\n        ((size_t) (p-command) < (MagickPathExtent-1)))\n      continue;\n    *p='\\0';\n    p=command;\n    /*\n      Is this a CMYK document?\n    */\n    if (LocaleNCompare(DeviceCMYK,command,strlen(DeviceCMYK)) == 0)\n      cmyk=MagickTrue;\n    if (LocaleNCompare(CropBox,command,strlen(CropBox)) == 0)\n      {\n        /*\n          Note region defined by crop box.\n        */\n        count=(ssize_t) sscanf(command,\"CropBox [%lf %lf %lf %lf\",\n          &bounds.x1,&bounds.y1,&bounds.x2,&bounds.y2);\n        if (count != 4)\n          count=(ssize_t) sscanf(command,\"CropBox[%lf %lf %lf %lf\",\n            &bounds.x1,&bounds.y1,&bounds.x2,&bounds.y2);\n      }\n    if (LocaleNCompare(MediaBox,command,strlen(MediaBox)) == 0)\n      {\n        /*\n          Note region defined by media box.\n        */\n        count=(ssize_t) sscanf(command,\"MediaBox [%lf %lf %lf %lf\",\n          &bounds.x1,&bounds.y1,&bounds.x2,&bounds.y2);\n        if (count != 4)\n          count=(ssize_t) sscanf(command,\"MediaBox[%lf %lf %lf %lf\",\n            &bounds.x1,&bounds.y1,&bounds.x2,&bounds.y2);\n      }\n    if (count != 4)\n      continue;\n    /*\n      Set PCL render geometry.\n    */\n    width=(size_t) floor(bounds.x2-bounds.x1+0.5);\n    height=(size_t) floor(bounds.y2-bounds.y1+0.5);\n    if (width > page.width)\n      page.width=width;\n    if (height > page.height)\n      page.height=height;\n  }\n  (void) CloseBlob(image);\n  /*\n    Render PCL with the GhostPCL delegate.\n  */\n  if ((page.width == 0) || (page.height == 0))\n    (void) ParseAbsoluteGeometry(PSPageGeometry,&page);\n  if (image_info->page != (char *) NULL)\n    (void) ParseAbsoluteGeometry(image_info->page,&page);\n  (void) FormatLocaleString(geometry,MagickPathExtent,\"%.20gx%.20g\",(double)\n    page.width,(double) page.height);\n  if (image_info->monochrome != MagickFalse)\n    delegate_info=GetDelegateInfo(\"pcl:mono\",(char *) NULL,exception);\n  else\n     if (cmyk != MagickFalse)\n       delegate_info=GetDelegateInfo(\"pcl:cmyk\",(char *) NULL,exception);\n     else\n       delegate_info=GetDelegateInfo(\"pcl:color\",(char *) NULL,exception);\n  if (delegate_info == (const DelegateInfo *) NULL)\n    {\n      image=DestroyImage(image);\n      return((Image *) NULL);\n    }\n  if ((page.width == 0) || (page.height == 0))\n    (void) ParseAbsoluteGeometry(PSPageGeometry,&page);\n  if (image_info->page != (char *) NULL)\n    (void) ParseAbsoluteGeometry(image_info->page,&page);\n  density=AcquireString(\"\");\n  options=AcquireString(\"\");\n  (void) FormatLocaleString(density,MagickPathExtent,\"%gx%g\",\n    image->resolution.x,image->resolution.y);\n  if (image_info->ping != MagickFalse)\n    (void) FormatLocaleString(density,MagickPathExtent,\"2.0x2.0\");\n  page.width=(size_t) floor(page.width*image->resolution.x/delta.x+0.5);\n  page.height=(size_t) floor(page.height*image->resolution.y/delta.y+0.5);\n  (void) FormatLocaleString(options,MagickPathExtent,\"-g%.20gx%.20g \",(double)\n    page.width,(double) page.height);\n  image=DestroyImage(image);\n  read_info=CloneImageInfo(image_info);\n  *read_info->magick='\\0';\n  if (read_info->number_scenes != 0)\n    {\n      if (read_info->number_scenes != 1)\n        (void) FormatLocaleString(options,MagickPathExtent,\"-dLastPage=%.20g\",\n          (double) (read_info->scene+read_info->number_scenes));\n      else\n        (void) FormatLocaleString(options,MagickPathExtent,\n          \"-dFirstPage=%.20g -dLastPage=%.20g\",(double) read_info->scene+1,\n          (double) (read_info->scene+read_info->number_scenes));\n      read_info->number_scenes=0;\n      if (read_info->scenes != (char *) NULL)\n        *read_info->scenes='\\0';\n    }\n  (void) CopyMagickString(filename,read_info->filename,MagickPathExtent);\n  (void) AcquireUniqueFilename(read_info->filename);\n  (void) FormatLocaleString(command,MagickPathExtent,\n    GetDelegateCommands(delegate_info),\n    read_info->antialias != MagickFalse ? 4 : 1,\n    read_info->antialias != MagickFalse ? 4 : 1,density,options,\n    read_info->filename,input_filename);\n  options=DestroyString(options);\n  density=DestroyString(density);\n  status=ExternalDelegateCommand(MagickFalse,read_info->verbose,command,\n    (char *) NULL,exception) != 0 ? MagickTrue : MagickFalse;\n  image=ReadImage(read_info,exception);\n  (void) RelinquishUniqueFileResource(read_info->filename);\n  (void) RelinquishUniqueFileResource(input_filename);\n  read_info=DestroyImageInfo(read_info);\n  if (image == (Image *) NULL)\n    ThrowReaderException(DelegateError,\"PCLDelegateFailed\");\n  if (LocaleCompare(image->magick,\"BMP\") == 0)\n    {\n      Image\n        *cmyk_image;\n\n      cmyk_image=ConsolidateCMYKImages(image,exception);\n      if (cmyk_image != (Image *) NULL)\n        {\n          image=DestroyImageList(image);\n          image=cmyk_image;\n        }\n    }\n  do\n  {\n    (void) CopyMagickString(image->filename,filename,MagickPathExtent);\n    image->page=page;\n    if (image_info->ping != MagickFalse)\n      {\n        image->magick_columns*=image->resolution.x/2.0;\n        image->magick_rows*=image->resolution.y/2.0;\n        image->columns*=image->resolution.x/2.0;\n        image->rows*=image->resolution.y/2.0;\n      }\n    next_image=SyncNextImageInList(image);\n    if (next_image != (Image *) NULL)\n      image=next_image;\n  } while (next_image != (Image *) NULL);\n  return(GetFirstImageInList(image));\n}",
        "func_hash": 164108098598115354275502589345492195560,
        "file_name": "pcl.c",
        "file_hash": 226900089914426038554396055314138187051,
        "cwe": [
            "CWE-190"
        ],
        "cve": "CVE-2022-32546",
        "cve_desc": "A vulnerability was found in ImageMagick, causing an outside the range of representable values of type 'unsigned long' at coders/pcl.c, when crafted or untrusted input is processed. This leads to a negative impact to application availability or other problems related to undefined behavior.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-32546",
        "func_name": "ReadPCLImage",
        "diff": [
            "diff --git a/coders/pcl.c b/coders/pcl.c\nindex c0cc213ed5a..70d2b4b9994 100644\n--- a/coders/pcl.c\n+++ b/coders/pcl.c\n@@ -295,8 +295,8 @@ static Image *ReadPCLImage(const ImageInfo *image_info,ExceptionInfo *exception)\n     /*\n       Set PCL render geometry.\n     */\n-    width=(size_t) floor(bounds.x2-bounds.x1+0.5);\n-    height=(size_t) floor(bounds.y2-bounds.y1+0.5);\n+    width=(size_t)CastDoubleToLong(floor(bounds.x2-bounds.x1+0.5));\n+    height=(size_t)CastDoubleToLong(floor(bounds.y2-bounds.y1+0.5));\n     if (width > page.width)\n       page.width=width;\n     if (height > page.height)\n"
        ],
        "func_after": []
    },
    {
        "idx": 195238,
        "project": "flatpak",
        "commit_id": "e26ac7586c392b5eb35ff4609fe232c52523b2cf",
        "project_url": "https://github.com/flatpak/flatpak",
        "commit_url": "https://github.com/flatpak/flatpak/commit/e26ac7586c392b5eb35ff4609fe232c52523b2cf",
        "commit_message": "run: Add an errno value to seccomp filters\n\nAt the moment, if we block a syscall we always make it fail with EPERM,\nbut this is risky: user-space libraries can start to use new replacements\nfor old syscalls at any time, and will often treat EPERM as a fatal error.\nFor new syscalls, we should make the syscall fail with ENOSYS, which is\nindistinguishable from running on an older kernel and will cause fallback\nto an older implementation, for example clone3() to clone().\n\nIn future we should probably move from EPERM to ENOSYS for some of the\nsyscalls we already block, but for now keep the status quo.\n\nThis is a prerequisite for fixing the vulnerability tracked as\nGHSA-67h7-w3jq-vh4q.\n\nSigned-off-by: Simon McVittie <smcv@collabora.com>",
        "target": 1,
        "irrelevant": 0,
        "func_before": "setup_seccomp (FlatpakBwrap   *bwrap,\n               const char     *arch,\n               gulong          allowed_personality,\n               FlatpakRunFlags run_flags,\n               GError        **error)\n{\n  gboolean multiarch = (run_flags & FLATPAK_RUN_FLAG_MULTIARCH) != 0;\n  gboolean devel = (run_flags & FLATPAK_RUN_FLAG_DEVEL) != 0;\n\n  __attribute__((cleanup (cleanup_seccomp))) scmp_filter_ctx seccomp = NULL;\n\n  /**** BEGIN NOTE ON CODE SHARING\n   *\n   * There are today a number of different Linux container\n   * implementations.  That will likely continue for long into the\n   * future.  But we can still try to share code, and it's important\n   * to do so because it affects what library and application writers\n   * can do, and we should support code portability between different\n   * container tools.\n   *\n   * This syscall blocklist is copied from linux-user-chroot, which was in turn\n   * clearly influenced by the Sandstorm.io blocklist.\n   *\n   * If you make any changes here, I suggest sending the changes along\n   * to other sandbox maintainers.  Using the libseccomp list is also\n   * an appropriate venue:\n   * https://groups.google.com/forum/#!forum/libseccomp\n   *\n   * A non-exhaustive list of links to container tooling that might\n   * want to share this blocklist:\n   *\n   *  https://github.com/sandstorm-io/sandstorm\n   *    in src/sandstorm/supervisor.c++\n   *  https://github.com/flatpak/flatpak.git\n   *    in common/flatpak-run.c\n   *  https://git.gnome.org/browse/linux-user-chroot\n   *    in src/setup-seccomp.c\n   *\n   **** END NOTE ON CODE SHARING\n   */\n  struct\n  {\n    int                  scall;\n    struct scmp_arg_cmp *arg;\n  } syscall_blocklist[] = {\n    /* Block dmesg */\n    {SCMP_SYS (syslog)},\n    /* Useless old syscall */\n    {SCMP_SYS (uselib)},\n    /* Don't allow disabling accounting */\n    {SCMP_SYS (acct)},\n    /* 16-bit code is unnecessary in the sandbox, and modify_ldt is a\n       historic source of interesting information leaks. */\n    {SCMP_SYS (modify_ldt)},\n    /* Don't allow reading current quota use */\n    {SCMP_SYS (quotactl)},\n\n    /* Don't allow access to the kernel keyring */\n    {SCMP_SYS (add_key)},\n    {SCMP_SYS (keyctl)},\n    {SCMP_SYS (request_key)},\n\n    /* Scary VM/NUMA ops */\n    {SCMP_SYS (move_pages)},\n    {SCMP_SYS (mbind)},\n    {SCMP_SYS (get_mempolicy)},\n    {SCMP_SYS (set_mempolicy)},\n    {SCMP_SYS (migrate_pages)},\n\n    /* Don't allow subnamespace setups: */\n    {SCMP_SYS (unshare)},\n    {SCMP_SYS (mount)},\n    {SCMP_SYS (pivot_root)},\n#if defined(__s390__) || defined(__s390x__) || defined(__CRIS__)\n    /* Architectures with CONFIG_CLONE_BACKWARDS2: the child stack\n     * and flags arguments are reversed so the flags come second */\n    {SCMP_SYS (clone), &SCMP_A1 (SCMP_CMP_MASKED_EQ, CLONE_NEWUSER, CLONE_NEWUSER)},\n#else\n    /* Normally the flags come first */\n    {SCMP_SYS (clone), &SCMP_A0 (SCMP_CMP_MASKED_EQ, CLONE_NEWUSER, CLONE_NEWUSER)},\n#endif\n\n    /* Don't allow faking input to the controlling tty (CVE-2017-5226) */\n    {SCMP_SYS (ioctl), &SCMP_A1 (SCMP_CMP_MASKED_EQ, 0xFFFFFFFFu, (int) TIOCSTI)},\n  };\n\n  struct\n  {\n    int                  scall;\n    struct scmp_arg_cmp *arg;\n  } syscall_nondevel_blocklist[] = {\n    /* Profiling operations; we expect these to be done by tools from outside\n     * the sandbox.  In particular perf has been the source of many CVEs.\n     */\n    {SCMP_SYS (perf_event_open)},\n    /* Don't allow you to switch to bsd emulation or whatnot */\n    {SCMP_SYS (personality), &SCMP_A0 (SCMP_CMP_NE, allowed_personality)},\n    {SCMP_SYS (ptrace)}\n  };\n  /* Blocklist all but unix, inet, inet6 and netlink */\n  struct\n  {\n    int             family;\n    FlatpakRunFlags flags_mask;\n  } socket_family_allowlist[] = {\n    /* NOTE: Keep in numerical order */\n    { AF_UNSPEC, 0 },\n    { AF_LOCAL, 0 },\n    { AF_INET, 0 },\n    { AF_INET6, 0 },\n    { AF_NETLINK, 0 },\n    { AF_CAN, FLATPAK_RUN_FLAG_CANBUS },\n    { AF_BLUETOOTH, FLATPAK_RUN_FLAG_BLUETOOTH },\n  };\n  int last_allowed_family;\n  int i, r;\n  g_auto(GLnxTmpfile) seccomp_tmpf  = { 0, };\n\n  seccomp = seccomp_init (SCMP_ACT_ALLOW);\n  if (!seccomp)\n    return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Initialize seccomp failed\"));\n\n  if (arch != NULL)\n    {\n      uint32_t arch_id = 0;\n      const uint32_t *extra_arches = NULL;\n\n      if (strcmp (arch, \"i386\") == 0)\n        {\n          arch_id = SCMP_ARCH_X86;\n        }\n      else if (strcmp (arch, \"x86_64\") == 0)\n        {\n          arch_id = SCMP_ARCH_X86_64;\n          extra_arches = seccomp_x86_64_extra_arches;\n        }\n      else if (strcmp (arch, \"arm\") == 0)\n        {\n          arch_id = SCMP_ARCH_ARM;\n        }\n#ifdef SCMP_ARCH_AARCH64\n      else if (strcmp (arch, \"aarch64\") == 0)\n        {\n          arch_id = SCMP_ARCH_AARCH64;\n          extra_arches = seccomp_aarch64_extra_arches;\n        }\n#endif\n\n      /* We only really need to handle arches on multiarch systems.\n       * If only one arch is supported the default is fine */\n      if (arch_id != 0)\n        {\n          /* This *adds* the target arch, instead of replacing the\n             native one. This is not ideal, because we'd like to only\n             allow the target arch, but we can't really disallow the\n             native arch at this point, because then bubblewrap\n             couldn't continue running. */\n          r = seccomp_arch_add (seccomp, arch_id);\n          if (r < 0 && r != -EEXIST)\n            return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to add architecture to seccomp filter\"));\n\n          if (multiarch && extra_arches != NULL)\n            {\n              for (i = 0; extra_arches[i] != 0; i++)\n                {\n                  r = seccomp_arch_add (seccomp, extra_arches[i]);\n                  if (r < 0 && r != -EEXIST)\n                    return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to add multiarch architecture to seccomp filter\"));\n                }\n            }\n        }\n    }\n\n  /* TODO: Should we filter the kernel keyring syscalls in some way?\n   * We do want them to be used by desktop apps, but they could also perhaps\n   * leak system stuff or secrets from other apps.\n   */\n\n  for (i = 0; i < G_N_ELEMENTS (syscall_blocklist); i++)\n    {\n      int scall = syscall_blocklist[i].scall;\n      if (syscall_blocklist[i].arg)\n        r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (EPERM), scall, 1, *syscall_blocklist[i].arg);\n      else\n        r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (EPERM), scall, 0);\n      if (r < 0 && r == -EFAULT /* unknown syscall */)\n        return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to block syscall %d\"), scall);\n    }\n\n  if (!devel)\n    {\n      for (i = 0; i < G_N_ELEMENTS (syscall_nondevel_blocklist); i++)\n        {\n          int scall = syscall_nondevel_blocklist[i].scall;\n          if (syscall_nondevel_blocklist[i].arg)\n            r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (EPERM), scall, 1, *syscall_nondevel_blocklist[i].arg);\n          else\n            r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (EPERM), scall, 0);\n\n          if (r < 0 && r == -EFAULT /* unknown syscall */)\n            return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to block syscall %d\"), scall);\n        }\n    }\n\n  /* Socket filtering doesn't work on e.g. i386, so ignore failures here\n   * However, we need to user seccomp_rule_add_exact to avoid libseccomp doing\n   * something else: https://github.com/seccomp/libseccomp/issues/8 */\n  last_allowed_family = -1;\n  for (i = 0; i < G_N_ELEMENTS (socket_family_allowlist); i++)\n    {\n      int family = socket_family_allowlist[i].family;\n      int disallowed;\n\n      if (socket_family_allowlist[i].flags_mask != 0 &&\n          (socket_family_allowlist[i].flags_mask & run_flags) != socket_family_allowlist[i].flags_mask)\n        continue;\n\n      for (disallowed = last_allowed_family + 1; disallowed < family; disallowed++)\n        {\n          /* Blocklist the in-between valid families */\n          seccomp_rule_add_exact (seccomp, SCMP_ACT_ERRNO (EAFNOSUPPORT), SCMP_SYS (socket), 1, SCMP_A0 (SCMP_CMP_EQ, disallowed));\n        }\n      last_allowed_family = family;\n    }\n  /* Blocklist the rest */\n  seccomp_rule_add_exact (seccomp, SCMP_ACT_ERRNO (EAFNOSUPPORT), SCMP_SYS (socket), 1, SCMP_A0 (SCMP_CMP_GE, last_allowed_family + 1));\n\n  if (!glnx_open_anonymous_tmpfile_full (O_RDWR | O_CLOEXEC, \"/tmp\", &seccomp_tmpf, error))\n    return FALSE;\n\n  if (seccomp_export_bpf (seccomp, seccomp_tmpf.fd) != 0)\n    return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to export bpf\"));\n\n  lseek (seccomp_tmpf.fd, 0, SEEK_SET);\n\n  flatpak_bwrap_add_args_data_fd (bwrap,\n                                  \"--seccomp\", glnx_steal_fd (&seccomp_tmpf.fd), NULL);\n\n  return TRUE;\n}",
        "func_hash": 173907427135324375391340249360357936070,
        "file_name": "flatpak-run.c",
        "file_hash": 69385831422573127576569412177760237535,
        "cwe": [
            "CWE-20"
        ],
        "cve": "CVE-2021-41133",
        "cve_desc": "Flatpak is a system for building, distributing, and running sandboxed desktop applications on Linux. In versions prior to 1.10.4 and 1.12.0, Flatpak apps with direct access to AF_UNIX sockets such as those used by Wayland, Pipewire or pipewire-pulse can trick portals and other host-OS services into treating the Flatpak app as though it was an ordinary, non-sandboxed host-OS process. They can do this by manipulating the VFS using recent mount-related syscalls that are not blocked by Flatpak's denylist seccomp filter, in order to substitute a crafted `/.flatpak-info` or make that file disappear entirely. Flatpak apps that act as clients for AF_UNIX sockets such as those used by Wayland, Pipewire or pipewire-pulse can escalate the privileges that the corresponding services will believe the Flatpak app has. Note that protocols that operate entirely over the D-Bus session bus (user bus), system bus or accessibility bus are not affected by this. This is due to the use of a proxy process `xdg-dbus-proxy`, whose VFS cannot be manipulated by the Flatpak app, when interacting with these buses. Patches exist for versions 1.10.4 and 1.12.0, and as of time of publication, a patch for version 1.8.2 is being planned. There are no workarounds aside from upgrading to a patched version.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-41133",
        "func_name": "setup_seccomp",
        "diff": [
            "diff --git a/common/flatpak-run.c b/common/flatpak-run.c\nindex e93b3d63b0..7817ff94f0 100644\n--- a/common/flatpak-run.c\n+++ b/common/flatpak-run.c\n@@ -2897,61 +2897,63 @@ setup_seccomp (FlatpakBwrap   *bwrap,\n   struct\n   {\n     int                  scall;\n+    int                  errnum;\n     struct scmp_arg_cmp *arg;\n   } syscall_blocklist[] = {\n     /* Block dmesg */\n-    {SCMP_SYS (syslog)},\n+    {SCMP_SYS (syslog), EPERM},\n     /* Useless old syscall */\n-    {SCMP_SYS (uselib)},\n+    {SCMP_SYS (uselib), EPERM},\n     /* Don't allow disabling accounting */\n-    {SCMP_SYS (acct)},\n+    {SCMP_SYS (acct), EPERM},\n     /* 16-bit code is unnecessary in the sandbox, and modify_ldt is a\n        historic source of interesting information leaks. */\n-    {SCMP_SYS (modify_ldt)},\n+    {SCMP_SYS (modify_ldt), EPERM},\n     /* Don't allow reading current quota use */\n-    {SCMP_SYS (quotactl)},\n+    {SCMP_SYS (quotactl), EPERM},\n \n     /* Don't allow access to the kernel keyring */\n-    {SCMP_SYS (add_key)},\n-    {SCMP_SYS (keyctl)},\n-    {SCMP_SYS (request_key)},\n+    {SCMP_SYS (add_key), EPERM},\n+    {SCMP_SYS (keyctl), EPERM},\n+    {SCMP_SYS (request_key), EPERM},\n \n     /* Scary VM/NUMA ops */\n-    {SCMP_SYS (move_pages)},\n-    {SCMP_SYS (mbind)},\n-    {SCMP_SYS (get_mempolicy)},\n-    {SCMP_SYS (set_mempolicy)},\n-    {SCMP_SYS (migrate_pages)},\n+    {SCMP_SYS (move_pages), EPERM},\n+    {SCMP_SYS (mbind), EPERM},\n+    {SCMP_SYS (get_mempolicy), EPERM},\n+    {SCMP_SYS (set_mempolicy), EPERM},\n+    {SCMP_SYS (migrate_pages), EPERM},\n \n     /* Don't allow subnamespace setups: */\n-    {SCMP_SYS (unshare)},\n-    {SCMP_SYS (mount)},\n-    {SCMP_SYS (pivot_root)},\n+    {SCMP_SYS (unshare), EPERM},\n+    {SCMP_SYS (mount), EPERM},\n+    {SCMP_SYS (pivot_root), EPERM},\n #if defined(__s390__) || defined(__s390x__) || defined(__CRIS__)\n     /* Architectures with CONFIG_CLONE_BACKWARDS2: the child stack\n      * and flags arguments are reversed so the flags come second */\n-    {SCMP_SYS (clone), &SCMP_A1 (SCMP_CMP_MASKED_EQ, CLONE_NEWUSER, CLONE_NEWUSER)},\n+    {SCMP_SYS (clone), EPERM, &SCMP_A1 (SCMP_CMP_MASKED_EQ, CLONE_NEWUSER, CLONE_NEWUSER)},\n #else\n     /* Normally the flags come first */\n-    {SCMP_SYS (clone), &SCMP_A0 (SCMP_CMP_MASKED_EQ, CLONE_NEWUSER, CLONE_NEWUSER)},\n+    {SCMP_SYS (clone), EPERM, &SCMP_A0 (SCMP_CMP_MASKED_EQ, CLONE_NEWUSER, CLONE_NEWUSER)},\n #endif\n \n     /* Don't allow faking input to the controlling tty (CVE-2017-5226) */\n-    {SCMP_SYS (ioctl), &SCMP_A1 (SCMP_CMP_MASKED_EQ, 0xFFFFFFFFu, (int) TIOCSTI)},\n+    {SCMP_SYS (ioctl), EPERM, &SCMP_A1 (SCMP_CMP_MASKED_EQ, 0xFFFFFFFFu, (int) TIOCSTI)},\n   };\n \n   struct\n   {\n     int                  scall;\n+    int                  errnum;\n     struct scmp_arg_cmp *arg;\n   } syscall_nondevel_blocklist[] = {\n     /* Profiling operations; we expect these to be done by tools from outside\n      * the sandbox.  In particular perf has been the source of many CVEs.\n      */\n-    {SCMP_SYS (perf_event_open)},\n+    {SCMP_SYS (perf_event_open), EPERM},\n     /* Don't allow you to switch to bsd emulation or whatnot */\n-    {SCMP_SYS (personality), &SCMP_A0 (SCMP_CMP_NE, allowed_personality)},\n-    {SCMP_SYS (ptrace)}\n+    {SCMP_SYS (personality), EPERM, &SCMP_A0 (SCMP_CMP_NE, allowed_personality)},\n+    {SCMP_SYS (ptrace), EPERM}\n   };\n   /* Blocklist all but unix, inet, inet6 and netlink */\n   struct\n@@ -3035,10 +3037,14 @@ setup_seccomp (FlatpakBwrap   *bwrap,\n   for (i = 0; i < G_N_ELEMENTS (syscall_blocklist); i++)\n     {\n       int scall = syscall_blocklist[i].scall;\n+      int errnum = syscall_blocklist[i].errnum;\n+\n+      g_return_val_if_fail (errnum == EPERM || errnum == ENOSYS, FALSE);\n+\n       if (syscall_blocklist[i].arg)\n-        r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (EPERM), scall, 1, *syscall_blocklist[i].arg);\n+        r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (errnum), scall, 1, *syscall_blocklist[i].arg);\n       else\n-        r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (EPERM), scall, 0);\n+        r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (errnum), scall, 0);\n       if (r < 0 && r == -EFAULT /* unknown syscall */)\n         return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to block syscall %d\"), scall);\n     }\n@@ -3048,10 +3054,14 @@ setup_seccomp (FlatpakBwrap   *bwrap,\n       for (i = 0; i < G_N_ELEMENTS (syscall_nondevel_blocklist); i++)\n         {\n           int scall = syscall_nondevel_blocklist[i].scall;\n+          int errnum = syscall_nondevel_blocklist[i].errnum;\n+\n+          g_return_val_if_fail (errnum == EPERM || errnum == ENOSYS, FALSE);\n+\n           if (syscall_nondevel_blocklist[i].arg)\n-            r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (EPERM), scall, 1, *syscall_nondevel_blocklist[i].arg);\n+            r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (errnum), scall, 1, *syscall_nondevel_blocklist[i].arg);\n           else\n-            r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (EPERM), scall, 0);\n+            r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (errnum), scall, 0);\n \n           if (r < 0 && r == -EFAULT /* unknown syscall */)\n             return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to block syscall %d\"), scall);\n"
        ],
        "func_after": []
    },
    {
        "idx": 195242,
        "project": "tensorflow",
        "commit_id": "1b54cadd19391b60b6fcccd8d076426f7221d5e8",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/1b54cadd19391b60b6fcccd8d076426f7221d5e8",
        "commit_message": "Add missing validation to sparse dense cwise ops.\n\nPiperOrigin-RevId: 415543133\nChange-Id: I5baf3284e919338afb96178c468ad3d3cb0d956c",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext *ctx) override {\n    const Tensor *indices_t, *values_t, *shape_t, *dense_t;\n    OP_REQUIRES_OK(ctx, ctx->input(\"sp_indices\", &indices_t));\n    OP_REQUIRES_OK(ctx, ctx->input(\"sp_values\", &values_t));\n    OP_REQUIRES_OK(ctx, ctx->input(\"sp_shape\", &shape_t));\n    OP_REQUIRES_OK(ctx, ctx->input(\"dense\", &dense_t));\n\n    // Validations.\n    OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(indices_t->shape()),\n                errors::InvalidArgument(\n                    \"Input sp_indices should be a matrix but received shape: \",\n                    indices_t->shape().DebugString()));\n    OP_REQUIRES(ctx,\n                TensorShapeUtils::IsVector(values_t->shape()) &&\n                    TensorShapeUtils::IsVector(shape_t->shape()),\n                errors::InvalidArgument(\n                    \"Inputs sp_values and sp_shape should be vectors \"\n                    \"but received shapes: \",\n                    values_t->shape().DebugString(), \" and \",\n                    shape_t->shape().DebugString()));\n    OP_REQUIRES(\n        ctx, values_t->dim_size(0) == indices_t->dim_size(0),\n        errors::InvalidArgument(\n            \"The first dimension of values and indices should match. (\",\n            values_t->dim_size(0), \" vs. \", indices_t->dim_size(0), \")\"));\n\n    const auto indices_mat = indices_t->matrix<int64_t>();\n    const auto shape_vec = shape_t->vec<int64_t>();\n    const auto lhs_dims = BCast::FromShape(TensorShape(shape_vec));\n    const auto rhs_dims = BCast::FromShape(dense_t->shape());\n    BCast b(lhs_dims, rhs_dims, false);  // false for keeping the same num dims.\n\n    // True iff (size(lhs) >= size(rhs)) and all dims in lhs is greater or equal\n    // to dims in rhs (from right to left).\n    auto VecGreaterEq = [](ArraySlice<int64_t> lhs, ArraySlice<int64_t> rhs) {\n      if (lhs.size() < rhs.size()) return false;\n      for (size_t i = 0; i < rhs.size(); ++i) {\n        if (lhs[lhs.size() - 1 - i] < rhs[rhs.size() - 1 - i]) return false;\n      }\n      return true;\n    };\n    OP_REQUIRES(ctx, VecGreaterEq(lhs_dims, rhs_dims) && b.IsValid(),\n                errors::InvalidArgument(\n                    \"SparseDenseBinaryOpShared broadcasts dense to sparse \"\n                    \"only; got incompatible shapes: [\",\n                    absl::StrJoin(lhs_dims, \",\"), \"] vs. [\",\n                    absl::StrJoin(rhs_dims, \",\"), \"]\"));\n\n    Tensor *output_values = nullptr;\n    Tensor dense_gathered;\n    const int64_t nnz = indices_t->dim_size(0);\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_output(0, TensorShape({nnz}), &output_values));\n    OP_REQUIRES_OK(\n        ctx, ctx->allocate_temp(DataTypeToEnum<T>::value, TensorShape({nnz}),\n                                &dense_gathered));\n    bool op_is_div = false;\n    if (absl::StrContains(ctx->op_kernel().type_string_view(), \"Div\")) {\n      op_is_div = true;\n    }\n    // Pulls relevant entries from the dense side, with reshape and broadcasting\n    // *of the dense side* taken into account.  Use a TensorRef to avoid blowing\n    // up memory.\n    //\n    // We can directly use the sparse indices to look up dense side, because\n    // \"b.y_reshape()\" and \"b.y_bcast()\" are guaranteed to have rank \"ndims\".\n    auto dense_gathered_flat = dense_gathered.flat<T>();\n    const int ndims = lhs_dims.size();\n    switch (ndims) {\n#define CASE(NDIM)                                                             \\\n  case NDIM: {                                                                 \\\n    TensorRef<Eigen::Tensor<const T, NDIM, Eigen::RowMajor>> rhs_ref =         \\\n        dense_t->shaped<T, NDIM>(b.y_reshape())                                \\\n            .broadcast(BCast::ToIndexArray<NDIM>(b.y_bcast()));                \\\n    Eigen::array<Eigen::DenseIndex, NDIM> idx;                                 \\\n    bool indices_valid = true;                                                 \\\n    for (int i = 0; i < nnz; ++i) {                                            \\\n      for (int d = 0; d < NDIM; ++d) {                                         \\\n        idx[d] = internal::SubtleMustCopy(indices_mat(i, d));                  \\\n        if (!FastBoundsCheck(idx[d], rhs_ref.dimension(d))) {                  \\\n          indices_valid = false;                                               \\\n        }                                                                      \\\n      }                                                                        \\\n      OP_REQUIRES(                                                             \\\n          ctx, indices_valid,                                                  \\\n          errors::InvalidArgument(\"Provided indices are out-of-bounds w.r.t. \" \\\n                                  \"dense side with broadcasted shape\"));       \\\n      dense_gathered_flat(i) = rhs_ref.coeff(idx);                             \\\n      if (op_is_div) {                                                         \\\n        OP_REQUIRES(ctx, dense_gathered_flat(i) != 0,                          \\\n                    errors::InvalidArgument(                                   \\\n                        \"SparseDenseCwiseDiv cannot divide by zero,\"           \\\n                        \"but input dense tensor contains zero \"));             \\\n      }                                                                        \\\n    }                                                                          \\\n    break;                                                                     \\\n  }\n\n      CASE(1);\n      CASE(2);\n      CASE(3);\n      CASE(4);\n      CASE(5);\n      default:\n        OP_REQUIRES(\n            ctx, false,\n            errors::InvalidArgument(\"Only tensors with ranks between 1 and 5 \"\n                                    \"are currently supported.  Tensor rank: \",\n                                    ndims));\n#undef CASE\n    }\n\n    output_values->flat<T>().device(ctx->eigen_device<Device>()) =\n        values_t->flat<T>().binaryExpr(dense_gathered_flat,\n                                       typename Functor::func());\n  }",
        "func_hash": 280343339014694875612411900055184725662,
        "file_name": "sparse_dense_binary_op_shared.cc",
        "file_hash": 149048879181841547116557871950334917673,
        "cwe": [
            "CWE-190"
        ],
        "cve": "CVE-2022-23567",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The implementations of `Sparse*Cwise*` ops are vulnerable to integer overflows. These can be used to trigger large allocations (so, OOM based denial of service) or `CHECK`-fails when building new `TensorShape` objects (so, assert failures based denial of service). We are missing some validation on the shapes of the input tensors as well as directly constructing a large `TensorShape` with user-provided dimensions. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23567",
        "func_name": "Compute",
        "diff": [
            "diff --git a/tensorflow/core/kernels/sparse_dense_binary_op_shared.cc b/tensorflow/core/kernels/sparse_dense_binary_op_shared.cc\nindex b8a391b560f3c1..db27abfda7e537 100644\n--- a/tensorflow/core/kernels/sparse_dense_binary_op_shared.cc\n+++ b/tensorflow/core/kernels/sparse_dense_binary_op_shared.cc\n@@ -78,11 +78,24 @@ class SparseDenseBinaryOpShared : public OpKernel {\n                     \"but received shapes: \",\n                     values_t->shape().DebugString(), \" and \",\n                     shape_t->shape().DebugString()));\n+    OP_REQUIRES(\n+        ctx, TensorShapeUtils::IsVector(shape_t->shape()),\n+        errors::InvalidArgument(\"Input sp_shape must be a vector. Got: \",\n+                                shape_t->shape().DebugString()));\n     OP_REQUIRES(\n         ctx, values_t->dim_size(0) == indices_t->dim_size(0),\n         errors::InvalidArgument(\n             \"The first dimension of values and indices should match. (\",\n             values_t->dim_size(0), \" vs. \", indices_t->dim_size(0), \")\"));\n+    OP_REQUIRES(\n+        ctx, shape_t->shape().dim_size(0) == indices_t->shape().dim_size(1),\n+        errors::InvalidArgument(\n+            \"Number of dimensions must match second dimension of indices. \",\n+            \"Got \", shape_t->shape().dim_size(0),\n+            \" dimensions, indices shape: \", indices_t->shape().DebugString()));\n+    OP_REQUIRES(ctx, shape_t->NumElements() > 0,\n+                errors::InvalidArgument(\n+                    \"The shape argument requires at least one element.\"));\n \n     const auto indices_mat = indices_t->matrix<int64_t>();\n     const auto shape_vec = shape_t->vec<int64_t>();\n"
        ],
        "func_after": []
    },
    {
        "idx": 198282,
        "project": "tensorflow",
        "commit_id": "4923de56ec94fff7770df259ab7f2288a74feb41",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/4923de56ec94fff7770df259ab7f2288a74feb41",
        "commit_message": "Don't do any work when reshaping 0 elements sparse tensor.\n\nIf reshaping to 0 elements tensor, check that input has no elements.\nIf reshaping no elements input, check that output has no elements.\n\nPiperOrigin-RevId: 388296986\nChange-Id: Iadc9fe7252e14313ca987e69bf0d7042fd10232a",
        "target": 1,
        "irrelevant": 0,
        "func_before": "void ReshapeSparseTensor(OpKernelContext *context,\n                         const Tensor &input_indices_in,\n                         const Tensor &input_shape_in,\n                         const Tensor &target_shape_in, int output_indices_idx,\n                         int output_shape_idx) {\n  OP_REQUIRES(context, TensorShapeUtils::IsMatrix(input_indices_in.shape()),\n              errors::InvalidArgument(\n                  \"Input indices should be a matrix but received shape \",\n                  input_indices_in.shape().DebugString()));\n  OP_REQUIRES(context, TensorShapeUtils::IsVector(input_shape_in.shape()),\n              errors::InvalidArgument(\n                  \"Input shape should be a vector but received shape \",\n                  input_shape_in.shape().DebugString()));\n  OP_REQUIRES(context, TensorShapeUtils::IsVector(target_shape_in.shape()),\n              errors::InvalidArgument(\n                  \"Target shape should be a vector but received shape \",\n                  target_shape_in.shape().DebugString()));\n\n  const int64_t output_rank = target_shape_in.NumElements();\n  const TensorShape input_shape(input_shape_in.vec<int64>());\n  const int64_t dense_size = input_shape.num_elements();\n  const int64_t nnz = input_indices_in.shape().dim_size(0);\n\n  // Compute the output shape. Determine product of specified dimensions, and\n  // find the index of the unspecified one.\n  TensorShape output_shape;\n  int64_t product = 1;\n  int unknown_index = -1;\n  auto target_shape = target_shape_in.vec<int64>();\n  for (int d = 0; d < output_rank; ++d) {\n    const int64_t size = target_shape(d);\n    if (size == -1) {\n      OP_REQUIRES(\n          context, unknown_index == -1,\n          errors::InvalidArgument(\"only one output dimension may be -1, \"\n                                  \"not both \",\n                                  unknown_index, \" and \", d));\n      unknown_index = d;\n      output_shape.AddDim(1);\n    } else {\n      OP_REQUIRES(context, size >= 0,\n                  errors::InvalidArgument(\"size \", d,\n                                          \" must be non-negative, not \", size));\n      product *= size;\n      output_shape.AddDim(size);\n    }\n  }\n  if (unknown_index != -1) {\n    OP_REQUIRES(\n        context, product > 0,\n        errors::InvalidArgument(\"reshape cannot infer the missing \"\n                                \"input size for an empty tensor unless all \"\n                                \"specified input sizes are non-zero\"));\n    const int64_t missing = dense_size / product;\n    OP_REQUIRES(\n        context, product * missing == dense_size,\n        errors::InvalidArgument(\n            \"Input to reshape is a SparseTensor with \", dense_size,\n            \" dense values, but the requested shape requires a multiple of \",\n            product, \". input_shape=\", input_shape.DebugString(),\n            \" output_shape=\", output_shape.DebugString()));\n    output_shape.set_dim(unknown_index, missing);\n  }\n\n  OP_REQUIRES(\n      context, output_shape.num_elements() == dense_size,\n      errors::InvalidArgument(\"Input to reshape is a tensor with \", dense_size,\n                              \" dense values, but the requested shape has \",\n                              output_shape.num_elements(),\n                              \". input_shape=\", input_shape.DebugString(),\n                              \" output_shape=\", output_shape.DebugString()));\n\n  // Optimize for reshaping to the same shape.\n  if (input_shape == output_shape) {\n    context->set_output(output_indices_idx, input_indices_in);\n    context->set_output(output_shape_idx, input_shape_in);\n    return;\n  }\n\n  Tensor *result_shape = nullptr;\n  OP_REQUIRES_OK(context, context->allocate_output(output_shape_idx,\n                                                   TensorShape({output_rank}),\n                                                   &result_shape));\n  auto output_shape_vec = result_shape->vec<int64>();\n  for (int j = 0; j < output_shape.dims(); ++j) {\n    output_shape_vec(j) = output_shape.dim_size(j);\n  }\n\n  Tensor *result_indices = nullptr;\n  OP_REQUIRES_OK(context,\n                 context->allocate_output(output_indices_idx,\n                                          TensorShape({nnz, output_rank}),\n                                          &result_indices));\n  if (nnz > 0) {\n    OP_REQUIRES_OK(context, functor::ReshapeSparseTensorFunctor<Device>()(\n                                context, input_shape, output_shape,\n                                input_indices_in.matrix<int64>(),\n                                result_indices->matrix<int64>()));\n  }\n}",
        "func_hash": 228488147174937246000179946900319201208,
        "file_name": "reshape_util.cc",
        "file_hash": 224364433068010361888882257047924749715,
        "cwe": [
            "CWE-369"
        ],
        "cve": "CVE-2021-37640",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions the implementation of `tf.raw_ops.SparseReshape` can be made to trigger an integral division by 0 exception. The [implementation](https://github.com/tensorflow/tensorflow/blob/8d72537c6abf5a44103b57b9c2e22c14f5f49698/tensorflow/core/kernels/reshape_util.cc#L176-L181) calls the reshaping functor whenever there is at least an index in the input but does not check that shape of the input or the target shape have both a non-zero number of elements. The [reshape functor](https://github.com/tensorflow/tensorflow/blob/8d72537c6abf5a44103b57b9c2e22c14f5f49698/tensorflow/core/kernels/reshape_util.cc#L40-L78) blindly divides by the dimensions of the target shape. Hence, if this is not checked, code will result in a division by 0. We have patched the issue in GitHub commit 4923de56ec94fff7770df259ab7f2288a74feb41. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1 as this is the other affected version.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37640",
        "func_name": "ReshapeSparseTensor",
        "diff": [
            "diff --git a/tensorflow/core/kernels/reshape_util.cc b/tensorflow/core/kernels/reshape_util.cc\nindex 6d6c6b3fcf193b..5db8944cebf06b 100644\n--- a/tensorflow/core/kernels/reshape_util.cc\n+++ b/tensorflow/core/kernels/reshape_util.cc\n@@ -174,6 +174,12 @@ void ReshapeSparseTensor(OpKernelContext *context,\n                                           TensorShape({nnz, output_rank}),\n                                           &result_indices));\n   if (nnz > 0) {\n+    OP_REQUIRES(\n+        context, dense_size > 0 && product > 0,\n+        errors::InvalidArgument(\n+            \"Input tensor has \", nnz, \" non zero elements but input shape (\",\n+            input_shape.DebugString(), \") or output shape (\",\n+            output_shape.DebugString(), \") is empty\"));\n     OP_REQUIRES_OK(context, functor::ReshapeSparseTensorFunctor<Device>()(\n                                 context, input_shape, output_shape,\n                                 input_indices_in.matrix<int64>(),\n"
        ],
        "func_after": []
    },
    {
        "idx": 198350,
        "project": "owntone-server",
        "commit_id": "246d8ae0cef27377e5dfe9ee3ad87e864d6b6266",
        "project_url": "https://github.com/owntone/owntone-server",
        "commit_url": "https://github.com/owntone/owntone-server/commit/246d8ae0cef27377e5dfe9ee3ad87e864d6b6266",
        "commit_message": "[misc] Fix use-after-free in net_bind()\n\nThanks to Ba Jinsheng for reporting this bug",
        "target": 1,
        "irrelevant": 0,
        "func_before": "net_bind(short unsigned *port, int type, const char *log_service_name)\n{\n  struct addrinfo hints = { 0 };\n  struct addrinfo *servinfo;\n  struct addrinfo *ptr;\n  const char *cfgaddr;\n  char addr[INET6_ADDRSTRLEN];\n  char strport[8];\n  int yes = 1;\n  int no = 0;\n  int fd;\n  int ret;\n\n  cfgaddr = cfg_getstr(cfg_getsec(cfg, \"general\"), \"bind_address\");\n\n  hints.ai_socktype = (type & (SOCK_STREAM | SOCK_DGRAM)); // filter since type can be SOCK_STREAM | SOCK_NONBLOCK\n  hints.ai_family = (cfg_getbool(cfg_getsec(cfg, \"general\"), \"ipv6\")) ? AF_INET6 : AF_INET;\n  hints.ai_flags = cfgaddr ? 0 : AI_PASSIVE;\n\n  snprintf(strport, sizeof(strport), \"%hu\", *port);\n  ret = getaddrinfo(cfgaddr, strport, &hints, &servinfo);\n  if (ret < 0)\n    {\n      DPRINTF(E_LOG, L_MISC, \"Failure creating '%s' service, could not resolve '%s' (port %s): %s\\n\", log_service_name, cfgaddr ? cfgaddr : \"(ANY)\", strport, gai_strerror(ret));\n      return -1;\n    }\n\n  for (ptr = servinfo, fd = -1; ptr != NULL; ptr = ptr->ai_next)\n    {\n      if (fd >= 0)\n\tclose(fd);\n\n      fd = socket(ptr->ai_family, type | SOCK_CLOEXEC, ptr->ai_protocol);\n      if (fd < 0)\n\tcontinue;\n\n      // TODO libevent sets this, we do the same?\n      ret = setsockopt(fd, SOL_SOCKET, SO_KEEPALIVE, &yes, sizeof(yes));\n      if (ret < 0)\n\tcontinue;\n\n      ret = setsockopt(fd, SOL_SOCKET, SO_REUSEADDR, &yes, sizeof(yes));\n      if (ret < 0)\n\tcontinue;\n\n      if (ptr->ai_family == AF_INET6)\n\t{\n\t  // We want to be sure the service is dual stack\n\t  ret = setsockopt(fd, IPPROTO_IPV6, IPV6_V6ONLY, &no, sizeof(no));\n\t  if (ret < 0)\n\t    continue;\n\t}\n\n      ret = bind(fd, ptr->ai_addr, ptr->ai_addrlen);\n      if (ret < 0)\n\tcontinue;\n\n      break;\n    }\n\n  freeaddrinfo(servinfo);\n\n  if (!ptr)\n    {\n      DPRINTF(E_LOG, L_MISC, \"Could not create service '%s' with address %s, port %hu: %s\\n\", log_service_name, cfgaddr ? cfgaddr : \"(ANY)\", *port, strerror(errno));\n      goto error;\n    }\n\n  // Get the port that was assigned\n  ret = getsockname(fd, ptr->ai_addr, &ptr->ai_addrlen);\n  if (ret < 0)\n    {\n      DPRINTF(E_LOG, L_MISC, \"Could not find address of service '%s': %s\\n\", log_service_name, strerror(errno));\n      goto error;\n    }\n\n  net_port_get(port, (union net_sockaddr *)ptr->ai_addr);\n  net_address_get(addr, sizeof(addr), (union net_sockaddr *)ptr->ai_addr);\n\n  DPRINTF(E_DBG, L_MISC, \"Service '%s' bound to %s, port %hu, socket %d\\n\", log_service_name, addr, *port, fd);\n\n  return fd;\n\n error:\n  close(fd);\n  return -1;\n}",
        "func_hash": 32546260713202661418218833633405896143,
        "file_name": "misc.c",
        "file_hash": 105075321496416144885475599863207164581,
        "cwe": [
            "CWE-416"
        ],
        "cve": "CVE-2021-38383",
        "cve_desc": "OwnTone (aka owntone-server) through 28.1 has a use-after-free in net_bind() in misc.c.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-38383",
        "func_name": "net_bind",
        "diff": [
            "diff --git a/src/misc.c b/src/misc.c\nindex 4062525719..73266c91a8 100644\n--- a/src/misc.c\n+++ b/src/misc.c\n@@ -251,6 +251,8 @@ net_bind(short unsigned *port, int type, const char *log_service_name)\n   struct addrinfo hints = { 0 };\n   struct addrinfo *servinfo;\n   struct addrinfo *ptr;\n+  union net_sockaddr naddr = { 0 };\n+  socklen_t naddr_len = sizeof(naddr);\n   const char *cfgaddr;\n   char addr[INET6_ADDRSTRLEN];\n   char strport[8];\n@@ -314,16 +316,22 @@ net_bind(short unsigned *port, int type, const char *log_service_name)\n       goto error;\n     }\n \n-  // Get the port that was assigned\n-  ret = getsockname(fd, ptr->ai_addr, &ptr->ai_addrlen);\n+  // Get our address (as string) and the port that was assigned (necessary when\n+  // caller didn't specify a port)\n+  ret = getsockname(fd, &naddr.sa, &naddr_len);\n   if (ret < 0)\n     {\n-      DPRINTF(E_LOG, L_MISC, \"Could not find address of service '%s': %s\\n\", log_service_name, strerror(errno));\n+      DPRINTF(E_LOG, L_MISC, \"Error finding address of service '%s': %s\\n\", log_service_name, strerror(errno));\n+      goto error;\n+    }\n+  else if (naddr_len > sizeof(naddr))\n+    {\n+      DPRINTF(E_LOG, L_MISC, \"Unexpected address length of service '%s'\\n\", log_service_name);\n       goto error;\n     }\n \n-  net_port_get(port, (union net_sockaddr *)ptr->ai_addr);\n-  net_address_get(addr, sizeof(addr), (union net_sockaddr *)ptr->ai_addr);\n+  net_port_get(port, &naddr);\n+  net_address_get(addr, sizeof(addr), &naddr);\n \n   DPRINTF(E_DBG, L_MISC, \"Service '%s' bound to %s, port %hu, socket %d\\n\", log_service_name, addr, *port, fd);\n \n"
        ],
        "func_after": []
    },
    {
        "idx": 198374,
        "project": "tensorflow",
        "commit_id": "803404044ae7a1efac48ba82d74111fce1ddb09a",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/803404044ae7a1efac48ba82d74111fce1ddb09a",
        "commit_message": "Fix security vulnerability with LSTMBlockCellOp\n\nPiperOrigin-RevId: 446028341",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor* x_tensor = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->input(\"x\", &x_tensor));\n\n    const Tensor* cs_prev_tensor = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->input(\"cs_prev\", &cs_prev_tensor));\n\n    const Tensor* h_prev_tensor = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->input(\"h_prev\", &h_prev_tensor));\n\n    const Tensor* w_tensor = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->input(\"w\", &w_tensor));\n\n    const Tensor* wci_tensor = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->input(\"wci\", &wci_tensor));\n\n    const Tensor* wcf_tensor = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->input(\"wcf\", &wcf_tensor));\n\n    const Tensor* wco_tensor = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->input(\"wco\", &wco_tensor));\n\n    const Tensor* b_tensor = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->input(\"b\", &b_tensor));\n\n    const int64_t batch_size = x_tensor->dim_size(0);\n    const int64_t input_size = x_tensor->dim_size(1);\n    const int64_t cell_size = cs_prev_tensor->dim_size(1);\n\n    // Sanity checks for our input shapes.\n    OP_REQUIRES(ctx, cs_prev_tensor->dim_size(0) == batch_size,\n                errors::InvalidArgument(\"cs_prev.dims(0) != batch_size: \",\n                                        cs_prev_tensor->dim_size(0), \" vs. \",\n                                        batch_size));\n    OP_REQUIRES(ctx, cs_prev_tensor->dim_size(1) == cell_size,\n                errors::InvalidArgument(\"cs_prev.dims(1) != cell_size: \",\n                                        cs_prev_tensor->dim_size(1), \" vs. \",\n                                        cell_size));\n\n    OP_REQUIRES(ctx, h_prev_tensor->dim_size(0) == batch_size,\n                errors::InvalidArgument(\"h_prev.dims(0) != batch_size: \",\n                                        h_prev_tensor->dim_size(0), \" vs. \",\n                                        batch_size));\n    OP_REQUIRES(ctx, h_prev_tensor->dim_size(1) == cell_size,\n                errors::InvalidArgument(\n                    \"h_prev.dims(1) != cell_size: \", h_prev_tensor->dim_size(1),\n                    \" vs. \", cell_size));\n\n    OP_REQUIRES(ctx, w_tensor->dim_size(0) == input_size + cell_size,\n                errors::InvalidArgument(\n                    \"w.dim_size(0) != input_size + cell_size: \",\n                    w_tensor->dim_size(0), \" vs. \", input_size + cell_size));\n    OP_REQUIRES(ctx, w_tensor->dim_size(1) == cell_size * 4,\n                errors::InvalidArgument(\n                    \"w.dim_size(1) != cell_size * 4: \", w_tensor->dim_size(1),\n                    \" vs. \", cell_size * 4));\n\n    OP_REQUIRES(ctx, b_tensor->dim_size(0) == cell_size * 4,\n                errors::InvalidArgument(\n                    \"b.dim_size(0) != cell_size * 4: \", b_tensor->dim_size(0),\n                    \" vs. \", cell_size * 4));\n\n    // Allocate our output tensors.\n    Tensor* i_tensor = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->forward_input_or_allocate_output(\n                            {\"h_prev\"}, \"i\",\n                            TensorShape({batch_size, cell_size}), &i_tensor));\n\n    Tensor* cs_tensor = nullptr;\n    OP_REQUIRES_OK(\n        ctx, ctx->allocate_output(\"cs\", TensorShape({batch_size, cell_size}),\n                                  &cs_tensor));\n\n    Tensor* f_tensor = nullptr;\n    OP_REQUIRES_OK(\n        ctx, ctx->allocate_output(\"f\", TensorShape({batch_size, cell_size}),\n                                  &f_tensor));\n\n    Tensor* o_tensor = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->forward_input_or_allocate_output(\n                            {\"cs_prev\"}, \"o\",\n                            TensorShape({batch_size, cell_size}), &o_tensor));\n\n    Tensor* ci_tensor = nullptr;\n    OP_REQUIRES_OK(\n        ctx, ctx->allocate_output(\"ci\", TensorShape({batch_size, cell_size}),\n                                  &ci_tensor));\n\n    Tensor* co_tensor = nullptr;\n    OP_REQUIRES_OK(\n        ctx, ctx->allocate_output(\"co\", TensorShape({batch_size, cell_size}),\n                                  &co_tensor));\n\n    Tensor* h_tensor = nullptr;\n    OP_REQUIRES_OK(\n        ctx, ctx->allocate_output(\"h\", TensorShape({batch_size, cell_size}),\n                                  &h_tensor));\n\n    // Allocate our temp tensors.\n    Tensor xh_tensor;\n    OP_REQUIRES_OK(ctx, ctx->allocate_temp(\n                            DataTypeToEnum<T>::v(),\n                            TensorShape({batch_size, input_size + cell_size}),\n                            &xh_tensor));\n\n    Tensor gates_tensor;\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_temp(DataTypeToEnum<T>::v(),\n                                      TensorShape({batch_size, cell_size * 4}),\n                                      &gates_tensor));\n\n    const Device& device = ctx->eigen_device<Device>();\n\n    functor::LSTMBlockCellFprop<Device, T, USE_CUBLAS, gate_layout>(\n        batch_size, input_size, cell_size)(\n        ctx, device, forget_bias_, cell_clip_, use_peephole_,\n        x_tensor->matrix<T>(), cs_prev_tensor->matrix<T>(),\n        h_prev_tensor->matrix<T>(), w_tensor->matrix<T>(), wci_tensor->vec<T>(),\n        wcf_tensor->vec<T>(), wco_tensor->vec<T>(), b_tensor->vec<T>(),\n        xh_tensor.matrix<T>(), i_tensor->matrix<T>(), cs_tensor->matrix<T>(),\n        f_tensor->matrix<T>(), o_tensor->matrix<T>(), ci_tensor->matrix<T>(),\n        co_tensor->matrix<T>(), gates_tensor.matrix<T>(),\n        h_tensor->matrix<T>());\n  }",
        "func_hash": 332787893197526379241591780916041422587,
        "file_name": "lstm_ops.cc",
        "file_hash": 94555141575162353468670590418949369497,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2022-29200",
        "cve_desc": "TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, the implementation of `tf.raw_ops.LSTMBlockCell` does not fully validate the input arguments. This results in a `CHECK`-failure which can be used to trigger a denial of service attack. The code does not validate the ranks of any of the arguments to this API call. This results in `CHECK`-failures when the elements of the tensor are accessed. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-29200",
        "func_name": "Compute",
        "diff": [
            "diff --git a/tensorflow/core/kernels/rnn/lstm_ops.cc b/tensorflow/core/kernels/rnn/lstm_ops.cc\nindex 711fc8f08275d8..ab4b9c695a5699 100644\n--- a/tensorflow/core/kernels/rnn/lstm_ops.cc\n+++ b/tensorflow/core/kernels/rnn/lstm_ops.cc\n@@ -416,6 +416,65 @@ class LSTMBlockCellOp : public OpKernel {\n \n     const Device& device = ctx->eigen_device<Device>();\n \n+    // Sanity check that each of the tensors have the required NDIMS.\n+    OP_REQUIRES(ctx, x_tensor->dims() == 2,\n+                errors::InvalidArgument(\"x_tensor must be rank 2 but is rank \",\n+                                        x_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, cs_prev_tensor->dims() == 2,\n+        errors::InvalidArgument(\"cs_prev_tensor must be rank 2 but is rank \",\n+                                cs_prev_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, h_prev_tensor->dims() == 2,\n+        errors::InvalidArgument(\"h_prev_tensor must be rank 2 but is rank \",\n+                                h_prev_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, w_tensor->dims() == 2,\n+                errors::InvalidArgument(\"w_tensor must be rank 2 but is rank \",\n+                                        w_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, wci_tensor->dims() == 1,\n+        errors::InvalidArgument(\"wci_tensor must be rank 1 but is rank \",\n+                                wci_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, wcf_tensor->dims() == 1,\n+        errors::InvalidArgument(\"wcf_tensor must be rank 1 but is rank \",\n+                                wci_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, wco_tensor->dims() == 1,\n+        errors::InvalidArgument(\"wco_tensor must be rank 1 but is rank \",\n+                                wco_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, b_tensor->dims() == 1,\n+                errors::InvalidArgument(\"b_tensor must be rank 1 but is rank \",\n+                                        b_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, xh_tensor.dims() == 2,\n+                errors::InvalidArgument(\"xh_tensor must be rank 2 but is rank \",\n+                                        xh_tensor.dims(), \".\"));\n+    OP_REQUIRES(ctx, i_tensor->dims() == 2,\n+                errors::InvalidArgument(\"i_tensor must be rank 2 but is rank \",\n+                                        i_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, cs_tensor->dims() == 2,\n+                errors::InvalidArgument(\"cs_tensor must be rank 2 but is rank \",\n+                                        cs_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, f_tensor->dims() == 2,\n+                errors::InvalidArgument(\"f_tensor must be rank 2 but is rank \",\n+                                        f_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, o_tensor->dims() == 2,\n+                errors::InvalidArgument(\"o_tensor must be rank 2 but is rank \",\n+                                        o_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, ci_tensor->dims() == 2,\n+                errors::InvalidArgument(\"ci_tensor must be rank 2 but is rank \",\n+                                        ci_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, co_tensor->dims() == 2,\n+                errors::InvalidArgument(\"co_tensor must be rank 2 but is rank \",\n+                                        co_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, gates_tensor.dims() == 2,\n+        errors::InvalidArgument(\"gates_tensor must be rank 2 but is rank \",\n+                                gates_tensor.dims(), \".\"));\n+    OP_REQUIRES(ctx, h_tensor->dims() == 2,\n+                errors::InvalidArgument(\"h_tensor must be rank 2 but is rank \",\n+                                        h_tensor->dims(), \".\"));\n+\n     functor::LSTMBlockCellFprop<Device, T, USE_CUBLAS, gate_layout>(\n         batch_size, input_size, cell_size)(\n         ctx, device, forget_bias_, cell_clip_, use_peephole_,\ndiff --git a/tensorflow/python/kernel_tests/nn_ops/rnn_cell_test.py b/tensorflow/python/kernel_tests/nn_ops/rnn_cell_test.py\nindex 438211f0cb71fa..bed3cbfd8aa2a9 100644\n--- a/tensorflow/python/kernel_tests/nn_ops/rnn_cell_test.py\n+++ b/tensorflow/python/kernel_tests/nn_ops/rnn_cell_test.py\n@@ -33,6 +33,7 @@\n from tensorflow.python.framework import test_util\n from tensorflow.python.ops import   array_ops\n from tensorflow.python.ops import control_flow_ops\n+from tensorflow.python.ops import gen_rnn_ops\n from tensorflow.python.ops import gradients_impl\n from tensorflow.python.ops import init_ops\n from tensorflow.python.ops import math_ops\n@@ -1323,6 +1324,36 @@ def testDynamicEquivalentToStaticRNN(self):\n   def testDynamicEquivalentToStaticRNNWithSequenceLength(self):\n     self._testDynamicEquivalentToStaticRNN(use_sequence_length=True)\n \n+  @test_util.run_in_graph_and_eager_modes\n+  def testLSTMBlockCellErrorHandling(self):\n+    forget_bias = 1\n+    cell_clip = 0\n+    use_peephole = False\n+    x = constant_op.constant(0.837607, shape=[28, 29], dtype=dtypes.float32)\n+    cs_prev = constant_op.constant(0, shape=[28, 17], dtype=dtypes.float32)\n+    h_prev = constant_op.constant(\n+        0.592631638, shape=[28, 17], dtype=dtypes.float32)\n+    w = constant_op.constant(0.887386262, shape=[46, 68], dtype=dtypes.float32)\n+    wci = constant_op.constant(0, shape=[], dtype=dtypes.float32)\n+    wcf = constant_op.constant(0, shape=[17], dtype=dtypes.float32)\n+    wco = constant_op.constant(\n+        0.592631638, shape=[28, 17], dtype=dtypes.float32)\n+    b = constant_op.constant(0.75259006, shape=[68], dtype=dtypes.float32)\n+    with self.assertRaises(errors_impl.InvalidArgumentError):\n+      self.evaluate(\n+          gen_rnn_ops.lstm_block_cell(\n+              x=x,\n+              cs_prev=cs_prev,\n+              h_prev=h_prev,\n+              w=w,\n+              wci=wci,\n+              wcf=wcf,\n+              wco=wco,\n+              b=b,\n+              forget_bias=forget_bias,\n+              cell_clip=cell_clip,\n+              use_peephole=use_peephole))\n+\n \n class BidirectionalRNNTest(test.TestCase):\n \n"
        ],
        "func_after": []
    },
    {
        "idx": 198399,
        "project": "uftpd",
        "commit_id": "0fb2c031ce0ace07cc19cd2cb2143c4b5a63c9dd",
        "project_url": "https://github.com/troglobit/uftpd",
        "commit_url": "https://github.com/troglobit/uftpd/commit/0fb2c031ce0ace07cc19cd2cb2143c4b5a63c9dd",
        "commit_message": "FTP: Fix buffer overflow in PORT parser, reported by Aaron Esau\n\nSigned-off-by: Joachim Nilsson <troglobit@gmail.com>",
        "target": 1,
        "irrelevant": 1,
        "func_before": "static void handle_PORT(ctrl_t *ctrl, char *str)\n{\n\tint a, b, c, d, e, f;\n\tchar addr[INET_ADDRSTRLEN];\n\tstruct sockaddr_in sin;\n\n\tif (ctrl->data_sd > 0) {\n\t\tuev_io_stop(&ctrl->data_watcher);\n\t\tclose(ctrl->data_sd);\n\t\tctrl->data_sd = -1;\n\t}\n\n\t/* Convert PORT command's argument to IP address + port */\n\tsscanf(str, \"%d,%d,%d,%d,%d,%d\", &a, &b, &c, &d, &e, &f);\n\tsprintf(addr, \"%d.%d.%d.%d\", a, b, c, d);\n\n\t/* Check IPv4 address using inet_aton(), throw away converted result */\n\tif (!inet_aton(addr, &(sin.sin_addr))) {\n\t\tERR(0, \"Invalid address '%s' given to PORT command\", addr);\n\t\tsend_msg(ctrl->sd, \"500 Illegal PORT command.\\r\\n\");\n\t\treturn;\n\t}\n\n\tstrlcpy(ctrl->data_address, addr, sizeof(ctrl->data_address));\n\tctrl->data_port = e * 256 + f;\n\n\tDBG(\"Client PORT command accepted for %s:%d\", ctrl->data_address, ctrl->data_port);\n\tsend_msg(ctrl->sd, \"200 PORT command successful.\\r\\n\");\n}",
        "func_hash": 5389607465091397932741652441661168107,
        "file_name": "ftpcmd.c",
        "file_hash": 13134413350440209021234166619599968419,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2020-20276",
        "cve_desc": "An unauthenticated stack-based buffer overflow vulnerability in common.c's handle_PORT in uftpd FTP server versions 2.10 and earlier can be abused to cause a crash and could potentially lead to remote code execution.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2020-20276",
        "func_name": "handle_PORT",
        "diff": [
            "diff --git a/src/ftpcmd.c b/src/ftpcmd.c\nindex b318711..34686a4 100644\n--- a/src/ftpcmd.c\n+++ b/src/ftpcmd.c\n@@ -441,7 +441,7 @@ static void handle_PORT(ctrl_t *ctrl, char *str)\n \n \t/* Convert PORT command's argument to IP address + port */\n \tsscanf(str, \"%d,%d,%d,%d,%d,%d\", &a, &b, &c, &d, &e, &f);\n-\tsprintf(addr, \"%d.%d.%d.%d\", a, b, c, d);\n+\tsnprintf(addr, sizeof(addr), \"%d.%d.%d.%d\", a, b, c, d);\n \n \t/* Check IPv4 address using inet_aton(), throw away converted result */\n \tif (!inet_aton(addr, &(sin.sin_addr))) {\n"
        ],
        "func_after": []
    },
    {
        "idx": 198439,
        "project": "mruby",
        "commit_id": "3cf291f72224715942beaf8553e42ba8891ab3c6",
        "project_url": "https://github.com/mruby/mruby",
        "commit_url": "https://github.com/mruby/mruby/commit/3cf291f72224715942beaf8553e42ba8891ab3c6",
        "commit_message": "vm.c: create break object before clearing GC arena.\n\nOtherwise it possibly cause use-after-free.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "mrb_vm_exec(mrb_state *mrb, const struct RProc *proc, const mrb_code *pc)\n{\n  /* mrb_assert(MRB_PROC_CFUNC_P(proc)) */\n  const mrb_irep *irep = proc->body.irep;\n  const mrb_pool_value *pool = irep->pool;\n  const mrb_sym *syms = irep->syms;\n  mrb_code insn;\n  int ai = mrb_gc_arena_save(mrb);\n  struct mrb_jmpbuf *prev_jmp = mrb->jmp;\n  struct mrb_jmpbuf c_jmp;\n  uint32_t a;\n  uint16_t b;\n  uint16_t c;\n  mrb_sym mid;\n  const struct mrb_irep_catch_handler *ch;\n\n#ifdef DIRECT_THREADED\n  static const void * const optable[] = {\n#define OPCODE(x,_) &&L_OP_ ## x,\n#include \"mruby/ops.h\"\n#undef OPCODE\n  };\n#endif\n\n  mrb_bool exc_catched = FALSE;\nRETRY_TRY_BLOCK:\n\n  MRB_TRY(&c_jmp) {\n\n  if (exc_catched) {\n    exc_catched = FALSE;\n    mrb_gc_arena_restore(mrb, ai);\n    if (mrb->exc && mrb->exc->tt == MRB_TT_BREAK)\n      goto L_BREAK;\n    goto L_RAISE;\n  }\n  mrb->jmp = &c_jmp;\n  mrb_vm_ci_proc_set(mrb->c->ci, proc);\n\n#define regs (mrb->c->ci->stack)\n  INIT_DISPATCH {\n    CASE(OP_NOP, Z) {\n      /* do nothing */\n      NEXT;\n    }\n\n    CASE(OP_MOVE, BB) {\n      regs[a] = regs[b];\n      NEXT;\n    }\n\n    CASE(OP_LOADL, BB) {\n      switch (pool[b].tt) {   /* number */\n      case IREP_TT_INT32:\n        regs[a] = mrb_int_value(mrb, (mrb_int)pool[b].u.i32);\n        break;\n      case IREP_TT_INT64:\n#if defined(MRB_INT64)\n        regs[a] = mrb_int_value(mrb, (mrb_int)pool[b].u.i64);\n        break;\n#else\n#if defined(MRB_64BIT)\n        if (INT32_MIN <= pool[b].u.i64 && pool[b].u.i64 <= INT32_MAX) {\n          regs[a] = mrb_int_value(mrb, (mrb_int)pool[b].u.i64);\n          break;\n        }\n#endif\n        goto L_INT_OVERFLOW;\n#endif\n      case IREP_TT_BIGINT:\n        goto L_INT_OVERFLOW;\n#ifndef MRB_NO_FLOAT\n      case IREP_TT_FLOAT:\n        regs[a] = mrb_float_value(mrb, pool[b].u.f);\n        break;\n#endif\n      default:\n        /* should not happen (tt:string) */\n        regs[a] = mrb_nil_value();\n        break;\n      }\n      NEXT;\n    }\n\n    CASE(OP_LOADI, BB) {\n      SET_FIXNUM_VALUE(regs[a], b);\n      NEXT;\n    }\n\n    CASE(OP_LOADINEG, BB) {\n      SET_FIXNUM_VALUE(regs[a], -b);\n      NEXT;\n    }\n\n    CASE(OP_LOADI__1,B) goto L_LOADI;\n    CASE(OP_LOADI_0,B) goto L_LOADI;\n    CASE(OP_LOADI_1,B) goto L_LOADI;\n    CASE(OP_LOADI_2,B) goto L_LOADI;\n    CASE(OP_LOADI_3,B) goto L_LOADI;\n    CASE(OP_LOADI_4,B) goto L_LOADI;\n    CASE(OP_LOADI_5,B) goto L_LOADI;\n    CASE(OP_LOADI_6,B) goto L_LOADI;\n    CASE(OP_LOADI_7, B) {\n    L_LOADI:\n      SET_FIXNUM_VALUE(regs[a], (mrb_int)insn - (mrb_int)OP_LOADI_0);\n      NEXT;\n    }\n\n    CASE(OP_LOADI16, BS) {\n      SET_FIXNUM_VALUE(regs[a], (mrb_int)(int16_t)b);\n      NEXT;\n    }\n\n    CASE(OP_LOADI32, BSS) {\n      SET_INT_VALUE(mrb, regs[a], (int32_t)(((uint32_t)b<<16)+c));\n      NEXT;\n    }\n\n    CASE(OP_LOADSYM, BB) {\n      SET_SYM_VALUE(regs[a], syms[b]);\n      NEXT;\n    }\n\n    CASE(OP_LOADNIL, B) {\n      SET_NIL_VALUE(regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_LOADSELF, B) {\n      regs[a] = regs[0];\n      NEXT;\n    }\n\n    CASE(OP_LOADT, B) {\n      SET_TRUE_VALUE(regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_LOADF, B) {\n      SET_FALSE_VALUE(regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETGV, BB) {\n      mrb_value val = mrb_gv_get(mrb, syms[b]);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETGV, BB) {\n      mrb_gv_set(mrb, syms[b], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETSV, BB) {\n      mrb_value val = mrb_vm_special_get(mrb, syms[b]);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETSV, BB) {\n      mrb_vm_special_set(mrb, syms[b], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETIV, BB) {\n      regs[a] = mrb_iv_get(mrb, regs[0], syms[b]);\n      NEXT;\n    }\n\n    CASE(OP_SETIV, BB) {\n      mrb_iv_set(mrb, regs[0], syms[b], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETCV, BB) {\n      mrb_value val;\n      val = mrb_vm_cv_get(mrb, syms[b]);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETCV, BB) {\n      mrb_vm_cv_set(mrb, syms[b], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETIDX, B) {\n      mrb_value va = regs[a], vb = regs[a+1];\n      switch (mrb_type(va)) {\n      case MRB_TT_ARRAY:\n        if (!mrb_integer_p(vb)) goto getidx_fallback;\n        regs[a] = mrb_ary_entry(va, mrb_integer(vb));\n        break;\n      case MRB_TT_HASH:\n        va = mrb_hash_get(mrb, va, vb);\n        regs[a] = va;\n        break;\n      case MRB_TT_STRING:\n        switch (mrb_type(vb)) {\n        case MRB_TT_INTEGER:\n        case MRB_TT_STRING:\n        case MRB_TT_RANGE:\n          va = mrb_str_aref(mrb, va, vb, mrb_undef_value());\n          regs[a] = va;\n          break;\n        default:\n          goto getidx_fallback;\n        }\n        break;\n      default:\n      getidx_fallback:\n        mid = MRB_OPSYM(aref);\n        goto L_SEND_SYM;\n      }\n      NEXT;\n    }\n\n    CASE(OP_SETIDX, B) {\n      c = 2;\n      mid = MRB_OPSYM(aset);\n      SET_NIL_VALUE(regs[a+3]);\n      goto L_SENDB_SYM;\n    }\n\n    CASE(OP_GETCONST, BB) {\n      mrb_value v = mrb_vm_const_get(mrb, syms[b]);\n      regs[a] = v;\n      NEXT;\n    }\n\n    CASE(OP_SETCONST, BB) {\n      mrb_vm_const_set(mrb, syms[b], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETMCNST, BB) {\n      mrb_value v = mrb_const_get(mrb, regs[a], syms[b]);\n      regs[a] = v;\n      NEXT;\n    }\n\n    CASE(OP_SETMCNST, BB) {\n      mrb_const_set(mrb, regs[a+1], syms[b], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETUPVAR, BBB) {\n      mrb_value *regs_a = regs + a;\n      struct REnv *e = uvenv(mrb, c);\n\n      if (e && b < MRB_ENV_LEN(e)) {\n        *regs_a = e->stack[b];\n      }\n      else {\n        *regs_a = mrb_nil_value();\n      }\n      NEXT;\n    }\n\n    CASE(OP_SETUPVAR, BBB) {\n      struct REnv *e = uvenv(mrb, c);\n\n      if (e) {\n        mrb_value *regs_a = regs + a;\n\n        if (b < MRB_ENV_LEN(e)) {\n          e->stack[b] = *regs_a;\n          mrb_write_barrier(mrb, (struct RBasic*)e);\n        }\n      }\n      NEXT;\n    }\n\n    CASE(OP_JMP, S) {\n      pc += (int16_t)a;\n      JUMP;\n    }\n    CASE(OP_JMPIF, BS) {\n      if (mrb_test(regs[a])) {\n        pc += (int16_t)b;\n        JUMP;\n      }\n      NEXT;\n    }\n    CASE(OP_JMPNOT, BS) {\n      if (!mrb_test(regs[a])) {\n        pc += (int16_t)b;\n        JUMP;\n      }\n      NEXT;\n    }\n    CASE(OP_JMPNIL, BS) {\n      if (mrb_nil_p(regs[a])) {\n        pc += (int16_t)b;\n        JUMP;\n      }\n      NEXT;\n    }\n\n    CASE(OP_JMPUW, S) {\n      a = (uint32_t)((pc - irep->iseq) + (int16_t)a);\n      CHECKPOINT_RESTORE(RBREAK_TAG_JUMP) {\n        struct RBreak *brk = (struct RBreak*)mrb->exc;\n        mrb_value target = mrb_break_value_get(brk);\n        mrb_assert(mrb_integer_p(target));\n        a = (uint32_t)mrb_integer(target);\n        mrb_assert(a >= 0 && a < irep->ilen);\n      }\n      CHECKPOINT_MAIN(RBREAK_TAG_JUMP) {\n        ch = catch_handler_find(mrb, mrb->c->ci, pc, MRB_CATCH_FILTER_ENSURE);\n        if (ch) {\n          /* avoiding a jump from a catch handler into the same handler */\n          if (a < mrb_irep_catch_handler_unpack(ch->begin) || a >= mrb_irep_catch_handler_unpack(ch->end)) {\n            THROW_TAGGED_BREAK(mrb, RBREAK_TAG_JUMP, proc, mrb_fixnum_value(a));\n          }\n        }\n      }\n      CHECKPOINT_END(RBREAK_TAG_JUMP);\n\n      mrb->exc = NULL; /* clear break object */\n      pc = irep->iseq + a;\n      JUMP;\n    }\n\n    CASE(OP_EXCEPT, B) {\n      mrb_value exc;\n\n      if (mrb->exc == NULL) {\n        exc = mrb_nil_value();\n      }\n      else {\n        switch (mrb->exc->tt) {\n        case MRB_TT_BREAK:\n        case MRB_TT_EXCEPTION:\n          exc = mrb_obj_value(mrb->exc);\n          break;\n        default:\n          mrb_assert(!\"bad mrb_type\");\n          exc = mrb_nil_value();\n          break;\n        }\n        mrb->exc = NULL;\n      }\n      regs[a] = exc;\n      NEXT;\n    }\n    CASE(OP_RESCUE, BB) {\n      mrb_value exc = regs[a];  /* exc on stack */\n      mrb_value e = regs[b];\n      struct RClass *ec;\n\n      switch (mrb_type(e)) {\n      case MRB_TT_CLASS:\n      case MRB_TT_MODULE:\n        break;\n      default:\n        {\n          mrb_value exc;\n\n          exc = mrb_exc_new_lit(mrb, E_TYPE_ERROR,\n                                    \"class or module required for rescue clause\");\n          mrb_exc_set(mrb, exc);\n          goto L_RAISE;\n        }\n      }\n      ec = mrb_class_ptr(e);\n      regs[b] = mrb_bool_value(mrb_obj_is_kind_of(mrb, exc, ec));\n      NEXT;\n    }\n\n    CASE(OP_RAISEIF, B) {\n      mrb_value exc = regs[a];\n      if (mrb_break_p(exc)) {\n        mrb->exc = mrb_obj_ptr(exc);\n        goto L_BREAK;\n      }\n      mrb_exc_set(mrb, exc);\n      if (mrb->exc) {\n        goto L_RAISE;\n      }\n      NEXT;\n    }\n\n    CASE(OP_SSEND, BBB) {\n      regs[a] = regs[0];\n      insn = OP_SEND;\n    }\n    goto L_SENDB;\n\n    CASE(OP_SSENDB, BBB) {\n      regs[a] = regs[0];\n    }\n    goto L_SENDB;\n\n    CASE(OP_SEND, BBB)\n    goto L_SENDB;\n\n    L_SEND_SYM:\n    c = 1;\n    /* push nil after arguments */\n    SET_NIL_VALUE(regs[a+2]);\n    goto L_SENDB_SYM;\n\n    CASE(OP_SENDB, BBB)\n    L_SENDB:\n    mid = syms[b];\n    L_SENDB_SYM:\n    {\n      mrb_callinfo *ci = mrb->c->ci;\n      mrb_method_t m;\n      struct RClass *cls;\n      mrb_value recv, blk;\n\n      ARGUMENT_NORMALIZE(a, &c, insn);\n\n      recv = regs[a];\n      cls = mrb_class(mrb, recv);\n      m = mrb_method_search_vm(mrb, &cls, mid);\n      if (MRB_METHOD_UNDEF_P(m)) {\n        m = prepare_missing(mrb, recv, mid, &cls, a, &c, blk, 0);\n        mid = MRB_SYM(method_missing);\n      }\n\n      /* push callinfo */\n      ci = cipush(mrb, a, 0, cls, NULL, mid, c);\n\n      if (MRB_METHOD_CFUNC_P(m)) {\n        if (MRB_METHOD_PROC_P(m)) {\n          struct RProc *p = MRB_METHOD_PROC(m);\n\n          mrb_vm_ci_proc_set(ci, p);\n          recv = p->body.func(mrb, recv);\n        }\n        else {\n          if (MRB_METHOD_NOARG_P(m)) {\n            check_method_noarg(mrb, ci);\n          }\n          recv = MRB_METHOD_FUNC(m)(mrb, recv);\n        }\n        mrb_gc_arena_shrink(mrb, ai);\n        if (mrb->exc) goto L_RAISE;\n        ci = mrb->c->ci;\n        if (mrb_proc_p(blk)) {\n          struct RProc *p = mrb_proc_ptr(blk);\n          if (p && !MRB_PROC_STRICT_P(p) && MRB_PROC_ENV(p) == mrb_vm_ci_env(&ci[-1])) {\n            p->flags |= MRB_PROC_ORPHAN;\n          }\n        }\n        if (!ci->u.target_class) { /* return from context modifying method (resume/yield) */\n          if (ci->cci == CINFO_RESUMED) {\n            mrb->jmp = prev_jmp;\n            return recv;\n          }\n          else {\n            mrb_assert(!MRB_PROC_CFUNC_P(ci[-1].proc));\n            proc = ci[-1].proc;\n            irep = proc->body.irep;\n            pool = irep->pool;\n            syms = irep->syms;\n          }\n        }\n        ci->stack[0] = recv;\n        /* pop stackpos */\n        ci = cipop(mrb);\n        pc = ci->pc;\n      }\n      else {\n        /* setup environment for calling method */\n        mrb_vm_ci_proc_set(ci, (proc = MRB_METHOD_PROC(m)));\n        irep = proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n        mrb_stack_extend(mrb, (irep->nregs < 4) ? 4 : irep->nregs);\n        pc = irep->iseq;\n      }\n    }\n    JUMP;\n\n    CASE(OP_CALL, Z) {\n      mrb_callinfo *ci = mrb->c->ci;\n      mrb_value recv = ci->stack[0];\n      struct RProc *m = mrb_proc_ptr(recv);\n\n      /* replace callinfo */\n      ci->u.target_class = MRB_PROC_TARGET_CLASS(m);\n      mrb_vm_ci_proc_set(ci, m);\n      if (MRB_PROC_ENV_P(m)) {\n        ci->mid = MRB_PROC_ENV(m)->mid;\n      }\n\n      /* prepare stack */\n      if (MRB_PROC_CFUNC_P(m)) {\n        recv = MRB_PROC_CFUNC(m)(mrb, recv);\n        mrb_gc_arena_shrink(mrb, ai);\n        if (mrb->exc) goto L_RAISE;\n        /* pop stackpos */\n        ci = cipop(mrb);\n        pc = ci->pc;\n        ci[1].stack[0] = recv;\n        irep = mrb->c->ci->proc->body.irep;\n      }\n      else {\n        /* setup environment for calling method */\n        proc = m;\n        irep = m->body.irep;\n        if (!irep) {\n          mrb->c->ci->stack[0] = mrb_nil_value();\n          a = 0;\n          c = OP_R_NORMAL;\n          goto L_OP_RETURN_BODY;\n        }\n        mrb_int nargs = mrb_ci_bidx(ci)+1;\n        if (nargs < irep->nregs) {\n          mrb_stack_extend(mrb, irep->nregs);\n          stack_clear(regs+nargs, irep->nregs-nargs);\n        }\n        if (MRB_PROC_ENV_P(m)) {\n          regs[0] = MRB_PROC_ENV(m)->stack[0];\n        }\n        pc = irep->iseq;\n      }\n      pool = irep->pool;\n      syms = irep->syms;\n      JUMP;\n    }\n\n    CASE(OP_SUPER, BB) {\n      mrb_method_t m;\n      struct RClass *cls;\n      mrb_callinfo *ci = mrb->c->ci;\n      mrb_value recv, blk;\n      const struct RProc *p = ci->proc;\n      mrb_sym mid = ci->mid;\n      struct RClass* target_class = MRB_PROC_TARGET_CLASS(p);\n\n      if (MRB_PROC_ENV_P(p) && p->e.env->mid && p->e.env->mid != mid) { /* alias support */\n        mid = p->e.env->mid;    /* restore old mid */\n      }\n\n      if (mid == 0 || !target_class) {\n        mrb_value exc = mrb_exc_new_lit(mrb, E_NOMETHOD_ERROR, \"super called outside of method\");\n        mrb_exc_set(mrb, exc);\n        goto L_RAISE;\n      }\n      if (target_class->flags & MRB_FL_CLASS_IS_PREPENDED) {\n        target_class = mrb_vm_ci_target_class(ci);\n      }\n      else if (target_class->tt == MRB_TT_MODULE) {\n        target_class = mrb_vm_ci_target_class(ci);\n        if (!target_class || target_class->tt != MRB_TT_ICLASS) {\n          goto super_typeerror;\n        }\n      }\n      recv = regs[0];\n      if (!mrb_obj_is_kind_of(mrb, recv, target_class)) {\n      super_typeerror: ;\n        mrb_value exc = mrb_exc_new_lit(mrb, E_TYPE_ERROR,\n                                            \"self has wrong type to call super in this context\");\n        mrb_exc_set(mrb, exc);\n        goto L_RAISE;\n      }\n\n      ARGUMENT_NORMALIZE(a, &b, OP_SUPER);\n\n      cls = target_class->super;\n      m = mrb_method_search_vm(mrb, &cls, mid);\n      if (MRB_METHOD_UNDEF_P(m)) {\n        m = prepare_missing(mrb, recv, mid, &cls, a, &b, blk, 1);\n        mid = MRB_SYM(method_missing);\n      }\n\n      /* push callinfo */\n      ci = cipush(mrb, a, 0, cls, NULL, mid, b);\n\n      /* prepare stack */\n      ci->stack[0] = recv;\n\n      if (MRB_METHOD_CFUNC_P(m)) {\n        mrb_value v;\n\n        if (MRB_METHOD_PROC_P(m)) {\n          mrb_vm_ci_proc_set(ci, MRB_METHOD_PROC(m));\n        }\n        v = MRB_METHOD_CFUNC(m)(mrb, recv);\n        mrb_gc_arena_restore(mrb, ai);\n        if (mrb->exc) goto L_RAISE;\n        ci = mrb->c->ci;\n        mrb_assert(!mrb_break_p(v));\n        if (!mrb_vm_ci_target_class(ci)) { /* return from context modifying method (resume/yield) */\n          if (ci->cci == CINFO_RESUMED) {\n            mrb->jmp = prev_jmp;\n            return v;\n          }\n          else {\n            mrb_assert(!MRB_PROC_CFUNC_P(ci[-1].proc));\n            proc = ci[-1].proc;\n            irep = proc->body.irep;\n            pool = irep->pool;\n            syms = irep->syms;\n          }\n        }\n        mrb->c->ci->stack[0] = v;\n        ci = cipop(mrb);\n        pc = ci->pc;\n      }\n      else {\n        /* setup environment for calling method */\n        mrb_vm_ci_proc_set(ci, (proc = MRB_METHOD_PROC(m)));\n        irep = proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n        mrb_stack_extend(mrb, (irep->nregs < 4) ? 4 : irep->nregs);\n        pc = irep->iseq;\n      }\n      JUMP;\n    }\n\n    CASE(OP_ARGARY, BS) {\n      mrb_int m1 = (b>>11)&0x3f;\n      mrb_int r  = (b>>10)&0x1;\n      mrb_int m2 = (b>>5)&0x1f;\n      mrb_int kd = (b>>4)&0x1;\n      mrb_int lv = (b>>0)&0xf;\n      mrb_value *stack;\n\n      if (mrb->c->ci->mid == 0 || mrb_vm_ci_target_class(mrb->c->ci) == NULL) {\n        mrb_value exc;\n\n      L_NOSUPER:\n        exc = mrb_exc_new_lit(mrb, E_NOMETHOD_ERROR, \"super called outside of method\");\n        mrb_exc_set(mrb, exc);\n        goto L_RAISE;\n      }\n      if (lv == 0) stack = regs + 1;\n      else {\n        struct REnv *e = uvenv(mrb, lv-1);\n        if (!e) goto L_NOSUPER;\n        if (MRB_ENV_LEN(e) <= m1+r+m2+1)\n          goto L_NOSUPER;\n        stack = e->stack + 1;\n      }\n      if (r == 0) {\n        regs[a] = mrb_ary_new_from_values(mrb, m1+m2, stack);\n      }\n      else {\n        mrb_value *pp = NULL;\n        struct RArray *rest;\n        mrb_int len = 0;\n\n        if (mrb_array_p(stack[m1])) {\n          struct RArray *ary = mrb_ary_ptr(stack[m1]);\n\n          pp = ARY_PTR(ary);\n          len = ARY_LEN(ary);\n        }\n        regs[a] = mrb_ary_new_capa(mrb, m1+len+m2);\n        rest = mrb_ary_ptr(regs[a]);\n        if (m1 > 0) {\n          stack_copy(ARY_PTR(rest), stack, m1);\n        }\n        if (len > 0) {\n          stack_copy(ARY_PTR(rest)+m1, pp, len);\n        }\n        if (m2 > 0) {\n          stack_copy(ARY_PTR(rest)+m1+len, stack+m1+1, m2);\n        }\n        ARY_SET_LEN(rest, m1+len+m2);\n      }\n      if (kd) {\n        regs[a+1] = stack[m1+r+m2];\n        regs[a+2] = stack[m1+r+m2+1];\n      }\n      else {\n        regs[a+1] = stack[m1+r+m2];\n      }\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_ENTER, W) {\n      mrb_int m1 = MRB_ASPEC_REQ(a);\n      mrb_int o  = MRB_ASPEC_OPT(a);\n      mrb_int r  = MRB_ASPEC_REST(a);\n      mrb_int m2 = MRB_ASPEC_POST(a);\n      mrb_int kd = (MRB_ASPEC_KEY(a) > 0 || MRB_ASPEC_KDICT(a))? 1 : 0;\n      /* unused\n      int b  = MRB_ASPEC_BLOCK(a);\n      */\n      mrb_int const len = m1 + o + r + m2;\n\n      mrb_callinfo *ci = mrb->c->ci;\n      mrb_int argc = ci->n;\n      mrb_value *argv = regs+1;\n      mrb_value * const argv0 = argv;\n      mrb_int const kw_pos = len + kd;    /* where kwhash should be */\n      mrb_int const blk_pos = kw_pos + 1; /* where block should be */\n      mrb_value blk = regs[mrb_ci_bidx(ci)];\n      mrb_value kdict = mrb_nil_value();\n\n      /* keyword arguments */\n      if (ci->nk > 0) {\n        mrb_int kidx = mrb_ci_kidx(ci);\n        kdict = regs[kidx];\n        if (!mrb_hash_p(kdict) || mrb_hash_size(mrb, kdict) == 0) {\n          kdict = mrb_nil_value();\n          ci->nk = 0;\n        }\n      }\n      if (!kd && !mrb_nil_p(kdict)) {\n        if (argc < 14) {\n          ci->n++;\n          argc++;    /* include kdict in normal arguments */\n        }\n        else if (argc == 14) {\n          /* pack arguments and kdict */\n          regs[1] = mrb_ary_new_from_values(mrb, argc+1, &regs[1]);\n          argc = ci->n = 15;\n        }\n        else {/* argc == 15 */\n          /* push kdict to packed arguments */\n          mrb_ary_push(mrb, regs[1], regs[2]);\n        }\n        ci->nk = 0;\n      }\n      if (kd && MRB_ASPEC_KEY(a) > 0 && mrb_hash_p(kdict)) {\n        kdict = mrb_hash_dup(mrb, kdict);\n      }\n\n      /* arguments is passed with Array */\n      if (argc == 15) {\n        struct RArray *ary = mrb_ary_ptr(regs[1]);\n        argv = ARY_PTR(ary);\n        argc = (int)ARY_LEN(ary);\n        mrb_gc_protect(mrb, regs[1]);\n      }\n\n      /* strict argument check */\n      if (ci->proc && MRB_PROC_STRICT_P(ci->proc)) {\n        if (argc < m1 + m2 || (r == 0 && argc > len)) {\n          argnum_error(mrb, m1+m2);\n          goto L_RAISE;\n        }\n      }\n      /* extract first argument array to arguments */\n      else if (len > 1 && argc == 1 && mrb_array_p(argv[0])) {\n        mrb_gc_protect(mrb, argv[0]);\n        argc = (int)RARRAY_LEN(argv[0]);\n        argv = RARRAY_PTR(argv[0]);\n      }\n\n      /* rest arguments */\n      mrb_value rest = mrb_nil_value();\n      if (argc < len) {\n        mrb_int mlen = m2;\n        if (argc < m1+m2) {\n          mlen = m1 < argc ? argc - m1 : 0;\n        }\n\n        /* copy mandatory and optional arguments */\n        if (argv0 != argv && argv) {\n          value_move(&regs[1], argv, argc-mlen); /* m1 + o */\n        }\n        if (argc < m1) {\n          stack_clear(&regs[argc+1], m1-argc);\n        }\n        /* copy post mandatory arguments */\n        if (mlen) {\n          value_move(&regs[len-m2+1], &argv[argc-mlen], mlen);\n        }\n        if (mlen < m2) {\n          stack_clear(&regs[len-m2+mlen+1], m2-mlen);\n        }\n        /* initialize rest arguments with empty Array */\n        if (r) {\n          rest = mrb_ary_new_capa(mrb, 0);\n          regs[m1+o+1] = rest;\n        }\n        /* skip initializer of passed arguments */\n        if (o > 0 && argc > m1+m2)\n          pc += (argc - m1 - m2)*3;\n      }\n      else {\n        mrb_int rnum = 0;\n        if (argv0 != argv) {\n          value_move(&regs[1], argv, m1+o);\n        }\n        if (r) {\n          rnum = argc-m1-o-m2;\n          rest = mrb_ary_new_from_values(mrb, rnum, argv+m1+o);\n          regs[m1+o+1] = rest;\n        }\n        if (m2 > 0 && argc-m2 > m1) {\n          value_move(&regs[m1+o+r+1], &argv[m1+o+rnum], m2);\n        }\n        pc += o*3;\n      }\n\n      /* need to be update blk first to protect blk from GC */\n      regs[blk_pos] = blk;              /* move block */\n      if (kd) {\n        if (mrb_nil_p(kdict))\n          kdict = mrb_hash_new_capa(mrb, 0);\n        regs[kw_pos] = kdict;           /* set kwhash */\n      }\n\n      /* format arguments for generated code */\n      mrb->c->ci->n = len;\n\n      /* clear local (but non-argument) variables */\n      if (irep->nlocals-blk_pos-1 > 0) {\n        stack_clear(&regs[blk_pos+1], irep->nlocals-blk_pos-1);\n      }\n      JUMP;\n    }\n\n    CASE(OP_KARG, BB) {\n      mrb_value k = mrb_symbol_value(syms[b]);\n      mrb_int kidx = mrb_ci_kidx(mrb->c->ci);\n      mrb_value kdict, v;\n\n      if (kidx < 0 || !mrb_hash_p(kdict=regs[kidx]) || !mrb_hash_key_p(mrb, kdict, k)) {\n        mrb_value str = mrb_format(mrb, \"missing keyword: %v\", k);\n        mrb_exc_set(mrb, mrb_exc_new_str(mrb, E_ARGUMENT_ERROR, str));\n        goto L_RAISE;\n      }\n      v = mrb_hash_get(mrb, kdict, k);\n      regs[a] = v;\n      mrb_hash_delete_key(mrb, kdict, k);\n      NEXT;\n    }\n\n    CASE(OP_KEY_P, BB) {\n      mrb_value k = mrb_symbol_value(syms[b]);\n      mrb_int kidx = mrb_ci_kidx(mrb->c->ci);\n      mrb_value kdict;\n      mrb_bool key_p = FALSE;\n\n      if (kidx >= 0 && mrb_hash_p(kdict=regs[kidx])) {\n        key_p = mrb_hash_key_p(mrb, kdict, k);\n      }\n      regs[a] = mrb_bool_value(key_p);\n      NEXT;\n    }\n\n    CASE(OP_KEYEND, Z) {\n      mrb_int kidx = mrb_ci_kidx(mrb->c->ci);\n      mrb_value kdict;\n\n      if (kidx >= 0 && mrb_hash_p(kdict=regs[kidx]) && !mrb_hash_empty_p(mrb, kdict)) {\n        mrb_value keys = mrb_hash_keys(mrb, kdict);\n        mrb_value key1 = RARRAY_PTR(keys)[0];\n        mrb_value str = mrb_format(mrb, \"unknown keyword: %v\", key1);\n        mrb_exc_set(mrb, mrb_exc_new_str(mrb, E_ARGUMENT_ERROR, str));\n        goto L_RAISE;\n      }\n      NEXT;\n    }\n\n    CASE(OP_BREAK, B) {\n      c = OP_R_BREAK;\n      goto L_RETURN;\n    }\n    CASE(OP_RETURN_BLK, B) {\n      c = OP_R_RETURN;\n      goto L_RETURN;\n    }\n    CASE(OP_RETURN, B)\n    c = OP_R_NORMAL;\n    L_RETURN:\n    {\n      mrb_callinfo *ci;\n\n      ci = mrb->c->ci;\n      if (ci->mid) {\n        mrb_value blk = regs[mrb_ci_bidx(ci)];\n\n        if (mrb_proc_p(blk)) {\n          struct RProc *p = mrb_proc_ptr(blk);\n\n          if (!MRB_PROC_STRICT_P(p) &&\n              ci > mrb->c->cibase && MRB_PROC_ENV(p) == mrb_vm_ci_env(&ci[-1])) {\n            p->flags |= MRB_PROC_ORPHAN;\n          }\n        }\n      }\n\n      if (mrb->exc) {\n      L_RAISE:\n        ci = mrb->c->ci;\n        if (ci == mrb->c->cibase) {\n          ch = catch_handler_find(mrb, ci, pc, MRB_CATCH_FILTER_ALL);\n          if (ch == NULL) goto L_FTOP;\n          goto L_CATCH;\n        }\n        while ((ch = catch_handler_find(mrb, ci, pc, MRB_CATCH_FILTER_ALL)) == NULL) {\n          ci = cipop(mrb);\n          if (ci[1].cci == CINFO_SKIP && prev_jmp) {\n            mrb->jmp = prev_jmp;\n            MRB_THROW(prev_jmp);\n          }\n          pc = ci[0].pc;\n          if (ci == mrb->c->cibase) {\n            ch = catch_handler_find(mrb, ci, pc, MRB_CATCH_FILTER_ALL);\n            if (ch == NULL) {\n            L_FTOP:             /* fiber top */\n              if (mrb->c == mrb->root_c) {\n                mrb->c->ci->stack = mrb->c->stbase;\n                goto L_STOP;\n              }\n              else {\n                struct mrb_context *c = mrb->c;\n\n                c->status = MRB_FIBER_TERMINATED;\n                mrb->c = c->prev;\n                c->prev = NULL;\n                goto L_RAISE;\n              }\n            }\n            break;\n          }\n        }\n      L_CATCH:\n        if (ch == NULL) goto L_STOP;\n        if (FALSE) {\n        L_CATCH_TAGGED_BREAK: /* from THROW_TAGGED_BREAK() or UNWIND_ENSURE() */\n          ci = mrb->c->ci;\n        }\n        proc = ci->proc;\n        irep = proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n        mrb_stack_extend(mrb, irep->nregs);\n        pc = irep->iseq + mrb_irep_catch_handler_unpack(ch->target);\n      }\n      else {\n        mrb_int acc;\n        mrb_value v;\n\n        ci = mrb->c->ci;\n        v = regs[a];\n        mrb_gc_protect(mrb, v);\n        switch (c) {\n        case OP_R_RETURN:\n          /* Fall through to OP_R_NORMAL otherwise */\n          if (ci->cci == CINFO_NONE && MRB_PROC_ENV_P(proc) && !MRB_PROC_STRICT_P(proc)) {\n            const struct RProc *dst;\n            mrb_callinfo *cibase;\n            cibase = mrb->c->cibase;\n            dst = top_proc(mrb, proc);\n\n            if (MRB_PROC_ENV_P(dst)) {\n              struct REnv *e = MRB_PROC_ENV(dst);\n\n              if (!MRB_ENV_ONSTACK_P(e) || (e->cxt && e->cxt != mrb->c)) {\n                localjump_error(mrb, LOCALJUMP_ERROR_RETURN);\n                goto L_RAISE;\n              }\n            }\n            /* check jump destination */\n            while (cibase <= ci && ci->proc != dst) {\n              if (ci->cci > CINFO_NONE) { /* jump cross C boundary */\n                localjump_error(mrb, LOCALJUMP_ERROR_RETURN);\n                goto L_RAISE;\n              }\n              ci--;\n            }\n            if (ci <= cibase) { /* no jump destination */\n              localjump_error(mrb, LOCALJUMP_ERROR_RETURN);\n              goto L_RAISE;\n            }\n            ci = mrb->c->ci;\n            while (cibase <= ci && ci->proc != dst) {\n              CHECKPOINT_RESTORE(RBREAK_TAG_RETURN_BLOCK) {\n                cibase = mrb->c->cibase;\n                dst = top_proc(mrb, proc);\n              }\n              CHECKPOINT_MAIN(RBREAK_TAG_RETURN_BLOCK) {\n                UNWIND_ENSURE(mrb, ci, pc, RBREAK_TAG_RETURN_BLOCK, proc, v);\n              }\n              CHECKPOINT_END(RBREAK_TAG_RETURN_BLOCK);\n              ci = cipop(mrb);\n              pc = ci->pc;\n            }\n            proc = ci->proc;\n            mrb->exc = NULL; /* clear break object */\n            break;\n          }\n          /* fallthrough */\n        case OP_R_NORMAL:\n        NORMAL_RETURN:\n          if (ci == mrb->c->cibase) {\n            struct mrb_context *c;\n            c = mrb->c;\n\n            if (!c->prev) { /* toplevel return */\n              regs[irep->nlocals] = v;\n              goto CHECKPOINT_LABEL_MAKE(RBREAK_TAG_STOP);\n            }\n            if (!c->vmexec && c->prev->ci == c->prev->cibase) {\n              mrb_value exc = mrb_exc_new_lit(mrb, E_FIBER_ERROR, \"double resume\");\n              mrb_exc_set(mrb, exc);\n              goto L_RAISE;\n            }\n            CHECKPOINT_RESTORE(RBREAK_TAG_RETURN_TOPLEVEL) {\n              c = mrb->c;\n            }\n            CHECKPOINT_MAIN(RBREAK_TAG_RETURN_TOPLEVEL) {\n              UNWIND_ENSURE(mrb, ci, pc, RBREAK_TAG_RETURN_TOPLEVEL, proc, v);\n            }\n            CHECKPOINT_END(RBREAK_TAG_RETURN_TOPLEVEL);\n            /* automatic yield at the end */\n            c->status = MRB_FIBER_TERMINATED;\n            mrb->c = c->prev;\n            mrb->c->status = MRB_FIBER_RUNNING;\n            c->prev = NULL;\n            if (c->vmexec) {\n              mrb_gc_arena_restore(mrb, ai);\n              c->vmexec = FALSE;\n              mrb->jmp = prev_jmp;\n              return v;\n            }\n            ci = mrb->c->ci;\n          }\n          CHECKPOINT_RESTORE(RBREAK_TAG_RETURN) {\n            /* do nothing */\n          }\n          CHECKPOINT_MAIN(RBREAK_TAG_RETURN) {\n            UNWIND_ENSURE(mrb, ci, pc, RBREAK_TAG_RETURN, proc, v);\n          }\n          CHECKPOINT_END(RBREAK_TAG_RETURN);\n          mrb->exc = NULL; /* clear break object */\n          break;\n        case OP_R_BREAK:\n          if (MRB_PROC_STRICT_P(proc)) goto NORMAL_RETURN;\n          if (MRB_PROC_ORPHAN_P(proc)) {\n            mrb_value exc;\n\n          L_BREAK_ERROR:\n            exc = mrb_exc_new_lit(mrb, E_LOCALJUMP_ERROR,\n                                      \"break from proc-closure\");\n            mrb_exc_set(mrb, exc);\n            goto L_RAISE;\n          }\n          if (!MRB_PROC_ENV_P(proc) || !MRB_ENV_ONSTACK_P(MRB_PROC_ENV(proc))) {\n            goto L_BREAK_ERROR;\n          }\n          else {\n            struct REnv *e = MRB_PROC_ENV(proc);\n\n            if (e->cxt != mrb->c) {\n              goto L_BREAK_ERROR;\n            }\n          }\n          CHECKPOINT_RESTORE(RBREAK_TAG_BREAK) {\n            /* do nothing */\n          }\n          CHECKPOINT_MAIN(RBREAK_TAG_BREAK) {\n            UNWIND_ENSURE(mrb, ci, pc, RBREAK_TAG_BREAK, proc, v);\n          }\n          CHECKPOINT_END(RBREAK_TAG_BREAK);\n          /* break from fiber block */\n          if (ci == mrb->c->cibase && ci->pc) {\n            struct mrb_context *c = mrb->c;\n\n            mrb->c = c->prev;\n            c->prev = NULL;\n            ci = mrb->c->ci;\n          }\n          if (ci->cci > CINFO_NONE) {\n            ci = cipop(mrb);\n            mrb_gc_arena_restore(mrb, ai);\n            mrb->c->vmexec = FALSE;\n            mrb->exc = (struct RObject*)break_new(mrb, RBREAK_TAG_BREAK, proc, v);\n            mrb->jmp = prev_jmp;\n            MRB_THROW(prev_jmp);\n          }\n          if (FALSE) {\n            struct RBreak *brk;\n\n          L_BREAK:\n            brk = (struct RBreak*)mrb->exc;\n            proc = mrb_break_proc_get(brk);\n            v = mrb_break_value_get(brk);\n            ci = mrb->c->ci;\n\n            switch (mrb_break_tag_get(brk)) {\n#define DISPATCH_CHECKPOINTS(n, i) case n: goto CHECKPOINT_LABEL_MAKE(n);\n              RBREAK_TAG_FOREACH(DISPATCH_CHECKPOINTS)\n#undef DISPATCH_CHECKPOINTS\n              default:\n                mrb_assert(!\"wrong break tag\");\n            }\n          }\n          while (mrb->c->cibase < ci && ci[-1].proc != proc->upper) {\n            if (ci[-1].cci == CINFO_SKIP) {\n              goto L_BREAK_ERROR;\n            }\n            CHECKPOINT_RESTORE(RBREAK_TAG_BREAK_UPPER) {\n              /* do nothing */\n            }\n            CHECKPOINT_MAIN(RBREAK_TAG_BREAK_UPPER) {\n              UNWIND_ENSURE(mrb, ci, pc, RBREAK_TAG_BREAK_UPPER, proc, v);\n            }\n            CHECKPOINT_END(RBREAK_TAG_BREAK_UPPER);\n            ci = cipop(mrb);\n            pc = ci->pc;\n          }\n          CHECKPOINT_RESTORE(RBREAK_TAG_BREAK_INTARGET) {\n            /* do nothing */\n          }\n          CHECKPOINT_MAIN(RBREAK_TAG_BREAK_INTARGET) {\n            UNWIND_ENSURE(mrb, ci, pc, RBREAK_TAG_BREAK_INTARGET, proc, v);\n          }\n          CHECKPOINT_END(RBREAK_TAG_BREAK_INTARGET);\n          if (ci == mrb->c->cibase) {\n            goto L_BREAK_ERROR;\n          }\n          mrb->exc = NULL; /* clear break object */\n          break;\n        default:\n          /* cannot happen */\n          break;\n        }\n        mrb_assert(ci == mrb->c->ci);\n        mrb_assert(mrb->exc == NULL);\n\n        if (mrb->c->vmexec && !mrb_vm_ci_target_class(ci)) {\n          mrb_gc_arena_restore(mrb, ai);\n          mrb->c->vmexec = FALSE;\n          mrb->jmp = prev_jmp;\n          return v;\n        }\n        acc = ci->cci;\n        ci = cipop(mrb);\n        if (acc == CINFO_SKIP || acc == CINFO_DIRECT) {\n          mrb_gc_arena_restore(mrb, ai);\n          mrb->jmp = prev_jmp;\n          return v;\n        }\n        pc = ci->pc;\n        DEBUG(fprintf(stderr, \"from :%s\\n\", mrb_sym_name(mrb, ci->mid)));\n        proc = ci->proc;\n        irep = proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n\n        ci[1].stack[0] = v;\n        mrb_gc_arena_restore(mrb, ai);\n      }\n      JUMP;\n    }\n\n    CASE(OP_BLKPUSH, BS) {\n      int m1 = (b>>11)&0x3f;\n      int r  = (b>>10)&0x1;\n      int m2 = (b>>5)&0x1f;\n      int kd = (b>>4)&0x1;\n      int lv = (b>>0)&0xf;\n      mrb_value *stack;\n\n      if (lv == 0) stack = regs + 1;\n      else {\n        struct REnv *e = uvenv(mrb, lv-1);\n        if (!e || (!MRB_ENV_ONSTACK_P(e) && e->mid == 0) ||\n            MRB_ENV_LEN(e) <= m1+r+m2+1) {\n          localjump_error(mrb, LOCALJUMP_ERROR_YIELD);\n          goto L_RAISE;\n        }\n        stack = e->stack + 1;\n      }\n      if (mrb_nil_p(stack[m1+r+m2+kd])) {\n        localjump_error(mrb, LOCALJUMP_ERROR_YIELD);\n        goto L_RAISE;\n      }\n      regs[a] = stack[m1+r+m2+kd];\n      NEXT;\n    }\n\n  L_INT_OVERFLOW:\n    {\n      mrb_value exc = mrb_exc_new_lit(mrb, E_RANGE_ERROR, \"integer overflow\");\n      mrb_exc_set(mrb, exc);\n    }\n    goto L_RAISE;\n\n#define TYPES2(a,b) ((((uint16_t)(a))<<8)|(((uint16_t)(b))&0xff))\n#define OP_MATH(op_name)                                                    \\\n  /* need to check if op is overridden */                                   \\\n  switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {                  \\\n    OP_MATH_CASE_INTEGER(op_name);                                          \\\n    OP_MATH_CASE_FLOAT(op_name, integer, float);                            \\\n    OP_MATH_CASE_FLOAT(op_name, float,  integer);                           \\\n    OP_MATH_CASE_FLOAT(op_name, float,  float);                             \\\n    OP_MATH_CASE_STRING_##op_name();                                        \\\n    default:                                                                \\\n      mid = MRB_OPSYM(op_name);                                             \\\n      goto L_SEND_SYM;                                                      \\\n  }                                                                         \\\n  NEXT;\n#define OP_MATH_CASE_INTEGER(op_name)                                       \\\n  case TYPES2(MRB_TT_INTEGER, MRB_TT_INTEGER):                              \\\n    {                                                                       \\\n      mrb_int x = mrb_integer(regs[a]), y = mrb_integer(regs[a+1]), z;      \\\n      if (mrb_int_##op_name##_overflow(x, y, &z))                           \\\n        OP_MATH_OVERFLOW_INT();                                             \\\n      else                                                                  \\\n        SET_INT_VALUE(mrb,regs[a], z);                                      \\\n    }                                                                       \\\n    break\n#ifdef MRB_NO_FLOAT\n#define OP_MATH_CASE_FLOAT(op_name, t1, t2) (void)0\n#else\n#define OP_MATH_CASE_FLOAT(op_name, t1, t2)                                     \\\n  case TYPES2(OP_MATH_TT_##t1, OP_MATH_TT_##t2):                                \\\n    {                                                                           \\\n      mrb_float z = mrb_##t1(regs[a]) OP_MATH_OP_##op_name mrb_##t2(regs[a+1]); \\\n      SET_FLOAT_VALUE(mrb, regs[a], z);                                         \\\n    }                                                                           \\\n    break\n#endif\n#define OP_MATH_OVERFLOW_INT() goto L_INT_OVERFLOW\n#define OP_MATH_CASE_STRING_add()                                           \\\n  case TYPES2(MRB_TT_STRING, MRB_TT_STRING):                                \\\n    regs[a] = mrb_str_plus(mrb, regs[a], regs[a+1]);                        \\\n    mrb_gc_arena_restore(mrb, ai);                                          \\\n    break\n#define OP_MATH_CASE_STRING_sub() (void)0\n#define OP_MATH_CASE_STRING_mul() (void)0\n#define OP_MATH_OP_add +\n#define OP_MATH_OP_sub -\n#define OP_MATH_OP_mul *\n#define OP_MATH_TT_integer MRB_TT_INTEGER\n#define OP_MATH_TT_float   MRB_TT_FLOAT\n\n    CASE(OP_ADD, B) {\n      OP_MATH(add);\n    }\n\n    CASE(OP_SUB, B) {\n      OP_MATH(sub);\n    }\n\n    CASE(OP_MUL, B) {\n      OP_MATH(mul);\n    }\n\n    CASE(OP_DIV, B) {\n#ifndef MRB_NO_FLOAT\n      mrb_float x, y, f;\n#endif\n\n      /* need to check if op is overridden */\n      switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\n      case TYPES2(MRB_TT_INTEGER,MRB_TT_INTEGER):\n        {\n          mrb_int x = mrb_integer(regs[a]);\n          mrb_int y = mrb_integer(regs[a+1]);\n          mrb_int div = mrb_div_int(mrb, x, y);\n          SET_INT_VALUE(mrb, regs[a], div);\n        }\n        NEXT;\n#ifndef MRB_NO_FLOAT\n      case TYPES2(MRB_TT_INTEGER,MRB_TT_FLOAT):\n        x = (mrb_float)mrb_integer(regs[a]);\n        y = mrb_float(regs[a+1]);\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_INTEGER):\n        x = mrb_float(regs[a]);\n        y = (mrb_float)mrb_integer(regs[a+1]);\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_FLOAT):\n        x = mrb_float(regs[a]);\n        y = mrb_float(regs[a+1]);\n        break;\n#endif\n      default:\n        mid = MRB_OPSYM(div);\n        goto L_SEND_SYM;\n      }\n\n#ifndef MRB_NO_FLOAT\n      f = mrb_div_float(x, y);\n      SET_FLOAT_VALUE(mrb, regs[a], f);\n#endif\n      NEXT;\n    }\n\n#define OP_MATHI(op_name)                                                   \\\n  /* need to check if op is overridden */                                   \\\n  switch (mrb_type(regs[a])) {                                              \\\n    OP_MATHI_CASE_INTEGER(op_name);                                         \\\n    OP_MATHI_CASE_FLOAT(op_name);                                           \\\n    default:                                                                \\\n      SET_INT_VALUE(mrb,regs[a+1], b);                                      \\\n      mid = MRB_OPSYM(op_name);                                             \\\n      goto L_SEND_SYM;                                                      \\\n  }                                                                         \\\n  NEXT;\n#define OP_MATHI_CASE_INTEGER(op_name)                                      \\\n  case MRB_TT_INTEGER:                                                      \\\n    {                                                                       \\\n      mrb_int x = mrb_integer(regs[a]), y = (mrb_int)b, z;                  \\\n      if (mrb_int_##op_name##_overflow(x, y, &z))                           \\\n        OP_MATH_OVERFLOW_INT();                                             \\\n      else                                                                  \\\n        SET_INT_VALUE(mrb,regs[a], z);                                      \\\n    }                                                                       \\\n    break\n#ifdef MRB_NO_FLOAT\n#define OP_MATHI_CASE_FLOAT(op_name) (void)0\n#else\n#define OP_MATHI_CASE_FLOAT(op_name)                                        \\\n  case MRB_TT_FLOAT:                                                        \\\n    {                                                                       \\\n      mrb_float z = mrb_float(regs[a]) OP_MATH_OP_##op_name b;              \\\n      SET_FLOAT_VALUE(mrb, regs[a], z);                                     \\\n    }                                                                       \\\n    break\n#endif\n\n    CASE(OP_ADDI, BB) {\n      OP_MATHI(add);\n    }\n\n    CASE(OP_SUBI, BB) {\n      OP_MATHI(sub);\n    }\n\n#define OP_CMP_BODY(op,v1,v2) (v1(regs[a]) op v2(regs[a+1]))\n\n#ifdef MRB_NO_FLOAT\n#define OP_CMP(op,sym) do {\\\n  int result;\\\n  /* need to check if - is overridden */\\\n  switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\\\n  case TYPES2(MRB_TT_INTEGER,MRB_TT_INTEGER):\\\n    result = OP_CMP_BODY(op,mrb_fixnum,mrb_fixnum);\\\n    break;\\\n  default:\\\n    mid = MRB_OPSYM(sym);\\\n    goto L_SEND_SYM;\\\n  }\\\n  if (result) {\\\n    SET_TRUE_VALUE(regs[a]);\\\n  }\\\n  else {\\\n    SET_FALSE_VALUE(regs[a]);\\\n  }\\\n} while(0)\n#else\n#define OP_CMP(op, sym) do {\\\n  int result;\\\n  /* need to check if - is overridden */\\\n  switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\\\n  case TYPES2(MRB_TT_INTEGER,MRB_TT_INTEGER):\\\n    result = OP_CMP_BODY(op,mrb_fixnum,mrb_fixnum);\\\n    break;\\\n  case TYPES2(MRB_TT_INTEGER,MRB_TT_FLOAT):\\\n    result = OP_CMP_BODY(op,mrb_fixnum,mrb_float);\\\n    break;\\\n  case TYPES2(MRB_TT_FLOAT,MRB_TT_INTEGER):\\\n    result = OP_CMP_BODY(op,mrb_float,mrb_fixnum);\\\n    break;\\\n  case TYPES2(MRB_TT_FLOAT,MRB_TT_FLOAT):\\\n    result = OP_CMP_BODY(op,mrb_float,mrb_float);\\\n    break;\\\n  default:\\\n    mid = MRB_OPSYM(sym);\\\n    goto L_SEND_SYM;\\\n  }\\\n  if (result) {\\\n    SET_TRUE_VALUE(regs[a]);\\\n  }\\\n  else {\\\n    SET_FALSE_VALUE(regs[a]);\\\n  }\\\n} while(0)\n#endif\n\n    CASE(OP_EQ, B) {\n      if (mrb_obj_eq(mrb, regs[a], regs[a+1])) {\n        SET_TRUE_VALUE(regs[a]);\n      }\n      else {\n        OP_CMP(==,eq);\n      }\n      NEXT;\n    }\n\n    CASE(OP_LT, B) {\n      OP_CMP(<,lt);\n      NEXT;\n    }\n\n    CASE(OP_LE, B) {\n      OP_CMP(<=,le);\n      NEXT;\n    }\n\n    CASE(OP_GT, B) {\n      OP_CMP(>,gt);\n      NEXT;\n    }\n\n    CASE(OP_GE, B) {\n      OP_CMP(>=,ge);\n      NEXT;\n    }\n\n    CASE(OP_ARRAY, BB) {\n      regs[a] = mrb_ary_new_from_values(mrb, b, &regs[a]);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n    CASE(OP_ARRAY2, BBB) {\n      regs[a] = mrb_ary_new_from_values(mrb, c, &regs[b]);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_ARYCAT, B) {\n      mrb_value splat = mrb_ary_splat(mrb, regs[a+1]);\n      if (mrb_nil_p(regs[a])) {\n        regs[a] = splat;\n      }\n      else {\n        mrb_assert(mrb_array_p(regs[a]));\n        mrb_ary_concat(mrb, regs[a], splat);\n      }\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_ARYPUSH, BB) {\n      mrb_assert(mrb_array_p(regs[a]));\n      for (mrb_int i=0; i<b; i++) {\n        mrb_ary_push(mrb, regs[a], regs[a+i+1]);\n      }\n      NEXT;\n    }\n\n    CASE(OP_ARYDUP, B) {\n      mrb_value ary = regs[a];\n      if (mrb_array_p(ary)) {\n        ary = mrb_ary_new_from_values(mrb, RARRAY_LEN(ary), RARRAY_PTR(ary));\n      }\n      else {\n        ary = mrb_ary_new_from_values(mrb, 1, &ary);\n      }\n      regs[a] = ary;\n      NEXT;\n    }\n\n    CASE(OP_AREF, BBB) {\n      mrb_value v = regs[b];\n\n      if (!mrb_array_p(v)) {\n        if (c == 0) {\n          regs[a] = v;\n        }\n        else {\n          SET_NIL_VALUE(regs[a]);\n        }\n      }\n      else {\n        v = mrb_ary_ref(mrb, v, c);\n        regs[a] = v;\n      }\n      NEXT;\n    }\n\n    CASE(OP_ASET, BBB) {\n      mrb_assert(mrb_array_p(regs[a]));\n      mrb_ary_set(mrb, regs[b], c, regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_APOST, BBB) {\n      mrb_value v = regs[a];\n      int pre  = b;\n      int post = c;\n      struct RArray *ary;\n      int len, idx;\n\n      if (!mrb_array_p(v)) {\n        v = mrb_ary_new_from_values(mrb, 1, &regs[a]);\n      }\n      ary = mrb_ary_ptr(v);\n      len = (int)ARY_LEN(ary);\n      if (len > pre + post) {\n        v = mrb_ary_new_from_values(mrb, len - pre - post, ARY_PTR(ary)+pre);\n        regs[a++] = v;\n        while (post--) {\n          regs[a++] = ARY_PTR(ary)[len-post-1];\n        }\n      }\n      else {\n        v = mrb_ary_new_capa(mrb, 0);\n        regs[a++] = v;\n        for (idx=0; idx+pre<len; idx++) {\n          regs[a+idx] = ARY_PTR(ary)[pre+idx];\n        }\n        while (idx < post) {\n          SET_NIL_VALUE(regs[a+idx]);\n          idx++;\n        }\n      }\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_INTERN, B) {\n      mrb_assert(mrb_string_p(regs[a]));\n      mrb_sym sym = mrb_intern_str(mrb, regs[a]);\n      regs[a] = mrb_symbol_value(sym);\n      NEXT;\n    }\n\n    CASE(OP_SYMBOL, BB) {\n      size_t len;\n      mrb_sym sym;\n\n      mrb_assert((pool[b].tt&IREP_TT_NFLAG)==0);\n      len = pool[b].tt >> 2;\n      if (pool[b].tt & IREP_TT_SFLAG) {\n        sym = mrb_intern_static(mrb, pool[b].u.str, len);\n      }\n      else {\n        sym  = mrb_intern(mrb, pool[b].u.str, len);\n      }\n      regs[a] = mrb_symbol_value(sym);\n      NEXT;\n    }\n\n    CASE(OP_STRING, BB) {\n      mrb_int len;\n\n      mrb_assert((pool[b].tt&IREP_TT_NFLAG)==0);\n      len = pool[b].tt >> 2;\n      if (pool[b].tt & IREP_TT_SFLAG) {\n        regs[a] = mrb_str_new_static(mrb, pool[b].u.str, len);\n      }\n      else {\n        regs[a] = mrb_str_new(mrb, pool[b].u.str, len);\n      }\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_STRCAT, B) {\n      mrb_assert(mrb_string_p(regs[a]));\n      mrb_str_concat(mrb, regs[a], regs[a+1]);\n      NEXT;\n    }\n\n    CASE(OP_HASH, BB) {\n      mrb_value hash = mrb_hash_new_capa(mrb, b);\n      int i;\n      int lim = a+b*2;\n\n      for (i=a; i<lim; i+=2) {\n        mrb_hash_set(mrb, hash, regs[i], regs[i+1]);\n      }\n      regs[a] = hash;\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_HASHADD, BB) {\n      mrb_value hash;\n      int i;\n      int lim = a+b*2+1;\n\n      hash = regs[a];\n      mrb_ensure_hash_type(mrb, hash);\n      for (i=a+1; i<lim; i+=2) {\n        mrb_hash_set(mrb, hash, regs[i], regs[i+1]);\n      }\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n    CASE(OP_HASHCAT, B) {\n      mrb_value hash = regs[a];\n\n      mrb_assert(mrb_hash_p(hash));\n      mrb_hash_merge(mrb, hash, regs[a+1]);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_LAMBDA, BB)\n    c = OP_L_LAMBDA;\n    L_MAKE_LAMBDA:\n    {\n      struct RProc *p;\n      const mrb_irep *nirep = irep->reps[b];\n\n      if (c & OP_L_CAPTURE) {\n        p = mrb_closure_new(mrb, nirep);\n      }\n      else {\n        p = mrb_proc_new(mrb, nirep);\n        p->flags |= MRB_PROC_SCOPE;\n      }\n      if (c & OP_L_STRICT) p->flags |= MRB_PROC_STRICT;\n      regs[a] = mrb_obj_value(p);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n    CASE(OP_BLOCK, BB) {\n      c = OP_L_BLOCK;\n      goto L_MAKE_LAMBDA;\n    }\n    CASE(OP_METHOD, BB) {\n      c = OP_L_METHOD;\n      goto L_MAKE_LAMBDA;\n    }\n\n    CASE(OP_RANGE_INC, B) {\n      mrb_value v = mrb_range_new(mrb, regs[a], regs[a+1], FALSE);\n      regs[a] = v;\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_RANGE_EXC, B) {\n      mrb_value v = mrb_range_new(mrb, regs[a], regs[a+1], TRUE);\n      regs[a] = v;\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_OCLASS, B) {\n      regs[a] = mrb_obj_value(mrb->object_class);\n      NEXT;\n    }\n\n    CASE(OP_CLASS, BB) {\n      struct RClass *c = 0, *baseclass;\n      mrb_value base, super;\n      mrb_sym id = syms[b];\n\n      base = regs[a];\n      super = regs[a+1];\n      if (mrb_nil_p(base)) {\n        baseclass = MRB_PROC_TARGET_CLASS(mrb->c->ci->proc);\n        if (!baseclass) baseclass = mrb->object_class;\n        base = mrb_obj_value(baseclass);\n      }\n      c = mrb_vm_define_class(mrb, base, super, id);\n      regs[a] = mrb_obj_value(c);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_MODULE, BB) {\n      struct RClass *cls = 0, *baseclass;\n      mrb_value base;\n      mrb_sym id = syms[b];\n\n      base = regs[a];\n      if (mrb_nil_p(base)) {\n        baseclass = MRB_PROC_TARGET_CLASS(mrb->c->ci->proc);\n        if (!baseclass) baseclass = mrb->object_class;\n        base = mrb_obj_value(baseclass);\n      }\n      cls = mrb_vm_define_module(mrb, base, id);\n      regs[a] = mrb_obj_value(cls);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_EXEC, BB)\n    {\n      mrb_value recv = regs[a];\n      struct RProc *p;\n      const mrb_irep *nirep = irep->reps[b];\n\n      /* prepare closure */\n      p = mrb_proc_new(mrb, nirep);\n      p->c = NULL;\n      mrb_field_write_barrier(mrb, (struct RBasic*)p, (struct RBasic*)proc);\n      MRB_PROC_SET_TARGET_CLASS(p, mrb_class_ptr(recv));\n      p->flags |= MRB_PROC_SCOPE;\n\n      /* prepare call stack */\n      cipush(mrb, a, 0, mrb_class_ptr(recv), p, 0, 0);\n\n      irep = p->body.irep;\n      pool = irep->pool;\n      syms = irep->syms;\n      mrb_stack_extend(mrb, irep->nregs);\n      stack_clear(regs+1, irep->nregs-1);\n      pc = irep->iseq;\n      JUMP;\n    }\n\n    CASE(OP_DEF, BB) {\n      struct RClass *target = mrb_class_ptr(regs[a]);\n      struct RProc *p = mrb_proc_ptr(regs[a+1]);\n      mrb_method_t m;\n      mrb_sym mid = syms[b];\n\n      MRB_METHOD_FROM_PROC(m, p);\n      mrb_define_method_raw(mrb, target, mid, m);\n      mrb_method_added(mrb, target, mid);\n      mrb_gc_arena_restore(mrb, ai);\n      regs[a] = mrb_symbol_value(mid);\n      NEXT;\n    }\n\n    CASE(OP_SCLASS, B) {\n      regs[a] = mrb_singleton_class(mrb, regs[a]);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_TCLASS, B) {\n      struct RClass *target = check_target_class(mrb);\n      if (!target) goto L_RAISE;\n      regs[a] = mrb_obj_value(target);\n      NEXT;\n    }\n\n    CASE(OP_ALIAS, BB) {\n      struct RClass *target = check_target_class(mrb);\n\n      if (!target) goto L_RAISE;\n      mrb_alias_method(mrb, target, syms[a], syms[b]);\n      mrb_method_added(mrb, target, syms[a]);\n      NEXT;\n    }\n    CASE(OP_UNDEF, B) {\n      struct RClass *target = check_target_class(mrb);\n\n      if (!target) goto L_RAISE;\n      mrb_undef_method_id(mrb, target, syms[a]);\n      NEXT;\n    }\n\n    CASE(OP_DEBUG, Z) {\n      FETCH_BBB();\n#ifdef MRB_USE_DEBUG_HOOK\n      mrb->debug_op_hook(mrb, irep, pc, regs);\n#else\n#ifndef MRB_NO_STDIO\n      printf(\"OP_DEBUG %d %d %d\\n\", a, b, c);\n#else\n      abort();\n#endif\n#endif\n      NEXT;\n    }\n\n    CASE(OP_ERR, B) {\n      size_t len = pool[a].tt >> 2;\n      mrb_value exc;\n\n      mrb_assert((pool[a].tt&IREP_TT_NFLAG)==0);\n      exc = mrb_exc_new(mrb, E_LOCALJUMP_ERROR, pool[a].u.str, len);\n      mrb_exc_set(mrb, exc);\n      goto L_RAISE;\n    }\n\n    CASE(OP_EXT1, Z) {\n      insn = READ_B();\n      switch (insn) {\n#define OPCODE(insn,ops) case OP_ ## insn: FETCH_ ## ops ## _1(); mrb->c->ci->pc = pc; goto L_OP_ ## insn ## _BODY;\n#include \"mruby/ops.h\"\n#undef OPCODE\n      }\n      pc--;\n      NEXT;\n    }\n    CASE(OP_EXT2, Z) {\n      insn = READ_B();\n      switch (insn) {\n#define OPCODE(insn,ops) case OP_ ## insn: FETCH_ ## ops ## _2(); mrb->c->ci->pc = pc; goto L_OP_ ## insn ## _BODY;\n#include \"mruby/ops.h\"\n#undef OPCODE\n      }\n      pc--;\n      NEXT;\n    }\n    CASE(OP_EXT3, Z) {\n      uint8_t insn = READ_B();\n      switch (insn) {\n#define OPCODE(insn,ops) case OP_ ## insn: FETCH_ ## ops ## _3(); mrb->c->ci->pc = pc; goto L_OP_ ## insn ## _BODY;\n#include \"mruby/ops.h\"\n#undef OPCODE\n      }\n      pc--;\n      NEXT;\n    }\n\n    CASE(OP_STOP, Z) {\n      /*        stop VM */\n      CHECKPOINT_RESTORE(RBREAK_TAG_STOP) {\n        /* do nothing */\n      }\n      CHECKPOINT_MAIN(RBREAK_TAG_STOP) {\n        UNWIND_ENSURE(mrb, mrb->c->ci, pc, RBREAK_TAG_STOP, proc, mrb_nil_value());\n      }\n      CHECKPOINT_END(RBREAK_TAG_STOP);\n    L_STOP:\n      mrb->jmp = prev_jmp;\n      if (mrb->exc) {\n        mrb_assert(mrb->exc->tt == MRB_TT_EXCEPTION);\n        return mrb_obj_value(mrb->exc);\n      }\n      return regs[irep->nlocals];\n    }\n  }\n  END_DISPATCH;\n#undef regs\n  }\n  MRB_CATCH(&c_jmp) {\n    mrb_callinfo *ci = mrb->c->ci;\n    while (ci > mrb->c->cibase && ci->cci == CINFO_DIRECT) {\n      ci = cipop(mrb);\n    }\n    exc_catched = TRUE;\n    pc = ci->pc;\n    goto RETRY_TRY_BLOCK;\n  }\n  MRB_END_EXC(&c_jmp);\n}",
        "func_hash": 109885974444796302561569813029771831944,
        "file_name": "vm.c",
        "file_hash": 83886473477345826235413068203214397377,
        "cwe": [
            "CWE-288"
        ],
        "cve": "CVE-2022-1212",
        "cve_desc": "Use-After-Free in str_escape in mruby/mruby in GitHub repository mruby/mruby prior to 3.2. Possible arbitrary code execution if being exploited.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-1212",
        "func_name": "mrb_vm_exec",
        "diff": [
            "diff --git a/src/vm.c b/src/vm.c\nindex 3796f41738..6d61386b31 100644\n--- a/src/vm.c\n+++ b/src/vm.c\n@@ -2268,9 +2268,9 @@ mrb_vm_exec(mrb_state *mrb, const struct RProc *proc, const mrb_code *pc)\n           }\n           if (ci->cci > CINFO_NONE) {\n             ci = cipop(mrb);\n+            mrb->exc = (struct RObject*)break_new(mrb, RBREAK_TAG_BREAK, proc, v);\n             mrb_gc_arena_restore(mrb, ai);\n             mrb->c->vmexec = FALSE;\n-            mrb->exc = (struct RObject*)break_new(mrb, RBREAK_TAG_BREAK, proc, v);\n             mrb->jmp = prev_jmp;\n             MRB_THROW(prev_jmp);\n           }\n"
        ],
        "func_after": []
    },
    {
        "idx": 198449,
        "project": "pjproject",
        "commit_id": "450baca94f475345542c6953832650c390889202",
        "project_url": "https://github.com/pjsip/pjproject",
        "commit_url": "https://github.com/pjsip/pjproject/commit/450baca94f475345542c6953832650c390889202",
        "commit_message": "Merge pull request from GHSA-26j7-ww69-c4qj",
        "target": 1,
        "irrelevant": 0,
        "func_before": "PJ_DEF(pj_status_t) pjstun_parse_msg( void *buf, pj_size_t buf_len, \n\t\t\t\t      pjstun_msg *msg)\n{\n    pj_uint16_t msg_type, msg_len;\n    char *p_attr;\n\n    PJ_CHECK_STACK();\n\n    msg->hdr = (pjstun_msg_hdr*)buf;\n    msg_type = pj_ntohs(msg->hdr->type);\n\n    switch (msg_type) {\n    case PJSTUN_BINDING_REQUEST:\n    case PJSTUN_BINDING_RESPONSE:\n    case PJSTUN_BINDING_ERROR_RESPONSE:\n    case PJSTUN_SHARED_SECRET_REQUEST:\n    case PJSTUN_SHARED_SECRET_RESPONSE:\n    case PJSTUN_SHARED_SECRET_ERROR_RESPONSE:\n\tbreak;\n    default:\n\tPJ_LOG(4,(THIS_FILE, \"Error: unknown msg type %d\", msg_type));\n\treturn PJLIB_UTIL_ESTUNINMSGTYPE;\n    }\n\n    msg_len = pj_ntohs(msg->hdr->length);\n    if (msg_len != buf_len - sizeof(pjstun_msg_hdr)) {\n\tPJ_LOG(4,(THIS_FILE, \"Error: invalid msg_len %d (expecting %d)\", \n\t\t\t     msg_len, buf_len - sizeof(pjstun_msg_hdr)));\n\treturn PJLIB_UTIL_ESTUNINMSGLEN;\n    }\n\n    msg->attr_count = 0;\n    p_attr = (char*)buf + sizeof(pjstun_msg_hdr);\n\n    while (msg_len > 0) {\n\tpjstun_attr_hdr **attr = &msg->attr[msg->attr_count];\n\tpj_uint32_t len;\n\tpj_uint16_t attr_type;\n\n\t*attr = (pjstun_attr_hdr*)p_attr;\n\tlen = pj_ntohs((pj_uint16_t) ((*attr)->length)) + sizeof(pjstun_attr_hdr);\n\tlen = (len + 3) & ~3;\n\n\tif (msg_len < len) {\n\t    PJ_LOG(4,(THIS_FILE, \"Error: length mismatch in attr %d\", \n\t\t\t\t msg->attr_count));\n\t    return PJLIB_UTIL_ESTUNINATTRLEN;\n\t}\n\n\tattr_type = pj_ntohs((*attr)->type);\n\tif (attr_type > PJSTUN_ATTR_REFLECTED_FROM &&\n\t    attr_type != PJSTUN_ATTR_XOR_MAPPED_ADDR)\n\t{\n\t    PJ_LOG(5,(THIS_FILE, \"Warning: unknown attr type %x in attr %d. \"\n\t\t\t\t \"Attribute was ignored.\",\n\t\t\t\t attr_type, msg->attr_count));\n\t}\n\n\tmsg_len = (pj_uint16_t)(msg_len - len);\n\tp_attr += len;\n\t++msg->attr_count;\n    }\n\n    return PJ_SUCCESS;\n}",
        "func_hash": 324794898254091416853424941566787120064,
        "file_name": "stun_simple.c",
        "file_hash": 304268271857931505815837287097781884670,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2022-31031",
        "cve_desc": "PJSIP is a free and open source multimedia communication library written in C language implementing standard based protocols such as SIP, SDP, RTP, STUN, TURN, and ICE. In versions prior to and including 2.12.1 a stack buffer overflow vulnerability affects PJSIP users that use STUN in their applications, either by: setting a STUN server in their account/media config in PJSUA/PJSUA2 level, or directly using `pjlib-util/stun_simple` API. A patch is available in commit 450baca which should be included in the next release. There are no known workarounds for this issue.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-31031",
        "func_name": "PJ_DEF",
        "diff": [
            "diff --git a/pjlib-util/src/pjlib-util/stun_simple.c b/pjlib-util/src/pjlib-util/stun_simple.c\nindex 7225195846..d0549176dd 100644\n--- a/pjlib-util/src/pjlib-util/stun_simple.c\n+++ b/pjlib-util/src/pjlib-util/stun_simple.c\n@@ -54,6 +54,7 @@ PJ_DEF(pj_status_t) pjstun_parse_msg( void *buf, pj_size_t buf_len,\n {\n     pj_uint16_t msg_type, msg_len;\n     char *p_attr;\n+    int attr_max_cnt = PJ_ARRAY_SIZE(msg->attr);\n \n     PJ_CHECK_STACK();\n \n@@ -83,7 +84,7 @@ PJ_DEF(pj_status_t) pjstun_parse_msg( void *buf, pj_size_t buf_len,\n     msg->attr_count = 0;\n     p_attr = (char*)buf + sizeof(pjstun_msg_hdr);\n \n-    while (msg_len > 0) {\n+    while (msg_len > 0 && msg->attr_count < attr_max_cnt) {\n \tpjstun_attr_hdr **attr = &msg->attr[msg->attr_count];\n \tpj_uint32_t len;\n \tpj_uint16_t attr_type;\n@@ -111,6 +112,10 @@ PJ_DEF(pj_status_t) pjstun_parse_msg( void *buf, pj_size_t buf_len,\n \tp_attr += len;\n \t++msg->attr_count;\n     }\n+    if (msg->attr_count == attr_max_cnt) {\n+\tPJ_LOG(4, (THIS_FILE, \"Warning: max number attribute %d reached.\",\n+\t\t   attr_max_cnt));\n+    }\n \n     return PJ_SUCCESS;\n }\n"
        ],
        "func_after": []
    },
    {
        "idx": 198452,
        "project": "tensorflow",
        "commit_id": "a989426ee1346693cc015792f11d715f6944f2b8",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/a989426ee1346693cc015792f11d715f6944f2b8",
        "commit_message": "Improve to cover scale value greater than one\n\nPiperOrigin-RevId: 433050921",
        "target": 1,
        "irrelevant": 0,
        "func_before": "void ComparisonQuantized(const TfLiteTensor* input1, const TfLiteTensor* input2,\n                         TfLiteTensor* output, bool requires_broadcast) {\n  if (input1->type == kTfLiteUInt8 || input1->type == kTfLiteInt8) {\n    auto input1_offset = -input1->params.zero_point;\n    auto input2_offset = -input2->params.zero_point;\n    const int left_shift = 8;\n\n    int32 input1_multiplier;\n    int input1_shift;\n    QuantizeMultiplierSmallerThanOneExp(input1->params.scale,\n                                        &input1_multiplier, &input1_shift);\n    int32 input2_multiplier;\n    int input2_shift;\n    QuantizeMultiplierSmallerThanOneExp(input2->params.scale,\n                                        &input2_multiplier, &input2_shift);\n\n    ComparisonParams op_params;\n    op_params.left_shift = left_shift;\n    op_params.input1_offset = input1_offset;\n    op_params.input1_multiplier = input1_multiplier;\n    op_params.input1_shift = input1_shift;\n    op_params.input2_offset = input2_offset;\n    op_params.input2_multiplier = input2_multiplier;\n    op_params.input2_shift = input2_shift;\n    if (requires_broadcast) {\n      reference_ops::BroadcastComparison4DSlowWithScaling<input_dtype, opname>(\n          op_params, GetTensorShape(input1), GetTensorData<input_dtype>(input1),\n          GetTensorShape(input2), GetTensorData<input_dtype>(input2),\n          GetTensorShape(output), GetTensorData<bool>(output));\n    } else {\n      reference_ops::ComparisonWithScaling<input_dtype, opname>(\n          op_params, GetTensorShape(input1), GetTensorData<input_dtype>(input1),\n          GetTensorShape(input2), GetTensorData<input_dtype>(input2),\n          GetTensorShape(output), GetTensorData<bool>(output));\n    }\n  }\n}",
        "func_hash": 284336502909303651692457957640037138117,
        "file_name": "comparisons.cc",
        "file_hash": 224870261654956140630544765652331160875,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2022-29212",
        "cve_desc": "TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, certain TFLite models that were created using TFLite model converter would crash when loaded in the TFLite interpreter. The culprit is that during quantization the scale of values could be greater than 1 but code was always assuming sub-unit scaling. Thus, since code was calling `QuantizeMultiplierSmallerThanOneExp`, the `TFLITE_CHECK_LT` assertion would trigger and abort the process. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-29212",
        "func_name": "ComparisonQuantized",
        "diff": [
            "diff --git a/tensorflow/lite/kernels/comparisons.cc b/tensorflow/lite/kernels/comparisons.cc\nindex d0a1876c5c654f..c3824c1db01706 100644\n--- a/tensorflow/lite/kernels/comparisons.cc\n+++ b/tensorflow/lite/kernels/comparisons.cc\n@@ -81,6 +81,17 @@ TfLiteStatus ComparisonPrepareStringAllowed(TfLiteContext* context,\n   return ComparisonPrepareCommon(context, node, true);\n }\n \n+void QuantizeMultiplier(double double_multiplier, int32_t* quantized_multiplier,\n+                        int* left_shift) {\n+  if (double_multiplier < 1.0) {\n+    QuantizeMultiplierSmallerThanOneExp(double_multiplier, quantized_multiplier,\n+                                        left_shift);\n+  } else {\n+    QuantizeMultiplierGreaterThanOne(double_multiplier, quantized_multiplier,\n+                                     left_shift);\n+  }\n+}\n+\n template <typename input_dtype, reference_ops::ComparisonFn<int32> opname>\n void ComparisonQuantized(const TfLiteTensor* input1, const TfLiteTensor* input2,\n                          TfLiteTensor* output, bool requires_broadcast) {\n@@ -90,13 +101,11 @@ void ComparisonQuantized(const TfLiteTensor* input1, const TfLiteTensor* input2,\n     const int left_shift = 8;\n \n     int32 input1_multiplier;\n-    int input1_shift;\n-    QuantizeMultiplierSmallerThanOneExp(input1->params.scale,\n-                                        &input1_multiplier, &input1_shift);\n     int32 input2_multiplier;\n+    int input1_shift;\n     int input2_shift;\n-    QuantizeMultiplierSmallerThanOneExp(input2->params.scale,\n-                                        &input2_multiplier, &input2_shift);\n+    QuantizeMultiplier(input1->params.scale, &input1_multiplier, &input1_shift);\n+    QuantizeMultiplier(input2->params.scale, &input2_multiplier, &input2_shift);\n \n     ComparisonParams op_params;\n     op_params.left_shift = left_shift;\ndiff --git a/tensorflow/lite/kernels/comparisons_test.cc b/tensorflow/lite/kernels/comparisons_test.cc\nindex f8cf6dee74c4bf..074d0f1f61513a 100644\n--- a/tensorflow/lite/kernels/comparisons_test.cc\n+++ b/tensorflow/lite/kernels/comparisons_test.cc\n@@ -653,6 +653,26 @@ TEST(ComparisonsTest, QuantizedInt8GreaterWithBroadcast) {\n   }\n }\n \n+TEST(ComparisonsTest,\n+     QuantizedInt8GreaterWithBroadcastMultiplierGreaterThanOne) {\n+  const float kMin = -127.f;\n+  const float kMax = 127.f;\n+  std::vector<std::vector<int>> test_shapes = {\n+      {6}, {2, 3}, {2, 1, 3}, {1, 3, 1, 2}};\n+  for (int i = 0; i < test_shapes.size(); ++i) {\n+    ComparisonOpModel model({TensorType_INT8, test_shapes[i], kMin, kMax},\n+                            {TensorType_INT8, {}, kMin, kMax}, TensorType_INT8,\n+                            BuiltinOperator_GREATER);\n+    model.QuantizeAndPopulate<int8_t>(model.input1(),\n+                                      {572, -2, -71, 8, 11, 20});\n+    model.QuantizeAndPopulate<int8_t>(model.input2(), {8});\n+    model.Invoke();\n+    EXPECT_THAT(model.GetOutput(),\n+                ElementsAre(true, false, false, false, true, true))\n+        << \"With shape number \" << i;\n+  }\n+}\n+\n TEST(ComparisonsTest, QuantizedUInt8GreaterEqualWithBroadcast) {\n   const float kMin = -1.f;\n   const float kMax = 128.f;\n"
        ],
        "func_after": []
    },
    {
        "idx": 198476,
        "project": "njs",
        "commit_id": "6a07c2156a07ef307b6dcf3c2ca8571a5f1af7a6",
        "project_url": "https://github.com/nginx/njs",
        "commit_url": "https://github.com/nginx/njs/commit/6a07c2156a07ef307b6dcf3c2ca8571a5f1af7a6",
        "commit_message": "Fixed recursive async function calls.\n\nPreviously, PromiseCapability record was stored (function->context)\ndirectly in function object during a function invocation.  This is\nnot correct, because PromiseCapability record should be linked to\ncurrent execution context.  As a result, function->context is\noverwritten with consecutive recursive calls which results in\nuse-after-free.\n\nThis closes #451 issue on Github.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "njs_await_fulfilled(njs_vm_t *vm, njs_value_t *args, njs_uint_t nargs,\n    njs_index_t unused)\n{\n    njs_int_t           ret;\n    njs_value_t         **cur_local, **cur_closures, **cur_temp, *value;\n    njs_frame_t         *frame, *async_frame;\n    njs_function_t      *function;\n    njs_async_ctx_t     *ctx;\n    njs_native_frame_t  *top, *async;\n\n    ctx = vm->top_frame->function->context;\n\n    value = njs_arg(args, nargs, 1);\n    if (njs_is_error(value)) {\n        goto failed;\n    }\n\n    async_frame = ctx->await;\n    async = &async_frame->native;\n    async->previous = vm->top_frame;\n\n    function = async->function;\n\n    cur_local = vm->levels[NJS_LEVEL_LOCAL];\n    cur_closures = vm->levels[NJS_LEVEL_CLOSURE];\n    cur_temp = vm->levels[NJS_LEVEL_TEMP];\n    top = vm->top_frame;\n    frame = vm->active_frame;\n\n    vm->levels[NJS_LEVEL_LOCAL] = async->local;\n    vm->levels[NJS_LEVEL_CLOSURE] = njs_function_closures(async->function);\n    vm->levels[NJS_LEVEL_TEMP] = async->temp;\n\n    vm->top_frame = async;\n    vm->active_frame = async_frame;\n\n    *njs_scope_value(vm, ctx->index) = *value;\n    vm->retval = *value;\n\n    vm->top_frame->retval = &vm->retval;\n\n    function->context = ctx->capability;\n    function->await = ctx;\n\n    ret = njs_vmcode_interpreter(vm, ctx->pc);\n\n    function->context = NULL;\n    function->await = NULL;\n\n    vm->levels[NJS_LEVEL_LOCAL] = cur_local;\n    vm->levels[NJS_LEVEL_CLOSURE] = cur_closures;\n    vm->levels[NJS_LEVEL_TEMP] = cur_temp;\n\n    vm->top_frame = top;\n    vm->active_frame = frame;\n\n    if (ret == NJS_OK) {\n        ret = njs_function_call(vm, njs_function(&ctx->capability->resolve),\n                            &njs_value_undefined, &vm->retval, 1, &vm->retval);\n\n        njs_async_context_free(vm, ctx);\n\n    } else if (ret == NJS_AGAIN) {\n        ret = NJS_OK;\n\n    } else if (ret == NJS_ERROR) {\n        if (njs_is_memory_error(vm, &vm->retval)) {\n            return NJS_ERROR;\n        }\n\n        value = &vm->retval;\n\n        goto failed;\n    }\n\n    return ret;\n\nfailed:\n\n    (void) njs_function_call(vm, njs_function(&ctx->capability->reject),\n                             &njs_value_undefined, value, 1, &vm->retval);\n\n    njs_async_context_free(vm, ctx);\n\n    return NJS_ERROR;\n}",
        "func_hash": 241518720909355358001984532864321433833,
        "file_name": "njs_async.c",
        "file_hash": 139542101989914499952242434630508544825,
        "cwe": [
            "CWE-416"
        ],
        "cve": "CVE-2022-25139",
        "cve_desc": "njs through 0.7.0, used in NGINX, was discovered to contain a heap use-after-free in njs_await_fulfilled.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-25139",
        "func_name": "njs_await_fulfilled",
        "diff": [
            "diff --git a/src/njs_async.c b/src/njs_async.c\nindex 7bc6c37e7..e4dd74863 100644\n--- a/src/njs_async.c\n+++ b/src/njs_async.c\n@@ -29,9 +29,7 @@ njs_async_function_frame_invoke(njs_vm_t *vm, njs_value_t *retval)\n         return NJS_ERROR;\n     }\n \n-    frame->function->context = capability;\n-\n-    ret = njs_function_lambda_call(vm);\n+    ret = njs_function_lambda_call(vm, capability, NULL);\n \n     if (ret == NJS_OK) {\n         ret = njs_function_call(vm, njs_function(&capability->resolve),\n@@ -63,7 +61,6 @@ njs_await_fulfilled(njs_vm_t *vm, njs_value_t *args, njs_uint_t nargs,\n     njs_int_t           ret;\n     njs_value_t         **cur_local, **cur_closures, **cur_temp, *value;\n     njs_frame_t         *frame, *async_frame;\n-    njs_function_t      *function;\n     njs_async_ctx_t     *ctx;\n     njs_native_frame_t  *top, *async;\n \n@@ -78,8 +75,6 @@ njs_await_fulfilled(njs_vm_t *vm, njs_value_t *args, njs_uint_t nargs,\n     async = &async_frame->native;\n     async->previous = vm->top_frame;\n \n-    function = async->function;\n-\n     cur_local = vm->levels[NJS_LEVEL_LOCAL];\n     cur_closures = vm->levels[NJS_LEVEL_CLOSURE];\n     cur_temp = vm->levels[NJS_LEVEL_TEMP];\n@@ -98,13 +93,7 @@ njs_await_fulfilled(njs_vm_t *vm, njs_value_t *args, njs_uint_t nargs,\n \n     vm->top_frame->retval = &vm->retval;\n \n-    function->context = ctx->capability;\n-    function->await = ctx;\n-\n-    ret = njs_vmcode_interpreter(vm, ctx->pc);\n-\n-    function->context = NULL;\n-    function->await = NULL;\n+    ret = njs_vmcode_interpreter(vm, ctx->pc, ctx->capability, ctx);\n \n     vm->levels[NJS_LEVEL_LOCAL] = cur_local;\n     vm->levels[NJS_LEVEL_CLOSURE] = cur_closures;\ndiff --git a/src/njs_function.c b/src/njs_function.c\nindex ae0fa11ff..5f07ddd9c 100644\n--- a/src/njs_function.c\n+++ b/src/njs_function.c\n@@ -608,7 +608,7 @@ njs_function_call2(njs_vm_t *vm, njs_function_t *function,\n \n \n njs_int_t\n-njs_function_lambda_call(njs_vm_t *vm)\n+njs_function_lambda_call(njs_vm_t *vm, void *promise_cap, void *async_ctx)\n {\n     uint32_t               n;\n     njs_int_t              ret;\n@@ -622,6 +622,8 @@ njs_function_lambda_call(njs_vm_t *vm)\n     frame = (njs_frame_t *) vm->top_frame;\n     function = frame->native.function;\n \n+    njs_assert(function->context == NULL);\n+\n     if (function->global && !function->closure_copied) {\n         ret = njs_function_capture_global_closures(vm, function);\n         if (njs_slow_path(ret != NJS_OK)) {\n@@ -698,7 +700,7 @@ njs_function_lambda_call(njs_vm_t *vm)\n         }\n     }\n \n-    ret = njs_vmcode_interpreter(vm, lambda->start);\n+    ret = njs_vmcode_interpreter(vm, lambda->start, promise_cap, async_ctx);\n \n     /* Restore current level. */\n     vm->levels[NJS_LEVEL_LOCAL] = cur_local;\n@@ -775,7 +777,7 @@ njs_function_frame_invoke(njs_vm_t *vm, njs_value_t *retval)\n         return njs_function_native_call(vm);\n \n     } else {\n-        return njs_function_lambda_call(vm);\n+        return njs_function_lambda_call(vm, NULL, NULL);\n     }\n }\n \ndiff --git a/src/njs_function.h b/src/njs_function.h\nindex b47e7dc6a..59150fdd5 100644\n--- a/src/njs_function.h\n+++ b/src/njs_function.h\n@@ -112,7 +112,8 @@ njs_int_t njs_function_lambda_frame(njs_vm_t *vm, njs_function_t *function,\n njs_int_t njs_function_call2(njs_vm_t *vm, njs_function_t *function,\n     const njs_value_t *this, const njs_value_t *args,\n     njs_uint_t nargs, njs_value_t *retval, njs_bool_t ctor);\n-njs_int_t njs_function_lambda_call(njs_vm_t *vm);\n+njs_int_t njs_function_lambda_call(njs_vm_t *vm, void *promise_cap,\n+    void *async_ctx);\n njs_int_t njs_function_native_call(njs_vm_t *vm);\n njs_native_frame_t *njs_function_frame_alloc(njs_vm_t *vm, size_t size);\n void njs_function_frame_free(njs_vm_t *vm, njs_native_frame_t *frame);\ndiff --git a/src/njs_value.h b/src/njs_value.h\nindex 12448eacd..7297df395 100644\n--- a/src/njs_value.h\n+++ b/src/njs_value.h\n@@ -270,7 +270,6 @@ struct njs_function_s {\n     } u;\n \n     void                              *context;\n-    void                              *await;\n \n     njs_value_t                       *bound;\n };\ndiff --git a/src/njs_vm.c b/src/njs_vm.c\nindex b46f88c62..0c75fff71 100644\n--- a/src/njs_vm.c\n+++ b/src/njs_vm.c\n@@ -490,7 +490,7 @@ njs_vm_start(njs_vm_t *vm)\n         return ret;\n     }\n \n-    ret = njs_vmcode_interpreter(vm, vm->start);\n+    ret = njs_vmcode_interpreter(vm, vm->start, NULL, NULL);\n \n     return (ret == NJS_ERROR) ? NJS_ERROR : NJS_OK;\n }\ndiff --git a/src/njs_vmcode.c b/src/njs_vmcode.c\nindex b371c3748..3039642cb 100644\n--- a/src/njs_vmcode.c\n+++ b/src/njs_vmcode.c\n@@ -42,7 +42,8 @@ static njs_jump_off_t njs_vmcode_debugger(njs_vm_t *vm);\n static njs_jump_off_t njs_vmcode_return(njs_vm_t *vm, njs_value_t *invld,\n     njs_value_t *retval);\n \n-static njs_jump_off_t njs_vmcode_await(njs_vm_t *vm, njs_vmcode_await_t *await);\n+static njs_jump_off_t njs_vmcode_await(njs_vm_t *vm, njs_vmcode_await_t *await,\n+    njs_promise_capability_t *pcap, njs_async_ctx_t *actx);\n \n static njs_jump_off_t njs_vmcode_try_start(njs_vm_t *vm, njs_value_t *value,\n     njs_value_t *offset, u_char *pc);\n@@ -77,7 +78,8 @@ static njs_jump_off_t njs_function_frame_create(njs_vm_t *vm,\n \n \n njs_int_t\n-njs_vmcode_interpreter(njs_vm_t *vm, u_char *pc)\n+njs_vmcode_interpreter(njs_vm_t *vm, u_char *pc, void *promise_cap,\n+    void *async_ctx)\n {\n     u_char                       *catch;\n     double                       num, exponent;\n@@ -826,7 +828,7 @@ njs_vmcode_interpreter(njs_vm_t *vm, u_char *pc)\n \n             case NJS_VMCODE_AWAIT:\n                 await = (njs_vmcode_await_t *) pc;\n-                return njs_vmcode_await(vm, await);\n+                return njs_vmcode_await(vm, await, promise_cap, async_ctx);\n \n             case NJS_VMCODE_TRY_START:\n                 ret = njs_vmcode_try_start(vm, value1, value2, pc);\n@@ -1812,7 +1814,8 @@ njs_vmcode_return(njs_vm_t *vm, njs_value_t *invld, njs_value_t *retval)\n \n \n static njs_jump_off_t\n-njs_vmcode_await(njs_vm_t *vm, njs_vmcode_await_t *await)\n+njs_vmcode_await(njs_vm_t *vm, njs_vmcode_await_t *await,\n+    njs_promise_capability_t *pcap, njs_async_ctx_t *ctx)\n {\n     size_t              size;\n     njs_int_t           ret;\n@@ -1820,7 +1823,6 @@ njs_vmcode_await(njs_vm_t *vm, njs_vmcode_await_t *await)\n     njs_value_t         ctor, val, on_fulfilled, on_rejected, *value;\n     njs_promise_t       *promise;\n     njs_function_t      *fulfilled, *rejected;\n-    njs_async_ctx_t     *ctx;\n     njs_native_frame_t  *active;\n \n     active = &vm->active_frame->native;\n@@ -1837,8 +1839,6 @@ njs_vmcode_await(njs_vm_t *vm, njs_vmcode_await_t *await)\n         return NJS_ERROR;\n     }\n \n-    ctx = active->function->await;\n-\n     if (ctx == NULL) {\n         ctx = njs_mp_alloc(vm->mem_pool, sizeof(njs_async_ctx_t));\n         if (njs_slow_path(ctx == NULL)) {\n@@ -1854,9 +1854,7 @@ njs_vmcode_await(njs_vm_t *vm, njs_vmcode_await_t *await)\n         }\n \n         ctx->await = fulfilled->context;\n-        ctx->capability = active->function->context;\n-\n-        active->function->context = NULL;\n+        ctx->capability = pcap;\n \n         ret = njs_function_frame_save(vm, ctx->await, NULL);\n         if (njs_slow_path(ret != NJS_OK)) {\ndiff --git a/src/njs_vmcode.h b/src/njs_vmcode.h\nindex c15a4bd9e..6b8f65582 100644\n--- a/src/njs_vmcode.h\n+++ b/src/njs_vmcode.h\n@@ -437,7 +437,8 @@ typedef struct {\n } njs_vmcode_await_t;\n \n \n-njs_int_t njs_vmcode_interpreter(njs_vm_t *vm, u_char *pc);\n+njs_int_t njs_vmcode_interpreter(njs_vm_t *vm, u_char *pc,\n+    void *promise_cap, void *async_ctx);\n \n njs_object_t *njs_function_new_object(njs_vm_t *vm, njs_value_t *constructor);\n \ndiff --git a/test/js/async_recursive_last.t.js b/test/js/async_recursive_last.t.js\nnew file mode 100644\nindex 000000000..84f1b5792\n--- /dev/null\n+++ b/test/js/async_recursive_last.t.js\n@@ -0,0 +1,26 @@\n+/*---\n+includes: [compareArray.js]\n+flags: [async]\n+---*/\n+\n+let stages = [];\n+\n+async function f(v) {\n+    if (v == 3) {\n+        return;\n+    }\n+\n+    stages.push(`f>${v}`);\n+\n+    f(v + 1);\n+\n+    stages.push(`f<${v}`);\n+\n+    await \"X\";\n+}\n+\n+f(0)\n+.then(v => {\n+    assert.compareArray(stages, ['f>0', 'f>1', 'f>2', 'f<2', 'f<1', 'f<0']);\n+})\n+.then($DONE, $DONE);\ndiff --git a/test/js/async_recursive_mid.t.js b/test/js/async_recursive_mid.t.js\nnew file mode 100644\nindex 000000000..4d3a9fd19\n--- /dev/null\n+++ b/test/js/async_recursive_mid.t.js\n@@ -0,0 +1,26 @@\n+/*---\n+includes: [compareArray.js]\n+flags: [async]\n+---*/\n+\n+let stages = [];\n+\n+async function f(v) {\n+    if (v == 3) {\n+        return;\n+    }\n+\n+    stages.push(`f>${v}`);\n+\n+    await \"X\";\n+\n+    f(v + 1);\n+\n+    stages.push(`f<${v}`);\n+}\n+\n+f(0)\n+.then(v => {\n+    assert.compareArray(stages, ['f>0','f>1','f<0','f>2','f<1']);\n+})\n+.then($DONE, $DONE);\n"
        ],
        "func_after": []
    },
    {
        "idx": 198499,
        "project": "micro-ecc",
        "commit_id": "1b5f5cea5145c96dd8791b9b2c41424fc74c2172",
        "project_url": "https://github.com/kmackay/micro-ecc",
        "commit_url": "https://github.com/kmackay/micro-ecc/commit/1b5f5cea5145c96dd8791b9b2c41424fc74c2172",
        "commit_message": "Fix for #168",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static int uECC_sign_with_k(const uint8_t *private_key,\n                            const uint8_t *message_hash,\n                            unsigned hash_size,\n                            uECC_word_t *k,\n                            uint8_t *signature,\n                            uECC_Curve curve) {\n\n    uECC_word_t tmp[uECC_MAX_WORDS];\n    uECC_word_t s[uECC_MAX_WORDS];\n    uECC_word_t *k2[2] = {tmp, s};\n#if uECC_VLI_NATIVE_LITTLE_ENDIAN\n    uECC_word_t *p = (uECC_word_t *)signature;\n#else\n    uECC_word_t p[uECC_MAX_WORDS * 2];\n#endif\n    uECC_word_t carry;\n    wordcount_t num_words = curve->num_words;\n    wordcount_t num_n_words = BITS_TO_WORDS(curve->num_n_bits);\n    bitcount_t num_n_bits = curve->num_n_bits;\n\n    /* Make sure 0 < k < curve_n */\n    if (uECC_vli_isZero(k, num_words) || uECC_vli_cmp(curve->n, k, num_n_words) != 1) {\n        return 0;\n    }\n\n    carry = regularize_k(k, tmp, s, curve);\n    EccPoint_mult(p, curve->G, k2[!carry], 0, num_n_bits + 1, curve);\n    if (uECC_vli_isZero(p, num_words)) {\n        return 0;\n    }\n\n    /* If an RNG function was specified, get a random number\n       to prevent side channel analysis of k. */\n    if (!g_rng_function) {\n        uECC_vli_clear(tmp, num_n_words);\n        tmp[0] = 1;\n    } else if (!uECC_generate_random_int(tmp, curve->n, num_n_words)) {\n        return 0;\n    }\n\n    /* Prevent side channel analysis of uECC_vli_modInv() to determine\n       bits of k / the private key by premultiplying by a random number */\n    uECC_vli_modMult(k, k, tmp, curve->n, num_n_words); /* k' = rand * k */\n    uECC_vli_modInv(k, k, curve->n, num_n_words);       /* k = 1 / k' */\n    uECC_vli_modMult(k, k, tmp, curve->n, num_n_words); /* k = 1 / k */\n\n#if uECC_VLI_NATIVE_LITTLE_ENDIAN == 0\n    uECC_vli_nativeToBytes(signature, curve->num_bytes, p); /* store r */\n#endif\n\n#if uECC_VLI_NATIVE_LITTLE_ENDIAN\n    bcopy((uint8_t *) tmp, private_key, BITS_TO_BYTES(curve->num_n_bits));\n#else\n    uECC_vli_bytesToNative(tmp, private_key, BITS_TO_BYTES(curve->num_n_bits)); /* tmp = d */\n#endif\n\n    s[num_n_words - 1] = 0;\n    uECC_vli_set(s, p, num_words);\n    uECC_vli_modMult(s, tmp, s, curve->n, num_n_words); /* s = r*d */\n\n    bits2int(tmp, message_hash, hash_size, curve);\n    uECC_vli_modAdd(s, tmp, s, curve->n, num_n_words); /* s = e + r*d */\n    uECC_vli_modMult(s, s, k, curve->n, num_n_words);  /* s = (e + r*d) / k */\n    if (uECC_vli_numBits(s, num_n_words) > (bitcount_t)curve->num_bytes * 8) {\n        return 0;\n    }\n#if uECC_VLI_NATIVE_LITTLE_ENDIAN\n    bcopy((uint8_t *) signature + curve->num_bytes, (uint8_t *) s, curve->num_bytes);\n#else\n    uECC_vli_nativeToBytes(signature + curve->num_bytes, curve->num_bytes, s);\n#endif    \n    return 1;\n}",
        "func_hash": 250707445511654521220716932779019293116,
        "file_name": "uECC.c",
        "file_hash": 221730154760089899908262595980065132519,
        "cwe": [
            "CWE-415"
        ],
        "cve": "CVE-2020-27209",
        "cve_desc": "The ECDSA operation of the micro-ecc library 1.0 is vulnerable to simple power analysis attacks which allows an adversary to extract the private ECC key.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2020-27209",
        "func_name": "uECC_sign_with_k",
        "diff": [
            "diff --git a/uECC.c b/uECC.c\nindex c08b7ac..17c0f6f 100644\n--- a/uECC.c\n+++ b/uECC.c\n@@ -1210,7 +1210,7 @@ static void bits2int(uECC_word_t *native,\n     bcopy((uint8_t *) native, bits, bits_size);\n #else\n     uECC_vli_bytesToNative(native, bits, bits_size);\n-#endif    \n+#endif\n     if (bits_size * 8 <= (unsigned)curve->num_n_bits) {\n         return;\n     }\n@@ -1239,6 +1239,7 @@ static int uECC_sign_with_k(const uint8_t *private_key,\n     uECC_word_t tmp[uECC_MAX_WORDS];\n     uECC_word_t s[uECC_MAX_WORDS];\n     uECC_word_t *k2[2] = {tmp, s};\n+    uECC_word_t *initial_Z = 0;\n #if uECC_VLI_NATIVE_LITTLE_ENDIAN\n     uECC_word_t *p = (uECC_word_t *)signature;\n #else\n@@ -1255,7 +1256,15 @@ static int uECC_sign_with_k(const uint8_t *private_key,\n     }\n \n     carry = regularize_k(k, tmp, s, curve);\n-    EccPoint_mult(p, curve->G, k2[!carry], 0, num_n_bits + 1, curve);\n+    /* If an RNG function was specified, try to get a random initial Z value to improve\n+       protection against side-channel attacks. */\n+    if (g_rng_function) {\n+        if (!uECC_generate_random_int(k2[carry], curve->p, num_words)) {\n+            return 0;\n+        }\n+        initial_Z = k2[carry];\n+    }\n+    EccPoint_mult(p, curve->G, k2[!carry], initial_Z, num_n_bits + 1, curve);\n     if (uECC_vli_isZero(p, num_words)) {\n         return 0;\n     }\n@@ -1299,7 +1308,7 @@ static int uECC_sign_with_k(const uint8_t *private_key,\n     bcopy((uint8_t *) signature + curve->num_bytes, (uint8_t *) s, curve->num_bytes);\n #else\n     uECC_vli_nativeToBytes(signature + curve->num_bytes, curve->num_bytes, s);\n-#endif    \n+#endif\n     return 1;\n }\n \n@@ -1472,7 +1481,7 @@ int uECC_verify(const uint8_t *public_key,\n     uECC_word_t *_public = (uECC_word_t *)public_key;\n #else\n     uECC_word_t _public[uECC_MAX_WORDS * 2];\n-#endif    \n+#endif\n     uECC_word_t r[uECC_MAX_WORDS], s[uECC_MAX_WORDS];\n     wordcount_t num_words = curve->num_words;\n     wordcount_t num_n_words = BITS_TO_WORDS(curve->num_n_bits);\n"
        ],
        "func_after": []
    },
    {
        "idx": 198512,
        "project": "mruby",
        "commit_id": "00acae117da1b45b318dc36531a7b0021b8097ae",
        "project_url": "https://github.com/mruby/mruby",
        "commit_url": "https://github.com/mruby/mruby/commit/00acae117da1b45b318dc36531a7b0021b8097ae",
        "commit_message": "vm.c: target class may be NULL.",
        "target": 1,
        "irrelevant": 1,
        "func_before": "mrb_vm_exec(mrb_state *mrb, const struct RProc *proc, const mrb_code *pc)\n{\n  /* mrb_assert(MRB_PROC_CFUNC_P(proc)) */\n  const mrb_irep *irep = proc->body.irep;\n  const mrb_pool_value *pool = irep->pool;\n  const mrb_sym *syms = irep->syms;\n  mrb_code insn;\n  int ai = mrb_gc_arena_save(mrb);\n  struct mrb_jmpbuf *prev_jmp = mrb->jmp;\n  struct mrb_jmpbuf c_jmp;\n  uint32_t a;\n  uint16_t b;\n  uint16_t c;\n  mrb_sym mid;\n  const struct mrb_irep_catch_handler *ch;\n\n#ifdef DIRECT_THREADED\n  static const void * const optable[] = {\n#define OPCODE(x,_) &&L_OP_ ## x,\n#include \"mruby/ops.h\"\n#undef OPCODE\n  };\n#endif\n\n  mrb_bool exc_catched = FALSE;\nRETRY_TRY_BLOCK:\n\n  MRB_TRY(&c_jmp) {\n\n  if (exc_catched) {\n    exc_catched = FALSE;\n    mrb_gc_arena_restore(mrb, ai);\n    if (mrb->exc && mrb->exc->tt == MRB_TT_BREAK)\n      goto L_BREAK;\n    goto L_RAISE;\n  }\n  mrb->jmp = &c_jmp;\n  mrb_vm_ci_proc_set(mrb->c->ci, proc);\n\n#define regs (mrb->c->ci->stack)\n  INIT_DISPATCH {\n    CASE(OP_NOP, Z) {\n      /* do nothing */\n      NEXT;\n    }\n\n    CASE(OP_MOVE, BB) {\n      regs[a] = regs[b];\n      NEXT;\n    }\n\n    CASE(OP_LOADL, BB) {\n      switch (pool[b].tt) {   /* number */\n      case IREP_TT_INT32:\n        regs[a] = mrb_int_value(mrb, (mrb_int)pool[b].u.i32);\n        break;\n      case IREP_TT_INT64:\n#if defined(MRB_INT64)\n        regs[a] = mrb_int_value(mrb, (mrb_int)pool[b].u.i64);\n        break;\n#else\n#if defined(MRB_64BIT)\n        if (INT32_MIN <= pool[b].u.i64 && pool[b].u.i64 <= INT32_MAX) {\n          regs[a] = mrb_int_value(mrb, (mrb_int)pool[b].u.i64);\n          break;\n        }\n#endif\n        goto L_INT_OVERFLOW;\n#endif\n      case IREP_TT_BIGINT:\n        goto L_INT_OVERFLOW;\n#ifndef MRB_NO_FLOAT\n      case IREP_TT_FLOAT:\n        regs[a] = mrb_float_value(mrb, pool[b].u.f);\n        break;\n#endif\n      default:\n        /* should not happen (tt:string) */\n        regs[a] = mrb_nil_value();\n        break;\n      }\n      NEXT;\n    }\n\n    CASE(OP_LOADI, BB) {\n      SET_FIXNUM_VALUE(regs[a], b);\n      NEXT;\n    }\n\n    CASE(OP_LOADINEG, BB) {\n      SET_FIXNUM_VALUE(regs[a], -b);\n      NEXT;\n    }\n\n    CASE(OP_LOADI__1,B) goto L_LOADI;\n    CASE(OP_LOADI_0,B) goto L_LOADI;\n    CASE(OP_LOADI_1,B) goto L_LOADI;\n    CASE(OP_LOADI_2,B) goto L_LOADI;\n    CASE(OP_LOADI_3,B) goto L_LOADI;\n    CASE(OP_LOADI_4,B) goto L_LOADI;\n    CASE(OP_LOADI_5,B) goto L_LOADI;\n    CASE(OP_LOADI_6,B) goto L_LOADI;\n    CASE(OP_LOADI_7, B) {\n    L_LOADI:\n      SET_FIXNUM_VALUE(regs[a], (mrb_int)insn - (mrb_int)OP_LOADI_0);\n      NEXT;\n    }\n\n    CASE(OP_LOADI16, BS) {\n      SET_FIXNUM_VALUE(regs[a], (mrb_int)(int16_t)b);\n      NEXT;\n    }\n\n    CASE(OP_LOADI32, BSS) {\n      SET_INT_VALUE(mrb, regs[a], (int32_t)(((uint32_t)b<<16)+c));\n      NEXT;\n    }\n\n    CASE(OP_LOADSYM, BB) {\n      SET_SYM_VALUE(regs[a], syms[b]);\n      NEXT;\n    }\n\n    CASE(OP_LOADNIL, B) {\n      SET_NIL_VALUE(regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_LOADSELF, B) {\n      regs[a] = regs[0];\n      NEXT;\n    }\n\n    CASE(OP_LOADT, B) {\n      SET_TRUE_VALUE(regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_LOADF, B) {\n      SET_FALSE_VALUE(regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETGV, BB) {\n      mrb_value val = mrb_gv_get(mrb, syms[b]);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETGV, BB) {\n      mrb_gv_set(mrb, syms[b], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETSV, BB) {\n      mrb_value val = mrb_vm_special_get(mrb, syms[b]);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETSV, BB) {\n      mrb_vm_special_set(mrb, syms[b], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETIV, BB) {\n      regs[a] = mrb_iv_get(mrb, regs[0], syms[b]);\n      NEXT;\n    }\n\n    CASE(OP_SETIV, BB) {\n      mrb_iv_set(mrb, regs[0], syms[b], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETCV, BB) {\n      mrb_value val;\n      val = mrb_vm_cv_get(mrb, syms[b]);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETCV, BB) {\n      mrb_vm_cv_set(mrb, syms[b], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETIDX, B) {\n      mrb_value va = regs[a], vb = regs[a+1];\n      switch (mrb_type(va)) {\n      case MRB_TT_ARRAY:\n        if (!mrb_integer_p(vb)) goto getidx_fallback;\n        regs[a] = mrb_ary_entry(va, mrb_integer(vb));\n        break;\n      case MRB_TT_HASH:\n        va = mrb_hash_get(mrb, va, vb);\n        regs[a] = va;\n        break;\n      case MRB_TT_STRING:\n        switch (mrb_type(vb)) {\n        case MRB_TT_INTEGER:\n        case MRB_TT_STRING:\n        case MRB_TT_RANGE:\n          va = mrb_str_aref(mrb, va, vb, mrb_undef_value());\n          regs[a] = va;\n          break;\n        default:\n          goto getidx_fallback;\n        }\n        break;\n      default:\n      getidx_fallback:\n        mid = MRB_OPSYM(aref);\n        goto L_SEND_SYM;\n      }\n      NEXT;\n    }\n\n    CASE(OP_SETIDX, B) {\n      c = 2;\n      mid = MRB_OPSYM(aset);\n      SET_NIL_VALUE(regs[a+3]);\n      goto L_SENDB_SYM;\n    }\n\n    CASE(OP_GETCONST, BB) {\n      mrb_value v = mrb_vm_const_get(mrb, syms[b]);\n      regs[a] = v;\n      NEXT;\n    }\n\n    CASE(OP_SETCONST, BB) {\n      mrb_vm_const_set(mrb, syms[b], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETMCNST, BB) {\n      mrb_value v = mrb_const_get(mrb, regs[a], syms[b]);\n      regs[a] = v;\n      NEXT;\n    }\n\n    CASE(OP_SETMCNST, BB) {\n      mrb_const_set(mrb, regs[a+1], syms[b], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETUPVAR, BBB) {\n      mrb_value *regs_a = regs + a;\n      struct REnv *e = uvenv(mrb, c);\n\n      if (e && b < MRB_ENV_LEN(e)) {\n        *regs_a = e->stack[b];\n      }\n      else {\n        *regs_a = mrb_nil_value();\n      }\n      NEXT;\n    }\n\n    CASE(OP_SETUPVAR, BBB) {\n      struct REnv *e = uvenv(mrb, c);\n\n      if (e) {\n        mrb_value *regs_a = regs + a;\n\n        if (b < MRB_ENV_LEN(e)) {\n          e->stack[b] = *regs_a;\n          mrb_write_barrier(mrb, (struct RBasic*)e);\n        }\n      }\n      NEXT;\n    }\n\n    CASE(OP_JMP, S) {\n      pc += (int16_t)a;\n      JUMP;\n    }\n    CASE(OP_JMPIF, BS) {\n      if (mrb_test(regs[a])) {\n        pc += (int16_t)b;\n        JUMP;\n      }\n      NEXT;\n    }\n    CASE(OP_JMPNOT, BS) {\n      if (!mrb_test(regs[a])) {\n        pc += (int16_t)b;\n        JUMP;\n      }\n      NEXT;\n    }\n    CASE(OP_JMPNIL, BS) {\n      if (mrb_nil_p(regs[a])) {\n        pc += (int16_t)b;\n        JUMP;\n      }\n      NEXT;\n    }\n\n    CASE(OP_JMPUW, S) {\n      a = (uint32_t)((pc - irep->iseq) + (int16_t)a);\n      CHECKPOINT_RESTORE(RBREAK_TAG_JUMP) {\n        struct RBreak *brk = (struct RBreak*)mrb->exc;\n        mrb_value target = mrb_break_value_get(brk);\n        mrb_assert(mrb_integer_p(target));\n        a = (uint32_t)mrb_integer(target);\n        mrb_assert(a >= 0 && a < irep->ilen);\n      }\n      CHECKPOINT_MAIN(RBREAK_TAG_JUMP) {\n        ch = catch_handler_find(mrb, mrb->c->ci, pc, MRB_CATCH_FILTER_ENSURE);\n        if (ch) {\n          /* avoiding a jump from a catch handler into the same handler */\n          if (a < mrb_irep_catch_handler_unpack(ch->begin) || a >= mrb_irep_catch_handler_unpack(ch->end)) {\n            THROW_TAGGED_BREAK(mrb, RBREAK_TAG_JUMP, proc, mrb_fixnum_value(a));\n          }\n        }\n      }\n      CHECKPOINT_END(RBREAK_TAG_JUMP);\n\n      mrb->exc = NULL; /* clear break object */\n      pc = irep->iseq + a;\n      JUMP;\n    }\n\n    CASE(OP_EXCEPT, B) {\n      mrb_value exc;\n\n      if (mrb->exc == NULL) {\n        exc = mrb_nil_value();\n      }\n      else {\n        switch (mrb->exc->tt) {\n        case MRB_TT_BREAK:\n        case MRB_TT_EXCEPTION:\n          exc = mrb_obj_value(mrb->exc);\n          break;\n        default:\n          mrb_assert(!\"bad mrb_type\");\n          exc = mrb_nil_value();\n          break;\n        }\n        mrb->exc = NULL;\n      }\n      regs[a] = exc;\n      NEXT;\n    }\n    CASE(OP_RESCUE, BB) {\n      mrb_value exc = regs[a];  /* exc on stack */\n      mrb_value e = regs[b];\n      struct RClass *ec;\n\n      switch (mrb_type(e)) {\n      case MRB_TT_CLASS:\n      case MRB_TT_MODULE:\n        break;\n      default:\n        {\n          mrb_value exc;\n\n          exc = mrb_exc_new_lit(mrb, E_TYPE_ERROR,\n                                    \"class or module required for rescue clause\");\n          mrb_exc_set(mrb, exc);\n          goto L_RAISE;\n        }\n      }\n      ec = mrb_class_ptr(e);\n      regs[b] = mrb_bool_value(mrb_obj_is_kind_of(mrb, exc, ec));\n      NEXT;\n    }\n\n    CASE(OP_RAISEIF, B) {\n      mrb_value exc = regs[a];\n      if (mrb_break_p(exc)) {\n        mrb->exc = mrb_obj_ptr(exc);\n        goto L_BREAK;\n      }\n      mrb_exc_set(mrb, exc);\n      if (mrb->exc) {\n        goto L_RAISE;\n      }\n      NEXT;\n    }\n\n    CASE(OP_SSEND, BBB) {\n      regs[a] = regs[0];\n      insn = OP_SEND;\n    }\n    goto L_SENDB;\n\n    CASE(OP_SSENDB, BBB) {\n      regs[a] = regs[0];\n    }\n    goto L_SENDB;\n\n    CASE(OP_SEND, BBB)\n    goto L_SENDB;\n\n    L_SEND_SYM:\n    c = 1;\n    /* push nil after arguments */\n    SET_NIL_VALUE(regs[a+2]);\n    goto L_SENDB_SYM;\n\n    CASE(OP_SENDB, BBB)\n    L_SENDB:\n    mid = syms[b];\n    L_SENDB_SYM:\n    {\n      mrb_callinfo *ci = mrb->c->ci;\n      mrb_method_t m;\n      struct RClass *cls;\n      mrb_value recv, blk;\n\n      ARGUMENT_NORMALIZE(a, &c, insn);\n\n      recv = regs[a];\n      cls = mrb_class(mrb, recv);\n      m = mrb_method_search_vm(mrb, &cls, mid);\n      if (MRB_METHOD_UNDEF_P(m)) {\n        m = prepare_missing(mrb, recv, mid, &cls, a, &c, blk, 0);\n        mid = MRB_SYM(method_missing);\n      }\n\n      /* push callinfo */\n      ci = cipush(mrb, a, 0, cls, NULL, mid, c);\n\n      if (MRB_METHOD_CFUNC_P(m)) {\n        if (MRB_METHOD_PROC_P(m)) {\n          struct RProc *p = MRB_METHOD_PROC(m);\n\n          mrb_vm_ci_proc_set(ci, p);\n          recv = p->body.func(mrb, recv);\n        }\n        else {\n          if (MRB_METHOD_NOARG_P(m)) {\n            check_method_noarg(mrb, ci);\n          }\n          recv = MRB_METHOD_FUNC(m)(mrb, recv);\n        }\n        mrb_gc_arena_shrink(mrb, ai);\n        if (mrb->exc) goto L_RAISE;\n        ci = mrb->c->ci;\n        if (mrb_proc_p(blk)) {\n          struct RProc *p = mrb_proc_ptr(blk);\n          if (p && !MRB_PROC_STRICT_P(p) && MRB_PROC_ENV(p) == mrb_vm_ci_env(&ci[-1])) {\n            p->flags |= MRB_PROC_ORPHAN;\n          }\n        }\n        if (!ci->u.target_class) { /* return from context modifying method (resume/yield) */\n          if (ci->cci == CINFO_RESUMED) {\n            mrb->jmp = prev_jmp;\n            return recv;\n          }\n          else {\n            mrb_assert(!MRB_PROC_CFUNC_P(ci[-1].proc));\n            proc = ci[-1].proc;\n            irep = proc->body.irep;\n            pool = irep->pool;\n            syms = irep->syms;\n          }\n        }\n        ci->stack[0] = recv;\n        /* pop stackpos */\n        ci = cipop(mrb);\n        pc = ci->pc;\n      }\n      else {\n        /* setup environment for calling method */\n        mrb_vm_ci_proc_set(ci, (proc = MRB_METHOD_PROC(m)));\n        irep = proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n        mrb_stack_extend(mrb, (irep->nregs < 4) ? 4 : irep->nregs);\n        pc = irep->iseq;\n      }\n    }\n    JUMP;\n\n    CASE(OP_CALL, Z) {\n      mrb_callinfo *ci = mrb->c->ci;\n      mrb_value recv = ci->stack[0];\n      struct RProc *m = mrb_proc_ptr(recv);\n\n      /* replace callinfo */\n      ci->u.target_class = MRB_PROC_TARGET_CLASS(m);\n      mrb_vm_ci_proc_set(ci, m);\n      if (MRB_PROC_ENV_P(m)) {\n        ci->mid = MRB_PROC_ENV(m)->mid;\n      }\n\n      /* prepare stack */\n      if (MRB_PROC_CFUNC_P(m)) {\n        recv = MRB_PROC_CFUNC(m)(mrb, recv);\n        mrb_gc_arena_shrink(mrb, ai);\n        if (mrb->exc) goto L_RAISE;\n        /* pop stackpos */\n        ci = cipop(mrb);\n        pc = ci->pc;\n        ci[1].stack[0] = recv;\n        irep = mrb->c->ci->proc->body.irep;\n      }\n      else {\n        /* setup environment for calling method */\n        proc = m;\n        irep = m->body.irep;\n        if (!irep) {\n          mrb->c->ci->stack[0] = mrb_nil_value();\n          a = 0;\n          c = OP_R_NORMAL;\n          goto L_OP_RETURN_BODY;\n        }\n        mrb_int nargs = mrb_ci_bidx(ci)+1;\n        if (nargs < irep->nregs) {\n          mrb_stack_extend(mrb, irep->nregs);\n          stack_clear(regs+nargs, irep->nregs-nargs);\n        }\n        if (MRB_PROC_ENV_P(m)) {\n          regs[0] = MRB_PROC_ENV(m)->stack[0];\n        }\n        pc = irep->iseq;\n      }\n      pool = irep->pool;\n      syms = irep->syms;\n      JUMP;\n    }\n\n    CASE(OP_SUPER, BB) {\n      mrb_method_t m;\n      struct RClass *cls;\n      mrb_callinfo *ci = mrb->c->ci;\n      mrb_value recv, blk;\n      const struct RProc *p = ci->proc;\n      mrb_sym mid = ci->mid;\n      struct RClass* target_class = MRB_PROC_TARGET_CLASS(p);\n\n      if (MRB_PROC_ENV_P(p) && p->e.env->mid && p->e.env->mid != mid) { /* alias support */\n        mid = p->e.env->mid;    /* restore old mid */\n      }\n\n      if (mid == 0 || !target_class) {\n        mrb_value exc = mrb_exc_new_lit(mrb, E_NOMETHOD_ERROR, \"super called outside of method\");\n        mrb_exc_set(mrb, exc);\n        goto L_RAISE;\n      }\n      if (target_class->flags & MRB_FL_CLASS_IS_PREPENDED) {\n        target_class = mrb_vm_ci_target_class(ci);\n      }\n      else if (target_class->tt == MRB_TT_MODULE) {\n        target_class = mrb_vm_ci_target_class(ci);\n        if (target_class->tt != MRB_TT_ICLASS) {\n          goto super_typeerror;\n        }\n      }\n      recv = regs[0];\n      if (!mrb_obj_is_kind_of(mrb, recv, target_class)) {\n      super_typeerror: ;\n        mrb_value exc = mrb_exc_new_lit(mrb, E_TYPE_ERROR,\n                                            \"self has wrong type to call super in this context\");\n        mrb_exc_set(mrb, exc);\n        goto L_RAISE;\n      }\n\n      ARGUMENT_NORMALIZE(a, &b, OP_SUPER);\n\n      cls = target_class->super;\n      m = mrb_method_search_vm(mrb, &cls, mid);\n      if (MRB_METHOD_UNDEF_P(m)) {\n        m = prepare_missing(mrb, recv, mid, &cls, a, &b, blk, 1);\n        mid = MRB_SYM(method_missing);\n      }\n\n      /* push callinfo */\n      ci = cipush(mrb, a, 0, cls, NULL, mid, b);\n\n      /* prepare stack */\n      ci->stack[0] = recv;\n\n      if (MRB_METHOD_CFUNC_P(m)) {\n        mrb_value v;\n\n        if (MRB_METHOD_PROC_P(m)) {\n          mrb_vm_ci_proc_set(ci, MRB_METHOD_PROC(m));\n        }\n        v = MRB_METHOD_CFUNC(m)(mrb, recv);\n        mrb_gc_arena_restore(mrb, ai);\n        if (mrb->exc) goto L_RAISE;\n        ci = mrb->c->ci;\n        mrb_assert(!mrb_break_p(v));\n        if (!mrb_vm_ci_target_class(ci)) { /* return from context modifying method (resume/yield) */\n          if (ci->cci == CINFO_RESUMED) {\n            mrb->jmp = prev_jmp;\n            return v;\n          }\n          else {\n            mrb_assert(!MRB_PROC_CFUNC_P(ci[-1].proc));\n            proc = ci[-1].proc;\n            irep = proc->body.irep;\n            pool = irep->pool;\n            syms = irep->syms;\n          }\n        }\n        mrb->c->ci->stack[0] = v;\n        ci = cipop(mrb);\n        pc = ci->pc;\n      }\n      else {\n        /* setup environment for calling method */\n        mrb_vm_ci_proc_set(ci, (proc = MRB_METHOD_PROC(m)));\n        irep = proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n        mrb_stack_extend(mrb, (irep->nregs < 4) ? 4 : irep->nregs);\n        pc = irep->iseq;\n      }\n      JUMP;\n    }\n\n    CASE(OP_ARGARY, BS) {\n      mrb_int m1 = (b>>11)&0x3f;\n      mrb_int r  = (b>>10)&0x1;\n      mrb_int m2 = (b>>5)&0x1f;\n      mrb_int kd = (b>>4)&0x1;\n      mrb_int lv = (b>>0)&0xf;\n      mrb_value *stack;\n\n      if (mrb->c->ci->mid == 0 || mrb_vm_ci_target_class(mrb->c->ci) == NULL) {\n        mrb_value exc;\n\n      L_NOSUPER:\n        exc = mrb_exc_new_lit(mrb, E_NOMETHOD_ERROR, \"super called outside of method\");\n        mrb_exc_set(mrb, exc);\n        goto L_RAISE;\n      }\n      if (lv == 0) stack = regs + 1;\n      else {\n        struct REnv *e = uvenv(mrb, lv-1);\n        if (!e) goto L_NOSUPER;\n        if (MRB_ENV_LEN(e) <= m1+r+m2+1)\n          goto L_NOSUPER;\n        stack = e->stack + 1;\n      }\n      if (r == 0) {\n        regs[a] = mrb_ary_new_from_values(mrb, m1+m2, stack);\n      }\n      else {\n        mrb_value *pp = NULL;\n        struct RArray *rest;\n        mrb_int len = 0;\n\n        if (mrb_array_p(stack[m1])) {\n          struct RArray *ary = mrb_ary_ptr(stack[m1]);\n\n          pp = ARY_PTR(ary);\n          len = ARY_LEN(ary);\n        }\n        regs[a] = mrb_ary_new_capa(mrb, m1+len+m2);\n        rest = mrb_ary_ptr(regs[a]);\n        if (m1 > 0) {\n          stack_copy(ARY_PTR(rest), stack, m1);\n        }\n        if (len > 0) {\n          stack_copy(ARY_PTR(rest)+m1, pp, len);\n        }\n        if (m2 > 0) {\n          stack_copy(ARY_PTR(rest)+m1+len, stack+m1+1, m2);\n        }\n        ARY_SET_LEN(rest, m1+len+m2);\n      }\n      if (kd) {\n        regs[a+1] = stack[m1+r+m2];\n        regs[a+2] = stack[m1+r+m2+1];\n      }\n      else {\n        regs[a+1] = stack[m1+r+m2];\n      }\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_ENTER, W) {\n      mrb_int m1 = MRB_ASPEC_REQ(a);\n      mrb_int o  = MRB_ASPEC_OPT(a);\n      mrb_int r  = MRB_ASPEC_REST(a);\n      mrb_int m2 = MRB_ASPEC_POST(a);\n      mrb_int kd = (MRB_ASPEC_KEY(a) > 0 || MRB_ASPEC_KDICT(a))? 1 : 0;\n      /* unused\n      int b  = MRB_ASPEC_BLOCK(a);\n      */\n      mrb_int const len = m1 + o + r + m2;\n\n      mrb_callinfo *ci = mrb->c->ci;\n      mrb_int argc = ci->n;\n      mrb_value *argv = regs+1;\n      mrb_value * const argv0 = argv;\n      mrb_int const kw_pos = len + kd;    /* where kwhash should be */\n      mrb_int const blk_pos = kw_pos + 1; /* where block should be */\n      mrb_value blk = regs[mrb_ci_bidx(ci)];\n      mrb_value kdict = mrb_nil_value();\n\n      /* keyword arguments */\n      if (ci->nk > 0) {\n        mrb_int kidx = mrb_ci_kidx(ci);\n        kdict = regs[kidx];\n        if (!mrb_hash_p(kdict) || mrb_hash_size(mrb, kdict) == 0) {\n          kdict = mrb_nil_value();\n          ci->nk = 0;\n        }\n      }\n      if (!kd && !mrb_nil_p(kdict)) {\n        if (argc < 14) {\n          ci->n++;\n          argc++;    /* include kdict in normal arguments */\n        }\n        else if (argc == 14) {\n          /* pack arguments and kdict */\n          regs[1] = mrb_ary_new_from_values(mrb, argc+1, &regs[1]);\n          argc = ci->n = 15;\n        }\n        else {/* argc == 15 */\n          /* push kdict to packed arguments */\n          mrb_ary_push(mrb, regs[1], regs[2]);\n        }\n        ci->nk = 0;\n      }\n      if (kd && MRB_ASPEC_KEY(a) > 0 && mrb_hash_p(kdict)) {\n        kdict = mrb_hash_dup(mrb, kdict);\n      }\n\n      /* arguments is passed with Array */\n      if (argc == 15) {\n        struct RArray *ary = mrb_ary_ptr(regs[1]);\n        argv = ARY_PTR(ary);\n        argc = (int)ARY_LEN(ary);\n        mrb_gc_protect(mrb, regs[1]);\n      }\n\n      /* strict argument check */\n      if (ci->proc && MRB_PROC_STRICT_P(ci->proc)) {\n        if (argc < m1 + m2 || (r == 0 && argc > len)) {\n          argnum_error(mrb, m1+m2);\n          goto L_RAISE;\n        }\n      }\n      /* extract first argument array to arguments */\n      else if (len > 1 && argc == 1 && mrb_array_p(argv[0])) {\n        mrb_gc_protect(mrb, argv[0]);\n        argc = (int)RARRAY_LEN(argv[0]);\n        argv = RARRAY_PTR(argv[0]);\n      }\n\n      /* rest arguments */\n      mrb_value rest = mrb_nil_value();\n      if (argc < len) {\n        mrb_int mlen = m2;\n        if (argc < m1+m2) {\n          mlen = m1 < argc ? argc - m1 : 0;\n        }\n\n        /* copy mandatory and optional arguments */\n        if (argv0 != argv && argv) {\n          value_move(&regs[1], argv, argc-mlen); /* m1 + o */\n        }\n        if (argc < m1) {\n          stack_clear(&regs[argc+1], m1-argc);\n        }\n        /* copy post mandatory arguments */\n        if (mlen) {\n          value_move(&regs[len-m2+1], &argv[argc-mlen], mlen);\n        }\n        if (mlen < m2) {\n          stack_clear(&regs[len-m2+mlen+1], m2-mlen);\n        }\n        /* initialize rest arguments with empty Array */\n        if (r) {\n          rest = mrb_ary_new_capa(mrb, 0);\n          regs[m1+o+1] = rest;\n        }\n        /* skip initializer of passed arguments */\n        if (o > 0 && argc > m1+m2)\n          pc += (argc - m1 - m2)*3;\n      }\n      else {\n        mrb_int rnum = 0;\n        if (argv0 != argv) {\n          value_move(&regs[1], argv, m1+o);\n        }\n        if (r) {\n          rnum = argc-m1-o-m2;\n          rest = mrb_ary_new_from_values(mrb, rnum, argv+m1+o);\n          regs[m1+o+1] = rest;\n        }\n        if (m2 > 0 && argc-m2 > m1) {\n          value_move(&regs[m1+o+r+1], &argv[m1+o+rnum], m2);\n        }\n        pc += o*3;\n      }\n\n      /* need to be update blk first to protect blk from GC */\n      regs[blk_pos] = blk;              /* move block */\n      if (kd) {\n        if (mrb_nil_p(kdict))\n          kdict = mrb_hash_new_capa(mrb, 0);\n        regs[kw_pos] = kdict;           /* set kwhash */\n      }\n\n      /* format arguments for generated code */\n      mrb->c->ci->n = len;\n\n      /* clear local (but non-argument) variables */\n      if (irep->nlocals-blk_pos-1 > 0) {\n        stack_clear(&regs[blk_pos+1], irep->nlocals-blk_pos-1);\n      }\n      JUMP;\n    }\n\n    CASE(OP_KARG, BB) {\n      mrb_value k = mrb_symbol_value(syms[b]);\n      mrb_int kidx = mrb_ci_kidx(mrb->c->ci);\n      mrb_value kdict, v;\n\n      if (kidx < 0 || !mrb_hash_p(kdict=regs[kidx]) || !mrb_hash_key_p(mrb, kdict, k)) {\n        mrb_value str = mrb_format(mrb, \"missing keyword: %v\", k);\n        mrb_exc_set(mrb, mrb_exc_new_str(mrb, E_ARGUMENT_ERROR, str));\n        goto L_RAISE;\n      }\n      v = mrb_hash_get(mrb, kdict, k);\n      regs[a] = v;\n      mrb_hash_delete_key(mrb, kdict, k);\n      NEXT;\n    }\n\n    CASE(OP_KEY_P, BB) {\n      mrb_value k = mrb_symbol_value(syms[b]);\n      mrb_int kidx = mrb_ci_kidx(mrb->c->ci);\n      mrb_value kdict;\n      mrb_bool key_p = FALSE;\n\n      if (kidx >= 0 && mrb_hash_p(kdict=regs[kidx])) {\n        key_p = mrb_hash_key_p(mrb, kdict, k);\n      }\n      regs[a] = mrb_bool_value(key_p);\n      NEXT;\n    }\n\n    CASE(OP_KEYEND, Z) {\n      mrb_int kidx = mrb_ci_kidx(mrb->c->ci);\n      mrb_value kdict;\n\n      if (kidx >= 0 && mrb_hash_p(kdict=regs[kidx]) && !mrb_hash_empty_p(mrb, kdict)) {\n        mrb_value keys = mrb_hash_keys(mrb, kdict);\n        mrb_value key1 = RARRAY_PTR(keys)[0];\n        mrb_value str = mrb_format(mrb, \"unknown keyword: %v\", key1);\n        mrb_exc_set(mrb, mrb_exc_new_str(mrb, E_ARGUMENT_ERROR, str));\n        goto L_RAISE;\n      }\n      NEXT;\n    }\n\n    CASE(OP_BREAK, B) {\n      c = OP_R_BREAK;\n      goto L_RETURN;\n    }\n    CASE(OP_RETURN_BLK, B) {\n      c = OP_R_RETURN;\n      goto L_RETURN;\n    }\n    CASE(OP_RETURN, B)\n    c = OP_R_NORMAL;\n    L_RETURN:\n    {\n      mrb_callinfo *ci;\n\n      ci = mrb->c->ci;\n      if (ci->mid) {\n        mrb_value blk = regs[mrb_ci_bidx(ci)];\n\n        if (mrb_proc_p(blk)) {\n          struct RProc *p = mrb_proc_ptr(blk);\n\n          if (!MRB_PROC_STRICT_P(p) &&\n              ci > mrb->c->cibase && MRB_PROC_ENV(p) == mrb_vm_ci_env(&ci[-1])) {\n            p->flags |= MRB_PROC_ORPHAN;\n          }\n        }\n      }\n\n      if (mrb->exc) {\n      L_RAISE:\n        ci = mrb->c->ci;\n        if (ci == mrb->c->cibase) {\n          ch = catch_handler_find(mrb, ci, pc, MRB_CATCH_FILTER_ALL);\n          if (ch == NULL) goto L_FTOP;\n          goto L_CATCH;\n        }\n        while ((ch = catch_handler_find(mrb, ci, pc, MRB_CATCH_FILTER_ALL)) == NULL) {\n          ci = cipop(mrb);\n          if (ci[1].cci == CINFO_SKIP && prev_jmp) {\n            mrb->jmp = prev_jmp;\n            MRB_THROW(prev_jmp);\n          }\n          pc = ci[0].pc;\n          if (ci == mrb->c->cibase) {\n            ch = catch_handler_find(mrb, ci, pc, MRB_CATCH_FILTER_ALL);\n            if (ch == NULL) {\n            L_FTOP:             /* fiber top */\n              if (mrb->c == mrb->root_c) {\n                mrb->c->ci->stack = mrb->c->stbase;\n                goto L_STOP;\n              }\n              else {\n                struct mrb_context *c = mrb->c;\n\n                c->status = MRB_FIBER_TERMINATED;\n                mrb->c = c->prev;\n                c->prev = NULL;\n                goto L_RAISE;\n              }\n            }\n            break;\n          }\n        }\n      L_CATCH:\n        if (ch == NULL) goto L_STOP;\n        if (FALSE) {\n        L_CATCH_TAGGED_BREAK: /* from THROW_TAGGED_BREAK() or UNWIND_ENSURE() */\n          ci = mrb->c->ci;\n        }\n        proc = ci->proc;\n        irep = proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n        mrb_stack_extend(mrb, irep->nregs);\n        pc = irep->iseq + mrb_irep_catch_handler_unpack(ch->target);\n      }\n      else {\n        mrb_int acc;\n        mrb_value v;\n\n        ci = mrb->c->ci;\n        v = regs[a];\n        mrb_gc_protect(mrb, v);\n        switch (c) {\n        case OP_R_RETURN:\n          /* Fall through to OP_R_NORMAL otherwise */\n          if (ci->cci == CINFO_NONE && MRB_PROC_ENV_P(proc) && !MRB_PROC_STRICT_P(proc)) {\n            const struct RProc *dst;\n            mrb_callinfo *cibase;\n            cibase = mrb->c->cibase;\n            dst = top_proc(mrb, proc);\n\n            if (MRB_PROC_ENV_P(dst)) {\n              struct REnv *e = MRB_PROC_ENV(dst);\n\n              if (!MRB_ENV_ONSTACK_P(e) || (e->cxt && e->cxt != mrb->c)) {\n                localjump_error(mrb, LOCALJUMP_ERROR_RETURN);\n                goto L_RAISE;\n              }\n            }\n            /* check jump destination */\n            while (cibase <= ci && ci->proc != dst) {\n              if (ci->cci > CINFO_NONE) { /* jump cross C boundary */\n                localjump_error(mrb, LOCALJUMP_ERROR_RETURN);\n                goto L_RAISE;\n              }\n              ci--;\n            }\n            if (ci <= cibase) { /* no jump destination */\n              localjump_error(mrb, LOCALJUMP_ERROR_RETURN);\n              goto L_RAISE;\n            }\n            ci = mrb->c->ci;\n            while (cibase <= ci && ci->proc != dst) {\n              CHECKPOINT_RESTORE(RBREAK_TAG_RETURN_BLOCK) {\n                cibase = mrb->c->cibase;\n                dst = top_proc(mrb, proc);\n              }\n              CHECKPOINT_MAIN(RBREAK_TAG_RETURN_BLOCK) {\n                UNWIND_ENSURE(mrb, ci, pc, RBREAK_TAG_RETURN_BLOCK, proc, v);\n              }\n              CHECKPOINT_END(RBREAK_TAG_RETURN_BLOCK);\n              ci = cipop(mrb);\n              pc = ci->pc;\n            }\n            proc = ci->proc;\n            mrb->exc = NULL; /* clear break object */\n            break;\n          }\n          /* fallthrough */\n        case OP_R_NORMAL:\n        NORMAL_RETURN:\n          if (ci == mrb->c->cibase) {\n            struct mrb_context *c;\n            c = mrb->c;\n\n            if (!c->prev) { /* toplevel return */\n              regs[irep->nlocals] = v;\n              goto CHECKPOINT_LABEL_MAKE(RBREAK_TAG_STOP);\n            }\n            if (!c->vmexec && c->prev->ci == c->prev->cibase) {\n              mrb_value exc = mrb_exc_new_lit(mrb, E_FIBER_ERROR, \"double resume\");\n              mrb_exc_set(mrb, exc);\n              goto L_RAISE;\n            }\n            CHECKPOINT_RESTORE(RBREAK_TAG_RETURN_TOPLEVEL) {\n              c = mrb->c;\n            }\n            CHECKPOINT_MAIN(RBREAK_TAG_RETURN_TOPLEVEL) {\n              UNWIND_ENSURE(mrb, ci, pc, RBREAK_TAG_RETURN_TOPLEVEL, proc, v);\n            }\n            CHECKPOINT_END(RBREAK_TAG_RETURN_TOPLEVEL);\n            /* automatic yield at the end */\n            c->status = MRB_FIBER_TERMINATED;\n            mrb->c = c->prev;\n            mrb->c->status = MRB_FIBER_RUNNING;\n            c->prev = NULL;\n            if (c->vmexec) {\n              mrb_gc_arena_restore(mrb, ai);\n              c->vmexec = FALSE;\n              mrb->jmp = prev_jmp;\n              return v;\n            }\n            ci = mrb->c->ci;\n          }\n          CHECKPOINT_RESTORE(RBREAK_TAG_RETURN) {\n            /* do nothing */\n          }\n          CHECKPOINT_MAIN(RBREAK_TAG_RETURN) {\n            UNWIND_ENSURE(mrb, ci, pc, RBREAK_TAG_RETURN, proc, v);\n          }\n          CHECKPOINT_END(RBREAK_TAG_RETURN);\n          mrb->exc = NULL; /* clear break object */\n          break;\n        case OP_R_BREAK:\n          if (MRB_PROC_STRICT_P(proc)) goto NORMAL_RETURN;\n          if (MRB_PROC_ORPHAN_P(proc)) {\n            mrb_value exc;\n\n          L_BREAK_ERROR:\n            exc = mrb_exc_new_lit(mrb, E_LOCALJUMP_ERROR,\n                                      \"break from proc-closure\");\n            mrb_exc_set(mrb, exc);\n            goto L_RAISE;\n          }\n          if (!MRB_PROC_ENV_P(proc) || !MRB_ENV_ONSTACK_P(MRB_PROC_ENV(proc))) {\n            goto L_BREAK_ERROR;\n          }\n          else {\n            struct REnv *e = MRB_PROC_ENV(proc);\n\n            if (e->cxt != mrb->c) {\n              goto L_BREAK_ERROR;\n            }\n          }\n          CHECKPOINT_RESTORE(RBREAK_TAG_BREAK) {\n            /* do nothing */\n          }\n          CHECKPOINT_MAIN(RBREAK_TAG_BREAK) {\n            UNWIND_ENSURE(mrb, ci, pc, RBREAK_TAG_BREAK, proc, v);\n          }\n          CHECKPOINT_END(RBREAK_TAG_BREAK);\n          /* break from fiber block */\n          if (ci == mrb->c->cibase && ci->pc) {\n            struct mrb_context *c = mrb->c;\n\n            mrb->c = c->prev;\n            c->prev = NULL;\n            ci = mrb->c->ci;\n          }\n          if (ci->cci > CINFO_NONE) {\n            ci = cipop(mrb);\n            mrb_gc_arena_restore(mrb, ai);\n            mrb->c->vmexec = FALSE;\n            mrb->exc = (struct RObject*)break_new(mrb, RBREAK_TAG_BREAK, proc, v);\n            mrb->jmp = prev_jmp;\n            MRB_THROW(prev_jmp);\n          }\n          if (FALSE) {\n            struct RBreak *brk;\n\n          L_BREAK:\n            brk = (struct RBreak*)mrb->exc;\n            proc = mrb_break_proc_get(brk);\n            v = mrb_break_value_get(brk);\n            ci = mrb->c->ci;\n\n            switch (mrb_break_tag_get(brk)) {\n#define DISPATCH_CHECKPOINTS(n, i) case n: goto CHECKPOINT_LABEL_MAKE(n);\n              RBREAK_TAG_FOREACH(DISPATCH_CHECKPOINTS)\n#undef DISPATCH_CHECKPOINTS\n              default:\n                mrb_assert(!\"wrong break tag\");\n            }\n          }\n          while (mrb->c->cibase < ci && ci[-1].proc != proc->upper) {\n            if (ci[-1].cci == CINFO_SKIP) {\n              goto L_BREAK_ERROR;\n            }\n            CHECKPOINT_RESTORE(RBREAK_TAG_BREAK_UPPER) {\n              /* do nothing */\n            }\n            CHECKPOINT_MAIN(RBREAK_TAG_BREAK_UPPER) {\n              UNWIND_ENSURE(mrb, ci, pc, RBREAK_TAG_BREAK_UPPER, proc, v);\n            }\n            CHECKPOINT_END(RBREAK_TAG_BREAK_UPPER);\n            ci = cipop(mrb);\n            pc = ci->pc;\n          }\n          CHECKPOINT_RESTORE(RBREAK_TAG_BREAK_INTARGET) {\n            /* do nothing */\n          }\n          CHECKPOINT_MAIN(RBREAK_TAG_BREAK_INTARGET) {\n            UNWIND_ENSURE(mrb, ci, pc, RBREAK_TAG_BREAK_INTARGET, proc, v);\n          }\n          CHECKPOINT_END(RBREAK_TAG_BREAK_INTARGET);\n          if (ci == mrb->c->cibase) {\n            goto L_BREAK_ERROR;\n          }\n          mrb->exc = NULL; /* clear break object */\n          break;\n        default:\n          /* cannot happen */\n          break;\n        }\n        mrb_assert(ci == mrb->c->ci);\n        mrb_assert(mrb->exc == NULL);\n\n        if (mrb->c->vmexec && !mrb_vm_ci_target_class(ci)) {\n          mrb_gc_arena_restore(mrb, ai);\n          mrb->c->vmexec = FALSE;\n          mrb->jmp = prev_jmp;\n          return v;\n        }\n        acc = ci->cci;\n        ci = cipop(mrb);\n        if (acc == CINFO_SKIP || acc == CINFO_DIRECT) {\n          mrb_gc_arena_restore(mrb, ai);\n          mrb->jmp = prev_jmp;\n          return v;\n        }\n        pc = ci->pc;\n        DEBUG(fprintf(stderr, \"from :%s\\n\", mrb_sym_name(mrb, ci->mid)));\n        proc = ci->proc;\n        irep = proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n\n        ci[1].stack[0] = v;\n        mrb_gc_arena_restore(mrb, ai);\n      }\n      JUMP;\n    }\n\n    CASE(OP_BLKPUSH, BS) {\n      int m1 = (b>>11)&0x3f;\n      int r  = (b>>10)&0x1;\n      int m2 = (b>>5)&0x1f;\n      int kd = (b>>4)&0x1;\n      int lv = (b>>0)&0xf;\n      mrb_value *stack;\n\n      if (lv == 0) stack = regs + 1;\n      else {\n        struct REnv *e = uvenv(mrb, lv-1);\n        if (!e || (!MRB_ENV_ONSTACK_P(e) && e->mid == 0) ||\n            MRB_ENV_LEN(e) <= m1+r+m2+1) {\n          localjump_error(mrb, LOCALJUMP_ERROR_YIELD);\n          goto L_RAISE;\n        }\n        stack = e->stack + 1;\n      }\n      if (mrb_nil_p(stack[m1+r+m2+kd])) {\n        localjump_error(mrb, LOCALJUMP_ERROR_YIELD);\n        goto L_RAISE;\n      }\n      regs[a] = stack[m1+r+m2+kd];\n      NEXT;\n    }\n\n  L_INT_OVERFLOW:\n    {\n      mrb_value exc = mrb_exc_new_lit(mrb, E_RANGE_ERROR, \"integer overflow\");\n      mrb_exc_set(mrb, exc);\n    }\n    goto L_RAISE;\n\n#define TYPES2(a,b) ((((uint16_t)(a))<<8)|(((uint16_t)(b))&0xff))\n#define OP_MATH(op_name)                                                    \\\n  /* need to check if op is overridden */                                   \\\n  switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {                  \\\n    OP_MATH_CASE_INTEGER(op_name);                                          \\\n    OP_MATH_CASE_FLOAT(op_name, integer, float);                            \\\n    OP_MATH_CASE_FLOAT(op_name, float,  integer);                           \\\n    OP_MATH_CASE_FLOAT(op_name, float,  float);                             \\\n    OP_MATH_CASE_STRING_##op_name();                                        \\\n    default:                                                                \\\n      mid = MRB_OPSYM(op_name);                                             \\\n      goto L_SEND_SYM;                                                      \\\n  }                                                                         \\\n  NEXT;\n#define OP_MATH_CASE_INTEGER(op_name)                                       \\\n  case TYPES2(MRB_TT_INTEGER, MRB_TT_INTEGER):                              \\\n    {                                                                       \\\n      mrb_int x = mrb_integer(regs[a]), y = mrb_integer(regs[a+1]), z;      \\\n      if (mrb_int_##op_name##_overflow(x, y, &z))                           \\\n        OP_MATH_OVERFLOW_INT();                                             \\\n      else                                                                  \\\n        SET_INT_VALUE(mrb,regs[a], z);                                      \\\n    }                                                                       \\\n    break\n#ifdef MRB_NO_FLOAT\n#define OP_MATH_CASE_FLOAT(op_name, t1, t2) (void)0\n#else\n#define OP_MATH_CASE_FLOAT(op_name, t1, t2)                                     \\\n  case TYPES2(OP_MATH_TT_##t1, OP_MATH_TT_##t2):                                \\\n    {                                                                           \\\n      mrb_float z = mrb_##t1(regs[a]) OP_MATH_OP_##op_name mrb_##t2(regs[a+1]); \\\n      SET_FLOAT_VALUE(mrb, regs[a], z);                                         \\\n    }                                                                           \\\n    break\n#endif\n#define OP_MATH_OVERFLOW_INT() goto L_INT_OVERFLOW\n#define OP_MATH_CASE_STRING_add()                                           \\\n  case TYPES2(MRB_TT_STRING, MRB_TT_STRING):                                \\\n    regs[a] = mrb_str_plus(mrb, regs[a], regs[a+1]);                        \\\n    mrb_gc_arena_restore(mrb, ai);                                          \\\n    break\n#define OP_MATH_CASE_STRING_sub() (void)0\n#define OP_MATH_CASE_STRING_mul() (void)0\n#define OP_MATH_OP_add +\n#define OP_MATH_OP_sub -\n#define OP_MATH_OP_mul *\n#define OP_MATH_TT_integer MRB_TT_INTEGER\n#define OP_MATH_TT_float   MRB_TT_FLOAT\n\n    CASE(OP_ADD, B) {\n      OP_MATH(add);\n    }\n\n    CASE(OP_SUB, B) {\n      OP_MATH(sub);\n    }\n\n    CASE(OP_MUL, B) {\n      OP_MATH(mul);\n    }\n\n    CASE(OP_DIV, B) {\n#ifndef MRB_NO_FLOAT\n      mrb_float x, y, f;\n#endif\n\n      /* need to check if op is overridden */\n      switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\n      case TYPES2(MRB_TT_INTEGER,MRB_TT_INTEGER):\n        {\n          mrb_int x = mrb_integer(regs[a]);\n          mrb_int y = mrb_integer(regs[a+1]);\n          mrb_int div = mrb_div_int(mrb, x, y);\n          SET_INT_VALUE(mrb, regs[a], div);\n        }\n        NEXT;\n#ifndef MRB_NO_FLOAT\n      case TYPES2(MRB_TT_INTEGER,MRB_TT_FLOAT):\n        x = (mrb_float)mrb_integer(regs[a]);\n        y = mrb_float(regs[a+1]);\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_INTEGER):\n        x = mrb_float(regs[a]);\n        y = (mrb_float)mrb_integer(regs[a+1]);\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_FLOAT):\n        x = mrb_float(regs[a]);\n        y = mrb_float(regs[a+1]);\n        break;\n#endif\n      default:\n        mid = MRB_OPSYM(div);\n        goto L_SEND_SYM;\n      }\n\n#ifndef MRB_NO_FLOAT\n      f = mrb_div_float(x, y);\n      SET_FLOAT_VALUE(mrb, regs[a], f);\n#endif\n      NEXT;\n    }\n\n#define OP_MATHI(op_name)                                                   \\\n  /* need to check if op is overridden */                                   \\\n  switch (mrb_type(regs[a])) {                                              \\\n    OP_MATHI_CASE_INTEGER(op_name);                                         \\\n    OP_MATHI_CASE_FLOAT(op_name);                                           \\\n    default:                                                                \\\n      SET_INT_VALUE(mrb,regs[a+1], b);                                      \\\n      mid = MRB_OPSYM(op_name);                                             \\\n      goto L_SEND_SYM;                                                      \\\n  }                                                                         \\\n  NEXT;\n#define OP_MATHI_CASE_INTEGER(op_name)                                      \\\n  case MRB_TT_INTEGER:                                                      \\\n    {                                                                       \\\n      mrb_int x = mrb_integer(regs[a]), y = (mrb_int)b, z;                  \\\n      if (mrb_int_##op_name##_overflow(x, y, &z))                           \\\n        OP_MATH_OVERFLOW_INT();                                             \\\n      else                                                                  \\\n        SET_INT_VALUE(mrb,regs[a], z);                                      \\\n    }                                                                       \\\n    break\n#ifdef MRB_NO_FLOAT\n#define OP_MATHI_CASE_FLOAT(op_name) (void)0\n#else\n#define OP_MATHI_CASE_FLOAT(op_name)                                        \\\n  case MRB_TT_FLOAT:                                                        \\\n    {                                                                       \\\n      mrb_float z = mrb_float(regs[a]) OP_MATH_OP_##op_name b;              \\\n      SET_FLOAT_VALUE(mrb, regs[a], z);                                     \\\n    }                                                                       \\\n    break\n#endif\n\n    CASE(OP_ADDI, BB) {\n      OP_MATHI(add);\n    }\n\n    CASE(OP_SUBI, BB) {\n      OP_MATHI(sub);\n    }\n\n#define OP_CMP_BODY(op,v1,v2) (v1(regs[a]) op v2(regs[a+1]))\n\n#ifdef MRB_NO_FLOAT\n#define OP_CMP(op,sym) do {\\\n  int result;\\\n  /* need to check if - is overridden */\\\n  switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\\\n  case TYPES2(MRB_TT_INTEGER,MRB_TT_INTEGER):\\\n    result = OP_CMP_BODY(op,mrb_fixnum,mrb_fixnum);\\\n    break;\\\n  default:\\\n    mid = MRB_OPSYM(sym);\\\n    goto L_SEND_SYM;\\\n  }\\\n  if (result) {\\\n    SET_TRUE_VALUE(regs[a]);\\\n  }\\\n  else {\\\n    SET_FALSE_VALUE(regs[a]);\\\n  }\\\n} while(0)\n#else\n#define OP_CMP(op, sym) do {\\\n  int result;\\\n  /* need to check if - is overridden */\\\n  switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\\\n  case TYPES2(MRB_TT_INTEGER,MRB_TT_INTEGER):\\\n    result = OP_CMP_BODY(op,mrb_fixnum,mrb_fixnum);\\\n    break;\\\n  case TYPES2(MRB_TT_INTEGER,MRB_TT_FLOAT):\\\n    result = OP_CMP_BODY(op,mrb_fixnum,mrb_float);\\\n    break;\\\n  case TYPES2(MRB_TT_FLOAT,MRB_TT_INTEGER):\\\n    result = OP_CMP_BODY(op,mrb_float,mrb_fixnum);\\\n    break;\\\n  case TYPES2(MRB_TT_FLOAT,MRB_TT_FLOAT):\\\n    result = OP_CMP_BODY(op,mrb_float,mrb_float);\\\n    break;\\\n  default:\\\n    mid = MRB_OPSYM(sym);\\\n    goto L_SEND_SYM;\\\n  }\\\n  if (result) {\\\n    SET_TRUE_VALUE(regs[a]);\\\n  }\\\n  else {\\\n    SET_FALSE_VALUE(regs[a]);\\\n  }\\\n} while(0)\n#endif\n\n    CASE(OP_EQ, B) {\n      if (mrb_obj_eq(mrb, regs[a], regs[a+1])) {\n        SET_TRUE_VALUE(regs[a]);\n      }\n      else {\n        OP_CMP(==,eq);\n      }\n      NEXT;\n    }\n\n    CASE(OP_LT, B) {\n      OP_CMP(<,lt);\n      NEXT;\n    }\n\n    CASE(OP_LE, B) {\n      OP_CMP(<=,le);\n      NEXT;\n    }\n\n    CASE(OP_GT, B) {\n      OP_CMP(>,gt);\n      NEXT;\n    }\n\n    CASE(OP_GE, B) {\n      OP_CMP(>=,ge);\n      NEXT;\n    }\n\n    CASE(OP_ARRAY, BB) {\n      regs[a] = mrb_ary_new_from_values(mrb, b, &regs[a]);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n    CASE(OP_ARRAY2, BBB) {\n      regs[a] = mrb_ary_new_from_values(mrb, c, &regs[b]);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_ARYCAT, B) {\n      mrb_value splat = mrb_ary_splat(mrb, regs[a+1]);\n      if (mrb_nil_p(regs[a])) {\n        regs[a] = splat;\n      }\n      else {\n        mrb_assert(mrb_array_p(regs[a]));\n        mrb_ary_concat(mrb, regs[a], splat);\n      }\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_ARYPUSH, BB) {\n      mrb_assert(mrb_array_p(regs[a]));\n      for (mrb_int i=0; i<b; i++) {\n        mrb_ary_push(mrb, regs[a], regs[a+i+1]);\n      }\n      NEXT;\n    }\n\n    CASE(OP_ARYDUP, B) {\n      mrb_value ary = regs[a];\n      if (mrb_array_p(ary)) {\n        ary = mrb_ary_new_from_values(mrb, RARRAY_LEN(ary), RARRAY_PTR(ary));\n      }\n      else {\n        ary = mrb_ary_new_from_values(mrb, 1, &ary);\n      }\n      regs[a] = ary;\n      NEXT;\n    }\n\n    CASE(OP_AREF, BBB) {\n      mrb_value v = regs[b];\n\n      if (!mrb_array_p(v)) {\n        if (c == 0) {\n          regs[a] = v;\n        }\n        else {\n          SET_NIL_VALUE(regs[a]);\n        }\n      }\n      else {\n        v = mrb_ary_ref(mrb, v, c);\n        regs[a] = v;\n      }\n      NEXT;\n    }\n\n    CASE(OP_ASET, BBB) {\n      mrb_assert(mrb_array_p(regs[a]));\n      mrb_ary_set(mrb, regs[b], c, regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_APOST, BBB) {\n      mrb_value v = regs[a];\n      int pre  = b;\n      int post = c;\n      struct RArray *ary;\n      int len, idx;\n\n      if (!mrb_array_p(v)) {\n        v = mrb_ary_new_from_values(mrb, 1, &regs[a]);\n      }\n      ary = mrb_ary_ptr(v);\n      len = (int)ARY_LEN(ary);\n      if (len > pre + post) {\n        v = mrb_ary_new_from_values(mrb, len - pre - post, ARY_PTR(ary)+pre);\n        regs[a++] = v;\n        while (post--) {\n          regs[a++] = ARY_PTR(ary)[len-post-1];\n        }\n      }\n      else {\n        v = mrb_ary_new_capa(mrb, 0);\n        regs[a++] = v;\n        for (idx=0; idx+pre<len; idx++) {\n          regs[a+idx] = ARY_PTR(ary)[pre+idx];\n        }\n        while (idx < post) {\n          SET_NIL_VALUE(regs[a+idx]);\n          idx++;\n        }\n      }\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_INTERN, B) {\n      mrb_assert(mrb_string_p(regs[a]));\n      mrb_sym sym = mrb_intern_str(mrb, regs[a]);\n      regs[a] = mrb_symbol_value(sym);\n      NEXT;\n    }\n\n    CASE(OP_SYMBOL, BB) {\n      size_t len;\n      mrb_sym sym;\n\n      mrb_assert((pool[b].tt&IREP_TT_NFLAG)==0);\n      len = pool[b].tt >> 2;\n      if (pool[b].tt & IREP_TT_SFLAG) {\n        sym = mrb_intern_static(mrb, pool[b].u.str, len);\n      }\n      else {\n        sym  = mrb_intern(mrb, pool[b].u.str, len);\n      }\n      regs[a] = mrb_symbol_value(sym);\n      NEXT;\n    }\n\n    CASE(OP_STRING, BB) {\n      mrb_int len;\n\n      mrb_assert((pool[b].tt&IREP_TT_NFLAG)==0);\n      len = pool[b].tt >> 2;\n      if (pool[b].tt & IREP_TT_SFLAG) {\n        regs[a] = mrb_str_new_static(mrb, pool[b].u.str, len);\n      }\n      else {\n        regs[a] = mrb_str_new(mrb, pool[b].u.str, len);\n      }\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_STRCAT, B) {\n      mrb_assert(mrb_string_p(regs[a]));\n      mrb_str_concat(mrb, regs[a], regs[a+1]);\n      NEXT;\n    }\n\n    CASE(OP_HASH, BB) {\n      mrb_value hash = mrb_hash_new_capa(mrb, b);\n      int i;\n      int lim = a+b*2;\n\n      for (i=a; i<lim; i+=2) {\n        mrb_hash_set(mrb, hash, regs[i], regs[i+1]);\n      }\n      regs[a] = hash;\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_HASHADD, BB) {\n      mrb_value hash;\n      int i;\n      int lim = a+b*2+1;\n\n      hash = regs[a];\n      mrb_ensure_hash_type(mrb, hash);\n      for (i=a+1; i<lim; i+=2) {\n        mrb_hash_set(mrb, hash, regs[i], regs[i+1]);\n      }\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n    CASE(OP_HASHCAT, B) {\n      mrb_value hash = regs[a];\n\n      mrb_assert(mrb_hash_p(hash));\n      mrb_hash_merge(mrb, hash, regs[a+1]);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_LAMBDA, BB)\n    c = OP_L_LAMBDA;\n    L_MAKE_LAMBDA:\n    {\n      struct RProc *p;\n      const mrb_irep *nirep = irep->reps[b];\n\n      if (c & OP_L_CAPTURE) {\n        p = mrb_closure_new(mrb, nirep);\n      }\n      else {\n        p = mrb_proc_new(mrb, nirep);\n        p->flags |= MRB_PROC_SCOPE;\n      }\n      if (c & OP_L_STRICT) p->flags |= MRB_PROC_STRICT;\n      regs[a] = mrb_obj_value(p);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n    CASE(OP_BLOCK, BB) {\n      c = OP_L_BLOCK;\n      goto L_MAKE_LAMBDA;\n    }\n    CASE(OP_METHOD, BB) {\n      c = OP_L_METHOD;\n      goto L_MAKE_LAMBDA;\n    }\n\n    CASE(OP_RANGE_INC, B) {\n      mrb_value v = mrb_range_new(mrb, regs[a], regs[a+1], FALSE);\n      regs[a] = v;\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_RANGE_EXC, B) {\n      mrb_value v = mrb_range_new(mrb, regs[a], regs[a+1], TRUE);\n      regs[a] = v;\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_OCLASS, B) {\n      regs[a] = mrb_obj_value(mrb->object_class);\n      NEXT;\n    }\n\n    CASE(OP_CLASS, BB) {\n      struct RClass *c = 0, *baseclass;\n      mrb_value base, super;\n      mrb_sym id = syms[b];\n\n      base = regs[a];\n      super = regs[a+1];\n      if (mrb_nil_p(base)) {\n        baseclass = MRB_PROC_TARGET_CLASS(mrb->c->ci->proc);\n        if (!baseclass) baseclass = mrb->object_class;\n        base = mrb_obj_value(baseclass);\n      }\n      c = mrb_vm_define_class(mrb, base, super, id);\n      regs[a] = mrb_obj_value(c);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_MODULE, BB) {\n      struct RClass *cls = 0, *baseclass;\n      mrb_value base;\n      mrb_sym id = syms[b];\n\n      base = regs[a];\n      if (mrb_nil_p(base)) {\n        baseclass = MRB_PROC_TARGET_CLASS(mrb->c->ci->proc);\n        if (!baseclass) baseclass = mrb->object_class;\n        base = mrb_obj_value(baseclass);\n      }\n      cls = mrb_vm_define_module(mrb, base, id);\n      regs[a] = mrb_obj_value(cls);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_EXEC, BB)\n    {\n      mrb_value recv = regs[a];\n      struct RProc *p;\n      const mrb_irep *nirep = irep->reps[b];\n\n      /* prepare closure */\n      p = mrb_proc_new(mrb, nirep);\n      p->c = NULL;\n      mrb_field_write_barrier(mrb, (struct RBasic*)p, (struct RBasic*)proc);\n      MRB_PROC_SET_TARGET_CLASS(p, mrb_class_ptr(recv));\n      p->flags |= MRB_PROC_SCOPE;\n\n      /* prepare call stack */\n      cipush(mrb, a, 0, mrb_class_ptr(recv), p, 0, 0);\n\n      irep = p->body.irep;\n      pool = irep->pool;\n      syms = irep->syms;\n      mrb_stack_extend(mrb, irep->nregs);\n      stack_clear(regs+1, irep->nregs-1);\n      pc = irep->iseq;\n      JUMP;\n    }\n\n    CASE(OP_DEF, BB) {\n      struct RClass *target = mrb_class_ptr(regs[a]);\n      struct RProc *p = mrb_proc_ptr(regs[a+1]);\n      mrb_method_t m;\n      mrb_sym mid = syms[b];\n\n      MRB_METHOD_FROM_PROC(m, p);\n      mrb_define_method_raw(mrb, target, mid, m);\n      mrb_method_added(mrb, target, mid);\n      mrb_gc_arena_restore(mrb, ai);\n      regs[a] = mrb_symbol_value(mid);\n      NEXT;\n    }\n\n    CASE(OP_SCLASS, B) {\n      regs[a] = mrb_singleton_class(mrb, regs[a]);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_TCLASS, B) {\n      struct RClass *target = check_target_class(mrb);\n      if (!target) goto L_RAISE;\n      regs[a] = mrb_obj_value(target);\n      NEXT;\n    }\n\n    CASE(OP_ALIAS, BB) {\n      struct RClass *target = check_target_class(mrb);\n\n      if (!target) goto L_RAISE;\n      mrb_alias_method(mrb, target, syms[a], syms[b]);\n      mrb_method_added(mrb, target, syms[a]);\n      NEXT;\n    }\n    CASE(OP_UNDEF, B) {\n      struct RClass *target = check_target_class(mrb);\n\n      if (!target) goto L_RAISE;\n      mrb_undef_method_id(mrb, target, syms[a]);\n      NEXT;\n    }\n\n    CASE(OP_DEBUG, Z) {\n      FETCH_BBB();\n#ifdef MRB_USE_DEBUG_HOOK\n      mrb->debug_op_hook(mrb, irep, pc, regs);\n#else\n#ifndef MRB_NO_STDIO\n      printf(\"OP_DEBUG %d %d %d\\n\", a, b, c);\n#else\n      abort();\n#endif\n#endif\n      NEXT;\n    }\n\n    CASE(OP_ERR, B) {\n      size_t len = pool[a].tt >> 2;\n      mrb_value exc;\n\n      mrb_assert((pool[a].tt&IREP_TT_NFLAG)==0);\n      exc = mrb_exc_new(mrb, E_LOCALJUMP_ERROR, pool[a].u.str, len);\n      mrb_exc_set(mrb, exc);\n      goto L_RAISE;\n    }\n\n    CASE(OP_EXT1, Z) {\n      insn = READ_B();\n      switch (insn) {\n#define OPCODE(insn,ops) case OP_ ## insn: FETCH_ ## ops ## _1(); mrb->c->ci->pc = pc; goto L_OP_ ## insn ## _BODY;\n#include \"mruby/ops.h\"\n#undef OPCODE\n      }\n      pc--;\n      NEXT;\n    }\n    CASE(OP_EXT2, Z) {\n      insn = READ_B();\n      switch (insn) {\n#define OPCODE(insn,ops) case OP_ ## insn: FETCH_ ## ops ## _2(); mrb->c->ci->pc = pc; goto L_OP_ ## insn ## _BODY;\n#include \"mruby/ops.h\"\n#undef OPCODE\n      }\n      pc--;\n      NEXT;\n    }\n    CASE(OP_EXT3, Z) {\n      uint8_t insn = READ_B();\n      switch (insn) {\n#define OPCODE(insn,ops) case OP_ ## insn: FETCH_ ## ops ## _3(); mrb->c->ci->pc = pc; goto L_OP_ ## insn ## _BODY;\n#include \"mruby/ops.h\"\n#undef OPCODE\n      }\n      pc--;\n      NEXT;\n    }\n\n    CASE(OP_STOP, Z) {\n      /*        stop VM */\n      CHECKPOINT_RESTORE(RBREAK_TAG_STOP) {\n        /* do nothing */\n      }\n      CHECKPOINT_MAIN(RBREAK_TAG_STOP) {\n        UNWIND_ENSURE(mrb, mrb->c->ci, pc, RBREAK_TAG_STOP, proc, mrb_nil_value());\n      }\n      CHECKPOINT_END(RBREAK_TAG_STOP);\n    L_STOP:\n      mrb->jmp = prev_jmp;\n      if (mrb->exc) {\n        mrb_assert(mrb->exc->tt == MRB_TT_EXCEPTION);\n        return mrb_obj_value(mrb->exc);\n      }\n      return regs[irep->nlocals];\n    }\n  }\n  END_DISPATCH;\n#undef regs\n  }\n  MRB_CATCH(&c_jmp) {\n    mrb_callinfo *ci = mrb->c->ci;\n    while (ci > mrb->c->cibase && ci->cci == CINFO_DIRECT) {\n      ci = cipop(mrb);\n    }\n    exc_catched = TRUE;\n    pc = ci->pc;\n    goto RETRY_TRY_BLOCK;\n  }\n  MRB_END_EXC(&c_jmp);\n}",
        "func_hash": 214632234325372237977713260759937528043,
        "file_name": "vm.c",
        "file_hash": 170767380435846497188487321763087479620,
        "cwe": [
            "CWE-476"
        ],
        "cve": "CVE-2022-1201",
        "cve_desc": "NULL Pointer Dereference in mrb_vm_exec with super in GitHub repository mruby/mruby prior to 3.2. This vulnerability is capable of making the mruby interpreter crash, thus affecting the availability of the system.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-1201",
        "func_name": "mrb_vm_exec",
        "diff": [
            "diff --git a/src/vm.c b/src/vm.c\nindex 77edbb38fc..3bb9510ec1 100644\n--- a/src/vm.c\n+++ b/src/vm.c\n@@ -1749,7 +1749,7 @@ mrb_vm_exec(mrb_state *mrb, const struct RProc *proc, const mrb_code *pc)\n       }\n       else if (target_class->tt == MRB_TT_MODULE) {\n         target_class = mrb_vm_ci_target_class(ci);\n-        if (target_class->tt != MRB_TT_ICLASS) {\n+        if (!target_class || target_class->tt != MRB_TT_ICLASS) {\n           goto super_typeerror;\n         }\n       }\n"
        ],
        "func_after": []
    },
    {
        "idx": 198523,
        "project": "tensorflow",
        "commit_id": "5ecec9c6fbdbc6be03295685190a45e7eee726ab",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/5ecec9c6fbdbc6be03295685190a45e7eee726ab",
        "commit_message": "Prevent use after free.\n\nA very old version of the code used `result` as a simple pointer to a resource. Two years later, the pointer got changed to a `unique_ptr` but author forgot to remove the call to `Unref`. Three years after that, we finally uncover the UAF.\n\nPiperOrigin-RevId: 387924872\nChange-Id: I70fb6f199164de49fac20c168132a07b84903f9b",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext* context) override {\n    // Get the stamp token.\n    const Tensor* stamp_token_t;\n    OP_REQUIRES_OK(context, context->input(\"stamp_token\", &stamp_token_t));\n    int64_t stamp_token = stamp_token_t->scalar<int64>()();\n\n    // Get the tree ensemble proto.\n    const Tensor* tree_ensemble_serialized_t;\n    OP_REQUIRES_OK(context, context->input(\"tree_ensemble_serialized\",\n                                           &tree_ensemble_serialized_t));\n    std::unique_ptr<BoostedTreesEnsembleResource> result(\n        new BoostedTreesEnsembleResource());\n    if (!result->InitFromSerialized(\n            tree_ensemble_serialized_t->scalar<tstring>()(), stamp_token)) {\n      result->Unref();\n      OP_REQUIRES(\n          context, false,\n          errors::InvalidArgument(\"Unable to parse tree ensemble proto.\"));\n    }\n\n    // Only create one, if one does not exist already. Report status for all\n    // other exceptions.\n    auto status =\n        CreateResource(context, HandleFromInput(context, 0), result.release());\n    if (status.code() != tensorflow::error::ALREADY_EXISTS) {\n      OP_REQUIRES_OK(context, status);\n    }\n  }",
        "func_hash": 151034027968901870222536100864741418474,
        "file_name": "resource_ops.cc",
        "file_hash": 40939400980967911969144269399937980796,
        "cwe": [
            "CWE-416"
        ],
        "cve": "CVE-2021-37652",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions the implementation for `tf.raw_ops.BoostedTreesCreateEnsemble` can result in a use after free error if an attacker supplies specially crafted arguments. The [implementation](https://github.com/tensorflow/tensorflow/blob/f24faa153ad31a4b51578f8181d3aaab77a1ddeb/tensorflow/core/kernels/boosted_trees/resource_ops.cc#L55) uses a reference counted resource and decrements the refcount if the initialization fails, as it should. However, when the code was written, the resource was represented as a naked pointer but later refactoring has changed it to be a smart pointer. Thus, when the pointer leaves the scope, a subsequent `free`-ing of the resource occurs, but this fails to take into account that the refcount has already reached 0, thus the resource has been already freed. During this double-free process, members of the resource object are accessed for cleanup but they are invalid as the entire resource has been freed. We have patched the issue in GitHub commit 5ecec9c6fbdbc6be03295685190a45e7eee726ab. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37652",
        "func_name": "Compute",
        "diff": [
            "diff --git a/tensorflow/core/kernels/boosted_trees/resource_ops.cc b/tensorflow/core/kernels/boosted_trees/resource_ops.cc\nindex d50885fa3f5113..f2c60b9b4511de 100644\n--- a/tensorflow/core/kernels/boosted_trees/resource_ops.cc\n+++ b/tensorflow/core/kernels/boosted_trees/resource_ops.cc\n@@ -53,6 +53,7 @@ class BoostedTreesCreateEnsembleOp : public OpKernel {\n     if (!result->InitFromSerialized(\n             tree_ensemble_serialized_t->scalar<tstring>()(), stamp_token)) {\n       result->Unref();\n+      result.release();  // Needed due to the `->Unref` above, to prevent UAF\n       OP_REQUIRES(\n           context, false,\n           errors::InvalidArgument(\"Unable to parse tree ensemble proto.\"));\n"
        ],
        "func_after": []
    },
    {
        "idx": 198545,
        "project": "u-boot",
        "commit_id": "8f8c04bf1ebbd2f72f1643e7ad9617dafa6e5409",
        "project_url": "https://github.com/u-boot/u-boot",
        "commit_url": "https://github.com/u-boot/u-boot/commit/8f8c04bf1ebbd2f72f1643e7ad9617dafa6e5409",
        "commit_message": "i2c: fix stack buffer overflow vulnerability in i2c md command\n\nWhen running \"i2c md 0 0 80000100\", the function do_i2c_md parses the\nlength into an unsigned int variable named length. The value is then\nmoved to a signed variable:\n\n    int nbytes = length;\n    #define DISP_LINE_LEN 16\n    int linebytes = (nbytes > DISP_LINE_LEN) ? DISP_LINE_LEN : nbytes;\n    ret = dm_i2c_read(dev, addr, linebuf, linebytes);\n\nOn systems where integers are 32 bits wide, 0x80000100 is a negative\nvalue to \"nbytes > DISP_LINE_LEN\" is false and linebytes gets assigned\n0x80000100 instead of 16.\n\nThe consequence is that the function which reads from the i2c device\n(dm_i2c_read or i2c_read) is called with a 16-byte stack buffer to fill\nbut with a size parameter which is too large. In some cases, this could\ntrigger a crash. But with some i2c drivers, such as drivers/i2c/nx_i2c.c\n(used with \"nexell,s5pxx18-i2c\" bus), the size is actually truncated to\na 16-bit integer. This is because function i2c_transfer expects an\nunsigned short length. In such a case, an attacker who can control the\nresponse of an i2c device can overwrite the return address of a function\nand execute arbitrary code through Return-Oriented Programming.\n\nFix this issue by using unsigned integers types in do_i2c_md. While at\nit, make also alen unsigned, as signed sizes can cause vulnerabilities\nwhen people forgot to check that they can be negative.\n\nSigned-off-by: Nicolas Iooss <nicolas.iooss+uboot@ledger.fr>\nReviewed-by: Heiko Schocher <hs@denx.de>",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static int do_i2c_md(struct cmd_tbl *cmdtp, int flag, int argc,\n\t\t     char *const argv[])\n{\n\tuint\tchip;\n\tuint\taddr, length;\n\tint alen;\n\tint\tj, nbytes, linebytes;\n\tint ret;\n#if CONFIG_IS_ENABLED(DM_I2C)\n\tstruct udevice *dev;\n#endif\n\n\t/* We use the last specified parameters, unless new ones are\n\t * entered.\n\t */\n\tchip   = i2c_dp_last_chip;\n\taddr   = i2c_dp_last_addr;\n\talen   = i2c_dp_last_alen;\n\tlength = i2c_dp_last_length;\n\n\tif (argc < 3)\n\t\treturn CMD_RET_USAGE;\n\n\tif ((flag & CMD_FLAG_REPEAT) == 0) {\n\t\t/*\n\t\t * New command specified.\n\t\t */\n\n\t\t/*\n\t\t * I2C chip address\n\t\t */\n\t\tchip = hextoul(argv[1], NULL);\n\n\t\t/*\n\t\t * I2C data address within the chip.  This can be 1 or\n\t\t * 2 bytes long.  Some day it might be 3 bytes long :-).\n\t\t */\n\t\taddr = hextoul(argv[2], NULL);\n\t\talen = get_alen(argv[2], DEFAULT_ADDR_LEN);\n\t\tif (alen > 3)\n\t\t\treturn CMD_RET_USAGE;\n\n\t\t/*\n\t\t * If another parameter, it is the length to display.\n\t\t * Length is the number of objects, not number of bytes.\n\t\t */\n\t\tif (argc > 3)\n\t\t\tlength = hextoul(argv[3], NULL);\n\t}\n\n#if CONFIG_IS_ENABLED(DM_I2C)\n\tret = i2c_get_cur_bus_chip(chip, &dev);\n\tif (!ret && alen != -1)\n\t\tret = i2c_set_chip_offset_len(dev, alen);\n\tif (ret)\n\t\treturn i2c_report_err(ret, I2C_ERR_READ);\n#endif\n\n\t/*\n\t * Print the lines.\n\t *\n\t * We buffer all read data, so we can make sure data is read only\n\t * once.\n\t */\n\tnbytes = length;\n\tdo {\n\t\tunsigned char\tlinebuf[DISP_LINE_LEN];\n\t\tunsigned char\t*cp;\n\n\t\tlinebytes = (nbytes > DISP_LINE_LEN) ? DISP_LINE_LEN : nbytes;\n\n#if CONFIG_IS_ENABLED(DM_I2C)\n\t\tret = dm_i2c_read(dev, addr, linebuf, linebytes);\n#else\n\t\tret = i2c_read(chip, addr, alen, linebuf, linebytes);\n#endif\n\t\tif (ret)\n\t\t\treturn i2c_report_err(ret, I2C_ERR_READ);\n\t\telse {\n\t\t\tprintf(\"%04x:\", addr);\n\t\t\tcp = linebuf;\n\t\t\tfor (j=0; j<linebytes; j++) {\n\t\t\t\tprintf(\" %02x\", *cp++);\n\t\t\t\taddr++;\n\t\t\t}\n\t\t\tputs (\"    \");\n\t\t\tcp = linebuf;\n\t\t\tfor (j=0; j<linebytes; j++) {\n\t\t\t\tif ((*cp < 0x20) || (*cp > 0x7e))\n\t\t\t\t\tputs (\".\");\n\t\t\t\telse\n\t\t\t\t\tprintf(\"%c\", *cp);\n\t\t\t\tcp++;\n\t\t\t}\n\t\t\tputc ('\\n');\n\t\t}\n\t\tnbytes -= linebytes;\n\t} while (nbytes > 0);\n\n\ti2c_dp_last_chip   = chip;\n\ti2c_dp_last_addr   = addr;\n\ti2c_dp_last_alen   = alen;\n\ti2c_dp_last_length = length;\n\n\treturn 0;\n}",
        "func_hash": 336388644236353594568664801027238457577,
        "file_name": "i2c.c",
        "file_hash": 135764079202241918781821738561519186738,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2022-34835",
        "cve_desc": "In Das U-Boot through 2022.07-rc5, an integer signedness error and resultant stack-based buffer overflow in the \"i2c md\" command enables the corruption of the return address pointer of the do_i2c_md function.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-34835",
        "func_name": "do_i2c_md",
        "diff": [
            "diff --git a/cmd/i2c.c b/cmd/i2c.c\nindex 9050b2b8d27a..bd04b14024be 100644\n--- a/cmd/i2c.c\n+++ b/cmd/i2c.c\n@@ -200,10 +200,10 @@ void i2c_init_board(void)\n  *\n  * Returns the address length.\n  */\n-static uint get_alen(char *arg, int default_len)\n+static uint get_alen(char *arg, uint default_len)\n {\n-\tint\tj;\n-\tint\talen;\n+\tuint\tj;\n+\tuint\talen;\n \n \talen = default_len;\n \tfor (j = 0; j < 8; j++) {\n@@ -247,7 +247,7 @@ static int do_i2c_read(struct cmd_tbl *cmdtp, int flag, int argc,\n {\n \tuint\tchip;\n \tuint\tdevaddr, length;\n-\tint alen;\n+\tuint\talen;\n \tu_char  *memaddr;\n \tint ret;\n #if CONFIG_IS_ENABLED(DM_I2C)\n@@ -301,7 +301,7 @@ static int do_i2c_write(struct cmd_tbl *cmdtp, int flag, int argc,\n {\n \tuint\tchip;\n \tuint\tdevaddr, length;\n-\tint alen;\n+\tuint\talen;\n \tu_char  *memaddr;\n \tint ret;\n #if CONFIG_IS_ENABLED(DM_I2C)\n@@ -469,8 +469,8 @@ static int do_i2c_md(struct cmd_tbl *cmdtp, int flag, int argc,\n {\n \tuint\tchip;\n \tuint\taddr, length;\n-\tint alen;\n-\tint\tj, nbytes, linebytes;\n+\tuint\talen;\n+\tuint\tj, nbytes, linebytes;\n \tint ret;\n #if CONFIG_IS_ENABLED(DM_I2C)\n \tstruct udevice *dev;\n@@ -589,9 +589,9 @@ static int do_i2c_mw(struct cmd_tbl *cmdtp, int flag, int argc,\n {\n \tuint\tchip;\n \tulong\taddr;\n-\tint\talen;\n+\tuint\talen;\n \tuchar\tbyte;\n-\tint\tcount;\n+\tuint\tcount;\n \tint ret;\n #if CONFIG_IS_ENABLED(DM_I2C)\n \tstruct udevice *dev;\n@@ -676,8 +676,8 @@ static int do_i2c_crc(struct cmd_tbl *cmdtp, int flag, int argc,\n {\n \tuint\tchip;\n \tulong\taddr;\n-\tint\talen;\n-\tint\tcount;\n+\tuint\talen;\n+\tuint\tcount;\n \tuchar\tbyte;\n \tulong\tcrc;\n \tulong\terr;\n@@ -985,7 +985,7 @@ static int do_i2c_loop(struct cmd_tbl *cmdtp, int flag, int argc,\n \t\t       char *const argv[])\n {\n \tuint\tchip;\n-\tint alen;\n+\tuint\talen;\n \tuint\taddr;\n \tuint\tlength;\n \tu_char\tbytes[16];\n"
        ],
        "func_after": []
    },
    {
        "idx": 198552,
        "project": "engine",
        "commit_id": "7df766124f87768b43b9e8947c5a01e17545772c",
        "project_url": "https://github.com/gost-engine/engine",
        "commit_url": "https://github.com/gost-engine/engine/commit/7df766124f87768b43b9e8947c5a01e17545772c",
        "commit_message": "Fix buffer overrun in creating key transport blob according to RFC 9189, 4.2.4.2\n\nResolves: CVE-2022-29242",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static int pkey_GOST_ECcp_encrypt(EVP_PKEY_CTX *pctx, unsigned char *out,\n                           size_t *out_len, const unsigned char *key,\n                           size_t key_len)\n{\n    GOST_KEY_TRANSPORT *gkt = NULL;\n    EVP_PKEY *pubk = EVP_PKEY_CTX_get0_pkey(pctx);\n    struct gost_pmeth_data *data = EVP_PKEY_CTX_get_data(pctx);\n    int pkey_nid = EVP_PKEY_base_id(pubk);\n    ASN1_OBJECT *crypt_params_obj = (pkey_nid == NID_id_GostR3410_2001 || pkey_nid == NID_id_GostR3410_2001DH) ?\n        OBJ_nid2obj(NID_id_Gost28147_89_CryptoPro_A_ParamSet) :\n        OBJ_nid2obj(NID_id_tc26_gost_28147_param_Z);\n    const struct gost_cipher_info *param =\n        get_encryption_params(crypt_params_obj);\n    unsigned char ukm[8], shared_key[32], crypted_key[44];\n    int ret = 0;\n    int key_is_ephemeral = 1;\n    gost_ctx cctx;\n    EVP_PKEY *sec_key = EVP_PKEY_CTX_get0_peerkey(pctx);\n    if (data->shared_ukm_size) {\n        memcpy(ukm, data->shared_ukm, 8);\n    } else {\n        if (RAND_bytes(ukm, 8) <= 0) {\n            GOSTerr(GOST_F_PKEY_GOST_ECCP_ENCRYPT, GOST_R_RNG_ERROR);\n            return 0;\n        }\n    }\n    if (!param)\n        goto err;\n    /* Check for private key in the peer_key of context */\n    if (sec_key) {\n        key_is_ephemeral = 0;\n        if (!gost_get0_priv_key(sec_key)) {\n            GOSTerr(GOST_F_PKEY_GOST_ECCP_ENCRYPT,\n                    GOST_R_NO_PRIVATE_PART_OF_NON_EPHEMERAL_KEYPAIR);\n            goto err;\n        }\n    } else {\n        key_is_ephemeral = 1;\n        if (out) {\n            sec_key = EVP_PKEY_new();\n            if (!EVP_PKEY_assign(sec_key, EVP_PKEY_base_id(pubk), EC_KEY_new())\n                || !EVP_PKEY_copy_parameters(sec_key, pubk)\n                || !gost_ec_keygen(EVP_PKEY_get0(sec_key))) {\n                GOSTerr(GOST_F_PKEY_GOST_ECCP_ENCRYPT,\n                        GOST_R_ERROR_COMPUTING_SHARED_KEY);\n                goto err;\n            }\n        }\n    }\n    if (out) {\n        int dgst_nid = NID_undef;\n        EVP_PKEY_get_default_digest_nid(pubk, &dgst_nid);\n        if (dgst_nid == NID_id_GostR3411_2012_512)\n            dgst_nid = NID_id_GostR3411_2012_256;\n\n        if (!VKO_compute_key(shared_key,\n                             EC_KEY_get0_public_key(EVP_PKEY_get0(pubk)),\n                             EVP_PKEY_get0(sec_key), ukm, 8, dgst_nid)) {\n            GOSTerr(GOST_F_PKEY_GOST_ECCP_ENCRYPT,\n                    GOST_R_ERROR_COMPUTING_SHARED_KEY);\n            goto err;\n        }\n        gost_init(&cctx, param->sblock);\n        keyWrapCryptoPro(&cctx, shared_key, ukm, key, crypted_key);\n    }\n    gkt = GOST_KEY_TRANSPORT_new();\n    if (!gkt) {\n        goto err;\n    }\n    if (!ASN1_OCTET_STRING_set(gkt->key_agreement_info->eph_iv, ukm, 8)) {\n        goto err;\n    }\n    if (!ASN1_OCTET_STRING_set(gkt->key_info->imit, crypted_key + 40, 4)) {\n        goto err;\n    }\n    if (!ASN1_OCTET_STRING_set\n        (gkt->key_info->encrypted_key, crypted_key + 8, 32)) {\n        goto err;\n    }\n    if (key_is_ephemeral) {\n        if (!X509_PUBKEY_set\n            (&gkt->key_agreement_info->ephem_key, out ? sec_key : pubk)) {\n            GOSTerr(GOST_F_PKEY_GOST_ECCP_ENCRYPT,\n                    GOST_R_CANNOT_PACK_EPHEMERAL_KEY);\n            goto err;\n        }\n    }\n    ASN1_OBJECT_free(gkt->key_agreement_info->cipher);\n    gkt->key_agreement_info->cipher = OBJ_nid2obj(param->nid);\n    if (key_is_ephemeral)\n        EVP_PKEY_free(sec_key);\n    if (!key_is_ephemeral) {\n        /* Set control \"public key from client certificate used\" */\n        if (EVP_PKEY_CTX_ctrl(pctx, -1, -1, EVP_PKEY_CTRL_PEER_KEY, 3, NULL)\n            <= 0) {\n            GOSTerr(GOST_F_PKEY_GOST_ECCP_ENCRYPT, GOST_R_CTRL_CALL_FAILED);\n            goto err;\n        }\n    }\n    if ((*out_len = i2d_GOST_KEY_TRANSPORT(gkt, out ? &out : NULL)) > 0)\n        ret = 1;\n    OPENSSL_cleanse(shared_key, sizeof(shared_key));\n    GOST_KEY_TRANSPORT_free(gkt);\n    return ret;\n err:\n    OPENSSL_cleanse(shared_key, sizeof(shared_key));\n    if (key_is_ephemeral)\n        EVP_PKEY_free(sec_key);\n    GOST_KEY_TRANSPORT_free(gkt);\n    return -1;\n}",
        "func_hash": 89031298057192357207711119163171237832,
        "file_name": "gost_ec_keyx.c",
        "file_hash": 151021593107318778140165694464640459536,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2022-29242",
        "cve_desc": "GOST engine is a reference implementation of the Russian GOST crypto algorithms for OpenSSL. TLS clients using GOST engine when ciphersuite `TLS_GOSTR341112_256_WITH_KUZNYECHIK_CTR_OMAC` is agreed and the server uses 512 bit GOST secret keys are vulnerable to buffer overflow. GOST engine version 3.0.1 contains a patch for this issue. Disabling ciphersuite `TLS_GOSTR341112_256_WITH_KUZNYECHIK_CTR_OMAC` is a possible workaround.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-29242",
        "func_name": "pkey_GOST_ECcp_encrypt",
        "diff": [
            "diff --git a/gost_ec_keyx.c b/gost_ec_keyx.c\nindex 5e677dc2..192b8922 100644\n--- a/gost_ec_keyx.c\n+++ b/gost_ec_keyx.c\n@@ -292,6 +292,8 @@ static int pkey_GOST_ECcp_encrypt(EVP_PKEY_CTX *pctx, unsigned char *out,\n     int key_is_ephemeral = 1;\n     gost_ctx cctx;\n     EVP_PKEY *sec_key = EVP_PKEY_CTX_get0_peerkey(pctx);\n+    int res_len = 0;\n+\n     if (data->shared_ukm_size) {\n         memcpy(ukm, data->shared_ukm, 8);\n     } else {\n@@ -373,8 +375,26 @@ static int pkey_GOST_ECcp_encrypt(EVP_PKEY_CTX *pctx, unsigned char *out,\n             goto err;\n         }\n     }\n-    if ((*out_len = i2d_GOST_KEY_TRANSPORT(gkt, out ? &out : NULL)) > 0)\n+    res_len = i2d_GOST_KEY_TRANSPORT(gkt, NULL);\n+    if (res_len <= 0) {\n+        GOSTerr(GOST_F_PKEY_GOST_ECCP_ENCRYPT, ERR_R_ASN1_LIB);\n+        goto err;\n+    }\n+\n+    if (out == NULL) {\n+        *out_len = res_len;\n         ret = 1;\n+    } else {\n+        if ((size_t)res_len > *out_len) {\n+            GOSTerr(GOST_F_PKEY_GOST_ECCP_ENCRYPT, GOST_R_INVALID_BUFFER_SIZE);\n+            goto err;\n+        }\n+        if ((*out_len = i2d_GOST_KEY_TRANSPORT(gkt, &out)) > 0)\n+            ret = 1;\n+        else\n+            GOSTerr(GOST_F_PKEY_GOST_ECCP_ENCRYPT, ERR_R_ASN1_LIB);\n+    }\n+\n     OPENSSL_cleanse(shared_key, sizeof(shared_key));\n     GOST_KEY_TRANSPORT_free(gkt);\n     return ret;\n"
        ],
        "func_after": []
    },
    {
        "idx": 198556,
        "project": "mruby",
        "commit_id": "da48e7dbb20024c198493b8724adae1b842083aa",
        "project_url": "https://github.com/mruby/mruby",
        "commit_url": "https://github.com/mruby/mruby/commit/da48e7dbb20024c198493b8724adae1b842083aa",
        "commit_message": "fiber.c: should pack 15+ arguments in an array.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "fiber_switch(mrb_state *mrb, mrb_value self, mrb_int len, const mrb_value *a, mrb_bool resume, mrb_bool vmexec)\n{\n  struct mrb_context *c = fiber_check(mrb, self);\n  struct mrb_context *old_c = mrb->c;\n  enum mrb_fiber_state status;\n  mrb_value value;\n\n  fiber_check_cfunc(mrb, c);\n  status = c->status;\n  switch (status) {\n  case MRB_FIBER_TRANSFERRED:\n    if (resume) {\n      mrb_raise(mrb, E_FIBER_ERROR, \"resuming transferred fiber\");\n    }\n    break;\n  case MRB_FIBER_RUNNING:\n  case MRB_FIBER_RESUMED:\n    mrb_raise(mrb, E_FIBER_ERROR, \"double resume\");\n    break;\n  case MRB_FIBER_TERMINATED:\n    mrb_raise(mrb, E_FIBER_ERROR, \"resuming dead fiber\");\n    break;\n  default:\n    break;\n  }\n  old_c->status = resume ? MRB_FIBER_RESUMED : MRB_FIBER_TRANSFERRED;\n  c->prev = resume ? mrb->c : (c->prev ? c->prev : mrb->root_c);\n  fiber_switch_context(mrb, c);\n  if (status == MRB_FIBER_CREATED) {\n    mrb_value *b, *e;\n\n    if (!c->ci->proc) {\n      mrb_raise(mrb, E_FIBER_ERROR, \"double resume (current)\");\n    }\n    mrb_stack_extend(mrb, len+2); /* for receiver and (optional) block */\n    b = c->stbase+1;\n    e = b + len;\n    while (b<e) {\n      *b++ = *a++;\n    }\n    if (vmexec) {\n      c->ci--;                    /* pop dummy callinfo */\n    }\n    c->cibase->n = len;\n    value = c->stbase[0] = MRB_PROC_ENV(c->cibase->proc)->stack[0];\n  }\n  else {\n    value = fiber_result(mrb, a, len);\n    if (vmexec) {\n      c->ci[1].stack[0] = value;\n    }\n  }\n\n  if (vmexec) {\n    c->vmexec = TRUE;\n    value = mrb_vm_exec(mrb, c->ci->proc, c->ci->pc);\n    mrb->c = old_c;\n  }\n  else {\n    MARK_CONTEXT_MODIFY(c);\n  }\n  return value;\n}",
        "func_hash": 47008074931842386485122959067604053158,
        "file_name": "fiber.c",
        "file_hash": 246157146670999327331490014943475085458,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2022-0890",
        "cve_desc": "NULL Pointer Dereference in GitHub repository mruby/mruby prior to 3.2.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-0890",
        "func_name": "fiber_switch",
        "diff": [
            "diff --git a/mrbgems/mruby-fiber/src/fiber.c b/mrbgems/mruby-fiber/src/fiber.c\nindex 0d85bedadc..322ed36ea8 100644\n--- a/mrbgems/mruby-fiber/src/fiber.c\n+++ b/mrbgems/mruby-fiber/src/fiber.c\n@@ -208,15 +208,22 @@ fiber_switch(mrb_state *mrb, mrb_value self, mrb_int len, const mrb_value *a, mr\n     if (!c->ci->proc) {\n       mrb_raise(mrb, E_FIBER_ERROR, \"double resume (current)\");\n     }\n-    mrb_stack_extend(mrb, len+2); /* for receiver and (optional) block */\n-    b = c->stbase+1;\n-    e = b + len;\n-    while (b<e) {\n-      *b++ = *a++;\n-    }\n     if (vmexec) {\n       c->ci--;                    /* pop dummy callinfo */\n     }\n+    if (len >= 15) {\n+      mrb_stack_extend(mrb, 3);   /* for receiver, args and (optional) block */\n+      c->stbase[1] = mrb_ary_new_from_values(mrb, len, a);\n+      len = 15;\n+    }\n+    else {\n+      mrb_stack_extend(mrb, len+2); /* for receiver and (optional) block */\n+      b = c->stbase+1;\n+      e = b + len;\n+      while (b<e) {\n+        *b++ = *a++;\n+      }\n+    }\n     c->cibase->n = len;\n     value = c->stbase[0] = MRB_PROC_ENV(c->cibase->proc)->stack[0];\n   }\n"
        ],
        "func_after": []
    },
    {
        "idx": 198566,
        "project": "libmobi",
        "commit_id": "eafc415bc6067e72577f70d6dd5acbf057ce6e6f",
        "project_url": "https://github.com/bfabiszewski/libmobi",
        "commit_url": "https://github.com/bfabiszewski/libmobi/commit/eafc415bc6067e72577f70d6dd5acbf057ce6e6f",
        "commit_message": "Fix wrong boundary checks in inflections parser resulting in stack buffer over-read with corrupt input",
        "target": 1,
        "irrelevant": 1,
        "func_before": "MOBI_RET mobi_decode_infl(unsigned char *decoded, int *decoded_size, const unsigned char *rule) {\n    int pos = *decoded_size;\n    char mod = 'i';\n    char dir = '<';\n    char olddir;\n    unsigned char c;\n    while ((c = *rule++)) {\n        if (c <= 4) {\n            mod = (c <= 2) ? 'i' : 'd'; /* insert, delete */\n            olddir = dir;\n            dir = (c & 2) ? '<' : '>'; /* left, right */\n            if (olddir != dir && olddir) {\n                pos = (c & 2) ? *decoded_size : 0;\n            }\n        }\n        else if (c > 10 && c < 20) {\n            if (dir == '>') {\n                pos = *decoded_size;\n            }\n            pos -= c - 10;\n            dir = 0;\n            if (pos < 0 || pos > *decoded_size) {\n                debug_print(\"Position setting failed (%s)\\n\", decoded);\n                return MOBI_DATA_CORRUPT;\n            }\n        }\n        else {\n            if (mod == 'i') {\n                const unsigned char *s = decoded + pos;\n                unsigned char *d = decoded + pos + 1;\n                const int l = *decoded_size - pos;\n                if (l < 0 || d + l > decoded + INDX_INFLBUF_SIZEMAX) {\n                    debug_print(\"Out of buffer in %s at pos: %i\\n\", decoded, pos);\n                    return MOBI_DATA_CORRUPT;\n                }\n                memmove(d, s, (size_t) l);\n                decoded[pos] = c;\n                (*decoded_size)++;\n                if (dir == '>') { pos++; }\n            } else {\n                if (dir == '<') { pos--; }\n                const unsigned char *s = decoded + pos + 1;\n                unsigned char *d = decoded + pos;\n                const int l = *decoded_size - pos;\n                if (l < 0 || d + l > decoded + INDX_INFLBUF_SIZEMAX) {\n                    debug_print(\"Out of buffer in %s at pos: %i\\n\", decoded, pos);\n                    return MOBI_DATA_CORRUPT;\n                }\n                if (decoded[pos] != c) {\n                    debug_print(\"Character mismatch in %s at pos: %i (%c != %c)\\n\", decoded, pos, decoded[pos], c);\n                    return MOBI_DATA_CORRUPT;\n                }\n                memmove(d, s, (size_t) l);\n                (*decoded_size)--;\n            }\n        }\n    }\n    return MOBI_SUCCESS;\n}",
        "func_hash": 38529228609046084805262566640890540140,
        "file_name": "index.c",
        "file_hash": 309095437889005741044332361577356993393,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2022-1533",
        "cve_desc": "Buffer Over-read in GitHub repository bfabiszewski/libmobi prior to 0.11. This vulnerability is capable of arbitrary code execution.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-1533",
        "func_name": "mobi_decode_infl",
        "diff": [
            "diff --git a/ChangeLog b/ChangeLog\nindex 8171034..b431347 100644\n--- a/ChangeLog\n+++ b/ChangeLog\n@@ -1,3 +1,4 @@\n+2022-04-27: Fix wrong boundary checks in inflections parser resulting in stack buffer over-read with corrupt input\n 2022-04-26: Fix text formatting\n 2022-04-26: Fix array boundary check when parsing inflections which could result in buffer over-read with corrupt input\n 2022-04-23: Fix formatting\ndiff --git a/src/index.c b/src/index.c\nindex 7e4f3b7..ca83675 100644\n--- a/src/index.c\n+++ b/src/index.c\n@@ -961,17 +961,13 @@ MOBI_RET mobi_decode_infl(unsigned char *decoded, int *decoded_size, const unsig\n             }\n             pos -= c - 10;\n             dir = 0;\n-            if (pos < 0 || pos > *decoded_size) {\n-                debug_print(\"Position setting failed (%s)\\n\", decoded);\n-                return MOBI_DATA_CORRUPT;\n-            }\n         }\n         else {\n             if (mod == 'i') {\n                 const unsigned char *s = decoded + pos;\n                 unsigned char *d = decoded + pos + 1;\n                 const int l = *decoded_size - pos;\n-                if (l < 0 || d + l > decoded + INDX_INFLBUF_SIZEMAX) {\n+                if (pos < 0 || l < 0 || d + l > decoded + INDX_INFLBUF_SIZEMAX) {\n                     debug_print(\"Out of buffer in %s at pos: %i\\n\", decoded, pos);\n                     return MOBI_DATA_CORRUPT;\n                 }\n@@ -984,7 +980,7 @@ MOBI_RET mobi_decode_infl(unsigned char *decoded, int *decoded_size, const unsig\n                 const unsigned char *s = decoded + pos + 1;\n                 unsigned char *d = decoded + pos;\n                 const int l = *decoded_size - pos;\n-                if (l < 0 || d + l > decoded + INDX_INFLBUF_SIZEMAX) {\n+                if (pos < 0 || l < 0 || s + l > decoded + INDX_INFLBUF_SIZEMAX) {\n                     debug_print(\"Out of buffer in %s at pos: %i\\n\", decoded, pos);\n                     return MOBI_DATA_CORRUPT;\n                 }\n"
        ],
        "func_after": []
    },
    {
        "idx": 198588,
        "project": "vim",
        "commit_id": "0e8e938d497260dd57be67b4966cb27a5f72376f",
        "project_url": "https://github.com/vim/vim",
        "commit_url": "https://github.com/vim/vim/commit/0e8e938d497260dd57be67b4966cb27a5f72376f",
        "commit_message": "patch 8.2.5122: lisp indenting my run over the end of the line\n\nProblem:    Lisp indenting my run over the end of the line.\nSolution:   Check for NUL earlier.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "get_lisp_indent(void)\n{\n    pos_T\t*pos, realpos, paren;\n    int\t\tamount;\n    char_u\t*that;\n    colnr_T\tcol;\n    colnr_T\tfirsttry;\n    int\t\tparencount, quotecount;\n    int\t\tvi_lisp;\n\n    // Set vi_lisp to use the vi-compatible method\n    vi_lisp = (vim_strchr(p_cpo, CPO_LISP) != NULL);\n\n    realpos = curwin->w_cursor;\n    curwin->w_cursor.col = 0;\n\n    if ((pos = findmatch(NULL, '(')) == NULL)\n\tpos = findmatch(NULL, '[');\n    else\n    {\n\tparen = *pos;\n\tpos = findmatch(NULL, '[');\n\tif (pos == NULL || LT_POSP(pos, &paren))\n\t    pos = &paren;\n    }\n    if (pos != NULL)\n    {\n\t// Extra trick: Take the indent of the first previous non-white\n\t// line that is at the same () level.\n\tamount = -1;\n\tparencount = 0;\n\n\twhile (--curwin->w_cursor.lnum >= pos->lnum)\n\t{\n\t    if (linewhite(curwin->w_cursor.lnum))\n\t\tcontinue;\n\t    for (that = ml_get_curline(); *that != NUL; ++that)\n\t    {\n\t\tif (*that == ';')\n\t\t{\n\t\t    while (*(that + 1) != NUL)\n\t\t\t++that;\n\t\t    continue;\n\t\t}\n\t\tif (*that == '\\\\')\n\t\t{\n\t\t    if (*(that + 1) != NUL)\n\t\t\t++that;\n\t\t    continue;\n\t\t}\n\t\tif (*that == '\"' && *(that + 1) != NUL)\n\t\t{\n\t\t    while (*++that && *that != '\"')\n\t\t    {\n\t\t\t// skipping escaped characters in the string\n\t\t\tif (*that == '\\\\')\n\t\t\t{\n\t\t\t    if (*++that == NUL)\n\t\t\t\tbreak;\n\t\t\t    if (that[1] == NUL)\n\t\t\t    {\n\t\t\t\t++that;\n\t\t\t\tbreak;\n\t\t\t    }\n\t\t\t}\n\t\t    }\n\t\t}\n\t\tif (*that == '(' || *that == '[')\n\t\t    ++parencount;\n\t\telse if (*that == ')' || *that == ']')\n\t\t    --parencount;\n\t    }\n\t    if (parencount == 0)\n\t    {\n\t\tamount = get_indent();\n\t\tbreak;\n\t    }\n\t}\n\n\tif (amount == -1)\n\t{\n\t    curwin->w_cursor.lnum = pos->lnum;\n\t    curwin->w_cursor.col = pos->col;\n\t    col = pos->col;\n\n\t    that = ml_get_curline();\n\n\t    if (vi_lisp && get_indent() == 0)\n\t\tamount = 2;\n\t    else\n\t    {\n\t\tchar_u *line = that;\n\n\t\tamount = 0;\n\t\twhile (*that && col)\n\t\t{\n\t\t    amount += lbr_chartabsize_adv(line, &that, (colnr_T)amount);\n\t\t    col--;\n\t\t}\n\n\t\t// Some keywords require \"body\" indenting rules (the\n\t\t// non-standard-lisp ones are Scheme special forms):\n\t\t//\n\t\t// (let ((a 1))    instead    (let ((a 1))\n\t\t//   (...))\t      of\t   (...))\n\n\t\tif (!vi_lisp && (*that == '(' || *that == '[')\n\t\t\t\t\t\t      && lisp_match(that + 1))\n\t\t    amount += 2;\n\t\telse\n\t\t{\n\t\t    that++;\n\t\t    amount++;\n\t\t    firsttry = amount;\n\n\t\t    while (VIM_ISWHITE(*that))\n\t\t    {\n\t\t\tamount += lbr_chartabsize(line, that, (colnr_T)amount);\n\t\t\t++that;\n\t\t    }\n\n\t\t    if (*that && *that != ';') // not a comment line\n\t\t    {\n\t\t\t// test *that != '(' to accommodate first let/do\n\t\t\t// argument if it is more than one line\n\t\t\tif (!vi_lisp && *that != '(' && *that != '[')\n\t\t\t    firsttry++;\n\n\t\t\tparencount = 0;\n\t\t\tquotecount = 0;\n\n\t\t\tif (vi_lisp\n\t\t\t\t|| (*that != '\"'\n\t\t\t\t    && *that != '\\''\n\t\t\t\t    && *that != '#'\n\t\t\t\t    && (*that < '0' || *that > '9')))\n\t\t\t{\n\t\t\t    while (*that\n\t\t\t\t    && (!VIM_ISWHITE(*that)\n\t\t\t\t\t|| quotecount\n\t\t\t\t\t|| parencount)\n\t\t\t\t    && (!((*that == '(' || *that == '[')\n\t\t\t\t\t    && !quotecount\n\t\t\t\t\t    && !parencount\n\t\t\t\t\t    && vi_lisp)))\n\t\t\t    {\n\t\t\t\tif (*that == '\"')\n\t\t\t\t    quotecount = !quotecount;\n\t\t\t\tif ((*that == '(' || *that == '[')\n\t\t\t\t\t\t\t       && !quotecount)\n\t\t\t\t    ++parencount;\n\t\t\t\tif ((*that == ')' || *that == ']')\n\t\t\t\t\t\t\t       && !quotecount)\n\t\t\t\t    --parencount;\n\t\t\t\tif (*that == '\\\\' && *(that+1) != NUL)\n\t\t\t\t    amount += lbr_chartabsize_adv(\n\t\t\t\t\t\tline, &that, (colnr_T)amount);\n\t\t\t\tamount += lbr_chartabsize_adv(\n\t\t\t\t\t\tline, &that, (colnr_T)amount);\n\t\t\t    }\n\t\t\t}\n\t\t\twhile (VIM_ISWHITE(*that))\n\t\t\t{\n\t\t\t    amount += lbr_chartabsize(\n\t\t\t\t\t\t line, that, (colnr_T)amount);\n\t\t\t    that++;\n\t\t\t}\n\t\t\tif (!*that || *that == ';')\n\t\t\t    amount = firsttry;\n\t\t    }\n\t\t}\n\t    }\n\t}\n    }\n    else\n\tamount = 0;\t// no matching '(' or '[' found, use zero indent\n\n    curwin->w_cursor = realpos;\n\n    return amount;\n}",
        "func_hash": 267243770561266702154763100814181771713,
        "file_name": "indent.c",
        "file_hash": 46571564835107155022160222786721867171,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2022-2125",
        "cve_desc": "Heap-based Buffer Overflow in GitHub repository vim/vim prior to 8.2.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-2125",
        "func_name": "get_lisp_indent",
        "diff": [
            "diff --git a/src/indent.c b/src/indent.c\nindex 794fa2c3430bc..fa177bcf2c791 100644\n--- a/src/indent.c\n+++ b/src/indent.c\n@@ -2029,6 +2029,8 @@ get_lisp_indent(void)\n \t\t\t    }\n \t\t\t}\n \t\t    }\n+\t\t    if (*that == NUL)\n+\t\t\tbreak;\n \t\t}\n \t\tif (*that == '(' || *that == '[')\n \t\t    ++parencount;\ndiff --git a/src/testdir/test_indent.vim b/src/testdir/test_indent.vim\nindex be55227bd20cb..3b5b643177b4e 100644\n--- a/src/testdir/test_indent.vim\n+++ b/src/testdir/test_indent.vim\n@@ -144,6 +144,16 @@ func Test_lisp_indent()\n   close!\n endfunc\n \n+func Test_lisp_indent_quoted()\n+  \" This was going past the end of the line\n+  new\n+  setlocal lisp autoindent\n+  call setline(1, ['\"[', '='])\n+  normal Gvk=\n+\n+  bwipe!\n+endfunc\n+\n \" Test for setting the 'indentexpr' from a modeline\n func Test_modeline_indent_expr()\n   let modeline = &modeline\ndiff --git a/src/version.c b/src/version.c\nindex 89e1fa1b7aff8..5411e1c189f3e 100644\n--- a/src/version.c\n+++ b/src/version.c\n@@ -734,6 +734,8 @@ static char *(features[]) =\n \n static int included_patches[] =\n {   /* Add new patch number below this line */\n+/**/\n+    5122,\n /**/\n     5121,\n /**/\n"
        ],
        "func_after": []
    },
    {
        "idx": 198662,
        "project": "vim",
        "commit_id": "dc5490e2cbc8c16022a23b449b48c1bd0083f366",
        "project_url": "https://github.com/vim/vim",
        "commit_url": "https://github.com/vim/vim/commit/dc5490e2cbc8c16022a23b449b48c1bd0083f366",
        "commit_message": "patch 8.2.4215: illegal memory access when copying lines in Visual mode\n\nProblem:    Illegal memory access when copying lines in Visual mode.\nSolution:   Adjust the Visual position after copying lines.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "ex_copy(linenr_T line1, linenr_T line2, linenr_T n)\n{\n    linenr_T\tcount;\n    char_u\t*p;\n\n    count = line2 - line1 + 1;\n    if ((cmdmod.cmod_flags & CMOD_LOCKMARKS) == 0)\n    {\n\tcurbuf->b_op_start.lnum = n + 1;\n\tcurbuf->b_op_end.lnum = n + count;\n\tcurbuf->b_op_start.col = curbuf->b_op_end.col = 0;\n    }\n\n    /*\n     * there are three situations:\n     * 1. destination is above line1\n     * 2. destination is between line1 and line2\n     * 3. destination is below line2\n     *\n     * n = destination (when starting)\n     * curwin->w_cursor.lnum = destination (while copying)\n     * line1 = start of source (while copying)\n     * line2 = end of source (while copying)\n     */\n    if (u_save(n, n + 1) == FAIL)\n\treturn;\n\n    curwin->w_cursor.lnum = n;\n    while (line1 <= line2)\n    {\n\t// need to use vim_strsave() because the line will be unlocked within\n\t// ml_append()\n\tp = vim_strsave(ml_get(line1));\n\tif (p != NULL)\n\t{\n\t    ml_append(curwin->w_cursor.lnum, p, (colnr_T)0, FALSE);\n\t    vim_free(p);\n\t}\n\t// situation 2: skip already copied lines\n\tif (line1 == n)\n\t    line1 = curwin->w_cursor.lnum;\n\t++line1;\n\tif (curwin->w_cursor.lnum < line1)\n\t    ++line1;\n\tif (curwin->w_cursor.lnum < line2)\n\t    ++line2;\n\t++curwin->w_cursor.lnum;\n    }\n\n    appended_lines_mark(n, count);\n\n    msgmore((long)count);\n}",
        "func_hash": 97186272074546929960699343746519426256,
        "file_name": "ex_cmds.c",
        "file_hash": 233687213068218474878856624724146444666,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2022-0361",
        "cve_desc": "Heap-based Buffer Overflow in GitHub repository vim/vim prior to 8.2.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-0361",
        "func_name": "ex_copy",
        "diff": [
            "diff --git a/src/ex_cmds.c b/src/ex_cmds.c\nindex 95209985e190af..f5d93e664531ef 100644\n--- a/src/ex_cmds.c\n+++ b/src/ex_cmds.c\n@@ -866,6 +866,8 @@ ex_copy(linenr_T line1, linenr_T line2, linenr_T n)\n     }\n \n     appended_lines_mark(n, count);\n+    if (VIsual_active)\n+\tcheck_pos(curbuf, &VIsual);\n \n     msgmore((long)count);\n }\ndiff --git a/src/testdir/test_visual.vim b/src/testdir/test_visual.vim\nindex 72f5388b934dfd..9b322fd211b385 100644\n--- a/src/testdir/test_visual.vim\n+++ b/src/testdir/test_visual.vim\n@@ -1328,5 +1328,16 @@ func Test_visual_exchange_windows()\n   bwipe!\n endfunc\n \n+\" this was leaving the end of the Visual area beyond the end of a line\n+func Test_visual_ex_copy_line()\n+  new\n+  call setline(1, [\"aaa\", \"bbbbbbbbbxbb\"])\n+  /x\n+  exe \"normal ggvjfxO\"\n+  t0\n+  normal gNU\n+  bwipe!\n+endfunc\n+\n \n \" vim: shiftwidth=2 sts=2 expandtab\ndiff --git a/src/version.c b/src/version.c\nindex 5d7eccb19109b0..ddc34d864be986 100644\n--- a/src/version.c\n+++ b/src/version.c\n@@ -750,6 +750,8 @@ static char *(features[]) =\n \n static int included_patches[] =\n {   /* Add new patch number below this line */\n+/**/\n+    4215,\n /**/\n     4214,\n /**/\n"
        ],
        "func_after": []
    },
    {
        "idx": 198692,
        "project": "ipsec",
        "commit_id": "7bab09631c2a303f87a7eb7e3d69e888673b9b7e",
        "project_url": "https://git.kernel.org/pub/scm/linux/kernel/git/klassert/ipsec",
        "commit_url": "https://git.kernel.org/pub/scm/linux/kernel/git/klassert/ipsec.git/commit/?id=7bab09631c2a303f87a7eb7e3d69e888673b9b7e",
        "commit_message": "xfrm: policy: check policy direction value\n\nThe 'dir' parameter in xfrm_migrate() is a user-controlled byte which is used\nas an array index. This can lead to an out-of-bound access, kernel lockup and\nDoS. Add a check for the 'dir' value.\n\nThis fixes CVE-2017-11600.\n\nReferences: https://bugzilla.redhat.com/show_bug.cgi?id=1474928\nFixes: 80c9abaabf42 (\"[XFRM]: Extension for dynamic update of endpoint address(es)\")\nCc: <stable@vger.kernel.org> # v2.6.21-rc1\nReported-by: \"bo Zhang\" <zhangbo5891001@gmail.com>\nSigned-off-by: Vladis Dronov <vdronov@redhat.com>\nSigned-off-by: Steffen Klassert <steffen.klassert@secunet.com>",
        "target": 1,
        "irrelevant": 0,
        "func_before": "int xfrm_migrate(const struct xfrm_selector *sel, u8 dir, u8 type,\n\t\t struct xfrm_migrate *m, int num_migrate,\n\t\t struct xfrm_kmaddress *k, struct net *net,\n\t\t struct xfrm_encap_tmpl *encap)\n{\n\tint i, err, nx_cur = 0, nx_new = 0;\n\tstruct xfrm_policy *pol = NULL;\n\tstruct xfrm_state *x, *xc;\n\tstruct xfrm_state *x_cur[XFRM_MAX_DEPTH];\n\tstruct xfrm_state *x_new[XFRM_MAX_DEPTH];\n\tstruct xfrm_migrate *mp;\n\n\tif ((err = xfrm_migrate_check(m, num_migrate)) < 0)\n\t\tgoto out;\n\n\t/* Stage 1 - find policy */\n\tif ((pol = xfrm_migrate_policy_find(sel, dir, type, net)) == NULL) {\n\t\terr = -ENOENT;\n\t\tgoto out;\n\t}\n\n\t/* Stage 2 - find and update state(s) */\n\tfor (i = 0, mp = m; i < num_migrate; i++, mp++) {\n\t\tif ((x = xfrm_migrate_state_find(mp, net))) {\n\t\t\tx_cur[nx_cur] = x;\n\t\t\tnx_cur++;\n\t\t\txc = xfrm_state_migrate(x, mp, encap);\n\t\t\tif (xc) {\n\t\t\t\tx_new[nx_new] = xc;\n\t\t\t\tnx_new++;\n\t\t\t} else {\n\t\t\t\terr = -ENODATA;\n\t\t\t\tgoto restore_state;\n\t\t\t}\n\t\t}\n\t}\n\n\t/* Stage 3 - update policy */\n\tif ((err = xfrm_policy_migrate(pol, m, num_migrate)) < 0)\n\t\tgoto restore_state;\n\n\t/* Stage 4 - delete old state(s) */\n\tif (nx_cur) {\n\t\txfrm_states_put(x_cur, nx_cur);\n\t\txfrm_states_delete(x_cur, nx_cur);\n\t}\n\n\t/* Stage 5 - announce */\n\tkm_migrate(sel, dir, type, m, num_migrate, k, encap);\n\n\txfrm_pol_put(pol);\n\n\treturn 0;\nout:\n\treturn err;\n\nrestore_state:\n\tif (pol)\n\t\txfrm_pol_put(pol);\n\tif (nx_cur)\n\t\txfrm_states_put(x_cur, nx_cur);\n\tif (nx_new)\n\t\txfrm_states_delete(x_new, nx_new);\n\n\treturn err;\n}",
        "func_hash": 263415810499121443569228863944466057298,
        "file_name": "xfrm_policy.c",
        "file_hash": 279839085612343169676292983391622616816,
        "cwe": [
            "CWE-125"
        ],
        "cve": "CVE-2017-11600",
        "cve_desc": "net/xfrm/xfrm_policy.c in the Linux kernel through 4.12.3, when CONFIG_XFRM_MIGRATE is enabled, does not ensure that the dir value of xfrm_userpolicy_id is XFRM_POLICY_MAX or less, which allows local users to cause a denial of service (out-of-bounds access) or possibly have unspecified other impact via an XFRM_MSG_MIGRATE xfrm Netlink message.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2017-11600",
        "func_name": "xfrm_migrate",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 198695,
        "project": "MilkyTracker",
        "commit_id": "fd607a3439fcdd0992e5efded3c16fc79c804e34",
        "project_url": "https://github.com/milkytracker/MilkyTracker",
        "commit_url": "https://github.com/milkytracker/MilkyTracker/commit/fd607a3439fcdd0992e5efded3c16fc79c804e34",
        "commit_message": "Fix #184: Heap overflow in S3M loader",
        "target": 1,
        "irrelevant": 1,
        "func_before": "mp_sint32 LoaderS3M::load(XMFileBase& f, XModule* module)\n{\t\n\tmodule->cleanUp();\n\n\t// this will make code much easier to read\n\tTXMHeader*\t\theader = &module->header;\n\tTXMInstrument*\tinstr  = module->instr;\n\tTXMSample*\t\tsmp\t   = module->smp;\n\tTXMPattern*\t\tphead  = module->phead;\t\n\n\t// we're already out of memory here\n\tif (!phead || !instr || !smp)\n\t\treturn MP_OUT_OF_MEMORY;\n\t\n\tf.read(&header->name,1,28);\n\theader->whythis1a = f.readByte();\n\t\n\tif (f.readByte() != 16) \n\t\treturn MP_LOADER_FAILED;\t// no ST3 module\n\t\n\tf.readByte(); // skip something\n\tf.readByte(); // skip something\n\t\n\theader->ordnum = f.readWord(); // number of positions in order list (songlength)\n\t\n\tmp_ubyte* orders = new mp_ubyte[header->ordnum];\n\tif (orders == NULL) \n\t\treturn MP_OUT_OF_MEMORY;\n\t\n\theader->insnum = f.readWord(); // number of instruments\n\theader->patnum = f.readWord(); // number of patterns\t\n\t\n\tmp_sint32 flags = f.readWord(); // st3 flags\t\n\n\tmp_sint32 Cvt = f.readWord();\n\n\theader->flags = XModule::MODULE_ST3NEWINSTRUMENT | XModule::MODULE_ST3DUALCOMMANDS;\n\n\tif (Cvt == 0x1300 || (flags & 64))\n\t\theader->flags |= module->MODULE_OLDS3MVOLSLIDES;\n\t\t\n\theader->flags |= module->MODULE_ST3NOTECUT;\n\t\n\t/*mp_uword Ffi = */f.readWord();\n\t\n\tf.read(header->sig,1,4);\n\t\n\theader->mainvol = module->vol64to255(f.readByte()); // initial main volume\n\t\n\theader->tempo = f.readByte(); // tempo\n\t\n\theader->speed = f.readByte(); // speed\n\t\n\tf.readByte(); // global volume? skipped...\n\t\n\tf.readByte(); // ignore GUS click removal\n\t\n\t/*mp_ubyte dp = */f.readByte();\n\t\n\tf.readDword();\t// skip something\n\tf.readDword();\t// skip something\n\tf.readWord();\t// skip some more...\n\t\n\tmp_ubyte channelSettings[32];\n\tf.read(channelSettings,1,32);\n\t\n\tmp_sint32 numChannels = 0;\n\t\n\tfor (numChannels = 0; numChannels < 32; numChannels++)\n\t\tif (channelSettings[numChannels] == 255)\n\t\t\tbreak;\n\t\n\theader->channum = numChannels; // number of channels\n\t\n\tf.read(orders,1,header->ordnum);\n\t\n\tmp_sint32 j = 0, i = 0;\n\tfor (i = 0; i < header->ordnum; i++)\n\t{\n\t\tif (orders[i] == 255) \n\t\t\tbreak;\n\t\t\n\t\theader->ord[j++] = orders[i];\t\t\n\t}\n\t\n\theader->ordnum = j; // final songlength\n\t\n\tdelete[] orders;\n\t\n\tmp_uword* insParaPtrs = new mp_uword[header->insnum];\n\t\n\tif (insParaPtrs == NULL)\n\t\treturn MP_OUT_OF_MEMORY;\n\t\n\tf.readWords(insParaPtrs,header->insnum);\n\t\n\tmp_uword* patParaPtrs = new mp_uword[header->patnum];\n\t\n\tif (patParaPtrs == NULL)\n\t{\n\t\tdelete[] insParaPtrs;\n\t\treturn MP_OUT_OF_MEMORY;\n\t}\n\t\n\tf.readWords(patParaPtrs,header->patnum);\n\t\n\t//for (i = 0; i < header->insnum; i++)\n\t//{\n\t//\tprintf(\"%x\\n\",insParaPtrs[i]*16);\n\t//}\n\t\t\n\t//////////////////////\n\t// read instruments //\n\t//////////////////////\n\tmp_uint32* samplePtrs = new mp_uint32[header->insnum];\n\tif (samplePtrs == NULL)\n\t{\n\t\tdelete[] insParaPtrs;\n\t\tdelete[] patParaPtrs;\n\t\treturn MP_OUT_OF_MEMORY;\n\t}\n\t\n\tmemset(samplePtrs,0,sizeof(mp_uint32)*header->insnum);\n\t\n\tmp_sint32 s = 0;\n\tfor (i = 0; i < header->insnum; i++)\n\t{\n\t\tmp_uint32 insOffs = insParaPtrs[i]*16;\n\n\t\tif (insOffs)\n\t\t{\n\t\t\tf.seekWithBaseOffset(insOffs);\n\t\t\n\t\t\t// We can only read that if it's a sample\n\t\t\tmp_ubyte type = f.readByte();\n\t\t\t\n\t\t\tif (type == 1)\n\t\t\t{\n\t\t\t\tf.read(smp[s].name,1,12);\t// read dos filename\n\t\t\n\t\t\t\tmp_ubyte bOffs = f.readByte();\n\t\t\t\tmp_uword wOffs = f.readWord();\n\t\t\t\t\n\t\t\t\t// stupid fileoffsets\n\t\t\t\tsamplePtrs[i] = (((mp_uint32)bOffs<<16)+(mp_uint32)wOffs)*16;\n\t\t\t\t\n\t\t\t\tsmp[s].flags = 1;\n\t\t\t\tsmp[s].pan = 0x80;\n\t\t\t\t\n\t\t\t\tsmp[s].samplen = f.readDword();\n\t\t\t\tsmp[s].loopstart = f.readDword();\n\t\t\t\tmp_sint32 looplen = ((mp_sint32)f.readDword() - (mp_sint32)smp[s].loopstart);\n\t\t\t\tif (looplen < 0) \n\t\t\t\t\tlooplen = 0;\n\t\t\t\tsmp[s].looplen = looplen;\n\t\t\t\t\n\t\t\t\tsmp[s].vol = module->vol64to255(f.readByte());\n\t\t\t\t\n\t\t\t\tf.readByte(); // skip something\n\t\t\t\t\n\t\t\t\tsmp[s].res = f.readByte() == 0x04 ? 0xAD : 0; // packing\n\t\t\t\t\n\t\t\t\tmp_ubyte flags = f.readByte();\n\t\t\t\t\n\t\t\t\t// looping\n\t\t\t\tif (flags & 1)\n\t\t\t\t{\n\t\t\t\t\tsmp[s].type = 1;\t\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\t// 16 bit sample\n\t\t\t\tif (flags & 4)\n\t\t\t\t{\n\t\t\t\t\tsmp[s].type |= 16;\n\t\t\t\t\tsmp[s].samplen >>= 1;\n\t\t\t\t\tsmp[s].loopstart >>= 1;\n\t\t\t\t\tsmp[s].looplen >>= 1;\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tmp_uint32 c4spd = f.readDword();\n\t\t\t\t\n\t\t\t\tXModule::convertc4spd(c4spd,&smp[s].finetune,&smp[s].relnote);\n\n#ifdef VERBOSE\n\t\t\t\tprintf(\"%i, %i\\n\",c4spd,module->getc4spd(smp[s].relnote,smp[s].finetune));\t\t\t\t\n#endif\n\n\t\t\t\tf.readDword(); // skip something\n\t\t\t\t\n\t\t\t\tf.readDword(); // skip two internal words\n\t\t\t\t\n\t\t\t\tf.readDword(); // skip internal dword\n\n\t\t\t\tf.read(instr[i].name,1,28); // instrument name\n\t\t\t\t\n\t\t\t\tf.readDword(); // skip signature\n\t\t\t\t\n\t\t\t\tif (samplePtrs[i] && smp[s].samplen)\n\t\t\t\t{\n\t\t\t\t\tinstr[i].samp=1;\n\t\t\t\t\tfor (j=0;j<120;j++) \n\t\t\t\t\t\tinstr[i].snum[j] = s;\n\t\t\t\t\ts++;\n\t\t\t\t}\n\t\t\t}\n\t\t\telse if (type == 0)\n\t\t\t{\n\t\t\t\tsamplePtrs[i] = 0;\n\t\t\t\n\t\t\t\tmp_ubyte buffer[12];\n\t\t\t\tf.read(buffer,1,12);\t// read dos filename\n\t\t\n\t\t\t\tf.readByte();\n\t\t\t\tf.readWord();\n\t\t\t\t\n\t\t\t\tf.readDword();\n\t\t\t\tf.readDword();\n\t\t\t\tf.readDword();\n\t\t\t\tf.readByte();\n\t\t\t\tf.readByte(); // skip something\n\t\t\t\tf.readByte(); // skip packing\n\t\t\t\t\n\t\t\t\tf.readByte();\n\t\t\t\t\n\t\t\t\tf.readDword();\n\t\t\t\t\n\t\t\t\tf.readDword(); // skip something\n\t\t\t\t\n\t\t\t\tf.readDword(); // skip two internal words\n\t\t\t\t\n\t\t\t\tf.readDword(); // skip internal dword\n\n\t\t\t\tf.read(instr[i].name,1,28); // instrument name\n\t\t\t\t\n\t\t\t\tf.readDword(); // skip signature\t\t\t\t\n\t\t\t}\n\t\t\telse \n\t\t\t{\n\t\t\t\tsamplePtrs[i] = 0;\n\t\t\t}\n\t\t\t\n\t\t}\n\n\t}\n\t\n\t//////////////////////\n\t// read patterns\t//\n\t//////////////////////\n\tmp_ubyte* pattern = new mp_ubyte[64*32*5];\n\tif (pattern == NULL)\n\t{\n\t\tdelete[] insParaPtrs;\n\t\tdelete[] patParaPtrs;\n\t\tdelete[] samplePtrs;\n\t\treturn MP_OUT_OF_MEMORY;\n\t}\n\t\n\tmp_uint32 songMaxChannels = 1;\n\t\n\tfor (i = 0; i < header->patnum; i++)\n\t{\n\t\tfor (j = 0; j < 32*64; j++)\n\t\t{\n\t\t\tpattern[j*5] = 0xFF;\n\t\t\tpattern[j*5+1] = 0;\n\t\t\tpattern[j*5+2] = 0xFF;\n\t\t\tpattern[j*5+3] = 0xFF;\n\t\t\tpattern[j*5+4] = 0;\n\t\t}\n\t\t\n\t\tmp_uint32 patOffs = patParaPtrs[i]*16;\n\t\t\n\t\tmp_uint32 maxChannels = 1;\t\t\t\n\t\t\n\t\tif (patOffs)\n\t\t{\n\t\t\tf.seekWithBaseOffset(patOffs);\n\t\t\t\n\t\t\tmp_uint32 size = f.readWord();\n\t\t\t\n\t\t\tif (size > 2)\n\t\t\t{\n\t\t\t\tsize-=2;\n\t\t\t\t\n\t\t\t\tmp_ubyte* packed = new mp_ubyte[size+5];\n\t\t\t\tif (packed == NULL)\n\t\t\t\t{\n\t\t\t\t\tdelete[] insParaPtrs;\n\t\t\t\t\tdelete[] patParaPtrs;\n\t\t\t\t\tdelete[] samplePtrs;\n\t\t\t\t\tdelete[] pattern;\n\t\t\t\t\treturn MP_OUT_OF_MEMORY;\t\t\t\t\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tmemset(packed, 0, size);\n\t\t\t\tf.read(packed, 1, size);\n\t\t\t\t\n\t\t\t\tmp_uint32 index = 0;\n\t\t\t\tmp_uint32 row = 0;\n\t\t\t\t\n\t\t\t\twhile (index<size)\n\t\t\t\t{\n\t\t\t\t\t\n\t\t\t\t\tmp_ubyte pi = safeRead(packed, index, size);\n\t\t\t\t\t\n\t\t\t\t\tif (pi == 0) \n\t\t\t\t\t{\n\t\t\t\t\t\trow++;\n\t\t\t\t\t\t// one more safety net for incorrectly saved pattern sizes\n\t\t\t\t\t\tif (row >= 64)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tint i = 0;\n\t\t\t\t\t\t\ti++;\n\t\t\t\t\t\t\ti--;\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t\t\n\t\t\t\t\tmp_uint32 chn = pi&31;\n\t\t\t\t\t\n\t\t\t\t\tif (chn>maxChannels && (pi & (32+64+128)))\n\t\t\t\t\t{\n\t\t\t\t\t\tmaxChannels = chn;\n\t\t\t\t\t}\n\t\t\t\t\t\n\t\t\t\t\tmp_ubyte* slot = pattern+(row*32*5)+chn*5;\n\t\t\t\t\t\n\t\t\t\t\tif (pi & 32)\n\t\t\t\t\t{\n\t\t\t\t\t\tslot[0] = safeRead(packed, index, size, 0xFF);\n\t\t\t\t\t\tslot[1] = safeRead(packed, index, size);\n\t\t\t\t\t}\n\t\t\t\t\tif (pi & 64)\n\t\t\t\t\t{\n\t\t\t\t\t\tslot[2] = safeRead(packed, index, size, 0xFF);\n\t\t\t\t\t}\n\t\t\t\t\tif (pi & 128)\n\t\t\t\t\t{\n\t\t\t\t\t\tslot[3] = safeRead(packed, index, size, 0xFF);\n\t\t\t\t\t\tslot[4] = safeRead(packed, index, size);\n\t\t\t\t\t}\n\t\t\t\t\t\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tmaxChannels++;\n\t\t\t\t\n\t\t\t\tif (maxChannels > header->channum)\n\t\t\t\t\tmaxChannels = header->channum;\n\t\t\t\t\n\t\t\t\tdelete[] packed;\n\t\t\t}\n\t\t\t\n\t\t\tif (maxChannels > songMaxChannels)\n\t\t\t\tsongMaxChannels = maxChannels;\n\t\t\t\n\t\t}\n\t\t\n\t\tconvertS3MPattern(&phead[i], pattern, maxChannels, i);\n\t\t\n\t\t\n\t}\n\t\n\tif (header->channum > songMaxChannels)\n\t\theader->channum = songMaxChannels;\n\t\n\tdelete[] pattern;\n\tdelete[] insParaPtrs;\n\tdelete[] patParaPtrs;\n\t\n\ts = 0;\n\tfor (i = 0; i < header->insnum; i++)\n\t{\n\t\tmp_uint32 smpOffs = samplePtrs[i];\n\n\t\tif (smpOffs)\n\t\t{\n\t\t\tf.seekWithBaseOffset(smpOffs);\n\t\t\t\n\t\t\tif (!smp[s].samplen)\n\t\t\t\tcontinue;\n\n\t\t\tbool adpcm = (smp[s].res == 0xAD);\n\n\t\t\tmp_sint32 result = module->loadModuleSample(f, s, \n\t\t\t\t\t\t\t\t\t\t  adpcm ? XModule::ST_PACKING_ADPCM : XModule::ST_UNSIGNED, \n\t\t\t\t\t\t\t\t\t\t  adpcm ? (XModule::ST_16BIT | XModule::ST_PACKING_ADPCM) : (XModule::ST_16BIT | XModule::ST_UNSIGNED));\n\t\t\tif (result != MP_OK)\n\t\t\t{\n\t\t\t\tdelete[] samplePtrs;\n\t\t\t\treturn result;\n\t\t\t}\n\t\t\t\n\t\t\tif (adpcm)\n\t\t\t\t// no longer needed\n\t\t\t\tsmp[s].res = 0;\t\t\t\n\t\t\t\t\t\t\t\n\t\t\ts++;\n\t\t\t\n\t\t}\n\n\t}\n\t\n\tdelete[] samplePtrs;\n\t\n\theader->smpnum = s;\n\t\n\tstrcpy(header->tracker,\"Screamtracker 3\");\n\t\n\tmodule->setDefaultPanning();\n\t\n\tmodule->postProcessSamples();\n\t\n\treturn MP_OK;\t\n}",
        "func_hash": 83839366626583868665259951755341094581,
        "file_name": "LoaderS3M.cpp",
        "file_hash": 183144652101625968491560243513367539209,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2019-14464",
        "cve_desc": "XMFile::read in XMFile.cpp in milkyplay in MilkyTracker 1.02.00 has a heap-based buffer overflow.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2019-14464",
        "func_name": "LoaderS3M::load",
        "diff": [
            "diff --git a/src/milkyplay/LoaderS3M.cpp b/src/milkyplay/LoaderS3M.cpp\nindex 5abf211c..edf0fd54 100644\n--- a/src/milkyplay/LoaderS3M.cpp\n+++ b/src/milkyplay/LoaderS3M.cpp\n@@ -340,7 +340,11 @@ mp_sint32 LoaderS3M::load(XMFileBase& f, XModule* module)\n \t\treturn MP_OUT_OF_MEMORY;\n \t\n \theader->insnum = f.readWord(); // number of instruments\n-\theader->patnum = f.readWord(); // number of patterns\t\n+\tif (header->insnum > MP_MAXINS)\n+\t\treturn MP_LOADER_FAILED;\n+\theader->patnum = f.readWord(); // number of patterns\n+\tif (header->patnum > 256)\n+\t\treturn MP_LOADER_FAILED;\n \t\n \tmp_sint32 flags = f.readWord(); // st3 flags\t\n \n"
        ],
        "func_after": []
    },
    {
        "idx": 198703,
        "project": "LibRaw",
        "commit_id": "4606c28f494a750892c5c1ac7903e62dd1c6fdb5",
        "project_url": "https://github.com/LibRaw/LibRaw",
        "commit_url": "https://github.com/LibRaw/LibRaw/commit/4606c28f494a750892c5c1ac7903e62dd1c6fdb5",
        "commit_message": "0.16.1: fix for dcraw ljpeg_start() vulnerability",
        "target": 1,
        "irrelevant": 0,
        "func_before": "int CLASS ljpeg_start (struct jhead *jh, int info_only)\n{\n  int c, tag, len;\n  uchar data[0x10000];\n  const uchar *dp;\n\n  memset (jh, 0, sizeof *jh);\n  jh->restart = INT_MAX;\n  fread (data, 2, 1, ifp);\n  if (data[1] != 0xd8) return 0;\n  do {\n    fread (data, 2, 2, ifp);\n    tag =  data[0] << 8 | data[1];\n    len = (data[2] << 8 | data[3]) - 2;\n    if (tag <= 0xff00) return 0;\n    fread (data, 1, len, ifp);\n    switch (tag) {\n      case 0xffc3:\n\tjh->sraw = ((data[7] >> 4) * (data[7] & 15) - 1) & 3;\n      case 0xffc0:\n\tjh->bits = data[0];\n\tjh->high = data[1] << 8 | data[2];\n\tjh->wide = data[3] << 8 | data[4];\n\tjh->clrs = data[5] + jh->sraw;\n\tif (len == 9 && !dng_version) getc(ifp);\n\tbreak;\n      case 0xffc4:\n\tif (info_only) break;\n\tfor (dp = data; dp < data+len && (c = *dp++) < 4; )\n\t  jh->free[c] = jh->huff[c] = make_decoder_ref (&dp);\n\tbreak;\n      case 0xffda:\n\tjh->psv = data[1+data[0]*2];\n\tjh->bits -= data[3+data[0]*2] & 15;\n\tbreak;\n      case 0xffdd:\n\tjh->restart = data[0] << 8 | data[1];\n    }\n  } while (tag != 0xffda);\n  if (info_only) return 1;\n  if (jh->clrs > 6 || !jh->huff[0]) return 0;\n  FORC(5) if (!jh->huff[c+1]) jh->huff[c+1] = jh->huff[c];\n  if (jh->sraw) {\n    FORC(4)        jh->huff[2+c] = jh->huff[1];\n    FORC(jh->sraw) jh->huff[1+c] = jh->huff[0];\n  }\n  jh->row = (ushort *) calloc (jh->wide*jh->clrs, 4);\n  merror (jh->row, \"ljpeg_start()\");\n  return zero_after_ff = 1;\n}",
        "func_hash": 130689334179908551360949370308005940309,
        "file_name": "dcraw.c",
        "file_hash": 16246307575535149063752681880088000458,
        "cwe": [
            "CWE-189"
        ],
        "cve": "CVE-2015-3885",
        "cve_desc": "Integer overflow in the ljpeg_start function in dcraw 7.00 and earlier allows remote attackers to cause a denial of service (crash) via a crafted image, which triggers a buffer overflow, related to the len variable.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2015-3885",
        "func_name": "ljpeg_start",
        "diff": [
            "diff --git a/Changelog.rus b/Changelog.rus\nindex 4813ffe6..75be4962 100644\n--- a/Changelog.rus\n+++ b/Changelog.rus\n@@ -1,4 +1,8 @@\n-\ufeff2014-01-17 Alex Tutubalin <lexa@lexa.ru>\n+\ufeff2015-05-11 Alex Tutubalin <lexa@lexa.ru>\n+  * \u0418\u0441\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u0430 \u0443\u044f\u0437\u0432\u0438\u043c\u043e\u0441\u0442\u044c \u0432 dcraw:ljpeg_start()\n+  * LibRaw 0.16.1\n+\n+2014-01-17 Alex Tutubalin <lexa@lexa.ru>\n   * \u041f\u043e\u0434\u0434\u0435\u0440\u0436\u043a\u0430 \u043a\u0430\u043c\u0435\u0440\n     \u0414\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u044b: Fujifilm X-E2,XQ1\n     \u041e\u0431\u043d\u043e\u0432\u043b\u0435\u043d\u044b \u0446\u0432\u0435\u0442\u043e\u0432\u044b\u0435 \u0434\u0430\u043d\u043d\u044b\u0435: Nikon D4, 1 AW1/J3; Fuji X-M2\n@@ -13,7 +17,7 @@\n   * \u0418\u0441\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u044b \u043e\u0448\u0438\u0431\u043a\u0438 \u043a\u043e\u043c\u043f\u0438\u043b\u044f\u0446\u0438\u0438 \u043f\u0440\u0438 \u0441\u0431\u043e\u0440\u043a\u0435 VS2012 \u0441 \u0432\u043a\u043b\u044e\u0447\u0435\u043d\u043d\u044b\u043c\n     OpenMP\n   * \u0418\u0441\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u0430 \u043e\u043f\u0435\u0447\u0430\u0442\u043a\u0430, \u043d\u0435 \u0434\u0430\u0432\u0430\u0432\u0448\u0430\u044f \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c Demosaic Pack GPL2\n-  * LibRaw 0.16.0-Beta1\n+  * LibRaw 0.16.0\n \n 2013-11-12 Alex Tutubalin <lexa@lexa.ru>\n   * \u041f\u043e\u0434\u0434\u0435\u0440\u0436\u043a\u0430 \u043d\u043e\u0432\u044b\u0445 \u043a\u0430\u043c\u0435\u0440\ndiff --git a/Changelog.txt b/Changelog.txt\nindex 9e675fda..546e532e 100644\n--- a/Changelog.txt\n+++ b/Changelog.txt\n@@ -1,3 +1,7 @@\n+2015-05-11 Alex Tutubalin <lexa@lexa.ru>\n+  * Fix for dcraw ljpeg_start() vulnerability\n+  * LibRaw 0.16.1-Release\n+\n 2014-01-17 Alex Tutubalin <lexa@lexa.ru>\n   * Camera support:\n      Added: Fujifilm XE2, XQ1\ndiff --git a/dcraw/dcraw.c b/dcraw/dcraw.c\nindex 8ea5cd72..938cab6a 100644\n--- a/dcraw/dcraw.c\n+++ b/dcraw/dcraw.c\n@@ -841,7 +841,8 @@ struct jhead {\n \n int CLASS ljpeg_start (struct jhead *jh, int info_only)\n {\n-  int c, tag, len;\n+  int c, tag;\n+  ushort len;\n   uchar data[0x10000];\n   const uchar *dp;\n \ndiff --git a/internal/dcraw_common.cpp b/internal/dcraw_common.cpp\nindex 2dcb886f..3a3c6824 100644\n--- a/internal/dcraw_common.cpp\n+++ b/internal/dcraw_common.cpp\n@@ -21,6 +21,7 @@ it under the terms of the one of three licenses as you choose:\n    for more information\n */\n \n+#line 261 \"dcraw/dcraw.c\"\n #include <math.h>\n #define CLASS LibRaw::\n #include \"libraw/libraw_types.h\"\n@@ -29,6 +30,7 @@ it under the terms of the one of three licenses as you choose:\n #include \"libraw/libraw.h\"\n #include \"internal/defines.h\"\n #include \"internal/var_defines.h\"\n+#line 272 \"dcraw/dcraw.c\"\n int CLASS fcol (int row, int col)\n {\n   static const char filter[16][16] =\n@@ -75,6 +77,7 @@ char *my_strcasestr (char *haystack, const char *needle)\n }\n #define strcasestr my_strcasestr\n #endif\n+#line 340 \"dcraw/dcraw.c\"\n ushort CLASS sget2 (uchar *s)\n {\n   if (order == 0x4949)\t\t/* \"II\" means little-endian */\n@@ -564,10 +567,12 @@ void CLASS canon_load_raw()\n #endif\n   FORC(2) free (huff[c]);\n }\n+#line 841 \"dcraw/dcraw.c\"\n \n int CLASS ljpeg_start (struct jhead *jh, int info_only)\n {\n-  int c, tag, len;\n+  int c, tag;\n+  ushort len;\n   uchar data[0x10000];\n   const uchar *dp;\n \n@@ -1153,6 +1158,7 @@ int CLASS minolta_z2()\n     if (tail[i]) nz++;\n   return nz > 20;\n }\n+#line 1436 \"dcraw/dcraw.c\"\n void CLASS ppm_thumb()\n {\n   char *thumb;\n@@ -2976,6 +2982,7 @@ void CLASS redcine_load_raw()\n #endif\n #endif\n }\n+#line 3983 \"dcraw/dcraw.c\"\n void CLASS crop_masked_pixels()\n {\n   int row, col;\n@@ -3081,6 +3088,7 @@ void CLASS remove_zeroes()\n   RUN_CALLBACK(LIBRAW_PROGRESS_REMOVE_ZEROES,1,2);\n #endif\n }\n+#line 4254 \"dcraw/dcraw.c\"\n void CLASS gamma_curve (double pwr, double ts, int mode, int imax)\n {\n   int i;\n@@ -4790,6 +4798,7 @@ void CLASS parse_thumb_note (int base, unsigned toff, unsigned tlen)\n     fseek (ifp, save, SEEK_SET);\n   }\n }\n+#line 5968 \"dcraw/dcraw.c\"\n void CLASS parse_makernote (int base, int uptag)\n {\n   static const uchar xlat[2][256] = {\n@@ -5349,6 +5358,7 @@ void CLASS parse_kodak_ifd (int base)\n     fseek (ifp, save, SEEK_SET);\n   }\n }\n+#line 6533 \"dcraw/dcraw.c\"\n int CLASS parse_tiff_ifd (int base)\n {\n   unsigned entries, tag, type, len, plen=16, save;\n@@ -6648,6 +6658,7 @@ void CLASS parse_redcine()\n     data_offset = get4();\n   }\n }\n+#line 7936 \"dcraw/dcraw.c\"\n \n /*\n    All matrices are from Adobe DNG Converter unless otherwise noted.\n@@ -8923,6 +8934,7 @@ void CLASS identify()\n }\n \n \n+#line 10303 \"dcraw/dcraw.c\"\n void CLASS convert_to_rgb()\n {\n #ifndef LIBRAW_LIBRARY_BUILD\n@@ -9153,6 +9165,7 @@ int CLASS flip_index (int row, int col)\n   if (flip & 1) col = iwidth  - 1 - col;\n   return row * iwidth + col;\n }\n+#line 10559 \"dcraw/dcraw.c\"\n void CLASS tiff_set (ushort *ntag,\n \tushort tag, ushort type, int count, int val)\n {\ndiff --git a/internal/dcraw_fileio.cpp b/internal/dcraw_fileio.cpp\nindex f099eeea..06933de4 100644\n--- a/internal/dcraw_fileio.cpp\n+++ b/internal/dcraw_fileio.cpp\n@@ -21,7 +21,7 @@ it under the terms of the one of three licenses as you choose:\n    for more information\n */\n \n-#line 4090 \"dcraw/dcraw.c\"\n+#line 4091 \"dcraw/dcraw.c\"\n #include <math.h>\n #define CLASS LibRaw::\n #include \"libraw/libraw_types.h\"\n@@ -29,7 +29,7 @@ it under the terms of the one of three licenses as you choose:\n #include \"libraw/libraw.h\"\n #include \"internal/defines.h\"\n #include \"internal/var_defines.h\"\n-#line 4101 \"dcraw/dcraw.c\"\n+#line 4102 \"dcraw/dcraw.c\"\n /*\n    Seach from the current directory up to the root looking for\n    a \".badpixels\" file, and fix those pixels now.\n@@ -54,7 +54,7 @@ void CLASS bad_pixels (const char *cfname)\n #endif\n   if (cfname)\n     fp = fopen (cfname, \"r\");\n-#line 4151 \"dcraw/dcraw.c\"\n+#line 4152 \"dcraw/dcraw.c\"\n   if (!fp)\n       {\n #ifdef LIBRAW_LIBRARY_BUILD\n@@ -154,7 +154,7 @@ void CLASS subtract (const char *fname)\n   RUN_CALLBACK(LIBRAW_PROGRESS_DARK_FRAME,1,2);\n #endif\n }\n-#line 10213 \"dcraw/dcraw.c\"\n+#line 10214 \"dcraw/dcraw.c\"\n #ifndef NO_LCMS\n void CLASS apply_profile (const char *input, const char *output)\n {\ndiff --git a/libraw/libraw_version.h b/libraw/libraw_version.h\nindex 3594136f..030a477e 100644\n--- a/libraw/libraw_version.h\n+++ b/libraw/libraw_version.h\n@@ -25,7 +25,7 @@ it under the terms of the one of three licenses as you choose:\n \n #define LIBRAW_MAJOR_VERSION  0\n #define LIBRAW_MINOR_VERSION  16\n-#define LIBRAW_PATCH_VERSION  0\n+#define LIBRAW_PATCH_VERSION  1\n #define LIBRAW_VERSION_TAIL   Release\n \n #define LIBRAW_SHLIB_CURRENT  \t10\n"
        ],
        "func_after": []
    }
]