[
    {
        "idx": 198736,
        "project": "linux",
        "commit_id": "d563131ef23cbc756026f839a82598c8445bc45f",
        "project_url": "https://github.com/torvalds/linux",
        "commit_url": "https://github.com/torvalds/linux/commit/d563131ef23cbc756026f839a82598c8445bc45f",
        "commit_message": "rsi: release skb if rsi_prepare_beacon fails\n\nIn rsi_send_beacon, if rsi_prepare_beacon fails the allocated skb should\nbe released.\n\nSigned-off-by: Navid Emamdoost <navid.emamdoost@gmail.com>\nSigned-off-by: Kalle Valo <kvalo@codeaurora.org>",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static int rsi_send_beacon(struct rsi_common *common)\n{\n\tstruct sk_buff *skb = NULL;\n\tu8 dword_align_bytes = 0;\n\n\tskb = dev_alloc_skb(MAX_MGMT_PKT_SIZE);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tmemset(skb->data, 0, MAX_MGMT_PKT_SIZE);\n\n\tdword_align_bytes = ((unsigned long)skb->data & 0x3f);\n\tif (dword_align_bytes)\n\t\tskb_pull(skb, (64 - dword_align_bytes));\n\tif (rsi_prepare_beacon(common, skb)) {\n\t\trsi_dbg(ERR_ZONE, \"Failed to prepare beacon\\n\");\n\t\treturn -EINVAL;\n\t}\n\tskb_queue_tail(&common->tx_queue[MGMT_BEACON_Q], skb);\n\trsi_set_event(&common->tx_thread.event);\n\trsi_dbg(DATA_TX_ZONE, \"%s: Added to beacon queue\\n\", __func__);\n\n\treturn 0;\n}",
        "func_hash": 130931178778692254191224779038755080046,
        "file_name": "rsi_91x_mgmt.c",
        "file_hash": 125660046646447806158908760119804627111,
        "cwe": [
            "CWE-401"
        ],
        "cve": "CVE-2019-19071",
        "cve_desc": "A memory leak in the rsi_send_beacon() function in drivers/net/wireless/rsi/rsi_91x_mgmt.c in the Linux kernel through 5.3.11 allows attackers to cause a denial of service (memory consumption) by triggering rsi_prepare_beacon() failures, aka CID-d563131ef23c.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2019-19071",
        "func_name": "rsi_send_beacon",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 198743,
        "project": "LuaJIT",
        "commit_id": "53f82e6e2e858a0a62fd1a2ff47e9866693382e6",
        "project_url": "https://github.com/LuaJIT/LuaJIT",
        "commit_url": "https://github.com/LuaJIT/LuaJIT/commit/53f82e6e2e858a0a62fd1a2ff47e9866693382e6",
        "commit_message": "Fix frame traversal for __gc handler frames.\n\nReported by Changochen.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static ptrdiff_t finderrfunc(lua_State *L)\n{\n  cTValue *frame = L->base-1, *bot = tvref(L->stack);\n  void *cf = L->cframe;\n  while (frame > bot && cf) {\n    while (cframe_nres(cframe_raw(cf)) < 0) {  /* cframe without frame? */\n      if (frame >= restorestack(L, -cframe_nres(cf)))\n\tbreak;\n      if (cframe_errfunc(cf) >= 0)  /* Error handler not inherited (-1)? */\n\treturn cframe_errfunc(cf);\n      cf = cframe_prev(cf);  /* Else unwind cframe and continue searching. */\n      if (cf == NULL)\n\treturn 0;\n    }\n    switch (frame_typep(frame)) {\n    case FRAME_LUA:\n    case FRAME_LUAP:\n      frame = frame_prevl(frame);\n      break;\n    case FRAME_C:\n      cf = cframe_prev(cf);\n      /* fallthrough */\n    case FRAME_VARG:\n      frame = frame_prevd(frame);\n      break;\n    case FRAME_CONT:\n#if LJ_HASFFI\n      if ((frame-1)->u32.lo == LJ_CONT_FFI_CALLBACK)\n\tcf = cframe_prev(cf);\n#endif\n      frame = frame_prevd(frame);\n      break;\n    case FRAME_CP:\n      if (cframe_canyield(cf)) return 0;\n      if (cframe_errfunc(cf) >= 0)\n\treturn cframe_errfunc(cf);\n      frame = frame_prevd(frame);\n      break;\n    case FRAME_PCALL:\n    case FRAME_PCALLH:\n      if (frame_ftsz(frame) >= (ptrdiff_t)(2*sizeof(TValue)))  /* xpcall? */\n\treturn savestack(L, frame-1);  /* Point to xpcall's errorfunc. */\n      return 0;\n    default:\n      lua_assert(0);\n      return 0;\n    }\n  }\n  return 0;\n}",
        "func_hash": 309200300493568288549157158368440611870,
        "file_name": "lj_err.c",
        "file_hash": 339549767514658029818043680727253046808,
        "cwe": [
            "CWE-125"
        ],
        "cve": "CVE-2020-15890",
        "cve_desc": "LuaJit through 2.1.0-beta3 has an out-of-bounds read because __gc handler frame traversal is mishandled.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2020-15890",
        "func_name": "finderrfunc",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 198927,
        "project": "radare2",
        "commit_id": "0a557045476a2969c7079aec9eeb29d02f2809c6",
        "project_url": "https://github.com/radare/radare2",
        "commit_url": "https://github.com/radareorg/radare2/commit/0a557045476a2969c7079aec9eeb29d02f2809c6",
        "commit_message": "Fix oobread and unaligned casts in the NE entrypoint logic ##crash\n\n* Reported by @hmsec via huntr.dev\n* Reproducer: nepocaligns\n* BountyID: ec538fa4-06c6-4050-a141-f60153ddeaac",
        "target": 1,
        "irrelevant": 1,
        "func_before": "RList *r_bin_ne_get_entrypoints(r_bin_ne_obj_t *bin) {\n\tif (!bin->entry_table) {\n\t\treturn NULL;\n\t}\n\tRList *entries = r_list_newf (free);\n\tif (!entries) {\n\t\treturn NULL;\n\t}\n\tRList *segments = r_bin_ne_get_segments (bin);\n\tif (!segments) {\n\t\tr_list_free (entries);\n\t\treturn NULL;\n\t}\n\tif (bin->ne_header->csEntryPoint) {\n\t\tRBinAddr *entry = R_NEW0 (RBinAddr);\n\t\tif (!entry) {\n\t\t\tr_list_free (entries);\n\t\t\treturn NULL;\n\t\t}\n\t\tentry->bits = 16;\n\t\tut32 entry_cs = bin->ne_header->csEntryPoint;\n\t\tRBinSection *s = r_list_get_n (segments, entry_cs - 1);\n\t\tentry->paddr = bin->ne_header->ipEntryPoint + (s? s->paddr: 0);\n\n\t\tr_list_append (entries, entry);\n\t}\n\tint off = 0;\n\tsize_t tableat = bin->header_offset + bin->ne_header->EntryTableOffset;\n\twhile (off < bin->ne_header->EntryTableLength) {\n\t\tif (tableat + off >= r_buf_size (bin->buf)) {\n\t\t\tbreak;\n\t\t}\n\t\tut8 bundle_length = *(ut8 *)(bin->entry_table + off);\n\t\tif (!bundle_length) {\n\t\t\tbreak;\n\t\t}\n\t\toff++;\n\t\tut8 bundle_type = *(ut8 *)(bin->entry_table + off);\n\t\toff++;\n\t\tint i;\n\t\tfor (i = 0; i < bundle_length; i++) {\n\t\t\tif (tableat + off + 4 >= r_buf_size (bin->buf)) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tRBinAddr *entry = R_NEW0 (RBinAddr);\n\t\t\tif (!entry) {\n\t\t\t\tr_list_free (entries);\n\t\t\t\treturn NULL;\n\t\t\t}\n\t\t\toff++;\n\t\t\tif (!bundle_type) { // Skip\n\t\t\t\toff--;\n\t\t\t\tfree (entry);\n\t\t\t\tbreak;\n\t\t\t} else if (bundle_type == 0xff) { // moveable\n\t\t\t\toff += 2;\n\t\t\t\tut8 segnum = *(bin->entry_table + off);\n\t\t\t\toff++;\n\t\t\t\tut16 segoff = *(ut16 *)(bin->entry_table + off);\n\t\t\t\tif (segnum > 0) {\n\t\t\t\t\tentry->paddr = (ut64)bin->segment_entries[segnum - 1].offset * bin->alignment + segoff;\n\t\t\t\t}\n\t\t\t} else { // Fixed\n\t\t\t\tif (bundle_type < bin->ne_header->SegCount) {\n\t\t\t\t\tentry->paddr = (ut64)bin->segment_entries[bundle_type - 1].offset\n\t\t\t\t\t\t* bin->alignment + *(ut16 *)(bin->entry_table + off);\n\t\t\t\t}\n\t\t\t}\n\t\t\toff += 2;\n\t\t\tr_list_append (entries, entry);\n\t\t}\n\t}\n\tr_list_free (segments);\n\tbin->entries = entries;\n\treturn entries;\n}",
        "func_hash": 128571297919304348712196386626162050665,
        "file_name": "ne.c",
        "file_hash": 267767472176864232009512780125221207666,
        "cwe": [
            "CWE-125"
        ],
        "cve": "CVE-2022-1297",
        "cve_desc": "Out-of-bounds Read in r_bin_ne_get_entrypoints function in GitHub repository radareorg/radare2 prior to 5.6.8. This vulnerability may allow attackers to read sensitive information or cause a crash.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-1297",
        "func_name": "r_bin_ne_get_entrypoints",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 198983,
        "project": "swtpm",
        "commit_id": "9f740868fc36761de27df3935513bdebf8852d19",
        "project_url": "https://github.com/stefanberger/swtpm",
        "commit_url": "https://github.com/stefanberger/swtpm/commit/9f740868fc36761de27df3935513bdebf8852d19",
        "commit_message": "swtpm: Check header size indicator against expected size (CID 375869)\n\nThis fix addresses Coverity issue CID 375869.\n\nCheck the header size indicated in the header of the state against the\nexpected size and return an error code in case the header size indicator\nis different. There was only one header size so far since blobheader was\nintroduced, so we don't need to deal with different sizes.\n\nWithout this fix a specially craft header could have cause out-of-bounds\naccesses on the byte array containing the swtpm's state.\n\nSigned-off-by: Stefan Berger <stefanb@linux.ibm.com>",
        "target": 1,
        "irrelevant": 1,
        "func_before": "SWTPM_NVRAM_CheckHeader(unsigned char *data, uint32_t length,\n                        uint32_t *dataoffset, uint16_t *hdrflags,\n                        uint8_t *hdrversion, bool quiet)\n{\n    blobheader *bh = (blobheader *)data;\n\n    if (length < sizeof(bh)) {\n        if (!quiet)\n            logprintf(STDERR_FILENO,\n                      \"not enough bytes for header: %u\\n\", length);\n        return TPM_BAD_PARAMETER;\n    }\n\n    if (ntohl(bh->totlen) != length) {\n        if (!quiet)\n            logprintf(STDERR_FILENO,\n                      \"broken header: bh->totlen %u != %u\\n\",\n                      htonl(bh->totlen), length);\n        return TPM_BAD_PARAMETER;\n    }\n\n    if (bh->min_version > BLOB_HEADER_VERSION) {\n        if (!quiet)\n            logprintf(STDERR_FILENO,\n                      \"Minimum required version for the blob is %d, we \"\n                      \"only support version %d\\n\", bh->min_version,\n                      BLOB_HEADER_VERSION);\n        return TPM_BAD_VERSION;\n    }\n\n    *hdrversion = bh->version;\n    *dataoffset = ntohs(bh->hdrsize);\n    *hdrflags = ntohs(bh->flags);\n\n    return TPM_SUCCESS;\n}",
        "func_hash": 173394517357295307246184358296702159922,
        "file_name": "swtpm_nvfile.c",
        "file_hash": 132354630792840361852785968580616241078,
        "cwe": [
            "CWE-125"
        ],
        "cve": "CVE-2022-23645",
        "cve_desc": "swtpm is a libtpms-based TPM emulator with socket, character device, and Linux CUSE interface. Versions prior to 0.5.3, 0.6.2, and 0.7.1 are vulnerable to out-of-bounds read. A specially crafted header of swtpm's state, where the blobheader's hdrsize indicator has an invalid value, may cause an out-of-bounds access when the byte array representing the state of the TPM is accessed. This will likely crash swtpm or prevent it from starting since the state cannot be understood. Users should upgrade to swtpm v0.5.3, v0.6.2, or v0.7.1 to receive a patch. There are currently no known workarounds.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23645",
        "func_name": "SWTPM_NVRAM_CheckHeader",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 199159,
        "project": "linux",
        "commit_id": "8423f0b6d513b259fdab9c9bf4aaa6188d054c2d",
        "project_url": "https://github.com/torvalds/linux",
        "commit_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=8423f0b6d513b259fdab9c9bf4aaa6188d054c2d",
        "commit_message": "ALSA: pcm: oss: Fix race at SNDCTL_DSP_SYNC\n\nThere is a small race window at snd_pcm_oss_sync() that is called from\nOSS PCM SNDCTL_DSP_SYNC ioctl; namely the function calls\nsnd_pcm_oss_make_ready() at first, then takes the params_lock mutex\nfor the rest.  When the stream is set up again by another thread\nbetween them, it leads to inconsistency, and may result in unexpected\nresults such as NULL dereference of OSS buffer as a fuzzer spotted\nrecently.\n\nThe fix is simply to cover snd_pcm_oss_make_ready() call into the same\nparams_lock mutex with snd_pcm_oss_make_ready_locked() variant.\n\nReported-and-tested-by: butt3rflyh4ck <butterflyhuangxx@gmail.com>\nReviewed-by: Jaroslav Kysela <perex@perex.cz>\nCc: <stable@vger.kernel.org>\nLink: https://lore.kernel.org/r/CAFcO6XN7JDM4xSXGhtusQfS2mSBcx50VJKwQpCq=WeLt57aaZA@mail.gmail.com\nLink: https://lore.kernel.org/r/20220905060714.22549-1-tiwai@suse.de\nSigned-off-by: Takashi Iwai <tiwai@suse.de>",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static int snd_pcm_oss_sync(struct snd_pcm_oss_file *pcm_oss_file)\n{\n\tint err = 0;\n\tunsigned int saved_f_flags;\n\tstruct snd_pcm_substream *substream;\n\tstruct snd_pcm_runtime *runtime;\n\tsnd_pcm_format_t format;\n\tunsigned long width;\n\tsize_t size;\n\n\tsubstream = pcm_oss_file->streams[SNDRV_PCM_STREAM_PLAYBACK];\n\tif (substream != NULL) {\n\t\truntime = substream->runtime;\n\t\tif (atomic_read(&substream->mmap_count))\n\t\t\tgoto __direct;\n\t\terr = snd_pcm_oss_make_ready(substream);\n\t\tif (err < 0)\n\t\t\treturn err;\n\t\tatomic_inc(&runtime->oss.rw_ref);\n\t\tif (mutex_lock_interruptible(&runtime->oss.params_lock)) {\n\t\t\tatomic_dec(&runtime->oss.rw_ref);\n\t\t\treturn -ERESTARTSYS;\n\t\t}\n\t\tformat = snd_pcm_oss_format_from(runtime->oss.format);\n\t\twidth = snd_pcm_format_physical_width(format);\n\t\tif (runtime->oss.buffer_used > 0) {\n#ifdef OSS_DEBUG\n\t\t\tpcm_dbg(substream->pcm, \"sync: buffer_used\\n\");\n#endif\n\t\t\tsize = (8 * (runtime->oss.period_bytes - runtime->oss.buffer_used) + 7) / width;\n\t\t\tsnd_pcm_format_set_silence(format,\n\t\t\t\t\t\t   runtime->oss.buffer + runtime->oss.buffer_used,\n\t\t\t\t\t\t   size);\n\t\t\terr = snd_pcm_oss_sync1(substream, runtime->oss.period_bytes);\n\t\t\tif (err < 0)\n\t\t\t\tgoto unlock;\n\t\t} else if (runtime->oss.period_ptr > 0) {\n#ifdef OSS_DEBUG\n\t\t\tpcm_dbg(substream->pcm, \"sync: period_ptr\\n\");\n#endif\n\t\t\tsize = runtime->oss.period_bytes - runtime->oss.period_ptr;\n\t\t\tsnd_pcm_format_set_silence(format,\n\t\t\t\t\t\t   runtime->oss.buffer,\n\t\t\t\t\t\t   size * 8 / width);\n\t\t\terr = snd_pcm_oss_sync1(substream, size);\n\t\t\tif (err < 0)\n\t\t\t\tgoto unlock;\n\t\t}\n\t\t/*\n\t\t * The ALSA's period might be a bit large than OSS one.\n\t\t * Fill the remain portion of ALSA period with zeros.\n\t\t */\n\t\tsize = runtime->control->appl_ptr % runtime->period_size;\n\t\tif (size > 0) {\n\t\t\tsize = runtime->period_size - size;\n\t\t\tif (runtime->access == SNDRV_PCM_ACCESS_RW_INTERLEAVED)\n\t\t\t\tsnd_pcm_lib_write(substream, NULL, size);\n\t\t\telse if (runtime->access == SNDRV_PCM_ACCESS_RW_NONINTERLEAVED)\n\t\t\t\tsnd_pcm_lib_writev(substream, NULL, size);\n\t\t}\nunlock:\n\t\tmutex_unlock(&runtime->oss.params_lock);\n\t\tatomic_dec(&runtime->oss.rw_ref);\n\t\tif (err < 0)\n\t\t\treturn err;\n\t\t/*\n\t\t * finish sync: drain the buffer\n\t\t */\n\t      __direct:\n\t\tsaved_f_flags = substream->f_flags;\n\t\tsubstream->f_flags &= ~O_NONBLOCK;\n\t\terr = snd_pcm_kernel_ioctl(substream, SNDRV_PCM_IOCTL_DRAIN, NULL);\n\t\tsubstream->f_flags = saved_f_flags;\n\t\tif (err < 0)\n\t\t\treturn err;\n\t\tmutex_lock(&runtime->oss.params_lock);\n\t\truntime->oss.prepare = 1;\n\t\tmutex_unlock(&runtime->oss.params_lock);\n\t}\n\n\tsubstream = pcm_oss_file->streams[SNDRV_PCM_STREAM_CAPTURE];\n\tif (substream != NULL) {\n\t\terr = snd_pcm_oss_make_ready(substream);\n\t\tif (err < 0)\n\t\t\treturn err;\n\t\truntime = substream->runtime;\n\t\terr = snd_pcm_kernel_ioctl(substream, SNDRV_PCM_IOCTL_DROP, NULL);\n\t\tif (err < 0)\n\t\t\treturn err;\n\t\tmutex_lock(&runtime->oss.params_lock);\n\t\truntime->oss.buffer_used = 0;\n\t\truntime->oss.prepare = 1;\n\t\tmutex_unlock(&runtime->oss.params_lock);\n\t}\n\treturn 0;\n}",
        "func_hash": 331549555245265175479800423924118181234,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-362"
        ],
        "cve": "CVE-2022-3303",
        "cve_desc": "A race condition flaw was found in the Linux kernel sound subsystem due to improper locking. It could lead to a NULL pointer dereference while handling the SNDCTL_DSP_SYNC ioctl. A privileged local user (root or member of the audio group) could use this flaw to crash the system, resulting in a denial of service condition",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-3303",
        "func_name": "snd_pcm_oss_sync",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 199681,
        "project": "linux",
        "commit_id": "233087ca063686964a53c829d547c7571e3f67bf",
        "project_url": "https://github.com/torvalds/linux",
        "commit_url": "https://github.com/torvalds/linux/commit/233087ca063686964a53c829d547c7571e3f67bf",
        "commit_message": "floppy: disable FDRAWCMD by default\n\nMinh Yuan reported a concurrency use-after-free issue in the floppy code\nbetween raw_cmd_ioctl and seek_interrupt.\n\n[ It turns out this has been around, and that others have reported the\n  KASAN splats over the years, but Minh Yuan had a reproducer for it and\n  so gets primary credit for reporting it for this fix   - Linus ]\n\nThe problem is, this driver tends to break very easily and nowadays,\nnobody is expected to use FDRAWCMD anyway since it was used to\nmanipulate non-standard formats.  The risk of breaking the driver is\nhigher than the risk presented by this race, and accessing the device\nrequires privileges anyway.\n\nLet's just add a config option to completely disable this ioctl and\nleave it disabled by default.  Distros shouldn't use it, and only those\nrunning on antique hardware might need to enable it.\n\nLink: https://lore.kernel.org/all/000000000000b71cdd05d703f6bf@google.com/\nLink: https://lore.kernel.org/lkml/CAKcFiNC=MfYVW-Jt9A3=FPJpTwCD2PL_ULNCpsCVE5s8ZeBQgQ@mail.gmail.com\nLink: https://lore.kernel.org/all/CAEAjamu1FRhz6StCe_55XY5s389ZP_xmCF69k987En+1z53=eg@mail.gmail.com\nReported-by: Minh Yuan <yuanmingbuaa@gmail.com>\nReported-by: syzbot+8e8958586909d62b6840@syzkaller.appspotmail.com\nReported-by: cruise k <cruise4k@gmail.com>\nReported-by: Kyungtae Kim <kt0755@gmail.com>\nSuggested-by: Linus Torvalds <torvalds@linuxfoundation.org>\nTested-by: Denis Efremov <efremov@linux.com>\nSigned-off-by: Willy Tarreau <w@1wt.eu>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static int fd_locked_ioctl(struct block_device *bdev, fmode_t mode, unsigned int cmd,\n\t\t    unsigned long param)\n{\n\tint drive = (long)bdev->bd_disk->private_data;\n\tint type = ITYPE(drive_state[drive].fd_device);\n\tint i;\n\tint ret;\n\tint size;\n\tunion inparam {\n\t\tstruct floppy_struct g;\t/* geometry */\n\t\tstruct format_descr f;\n\t\tstruct floppy_max_errors max_errors;\n\t\tstruct floppy_drive_params dp;\n\t} inparam;\t\t/* parameters coming from user space */\n\tconst void *outparam;\t/* parameters passed back to user space */\n\n\t/* convert compatibility eject ioctls into floppy eject ioctl.\n\t * We do this in order to provide a means to eject floppy disks before\n\t * installing the new fdutils package */\n\tif (cmd == CDROMEJECT ||\t/* CD-ROM eject */\n\t    cmd == 0x6470) {\t\t/* SunOS floppy eject */\n\t\tDPRINT(\"obsolete eject ioctl\\n\");\n\t\tDPRINT(\"please use floppycontrol --eject\\n\");\n\t\tcmd = FDEJECT;\n\t}\n\n\tif (!((cmd & 0xff00) == 0x0200))\n\t\treturn -EINVAL;\n\n\t/* convert the old style command into a new style command */\n\tret = normalize_ioctl(&cmd, &size);\n\tif (ret)\n\t\treturn ret;\n\n\t/* permission checks */\n\tif (((cmd & 0x40) && !(mode & (FMODE_WRITE | FMODE_WRITE_IOCTL))) ||\n\t    ((cmd & 0x80) && !capable(CAP_SYS_ADMIN)))\n\t\treturn -EPERM;\n\n\tif (WARN_ON(size < 0 || size > sizeof(inparam)))\n\t\treturn -EINVAL;\n\n\t/* copyin */\n\tmemset(&inparam, 0, sizeof(inparam));\n\tif (_IOC_DIR(cmd) & _IOC_WRITE) {\n\t\tret = fd_copyin((void __user *)param, &inparam, size);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tswitch (cmd) {\n\tcase FDEJECT:\n\t\tif (drive_state[drive].fd_ref != 1)\n\t\t\t/* somebody else has this drive open */\n\t\t\treturn -EBUSY;\n\t\tif (lock_fdc(drive))\n\t\t\treturn -EINTR;\n\n\t\t/* do the actual eject. Fails on\n\t\t * non-Sparc architectures */\n\t\tret = fd_eject(UNIT(drive));\n\n\t\tset_bit(FD_DISK_CHANGED_BIT, &drive_state[drive].flags);\n\t\tset_bit(FD_VERIFY_BIT, &drive_state[drive].flags);\n\t\tprocess_fd_request();\n\t\treturn ret;\n\tcase FDCLRPRM:\n\t\tif (lock_fdc(drive))\n\t\t\treturn -EINTR;\n\t\tcurrent_type[drive] = NULL;\n\t\tfloppy_sizes[drive] = MAX_DISK_SIZE << 1;\n\t\tdrive_state[drive].keep_data = 0;\n\t\treturn invalidate_drive(bdev);\n\tcase FDSETPRM:\n\tcase FDDEFPRM:\n\t\treturn set_geometry(cmd, &inparam.g, drive, type, bdev);\n\tcase FDGETPRM:\n\t\tret = get_floppy_geometry(drive, type,\n\t\t\t\t\t  (struct floppy_struct **)&outparam);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tmemcpy(&inparam.g, outparam,\n\t\t\t\toffsetof(struct floppy_struct, name));\n\t\toutparam = &inparam.g;\n\t\tbreak;\n\tcase FDMSGON:\n\t\tdrive_params[drive].flags |= FTD_MSG;\n\t\treturn 0;\n\tcase FDMSGOFF:\n\t\tdrive_params[drive].flags &= ~FTD_MSG;\n\t\treturn 0;\n\tcase FDFMTBEG:\n\t\tif (lock_fdc(drive))\n\t\t\treturn -EINTR;\n\t\tif (poll_drive(true, FD_RAW_NEED_DISK) == -EINTR)\n\t\t\treturn -EINTR;\n\t\tret = drive_state[drive].flags;\n\t\tprocess_fd_request();\n\t\tif (ret & FD_VERIFY)\n\t\t\treturn -ENODEV;\n\t\tif (!(ret & FD_DISK_WRITABLE))\n\t\t\treturn -EROFS;\n\t\treturn 0;\n\tcase FDFMTTRK:\n\t\tif (drive_state[drive].fd_ref != 1)\n\t\t\treturn -EBUSY;\n\t\treturn do_format(drive, &inparam.f);\n\tcase FDFMTEND:\n\tcase FDFLUSH:\n\t\tif (lock_fdc(drive))\n\t\t\treturn -EINTR;\n\t\treturn invalidate_drive(bdev);\n\tcase FDSETEMSGTRESH:\n\t\tdrive_params[drive].max_errors.reporting = (unsigned short)(param & 0x0f);\n\t\treturn 0;\n\tcase FDGETMAXERRS:\n\t\toutparam = &drive_params[drive].max_errors;\n\t\tbreak;\n\tcase FDSETMAXERRS:\n\t\tdrive_params[drive].max_errors = inparam.max_errors;\n\t\tbreak;\n\tcase FDGETDRVTYP:\n\t\toutparam = drive_name(type, drive);\n\t\tSUPBOUND(size, strlen((const char *)outparam) + 1);\n\t\tbreak;\n\tcase FDSETDRVPRM:\n\t\tif (!valid_floppy_drive_params(inparam.dp.autodetect,\n\t\t\t\tinparam.dp.native_format))\n\t\t\treturn -EINVAL;\n\t\tdrive_params[drive] = inparam.dp;\n\t\tbreak;\n\tcase FDGETDRVPRM:\n\t\toutparam = &drive_params[drive];\n\t\tbreak;\n\tcase FDPOLLDRVSTAT:\n\t\tif (lock_fdc(drive))\n\t\t\treturn -EINTR;\n\t\tif (poll_drive(true, FD_RAW_NEED_DISK) == -EINTR)\n\t\t\treturn -EINTR;\n\t\tprocess_fd_request();\n\t\tfallthrough;\n\tcase FDGETDRVSTAT:\n\t\toutparam = &drive_state[drive];\n\t\tbreak;\n\tcase FDRESET:\n\t\treturn user_reset_fdc(drive, (int)param, true);\n\tcase FDGETFDCSTAT:\n\t\toutparam = &fdc_state[FDC(drive)];\n\t\tbreak;\n\tcase FDWERRORCLR:\n\t\tmemset(&write_errors[drive], 0, sizeof(write_errors[drive]));\n\t\treturn 0;\n\tcase FDWERRORGET:\n\t\toutparam = &write_errors[drive];\n\t\tbreak;\n\tcase FDRAWCMD:\n\t\tif (type)\n\t\t\treturn -EINVAL;\n\t\tif (lock_fdc(drive))\n\t\t\treturn -EINTR;\n\t\tset_floppy(drive);\n\t\ti = raw_cmd_ioctl(cmd, (void __user *)param);\n\t\tif (i == -EINTR)\n\t\t\treturn -EINTR;\n\t\tprocess_fd_request();\n\t\treturn i;\n\tcase FDTWADDLE:\n\t\tif (lock_fdc(drive))\n\t\t\treturn -EINTR;\n\t\ttwaddle(current_fdc, current_drive);\n\t\tprocess_fd_request();\n\t\treturn 0;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\tif (_IOC_DIR(cmd) & _IOC_READ)\n\t\treturn fd_copyout((void __user *)param, outparam, size);\n\n\treturn 0;\n}",
        "func_hash": 185600890459651071126358112291118902664,
        "file_name": "floppy.c",
        "file_hash": 276679374674708517482827678033656857128,
        "cwe": [
            "CWE-416"
        ],
        "cve": "CVE-2022-1836",
        "cve_desc": "Rejected reason: DO NOT USE THIS CANDIDATE NUMBER. ConsultIDs: CVE-2022-33981. Reason: This candidate is a reservation duplicate of CVE-2022-33981. Notes: All CVE users should reference CVE-2022-33981 instead of this candidate. All references and descriptions in this candidate have been removed to prevent accidental usage",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-1836",
        "func_name": "fd_locked_ioctl",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 199712,
        "project": "linux",
        "commit_id": "8700af2cc18c919b2a83e74e0479038fd113c15d",
        "project_url": "https://github.com/torvalds/linux",
        "commit_url": "https://github.com/torvalds/linux/commit/8700af2cc18c919b2a83e74e0479038fd113c15d",
        "commit_message": "RDMA/rtrs-clt: Fix possible double free in error case\n\nCallback function rtrs_clt_dev_release() for put_device() calls kfree(clt)\nto free memory. We shouldn't call kfree(clt) again, and we can't use the\nclt after kfree too.\n\nReplace device_register() with device_initialize() and device_add() so that\ndev_set_name can() be used appropriately.\n\nMove mutex_destroy() to the release function so it can be called in\nthe alloc_clt err path.\n\nFixes: eab098246625 (\"RDMA/rtrs-clt: Refactor the failure cases in alloc_clt\")\nLink: https://lore.kernel.org/r/20220217030929.323849-1-haris.iqbal@ionos.com\nReported-by: Miaoqian Lin <linmq006@gmail.com>\nSigned-off-by: Md Haris Iqbal <haris.iqbal@ionos.com>\nReviewed-by: Jack Wang <jinpu.wang@ionos.com>\nSigned-off-by: Jason Gunthorpe <jgg@nvidia.com>",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static void rtrs_clt_dev_release(struct device *dev)\n{\n\tstruct rtrs_clt_sess *clt = container_of(dev, struct rtrs_clt_sess,\n\t\t\t\t\t\t dev);\n\n\tkfree(clt);\n}",
        "func_hash": 64652297556654438298355501352205556509,
        "file_name": "rtrs-clt.c",
        "file_hash": 149775209474441169700962555059878991264,
        "cwe": [
            "CWE-415"
        ],
        "cve": "CVE-2022-29156",
        "cve_desc": "drivers/infiniband/ulp/rtrs/rtrs-clt.c in the Linux kernel before 5.16.12 has a double free related to rtrs_clt_dev_release.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-29156",
        "func_name": "rtrs_clt_dev_release",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 199767,
        "project": "hexchat",
        "commit_id": "4e061a43b3453a9856d34250c3913175c45afe9d",
        "project_url": "https://github.com/hexchat/hexchat",
        "commit_url": "https://github.com/hexchat/hexchat/commit/4e061a43b3453a9856d34250c3913175c45afe9d",
        "commit_message": "Clean up handling CAP LS",
        "target": 1,
        "irrelevant": 0,
        "func_before": "inbound_cap_ls (server *serv, char *nick, char *extensions_str,\n\t\t\t\t\t const message_tags_data *tags_data)\n{\n\tchar buffer[256];\t/* buffer for requesting capabilities and emitting the signal */\n\tguint32 want_cap; /* format the CAP REQ string based on previous capabilities being requested or not */\n\tguint32 want_sasl; /* CAP END shouldn't be sent when SASL is requested, it needs further responses */\n\tchar **extensions;\n\tint i;\n\n\tEMIT_SIGNAL_TIMESTAMP (XP_TE_CAPLIST, serv->server_session, nick,\n\t\t\t\t\t\t\t\t  extensions_str, NULL, NULL, 0, tags_data->timestamp);\n\twant_cap = 0;\n\twant_sasl = 0;\n\n\textensions = g_strsplit (extensions_str, \" \", 0);\n\n\tstrcpy (buffer, \"CAP REQ :\");\n\n\tfor (i=0; extensions[i]; i++)\n\t{\n\t\tconst char *extension = extensions[i];\n\n\t\tif (!strcmp (extension, \"identify-msg\"))\n\t\t{\n\t\t\tstrcat (buffer, \"identify-msg \");\n\t\t\twant_cap = 1;\n\t\t}\n\t\tif (!strcmp (extension, \"multi-prefix\"))\n\t\t{\n\t\t\tstrcat (buffer, \"multi-prefix \");\n\t\t\twant_cap = 1;\n\t\t}\n\t\tif (!strcmp (extension, \"away-notify\"))\n\t\t{\n\t\t\tstrcat (buffer, \"away-notify \");\n\t\t\twant_cap = 1;\n\t\t}\n\t\tif (!strcmp (extension, \"account-notify\"))\n\t\t{\n\t\t\tstrcat (buffer, \"account-notify \");\n\t\t\twant_cap = 1;\n\t\t}\n\t\tif (!strcmp (extension, \"extended-join\"))\n\t\t{\n\t\t\tstrcat (buffer, \"extended-join \");\n\t\t\twant_cap = 1;\n\t\t}\n\t\tif (!strcmp (extension, \"userhost-in-names\"))\n\t\t{\n\t\t\tstrcat (buffer, \"userhost-in-names \");\n\t\t\twant_cap = 1;\n\t\t}\n\n\t\t/* bouncers can prefix a name space to the extension so we should use.\n\t\t * znc <= 1.0 uses \"znc.in/server-time\" and newer use \"znc.in/server-time-iso\".\n\t\t */\n\t\tif (!strcmp (extension, \"znc.in/server-time-iso\"))\n\t\t{\n\t\t\tstrcat (buffer, \"znc.in/server-time-iso \");\n\t\t\twant_cap = 1;\n\t\t}\n\t\tif (!strcmp (extension, \"znc.in/server-time\"))\n\t\t{\n\t\t\tstrcat (buffer, \"znc.in/server-time \");\n\t\t\twant_cap = 1;\n\t\t}\n\t\tif (prefs.hex_irc_cap_server_time\n\t\t\t && !strcmp (extension, \"server-time\"))\n\t\t{\n\t\t\tstrcat (buffer, \"server-time \");\n\t\t\twant_cap = 1;\n\t\t}\n\t\t\n\t\t/* if the SASL password is set AND auth mode is set to SASL, request SASL auth */\n\t\tif (!strcmp (extension, \"sasl\")\n\t\t\t&& ((serv->loginmethod == LOGIN_SASL && strlen (serv->password) != 0)\n\t\t\t|| (serv->loginmethod == LOGIN_SASLEXTERNAL && serv->have_cert)))\n\t\t{\n\t\t\tstrcat (buffer, \"sasl \");\n\t\t\twant_cap = 1;\n\t\t\twant_sasl = 1;\n\t\t}\n\t}\n\n\tg_strfreev (extensions);\n\n\tif (want_cap)\n\t{\n\t\t/* buffer + 9 = emit buffer without \"CAP REQ :\" */\n\t\tEMIT_SIGNAL_TIMESTAMP (XP_TE_CAPREQ, serv->server_session,\n\t\t\t\t\t\t\t\t\t  buffer + 9, NULL, NULL, NULL, 0,\n\t\t\t\t\t\t\t\t\t  tags_data->timestamp);\n\t\ttcp_sendf (serv, \"%s\\r\\n\", g_strchomp (buffer));\n\t}\n\tif (!want_sasl)\n\t{\n\t\t/* if we use SASL, CAP END is dealt via raw numerics */\n\t\tserv->sent_capend = TRUE;\n\t\ttcp_send_len (serv, \"CAP END\\r\\n\", 9);\n\t}\n}",
        "func_hash": 289376674180826741553106169575003472652,
        "file_name": "inbound.c",
        "file_hash": 202497518967624726910452754426675896941,
        "cwe": [
            "CWE-22"
        ],
        "cve": "CVE-2016-2087",
        "cve_desc": "Directory traversal vulnerability in the client in HexChat 2.11.0 allows remote IRC servers to read or modify arbitrary files via a .. (dot dot) in the server name.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2016-2087",
        "func_name": "inbound_cap_ls",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 199778,
        "project": "puma",
        "commit_id": "acdc3ae571dfae0e045cf09a295280127db65c7f",
        "project_url": "https://github.com/puma/puma",
        "commit_url": "https://github.com/puma/puma/commit/acdc3ae571dfae0e045cf09a295280127db65c7f",
        "commit_message": "Merge pull request from GHSA-48w2-rm65-62xx\n\n* Fix HTTP request smuggling vulnerability\n\nSee GHSA-48w2-rm65-62xx or CVE-2021-41136 for more info.\n\n* 4.3.9 release note\n\n* 5.5.1 release note\n\n* 5.5.1",
        "target": 1,
        "irrelevant": 0,
        "func_before": "size_t puma_parser_execute(puma_parser *parser, const char *buffer, size_t len, size_t off)  {\n  const char *p, *pe;\n  int cs = parser->cs;\n\n  assert(off <= len && \"offset past end of buffer\");\n\n  p = buffer+off;\n  pe = buffer+len;\n\n  /* assert(*pe == '\\0' && \"pointer does not end on NUL\"); */\n  assert((size_t) (pe - p) == len - off && \"pointers aren't same distance\");\n\n  \n#line 87 \"ext/puma_http11/http11_parser.c\"\n\t{\n\tif ( p == pe )\n\t\tgoto _test_eof;\n\tswitch ( cs )\n\t{\ncase 1:\n\tswitch( (*p) ) {\n\t\tcase 36: goto tr0;\n\t\tcase 95: goto tr0;\n\t}\n\tif ( (*p) < 48 ) {\n\t\tif ( 45 <= (*p) && (*p) <= 46 )\n\t\t\tgoto tr0;\n\t} else if ( (*p) > 57 ) {\n\t\tif ( 65 <= (*p) && (*p) <= 90 )\n\t\t\tgoto tr0;\n\t} else\n\t\tgoto tr0;\n\tgoto st0;\nst0:\ncs = 0;\n\tgoto _out;\ntr0:\n#line 37 \"ext/puma_http11/http11_parser.rl\"\n\t{ MARK(mark, p); }\n\tgoto st2;\nst2:\n\tif ( ++p == pe )\n\t\tgoto _test_eof2;\ncase 2:\n#line 118 \"ext/puma_http11/http11_parser.c\"\n\tswitch( (*p) ) {\n\t\tcase 32: goto tr2;\n\t\tcase 36: goto st27;\n\t\tcase 95: goto st27;\n\t}\n\tif ( (*p) < 48 ) {\n\t\tif ( 45 <= (*p) && (*p) <= 46 )\n\t\t\tgoto st27;\n\t} else if ( (*p) > 57 ) {\n\t\tif ( 65 <= (*p) && (*p) <= 90 )\n\t\t\tgoto st27;\n\t} else\n\t\tgoto st27;\n\tgoto st0;\ntr2:\n#line 50 \"ext/puma_http11/http11_parser.rl\"\n\t{\n    parser->request_method(parser, PTR_TO(mark), LEN(mark, p));\n  }\n\tgoto st3;\nst3:\n\tif ( ++p == pe )\n\t\tgoto _test_eof3;\ncase 3:\n#line 143 \"ext/puma_http11/http11_parser.c\"\n\tswitch( (*p) ) {\n\t\tcase 42: goto tr4;\n\t\tcase 43: goto tr5;\n\t\tcase 47: goto tr6;\n\t\tcase 58: goto tr7;\n\t}\n\tif ( (*p) < 65 ) {\n\t\tif ( 45 <= (*p) && (*p) <= 57 )\n\t\t\tgoto tr5;\n\t} else if ( (*p) > 90 ) {\n\t\tif ( 97 <= (*p) && (*p) <= 122 )\n\t\t\tgoto tr5;\n\t} else\n\t\tgoto tr5;\n\tgoto st0;\ntr4:\n#line 37 \"ext/puma_http11/http11_parser.rl\"\n\t{ MARK(mark, p); }\n\tgoto st4;\nst4:\n\tif ( ++p == pe )\n\t\tgoto _test_eof4;\ncase 4:\n#line 167 \"ext/puma_http11/http11_parser.c\"\n\tswitch( (*p) ) {\n\t\tcase 32: goto tr8;\n\t\tcase 35: goto tr9;\n\t}\n\tgoto st0;\ntr8:\n#line 53 \"ext/puma_http11/http11_parser.rl\"\n\t{\n    parser->request_uri(parser, PTR_TO(mark), LEN(mark, p));\n  }\n\tgoto st5;\ntr31:\n#line 37 \"ext/puma_http11/http11_parser.rl\"\n\t{ MARK(mark, p); }\n#line 56 \"ext/puma_http11/http11_parser.rl\"\n\t{\n    parser->fragment(parser, PTR_TO(mark), LEN(mark, p));\n  }\n\tgoto st5;\ntr33:\n#line 56 \"ext/puma_http11/http11_parser.rl\"\n\t{\n    parser->fragment(parser, PTR_TO(mark), LEN(mark, p));\n  }\n\tgoto st5;\ntr37:\n#line 69 \"ext/puma_http11/http11_parser.rl\"\n\t{\n    parser->request_path(parser, PTR_TO(mark), LEN(mark,p));\n  }\n#line 53 \"ext/puma_http11/http11_parser.rl\"\n\t{\n    parser->request_uri(parser, PTR_TO(mark), LEN(mark, p));\n  }\n\tgoto st5;\ntr41:\n#line 60 \"ext/puma_http11/http11_parser.rl\"\n\t{ MARK(query_start, p); }\n#line 61 \"ext/puma_http11/http11_parser.rl\"\n\t{\n    parser->query_string(parser, PTR_TO(query_start), LEN(query_start, p));\n  }\n#line 53 \"ext/puma_http11/http11_parser.rl\"\n\t{\n    parser->request_uri(parser, PTR_TO(mark), LEN(mark, p));\n  }\n\tgoto st5;\ntr44:\n#line 61 \"ext/puma_http11/http11_parser.rl\"\n\t{\n    parser->query_string(parser, PTR_TO(query_start), LEN(query_start, p));\n  }\n#line 53 \"ext/puma_http11/http11_parser.rl\"\n\t{\n    parser->request_uri(parser, PTR_TO(mark), LEN(mark, p));\n  }\n\tgoto st5;\nst5:\n\tif ( ++p == pe )\n\t\tgoto _test_eof5;\ncase 5:\n#line 229 \"ext/puma_http11/http11_parser.c\"\n\tif ( (*p) == 72 )\n\t\tgoto tr10;\n\tgoto st0;\ntr10:\n#line 37 \"ext/puma_http11/http11_parser.rl\"\n\t{ MARK(mark, p); }\n\tgoto st6;\nst6:\n\tif ( ++p == pe )\n\t\tgoto _test_eof6;\ncase 6:\n#line 241 \"ext/puma_http11/http11_parser.c\"\n\tif ( (*p) == 84 )\n\t\tgoto st7;\n\tgoto st0;\nst7:\n\tif ( ++p == pe )\n\t\tgoto _test_eof7;\ncase 7:\n\tif ( (*p) == 84 )\n\t\tgoto st8;\n\tgoto st0;\nst8:\n\tif ( ++p == pe )\n\t\tgoto _test_eof8;\ncase 8:\n\tif ( (*p) == 80 )\n\t\tgoto st9;\n\tgoto st0;\nst9:\n\tif ( ++p == pe )\n\t\tgoto _test_eof9;\ncase 9:\n\tif ( (*p) == 47 )\n\t\tgoto st10;\n\tgoto st0;\nst10:\n\tif ( ++p == pe )\n\t\tgoto _test_eof10;\ncase 10:\n\tif ( 48 <= (*p) && (*p) <= 57 )\n\t\tgoto st11;\n\tgoto st0;\nst11:\n\tif ( ++p == pe )\n\t\tgoto _test_eof11;\ncase 11:\n\tif ( (*p) == 46 )\n\t\tgoto st12;\n\tif ( 48 <= (*p) && (*p) <= 57 )\n\t\tgoto st11;\n\tgoto st0;\nst12:\n\tif ( ++p == pe )\n\t\tgoto _test_eof12;\ncase 12:\n\tif ( 48 <= (*p) && (*p) <= 57 )\n\t\tgoto st13;\n\tgoto st0;\nst13:\n\tif ( ++p == pe )\n\t\tgoto _test_eof13;\ncase 13:\n\tif ( (*p) == 13 )\n\t\tgoto tr18;\n\tif ( 48 <= (*p) && (*p) <= 57 )\n\t\tgoto st13;\n\tgoto st0;\ntr18:\n#line 65 \"ext/puma_http11/http11_parser.rl\"\n\t{\n    parser->http_version(parser, PTR_TO(mark), LEN(mark, p));\n  }\n\tgoto st14;\ntr26:\n#line 46 \"ext/puma_http11/http11_parser.rl\"\n\t{ MARK(mark, p); }\n#line 47 \"ext/puma_http11/http11_parser.rl\"\n\t{\n    parser->http_field(parser, PTR_TO(field_start), parser->field_len, PTR_TO(mark), LEN(mark, p));\n  }\n\tgoto st14;\ntr29:\n#line 47 \"ext/puma_http11/http11_parser.rl\"\n\t{\n    parser->http_field(parser, PTR_TO(field_start), parser->field_len, PTR_TO(mark), LEN(mark, p));\n  }\n\tgoto st14;\nst14:\n\tif ( ++p == pe )\n\t\tgoto _test_eof14;\ncase 14:\n#line 322 \"ext/puma_http11/http11_parser.c\"\n\tif ( (*p) == 10 )\n\t\tgoto st15;\n\tgoto st0;\nst15:\n\tif ( ++p == pe )\n\t\tgoto _test_eof15;\ncase 15:\n\tswitch( (*p) ) {\n\t\tcase 13: goto st16;\n\t\tcase 33: goto tr21;\n\t\tcase 124: goto tr21;\n\t\tcase 126: goto tr21;\n\t}\n\tif ( (*p) < 45 ) {\n\t\tif ( (*p) > 39 ) {\n\t\t\tif ( 42 <= (*p) && (*p) <= 43 )\n\t\t\t\tgoto tr21;\n\t\t} else if ( (*p) >= 35 )\n\t\t\tgoto tr21;\n\t} else if ( (*p) > 46 ) {\n\t\tif ( (*p) < 65 ) {\n\t\t\tif ( 48 <= (*p) && (*p) <= 57 )\n\t\t\t\tgoto tr21;\n\t\t} else if ( (*p) > 90 ) {\n\t\t\tif ( 94 <= (*p) && (*p) <= 122 )\n\t\t\t\tgoto tr21;\n\t\t} else\n\t\t\tgoto tr21;\n\t} else\n\t\tgoto tr21;\n\tgoto st0;\nst16:\n\tif ( ++p == pe )\n\t\tgoto _test_eof16;\ncase 16:\n\tif ( (*p) == 10 )\n\t\tgoto tr22;\n\tgoto st0;\ntr22:\n#line 73 \"ext/puma_http11/http11_parser.rl\"\n\t{\n    parser->body_start = p - buffer + 1;\n    parser->header_done(parser, p + 1, pe - p - 1);\n    {p++; cs = 46; goto _out;}\n  }\n\tgoto st46;\nst46:\n\tif ( ++p == pe )\n\t\tgoto _test_eof46;\ncase 46:\n#line 373 \"ext/puma_http11/http11_parser.c\"\n\tgoto st0;\ntr21:\n#line 40 \"ext/puma_http11/http11_parser.rl\"\n\t{ MARK(field_start, p); }\n#line 41 \"ext/puma_http11/http11_parser.rl\"\n\t{ snake_upcase_char((char *)p); }\n\tgoto st17;\ntr23:\n#line 41 \"ext/puma_http11/http11_parser.rl\"\n\t{ snake_upcase_char((char *)p); }\n\tgoto st17;\nst17:\n\tif ( ++p == pe )\n\t\tgoto _test_eof17;\ncase 17:\n#line 389 \"ext/puma_http11/http11_parser.c\"\n\tswitch( (*p) ) {\n\t\tcase 33: goto tr23;\n\t\tcase 58: goto tr24;\n\t\tcase 124: goto tr23;\n\t\tcase 126: goto tr23;\n\t}\n\tif ( (*p) < 45 ) {\n\t\tif ( (*p) > 39 ) {\n\t\t\tif ( 42 <= (*p) && (*p) <= 43 )\n\t\t\t\tgoto tr23;\n\t\t} else if ( (*p) >= 35 )\n\t\t\tgoto tr23;\n\t} else if ( (*p) > 46 ) {\n\t\tif ( (*p) < 65 ) {\n\t\t\tif ( 48 <= (*p) && (*p) <= 57 )\n\t\t\t\tgoto tr23;\n\t\t} else if ( (*p) > 90 ) {\n\t\t\tif ( 94 <= (*p) && (*p) <= 122 )\n\t\t\t\tgoto tr23;\n\t\t} else\n\t\t\tgoto tr23;\n\t} else\n\t\tgoto tr23;\n\tgoto st0;\ntr24:\n#line 42 \"ext/puma_http11/http11_parser.rl\"\n\t{\n    parser->field_len = LEN(field_start, p);\n  }\n\tgoto st18;\ntr27:\n#line 46 \"ext/puma_http11/http11_parser.rl\"\n\t{ MARK(mark, p); }\n\tgoto st18;\nst18:\n\tif ( ++p == pe )\n\t\tgoto _test_eof18;\ncase 18:\n#line 428 \"ext/puma_http11/http11_parser.c\"\n\tswitch( (*p) ) {\n\t\tcase 13: goto tr26;\n\t\tcase 32: goto tr27;\n\t}\n\tgoto tr25;\ntr25:\n#line 46 \"ext/puma_http11/http11_parser.rl\"\n\t{ MARK(mark, p); }\n\tgoto st19;\nst19:\n\tif ( ++p == pe )\n\t\tgoto _test_eof19;\ncase 19:\n#line 442 \"ext/puma_http11/http11_parser.c\"\n\tif ( (*p) == 13 )\n\t\tgoto tr29;\n\tgoto st19;\ntr9:\n#line 53 \"ext/puma_http11/http11_parser.rl\"\n\t{\n    parser->request_uri(parser, PTR_TO(mark), LEN(mark, p));\n  }\n\tgoto st20;\ntr38:\n#line 69 \"ext/puma_http11/http11_parser.rl\"\n\t{\n    parser->request_path(parser, PTR_TO(mark), LEN(mark,p));\n  }\n#line 53 \"ext/puma_http11/http11_parser.rl\"\n\t{\n    parser->request_uri(parser, PTR_TO(mark), LEN(mark, p));\n  }\n\tgoto st20;\ntr42:\n#line 60 \"ext/puma_http11/http11_parser.rl\"\n\t{ MARK(query_start, p); }\n#line 61 \"ext/puma_http11/http11_parser.rl\"\n\t{\n    parser->query_string(parser, PTR_TO(query_start), LEN(query_start, p));\n  }\n#line 53 \"ext/puma_http11/http11_parser.rl\"\n\t{\n    parser->request_uri(parser, PTR_TO(mark), LEN(mark, p));\n  }\n\tgoto st20;\ntr45:\n#line 61 \"ext/puma_http11/http11_parser.rl\"\n\t{\n    parser->query_string(parser, PTR_TO(query_start), LEN(query_start, p));\n  }\n#line 53 \"ext/puma_http11/http11_parser.rl\"\n\t{\n    parser->request_uri(parser, PTR_TO(mark), LEN(mark, p));\n  }\n\tgoto st20;\nst20:\n\tif ( ++p == pe )\n\t\tgoto _test_eof20;\ncase 20:\n#line 488 \"ext/puma_http11/http11_parser.c\"\n\tswitch( (*p) ) {\n\t\tcase 32: goto tr31;\n\t\tcase 60: goto st0;\n\t\tcase 62: goto st0;\n\t\tcase 127: goto st0;\n\t}\n\tif ( (*p) > 31 ) {\n\t\tif ( 34 <= (*p) && (*p) <= 35 )\n\t\t\tgoto st0;\n\t} else if ( (*p) >= 0 )\n\t\tgoto st0;\n\tgoto tr30;\ntr30:\n#line 37 \"ext/puma_http11/http11_parser.rl\"\n\t{ MARK(mark, p); }\n\tgoto st21;\nst21:\n\tif ( ++p == pe )\n\t\tgoto _test_eof21;\ncase 21:\n#line 509 \"ext/puma_http11/http11_parser.c\"\n\tswitch( (*p) ) {\n\t\tcase 32: goto tr33;\n\t\tcase 60: goto st0;\n\t\tcase 62: goto st0;\n\t\tcase 127: goto st0;\n\t}\n\tif ( (*p) > 31 ) {\n\t\tif ( 34 <= (*p) && (*p) <= 35 )\n\t\t\tgoto st0;\n\t} else if ( (*p) >= 0 )\n\t\tgoto st0;\n\tgoto st21;\ntr5:\n#line 37 \"ext/puma_http11/http11_parser.rl\"\n\t{ MARK(mark, p); }\n\tgoto st22;\nst22:\n\tif ( ++p == pe )\n\t\tgoto _test_eof22;\ncase 22:\n#line 530 \"ext/puma_http11/http11_parser.c\"\n\tswitch( (*p) ) {\n\t\tcase 43: goto st22;\n\t\tcase 58: goto st23;\n\t}\n\tif ( (*p) < 48 ) {\n\t\tif ( 45 <= (*p) && (*p) <= 46 )\n\t\t\tgoto st22;\n\t} else if ( (*p) > 57 ) {\n\t\tif ( (*p) > 90 ) {\n\t\t\tif ( 97 <= (*p) && (*p) <= 122 )\n\t\t\t\tgoto st22;\n\t\t} else if ( (*p) >= 65 )\n\t\t\tgoto st22;\n\t} else\n\t\tgoto st22;\n\tgoto st0;\ntr7:\n#line 37 \"ext/puma_http11/http11_parser.rl\"\n\t{ MARK(mark, p); }\n\tgoto st23;\nst23:\n\tif ( ++p == pe )\n\t\tgoto _test_eof23;\ncase 23:\n#line 555 \"ext/puma_http11/http11_parser.c\"\n\tswitch( (*p) ) {\n\t\tcase 32: goto tr8;\n\t\tcase 34: goto st0;\n\t\tcase 35: goto tr9;\n\t\tcase 60: goto st0;\n\t\tcase 62: goto st0;\n\t\tcase 127: goto st0;\n\t}\n\tif ( 0 <= (*p) && (*p) <= 31 )\n\t\tgoto st0;\n\tgoto st23;\ntr6:\n#line 37 \"ext/puma_http11/http11_parser.rl\"\n\t{ MARK(mark, p); }\n\tgoto st24;\nst24:\n\tif ( ++p == pe )\n\t\tgoto _test_eof24;\ncase 24:\n#line 575 \"ext/puma_http11/http11_parser.c\"\n\tswitch( (*p) ) {\n\t\tcase 32: goto tr37;\n\t\tcase 34: goto st0;\n\t\tcase 35: goto tr38;\n\t\tcase 60: goto st0;\n\t\tcase 62: goto st0;\n\t\tcase 63: goto tr39;\n\t\tcase 127: goto st0;\n\t}\n\tif ( 0 <= (*p) && (*p) <= 31 )\n\t\tgoto st0;\n\tgoto st24;\ntr39:\n#line 69 \"ext/puma_http11/http11_parser.rl\"\n\t{\n    parser->request_path(parser, PTR_TO(mark), LEN(mark,p));\n  }\n\tgoto st25;\nst25:\n\tif ( ++p == pe )\n\t\tgoto _test_eof25;\ncase 25:\n#line 598 \"ext/puma_http11/http11_parser.c\"\n\tswitch( (*p) ) {\n\t\tcase 32: goto tr41;\n\t\tcase 34: goto st0;\n\t\tcase 35: goto tr42;\n\t\tcase 60: goto st0;\n\t\tcase 62: goto st0;\n\t\tcase 127: goto st0;\n\t}\n\tif ( 0 <= (*p) && (*p) <= 31 )\n\t\tgoto st0;\n\tgoto tr40;\ntr40:\n#line 60 \"ext/puma_http11/http11_parser.rl\"\n\t{ MARK(query_start, p); }\n\tgoto st26;\nst26:\n\tif ( ++p == pe )\n\t\tgoto _test_eof26;\ncase 26:\n#line 618 \"ext/puma_http11/http11_parser.c\"\n\tswitch( (*p) ) {\n\t\tcase 32: goto tr44;\n\t\tcase 34: goto st0;\n\t\tcase 35: goto tr45;\n\t\tcase 60: goto st0;\n\t\tcase 62: goto st0;\n\t\tcase 127: goto st0;\n\t}\n\tif ( 0 <= (*p) && (*p) <= 31 )\n\t\tgoto st0;\n\tgoto st26;\nst27:\n\tif ( ++p == pe )\n\t\tgoto _test_eof27;\ncase 27:\n\tswitch( (*p) ) {\n\t\tcase 32: goto tr2;\n\t\tcase 36: goto st28;\n\t\tcase 95: goto st28;\n\t}\n\tif ( (*p) < 48 ) {\n\t\tif ( 45 <= (*p) && (*p) <= 46 )\n\t\t\tgoto st28;\n\t} else if ( (*p) > 57 ) {\n\t\tif ( 65 <= (*p) && (*p) <= 90 )\n\t\t\tgoto st28;\n\t} else\n\t\tgoto st28;\n\tgoto st0;\nst28:\n\tif ( ++p == pe )\n\t\tgoto _test_eof28;\ncase 28:\n\tswitch( (*p) ) {\n\t\tcase 32: goto tr2;\n\t\tcase 36: goto st29;\n\t\tcase 95: goto st29;\n\t}\n\tif ( (*p) < 48 ) {\n\t\tif ( 45 <= (*p) && (*p) <= 46 )\n\t\t\tgoto st29;\n\t} else if ( (*p) > 57 ) {\n\t\tif ( 65 <= (*p) && (*p) <= 90 )\n\t\t\tgoto st29;\n\t} else\n\t\tgoto st29;\n\tgoto st0;\nst29:\n\tif ( ++p == pe )\n\t\tgoto _test_eof29;\ncase 29:\n\tswitch( (*p) ) {\n\t\tcase 32: goto tr2;\n\t\tcase 36: goto st30;\n\t\tcase 95: goto st30;\n\t}\n\tif ( (*p) < 48 ) {\n\t\tif ( 45 <= (*p) && (*p) <= 46 )\n\t\t\tgoto st30;\n\t} else if ( (*p) > 57 ) {\n\t\tif ( 65 <= (*p) && (*p) <= 90 )\n\t\t\tgoto st30;\n\t} else\n\t\tgoto st30;\n\tgoto st0;\nst30:\n\tif ( ++p == pe )\n\t\tgoto _test_eof30;\ncase 30:\n\tswitch( (*p) ) {\n\t\tcase 32: goto tr2;\n\t\tcase 36: goto st31;\n\t\tcase 95: goto st31;\n\t}\n\tif ( (*p) < 48 ) {\n\t\tif ( 45 <= (*p) && (*p) <= 46 )\n\t\t\tgoto st31;\n\t} else if ( (*p) > 57 ) {\n\t\tif ( 65 <= (*p) && (*p) <= 90 )\n\t\t\tgoto st31;\n\t} else\n\t\tgoto st31;\n\tgoto st0;\nst31:\n\tif ( ++p == pe )\n\t\tgoto _test_eof31;\ncase 31:\n\tswitch( (*p) ) {\n\t\tcase 32: goto tr2;\n\t\tcase 36: goto st32;\n\t\tcase 95: goto st32;\n\t}\n\tif ( (*p) < 48 ) {\n\t\tif ( 45 <= (*p) && (*p) <= 46 )\n\t\t\tgoto st32;\n\t} else if ( (*p) > 57 ) {\n\t\tif ( 65 <= (*p) && (*p) <= 90 )\n\t\t\tgoto st32;\n\t} else\n\t\tgoto st32;\n\tgoto st0;\nst32:\n\tif ( ++p == pe )\n\t\tgoto _test_eof32;\ncase 32:\n\tswitch( (*p) ) {\n\t\tcase 32: goto tr2;\n\t\tcase 36: goto st33;\n\t\tcase 95: goto st33;\n\t}\n\tif ( (*p) < 48 ) {\n\t\tif ( 45 <= (*p) && (*p) <= 46 )\n\t\t\tgoto st33;\n\t} else if ( (*p) > 57 ) {\n\t\tif ( 65 <= (*p) && (*p) <= 90 )\n\t\t\tgoto st33;\n\t} else\n\t\tgoto st33;\n\tgoto st0;\nst33:\n\tif ( ++p == pe )\n\t\tgoto _test_eof33;\ncase 33:\n\tswitch( (*p) ) {\n\t\tcase 32: goto tr2;\n\t\tcase 36: goto st34;\n\t\tcase 95: goto st34;\n\t}\n\tif ( (*p) < 48 ) {\n\t\tif ( 45 <= (*p) && (*p) <= 46 )\n\t\t\tgoto st34;\n\t} else if ( (*p) > 57 ) {\n\t\tif ( 65 <= (*p) && (*p) <= 90 )\n\t\t\tgoto st34;\n\t} else\n\t\tgoto st34;\n\tgoto st0;\nst34:\n\tif ( ++p == pe )\n\t\tgoto _test_eof34;\ncase 34:\n\tswitch( (*p) ) {\n\t\tcase 32: goto tr2;\n\t\tcase 36: goto st35;\n\t\tcase 95: goto st35;\n\t}\n\tif ( (*p) < 48 ) {\n\t\tif ( 45 <= (*p) && (*p) <= 46 )\n\t\t\tgoto st35;\n\t} else if ( (*p) > 57 ) {\n\t\tif ( 65 <= (*p) && (*p) <= 90 )\n\t\t\tgoto st35;\n\t} else\n\t\tgoto st35;\n\tgoto st0;\nst35:\n\tif ( ++p == pe )\n\t\tgoto _test_eof35;\ncase 35:\n\tswitch( (*p) ) {\n\t\tcase 32: goto tr2;\n\t\tcase 36: goto st36;\n\t\tcase 95: goto st36;\n\t}\n\tif ( (*p) < 48 ) {\n\t\tif ( 45 <= (*p) && (*p) <= 46 )\n\t\t\tgoto st36;\n\t} else if ( (*p) > 57 ) {\n\t\tif ( 65 <= (*p) && (*p) <= 90 )\n\t\t\tgoto st36;\n\t} else\n\t\tgoto st36;\n\tgoto st0;\nst36:\n\tif ( ++p == pe )\n\t\tgoto _test_eof36;\ncase 36:\n\tswitch( (*p) ) {\n\t\tcase 32: goto tr2;\n\t\tcase 36: goto st37;\n\t\tcase 95: goto st37;\n\t}\n\tif ( (*p) < 48 ) {\n\t\tif ( 45 <= (*p) && (*p) <= 46 )\n\t\t\tgoto st37;\n\t} else if ( (*p) > 57 ) {\n\t\tif ( 65 <= (*p) && (*p) <= 90 )\n\t\t\tgoto st37;\n\t} else\n\t\tgoto st37;\n\tgoto st0;\nst37:\n\tif ( ++p == pe )\n\t\tgoto _test_eof37;\ncase 37:\n\tswitch( (*p) ) {\n\t\tcase 32: goto tr2;\n\t\tcase 36: goto st38;\n\t\tcase 95: goto st38;\n\t}\n\tif ( (*p) < 48 ) {\n\t\tif ( 45 <= (*p) && (*p) <= 46 )\n\t\t\tgoto st38;\n\t} else if ( (*p) > 57 ) {\n\t\tif ( 65 <= (*p) && (*p) <= 90 )\n\t\t\tgoto st38;\n\t} else\n\t\tgoto st38;\n\tgoto st0;\nst38:\n\tif ( ++p == pe )\n\t\tgoto _test_eof38;\ncase 38:\n\tswitch( (*p) ) {\n\t\tcase 32: goto tr2;\n\t\tcase 36: goto st39;\n\t\tcase 95: goto st39;\n\t}\n\tif ( (*p) < 48 ) {\n\t\tif ( 45 <= (*p) && (*p) <= 46 )\n\t\t\tgoto st39;\n\t} else if ( (*p) > 57 ) {\n\t\tif ( 65 <= (*p) && (*p) <= 90 )\n\t\t\tgoto st39;\n\t} else\n\t\tgoto st39;\n\tgoto st0;\nst39:\n\tif ( ++p == pe )\n\t\tgoto _test_eof39;\ncase 39:\n\tswitch( (*p) ) {\n\t\tcase 32: goto tr2;\n\t\tcase 36: goto st40;\n\t\tcase 95: goto st40;\n\t}\n\tif ( (*p) < 48 ) {\n\t\tif ( 45 <= (*p) && (*p) <= 46 )\n\t\t\tgoto st40;\n\t} else if ( (*p) > 57 ) {\n\t\tif ( 65 <= (*p) && (*p) <= 90 )\n\t\t\tgoto st40;\n\t} else\n\t\tgoto st40;\n\tgoto st0;\nst40:\n\tif ( ++p == pe )\n\t\tgoto _test_eof40;\ncase 40:\n\tswitch( (*p) ) {\n\t\tcase 32: goto tr2;\n\t\tcase 36: goto st41;\n\t\tcase 95: goto st41;\n\t}\n\tif ( (*p) < 48 ) {\n\t\tif ( 45 <= (*p) && (*p) <= 46 )\n\t\t\tgoto st41;\n\t} else if ( (*p) > 57 ) {\n\t\tif ( 65 <= (*p) && (*p) <= 90 )\n\t\t\tgoto st41;\n\t} else\n\t\tgoto st41;\n\tgoto st0;\nst41:\n\tif ( ++p == pe )\n\t\tgoto _test_eof41;\ncase 41:\n\tswitch( (*p) ) {\n\t\tcase 32: goto tr2;\n\t\tcase 36: goto st42;\n\t\tcase 95: goto st42;\n\t}\n\tif ( (*p) < 48 ) {\n\t\tif ( 45 <= (*p) && (*p) <= 46 )\n\t\t\tgoto st42;\n\t} else if ( (*p) > 57 ) {\n\t\tif ( 65 <= (*p) && (*p) <= 90 )\n\t\t\tgoto st42;\n\t} else\n\t\tgoto st42;\n\tgoto st0;\nst42:\n\tif ( ++p == pe )\n\t\tgoto _test_eof42;\ncase 42:\n\tswitch( (*p) ) {\n\t\tcase 32: goto tr2;\n\t\tcase 36: goto st43;\n\t\tcase 95: goto st43;\n\t}\n\tif ( (*p) < 48 ) {\n\t\tif ( 45 <= (*p) && (*p) <= 46 )\n\t\t\tgoto st43;\n\t} else if ( (*p) > 57 ) {\n\t\tif ( 65 <= (*p) && (*p) <= 90 )\n\t\t\tgoto st43;\n\t} else\n\t\tgoto st43;\n\tgoto st0;\nst43:\n\tif ( ++p == pe )\n\t\tgoto _test_eof43;\ncase 43:\n\tswitch( (*p) ) {\n\t\tcase 32: goto tr2;\n\t\tcase 36: goto st44;\n\t\tcase 95: goto st44;\n\t}\n\tif ( (*p) < 48 ) {\n\t\tif ( 45 <= (*p) && (*p) <= 46 )\n\t\t\tgoto st44;\n\t} else if ( (*p) > 57 ) {\n\t\tif ( 65 <= (*p) && (*p) <= 90 )\n\t\t\tgoto st44;\n\t} else\n\t\tgoto st44;\n\tgoto st0;\nst44:\n\tif ( ++p == pe )\n\t\tgoto _test_eof44;\ncase 44:\n\tswitch( (*p) ) {\n\t\tcase 32: goto tr2;\n\t\tcase 36: goto st45;\n\t\tcase 95: goto st45;\n\t}\n\tif ( (*p) < 48 ) {\n\t\tif ( 45 <= (*p) && (*p) <= 46 )\n\t\t\tgoto st45;\n\t} else if ( (*p) > 57 ) {\n\t\tif ( 65 <= (*p) && (*p) <= 90 )\n\t\t\tgoto st45;\n\t} else\n\t\tgoto st45;\n\tgoto st0;\nst45:\n\tif ( ++p == pe )\n\t\tgoto _test_eof45;\ncase 45:\n\tif ( (*p) == 32 )\n\t\tgoto tr2;\n\tgoto st0;\n\t}\n\t_test_eof2: cs = 2; goto _test_eof; \n\t_test_eof3: cs = 3; goto _test_eof; \n\t_test_eof4: cs = 4; goto _test_eof; \n\t_test_eof5: cs = 5; goto _test_eof; \n\t_test_eof6: cs = 6; goto _test_eof; \n\t_test_eof7: cs = 7; goto _test_eof; \n\t_test_eof8: cs = 8; goto _test_eof; \n\t_test_eof9: cs = 9; goto _test_eof; \n\t_test_eof10: cs = 10; goto _test_eof; \n\t_test_eof11: cs = 11; goto _test_eof; \n\t_test_eof12: cs = 12; goto _test_eof; \n\t_test_eof13: cs = 13; goto _test_eof; \n\t_test_eof14: cs = 14; goto _test_eof; \n\t_test_eof15: cs = 15; goto _test_eof; \n\t_test_eof16: cs = 16; goto _test_eof; \n\t_test_eof46: cs = 46; goto _test_eof; \n\t_test_eof17: cs = 17; goto _test_eof; \n\t_test_eof18: cs = 18; goto _test_eof; \n\t_test_eof19: cs = 19; goto _test_eof; \n\t_test_eof20: cs = 20; goto _test_eof; \n\t_test_eof21: cs = 21; goto _test_eof; \n\t_test_eof22: cs = 22; goto _test_eof; \n\t_test_eof23: cs = 23; goto _test_eof; \n\t_test_eof24: cs = 24; goto _test_eof; \n\t_test_eof25: cs = 25; goto _test_eof; \n\t_test_eof26: cs = 26; goto _test_eof; \n\t_test_eof27: cs = 27; goto _test_eof; \n\t_test_eof28: cs = 28; goto _test_eof; \n\t_test_eof29: cs = 29; goto _test_eof; \n\t_test_eof30: cs = 30; goto _test_eof; \n\t_test_eof31: cs = 31; goto _test_eof; \n\t_test_eof32: cs = 32; goto _test_eof; \n\t_test_eof33: cs = 33; goto _test_eof; \n\t_test_eof34: cs = 34; goto _test_eof; \n\t_test_eof35: cs = 35; goto _test_eof; \n\t_test_eof36: cs = 36; goto _test_eof; \n\t_test_eof37: cs = 37; goto _test_eof; \n\t_test_eof38: cs = 38; goto _test_eof; \n\t_test_eof39: cs = 39; goto _test_eof; \n\t_test_eof40: cs = 40; goto _test_eof; \n\t_test_eof41: cs = 41; goto _test_eof; \n\t_test_eof42: cs = 42; goto _test_eof; \n\t_test_eof43: cs = 43; goto _test_eof; \n\t_test_eof44: cs = 44; goto _test_eof; \n\t_test_eof45: cs = 45; goto _test_eof; \n\n\t_test_eof: {}\n\t_out: {}\n\t}\n\n#line 117 \"ext/puma_http11/http11_parser.rl\"\n\n  if (!puma_parser_has_error(parser))\n    parser->cs = cs;\n  parser->nread += p - (buffer + off);\n\n  assert(p <= pe && \"buffer overflow after parsing execute\");\n  assert(parser->nread <= len && \"nread longer than length\");\n  assert(parser->body_start <= len && \"body starts after buffer end\");\n  assert(parser->mark < len && \"mark is after buffer end\");\n  assert(parser->field_len <= len && \"field has length longer than whole buffer\");\n  assert(parser->field_start < len && \"field starts after buffer end\");\n\n  return(parser->nread);\n}",
        "func_hash": 94439113710401505299900606066823977917,
        "file_name": "http11_parser.c",
        "file_hash": 59830834973701402944362779116096200943,
        "cwe": [
            "CWE-444"
        ],
        "cve": "CVE-2021-41136",
        "cve_desc": "Puma is a HTTP 1.1 server for Ruby/Rack applications. Prior to versions 5.5.1 and 4.3.9, using `puma` with a proxy which forwards HTTP header values which contain the LF character could allow HTTP request smugggling. A client could smuggle a request through a proxy, causing the proxy to send a response back to another unknown client. The only proxy which has this behavior, as far as the Puma team is aware of, is Apache Traffic Server. If the proxy uses persistent connections and the client adds another request in via HTTP pipelining, the proxy may mistake it as the first request's body. Puma, however, would see it as two requests, and when processing the second request, send back a response that the proxy does not expect. If the proxy has reused the persistent connection to Puma to send another request for a different client, the second response from the first client will be sent to the second client. This vulnerability was patched in Puma 5.5.1 and 4.3.9. As a workaround, do not use Apache Traffic Server with `puma`.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-41136",
        "func_name": "puma_parser_execute",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 199833,
        "project": "chafa",
        "commit_id": "e4b777c7b7c144cd16a0ea96108267b1004fe6c9",
        "project_url": "https://github.com/hpjansson/chafa",
        "commit_url": "https://github.com/hpjansson/chafa/commit/e4b777c7b7c144cd16a0ea96108267b1004fe6c9",
        "commit_message": "libnsgif: Fix null pointer deref on frameless GIF input\n\nA crafted GIF file with no frame data could cause a null pointer\ndereference leading to denial of service (crash). Reported by\n@JieyongMa via huntr.dev.",
        "target": 1,
        "irrelevant": 1,
        "func_before": "gif_internal_decode_frame(gif_animation *gif,\n                          unsigned int frame,\n                          bool clear_image)\n{\n        unsigned int index = 0;\n        const unsigned char *gif_data, *gif_end;\n        ssize_t gif_bytes;\n        unsigned int width, height, offset_x, offset_y;\n        unsigned int flags, colour_table_size, interlace;\n        unsigned int *colour_table;\n        unsigned int *frame_data = 0;\t// Set to 0 for no warnings\n        unsigned int *frame_scanline;\n        ssize_t save_buffer_position;\n        unsigned int return_value = 0;\n        unsigned int x, y, decode_y, burst_bytes;\n        register unsigned char colour;\n\n        /* Ensure this frame is supposed to be decoded */\n        if (gif->frames[frame].display == false) {\n                return GIF_OK;\n        }\n\n        /* Ensure the frame is in range to decode */\n        if (frame > gif->frame_count_partial) {\n                return GIF_INSUFFICIENT_DATA;\n        }\n\n        /* done if frame is already decoded */\n        if ((!clear_image) &&\n            ((int)frame == gif->decoded_frame)) {\n                return GIF_OK;\n        }\n\n        /* Get the start of our frame data and the end of the GIF data */\n        gif_data = gif->gif_data + gif->frames[frame].frame_pointer;\n        gif_end = gif->gif_data + gif->buffer_size;\n        gif_bytes = (gif_end - gif_data);\n\n        /*\n         * Ensure there is a minimal amount of data to proceed.  The shortest\n         * block of data is a 10-byte image descriptor + 1-byte gif trailer\n         */\n        if (gif_bytes < 12) {\n                return GIF_INSUFFICIENT_FRAME_DATA;\n        }\n\n        /* Save the buffer position */\n        save_buffer_position = gif->buffer_position;\n        gif->buffer_position = gif_data - gif->gif_data;\n\n        /* Skip any extensions because they have allready been processed */\n        if ((return_value = gif_skip_frame_extensions(gif)) != GIF_OK) {\n                goto gif_decode_frame_exit;\n        }\n        gif_data = (gif->gif_data + gif->buffer_position);\n        gif_bytes = (gif_end - gif_data);\n\n        /* Ensure we have enough data for the 10-byte image descriptor + 1-byte\n         * gif trailer\n         */\n        if (gif_bytes < 12) {\n                return_value = GIF_INSUFFICIENT_FRAME_DATA;\n                goto gif_decode_frame_exit;\n        }\n\n        /* 10-byte Image Descriptor is:\n         *\n         *\t+0\tCHAR\tImage Separator (0x2c)\n         *\t+1\tSHORT\tImage Left Position\n         *\t+3\tSHORT\tImage Top Position\n         *\t+5\tSHORT\tWidth\n         *\t+7\tSHORT\tHeight\n         *\t+9\tCHAR\t__Packed Fields__\n         *\t\t\t1BIT\tLocal Colour Table Flag\n         *\t\t\t1BIT\tInterlace Flag\n         *\t\t\t1BIT\tSort Flag\n         *\t\t\t2BITS\tReserved\n         *\t\t\t3BITS\tSize of Local Colour Table\n         */\n        if (gif_data[0] != GIF_IMAGE_SEPARATOR) {\n                return_value = GIF_DATA_ERROR;\n                goto gif_decode_frame_exit;\n        }\n        offset_x = gif_data[1] | (gif_data[2] << 8);\n        offset_y = gif_data[3] | (gif_data[4] << 8);\n        width = gif_data[5] | (gif_data[6] << 8);\n        height = gif_data[7] | (gif_data[8] << 8);\n\n        /* Boundary checking - shouldn't ever happen except unless the data has\n         * been modified since initialisation.\n         */\n        if ((offset_x + width > gif->width) ||\n            (offset_y + height > gif->height)) {\n                return_value = GIF_DATA_ERROR;\n                goto gif_decode_frame_exit;\n        }\n\n        /* Decode the flags */\n        flags = gif_data[9];\n        colour_table_size = 2 << (flags & GIF_COLOUR_TABLE_SIZE_MASK);\n        interlace = flags & GIF_INTERLACE_MASK;\n\n        /* Advance data pointer to next block either colour table or image\n         * data.\n         */\n        gif_data += 10;\n        gif_bytes = (gif_end - gif_data);\n\n        /* Set up the colour table */\n        if (flags & GIF_COLOUR_TABLE_MASK) {\n                if (gif_bytes < (int)(3 * colour_table_size)) {\n                        return_value = GIF_INSUFFICIENT_FRAME_DATA;\n                        goto gif_decode_frame_exit;\n                }\n                colour_table = gif->local_colour_table;\n                if (!clear_image) {\n                        for (index = 0; index < colour_table_size; index++) {\n                                /* Gif colour map contents are r,g,b.\n                                 *\n                                 * We want to pack them bytewise into the\n                                 * colour table, such that the red component\n                                 * is in byte 0 and the alpha component is in\n                                 * byte 3.\n                                 */\n                                unsigned char *entry =\n                                        (unsigned char *) &colour_table[index];\n\n                                entry[0] = gif_data[0];\t/* r */\n                                entry[1] = gif_data[1];\t/* g */\n                                entry[2] = gif_data[2];\t/* b */\n                                entry[3] = 0xff;\t/* a */\n\n                                gif_data += 3;\n                        }\n                } else {\n                        gif_data += 3 * colour_table_size;\n                }\n                gif_bytes = (gif_end - gif_data);\n        } else {\n                colour_table = gif->global_colour_table;\n        }\n\n        /* Ensure sufficient data remains */\n        if (gif_bytes < 1) {\n                return_value = GIF_INSUFFICIENT_FRAME_DATA;\n                goto gif_decode_frame_exit;\n        }\n\n        /* check for an end marker */\n        if (gif_data[0] == GIF_TRAILER) {\n                return_value = GIF_OK;\n                goto gif_decode_frame_exit;\n        }\n\n        /* Get the frame data */\n        assert(gif->bitmap_callbacks.bitmap_get_buffer);\n        frame_data = (void *)gif->bitmap_callbacks.bitmap_get_buffer(gif->frame_image);\n        if (!frame_data) {\n                return GIF_INSUFFICIENT_MEMORY;\n        }\n\n        /* If we are clearing the image we just clear, if not decode */\n        if (!clear_image) {\n                lzw_result res;\n                const uint8_t *stack_base;\n                const uint8_t *stack_pos;\n\n                /* Ensure we have enough data for a 1-byte LZW code size +\n                 * 1-byte gif trailer\n                 */\n                if (gif_bytes < 2) {\n                        return_value = GIF_INSUFFICIENT_FRAME_DATA;\n                        goto gif_decode_frame_exit;\n                }\n\n                /* If we only have a 1-byte LZW code size + 1-byte gif trailer,\n                 * we're finished\n                 */\n                if ((gif_bytes == 2) && (gif_data[1] == GIF_TRAILER)) {\n                        return_value = GIF_OK;\n                        goto gif_decode_frame_exit;\n                }\n\n                /* If the previous frame's disposal method requires we restore\n                 * the background colour or this is the first frame, clear\n                 * the frame data\n                 */\n                if ((frame == 0) || (gif->decoded_frame == GIF_INVALID_FRAME)) {\n                        memset((char*)frame_data,\n                               GIF_TRANSPARENT_COLOUR,\n                               gif->width * gif->height * sizeof(int));\n                        gif->decoded_frame = frame;\n                        /* The line below would fill the image with its\n                         * background color, but because GIFs support\n                         * transparency we likely wouldn't want to do that. */\n                        /* memset((char*)frame_data, colour_table[gif->background_index], gif->width * gif->height * sizeof(int)); */\n                } else if ((frame != 0) &&\n                           (gif->frames[frame - 1].disposal_method == GIF_FRAME_CLEAR)) {\n                        return_value = gif_internal_decode_frame(gif,\n                                                                 (frame - 1),\n                                                                 true);\n                        if (return_value != GIF_OK) {\n                                goto gif_decode_frame_exit;\n                        }\n\n                } else if ((frame != 0) &&\n                           (gif->frames[frame - 1].disposal_method == GIF_FRAME_RESTORE)) {\n                        /*\n                         * If the previous frame's disposal method requires we\n                         * restore the previous image, find the last image set\n                         * to \"do not dispose\" and get that frame data\n                         */\n                        int last_undisposed_frame = frame - 2;\n                        while ((last_undisposed_frame >= 0) &&\n                               (gif->frames[last_undisposed_frame].disposal_method == GIF_FRAME_RESTORE)) {\n                                last_undisposed_frame--;\n                        }\n\n                        /* If we don't find one, clear the frame data */\n                        if (last_undisposed_frame == -1) {\n                                /* see notes above on transparency\n                                 * vs. background color\n                                 */\n                                memset((char*)frame_data,\n                                       GIF_TRANSPARENT_COLOUR,\n                                       gif->width * gif->height * sizeof(int));\n                        } else {\n                                return_value = gif_internal_decode_frame(gif, last_undisposed_frame, false);\n                                if (return_value != GIF_OK) {\n                                        goto gif_decode_frame_exit;\n                                }\n                                /* Get this frame's data */\n                                assert(gif->bitmap_callbacks.bitmap_get_buffer);\n                                frame_data = (void *)gif->bitmap_callbacks.bitmap_get_buffer(gif->frame_image);\n                                if (!frame_data) {\n                                        return GIF_INSUFFICIENT_MEMORY;\n                                }\n                        }\n                }\n                gif->decoded_frame = frame;\n                gif->buffer_position = (gif_data - gif->gif_data) + 1;\n\n                /* Initialise the LZW decoding */\n                res = lzw_decode_init(gif->lzw_ctx, gif->gif_data,\n                                gif->buffer_size, gif->buffer_position,\n                                gif_data[0], &stack_base, &stack_pos);\n                if (res != LZW_OK) {\n                        return gif_error_from_lzw(res);\n                }\n\n                /* Decompress the data */\n                for (y = 0; y < height; y++) {\n                        if (interlace) {\n                                decode_y = gif_interlaced_line(height, y) + offset_y;\n                        } else {\n                                decode_y = y + offset_y;\n                        }\n                        frame_scanline = frame_data + offset_x + (decode_y * gif->width);\n\n                        /* Rather than decoding pixel by pixel, we try to burst\n                         * out streams of data to remove the need for end-of\n                         * data checks every pixel.\n                         */\n                        x = width;\n                        while (x > 0) {\n                                burst_bytes = (stack_pos - stack_base);\n                                if (burst_bytes > 0) {\n                                        if (burst_bytes > x) {\n                                                burst_bytes = x;\n                                        }\n                                        x -= burst_bytes;\n                                        while (burst_bytes-- > 0) {\n                                                colour = *--stack_pos;\n                                                if (((gif->frames[frame].transparency) &&\n                                                     (colour != gif->frames[frame].transparency_index)) ||\n                                                    (!gif->frames[frame].transparency)) {\n                                                        *frame_scanline = colour_table[colour];\n                                                }\n                                                frame_scanline++;\n                                        }\n                                } else {\n                                        res = lzw_decode(gif->lzw_ctx, &stack_pos);\n                                        if (res != LZW_OK) {\n                                                /* Unexpected end of frame, try to recover */\n                                                if (res == LZW_OK_EOD) {\n                                                        return_value = GIF_OK;\n                                                } else {\n                                                        return_value = gif_error_from_lzw(res);\n                                                }\n                                                goto gif_decode_frame_exit;\n                                        }\n                                }\n                        }\n                }\n        } else {\n                /* Clear our frame */\n                if (gif->frames[frame].disposal_method == GIF_FRAME_CLEAR) {\n                        for (y = 0; y < height; y++) {\n                                frame_scanline = frame_data + offset_x + ((offset_y + y) * gif->width);\n                                if (gif->frames[frame].transparency) {\n                                        memset(frame_scanline,\n                                               GIF_TRANSPARENT_COLOUR,\n                                               width * 4);\n                                } else {\n                                        memset(frame_scanline,\n                                               colour_table[gif->background_index],\n                                               width * 4);\n                                }\n                        }\n                }\n        }\ngif_decode_frame_exit:\n\n        /* Check if we should test for optimisation */\n        if (gif->frames[frame].virgin) {\n                if (gif->bitmap_callbacks.bitmap_test_opaque) {\n                        gif->frames[frame].opaque = gif->bitmap_callbacks.bitmap_test_opaque(gif->frame_image);\n                } else {\n                        gif->frames[frame].opaque = false;\n                }\n                gif->frames[frame].virgin = false;\n        }\n\n        if (gif->bitmap_callbacks.bitmap_set_opaque) {\n                gif->bitmap_callbacks.bitmap_set_opaque(gif->frame_image, gif->frames[frame].opaque);\n        }\n\n        if (gif->bitmap_callbacks.bitmap_modified) {\n                gif->bitmap_callbacks.bitmap_modified(gif->frame_image);\n        }\n\n        /* Restore the buffer position */\n        gif->buffer_position = save_buffer_position;\n\n        return return_value;\n}",
        "func_hash": 44351140165833891890072470559672892000,
        "file_name": "libnsgif.c",
        "file_hash": 198094748346353506643883012228634204471,
        "cwe": [
            "CWE-476"
        ],
        "cve": "CVE-2022-1507",
        "cve_desc": "chafa: NULL Pointer Dereference in function gif_internal_decode_frame at libnsgif.c:599 allows attackers to cause a denial of service (crash) via a crafted input file. in GitHub repository hpjansson/chafa prior to 1.10.2. chafa: NULL Pointer Dereference in function gif_internal_decode_frame at libnsgif.c:599 allows attackers to cause a denial of service (crash) via a crafted input file.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-1507",
        "func_name": "gif_internal_decode_frame",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 199834,
        "project": "vim",
        "commit_id": "f12129f1714f7d2301935bb21d896609bdac221c",
        "project_url": "https://github.com/vim/vim",
        "commit_url": "https://github.com/vim/vim/commit/f12129f1714f7d2301935bb21d896609bdac221c",
        "commit_message": "patch 9.0.0020: with some completion reading past end of string\n\nProblem:    With some completion reading past end of string.\nSolution:   Check the length of the string.",
        "target": 1,
        "irrelevant": 1,
        "func_before": "ins_compl_stop(int c, int prev_mode, int retval)\n{\n    char_u\t*ptr;\n    int\t\twant_cindent;\n\n    // Get here when we have finished typing a sequence of ^N and\n    // ^P or other completion characters in CTRL-X mode.  Free up\n    // memory that was used, and make sure we can redo the insert.\n    if (compl_curr_match != NULL || compl_leader != NULL || c == Ctrl_E)\n    {\n\t// If any of the original typed text has been changed, eg when\n\t// ignorecase is set, we must add back-spaces to the redo\n\t// buffer.  We add as few as necessary to delete just the part\n\t// of the original text that has changed.\n\t// When using the longest match, edited the match or used\n\t// CTRL-E then don't use the current match.\n\tif (compl_curr_match != NULL && compl_used_match && c != Ctrl_E)\n\t    ptr = compl_curr_match->cp_str;\n\telse\n\t    ptr = NULL;\n\tins_compl_fixRedoBufForLeader(ptr);\n    }\n\n    want_cindent = (get_can_cindent() && cindent_on());\n\n    // When completing whole lines: fix indent for 'cindent'.\n    // Otherwise, break line if it's too long.\n    if (compl_cont_mode == CTRL_X_WHOLE_LINE)\n    {\n\t// re-indent the current line\n\tif (want_cindent)\n\t{\n\t    do_c_expr_indent();\n\t    want_cindent = FALSE;\t// don't do it again\n\t}\n    }\n    else\n    {\n\tint prev_col = curwin->w_cursor.col;\n\n\t// put the cursor on the last char, for 'tw' formatting\n\tif (prev_col > 0)\n\t    dec_cursor();\n\t// only format when something was inserted\n\tif (!arrow_used && !ins_need_undo_get() && c != Ctrl_E)\n\t    insertchar(NUL, 0, -1);\n\tif (prev_col > 0\n\t\t&& ml_get_curline()[curwin->w_cursor.col] != NUL)\n\t    inc_cursor();\n    }\n\n    // If the popup menu is displayed pressing CTRL-Y means accepting\n    // the selection without inserting anything.  When\n    // compl_enter_selects is set the Enter key does the same.\n    if ((c == Ctrl_Y || (compl_enter_selects\n\t\t    && (c == CAR || c == K_KENTER || c == NL)))\n\t    && pum_visible())\n\tretval = TRUE;\n\n    // CTRL-E means completion is Ended, go back to the typed text.\n    // but only do this, if the Popup is still visible\n    if (c == Ctrl_E)\n    {\n\tins_compl_delete();\n\tif (compl_leader != NULL)\n\t    ins_bytes(compl_leader + get_compl_len());\n\telse if (compl_first_match != NULL)\n\t    ins_bytes(compl_orig_text + get_compl_len());\n\tretval = TRUE;\n    }\n\n    auto_format(FALSE, TRUE);\n\n    // Trigger the CompleteDonePre event to give scripts a chance to\n    // act upon the completion before clearing the info, and restore\n    // ctrl_x_mode, so that complete_info() can be used.\n    ctrl_x_mode = prev_mode;\n    ins_apply_autocmds(EVENT_COMPLETEDONEPRE);\n\n    ins_compl_free();\n    compl_started = FALSE;\n    compl_matches = 0;\n    if (!shortmess(SHM_COMPLETIONMENU))\n\tmsg_clr_cmdline();\t// necessary for \"noshowmode\"\n    ctrl_x_mode = CTRL_X_NORMAL;\n    compl_enter_selects = FALSE;\n    if (edit_submode != NULL)\n    {\n\tedit_submode = NULL;\n\tshowmode();\n    }\n\n#ifdef FEAT_CMDWIN\n    if (c == Ctrl_C && cmdwin_type != 0)\n\t// Avoid the popup menu remains displayed when leaving the\n\t// command line window.\n\tupdate_screen(0);\n#endif\n    // Indent now if a key was typed that is in 'cinkeys'.\n    if (want_cindent && in_cinkeys(KEY_COMPLETE, ' ', inindent(0)))\n\tdo_c_expr_indent();\n    // Trigger the CompleteDone event to give scripts a chance to act\n    // upon the end of completion.\n    ins_apply_autocmds(EVENT_COMPLETEDONE);\n\n    return retval;\n}",
        "func_hash": 319633245097677404453951244574334910213,
        "file_name": "insexpand.c",
        "file_hash": 292997256287164132386360145530649653298,
        "cwe": [
            "CWE-125"
        ],
        "cve": "CVE-2022-2286",
        "cve_desc": "Out-of-bounds Read in GitHub repository vim/vim prior to 9.0.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-2286",
        "func_name": "ins_compl_stop",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 199836,
        "project": "pjproject",
        "commit_id": "077b465c33f0aec05a49cd2ca456f9a1b112e896",
        "project_url": "https://github.com/pjsip/pjproject",
        "commit_url": "https://github.com/pjsip/pjproject/commit/077b465c33f0aec05a49cd2ca456f9a1b112e896",
        "commit_message": "Merge pull request from GHSA-7fw8-54cv-r7pm",
        "target": 1,
        "irrelevant": 1,
        "func_before": "PJ_DEF(int) pj_scan_get_char( pj_scanner *scanner )\n{\n    int chr = *scanner->curptr;\n\n    if (!chr) {\n\tpj_scan_syntax_err(scanner);\n\treturn 0;\n    }\n\n    ++scanner->curptr;\n\n    if (PJ_SCAN_IS_PROBABLY_SPACE(*scanner->curptr) && scanner->skip_ws) {\n\tpj_scan_skip_whitespace(scanner);\n    }\n    return chr;\n}",
        "func_hash": 113292852369107945981597354542276439074,
        "file_name": "scanner.c",
        "file_hash": null,
        "cwe": [
            "CWE-125"
        ],
        "cve": "CVE-2022-21723",
        "cve_desc": "PJSIP is a free and open source multimedia communication library written in C language implementing standard based protocols such as SIP, SDP, RTP, STUN, TURN, and ICE. In versions 2.11.1 and prior, parsing an incoming SIP message that contains a malformed multipart can potentially cause out-of-bound read access. This issue affects all PJSIP users that accept SIP multipart. The patch is available as commit in the `master` branch. There are no known workarounds.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-21723",
        "func_name": "PJ_DEF",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 199841,
        "project": "radare2",
        "commit_id": "feaa4e7f7399c51ee6f52deb84dc3f795b4035d6",
        "project_url": "https://github.com/radare/radare2",
        "commit_url": "https://github.com/radareorg/radare2/commit/feaa4e7f7399c51ee6f52deb84dc3f795b4035d6",
        "commit_message": "Fix null deref in xnu.kernelcache ##crash\n\n* Reported by @xshad3 via huntr.dev",
        "target": 1,
        "irrelevant": 1,
        "func_before": "static bool load_buffer(RBinFile *bf, void **bin_obj, RBuffer *buf, ut64 loadaddr, Sdb *sdb) {\n\tRBuffer *fbuf = r_buf_ref (buf);\n\tstruct MACH0_(opts_t) opts;\n\tMACH0_(opts_set_default) (&opts, bf);\n\tstruct MACH0_(obj_t) *main_mach0 = MACH0_(new_buf) (fbuf, &opts);\n\tif (!main_mach0) {\n\t\treturn false;\n\t}\n\n\tRRebaseInfo *rebase_info = r_rebase_info_new_from_mach0 (fbuf, main_mach0);\n\tRKernelCacheObj *obj = NULL;\n\n\tRPrelinkRange *prelink_range = get_prelink_info_range_from_mach0 (main_mach0);\n\tif (!prelink_range) {\n\t\tgoto beach;\n\t}\n\n\tobj = R_NEW0 (RKernelCacheObj);\n\tif (!obj) {\n\t\tR_FREE (prelink_range);\n\t\tgoto beach;\n\t}\n\n\tRCFValueDict *prelink_info = NULL;\n\tif (main_mach0->hdr.filetype != MH_FILESET && prelink_range->range.size) {\n\t\tprelink_info = r_cf_value_dict_parse (fbuf, prelink_range->range.offset,\n\t\t\t\tprelink_range->range.size, R_CF_OPTION_SKIP_NSDATA);\n\t\tif (!prelink_info) {\n\t\t\tR_FREE (prelink_range);\n\t\t\tR_FREE (obj);\n\t\t\tgoto beach;\n\t\t}\n\t}\n\n\tif (!pending_bin_files) {\n\t\tpending_bin_files = r_list_new ();\n\t\tif (!pending_bin_files) {\n\t\t\tR_FREE (prelink_range);\n\t\t\tR_FREE (obj);\n\t\t\tR_FREE (prelink_info);\n\t\t\tgoto beach;\n\t\t}\n\t}\n\n\tobj->mach0 = main_mach0;\n\tobj->rebase_info = rebase_info;\n\tobj->prelink_info = prelink_info;\n\tobj->cache_buf = fbuf;\n\tobj->pa2va_exec = prelink_range->pa2va_exec;\n\tobj->pa2va_data = prelink_range->pa2va_data;\n\n\tR_FREE (prelink_range);\n\n\t*bin_obj = obj;\n\n\tr_list_push (pending_bin_files, bf);\n\n\tif (rebase_info || main_mach0->chained_starts) {\n\t\tRIO *io = bf->rbin->iob.io;\n\t\tswizzle_io_read (obj, io);\n\t}\n\n\treturn true;\n\nbeach:\n\tr_buf_free (fbuf);\n\tobj->cache_buf = NULL;\n\tMACH0_(mach0_free) (main_mach0);\n\treturn false;\n}",
        "func_hash": 233224811640274540394040555084759924603,
        "file_name": "bin_xnu_kernelcache.c",
        "file_hash": 125322815790464606650182134413161579767,
        "cwe": [
            "CWE-476"
        ],
        "cve": "CVE-2022-0419",
        "cve_desc": "NULL Pointer Dereference in GitHub repository radareorg/radare2 prior to 5.6.0.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-0419",
        "func_name": "load_buffer",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 199851,
        "project": "vim",
        "commit_id": "6e28703a8e41f775f64e442c5d11ce1ff599aa3f",
        "project_url": "https://github.com/vim/vim",
        "commit_url": "https://github.com/vim/vim/commit/6e28703a8e41f775f64e442c5d11ce1ff599aa3f",
        "commit_message": "patch 8.2.4359: crash when repeatedly using :retab\n\nProblem:    crash when repeatedly using :retab.\nSolution:   Bail out when the line is getting too long.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "ex_retab(exarg_T *eap)\n{\n    linenr_T\tlnum;\n    int\t\tgot_tab = FALSE;\n    long\tnum_spaces = 0;\n    long\tnum_tabs;\n    long\tlen;\n    long\tcol;\n    long\tvcol;\n    long\tstart_col = 0;\t\t// For start of white-space string\n    long\tstart_vcol = 0;\t\t// For start of white-space string\n    long\told_len;\n    char_u\t*ptr;\n    char_u\t*new_line = (char_u *)1; // init to non-NULL\n    int\t\tdid_undo;\t\t// called u_save for current line\n#ifdef FEAT_VARTABS\n    int\t\t*new_vts_array = NULL;\n    char_u\t*new_ts_str;\t\t// string value of tab argument\n#else\n    int\t\ttemp;\n    int\t\tnew_ts;\n#endif\n    int\t\tsave_list;\n    linenr_T\tfirst_line = 0;\t\t// first changed line\n    linenr_T\tlast_line = 0;\t\t// last changed line\n\n    save_list = curwin->w_p_list;\n    curwin->w_p_list = 0;\t    // don't want list mode here\n\n#ifdef FEAT_VARTABS\n    new_ts_str = eap->arg;\n    if (tabstop_set(eap->arg, &new_vts_array) == FAIL)\n\treturn;\n    while (vim_isdigit(*(eap->arg)) || *(eap->arg) == ',')\n\t++(eap->arg);\n\n    // This ensures that either new_vts_array and new_ts_str are freshly\n    // allocated, or new_vts_array points to an existing array and new_ts_str\n    // is null.\n    if (new_vts_array == NULL)\n    {\n\tnew_vts_array = curbuf->b_p_vts_array;\n\tnew_ts_str = NULL;\n    }\n    else\n\tnew_ts_str = vim_strnsave(new_ts_str, eap->arg - new_ts_str);\n#else\n    ptr = eap->arg;\n    new_ts = getdigits(&ptr);\n    if (new_ts < 0 && *eap->arg == '-')\n    {\n\temsg(_(e_argument_must_be_positive));\n\treturn;\n    }\n    if (new_ts < 0 || new_ts > TABSTOP_MAX)\n    {\n\tsemsg(_(e_invalid_argument_str), eap->arg);\n\treturn;\n    }\n    if (new_ts == 0)\n\tnew_ts = curbuf->b_p_ts;\n#endif\n    for (lnum = eap->line1; !got_int && lnum <= eap->line2; ++lnum)\n    {\n\tptr = ml_get(lnum);\n\tcol = 0;\n\tvcol = 0;\n\tdid_undo = FALSE;\n\tfor (;;)\n\t{\n\t    if (VIM_ISWHITE(ptr[col]))\n\t    {\n\t\tif (!got_tab && num_spaces == 0)\n\t\t{\n\t\t    // First consecutive white-space\n\t\t    start_vcol = vcol;\n\t\t    start_col = col;\n\t\t}\n\t\tif (ptr[col] == ' ')\n\t\t    num_spaces++;\n\t\telse\n\t\t    got_tab = TRUE;\n\t    }\n\t    else\n\t    {\n\t\tif (got_tab || (eap->forceit && num_spaces > 1))\n\t\t{\n\t\t    // Retabulate this string of white-space\n\n\t\t    // len is virtual length of white string\n\t\t    len = num_spaces = vcol - start_vcol;\n\t\t    num_tabs = 0;\n\t\t    if (!curbuf->b_p_et)\n\t\t    {\n#ifdef FEAT_VARTABS\n\t\t\tint t, s;\n\n\t\t\ttabstop_fromto(start_vcol, vcol,\n\t\t\t\t\tcurbuf->b_p_ts, new_vts_array, &t, &s);\n\t\t\tnum_tabs = t;\n\t\t\tnum_spaces = s;\n#else\n\t\t\ttemp = new_ts - (start_vcol % new_ts);\n\t\t\tif (num_spaces >= temp)\n\t\t\t{\n\t\t\t    num_spaces -= temp;\n\t\t\t    num_tabs++;\n\t\t\t}\n\t\t\tnum_tabs += num_spaces / new_ts;\n\t\t\tnum_spaces -= (num_spaces / new_ts) * new_ts;\n#endif\n\t\t    }\n\t\t    if (curbuf->b_p_et || got_tab ||\n\t\t\t\t\t(num_spaces + num_tabs < len))\n\t\t    {\n\t\t\tif (did_undo == FALSE)\n\t\t\t{\n\t\t\t    did_undo = TRUE;\n\t\t\t    if (u_save((linenr_T)(lnum - 1),\n\t\t\t\t\t\t(linenr_T)(lnum + 1)) == FAIL)\n\t\t\t    {\n\t\t\t\tnew_line = NULL;\t// flag out-of-memory\n\t\t\t\tbreak;\n\t\t\t    }\n\t\t\t}\n\n\t\t\t// len is actual number of white characters used\n\t\t\tlen = num_spaces + num_tabs;\n\t\t\told_len = (long)STRLEN(ptr);\n\t\t\tnew_line = alloc(old_len - col + start_col + len + 1);\n\t\t\tif (new_line == NULL)\n\t\t\t    break;\n\t\t\tif (start_col > 0)\n\t\t\t    mch_memmove(new_line, ptr, (size_t)start_col);\n\t\t\tmch_memmove(new_line + start_col + len,\n\t\t\t\t      ptr + col, (size_t)(old_len - col + 1));\n\t\t\tptr = new_line + start_col;\n\t\t\tfor (col = 0; col < len; col++)\n\t\t\t    ptr[col] = (col < num_tabs) ? '\\t' : ' ';\n\t\t\tif (ml_replace(lnum, new_line, FALSE) == OK)\n\t\t\t    // \"new_line\" may have been copied\n\t\t\t    new_line = curbuf->b_ml.ml_line_ptr;\n\t\t\tif (first_line == 0)\n\t\t\t    first_line = lnum;\n\t\t\tlast_line = lnum;\n\t\t\tptr = new_line;\n\t\t\tcol = start_col + len;\n\t\t    }\n\t\t}\n\t\tgot_tab = FALSE;\n\t\tnum_spaces = 0;\n\t    }\n\t    if (ptr[col] == NUL)\n\t\tbreak;\n\t    vcol += chartabsize(ptr + col, (colnr_T)vcol);\n\t    if (has_mbyte)\n\t\tcol += (*mb_ptr2len)(ptr + col);\n\t    else\n\t\t++col;\n\t}\n\tif (new_line == NULL)\t\t    // out of memory\n\t    break;\n\tline_breakcheck();\n    }\n    if (got_int)\n\temsg(_(e_interrupted));\n\n#ifdef FEAT_VARTABS\n    // If a single value was given then it can be considered equal to\n    // either the value of 'tabstop' or the value of 'vartabstop'.\n    if (tabstop_count(curbuf->b_p_vts_array) == 0\n\t&& tabstop_count(new_vts_array) == 1\n\t&& curbuf->b_p_ts == tabstop_first(new_vts_array))\n\t; // not changed\n    else if (tabstop_count(curbuf->b_p_vts_array) > 0\n        && tabstop_eq(curbuf->b_p_vts_array, new_vts_array))\n\t; // not changed\n    else\n\tredraw_curbuf_later(NOT_VALID);\n#else\n    if (curbuf->b_p_ts != new_ts)\n\tredraw_curbuf_later(NOT_VALID);\n#endif\n    if (first_line != 0)\n\tchanged_lines(first_line, 0, last_line + 1, 0L);\n\n    curwin->w_p_list = save_list;\t// restore 'list'\n\n#ifdef FEAT_VARTABS\n    if (new_ts_str != NULL)\t\t// set the new tabstop\n    {\n\t// If 'vartabstop' is in use or if the value given to retab has more\n\t// than one tabstop then update 'vartabstop'.\n\tint *old_vts_ary = curbuf->b_p_vts_array;\n\n\tif (tabstop_count(old_vts_ary) > 0 || tabstop_count(new_vts_array) > 1)\n\t{\n\t    set_string_option_direct((char_u *)\"vts\", -1, new_ts_str,\n\t\t\t\t\t\t\tOPT_FREE|OPT_LOCAL, 0);\n\t    curbuf->b_p_vts_array = new_vts_array;\n\t    vim_free(old_vts_ary);\n\t}\n\telse\n\t{\n\t    // 'vartabstop' wasn't in use and a single value was given to\n\t    // retab then update 'tabstop'.\n\t    curbuf->b_p_ts = tabstop_first(new_vts_array);\n\t    vim_free(new_vts_array);\n\t}\n\tvim_free(new_ts_str);\n    }\n#else\n    curbuf->b_p_ts = new_ts;\n#endif\n    coladvance(curwin->w_curswant);\n\n    u_clearline();\n}",
        "func_hash": 55704685563391152697895881333081984969,
        "file_name": "indent.c",
        "file_hash": 264017227782989622614587099376842569247,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2022-0572",
        "cve_desc": "Heap-based Buffer Overflow in GitHub repository vim/vim prior to 8.2.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-0572",
        "func_name": "ex_retab",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 199918,
        "project": "vim",
        "commit_id": "2813f38e021c6e6581c0c88fcf107e41788bc835",
        "project_url": "https://github.com/vim/vim",
        "commit_url": "https://github.com/vim/vim/commit/2813f38e021c6e6581c0c88fcf107e41788bc835",
        "commit_message": "patch 8.2.5072: using uninitialized value and freed memory in spell command\n\nProblem:    Using uninitialized value and freed memory in spell command.\nSolution:   Initialize \"attr\".  Check for empty line early.",
        "target": 1,
        "irrelevant": 1,
        "func_before": "spell_move_to(\n    win_T\t*wp,\n    int\t\tdir,\t\t// FORWARD or BACKWARD\n    int\t\tallwords,\t// TRUE for \"[s\"/\"]s\", FALSE for \"[S\"/\"]S\"\n    int\t\tcurline,\n    hlf_T\t*attrp)\t\t// return: attributes of bad word or NULL\n\t\t\t\t// (only when \"dir\" is FORWARD)\n{\n    linenr_T\tlnum;\n    pos_T\tfound_pos;\n    int\t\tfound_len = 0;\n    char_u\t*line;\n    char_u\t*p;\n    char_u\t*endp;\n    hlf_T\tattr;\n    int\t\tlen;\n#ifdef FEAT_SYN_HL\n    int\t\thas_syntax = syntax_present(wp);\n#endif\n    int\t\tcol;\n    int\t\tcan_spell;\n    char_u\t*buf = NULL;\n    int\t\tbuflen = 0;\n    int\t\tskip = 0;\n    int\t\tcapcol = -1;\n    int\t\tfound_one = FALSE;\n    int\t\twrapped = FALSE;\n\n    if (no_spell_checking(wp))\n\treturn 0;\n\n    /*\n     * Start looking for bad word at the start of the line, because we can't\n     * start halfway a word, we don't know where it starts or ends.\n     *\n     * When searching backwards, we continue in the line to find the last\n     * bad word (in the cursor line: before the cursor).\n     *\n     * We concatenate the start of the next line, so that wrapped words work\n     * (e.g. \"et<line-break>cetera\").  Doesn't work when searching backwards\n     * though...\n     */\n    lnum = wp->w_cursor.lnum;\n    CLEAR_POS(&found_pos);\n\n    while (!got_int)\n    {\n\tline = ml_get_buf(wp->w_buffer, lnum, FALSE);\n\n\tlen = (int)STRLEN(line);\n\tif (buflen < len + MAXWLEN + 2)\n\t{\n\t    vim_free(buf);\n\t    buflen = len + MAXWLEN + 2;\n\t    buf = alloc(buflen);\n\t    if (buf == NULL)\n\t\tbreak;\n\t}\n\n\t// In first line check first word for Capital.\n\tif (lnum == 1)\n\t    capcol = 0;\n\n\t// For checking first word with a capital skip white space.\n\tif (capcol == 0)\n\t    capcol = getwhitecols(line);\n\telse if (curline && wp == curwin)\n\t{\n\t    // For spellbadword(): check if first word needs a capital.\n\t    col = getwhitecols(line);\n\t    if (check_need_cap(lnum, col))\n\t\tcapcol = col;\n\n\t    // Need to get the line again, may have looked at the previous\n\t    // one.\n\t    line = ml_get_buf(wp->w_buffer, lnum, FALSE);\n\t}\n\n\t// Copy the line into \"buf\" and append the start of the next line if\n\t// possible.\n\tSTRCPY(buf, line);\n\tif (lnum < wp->w_buffer->b_ml.ml_line_count)\n\t    spell_cat_line(buf + STRLEN(buf),\n\t\t\t  ml_get_buf(wp->w_buffer, lnum + 1, FALSE), MAXWLEN);\n\n\tp = buf + skip;\n\tendp = buf + len;\n\twhile (p < endp)\n\t{\n\t    // When searching backward don't search after the cursor.  Unless\n\t    // we wrapped around the end of the buffer.\n\t    if (dir == BACKWARD\n\t\t    && lnum == wp->w_cursor.lnum\n\t\t    && !wrapped\n\t\t    && (colnr_T)(p - buf) >= wp->w_cursor.col)\n\t\tbreak;\n\n\t    // start of word\n\t    attr = HLF_COUNT;\n\t    len = spell_check(wp, p, &attr, &capcol, FALSE);\n\n\t    if (attr != HLF_COUNT)\n\t    {\n\t\t// We found a bad word.  Check the attribute.\n\t\tif (allwords || attr == HLF_SPB)\n\t\t{\n\t\t    // When searching forward only accept a bad word after\n\t\t    // the cursor.\n\t\t    if (dir == BACKWARD\n\t\t\t    || lnum != wp->w_cursor.lnum\n\t\t\t    || (wrapped\n\t\t\t\t|| (colnr_T)(curline ? p - buf + len\n\t\t\t\t\t\t     : p - buf)\n\t\t\t\t\t\t  > wp->w_cursor.col))\n\t\t    {\n#ifdef FEAT_SYN_HL\n\t\t\tif (has_syntax)\n\t\t\t{\n\t\t\t    col = (int)(p - buf);\n\t\t\t    (void)syn_get_id(wp, lnum, (colnr_T)col,\n\t\t\t\t\t\t    FALSE, &can_spell, FALSE);\n\t\t\t    if (!can_spell)\n\t\t\t\tattr = HLF_COUNT;\n\t\t\t}\n\t\t\telse\n#endif\n\t\t\t    can_spell = TRUE;\n\n\t\t\tif (can_spell)\n\t\t\t{\n\t\t\t    found_one = TRUE;\n\t\t\t    found_pos.lnum = lnum;\n\t\t\t    found_pos.col = (int)(p - buf);\n\t\t\t    found_pos.coladd = 0;\n\t\t\t    if (dir == FORWARD)\n\t\t\t    {\n\t\t\t\t// No need to search further.\n\t\t\t\twp->w_cursor = found_pos;\n\t\t\t\tvim_free(buf);\n\t\t\t\tif (attrp != NULL)\n\t\t\t\t    *attrp = attr;\n\t\t\t\treturn len;\n\t\t\t    }\n\t\t\t    else if (curline)\n\t\t\t\t// Insert mode completion: put cursor after\n\t\t\t\t// the bad word.\n\t\t\t\tfound_pos.col += len;\n\t\t\t    found_len = len;\n\t\t\t}\n\t\t    }\n\t\t    else\n\t\t\tfound_one = TRUE;\n\t\t}\n\t    }\n\n\t    // advance to character after the word\n\t    p += len;\n\t    capcol -= len;\n\t}\n\n\tif (dir == BACKWARD && found_pos.lnum != 0)\n\t{\n\t    // Use the last match in the line (before the cursor).\n\t    wp->w_cursor = found_pos;\n\t    vim_free(buf);\n\t    return found_len;\n\t}\n\n\tif (curline)\n\t    break;\t// only check cursor line\n\n\t// If we are back at the starting line and searched it again there\n\t// is no match, give up.\n\tif (lnum == wp->w_cursor.lnum && wrapped)\n\t    break;\n\n\t// Advance to next line.\n\tif (dir == BACKWARD)\n\t{\n\t    if (lnum > 1)\n\t\t--lnum;\n\t    else if (!p_ws)\n\t\tbreak;\t    // at first line and 'nowrapscan'\n\t    else\n\t    {\n\t\t// Wrap around to the end of the buffer.  May search the\n\t\t// starting line again and accept the last match.\n\t\tlnum = wp->w_buffer->b_ml.ml_line_count;\n\t\twrapped = TRUE;\n\t\tif (!shortmess(SHM_SEARCH))\n\t\t    give_warning((char_u *)_(top_bot_msg), TRUE);\n\t    }\n\t    capcol = -1;\n\t}\n\telse\n\t{\n\t    if (lnum < wp->w_buffer->b_ml.ml_line_count)\n\t\t++lnum;\n\t    else if (!p_ws)\n\t\tbreak;\t    // at first line and 'nowrapscan'\n\t    else\n\t    {\n\t\t// Wrap around to the start of the buffer.  May search the\n\t\t// starting line again and accept the first match.\n\t\tlnum = 1;\n\t\twrapped = TRUE;\n\t\tif (!shortmess(SHM_SEARCH))\n\t\t    give_warning((char_u *)_(bot_top_msg), TRUE);\n\t    }\n\n\t    // If we are back at the starting line and there is no match then\n\t    // give up.\n\t    if (lnum == wp->w_cursor.lnum && !found_one)\n\t\tbreak;\n\n\t    // Skip the characters at the start of the next line that were\n\t    // included in a match crossing line boundaries.\n\t    if (attr == HLF_COUNT)\n\t\tskip = (int)(p - endp);\n\t    else\n\t\tskip = 0;\n\n\t    // Capcol skips over the inserted space.\n\t    --capcol;\n\n\t    // But after empty line check first word in next line\n\t    if (*skipwhite(line) == NUL)\n\t\tcapcol = 0;\n\t}\n\n\tline_breakcheck();\n    }\n\n    vim_free(buf);\n    return 0;\n}",
        "func_hash": 325648624112738029614022837693568870938,
        "file_name": "spell.c",
        "file_hash": 86411941404865310721318848603964614236,
        "cwe": [
            "CWE-416"
        ],
        "cve": "CVE-2022-2042",
        "cve_desc": "Use After Free in GitHub repository vim/vim prior to 8.2.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-2042",
        "func_name": "spell_move_to",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 199952,
        "project": "MilkyTracker",
        "commit_id": "3a5474f9102cbdc10fbd9e7b1b2c8d3f3f45d91b",
        "project_url": "https://github.com/milkytracker/MilkyTracker",
        "commit_url": "https://github.com/milkytracker/MilkyTracker/commit/3a5474f9102cbdc10fbd9e7b1b2c8d3f3f45d91b",
        "commit_message": "Fix possible stack corruption with XM instrument headers claiming a size of less than 4\n\nCloses #275",
        "target": 1,
        "irrelevant": 0,
        "func_before": "mp_sint32 LoaderXM::load(XMFileBase& f, XModule* module)\n{\n\tmp_ubyte insData[230];\t\t\n\tmp_sint32 smpReloc[MP_MAXINSSAMPS];\n\tmp_ubyte nbu[MP_MAXINSSAMPS];\n\tmp_uint32 fileSize = 0;\n\t\t\t\n\tmodule->cleanUp();\n\n\t// this will make code much easier to read\n\tTXMHeader*\t\theader = &module->header;\n\tTXMInstrument*\tinstr  = module->instr;\n\tTXMSample*\t\tsmp\t   = module->smp;\n\tTXMPattern*\t\tphead  = module->phead;\t\n\n\t// we're already out of memory here\n\tif (!phead || !instr || !smp)\n\t\treturn MP_OUT_OF_MEMORY;\n\t\n\tfileSize = f.sizeWithBaseOffset();\n\t\n\tf.read(&header->sig,1,17);\n\tf.read(&header->name,1,20);\n\tf.read(&header->whythis1a,1,1);\n\theader->whythis1a=0;\n\tf.read(&header->tracker,1,20);\n\tf.readWords(&header->ver,1);\n\t\n\tif (header->ver != 0x102 && \n\t\theader->ver != 0x103 && // untested\n\t\theader->ver != 0x104)\n\t\treturn MP_LOADER_FAILED;\n\t\n\tf.readDwords(&header->hdrsize,1);\n\t\n\theader->hdrsize-=4;\n\t\n\tmp_uint32 hdrSize = 0x110;\n\tif (header->hdrsize > hdrSize)\n\t\thdrSize = header->hdrsize;\n\t\t\t\t\n\tmp_ubyte* hdrBuff = new mp_ubyte[hdrSize];\n\tmemset(hdrBuff, 0, hdrSize);\n\t\n\tf.read(hdrBuff, 1, header->hdrsize);\n\t\n\theader->ordnum = LittleEndian::GET_WORD(hdrBuff);\n\theader->restart = LittleEndian::GET_WORD(hdrBuff+2);\n\theader->channum = LittleEndian::GET_WORD(hdrBuff+4);\n\theader->patnum = LittleEndian::GET_WORD(hdrBuff+6);\n\theader->insnum = LittleEndian::GET_WORD(hdrBuff+8);\n\theader->freqtab = LittleEndian::GET_WORD(hdrBuff+10);\n\theader->tempo = LittleEndian::GET_WORD(hdrBuff+12);\n\theader->speed = LittleEndian::GET_WORD(hdrBuff+14);\n\tmemcpy(header->ord, hdrBuff+16, 256);\n\tif(header->ordnum > MP_MAXORDERS)\n\t\theader->ordnum = MP_MAXORDERS;\n\tif(header->insnum > MP_MAXINS)\n\t\treturn MP_LOADER_FAILED;\n\n\tdelete[] hdrBuff;\n\t\n\theader->mainvol=255;\n\theader->flags = XModule::MODULE_XMNOTECLIPPING | \n\t\tXModule::MODULE_XMARPEGGIO | \n\t\tXModule::MODULE_XMPORTANOTEBUFFER | \n\t\tXModule::MODULE_XMVOLCOLUMNVIBRATO;\n\n\theader->uppernotebound = 119;\n\t\n\tmp_sint32 i,y,sc;\n\tfor (i=0;i<32;i++) header->pan[i]=0x80;\n\t\n\t// old version?\n\tif (header->ver == 0x102 || header->ver == 0x103)\n\t{\n\t\tmp_sint32 s = 0;\n\t\tmp_sint32 e = 0;\n\t\tfor (y=0;y<header->insnum;y++) {\n\t\t\t\n\t\t\tf.readDwords(&instr[y].size,1);\n\t\t\tf.read(&instr[y].name,1,22);\t\t\n\t\t\tf.read(&instr[y].type,1,1);\n\t\t\tmp_uword numSamples = 0;\n\t\t\tf.readWords(&numSamples,1);\n\t\t\tif(numSamples > MP_MAXINSSAMPS)\n\t\t\t\treturn MP_LOADER_FAILED;\n\t\t\tinstr[y].samp = numSamples;\n\n\t\t\tif (instr[y].size == 29)\n\t\t\t{\n#ifdef MILKYTRACKER\n\t\t\t\ts+=16;\n#endif\n\t\t\t\tfor (mp_sint32 i = 0; i < 120; i++)\n\t\t\t\t\tinstr[y].snum[i] = -1;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tf.readDwords(&instr[y].shsize,1);\n\n\t\t\tmemset(insData, 0, 230);\n\t\t\t\n\t\t\tif (instr[y].size - 33 > 230)\n\t\t\t\treturn MP_OUT_OF_MEMORY;\n\t\t\t\n\t\t\tf.read(insData, 1, instr[y].size - 33);\n\t\t\t\t\t\t\n\t\t\tif (instr[y].samp) {\n\t\t\t\tmp_ubyte* insDataPtr = insData;\n\t\t\t\t\n\t\t\t\tmemcpy(nbu, insDataPtr, MP_MAXINSSAMPS);\n\t\t\t\tinsDataPtr+=MP_MAXINSSAMPS;\n\t\t\t\t\n\t\t\t\tTEnvelope venv;\n\t\t\t\tTEnvelope penv;\n\t\t\t\tmemset(&venv,0,sizeof(venv));\n\t\t\t\tmemset(&penv,0,sizeof(penv));\n\t\t\t\t\n\t\t\t\tmp_sint32 k;\n\t\t\t\tfor (k = 0; k < XM_ENVELOPENUMPOINTS; k++)\n\t\t\t\t{\n\t\t\t\t\tvenv.env[k][0] = LittleEndian::GET_WORD(insDataPtr);\n\t\t\t\t\tvenv.env[k][1] = LittleEndian::GET_WORD(insDataPtr+2);\n\t\t\t\t\tinsDataPtr+=4;\n\t\t\t\t}\n\t\t\t\tfor (k = 0; k < XM_ENVELOPENUMPOINTS; k++)\n\t\t\t\t{\n\t\t\t\t\tpenv.env[k][0] = LittleEndian::GET_WORD(insDataPtr);\n\t\t\t\t\tpenv.env[k][1] = LittleEndian::GET_WORD(insDataPtr+2);\n\t\t\t\t\tinsDataPtr+=4;\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tvenv.num = *insDataPtr++;\t\n\t\t\t\tif (venv.num > XM_ENVELOPENUMPOINTS) venv.num = XM_ENVELOPENUMPOINTS;\n\t\t\t\tpenv.num = *insDataPtr++;\t\n\t\t\t\tif (penv.num > XM_ENVELOPENUMPOINTS) penv.num = XM_ENVELOPENUMPOINTS;\n\t\t\t\tvenv.sustain = *insDataPtr++;\n\t\t\t\tvenv.loops = *insDataPtr++;\n\t\t\t\tvenv.loope = *insDataPtr++;\n\t\t\t\tpenv.sustain = *insDataPtr++;\n\t\t\t\tpenv.loops = *insDataPtr++;\n\t\t\t\tpenv.loope = *insDataPtr++;\n\t\t\t\tvenv.type = *insDataPtr++;\n\t\t\t\tpenv.type = *insDataPtr++;\t\t\t\t\n\t\t\t\t\n\t\t\t\tmp_ubyte vibtype, vibsweep, vibdepth, vibrate;\n\t\t\t\tmp_uword volfade;\n\t\t\t\t\n\t\t\t\tvibtype = *insDataPtr++;\n\t\t\t\tvibsweep = *insDataPtr++;\n\t\t\t\tvibdepth = *insDataPtr++;\n\t\t\t\tvibrate = *insDataPtr++;\n\t\t\t\t\n\t\t\t\tvibdepth<<=1;\n\t\t\t\t\n\t\t\t\tvolfade = LittleEndian::GET_WORD(insDataPtr);\n\t\t\t\tinsDataPtr+=2;\n\t\t\t\tvolfade<<=1;\n\t\t\t\t\n\t\t\t\t//instr[y].res = LittleEndian::GET_WORD(insDataPtr);\n\t\t\t\tinsDataPtr+=2;\n\t\t\t\t\n\t\t\t\tfor (mp_sint32 l=0;l<XM_ENVELOPENUMPOINTS;l++) {\n\t\t\t\t\tvenv.env[l][1]<<=2;\n\t\t\t\t\tpenv.env[l][1]<<=2;\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tif (!module->addVolumeEnvelope(venv)) \n\t\t\t\t\treturn MP_OUT_OF_MEMORY;\n\t\t\t\tif (!module->addPanningEnvelope(penv)) \n\t\t\t\t\treturn MP_OUT_OF_MEMORY;\n\t\t\t\t\n\t\t\t\tmp_sint32 g=0, sc;\n\t\t\t\tfor (sc=0;sc<instr[y].samp;sc++) {\n\t\t\t\t\t\n\t\t\t\t\tsmp[g+s].flags=3;\n\t\t\t\t\tsmp[g+s].venvnum=e+1;\n\t\t\t\t\tsmp[g+s].penvnum=e+1;\n\t\t\t\t\t\n\t\t\t\t\tsmp[g+s].vibtype=vibtype;\n\t\t\t\t\tsmp[g+s].vibsweep=vibsweep;\n\t\t\t\t\tsmp[g+s].vibdepth=vibdepth;\n\t\t\t\t\tsmp[g+s].vibrate=vibrate;\n\t\t\t\t\tsmp[g+s].volfade=volfade;\n\t\t\t\t\t\n\t\t\t\t\t// not sure why I did that, actually doesn't make sense\n\t\t\t\t\t//if (!(venv.type&1)) smp[g+s].volfade=0;\n\t\t\t\t\t\n\t\t\t\t\tf.readDwords(&smp[g+s].samplen,1);\n\t\t\t\t\tf.readDwords(&smp[g+s].loopstart,1);\n\t\t\t\t\tf.readDwords(&smp[g+s].looplen,1);\n\t\t\t\t\tsmp[g+s].vol=XModule::vol64to255(f.readByte());\n\t\t\t\t\t//f.read(&smp[g+s].vol,1,1);\n\t\t\t\t\tf.read(&smp[g+s].finetune,1,1);\n\t\t\t\t\tf.read(&smp[g+s].type,1,1);\n#ifdef VERBOSE\n\t\t\t\t\tprintf(\"Before: %i, After: %i\\n\", smp[g+s].type, smp[g+s].type & (3+16));\n#endif\n\t\t\t\t\tf.read(&smp[g+s].pan,1,1);\n\t\t\t\t\tf.read(&smp[g+s].relnote,1,1);\n\t\t\t\t\tf.read(&smp[g+s].res,1,1);\n\t\t\t\t\tf.read(&smp[g+s].name,1,22);\n\t\t\t\t\t\n\t\t\t\t\tchar line[30];\n\t\t\t\t\tmemset(line, 0, sizeof(line));\n\t\t\t\t\tXModule::convertStr(line, smp[g+s].name, 23, false);\t\t\t\t\t\n\t\t\t\t\tif (line[0])\n\t\t\t\t\t\tmodule->addSongMessageLine(line);\n\t\t\t\t\t\n\t\t\t\t\t// ignore empty samples\n#ifndef MILKYTRACKER\n\t\t\t\t\t// ignore empty samples when not being a tracker\n\t\t\t\t\tif (smp[g+s].samplen) {\n\t\t\t\t\t\tsmpReloc[sc] = g;\n\t\t\t\t\t\tg++;\n\t\t\t\t\t}\n\t\t\t\t\telse\n\t\t\t\t\t\tsmpReloc[sc] = -1;\n#else\n\t\t\t\t\tsmpReloc[sc] = g;\n\t\t\t\t\tg++;\n#endif\n\t\t\t\t}\n\n\t\t\t\tinstr[y].samp = g;\n\n\t\t\t\tfor (sc = 0; sc < MP_MAXINSSAMPS; sc++) {\n\t\t\t\t\tif (smpReloc[nbu[sc]] == -1)\n\t\t\t\t\t\tinstr[y].snum[sc] = -1;\n\t\t\t\t\telse\n\t\t\t\t\t\tinstr[y].snum[sc] = smpReloc[nbu[sc]]+s;\t\t\t\t\t\n\t\t\t\t}\n\n\t\t\t\te++;\n\t\t\t\t\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tfor (mp_sint32 i = 0; i < 120; i++)\n\t\t\t\t\tinstr[y].snum[i] = -1;\n\t\t\t}\n\n#ifdef MILKYTRACKER\n\t\t\ts+=16;\n#else\n\t\t\ts+=instr[y].samp;\n#endif\t\t\t\t\n\t\t\t\t\n\t\t\t\n\t\t}\n\t\t\n\t\theader->smpnum=s;\n\t\theader->volenvnum=e;\n\t\theader->panenvnum=e;\n\t}\n\t\n\tfor (y=0;y<header->patnum;y++) {\n\t\t\n\t\tif (header->ver == 0x104 || header->ver == 0x103)\n\t\t{\n\t\t\tf.readDwords(&phead[y].len,1);\n\t\t\tf.read(&phead[y].ptype,1,1);\n\t\t\tf.readWords(&phead[y].rows,1);\n\t\t\tf.readWords(&phead[y].patdata,1);\n\t\t}\n\t\telse\n\t\t{\n\t\t\tf.readDwords(&phead[y].len,1);\n\t\t\tf.read(&phead[y].ptype,1,1);\n\t\t\tphead[y].rows = (mp_uword)f.readByte()+1;\n\t\t\tf.readWords(&phead[y].patdata,1);\t\t\t\n\t\t}\n\t\t\n\t\tphead[y].effnum=2;\n\t\tphead[y].channum=(mp_ubyte)header->channum;\n\t\t\n\t\tphead[y].patternData = new mp_ubyte[phead[y].rows*header->channum*6];\n\t\t\n\t\t// out of memory?\n\t\tif (phead[y].patternData == NULL)\n\t\t{\n\t\t\treturn MP_OUT_OF_MEMORY;\n\t\t}\n\t\t\n\t\tmemset(phead[y].patternData,0,phead[y].rows*header->channum*6);\n\t\t\n\t\tif (phead[y].patdata) {\n\t\t\tmp_ubyte *buffer = new mp_ubyte[phead[y].patdata];\n\t\t\t\n\t\t\t// out of memory?\n\t\t\tif (buffer == NULL)\n\t\t\t{\n\t\t\t\treturn MP_OUT_OF_MEMORY;\t\t\t\n\t\t\t}\n\t\t\t\n\t\t\tf.read(buffer,1,phead[y].patdata);\n\t\t\t\n\t\t\t//printf(\"%i\\n\", phead[y].patdata);\n\t\t\t\n\t\t\tmp_sint32 pc = 0, bc = 0;\n\t\t\tfor (mp_sint32 r=0;r<phead[y].rows;r++) {\n\t\t\t\tfor (mp_sint32 c=0;c<header->channum;c++) {\n\t\t\t\t\t\n\t\t\t\t\tmp_ubyte slot[5];\n\t\t\t\t\tmemset(slot,0,5);\n\t\t\t\t\t\n\t\t\t\t\tif ((buffer[pc]&128)) {\n\t\t\t\t\t\t\n\t\t\t\t\t\tmp_ubyte pb = buffer[pc];\n\t\t\t\t\t\tpc++;\n\t\t\t\t\t\t\n\t\t\t\t\t\tif ((pb&1)) {\n\t\t\t\t\t\t\t//phead[y].patternData[bc]=buffer[pc];\n\t\t\t\t\t\t\tslot[0]=buffer[pc];\n\t\t\t\t\t\t\tpc++;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif ((pb&2)) {\n\t\t\t\t\t\t\t//phead[y].patternData[bc+1]=buffer[pc];\n\t\t\t\t\t\t\tslot[1]=buffer[pc];\n\t\t\t\t\t\t\tpc++;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif ((pb&4)) {\n\t\t\t\t\t\t\t//phead[y].patternData[bc+2]=buffer[pc];\n\t\t\t\t\t\t\tslot[2]=buffer[pc];\n\t\t\t\t\t\t\tpc++;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif ((pb&8)) {\n\t\t\t\t\t\t\t//phead[y].patternData[bc+3]=buffer[pc];\n\t\t\t\t\t\t\tslot[3]=buffer[pc];\n\t\t\t\t\t\t\tpc++;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif ((pb&16)) {\n\t\t\t\t\t\t\t//phead[y].patternData[bc+4]=buffer[pc];\n\t\t\t\t\t\t\tslot[4]=buffer[pc];\n\t\t\t\t\t\t\tpc++;\n\t\t\t\t\t\t}\n\t\t\t\t\t\t\n\t\t\t\t\t}\n\t\t\t\t\telse {\n\t\t\t\t\t\t//memcpy(phead[y].patternData+bc,buffer+pc,5);\n\t\t\t\t\t\tmemcpy(slot,buffer+pc,5);\n\t\t\t\t\t\tpc+=5;\n\t\t\t\t\t}\n\t\t\t\t\t\n\t\t\t\t\tchar gl=0;\n\t\t\t\t\tfor (mp_sint32 i=0;i<XModule::numValidXMEffects;i++)\n\t\t\t\t\t\tif (slot[3]==XModule::validXMEffects[i]) gl=1;\n\t\t\t\t\t\n\t\t\t\t\tif (!gl) slot[3]=slot[4]=0;\n\t\t\t\t\t\n\t\t\t\t\tif ((slot[3]==0xC)||(slot[3]==0x10)) {\n\t\t\t\t\t\tslot[4] = XModule::vol64to255(slot[4]);\n\t\t\t\t\t\t/*mp_sint32 bl = slot[4];\n\t\t\t\t\t\tif (bl>64) bl=64;\n\t\t\t\t\t\tslot[4]=(bl*261120)>>16;*/\n\t\t\t\t\t}\n\t\t\t\t\t\n\t\t\t\t\tif ((!slot[3])&&(slot[4])) slot[3]=0x20;\n\t\t\t\t\t\n\t\t\t\t\tif (slot[3]==0xE) {\n\t\t\t\t\t\tslot[3]=(slot[4]>>4)+0x30;\n\t\t\t\t\t\tslot[4]=slot[4]&0xf;\n\t\t\t\t\t}\n\t\t\t\t\t\n\t\t\t\t\tif (slot[3]==0x21) {\n\t\t\t\t\t\tslot[3]=(slot[4]>>4)+0x40;\n\t\t\t\t\t\tslot[4]=slot[4]&0xf;\n\t\t\t\t\t}\n\t\t\t\t\t\n\t\t\t\t\tif (slot[0]==97) slot[0]=XModule::NOTE_OFF;\n\t\t\t\t\t\n\t\t\t\t\tphead[y].patternData[bc]=slot[0];\n\t\t\t\t\tphead[y].patternData[bc+1]=slot[1];\n\t\t\t\t\t\n\t\t\t\t\tXModule::convertXMVolumeEffects(slot[2], phead[y].patternData[bc+2], phead[y].patternData[bc+3]);\n\n\t\t\t\t\tphead[y].patternData[bc+4]=slot[3];\n\t\t\t\t\tphead[y].patternData[bc+5]=slot[4];\n\t\t\t\t\t\n\t\t\t\t\t/*if ((y==3)&&(c==2)) {\n\t\t\t\t\t\tfor (mp_sint32 bl=0;bl<6;bl++) cprintf(\"%x \",phead[y].patternData[bc+bl]);\n\t\t\t\t\tcprintf(\"\\r\\n\");\n\t\t\t\t\tgetch();\n\t\t\t\t\t};*/\n\t\t\t\t\t\n\t\t\t\t\t/*printf(\"Note : %i\\r\\n\",phead[y].patternData[bc]);\n\t\t\t\t\tprintf(\"Ins  : %i\\r\\n\",phead[y].patternData[bc+1]);\n\t\t\t\t\tprintf(\"Vol  : %i\\r\\n\",phead[y].patternData[bc+2]);\n\t\t\t\t\tprintf(\"Eff  : %i\\r\\n\",phead[y].patternData[bc+3]);\n\t\t\t\t\tprintf(\"Effop: %i\\r\\n\",phead[y].patternData[bc+4]);\n\t\t\t\t\tgetch();*/\n\t\t\t\t\t\n\t\t\t\t\tbc+=6;\n\t\t\t\t} // for c\n\t\t\t\t\t\n\t\t\t} // for r\n\t\t\t\t\n\t\t\tdelete[] buffer;\n\t\t}\n\t\t\t\n\t}\n\t\t\n\tif (header->ver == 0x104)\n\t{\n\t\tmp_sint32 s = 0;\n\t\tmp_sint32 e = 0;\n\t\tfor (y=0;y<header->insnum;y++) {\n\n\t\t\t// fixes MOOH.XM loading problems\n\t\t\t// seems to store more instruments in the header than in the actual file\n\t\t\tif (f.posWithBaseOffset() >= fileSize)\n\t\t\t\tbreak;\n\t\t\n\t\t\t//TXMInstrument* ins = &instr[y];\n\t\t\n\t\t\tf.readDwords(&instr[y].size,1);\n\t\t\t\n\t\t\tif (instr[y].size < 29)\n\t\t\t{\n\t\t\t\tmp_ubyte buffer[29];\n\t\t\t\tmemset(buffer, 0, sizeof(buffer));\n\t\t\t\tf.read(buffer, 1, instr[y].size - 4);\n\t\t\t\tmemcpy(instr[y].name, buffer, 22);\n\t\t\t\tinstr[y].type = buffer[22];\n\t\t\t\tinstr[y].samp = LittleEndian::GET_WORD(buffer + 23);\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tf.read(&instr[y].name,1,22);\t\t\n\t\t\t\tf.read(&instr[y].type,1,1);\n\t\t\t\tf.readWords(&instr[y].samp,1);\n\t\t\t}\n\t\t\tif (instr[y].samp > MP_MAXINSSAMPS)\n\t\t\t\treturn MP_LOADER_FAILED;\n\n\t\t\t//printf(\"%i, %i\\n\", instr[y].size, instr[y].samp);\n\n\t\t\tif (instr[y].size <= 29)\n\t\t\t{\n#ifdef MILKYTRACKER\n\t\t\t\ts+=16;\n#endif\n\t\t\t\tfor (mp_sint32 i = 0; i < 120; i++)\n\t\t\t\t\tinstr[y].snum[i] = -1;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tf.readDwords(&instr[y].shsize,1);\n#ifdef VERBOSE\n\t\t\tprintf(\"%i/%i: %i, %i, %i, %s\\n\",y,header->insnum-1,instr[y].size,instr[y].shsize,instr[y].samp,instr[y].name);\t\t\t\n#endif\n\t\t\tmemset(insData, 0, 230);\n\t\t\t\n\t\t\tif (instr[y].size - 33 > 230)\n\t\t\t{\n\t\t\t\t//return -7;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\t\n\t\t\tf.read(insData, 1, instr[y].size - 33);\n\t\t\t\n\t\t\t/*printf(\"%i\\r\\n\",instr[y].size);\n\t\t\tprintf(\"%s\\r\\n\",instr[y].name);\n\t\t\tprintf(\"%i\\r\\n\",instr[y].type);\n\t\t\tprintf(\"%i\\r\\n\",instr[y].samp);\n\t\t\tprintf(\"%i\\r\\n\",instr[y].shsize);*/\n\t\t\t//getch();\n\t\t\t\t\t\n\t\t\tmemset(smpReloc, 0, sizeof(smpReloc));\n\t\t\t\n\t\t\tif (instr[y].samp) {\n\t\t\t\tmp_ubyte* insDataPtr = insData;\n\t\t\t\t\n\t\t\t\t//f.read(&nbu,1,96);\n\t\t\t\t\n\t\t\t\tmemcpy(nbu, insDataPtr, MP_MAXINSSAMPS);\n\t\t\t\tinsDataPtr+=MP_MAXINSSAMPS;\n\t\t\t\t\n\t\t\t\tTEnvelope venv;\n\t\t\t\tTEnvelope penv;\n\t\t\t\tmemset(&venv,0,sizeof(venv));\n\t\t\t\tmemset(&penv,0,sizeof(penv));\n\t\t\t\t\n\t\t\t\tmp_sint32 k;\n\t\t\t\tfor (k = 0; k < XM_ENVELOPENUMPOINTS; k++)\n\t\t\t\t{\n\t\t\t\t\tvenv.env[k][0] = LittleEndian::GET_WORD(insDataPtr);\n\t\t\t\t\tvenv.env[k][1] = LittleEndian::GET_WORD(insDataPtr+2);\n\t\t\t\t\tinsDataPtr+=4;\n\t\t\t\t}\n\t\t\t\tfor (k = 0; k < XM_ENVELOPENUMPOINTS; k++)\n\t\t\t\t{\n\t\t\t\t\tpenv.env[k][0] = LittleEndian::GET_WORD(insDataPtr);\n\t\t\t\t\tpenv.env[k][1] = LittleEndian::GET_WORD(insDataPtr+2);\n\t\t\t\t\tinsDataPtr+=4;\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tvenv.num = *insDataPtr++;\t\n\t\t\t\tif (venv.num > XM_ENVELOPENUMPOINTS) venv.num = XM_ENVELOPENUMPOINTS;\n\t\t\t\tpenv.num = *insDataPtr++;\t\t\t\t\t\n\t\t\t\tif (penv.num > XM_ENVELOPENUMPOINTS) penv.num = XM_ENVELOPENUMPOINTS;\n\t\t\t\tvenv.sustain = *insDataPtr++;\n\t\t\t\tvenv.loops = *insDataPtr++;\n\t\t\t\tvenv.loope = *insDataPtr++;\n\t\t\t\tpenv.sustain = *insDataPtr++;\n\t\t\t\tpenv.loops = *insDataPtr++;\n\t\t\t\tpenv.loope = *insDataPtr++;\n\t\t\t\tvenv.type = *insDataPtr++;\n\t\t\t\tpenv.type = *insDataPtr++;\t\t\t\t\n\t\t\t\t\n\t\t\t\tmp_ubyte vibtype, vibsweep, vibdepth, vibrate;\n\t\t\t\tmp_uword volfade;\n\t\t\t\t\n\t\t\t\tvibtype = *insDataPtr++;\n\t\t\t\tvibsweep = *insDataPtr++;\n\t\t\t\tvibdepth = *insDataPtr++;\n\t\t\t\tvibrate = *insDataPtr++;\n\t\t\t\t\n\t\t\t\tvibdepth<<=1;\n\t\t\t\t\n\t\t\t\t//f.readWords(&volfade,1);\n\t\t\t\tvolfade = LittleEndian::GET_WORD(insDataPtr);\n\t\t\t\tinsDataPtr+=2;\n\t\t\t\tvolfade<<=1;\n\t\t\t\t\n\t\t\t\t//instr[y].res = LittleEndian::GET_WORD(insDataPtr);\n\t\t\t\tinsDataPtr+=2;\n\t\t\t\t\n\t\t\t\tfor (mp_sint32 l=0;l<XM_ENVELOPENUMPOINTS;l++) {\n\t\t\t\t\tvenv.env[l][1]<<=2;\n\t\t\t\t\tpenv.env[l][1]<<=2;\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tif (!module->addVolumeEnvelope(venv)) \n\t\t\t\t\treturn MP_OUT_OF_MEMORY;\n\t\t\t\tif (!module->addPanningEnvelope(penv)) \n\t\t\t\t\treturn MP_OUT_OF_MEMORY;\n\t\t\t\t\n\t\t\t\tmp_sint32 g=0, sc;\n\t\t\t\tfor (sc=0;sc<instr[y].samp;sc++) {\n\t\t\t\t\t//TXMSample* smpl = &smp[g+s];\n\t\t\t\t\t\n\t\t\t\t\tsmp[g+s].flags=3;\n\t\t\t\t\tsmp[g+s].venvnum=e+1;\n\t\t\t\t\tsmp[g+s].penvnum=e+1;\n\t\t\t\t\t\n\t\t\t\t\tsmp[g+s].vibtype=vibtype;\n\t\t\t\t\tsmp[g+s].vibsweep=vibsweep;\n\t\t\t\t\tsmp[g+s].vibdepth=vibdepth;\n\t\t\t\t\tsmp[g+s].vibrate=vibrate;\n\t\t\t\t\tsmp[g+s].volfade=volfade;\n\t\t\t\t\t\n\t\t\t\t\t// not sure why I did that, actually doesn't make sense\n\t\t\t\t\t//if (!(venv.type&1)) smp[g+s].volfade=0;\n\t\t\t\t\t\n\t\t\t\t\tf.readDwords(&smp[g+s].samplen,1);\n\t\t\t\t\t\n\t\t\t\t\tf.readDwords(&smp[g+s].loopstart,1);\n\t\t\t\t\tf.readDwords(&smp[g+s].looplen,1);\n\t\t\t\t\tsmp[g+s].vol=XModule::vol64to255(f.readByte());\n\t\t\t\t\t//f.read(&smp[g+s].vol,1,1);\n\t\t\t\t\tf.read(&smp[g+s].finetune,1,1);\n\t\t\t\t\tf.read(&smp[g+s].type,1,1);\n#ifdef VERBOSE\n\t\t\t\t\tprintf(\"Before: %i, After: %i\\n\", smp[g+s].type, smp[g+s].type & (3+16));\n#endif\n\t\t\t\t\tf.read(&smp[g+s].pan,1,1);\n\t\t\t\t\tf.read(&smp[g+s].relnote,1,1);\n\t\t\t\t\tf.read(&smp[g+s].res,1,1);\n\t\t\t\t\tf.read(&smp[g+s].name,1,22);\n\n\t\t\t\t\tchar line[30];\n\t\t\t\t\tmemset(line, 0, sizeof(line));\n\t\t\t\t\tXModule::convertStr(line, smp[g+s].name, 23, false);\t\t\t\t\t\n\t\t\t\t\tif (line[0])\n\t\t\t\t\t\tmodule->addSongMessageLine(line);\n\t\t\t\t\t\n#ifndef MILKYTRACKER\n\t\t\t\t\t// ignore empty samples when not being a tracker\n\t\t\t\t\tif (smp[g+s].samplen) {\n\t\t\t\t\t\tsmpReloc[sc] = g;\n\t\t\t\t\t\tg++;\n\t\t\t\t\t}\n\t\t\t\t\telse\n\t\t\t\t\t\tsmpReloc[sc] = -1;\n#else\n\t\t\t\t\tsmpReloc[sc] = g;\n\t\t\t\t\tg++;\n#endif\n\t\t\t\t}\n\n\t\t\t\tinstr[y].samp = g;\n\n\t\t\t\tfor (sc = 0; sc < MP_MAXINSSAMPS; sc++) {\t\t\t\t\t\n\t\t\t\t\tif (smpReloc[nbu[sc]] == -1)\n\t\t\t\t\t\tinstr[y].snum[sc] = -1;\n\t\t\t\t\telse\n\t\t\t\t\t\tinstr[y].snum[sc] = smpReloc[nbu[sc]]+s;\n\t\t\t\t}\n\t\t\t\t\t\t\n\t\t\t\tfor (sc=0;sc<instr[y].samp;sc++) {\n\t\t\t\t\n\t\t\t\t\tif (smp[s].samplen)\n\t\t\t\t\t{\n\t\t\t\t\t\tbool adpcm = (smp[s].res == 0xAD);\n\t\t\t\t\t\n\t\t\t\t\t\tmp_uint32 oldSize = smp[s].samplen;\n\t\t\t\t\t\tif (smp[s].type&16) \n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tsmp[s].samplen>>=1;\n\t\t\t\t\t\t\tsmp[s].loopstart>>=1;\n\t\t\t\t\t\t\tsmp[s].looplen>>=1;\n\t\t\t\t\t\t}\n\t\t\t\t\t\t\n\t\t\t\t\t\tmp_sint32 result = module->loadModuleSample(f, s, \n\t\t\t\t\t\t\t\t\t\t\t\t\t adpcm ? XModule::ST_PACKING_ADPCM : XModule::ST_DELTA, \n\t\t\t\t\t\t\t\t\t\t\t\t\t adpcm ? (XModule::ST_PACKING_ADPCM | XModule::ST_16BIT) : (XModule::ST_DELTA | XModule::ST_16BIT), \n\t\t\t\t\t\t\t\t\t\t\t\t\t oldSize);\n\t\t\t\t\t\tif (result != MP_OK)\n\t\t\t\t\t\t\treturn result;\t\t\t\t\t\n\t\t\t\t\t\t\n\t\t\t\t\t\tif (adpcm)\n\t\t\t\t\t\t\tsmp[s].res = 0;\n\t\t\t\t\t}\n\t\t\t\t\t\n\t\t\t\t\ts++;\n\t\t\t\t\t\n\t\t\t\t\tif (s>=MP_MAXSAMPLES)\n\t\t\t\t\t\treturn MP_OUT_OF_MEMORY;\n\t\t\t\t\t\n\t\t\t\t}\n\n\t\t\t\te++;\n\t\t\t\t\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tfor (mp_sint32 i = 0; i < 120; i++)\n\t\t\t\t\tinstr[y].snum[i] = -1;\n\t\t\t}\n\n#ifdef MILKYTRACKER\n\t\t\ts+=16 - instr[y].samp;\n#endif\t\t\t\t\n\t\t\t\n\t\t}\n\t\t\n\t\theader->smpnum=s;\n\t\theader->volenvnum=e;\n\t\theader->panenvnum=e;\t\t\n\t\t\n\t}\n\telse\n\t{\n\t\tmp_sint32 s = 0;\n\t\tfor (y=0;y<header->insnum;y++) {\n\t\t\tfor (sc=0;sc<instr[y].samp;sc++) {\n\n\t\t\t\tif (smp[s].samplen)\n\t\t\t\t{\n\t\t\t\t\tmp_uint32 oldSize = smp[s].samplen;\n\t\t\t\t\tif (smp[s].type&16) \n\t\t\t\t\t{\n\t\t\t\t\t\tsmp[s].samplen>>=1;\n\t\t\t\t\t\tsmp[s].loopstart>>=1;\n\t\t\t\t\t\tsmp[s].looplen>>=1;\n\t\t\t\t\t}\n\t\t\t\t\t\n\t\t\t\t\tmp_sint32 result = module->loadModuleSample(f, s, XModule::ST_DELTA, XModule::ST_DELTA | XModule::ST_16BIT, oldSize);\n\t\t\t\t\tif (result != MP_OK)\n\t\t\t\t\t\treturn result;\t\t\t\t\t\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\ts++;\n\t\t\t\t\n\t\t\t\tif (s>=MP_MAXSAMPLES)\n\t\t\t\t\treturn MP_OUT_OF_MEMORY;\t\t\t\t\n\t\t\t}\n\t\t\t\n#ifdef MILKYTRACKER\n\t\t\ts+=16 - instr[y].samp;\n#endif\n\t\t\t\n\t\t}\t\t\n\t}\n\t\n\t// convert modplug stereo samples\n\tfor (mp_sint32 s = 0; s < header->smpnum; s++)\n\t{\n\t\tif (smp[s].type & 32)\n\t\t{\t\t\n\t\t\t// that's what's allowed, stupid modplug tracker\n\t\t\tsmp[s].type &= 3+16;\t\t\t\t\t\n\n\t\t\tif (smp[s].sample == NULL)\n\t\t\t\tcontinue;\n\t\t\t\n\t\t\tif (!(smp[s].type&16)) {\t\t\t\n\t\t\t\tsmp[s].samplen>>=1;\n\t\t\t\tsmp[s].loopstart>>=1;\n\t\t\t\tsmp[s].looplen>>=1;\n\t\t\t\t\n\t\t\t\tmp_sbyte* sample = (mp_sbyte*)smp[s].sample;\n\t\t\t\tmp_sint32 samplen = smp[s].samplen;\n\t\t\t\tfor (mp_sint32 i = 0; i < samplen; i++)\n\t\t\t\t{\n\t\t\t\t\tmp_sint32 s = ((mp_sint32)sample[i] + (mp_sint32)sample[i + samplen]) >> 1;\n\t\t\t\t\tif (s < -128) s = -128;\n\t\t\t\t\tif (s > 127) s = 127;\n\t\t\t\t\tsample[i] = (mp_sbyte)s;\n\t\t\t\t}\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tsmp[s].samplen>>=1;\n\t\t\t\tsmp[s].loopstart>>=1;\n\t\t\t\tsmp[s].looplen>>=1;\n\t\t\t\t\n\t\t\t\tmp_sword* sample = (mp_sword*)smp[s].sample;\n\t\t\t\tmp_sint32 samplen = smp[s].samplen;\n\t\t\t\tfor (mp_sint32 i = 0; i < samplen; i++)\n\t\t\t\t{\n\t\t\t\t\tmp_sint32 s = ((mp_sint32)sample[i] + (mp_sint32)sample[i + samplen]) >> 1;\n\t\t\t\t\tif (s < -32768) s = -32768;\n\t\t\t\t\tif (s > 32767) s = 32767;\n\t\t\t\t\tsample[i] = (mp_sword)s;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t\n\t\t// correct loop type 0x03 (undefined)\n\t\t// will become ping pong loop\n\t\t// note that FT2 will refuse to load XM files with such a loop type\n\t\tif ((smp[s].type & 0x3) == 0x3)\n\t\t\tsmp[s].type&=~1;\t\t\n\t}\n\n\t// correct number of patterns if necessary, otherwise the post processing will remove\n\t// the \"invalid\" patterns from the order list\n\tbool addPatterns = false;\n\tfor (i = 0; i < header->ordnum; i++)\n\t\tif (header->ord[i]+1 > header->patnum)\n\t\t{\n\t\t\theader->patnum = header->ord[i]+1;\t\n\t\t\taddPatterns = true;\n\t\t}\n\t\n\t// if the pattern number has been adjusted, add some empty patterns\n\tif (addPatterns)\n\t{\n\t\tfor (i = 0; i < header->patnum; i++)\n\t\t\tif (phead[i].patternData == NULL)\n\t\t\t{\n\t\t\t\tphead[i].rows = 64;\n\t\t\t\tphead[i].effnum = 2;\n\t\t\t\tphead[i].channum = (mp_ubyte)header->channum;\n\n\t\t\t\tphead[i].patternData = new mp_ubyte[phead[i].rows*header->channum*6];\n\t\t\t\n\t\t\t\t// out of memory?\n\t\t\t\tif (phead[i].patternData == NULL)\n\t\t\t\t{\n\t\t\t\t\treturn MP_OUT_OF_MEMORY;\n\t\t\t\t}\n\t\t\n\t\t\t\tmemset(phead[i].patternData,0,phead[i].rows*header->channum*6);\n\t\t\t}\n\t}\n\t\n\t// check for MODPLUG extensions\n\tif (f.posWithBaseOffset() + 8 <= fileSize)\n\t{\n\t\tchar buffer[4];\n\t\tf.read(buffer, 1, 4);\n\t\tif (memcmp(buffer, \"text\", 4) == 0)\n\t\t{\n\t\t\tmp_uint32 len = f.readDword();\n\t\t\tmodule->allocateSongMessage(len+1);\n\t\t\t\n\t\t\tmemset(module->message, 0, len+1);\n\t\t\t\n\t\t\tf.read(module->message, 1, len);\n\t\t}\n\t}\n\t\n\tmodule->postProcessSamples();\n\t\n\treturn MP_OK;\n}",
        "func_hash": 297622282182467898464562664481031169978,
        "file_name": "LoaderXM.cpp",
        "file_hash": null,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2022-34927",
        "cve_desc": "MilkyTracker v1.03.00 was discovered to contain a stack overflow via the component LoaderXM::load. This vulnerability is triggered when the program is supplied a crafted XM module file.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-34927",
        "func_name": "LoaderXM::load",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 199984,
        "project": "vim",
        "commit_id": "37f47958b8a2a44abc60614271d9537e7f14e51a",
        "project_url": "https://github.com/vim/vim",
        "commit_url": "https://github.com/vim/vim/commit/37f47958b8a2a44abc60614271d9537e7f14e51a",
        "commit_message": "patch 8.2.4253: using freed memory when substitute with function call\n\nProblem:    Using freed memory when substitute uses a recursive function call.\nSolution:   Make a copy of the substitute text.",
        "target": 1,
        "irrelevant": 1,
        "func_before": "ex_substitute(exarg_T *eap)\n{\n    linenr_T\tlnum;\n    long\ti = 0;\n    regmmatch_T regmatch;\n    static subflags_T subflags = {FALSE, FALSE, FALSE, TRUE, FALSE,\n\t\t\t\t\t\t\t      FALSE, FALSE, 0};\n#ifdef FEAT_EVAL\n    subflags_T\tsubflags_save;\n#endif\n    int\t\tsave_do_all;\t\t// remember user specified 'g' flag\n    int\t\tsave_do_ask;\t\t// remember user specified 'c' flag\n    char_u\t*pat = NULL, *sub = NULL;\t// init for GCC\n    int\t\tdelimiter;\n    int\t\tsublen;\n    int\t\tgot_quit = FALSE;\n    int\t\tgot_match = FALSE;\n    int\t\ttemp;\n    int\t\twhich_pat;\n    char_u\t*cmd;\n    int\t\tsave_State;\n    linenr_T\tfirst_line = 0;\t\t// first changed line\n    linenr_T\tlast_line= 0;\t\t// below last changed line AFTER the\n\t\t\t\t\t// change\n    linenr_T\told_line_count = curbuf->b_ml.ml_line_count;\n    linenr_T\tline2;\n    long\tnmatch;\t\t\t// number of lines in match\n    char_u\t*sub_firstline;\t\t// allocated copy of first sub line\n    int\t\tendcolumn = FALSE;\t// cursor in last column when done\n    pos_T\told_cursor = curwin->w_cursor;\n    int\t\tstart_nsubs;\n#ifdef FEAT_EVAL\n    int\t\tsave_ma = 0;\n#endif\n\n    cmd = eap->arg;\n    if (!global_busy)\n    {\n\tsub_nsubs = 0;\n\tsub_nlines = 0;\n    }\n    start_nsubs = sub_nsubs;\n\n    if (eap->cmdidx == CMD_tilde)\n\twhich_pat = RE_LAST;\t// use last used regexp\n    else\n\twhich_pat = RE_SUBST;\t// use last substitute regexp\n\n\t\t\t\t// new pattern and substitution\n    if (eap->cmd[0] == 's' && *cmd != NUL && !VIM_ISWHITE(*cmd)\n\t\t&& vim_strchr((char_u *)\"0123456789cegriIp|\\\"\", *cmd) == NULL)\n    {\n\t\t\t\t// don't accept alphanumeric for separator\n\tif (check_regexp_delim(*cmd) == FAIL)\n\t    return;\n#ifdef FEAT_EVAL\n\tif (in_vim9script() && check_global_and_subst(eap->cmd, eap->arg)\n\t\t\t\t\t\t\t\t      == FAIL)\n\t    return;\n#endif\n\n\t/*\n\t * undocumented vi feature:\n\t *  \"\\/sub/\" and \"\\?sub?\" use last used search pattern (almost like\n\t *  //sub/r).  \"\\&sub&\" use last substitute pattern (like //sub/).\n\t */\n\tif (*cmd == '\\\\')\n\t{\n\t    ++cmd;\n\t    if (vim_strchr((char_u *)\"/?&\", *cmd) == NULL)\n\t    {\n\t\temsg(_(e_backslash_should_be_followed_by));\n\t\treturn;\n\t    }\n\t    if (*cmd != '&')\n\t\twhich_pat = RE_SEARCH;\t    // use last '/' pattern\n\t    pat = (char_u *)\"\";\t\t    // empty search pattern\n\t    delimiter = *cmd++;\t\t    // remember delimiter character\n\t}\n\telse\t\t// find the end of the regexp\n\t{\n\t    which_pat = RE_LAST;\t    // use last used regexp\n\t    delimiter = *cmd++;\t\t    // remember delimiter character\n\t    pat = cmd;\t\t\t    // remember start of search pat\n\t    cmd = skip_regexp_ex(cmd, delimiter, magic_isset(),\n\t\t\t\t\t\t\t&eap->arg, NULL, NULL);\n\t    if (cmd[0] == delimiter)\t    // end delimiter found\n\t\t*cmd++ = NUL;\t\t    // replace it with a NUL\n\t}\n\n\t/*\n\t * Small incompatibility: vi sees '\\n' as end of the command, but in\n\t * Vim we want to use '\\n' to find/substitute a NUL.\n\t */\n\tsub = cmd;\t    // remember the start of the substitution\n\tcmd = skip_substitute(cmd, delimiter);\n\n\tif (!eap->skip)\n\t{\n\t    // In POSIX vi \":s/pat/%/\" uses the previous subst. string.\n\t    if (STRCMP(sub, \"%\") == 0\n\t\t\t\t && vim_strchr(p_cpo, CPO_SUBPERCENT) != NULL)\n\t    {\n\t\tif (old_sub == NULL)\t// there is no previous command\n\t\t{\n\t\t    emsg(_(e_no_previous_substitute_regular_expression));\n\t\t    return;\n\t\t}\n\t\tsub = old_sub;\n\t    }\n\t    else\n\t    {\n\t\tvim_free(old_sub);\n\t\told_sub = vim_strsave(sub);\n\t    }\n\t}\n    }\n    else if (!eap->skip)\t// use previous pattern and substitution\n    {\n\tif (old_sub == NULL)\t// there is no previous command\n\t{\n\t    emsg(_(e_no_previous_substitute_regular_expression));\n\t    return;\n\t}\n\tpat = NULL;\t\t// search_regcomp() will use previous pattern\n\tsub = old_sub;\n\n\t// Vi compatibility quirk: repeating with \":s\" keeps the cursor in the\n\t// last column after using \"$\".\n\tendcolumn = (curwin->w_curswant == MAXCOL);\n    }\n\n    // Recognize \":%s/\\n//\" and turn it into a join command, which is much\n    // more efficient.\n    // TODO: find a generic solution to make line-joining operations more\n    // efficient, avoid allocating a string that grows in size.\n    if (pat != NULL && STRCMP(pat, \"\\\\n\") == 0\n\t    && *sub == NUL\n\t    && (*cmd == NUL || (cmd[1] == NUL && (*cmd == 'g' || *cmd == 'l'\n\t\t\t\t\t     || *cmd == 'p' || *cmd == '#'))))\n    {\n\tlinenr_T    joined_lines_count;\n\n\tif (eap->skip)\n\t    return;\n\tcurwin->w_cursor.lnum = eap->line1;\n\tif (*cmd == 'l')\n\t    eap->flags = EXFLAG_LIST;\n\telse if (*cmd == '#')\n\t    eap->flags = EXFLAG_NR;\n\telse if (*cmd == 'p')\n\t    eap->flags = EXFLAG_PRINT;\n\n\t// The number of lines joined is the number of lines in the range plus\n\t// one.  One less when the last line is included.\n\tjoined_lines_count = eap->line2 - eap->line1 + 1;\n\tif (eap->line2 < curbuf->b_ml.ml_line_count)\n\t    ++joined_lines_count;\n\tif (joined_lines_count > 1)\n\t{\n\t    (void)do_join(joined_lines_count, FALSE, TRUE, FALSE, TRUE);\n\t    sub_nsubs = joined_lines_count - 1;\n\t    sub_nlines = 1;\n\t    (void)do_sub_msg(FALSE);\n\t    ex_may_print(eap);\n\t}\n\n\tif ((cmdmod.cmod_flags & CMOD_KEEPPATTERNS) == 0)\n\t    save_re_pat(RE_SUBST, pat, magic_isset());\n\t// put pattern in history\n\tadd_to_history(HIST_SEARCH, pat, TRUE, NUL);\n\n\treturn;\n    }\n\n    /*\n     * Find trailing options.  When '&' is used, keep old options.\n     */\n    if (*cmd == '&')\n\t++cmd;\n    else\n    {\n#ifdef FEAT_EVAL\n\tif (in_vim9script())\n\t{\n\t    // ignore 'gdefault' and 'edcompatible'\n\t    subflags.do_all = FALSE;\n\t    subflags.do_ask = FALSE;\n\t}\n\telse\n#endif\n\tif (!p_ed)\n\t{\n\t    if (p_gd)\t\t// default is global on\n\t\tsubflags.do_all = TRUE;\n\t    else\n\t\tsubflags.do_all = FALSE;\n\t    subflags.do_ask = FALSE;\n\t}\n\tsubflags.do_error = TRUE;\n\tsubflags.do_print = FALSE;\n\tsubflags.do_list = FALSE;\n\tsubflags.do_count = FALSE;\n\tsubflags.do_number = FALSE;\n\tsubflags.do_ic = 0;\n    }\n    while (*cmd)\n    {\n\t/*\n\t * Note that 'g' and 'c' are always inverted, also when p_ed is off.\n\t * 'r' is never inverted.\n\t */\n\tif (*cmd == 'g')\n\t    subflags.do_all = !subflags.do_all;\n\telse if (*cmd == 'c')\n\t    subflags.do_ask = !subflags.do_ask;\n\telse if (*cmd == 'n')\n\t    subflags.do_count = TRUE;\n\telse if (*cmd == 'e')\n\t    subflags.do_error = !subflags.do_error;\n\telse if (*cmd == 'r')\t    // use last used regexp\n\t    which_pat = RE_LAST;\n\telse if (*cmd == 'p')\n\t    subflags.do_print = TRUE;\n\telse if (*cmd == '#')\n\t{\n\t    subflags.do_print = TRUE;\n\t    subflags.do_number = TRUE;\n\t}\n\telse if (*cmd == 'l')\n\t{\n\t    subflags.do_print = TRUE;\n\t    subflags.do_list = TRUE;\n\t}\n\telse if (*cmd == 'i')\t    // ignore case\n\t    subflags.do_ic = 'i';\n\telse if (*cmd == 'I')\t    // don't ignore case\n\t    subflags.do_ic = 'I';\n\telse\n\t    break;\n\t++cmd;\n    }\n    if (subflags.do_count)\n\tsubflags.do_ask = FALSE;\n\n    save_do_all = subflags.do_all;\n    save_do_ask = subflags.do_ask;\n\n    /*\n     * check for a trailing count\n     */\n    cmd = skipwhite(cmd);\n    if (VIM_ISDIGIT(*cmd))\n    {\n\ti = getdigits(&cmd);\n\tif (i <= 0 && !eap->skip && subflags.do_error)\n\t{\n\t    emsg(_(e_positive_count_required));\n\t    return;\n\t}\n\teap->line1 = eap->line2;\n\teap->line2 += i - 1;\n\tif (eap->line2 > curbuf->b_ml.ml_line_count)\n\t    eap->line2 = curbuf->b_ml.ml_line_count;\n    }\n\n    /*\n     * check for trailing command or garbage\n     */\n    cmd = skipwhite(cmd);\n    if (*cmd && *cmd != '\"')\t    // if not end-of-line or comment\n    {\n\tset_nextcmd(eap, cmd);\n\tif (eap->nextcmd == NULL)\n\t{\n\t    semsg(_(e_trailing_characters_str), cmd);\n\t    return;\n\t}\n    }\n\n    if (eap->skip)\t    // not executing commands, only parsing\n\treturn;\n\n    if (!subflags.do_count && !curbuf->b_p_ma)\n    {\n\t// Substitution is not allowed in non-'modifiable' buffer\n\temsg(_(e_cannot_make_changes_modifiable_is_off));\n\treturn;\n    }\n\n    if (search_regcomp(pat, RE_SUBST, which_pat, SEARCH_HIS, &regmatch) == FAIL)\n    {\n\tif (subflags.do_error)\n\t    emsg(_(e_invalid_command));\n\treturn;\n    }\n\n    // the 'i' or 'I' flag overrules 'ignorecase' and 'smartcase'\n    if (subflags.do_ic == 'i')\n\tregmatch.rmm_ic = TRUE;\n    else if (subflags.do_ic == 'I')\n\tregmatch.rmm_ic = FALSE;\n\n    sub_firstline = NULL;\n\n    /*\n     * ~ in the substitute pattern is replaced with the old pattern.\n     * We do it here once to avoid it to be replaced over and over again.\n     * But don't do it when it starts with \"\\=\", then it's an expression.\n     */\n    if (!(sub[0] == '\\\\' && sub[1] == '='))\n\tsub = regtilde(sub, magic_isset());\n\n    /*\n     * Check for a match on each line.\n     */\n    line2 = eap->line2;\n    for (lnum = eap->line1; lnum <= line2 && !(got_quit\n#if defined(FEAT_EVAL)\n\t\t|| aborting()\n#endif\n\t\t); ++lnum)\n    {\n\tnmatch = vim_regexec_multi(&regmatch, curwin, curbuf, lnum,\n\t\t\t\t\t\t       (colnr_T)0, NULL, NULL);\n\tif (nmatch)\n\t{\n\t    colnr_T\tcopycol;\n\t    colnr_T\tmatchcol;\n\t    colnr_T\tprev_matchcol = MAXCOL;\n\t    char_u\t*new_end, *new_start = NULL;\n\t    unsigned\tnew_start_len = 0;\n\t    char_u\t*p1;\n\t    int\t\tdid_sub = FALSE;\n\t    int\t\tlastone;\n\t    int\t\tlen, copy_len, needed_len;\n\t    long\tnmatch_tl = 0;\t// nr of lines matched below lnum\n\t    int\t\tdo_again;\t// do it again after joining lines\n\t    int\t\tskip_match = FALSE;\n\t    linenr_T\tsub_firstlnum;\t// nr of first sub line\n#ifdef FEAT_PROP_POPUP\n\t    int\t\tapc_flags = APC_SAVE_FOR_UNDO | APC_SUBSTITUTE;\n\t    colnr_T\ttotal_added =  0;\n#endif\n\n\t    /*\n\t     * The new text is build up step by step, to avoid too much\n\t     * copying.  There are these pieces:\n\t     * sub_firstline\tThe old text, unmodified.\n\t     * copycol\t\tColumn in the old text where we started\n\t     *\t\t\tlooking for a match; from here old text still\n\t     *\t\t\tneeds to be copied to the new text.\n\t     * matchcol\t\tColumn number of the old text where to look\n\t     *\t\t\tfor the next match.  It's just after the\n\t     *\t\t\tprevious match or one further.\n\t     * prev_matchcol\tColumn just after the previous match (if any).\n\t     *\t\t\tMostly equal to matchcol, except for the first\n\t     *\t\t\tmatch and after skipping an empty match.\n\t     * regmatch.*pos\tWhere the pattern matched in the old text.\n\t     * new_start\tThe new text, all that has been produced so\n\t     *\t\t\tfar.\n\t     * new_end\t\tThe new text, where to append new text.\n\t     *\n\t     * lnum\t\tThe line number where we found the start of\n\t     *\t\t\tthe match.  Can be below the line we searched\n\t     *\t\t\twhen there is a \\n before a \\zs in the\n\t     *\t\t\tpattern.\n\t     * sub_firstlnum\tThe line number in the buffer where to look\n\t     *\t\t\tfor a match.  Can be different from \"lnum\"\n\t     *\t\t\twhen the pattern or substitute string contains\n\t     *\t\t\tline breaks.\n\t     *\n\t     * Special situations:\n\t     * - When the substitute string contains a line break, the part up\n\t     *   to the line break is inserted in the text, but the copy of\n\t     *   the original line is kept.  \"sub_firstlnum\" is adjusted for\n\t     *   the inserted lines.\n\t     * - When the matched pattern contains a line break, the old line\n\t     *   is taken from the line at the end of the pattern.  The lines\n\t     *   in the match are deleted later, \"sub_firstlnum\" is adjusted\n\t     *   accordingly.\n\t     *\n\t     * The new text is built up in new_start[].  It has some extra\n\t     * room to avoid using alloc()/free() too often.  new_start_len is\n\t     * the length of the allocated memory at new_start.\n\t     *\n\t     * Make a copy of the old line, so it won't be taken away when\n\t     * updating the screen or handling a multi-line match.  The \"old_\"\n\t     * pointers point into this copy.\n\t     */\n\t    sub_firstlnum = lnum;\n\t    copycol = 0;\n\t    matchcol = 0;\n\n\t    // At first match, remember current cursor position.\n\t    if (!got_match)\n\t    {\n\t\tsetpcmark();\n\t\tgot_match = TRUE;\n\t    }\n\n\t    /*\n\t     * Loop until nothing more to replace in this line.\n\t     * 1. Handle match with empty string.\n\t     * 2. If do_ask is set, ask for confirmation.\n\t     * 3. substitute the string.\n\t     * 4. if do_all is set, find next match\n\t     * 5. break if there isn't another match in this line\n\t     */\n\t    for (;;)\n\t    {\n\t\t// Advance \"lnum\" to the line where the match starts.  The\n\t\t// match does not start in the first line when there is a line\n\t\t// break before \\zs.\n\t\tif (regmatch.startpos[0].lnum > 0)\n\t\t{\n\t\t    lnum += regmatch.startpos[0].lnum;\n\t\t    sub_firstlnum += regmatch.startpos[0].lnum;\n\t\t    nmatch -= regmatch.startpos[0].lnum;\n\t\t    VIM_CLEAR(sub_firstline);\n\t\t}\n\n\t\t// Match might be after the last line for \"\\n\\zs\" matching at\n\t\t// the end of the last line.\n\t\tif (lnum > curbuf->b_ml.ml_line_count)\n\t\t    break;\n\n\t\tif (sub_firstline == NULL)\n\t\t{\n\t\t    sub_firstline = vim_strsave(ml_get(sub_firstlnum));\n\t\t    if (sub_firstline == NULL)\n\t\t    {\n\t\t\tvim_free(new_start);\n\t\t\tgoto outofmem;\n\t\t    }\n\t\t}\n\n\t\t// Save the line number of the last change for the final\n\t\t// cursor position (just like Vi).\n\t\tcurwin->w_cursor.lnum = lnum;\n\t\tdo_again = FALSE;\n\n\t\t/*\n\t\t * 1. Match empty string does not count, except for first\n\t\t * match.  This reproduces the strange vi behaviour.\n\t\t * This also catches endless loops.\n\t\t */\n\t\tif (matchcol == prev_matchcol\n\t\t\t&& regmatch.endpos[0].lnum == 0\n\t\t\t&& matchcol == regmatch.endpos[0].col)\n\t\t{\n\t\t    if (sub_firstline[matchcol] == NUL)\n\t\t\t// We already were at the end of the line.  Don't look\n\t\t\t// for a match in this line again.\n\t\t\tskip_match = TRUE;\n\t\t    else\n\t\t    {\n\t\t\t // search for a match at next column\n\t\t\tif (has_mbyte)\n\t\t\t    matchcol += mb_ptr2len(sub_firstline + matchcol);\n\t\t\telse\n\t\t\t    ++matchcol;\n\t\t    }\n\t\t    goto skip;\n\t\t}\n\n\t\t// Normally we continue searching for a match just after the\n\t\t// previous match.\n\t\tmatchcol = regmatch.endpos[0].col;\n\t\tprev_matchcol = matchcol;\n\n\t\t/*\n\t\t * 2. If do_count is set only increase the counter.\n\t\t *    If do_ask is set, ask for confirmation.\n\t\t */\n\t\tif (subflags.do_count)\n\t\t{\n\t\t    // For a multi-line match, put matchcol at the NUL at\n\t\t    // the end of the line and set nmatch to one, so that\n\t\t    // we continue looking for a match on the next line.\n\t\t    // Avoids that \":s/\\nB\\@=//gc\" get stuck.\n\t\t    if (nmatch > 1)\n\t\t    {\n\t\t\tmatchcol = (colnr_T)STRLEN(sub_firstline);\n\t\t\tnmatch = 1;\n\t\t\tskip_match = TRUE;\n\t\t    }\n\t\t    sub_nsubs++;\n\t\t    did_sub = TRUE;\n#ifdef FEAT_EVAL\n\t\t    // Skip the substitution, unless an expression is used,\n\t\t    // then it is evaluated in the sandbox.\n\t\t    if (!(sub[0] == '\\\\' && sub[1] == '='))\n#endif\n\t\t\tgoto skip;\n\t\t}\n\n\t\tif (subflags.do_ask)\n\t\t{\n\t\t    int typed = 0;\n\n\t\t    // change State to CONFIRM, so that the mouse works\n\t\t    // properly\n\t\t    save_State = State;\n\t\t    State = CONFIRM;\n\t\t    setmouse();\t\t// disable mouse in xterm\n\t\t    curwin->w_cursor.col = regmatch.startpos[0].col;\n\t\t    if (curwin->w_p_crb)\n\t\t\tdo_check_cursorbind();\n\n\t\t    // When 'cpoptions' contains \"u\" don't sync undo when\n\t\t    // asking for confirmation.\n\t\t    if (vim_strchr(p_cpo, CPO_UNDO) != NULL)\n\t\t\t++no_u_sync;\n\n\t\t    /*\n\t\t     * Loop until 'y', 'n', 'q', CTRL-E or CTRL-Y typed.\n\t\t     */\n\t\t    while (subflags.do_ask)\n\t\t    {\n\t\t\tif (exmode_active)\n\t\t\t{\n\t\t\t    char_u\t*resp;\n\t\t\t    colnr_T\tsc, ec;\n\n\t\t\t    print_line_no_prefix(lnum,\n\t\t\t\t\t subflags.do_number, subflags.do_list);\n\n\t\t\t    getvcol(curwin, &curwin->w_cursor, &sc, NULL, NULL);\n\t\t\t    curwin->w_cursor.col = regmatch.endpos[0].col - 1;\n\t\t\t    if (curwin->w_cursor.col < 0)\n\t\t\t\tcurwin->w_cursor.col = 0;\n\t\t\t    getvcol(curwin, &curwin->w_cursor, NULL, NULL, &ec);\n\t\t\t    curwin->w_cursor.col = regmatch.startpos[0].col;\n\t\t\t    if (subflags.do_number || curwin->w_p_nu)\n\t\t\t    {\n\t\t\t\tint numw = number_width(curwin) + 1;\n\t\t\t\tsc += numw;\n\t\t\t\tec += numw;\n\t\t\t    }\n\t\t\t    msg_start();\n\t\t\t    for (i = 0; i < (long)sc; ++i)\n\t\t\t\tmsg_putchar(' ');\n\t\t\t    for ( ; i <= (long)ec; ++i)\n\t\t\t\tmsg_putchar('^');\n\n\t\t\t    resp = getexmodeline('?', NULL, 0, TRUE);\n\t\t\t    if (resp != NULL)\n\t\t\t    {\n\t\t\t\ttyped = *resp;\n\t\t\t\tvim_free(resp);\n\t\t\t    }\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t    char_u *orig_line = NULL;\n\t\t\t    int    len_change = 0;\n\t\t\t    int\t   save_p_lz = p_lz;\n#ifdef FEAT_FOLDING\n\t\t\t    int save_p_fen = curwin->w_p_fen;\n\n\t\t\t    curwin->w_p_fen = FALSE;\n#endif\n\t\t\t    // Invert the matched string.\n\t\t\t    // Remove the inversion afterwards.\n\t\t\t    temp = RedrawingDisabled;\n\t\t\t    RedrawingDisabled = 0;\n\n\t\t\t    // avoid calling update_screen() in vgetorpeek()\n\t\t\t    p_lz = FALSE;\n\n\t\t\t    if (new_start != NULL)\n\t\t\t    {\n\t\t\t\t// There already was a substitution, we would\n\t\t\t\t// like to show this to the user.  We cannot\n\t\t\t\t// really update the line, it would change\n\t\t\t\t// what matches.  Temporarily replace the line\n\t\t\t\t// and change it back afterwards.\n\t\t\t\torig_line = vim_strsave(ml_get(lnum));\n\t\t\t\tif (orig_line != NULL)\n\t\t\t\t{\n\t\t\t\t    char_u *new_line = concat_str(new_start,\n\t\t\t\t\t\t     sub_firstline + copycol);\n\n\t\t\t\t    if (new_line == NULL)\n\t\t\t\t\tVIM_CLEAR(orig_line);\n\t\t\t\t    else\n\t\t\t\t    {\n\t\t\t\t\t// Position the cursor relative to the\n\t\t\t\t\t// end of the line, the previous\n\t\t\t\t\t// substitute may have inserted or\n\t\t\t\t\t// deleted characters before the\n\t\t\t\t\t// cursor.\n\t\t\t\t\tlen_change = (int)STRLEN(new_line)\n\t\t\t\t\t\t     - (int)STRLEN(orig_line);\n\t\t\t\t\tcurwin->w_cursor.col += len_change;\n\t\t\t\t\tml_replace(lnum, new_line, FALSE);\n\t\t\t\t    }\n\t\t\t\t}\n\t\t\t    }\n\n\t\t\t    search_match_lines = regmatch.endpos[0].lnum\n\t\t\t\t\t\t  - regmatch.startpos[0].lnum;\n\t\t\t    search_match_endcol = regmatch.endpos[0].col\n\t\t\t\t\t\t\t\t + len_change;\n\t\t\t    highlight_match = TRUE;\n\n\t\t\t    update_topline();\n\t\t\t    validate_cursor();\n\t\t\t    update_screen(SOME_VALID);\n\t\t\t    highlight_match = FALSE;\n\t\t\t    redraw_later(SOME_VALID);\n\n#ifdef FEAT_FOLDING\n\t\t\t    curwin->w_p_fen = save_p_fen;\n#endif\n\t\t\t    if (msg_row == Rows - 1)\n\t\t\t\tmsg_didout = FALSE;\t// avoid a scroll-up\n\t\t\t    msg_starthere();\n\t\t\t    i = msg_scroll;\n\t\t\t    msg_scroll = 0;\t\t// truncate msg when\n\t\t\t\t\t\t\t// needed\n\t\t\t    msg_no_more = TRUE;\n\t\t\t    // write message same highlighting as for\n\t\t\t    // wait_return\n\t\t\t    smsg_attr(HL_ATTR(HLF_R),\n\t\t\t\t_(\"replace with %s (y/n/a/q/l/^E/^Y)?\"), sub);\n\t\t\t    msg_no_more = FALSE;\n\t\t\t    msg_scroll = i;\n\t\t\t    showruler(TRUE);\n\t\t\t    windgoto(msg_row, msg_col);\n\t\t\t    RedrawingDisabled = temp;\n\n#ifdef USE_ON_FLY_SCROLL\n\t\t\t    dont_scroll = FALSE; // allow scrolling here\n#endif\n\t\t\t    ++no_mapping;\t// don't map this key\n\t\t\t    ++allow_keys;\t// allow special keys\n\t\t\t    typed = plain_vgetc();\n\t\t\t    --allow_keys;\n\t\t\t    --no_mapping;\n\n\t\t\t    // clear the question\n\t\t\t    msg_didout = FALSE;\t// don't scroll up\n\t\t\t    msg_col = 0;\n\t\t\t    gotocmdline(TRUE);\n\t\t\t    p_lz = save_p_lz;\n\n\t\t\t    // restore the line\n\t\t\t    if (orig_line != NULL)\n\t\t\t\tml_replace(lnum, orig_line, FALSE);\n\t\t\t}\n\n\t\t\tneed_wait_return = FALSE; // no hit-return prompt\n\t\t\tif (typed == 'q' || typed == ESC || typed == Ctrl_C\n#ifdef UNIX\n\t\t\t\t|| typed == intr_char\n#endif\n\t\t\t\t)\n\t\t\t{\n\t\t\t    got_quit = TRUE;\n\t\t\t    break;\n\t\t\t}\n\t\t\tif (typed == 'n')\n\t\t\t    break;\n\t\t\tif (typed == 'y')\n\t\t\t    break;\n\t\t\tif (typed == 'l')\n\t\t\t{\n\t\t\t    // last: replace and then stop\n\t\t\t    subflags.do_all = FALSE;\n\t\t\t    line2 = lnum;\n\t\t\t    break;\n\t\t\t}\n\t\t\tif (typed == 'a')\n\t\t\t{\n\t\t\t    subflags.do_ask = FALSE;\n\t\t\t    break;\n\t\t\t}\n\t\t\tif (typed == Ctrl_E)\n\t\t\t    scrollup_clamp();\n\t\t\telse if (typed == Ctrl_Y)\n\t\t\t    scrolldown_clamp();\n\t\t    }\n\t\t    State = save_State;\n\t\t    setmouse();\n\t\t    if (vim_strchr(p_cpo, CPO_UNDO) != NULL)\n\t\t\t--no_u_sync;\n\n\t\t    if (typed == 'n')\n\t\t    {\n\t\t\t// For a multi-line match, put matchcol at the NUL at\n\t\t\t// the end of the line and set nmatch to one, so that\n\t\t\t// we continue looking for a match on the next line.\n\t\t\t// Avoids that \":%s/\\nB\\@=//gc\" and \":%s/\\n/,\\r/gc\"\n\t\t\t// get stuck when pressing 'n'.\n\t\t\tif (nmatch > 1)\n\t\t\t{\n\t\t\t    matchcol = (colnr_T)STRLEN(sub_firstline);\n\t\t\t    skip_match = TRUE;\n\t\t\t}\n\t\t\tgoto skip;\n\t\t    }\n\t\t    if (got_quit)\n\t\t\tgoto skip;\n\t\t}\n\n\t\t// Move the cursor to the start of the match, so that we can\n\t\t// use \"\\=col(\".\").\n\t\tcurwin->w_cursor.col = regmatch.startpos[0].col;\n\n\t\t/*\n\t\t * 3. substitute the string.\n\t\t */\n#ifdef FEAT_EVAL\n\t\tsave_ma = curbuf->b_p_ma;\n\t\tif (subflags.do_count)\n\t\t{\n\t\t    // prevent accidentally changing the buffer by a function\n\t\t    curbuf->b_p_ma = FALSE;\n\t\t    sandbox++;\n\t\t}\n\t\t// Save flags for recursion.  They can change for e.g.\n\t\t// :s/^/\\=execute(\"s#^##gn\")\n\t\tsubflags_save = subflags;\n#endif\n\t\t// get length of substitution part\n\t\tsublen = vim_regsub_multi(&regmatch,\n\t\t\t\t    sub_firstlnum - regmatch.startpos[0].lnum,\n\t\t\t       sub, sub_firstline, FALSE, magic_isset(), TRUE);\n#ifdef FEAT_EVAL\n\t\t// If getting the substitute string caused an error, don't do\n\t\t// the replacement.\n\t\t// Don't keep flags set by a recursive call.\n\t\tsubflags = subflags_save;\n\t\tif (aborting() || subflags.do_count)\n\t\t{\n\t\t    curbuf->b_p_ma = save_ma;\n\t\t    if (sandbox > 0)\n\t\t\tsandbox--;\n\t\t    goto skip;\n\t\t}\n#endif\n\n\t\t// When the match included the \"$\" of the last line it may\n\t\t// go beyond the last line of the buffer.\n\t\tif (nmatch > curbuf->b_ml.ml_line_count - sub_firstlnum + 1)\n\t\t{\n\t\t    nmatch = curbuf->b_ml.ml_line_count - sub_firstlnum + 1;\n\t\t    skip_match = TRUE;\n\t\t}\n\n\t\t// Need room for:\n\t\t// - result so far in new_start (not for first sub in line)\n\t\t// - original text up to match\n\t\t// - length of substituted part\n\t\t// - original text after match\n\t\t// Adjust text properties here, since we have all information\n\t\t// needed.\n\t\tif (nmatch == 1)\n\t\t{\n\t\t    p1 = sub_firstline;\n#ifdef FEAT_PROP_POPUP\n\t\t    if (curbuf->b_has_textprop)\n\t\t    {\n\t\t\tint bytes_added = sublen - 1 - (regmatch.endpos[0].col\n\t\t\t\t\t\t   - regmatch.startpos[0].col);\n\n\t\t\t// When text properties are changed, need to save for\n\t\t\t// undo first, unless done already.\n\t\t\tif (adjust_prop_columns(lnum,\n\t\t\t\t\ttotal_added + regmatch.startpos[0].col,\n\t\t\t\t\t\t       bytes_added, apc_flags))\n\t\t\t    apc_flags &= ~APC_SAVE_FOR_UNDO;\n\t\t\t// Offset for column byte number of the text property\n\t\t\t// in the resulting buffer afterwards.\n\t\t\ttotal_added += bytes_added;\n\t\t    }\n#endif\n\t\t}\n\t\telse\n\t\t{\n\t\t    p1 = ml_get(sub_firstlnum + nmatch - 1);\n\t\t    nmatch_tl += nmatch - 1;\n\t\t}\n\t\tcopy_len = regmatch.startpos[0].col - copycol;\n\t\tneeded_len = copy_len + ((unsigned)STRLEN(p1)\n\t\t\t\t       - regmatch.endpos[0].col) + sublen + 1;\n\t\tif (new_start == NULL)\n\t\t{\n\t\t    /*\n\t\t     * Get some space for a temporary buffer to do the\n\t\t     * substitution into (and some extra space to avoid\n\t\t     * too many calls to alloc()/free()).\n\t\t     */\n\t\t    new_start_len = needed_len + 50;\n\t\t    if ((new_start = alloc(new_start_len)) == NULL)\n\t\t\tgoto outofmem;\n\t\t    *new_start = NUL;\n\t\t    new_end = new_start;\n\t\t}\n\t\telse\n\t\t{\n\t\t    /*\n\t\t     * Check if the temporary buffer is long enough to do the\n\t\t     * substitution into.  If not, make it larger (with a bit\n\t\t     * extra to avoid too many calls to alloc()/free()).\n\t\t     */\n\t\t    len = (unsigned)STRLEN(new_start);\n\t\t    needed_len += len;\n\t\t    if (needed_len > (int)new_start_len)\n\t\t    {\n\t\t\tnew_start_len = needed_len + 50;\n\t\t\tif ((p1 = alloc(new_start_len)) == NULL)\n\t\t\t{\n\t\t\t    vim_free(new_start);\n\t\t\t    goto outofmem;\n\t\t\t}\n\t\t\tmch_memmove(p1, new_start, (size_t)(len + 1));\n\t\t\tvim_free(new_start);\n\t\t\tnew_start = p1;\n\t\t    }\n\t\t    new_end = new_start + len;\n\t\t}\n\n\t\t/*\n\t\t * copy the text up to the part that matched\n\t\t */\n\t\tmch_memmove(new_end, sub_firstline + copycol, (size_t)copy_len);\n\t\tnew_end += copy_len;\n\n\t\t(void)vim_regsub_multi(&regmatch,\n\t\t\t\t    sub_firstlnum - regmatch.startpos[0].lnum,\n\t\t\t\t      sub, new_end, TRUE, magic_isset(), TRUE);\n\t\tsub_nsubs++;\n\t\tdid_sub = TRUE;\n\n\t\t// Move the cursor to the start of the line, to avoid that it\n\t\t// is beyond the end of the line after the substitution.\n\t\tcurwin->w_cursor.col = 0;\n\n\t\t// For a multi-line match, make a copy of the last matched\n\t\t// line and continue in that one.\n\t\tif (nmatch > 1)\n\t\t{\n\t\t    sub_firstlnum += nmatch - 1;\n\t\t    vim_free(sub_firstline);\n\t\t    sub_firstline = vim_strsave(ml_get(sub_firstlnum));\n\t\t    // When going beyond the last line, stop substituting.\n\t\t    if (sub_firstlnum <= line2)\n\t\t\tdo_again = TRUE;\n\t\t    else\n\t\t\tsubflags.do_all = FALSE;\n\t\t}\n\n\t\t// Remember next character to be copied.\n\t\tcopycol = regmatch.endpos[0].col;\n\n\t\tif (skip_match)\n\t\t{\n\t\t    // Already hit end of the buffer, sub_firstlnum is one\n\t\t    // less than what it ought to be.\n\t\t    vim_free(sub_firstline);\n\t\t    sub_firstline = vim_strsave((char_u *)\"\");\n\t\t    copycol = 0;\n\t\t}\n\n\t\t/*\n\t\t * Now the trick is to replace CTRL-M chars with a real line\n\t\t * break.  This would make it impossible to insert a CTRL-M in\n\t\t * the text.  The line break can be avoided by preceding the\n\t\t * CTRL-M with a backslash.  To be able to insert a backslash,\n\t\t * they must be doubled in the string and are halved here.\n\t\t * That is Vi compatible.\n\t\t */\n\t\tfor (p1 = new_end; *p1; ++p1)\n\t\t{\n\t\t    if (p1[0] == '\\\\' && p1[1] != NUL)  // remove backslash\n\t\t    {\n\t\t\tSTRMOVE(p1, p1 + 1);\n#ifdef FEAT_PROP_POPUP\n\t\t\tif (curbuf->b_has_textprop)\n\t\t\t{\n\t\t\t    // When text properties are changed, need to save\n\t\t\t    // for undo first, unless done already.\n\t\t\t    if (adjust_prop_columns(lnum,\n\t\t\t\t\t(colnr_T)(p1 - new_start), -1,\n\t\t\t\t\tapc_flags))\n\t\t\t\tapc_flags &= ~APC_SAVE_FOR_UNDO;\n\t\t\t}\n#endif\n\t\t    }\n\t\t    else if (*p1 == CAR)\n\t\t    {\n\t\t\tif (u_inssub(lnum) == OK)   // prepare for undo\n\t\t\t{\n\t\t\t    colnr_T\tplen = (colnr_T)(p1 - new_start + 1);\n\n\t\t\t    *p1 = NUL;\t\t    // truncate up to the CR\n\t\t\t    ml_append(lnum - 1, new_start, plen, FALSE);\n\t\t\t    mark_adjust(lnum + 1, (linenr_T)MAXLNUM, 1L, 0L);\n\t\t\t    if (subflags.do_ask)\n\t\t\t\tappended_lines(lnum - 1, 1L);\n\t\t\t    else\n\t\t\t    {\n\t\t\t\tif (first_line == 0)\n\t\t\t\t    first_line = lnum;\n\t\t\t\tlast_line = lnum + 1;\n\t\t\t    }\n#ifdef FEAT_PROP_POPUP\n\t\t\t    adjust_props_for_split(lnum + 1, lnum, plen, 1);\n#endif\n\t\t\t    // all line numbers increase\n\t\t\t    ++sub_firstlnum;\n\t\t\t    ++lnum;\n\t\t\t    ++line2;\n\t\t\t    // move the cursor to the new line, like Vi\n\t\t\t    ++curwin->w_cursor.lnum;\n\t\t\t    // copy the rest\n\t\t\t    STRMOVE(new_start, p1 + 1);\n\t\t\t    p1 = new_start - 1;\n\t\t\t}\n\t\t    }\n\t\t    else if (has_mbyte)\n\t\t\tp1 += (*mb_ptr2len)(p1) - 1;\n\t\t}\n\n\t\t/*\n\t\t * 4. If do_all is set, find next match.\n\t\t * Prevent endless loop with patterns that match empty\n\t\t * strings, e.g. :s/$/pat/g or :s/[a-z]* /(&)/g.\n\t\t * But \":s/\\n/#/\" is OK.\n\t\t */\nskip:\n\t\t// We already know that we did the last subst when we are at\n\t\t// the end of the line, except that a pattern like\n\t\t// \"bar\\|\\nfoo\" may match at the NUL.  \"lnum\" can be below\n\t\t// \"line2\" when there is a \\zs in the pattern after a line\n\t\t// break.\n\t\tlastone = (skip_match\n\t\t\t|| got_int\n\t\t\t|| got_quit\n\t\t\t|| lnum > line2\n\t\t\t|| !(subflags.do_all || do_again)\n\t\t\t|| (sub_firstline[matchcol] == NUL && nmatch <= 1\n\t\t\t\t\t && !re_multiline(regmatch.regprog)));\n\t\tnmatch = -1;\n\n\t\t/*\n\t\t * Replace the line in the buffer when needed.  This is\n\t\t * skipped when there are more matches.\n\t\t * The check for nmatch_tl is needed for when multi-line\n\t\t * matching must replace the lines before trying to do another\n\t\t * match, otherwise \"\\@<=\" won't work.\n\t\t * When the match starts below where we start searching also\n\t\t * need to replace the line first (using \\zs after \\n).\n\t\t */\n\t\tif (lastone\n\t\t\t|| nmatch_tl > 0\n\t\t\t|| (nmatch = vim_regexec_multi(&regmatch, curwin,\n\t\t\t\t\t\t\tcurbuf, sub_firstlnum,\n\t\t\t\t\t\t    matchcol, NULL, NULL)) == 0\n\t\t\t|| regmatch.startpos[0].lnum > 0)\n\t\t{\n\t\t    if (new_start != NULL)\n\t\t    {\n\t\t\t/*\n\t\t\t * Copy the rest of the line, that didn't match.\n\t\t\t * \"matchcol\" has to be adjusted, we use the end of\n\t\t\t * the line as reference, because the substitute may\n\t\t\t * have changed the number of characters.  Same for\n\t\t\t * \"prev_matchcol\".\n\t\t\t */\n\t\t\tSTRCAT(new_start, sub_firstline + copycol);\n\t\t\tmatchcol = (colnr_T)STRLEN(sub_firstline) - matchcol;\n\t\t\tprev_matchcol = (colnr_T)STRLEN(sub_firstline)\n\t\t\t\t\t\t\t      - prev_matchcol;\n\n\t\t\tif (u_savesub(lnum) != OK)\n\t\t\t    break;\n\t\t\tml_replace(lnum, new_start, TRUE);\n\n\t\t\tif (nmatch_tl > 0)\n\t\t\t{\n\t\t\t    /*\n\t\t\t     * Matched lines have now been substituted and are\n\t\t\t     * useless, delete them.  The part after the match\n\t\t\t     * has been appended to new_start, we don't need\n\t\t\t     * it in the buffer.\n\t\t\t     */\n\t\t\t    ++lnum;\n\t\t\t    if (u_savedel(lnum, nmatch_tl) != OK)\n\t\t\t\tbreak;\n\t\t\t    for (i = 0; i < nmatch_tl; ++i)\n\t\t\t\tml_delete(lnum);\n\t\t\t    mark_adjust(lnum, lnum + nmatch_tl - 1,\n\t\t\t\t\t\t   (long)MAXLNUM, -nmatch_tl);\n\t\t\t    if (subflags.do_ask)\n\t\t\t\tdeleted_lines(lnum, nmatch_tl);\n\t\t\t    --lnum;\n\t\t\t    line2 -= nmatch_tl; // nr of lines decreases\n\t\t\t    nmatch_tl = 0;\n\t\t\t}\n\n\t\t\t// When asking, undo is saved each time, must also set\n\t\t\t// changed flag each time.\n\t\t\tif (subflags.do_ask)\n\t\t\t    changed_bytes(lnum, 0);\n\t\t\telse\n\t\t\t{\n\t\t\t    if (first_line == 0)\n\t\t\t\tfirst_line = lnum;\n\t\t\t    last_line = lnum + 1;\n\t\t\t}\n\n\t\t\tsub_firstlnum = lnum;\n\t\t\tvim_free(sub_firstline);    // free the temp buffer\n\t\t\tsub_firstline = new_start;\n\t\t\tnew_start = NULL;\n\t\t\tmatchcol = (colnr_T)STRLEN(sub_firstline) - matchcol;\n\t\t\tprev_matchcol = (colnr_T)STRLEN(sub_firstline)\n\t\t\t\t\t\t\t      - prev_matchcol;\n\t\t\tcopycol = 0;\n\t\t    }\n\t\t    if (nmatch == -1 && !lastone)\n\t\t\tnmatch = vim_regexec_multi(&regmatch, curwin, curbuf,\n\t\t\t\t\t  sub_firstlnum, matchcol, NULL, NULL);\n\n\t\t    /*\n\t\t     * 5. break if there isn't another match in this line\n\t\t     */\n\t\t    if (nmatch <= 0)\n\t\t    {\n\t\t\t// If the match found didn't start where we were\n\t\t\t// searching, do the next search in the line where we\n\t\t\t// found the match.\n\t\t\tif (nmatch == -1)\n\t\t\t    lnum -= regmatch.startpos[0].lnum;\n\t\t\tbreak;\n\t\t    }\n\t\t}\n\n\t\tline_breakcheck();\n\t    }\n\n\t    if (did_sub)\n\t\t++sub_nlines;\n\t    vim_free(new_start);\t// for when substitute was cancelled\n\t    VIM_CLEAR(sub_firstline);\t// free the copy of the original line\n\t}\n\n\tline_breakcheck();\n    }\n\n    if (first_line != 0)\n    {\n\t// Need to subtract the number of added lines from \"last_line\" to get\n\t// the line number before the change (same as adding the number of\n\t// deleted lines).\n\ti = curbuf->b_ml.ml_line_count - old_line_count;\n\tchanged_lines(first_line, 0, last_line - i, i);\n    }\n\noutofmem:\n    vim_free(sub_firstline); // may have to free allocated copy of the line\n\n    // \":s/pat//n\" doesn't move the cursor\n    if (subflags.do_count)\n\tcurwin->w_cursor = old_cursor;\n\n    if (sub_nsubs > start_nsubs)\n    {\n\tif ((cmdmod.cmod_flags & CMOD_LOCKMARKS) == 0)\n\t{\n\t    // Set the '[ and '] marks.\n\t    curbuf->b_op_start.lnum = eap->line1;\n\t    curbuf->b_op_end.lnum = line2;\n\t    curbuf->b_op_start.col = curbuf->b_op_end.col = 0;\n\t}\n\n\tif (!global_busy)\n\t{\n\t    // when interactive leave cursor on the match\n\t    if (!subflags.do_ask)\n\t    {\n\t\tif (endcolumn)\n\t\t    coladvance((colnr_T)MAXCOL);\n\t\telse\n\t\t    beginline(BL_WHITE | BL_FIX);\n\t    }\n\t    if (!do_sub_msg(subflags.do_count) && subflags.do_ask)\n\t\tmsg(\"\");\n\t}\n\telse\n\t    global_need_beginline = TRUE;\n\tif (subflags.do_print)\n\t    print_line(curwin->w_cursor.lnum,\n\t\t\t\t\t subflags.do_number, subflags.do_list);\n    }\n    else if (!global_busy)\n    {\n\tif (got_int)\t\t// interrupted\n\t    emsg(_(e_interrupted));\n\telse if (got_match)\t// did find something but nothing substituted\n\t    msg(\"\");\n\telse if (subflags.do_error)\t// nothing found\n\t    semsg(_(e_pattern_not_found_str), get_search_pat());\n    }\n\n#ifdef FEAT_FOLDING\n    if (subflags.do_ask && hasAnyFolding(curwin))\n\t// Cursor position may require updating\n\tchanged_window_setting();\n#endif\n\n    vim_regfree(regmatch.regprog);\n\n    // Restore the flag values, they can be used for \":&&\".\n    subflags.do_all = save_do_all;\n    subflags.do_ask = save_do_ask;\n}",
        "func_hash": 259196751787508005925510441148614080583,
        "file_name": "ex_cmds.c",
        "file_hash": 59965875084146466287270368497703800580,
        "cwe": [
            "CWE-416"
        ],
        "cve": "CVE-2022-0413",
        "cve_desc": "Use After Free in GitHub repository vim/vim prior to 8.2.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-0413",
        "func_name": "ex_substitute",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 200113,
        "project": "ImageMagick",
        "commit_id": "389ecc365a7c61404ba078a72c3fa5a3cf1b4101",
        "project_url": "https://github.com/ImageMagick/ImageMagick",
        "commit_url": "https://github.com/ImageMagick/ImageMagick/commit/389ecc365a7c61404ba078a72c3fa5a3cf1b4101",
        "commit_message": "https://github.com/ImageMagick/ImageMagick/issues/1221",
        "target": 1,
        "irrelevant": 1,
        "func_before": "static Image *ReadMATImageV4(const ImageInfo *image_info,Image *image,\n  ExceptionInfo *exception)\n{\n  typedef struct {\n    unsigned char Type[4];\n    unsigned int nRows;\n    unsigned int nCols;\n    unsigned int imagf;\n    unsigned int nameLen;\n  } MAT4_HDR;\n\n  long\n    ldblk;\n\n  EndianType\n    endian;\n\n  Image\n    *rotated_image;\n\n  MagickBooleanType\n    status;\n\n  MAT4_HDR\n    HDR;\n\n  QuantumInfo\n    *quantum_info;\n\n  QuantumFormatType\n    format_type;\n\n  register ssize_t\n    i;\n\n  ssize_t\n    count,\n    y;\n\n  unsigned char\n    *pixels;\n\n  unsigned int\n    depth;\n\n\n  quantum_info=(QuantumInfo *) NULL;\n  (void) SeekBlob(image,0,SEEK_SET);\n  while (EOFBlob(image) == MagickFalse)\n  {\n    /*\n     Object parser loop.\n    */\n    ldblk=ReadBlobLSBLong(image);\n    if ((ldblk > 9999) || (ldblk < 0))\n      break;\n    HDR.Type[3]=ldblk % 10; ldblk /= 10;  /* T digit */\n    HDR.Type[2]=ldblk % 10; ldblk /= 10;  /* P digit */\n    HDR.Type[1]=ldblk % 10; ldblk /= 10;  /* O digit */\n    HDR.Type[0]=ldblk;        /* M digit */\n    if (HDR.Type[3] != 0)\n      break;  /* Data format */\n    if (HDR.Type[2] != 0)\n      break;  /* Always 0 */\n    if (HDR.Type[0] == 0)\n      {\n        HDR.nRows=ReadBlobLSBLong(image);\n        HDR.nCols=ReadBlobLSBLong(image);\n        HDR.imagf=ReadBlobLSBLong(image);\n        HDR.nameLen=ReadBlobLSBLong(image);\n        endian=LSBEndian;\n      }\n    else\n      {\n        HDR.nRows=ReadBlobMSBLong(image);\n        HDR.nCols=ReadBlobMSBLong(image);\n        HDR.imagf=ReadBlobMSBLong(image);\n        HDR.nameLen=ReadBlobMSBLong(image);\n        endian=MSBEndian;\n      }\n    if ((HDR.imagf != 0) && (HDR.imagf != 1))\n      break;\n    if (HDR.nameLen > 0xFFFF)\n      return(DestroyImageList(image));\n    for (i=0; i < (ssize_t) HDR.nameLen; i++)\n    {\n      int\n        byte;\n\n      /*\n        Skip matrix name.\n      */\n      byte=ReadBlobByte(image);\n      if (byte == EOF)\n        {\n          ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n            image->filename);\n          break;\n        }\n    }\n    image->columns=(size_t) HDR.nRows;\n    image->rows=(size_t) HDR.nCols;\n    if ((image->columns == 0) || (image->rows == 0))\n      return(DestroyImageList(image));\n    if (image_info->ping != MagickFalse)\n      {\n        Swap(image->columns,image->rows);\n        if(HDR.imagf==1) ldblk *= 2;\n        SeekBlob(image, HDR.nCols*ldblk, SEEK_CUR);\n        if ((image->columns == 0) || (image->rows == 0))\n          return(image->previous == (Image *) NULL ? DestroyImageList(image)\n            : image);\n        goto skip_reading_current;\n      }\n    status=SetImageExtent(image,image->columns,image->rows,exception);\n    if (status == MagickFalse)\n      return(DestroyImageList(image));\n    (void) SetImageBackgroundColor(image,exception);\n    (void) SetImageColorspace(image,GRAYColorspace,exception);\n    quantum_info=AcquireQuantumInfo(image_info,image);\n    if (quantum_info == (QuantumInfo *) NULL)\n      return(DestroyImageList(image));\n    switch(HDR.Type[1])\n    {\n      case 0:\n        format_type=FloatingPointQuantumFormat;\n        depth=64;\n        break;\n      case 1:\n        format_type=FloatingPointQuantumFormat;\n        depth=32;\n        break;\n      case 2:\n        format_type=UnsignedQuantumFormat;\n        depth=16;\n        break;\n      case 3:\n        format_type=SignedQuantumFormat;\n        depth=16;\n        break;\n      case 4:\n        format_type=UnsignedQuantumFormat;\n        depth=8;\n        break;\n      default:\n        format_type=UnsignedQuantumFormat;\n        depth=8;\n        break;\n    }\n    image->depth=depth;\n    if (HDR.Type[0] != 0)\n      SetQuantumEndian(image,quantum_info,MSBEndian);\n    status=SetQuantumFormat(image,quantum_info,format_type);\n    status=SetQuantumDepth(image,quantum_info,depth);\n    status=SetQuantumEndian(image,quantum_info,endian);\n    SetQuantumScale(quantum_info,1.0);\n    pixels=(unsigned char *) GetQuantumPixels(quantum_info);\n    for (y=0; y < (ssize_t) image->rows; y++)\n    {\n      register Quantum\n        *magick_restrict q;\n\n      count=ReadBlob(image,depth/8*image->columns,(char *) pixels);\n      if (count == -1)\n        break;\n      q=QueueAuthenticPixels(image,0,image->rows-y-1,image->columns,1,\n        exception);\n      if (q == (Quantum *) NULL)\n        break;\n      (void) ImportQuantumPixels(image,(CacheView *) NULL,quantum_info,\n        GrayQuantum,pixels,exception);\n      if ((HDR.Type[1] == 2) || (HDR.Type[1] == 3))\n        FixSignedValues(image,q,(int) image->columns);\n      if (SyncAuthenticPixels(image,exception) == MagickFalse)\n        break;\n      if (image->previous == (Image *) NULL)\n        {\n          status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n            image->rows);\n          if (status == MagickFalse)\n            break;\n        }\n    }\n    if (HDR.imagf == 1)\n      for (y=0; y < (ssize_t) image->rows; y++)\n      {\n        /*\n          Read complex pixels.\n        */\n        count=ReadBlob(image,depth/8*image->columns,(char *) pixels);\n        if (count == -1)\n          break;\n        if (HDR.Type[1] == 0)\n          InsertComplexDoubleRow(image,(double *) pixels,y,0,0,exception);\n        else\n          InsertComplexFloatRow(image,(float *) pixels,y,0,0,exception);\n      }\n    if (quantum_info != (QuantumInfo *) NULL)\n      quantum_info=DestroyQuantumInfo(quantum_info);\n    if (EOFBlob(image) != MagickFalse)\n      {\n        ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n          image->filename);\n        break;\n      }\n    rotated_image=RotateImage(image,90.0,exception);\n    if (rotated_image != (Image *) NULL)\n      {\n        rotated_image->page.x=0;\n        rotated_image->page.y=0;\n        rotated_image->colors = image->colors;\n        DestroyBlob(rotated_image);\n        rotated_image->blob=ReferenceBlob(image->blob);\n        AppendImageToList(&image,rotated_image);\n        DeleteImageFromList(&image);\n      }\n    /*\n      Proceed to next image.\n    */\n    if (image_info->number_scenes != 0)\n      if (image->scene >= (image_info->scene+image_info->number_scenes-1))\n        break;\n    /*\n      Allocate next image structure.\n    */\nskip_reading_current:\n    AcquireNextImage(image_info,image,exception);\n    if (GetNextImageInList(image) == (Image *) NULL)\n      {\n        status=MagickFalse;\n        break;\n      }\n    image=SyncNextImageInList(image);\n    status=SetImageProgress(image,LoadImagesTag,TellBlob(image),\n      GetBlobSize(image));\n    if (status == MagickFalse)\n      break;\n  }\n  (void) CloseBlob(image);\n  if (status == MagickFalse)\n    return(DestroyImageList(image));\n  return(GetFirstImageInList(image));\n}",
        "func_hash": 285338942932126464684406061663699404409,
        "file_name": "mat.c",
        "file_hash": 152895055268444149031499537279657208937,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2018-14551",
        "cve_desc": "The ReadMATImageV4 function in coders/mat.c in ImageMagick 7.0.8-7 uses an uninitialized variable, leading to memory corruption.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2018-14551",
        "func_name": "ReadMATImageV4",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 200157,
        "project": "exim",
        "commit_id": "e2f5dc151e2e79058e93924e6d35510557f0535d",
        "project_url": "https://github.com/Exim/exim",
        "commit_url": "http://git.exim.org/exim.git/commit/e2f5dc151e2e79058e93924e6d35510557f0535d",
        "commit_message": "Check configure file permissions even for non-default files if still privileged\n\n(Bug 1044, CVE-2010-4345)",
        "target": 1,
        "irrelevant": 0,
        "func_before": "readconf_main(void)\n{\nint sep = 0;\nstruct stat statbuf;\nuschar *s, *filename;\nuschar *list = config_main_filelist;\n\n/* Loop through the possible file names */\n\nwhile((filename = string_nextinlist(&list, &sep, big_buffer, big_buffer_size))\n       != NULL)\n  {\n  /* Cut out all the fancy processing unless specifically wanted */\n\n  #if defined(CONFIGURE_FILE_USE_NODE) || defined(CONFIGURE_FILE_USE_EUID)\n  uschar *suffix = filename + Ustrlen(filename);\n\n  /* Try for the node-specific file if a node name exists */\n\n  #ifdef CONFIGURE_FILE_USE_NODE\n  struct utsname uts;\n  if (uname(&uts) >= 0)\n    {\n    #ifdef CONFIGURE_FILE_USE_EUID\n    sprintf(CS suffix, \".%ld.%.256s\", (long int)original_euid, uts.nodename);\n    config_file = Ufopen(filename, \"rb\");\n    if (config_file == NULL)\n    #endif  /* CONFIGURE_FILE_USE_EUID */\n      {\n      sprintf(CS suffix, \".%.256s\", uts.nodename);\n      config_file = Ufopen(filename, \"rb\");\n      }\n    }\n  #endif  /* CONFIGURE_FILE_USE_NODE */\n\n  /* Otherwise, try the generic name, possibly with the euid added */\n\n  #ifdef CONFIGURE_FILE_USE_EUID\n  if (config_file == NULL)\n    {\n    sprintf(CS suffix, \".%ld\", (long int)original_euid);\n    config_file = Ufopen(filename, \"rb\");\n    }\n  #endif  /* CONFIGURE_FILE_USE_EUID */\n\n  /* Finally, try the unadorned name */\n\n  if (config_file == NULL)\n    {\n    *suffix = 0;\n    config_file = Ufopen(filename, \"rb\");\n    }\n  #else  /* if neither defined */\n\n  /* This is the common case when the fancy processing is not included. */\n\n  config_file = Ufopen(filename, \"rb\");\n  #endif\n\n  /* If the file does not exist, continue to try any others. For any other\n  error, break out (and die). */\n\n  if (config_file != NULL || errno != ENOENT) break;\n  }\n\n/* On success, save the name for verification; config_filename is used when\nlogging configuration errors (it changes for .included files) whereas\nconfig_main_filename is the name shown by -bP. Failure to open a configuration\nfile is a serious disaster. */\n\nif (config_file != NULL)\n  {\n  config_filename = config_main_filename = string_copy(filename);\n  }\nelse\n  {\n  if (filename == NULL)\n    log_write(0, LOG_MAIN|LOG_PANIC_DIE, \"non-existent configuration file(s): \"\n      \"%s\", config_main_filelist);\n  else\n    log_write(0, LOG_MAIN|LOG_PANIC_DIE, \"%s\", string_open_failed(errno,\n      \"configuration file %s\", filename));\n  }\n\n/* Check the status of the file we have opened, unless it was specified on\nthe command line, in which case privilege was given away at the start. */\n\nif (!config_changed)\n  {\n  if (fstat(fileno(config_file), &statbuf) != 0)\n    log_write(0, LOG_MAIN|LOG_PANIC_DIE, \"failed to stat configuration file %s\",\n      big_buffer);\n\n  if ((statbuf.st_uid != root_uid                /* owner not root */\n       #ifdef CONFIGURE_OWNER\n       && statbuf.st_uid != config_uid           /* owner not the special one */\n       #endif\n         ) ||                                    /* or */\n      (statbuf.st_gid != root_gid                /* group not root & */\n       #ifdef CONFIGURE_GROUP\n       && statbuf.st_gid != config_gid           /* group not the special one */\n       #endif\n       && (statbuf.st_mode & 020) != 0) ||       /* group writeable  */\n                                                 /* or */\n      ((statbuf.st_mode & 2) != 0))              /* world writeable  */\n\n    log_write(0, LOG_MAIN|LOG_PANIC_DIE, \"Exim configuration file %s has the \"\n      \"wrong owner, group, or mode\", big_buffer);\n  }\n\n/* Process the main configuration settings. They all begin with a lower case\nletter. If we see something starting with an upper case letter, it is taken as\na macro definition. */\n\nwhile ((s = get_config_line()) != NULL)\n  {\n  if (isupper(s[0])) read_macro_assignment(s);\n\n  else if (Ustrncmp(s, \"domainlist\", 10) == 0)\n    read_named_list(&domainlist_anchor, &domainlist_count,\n      MAX_NAMED_LIST, s+10, US\"domain list\");\n\n  else if (Ustrncmp(s, \"hostlist\", 8) == 0)\n    read_named_list(&hostlist_anchor, &hostlist_count,\n      MAX_NAMED_LIST, s+8, US\"host list\");\n\n  else if (Ustrncmp(s, US\"addresslist\", 11) == 0)\n    read_named_list(&addresslist_anchor, &addresslist_count,\n      MAX_NAMED_LIST, s+11, US\"address list\");\n\n  else if (Ustrncmp(s, US\"localpartlist\", 13) == 0)\n    read_named_list(&localpartlist_anchor, &localpartlist_count,\n      MAX_NAMED_LIST, s+13, US\"local part list\");\n\n  else\n    (void) readconf_handle_option(s, optionlist_config, optionlist_config_size,\n      NULL, US\"main option \\\"%s\\\" unknown\");\n  }\n\n\n/* If local_sender_retain is set, local_from_check must be unset. */\n\nif (local_sender_retain && local_from_check)\n  log_write(0, LOG_MAIN|LOG_PANIC_DIE, \"both local_from_check and \"\n    \"local_sender_retain are set; this combination is not allowed\");\n\n/* If the timezone string is empty, set it to NULL, implying no TZ variable\nwanted. */\n\nif (timezone_string != NULL && *timezone_string == 0) timezone_string = NULL;\n\n/* The max retry interval must not be greater than 24 hours. */\n\nif (retry_interval_max > 24*60*60) retry_interval_max = 24*60*60;\n\n/* remote_max_parallel must be > 0 */\n\nif (remote_max_parallel <= 0) remote_max_parallel = 1;\n\n/* Save the configured setting of freeze_tell, so we can re-instate it at the\nstart of a new SMTP message. */\n\nfreeze_tell_config = freeze_tell;\n\n/* The primary host name may be required for expansion of spool_directory\nand log_file_path, so make sure it is set asap. It is obtained from uname(),\nbut if that yields an unqualified value, make a FQDN by using gethostbyname to\ncanonize it. Some people like upper case letters in their host names, so we\ndon't force the case. */\n\nif (primary_hostname == NULL)\n  {\n  uschar *hostname;\n  struct utsname uts;\n  if (uname(&uts) < 0)\n    log_write(0, LOG_MAIN|LOG_PANIC_DIE, \"uname() failed to yield host name\");\n  hostname = US uts.nodename;\n\n  if (Ustrchr(hostname, '.') == NULL)\n    {\n    int af = AF_INET;\n    struct hostent *hostdata;\n\n    #if HAVE_IPV6\n    if (!disable_ipv6 && (dns_ipv4_lookup == NULL ||\n         match_isinlist(hostname, &dns_ipv4_lookup, 0, NULL, NULL, MCL_DOMAIN,\n           TRUE, NULL) != OK))\n      af = AF_INET6;\n    #else\n    af = AF_INET;\n    #endif\n\n    for (;;)\n      {\n      #if HAVE_IPV6\n        #if HAVE_GETIPNODEBYNAME\n        int error_num;\n        hostdata = getipnodebyname(CS hostname, af, 0, &error_num);\n        #else\n        hostdata = gethostbyname2(CS hostname, af);\n        #endif\n      #else\n      hostdata = gethostbyname(CS hostname);\n      #endif\n\n      if (hostdata != NULL)\n        {\n        hostname = US hostdata->h_name;\n        break;\n        }\n\n      if (af == AF_INET) break;\n      af = AF_INET;\n      }\n    }\n\n  primary_hostname = string_copy(hostname);\n  }\n\n/* Set up default value for smtp_active_hostname */\n\nsmtp_active_hostname = primary_hostname;\n\n/* If spool_directory wasn't set in the build-time configuration, it must have\ngot set above. Of course, writing to the log may not work if log_file_path is\nnot set, but it will at least get to syslog or somewhere, with any luck. */\n\nif (*spool_directory == 0)\n  log_write(0, LOG_MAIN|LOG_PANIC_DIE, \"spool_directory undefined: cannot \"\n    \"proceed\");\n\n/* Expand the spool directory name; it may, for example, contain the primary\nhost name. Same comment about failure. */\n\ns = expand_string(spool_directory);\nif (s == NULL)\n  log_write(0, LOG_MAIN|LOG_PANIC_DIE, \"failed to expand spool_directory \"\n    \"\\\"%s\\\": %s\", spool_directory, expand_string_message);\nspool_directory = s;\n\n/* Expand log_file_path, which must contain \"%s\" in any component that isn't\nthe null string or \"syslog\". It is also allowed to contain one instance of %D.\nHowever, it must NOT contain % followed by anything else. */\n\nif (*log_file_path != 0)\n  {\n  uschar *ss, *sss;\n  int sep = ':';                       /* Fixed for log file path */\n  s = expand_string(log_file_path);\n  if (s == NULL)\n    log_write(0, LOG_MAIN|LOG_PANIC_DIE, \"failed to expand log_file_path \"\n      \"\\\"%s\\\": %s\", log_file_path, expand_string_message);\n\n  ss = s;\n  while ((sss = string_nextinlist(&ss,&sep,big_buffer,big_buffer_size)) != NULL)\n    {\n    uschar *t;\n    if (sss[0] == 0 || Ustrcmp(sss, \"syslog\") == 0) continue;\n    t = Ustrstr(sss, \"%s\");\n    if (t == NULL)\n      log_write(0, LOG_MAIN|LOG_PANIC_DIE, \"log_file_path \\\"%s\\\" does not \"\n        \"contain \\\"%%s\\\"\", sss);\n    *t = 'X';\n    t = Ustrchr(sss, '%');\n    if (t != NULL)\n      {\n      if (t[1] != 'D' || Ustrchr(t+2, '%') != NULL)\n        log_write(0, LOG_MAIN|LOG_PANIC_DIE, \"log_file_path \\\"%s\\\" contains \"\n          \"unexpected \\\"%%\\\" character\", s);\n      }\n    }\n\n  log_file_path = s;\n  }\n\n/* Interpret syslog_facility into an integer argument for 'ident' param to\nopenlog(). Default is LOG_MAIL set in globals.c. Allow the user to omit the\nleading \"log_\". */\n\nif (syslog_facility_str != NULL)\n  {\n  int i;\n  uschar *s = syslog_facility_str;\n\n  if ((Ustrlen(syslog_facility_str) >= 4) &&\n        (strncmpic(syslog_facility_str, US\"log_\", 4) == 0))\n    s += 4;\n\n  for (i = 0; i < syslog_list_size; i++)\n    {\n    if (strcmpic(s, syslog_list[i].name) == 0)\n      {\n      syslog_facility = syslog_list[i].value;\n      break;\n      }\n    }\n\n  if (i >= syslog_list_size)\n    {\n    log_write(0, LOG_PANIC_DIE|LOG_CONFIG,\n      \"failed to interpret syslog_facility \\\"%s\\\"\", syslog_facility_str);\n    }\n  }\n\n/* Expand pid_file_path */\n\nif (*pid_file_path != 0)\n  {\n  s = expand_string(pid_file_path);\n  if (s == NULL)\n    log_write(0, LOG_MAIN|LOG_PANIC_DIE, \"failed to expand pid_file_path \"\n      \"\\\"%s\\\": %s\", pid_file_path, expand_string_message);\n  pid_file_path = s;\n  }\n\n/* Compile the regex for matching a UUCP-style \"From_\" line in an incoming\nmessage. */\n\nregex_From = regex_must_compile(uucp_from_pattern, FALSE, TRUE);\n\n/* Unpick the SMTP rate limiting options, if set */\n\nif (smtp_ratelimit_mail != NULL)\n  {\n  unpick_ratelimit(smtp_ratelimit_mail, &smtp_rlm_threshold,\n    &smtp_rlm_base, &smtp_rlm_factor, &smtp_rlm_limit);\n  }\n\nif (smtp_ratelimit_rcpt != NULL)\n  {\n  unpick_ratelimit(smtp_ratelimit_rcpt, &smtp_rlr_threshold,\n    &smtp_rlr_base, &smtp_rlr_factor, &smtp_rlr_limit);\n  }\n\n/* The qualify domains default to the primary host name */\n\nif (qualify_domain_sender == NULL)\n  qualify_domain_sender = primary_hostname;\nif (qualify_domain_recipient == NULL)\n  qualify_domain_recipient = qualify_domain_sender;\n\n/* Setting system_filter_user in the configuration sets the gid as well if a\nname is given, but a numerical value does not. */\n\nif (system_filter_uid_set && !system_filter_gid_set)\n  {\n  struct passwd *pw = getpwuid(system_filter_uid);\n  if (pw == NULL)\n    log_write(0, LOG_MAIN|LOG_PANIC_DIE, \"Failed to look up uid %ld\",\n      (long int)system_filter_uid);\n  system_filter_gid = pw->pw_gid;\n  system_filter_gid_set = TRUE;\n  }\n\n/* If the errors_reply_to field is set, check that it is syntactically valid\nand ensure it contains a domain. */\n\nif (errors_reply_to != NULL)\n  {\n  uschar *errmess;\n  int start, end, domain;\n  uschar *recipient = parse_extract_address(errors_reply_to, &errmess,\n    &start, &end, &domain, FALSE);\n\n  if (recipient == NULL)\n    log_write(0, LOG_PANIC_DIE|LOG_CONFIG,\n      \"error in errors_reply_to (%s): %s\", errors_reply_to, errmess);\n\n  if (domain == 0)\n    log_write(0, LOG_PANIC_DIE|LOG_CONFIG,\n      \"errors_reply_to (%s) does not contain a domain\", errors_reply_to);\n  }\n\n/* If smtp_accept_queue or smtp_accept_max_per_host is set, then\nsmtp_accept_max must also be set. */\n\nif (smtp_accept_max == 0 &&\n    (smtp_accept_queue > 0 || smtp_accept_max_per_host != NULL))\n  log_write(0, LOG_PANIC_DIE|LOG_CONFIG,\n    \"smtp_accept_max must be set if smtp_accept_queue or \"\n    \"smtp_accept_max_per_host is set\");\n\n/* Set up the host number if anything is specified. It is an expanded string\nso that it can be computed from the host name, for example. We do this last\nso as to ensure that everything else is set up before the expansion. */\n\nif (host_number_string != NULL)\n  {\n  uschar *end;\n  uschar *s = expand_string(host_number_string);\n  long int n = Ustrtol(s, &end, 0);\n  while (isspace(*end)) end++;\n  if (*end != 0)\n    log_write(0, LOG_PANIC_DIE|LOG_CONFIG,\n      \"localhost_number value is not a number: %s\", s);\n  if (n > LOCALHOST_MAX)\n    log_write(0, LOG_PANIC_DIE|LOG_CONFIG,\n      \"localhost_number is greater than the maximum allowed value (%d)\",\n        LOCALHOST_MAX);\n  host_number = n;\n  }\n\n#ifdef SUPPORT_TLS\n/* If tls_verify_hosts is set, tls_verify_certificates must also be set */\n\nif ((tls_verify_hosts != NULL || tls_try_verify_hosts != NULL) &&\n     tls_verify_certificates == NULL)\n  log_write(0, LOG_PANIC_DIE|LOG_CONFIG,\n    \"tls_%sverify_hosts is set, but tls_verify_certificates is not set\",\n    (tls_verify_hosts != NULL)? \"\" : \"try_\");\n\n/* If openssl_options is set, validate it */\nif (openssl_options != NULL)\n  {\n# ifdef USE_GNUTLS\n  log_write(0, LOG_PANIC_DIE|LOG_CONFIG,\n    \"openssl_options is set but we're using GnuTLS\");\n# else\n  long dummy;\n  if (!(tls_openssl_options_parse(openssl_options, &dummy)))\n    log_write(0, LOG_PANIC_DIE|LOG_CONFIG,\n      \"openssl_options parse error: %s\", openssl_options);\n# endif\n  }\n#endif\n}",
        "func_hash": 74987850300315727501245353003929658606,
        "file_name": "readconf.c",
        "file_hash": 217124537327695199621061480517955399637,
        "cwe": [
            "CWE-264"
        ],
        "cve": "CVE-2010-4345",
        "cve_desc": "Exim 4.72 and earlier allows local users to gain privileges by leveraging the ability of the exim user account to specify an alternate configuration file with a directive that contains arbitrary commands, as demonstrated by the spool_directory directive.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2010-4345",
        "func_name": "readconf_main",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 200163,
        "project": "linux",
        "commit_id": "817b8b9c5396d2b2d92311b46719aad5d3339dbe",
        "project_url": "https://github.com/torvalds/linux",
        "commit_url": "https://github.com/torvalds/linux/commit/817b8b9c5396d2b2d92311b46719aad5d3339dbe",
        "commit_message": "HID: elo: fix memory leak in elo_probe\n\nWhen hid_parse() in elo_probe() fails, it forgets to call usb_put_dev to\ndecrease the refcount.\n\nFix this by adding usb_put_dev() in the error handling code of elo_probe().\n\nFixes: fbf42729d0e9 (\"HID: elo: update the reference count of the usb device structure\")\nReported-by: syzkaller <syzkaller@googlegroups.com>\nSigned-off-by: Dongliang Mu <mudongliangabcd@gmail.com>\nSigned-off-by: Jiri Kosina <jkosina@suse.cz>",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static int elo_probe(struct hid_device *hdev, const struct hid_device_id *id)\n{\n\tstruct elo_priv *priv;\n\tint ret;\n\tstruct usb_device *udev;\n\n\tif (!hid_is_usb(hdev))\n\t\treturn -EINVAL;\n\n\tpriv = kzalloc(sizeof(*priv), GFP_KERNEL);\n\tif (!priv)\n\t\treturn -ENOMEM;\n\n\tINIT_DELAYED_WORK(&priv->work, elo_work);\n\tudev = interface_to_usbdev(to_usb_interface(hdev->dev.parent));\n\tpriv->usbdev = usb_get_dev(udev);\n\n\thid_set_drvdata(hdev, priv);\n\n\tret = hid_parse(hdev);\n\tif (ret) {\n\t\thid_err(hdev, \"parse failed\\n\");\n\t\tgoto err_free;\n\t}\n\n\tret = hid_hw_start(hdev, HID_CONNECT_DEFAULT);\n\tif (ret) {\n\t\thid_err(hdev, \"hw start failed\\n\");\n\t\tgoto err_free;\n\t}\n\n\tif (elo_broken_firmware(priv->usbdev)) {\n\t\thid_info(hdev, \"broken firmware found, installing workaround\\n\");\n\t\tqueue_delayed_work(wq, &priv->work, ELO_PERIODIC_READ_INTERVAL);\n\t}\n\n\treturn 0;\nerr_free:\n\tkfree(priv);\n\treturn ret;\n}",
        "func_hash": 119771214080354607700352502150468808097,
        "file_name": "hid-elo.c",
        "file_hash": 34235452733984026251117954935462979934,
        "cwe": [
            "CWE-200"
        ],
        "cve": "CVE-2022-27950",
        "cve_desc": "In drivers/hid/hid-elo.c in the Linux kernel before 5.16.11, a memory leak exists for a certain hid_parse error condition.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-27950",
        "func_name": "elo_probe",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195246,
        "project": "gpac",
        "commit_id": "cf6771c857eb9a290e2c19ddacfdd3ed98b27618",
        "project_url": "https://github.com/gpac/gpac",
        "commit_url": "https://github.com/gpac/gpac/commit/cf6771c857eb9a290e2c19ddacfdd3ed98b27618",
        "commit_message": "fixed #1898",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static s32 avc_parse_slice(GF_BitStream *bs, AVCState *avc, Bool svc_idr_flag, AVCSliceInfo *si)\n{\n\ts32 pps_id, num_ref_idx_l0_active_minus1 = 0, num_ref_idx_l1_active_minus1 = 0;\n\n\t/*s->current_picture.reference= h->nal_ref_idc != 0;*/\n\tgf_bs_read_ue_log(bs, \"first_mb_in_slice\");\n\tsi->slice_type = gf_bs_read_ue_log(bs, \"slice_type\");\n\tif (si->slice_type > 9) return -1;\n\n\tpps_id = gf_bs_read_ue_log(bs, \"pps_id\");\n\tif (pps_id > 255) return -1;\n\tsi->pps = &avc->pps[pps_id];\n\tif (!si->pps->slice_group_count) return -2;\n\tsi->sps = &avc->sps[si->pps->sps_id];\n\tif (!si->sps->log2_max_frame_num) return -2;\n\tavc->sps_active_idx = si->pps->sps_id;\n\tavc->pps_active_idx = pps_id;\n\n\tsi->frame_num = gf_bs_read_int_log(bs, si->sps->log2_max_frame_num, \"frame_num\");\n\n\tsi->field_pic_flag = 0;\n\tsi->bottom_field_flag = 0;\n\tif (!si->sps->frame_mbs_only_flag) {\n\t\tsi->field_pic_flag = gf_bs_read_int_log(bs, 1, \"field_pic_flag\");\n\t\tif (si->field_pic_flag)\n\t\t\tsi->bottom_field_flag = gf_bs_read_int_log(bs, 1, \"bottom_field_flag\");\n\t}\n\n\tif ((si->nal_unit_type == GF_AVC_NALU_IDR_SLICE) || svc_idr_flag)\n\t\tsi->idr_pic_id = gf_bs_read_ue_log(bs, \"idr_pic_id\");\n\n\tif (si->sps->poc_type == 0) {\n\t\tsi->poc_lsb = gf_bs_read_int_log(bs, si->sps->log2_max_poc_lsb, \"poc_lsb\");\n\t\tif (si->pps->pic_order_present && !si->field_pic_flag) {\n\t\t\tsi->delta_poc_bottom = gf_bs_read_se_log(bs, \"poc_lsb\");\n\t\t}\n\t}\n\telse if ((si->sps->poc_type == 1) && !si->sps->delta_pic_order_always_zero_flag) {\n\t\tsi->delta_poc[0] = gf_bs_read_se_log(bs, \"delta_poc0\");\n\t\tif ((si->pps->pic_order_present == 1) && !si->field_pic_flag)\n\t\t\tsi->delta_poc[1] = gf_bs_read_se_log(bs, \"delta_poc1\");\n\t}\n\n\tif (si->pps->redundant_pic_cnt_present) {\n\t\tsi->redundant_pic_cnt = gf_bs_read_ue_log(bs, \"redundant_pic_cnt\");\n\t}\n\n\tif (si->slice_type % 5 == GF_AVC_TYPE_B) {\n\t\tgf_bs_read_int_log(bs, 1, \"direct_spatial_mv_pred_flag\");\n\t}\n\n\tnum_ref_idx_l0_active_minus1 = si->pps->num_ref_idx_l0_default_active_minus1;\n\tnum_ref_idx_l1_active_minus1 = si->pps->num_ref_idx_l1_default_active_minus1;\n\n\tif (si->slice_type % 5 == GF_AVC_TYPE_P || si->slice_type % 5 == GF_AVC_TYPE_SP || si->slice_type % 5 == GF_AVC_TYPE_B) {\n\t\tBool num_ref_idx_active_override_flag = gf_bs_read_int_log(bs, 1, \"num_ref_idx_active_override_flag\");\n\t\tif (num_ref_idx_active_override_flag) {\n\t\t\tnum_ref_idx_l0_active_minus1 = gf_bs_read_ue_log(bs, \"num_ref_idx_l0_active_minus1\");\n\t\t\tif (si->slice_type % 5 == GF_AVC_TYPE_B) {\n\t\t\t\tnum_ref_idx_l1_active_minus1 = gf_bs_read_ue_log(bs, \"num_ref_idx_l1_active_minus1\");\n\t\t\t}\n\t\t}\n\t}\n\n\tif (si->nal_unit_type == 20 || si->nal_unit_type == 21) {\n\t\t//ref_pic_list_mvc_modification(); /* specified in Annex H */\n\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CODING, (\"[avc-h264] unimplemented ref_pic_list_mvc_modification() in slide header\\n\"));\n\t\tassert(0);\n\t\treturn -1;\n\t}\n\telse {\n\t\tref_pic_list_modification(bs, si->slice_type);\n\t}\n\n\tif ((si->pps->weighted_pred_flag && (si->slice_type % 5 == GF_AVC_TYPE_P || si->slice_type % 5 == GF_AVC_TYPE_SP))\n\t\t|| (si->pps->weighted_bipred_idc == 1 && si->slice_type % 5 == GF_AVC_TYPE_B)) {\n\t\tpred_weight_table(bs, si->slice_type, si->sps->ChromaArrayType, num_ref_idx_l0_active_minus1, num_ref_idx_l1_active_minus1);\n\t}\n\n\tif (si->nal_ref_idc != 0) {\n\t\tdec_ref_pic_marking(bs, (si->nal_unit_type == GF_AVC_NALU_IDR_SLICE));\n\t}\n\n\tif (si->pps->entropy_coding_mode_flag && si->slice_type % 5 != GF_AVC_TYPE_I && si->slice_type % 5 != GF_AVC_TYPE_SI) {\n\t\tgf_bs_read_ue_log(bs, \"cabac_init_idc\");\n\t}\n\n\t/*slice_qp_delta = */gf_bs_read_se(bs);\n\tif (si->slice_type % 5 == GF_AVC_TYPE_SP || si->slice_type % 5 == GF_AVC_TYPE_SI) {\n\t\tif (si->slice_type % 5 == GF_AVC_TYPE_SP) {\n\t\t\tgf_bs_read_int_log(bs, 1, \"sp_for_switch_flag\");\n\t\t}\n\t\tgf_bs_read_se_log(bs, \"slice_qs_delta\");\n\t}\n\n\tif (si->pps->deblocking_filter_control_present_flag) {\n\t\tif (gf_bs_read_ue_log(bs, \"disable_deblocking_filter_idc\") != 1) {\n\t\t\tgf_bs_read_se_log(bs, \"slice_alpha_c0_offset_div2\");\n\t\t\tgf_bs_read_se_log(bs, \"slice_beta_offset_div2\");\n\t\t}\n\t}\n\n\tif (si->pps->slice_group_count > 1 && si->pps->mb_slice_group_map_type >= 3 && si->pps->mb_slice_group_map_type <= 5) {\n\t\tgf_bs_read_int_log(bs, (u32)ceil(log1p((si->pps->pic_size_in_map_units_minus1 + 1) / (si->pps->slice_group_change_rate_minus1 + 1) ) / log(2)), \"slice_group_change_cycle\");\n\t}\n\treturn 0;\n}",
        "func_hash": 250322460567095926906340260446333370263,
        "file_name": "av_parsers.c",
        "file_hash": 168517587328341017594269375399465893964,
        "cwe": [
            "CWE-476"
        ],
        "cve": "CVE-2021-40564",
        "cve_desc": "A Segmentation fault caused by null pointer dereference vulnerability eists in Gpac through 1.0.2 via the avc_parse_slice function in av_parsers.c when using mp4box, which causes a denial of service.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-40564",
        "func_name": "avc_parse_slice",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195261,
        "project": "tensorflow",
        "commit_id": "955059813cc325dc1db5e2daa6221271406d4439",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/955059813cc325dc1db5e2daa6221271406d4439",
        "commit_message": "Check for type inference error on node construction.\n\nPiperOrigin-RevId: 409415804\nChange-Id: Ieb6e020906b96f522bf8e2fa103715ddbbdc434a",
        "target": 1,
        "irrelevant": 0,
        "func_before": "Node* Graph::AddNode(NodeDef node_def, Status* status) {\n  const OpRegistrationData* op_reg_data;\n  status->Update(ops_.LookUp(node_def.op(), &op_reg_data));\n  if (!status->ok()) return nullptr;\n\n  DataTypeVector inputs;\n  DataTypeVector outputs;\n  status->Update(\n      InOutTypesForNode(node_def, op_reg_data->op_def, &inputs, &outputs));\n  if (!status->ok()) {\n    *status = AttachDef(*status, node_def);\n    return nullptr;\n  }\n\n  Node::NodeClass node_class = op_reg_data->is_function_op\n                                   ? Node::NC_FUNCTION_OP\n                                   : Node::GetNodeClassForOp(node_def.op());\n\n  if (op_reg_data->type_ctor != nullptr) {\n    VLOG(3) << \"AddNode: found type constructor for \" << node_def.name();\n    const auto ctor_type =\n        full_type::SpecializeType(AttrSlice(node_def), op_reg_data->op_def);\n    const FullTypeDef ctor_typedef = ctor_type.ValueOrDie();\n    if (ctor_typedef.type_id() != TFT_UNSET) {\n      *(node_def.mutable_experimental_type()) = ctor_typedef;\n    }\n  } else {\n    VLOG(3) << \"AddNode: no type constructor for \" << node_def.name();\n  }\n\n  Node* node = AllocateNode(std::make_shared<NodeProperties>(\n                                &op_reg_data->op_def, std::move(node_def),\n                                inputs, outputs, op_reg_data->fwd_type_fn),\n                            nullptr, node_class);\n  return node;\n}",
        "func_hash": 216608112162338080739127582529653382623,
        "file_name": "graph.cc",
        "file_hash": 171004513035817799651733534811388619872,
        "cwe": [
            "CWE-754"
        ],
        "cve": "CVE-2022-23590",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. A `GraphDef` from a TensorFlow `SavedModel` can be maliciously altered to cause a TensorFlow process to crash due to encountering a `StatusOr` value that is an error and forcibly extracting the value from it. We have patched the issue in multiple GitHub commits and these will be included in TensorFlow 2.8.0 and TensorFlow 2.7.1, as both are affected.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23590",
        "func_name": "Graph::AddNode",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195264,
        "project": "pcre2",
        "commit_id": "d4fa336fbcc388f89095b184ba6d99422cfc676c",
        "project_url": "https://github.com/PCRE2Project/pcre2",
        "commit_url": "https://github.com/PCRE2Project/pcre2/commit/d4fa336fbcc388f89095b184ba6d99422cfc676c",
        "commit_message": "Fix incorrect value reading in JIT.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static void compile_xclass_matchingpath(compiler_common *common, PCRE2_SPTR cc, jump_list **backtracks)\n{\nDEFINE_COMPILER;\njump_list *found = NULL;\njump_list **list = (cc[0] & XCL_NOT) == 0 ? &found : backtracks;\nsljit_uw c, charoffset, max = 256, min = READ_CHAR_MAX;\nstruct sljit_jump *jump = NULL;\nPCRE2_SPTR ccbegin;\nint compares, invertcmp, numberofcmps;\n#if defined SUPPORT_UNICODE && (PCRE2_CODE_UNIT_WIDTH == 8 || PCRE2_CODE_UNIT_WIDTH == 16)\nBOOL utf = common->utf;\n#endif /* SUPPORT_UNICODE && PCRE2_CODE_UNIT_WIDTH == [8|16] */\n\n#ifdef SUPPORT_UNICODE\nsljit_u32 unicode_status = 0;\nint typereg = TMP1;\nconst sljit_u32 *other_cases;\nsljit_uw typeoffset;\n#endif /* SUPPORT_UNICODE */\n\n/* Scanning the necessary info. */\ncc++;\nccbegin = cc;\ncompares = 0;\n\nif (cc[-1] & XCL_MAP)\n  {\n  min = 0;\n  cc += 32 / sizeof(PCRE2_UCHAR);\n  }\n\nwhile (*cc != XCL_END)\n  {\n  compares++;\n  if (*cc == XCL_SINGLE)\n    {\n    cc ++;\n    GETCHARINCTEST(c, cc);\n    if (c > max) max = c;\n    if (c < min) min = c;\n#ifdef SUPPORT_UNICODE\n    unicode_status |= XCLASS_SAVE_CHAR;\n#endif /* SUPPORT_UNICODE */\n    }\n  else if (*cc == XCL_RANGE)\n    {\n    cc ++;\n    GETCHARINCTEST(c, cc);\n    if (c < min) min = c;\n    GETCHARINCTEST(c, cc);\n    if (c > max) max = c;\n#ifdef SUPPORT_UNICODE\n    unicode_status |= XCLASS_SAVE_CHAR;\n#endif /* SUPPORT_UNICODE */\n    }\n#ifdef SUPPORT_UNICODE\n  else\n    {\n    SLJIT_ASSERT(*cc == XCL_PROP || *cc == XCL_NOTPROP);\n    cc++;\n    if (*cc == PT_CLIST && *cc == XCL_PROP)\n      {\n      other_cases = PRIV(ucd_caseless_sets) + cc[1];\n      while (*other_cases != NOTACHAR)\n        {\n        if (*other_cases > max) max = *other_cases;\n        if (*other_cases < min) min = *other_cases;\n        other_cases++;\n        }\n      }\n    else\n      {\n      max = READ_CHAR_MAX;\n      min = 0;\n      }\n\n    switch(*cc)\n      {\n      case PT_ANY:\n      /* Any either accepts everything or ignored. */\n      if (cc[-1] == XCL_PROP)\n        {\n        compile_char1_matchingpath(common, OP_ALLANY, cc, backtracks, FALSE);\n        if (list == backtracks)\n          add_jump(compiler, backtracks, JUMP(SLJIT_JUMP));\n        return;\n        }\n      break;\n\n      case PT_LAMP:\n      case PT_GC:\n      case PT_PC:\n      case PT_ALNUM:\n      unicode_status |= XCLASS_HAS_TYPE;\n      break;\n\n      case PT_SCX:\n      unicode_status |= XCLASS_HAS_SCRIPT_EXTENSION;\n      if (cc[-1] == XCL_NOTPROP)\n        {\n        unicode_status |= XCLASS_SCRIPT_EXTENSION_NOTPROP;\n        break;\n        }\n      compares++;\n      /* Fall through */ \n\n      case PT_SC:\n      unicode_status |= XCLASS_HAS_SCRIPT;\n      break;\n\n      case PT_SPACE:\n      case PT_PXSPACE:\n      case PT_WORD:\n      case PT_PXGRAPH:\n      case PT_PXPRINT:\n      case PT_PXPUNCT:\n      unicode_status |= XCLASS_SAVE_CHAR | XCLASS_HAS_TYPE;\n      break;\n\n      case PT_CLIST:\n      case PT_UCNC:\n      unicode_status |= XCLASS_SAVE_CHAR;\n      break;\n\n      case PT_BOOL:\n      unicode_status |= XCLASS_HAS_BOOL;\n      break;\n\n      case PT_BIDICL:\n      unicode_status |= XCLASS_HAS_BIDICL;\n      break;\n\n      default:\n      SLJIT_UNREACHABLE();\n      break;\n      }\n    cc += 2;\n    }\n#endif /* SUPPORT_UNICODE */\n  }\nSLJIT_ASSERT(compares > 0);\n\n/* We are not necessary in utf mode even in 8 bit mode. */\ncc = ccbegin;\nif ((cc[-1] & XCL_NOT) != 0)\n  read_char(common, min, max, backtracks, READ_CHAR_UPDATE_STR_PTR);\nelse\n  {\n#ifdef SUPPORT_UNICODE\n  read_char(common, min, max, (unicode_status & XCLASS_NEEDS_UCD) ? backtracks : NULL, 0);\n#else /* !SUPPORT_UNICODE */\n  read_char(common, min, max, NULL, 0);\n#endif /* SUPPORT_UNICODE */\n  }\n\nif ((cc[-1] & XCL_HASPROP) == 0)\n  {\n  if ((cc[-1] & XCL_MAP) != 0)\n    {\n    jump = CMP(SLJIT_GREATER, TMP1, 0, SLJIT_IMM, 255);\n    if (!optimize_class(common, (const sljit_u8 *)cc, (((const sljit_u8 *)cc)[31] & 0x80) != 0, TRUE, &found))\n      {\n      OP2(SLJIT_AND, TMP2, 0, TMP1, 0, SLJIT_IMM, 0x7);\n      OP2(SLJIT_LSHR, TMP1, 0, TMP1, 0, SLJIT_IMM, 3);\n      OP1(SLJIT_MOV_U8, TMP1, 0, SLJIT_MEM1(TMP1), (sljit_sw)cc);\n      OP2(SLJIT_SHL, TMP2, 0, SLJIT_IMM, 1, TMP2, 0);\n      OP2U(SLJIT_AND | SLJIT_SET_Z, TMP1, 0, TMP2, 0);\n      add_jump(compiler, &found, JUMP(SLJIT_NOT_ZERO));\n      }\n\n    add_jump(compiler, backtracks, JUMP(SLJIT_JUMP));\n    JUMPHERE(jump);\n\n    cc += 32 / sizeof(PCRE2_UCHAR);\n    }\n  else\n    {\n    OP2(SLJIT_SUB, TMP2, 0, TMP1, 0, SLJIT_IMM, min);\n    add_jump(compiler, (cc[-1] & XCL_NOT) == 0 ? backtracks : &found, CMP(SLJIT_GREATER, TMP2, 0, SLJIT_IMM, max - min));\n    }\n  }\nelse if ((cc[-1] & XCL_MAP) != 0)\n  {\n  OP1(SLJIT_MOV, RETURN_ADDR, 0, TMP1, 0);\n#ifdef SUPPORT_UNICODE\n  unicode_status |= XCLASS_CHAR_SAVED;\n#endif /* SUPPORT_UNICODE */\n  if (!optimize_class(common, (const sljit_u8 *)cc, FALSE, TRUE, list))\n    {\n#if PCRE2_CODE_UNIT_WIDTH == 8\n    jump = NULL;\n    if (common->utf)\n#endif /* PCRE2_CODE_UNIT_WIDTH == 8 */\n      jump = CMP(SLJIT_GREATER, TMP1, 0, SLJIT_IMM, 255);\n\n    OP2(SLJIT_AND, TMP2, 0, TMP1, 0, SLJIT_IMM, 0x7);\n    OP2(SLJIT_LSHR, TMP1, 0, TMP1, 0, SLJIT_IMM, 3);\n    OP1(SLJIT_MOV_U8, TMP1, 0, SLJIT_MEM1(TMP1), (sljit_sw)cc);\n    OP2(SLJIT_SHL, TMP2, 0, SLJIT_IMM, 1, TMP2, 0);\n    OP2U(SLJIT_AND | SLJIT_SET_Z, TMP1, 0, TMP2, 0);\n    add_jump(compiler, list, JUMP(SLJIT_NOT_ZERO));\n\n#if PCRE2_CODE_UNIT_WIDTH == 8\n    if (common->utf)\n#endif /* PCRE2_CODE_UNIT_WIDTH == 8 */\n      JUMPHERE(jump);\n    }\n\n  OP1(SLJIT_MOV, TMP1, 0, RETURN_ADDR, 0);\n  cc += 32 / sizeof(PCRE2_UCHAR);\n  }\n\n#ifdef SUPPORT_UNICODE\nif (unicode_status & XCLASS_NEEDS_UCD)\n  {\n  if ((unicode_status & (XCLASS_SAVE_CHAR | XCLASS_CHAR_SAVED)) == XCLASS_SAVE_CHAR)\n    OP1(SLJIT_MOV, RETURN_ADDR, 0, TMP1, 0);\n\n#if PCRE2_CODE_UNIT_WIDTH == 32\n  if (!common->utf)\n    {\n    jump = CMP(SLJIT_LESS, TMP1, 0, SLJIT_IMM, MAX_UTF_CODE_POINT + 1);\n    OP1(SLJIT_MOV, TMP1, 0, SLJIT_IMM, UNASSIGNED_UTF_CHAR);\n    JUMPHERE(jump);\n    }\n#endif /* PCRE2_CODE_UNIT_WIDTH == 32 */\n\n  OP2(SLJIT_LSHR, TMP2, 0, TMP1, 0, SLJIT_IMM, UCD_BLOCK_SHIFT);\n  OP2(SLJIT_SHL, TMP2, 0, TMP2, 0, SLJIT_IMM, 1);\n  OP1(SLJIT_MOV_U16, TMP2, 0, SLJIT_MEM1(TMP2), (sljit_sw)PRIV(ucd_stage1));\n  OP2(SLJIT_AND, TMP1, 0, TMP1, 0, SLJIT_IMM, UCD_BLOCK_MASK);\n  OP2(SLJIT_SHL, TMP2, 0, TMP2, 0, SLJIT_IMM, UCD_BLOCK_SHIFT);\n  OP2(SLJIT_ADD, TMP1, 0, TMP1, 0, TMP2, 0);\n  OP1(SLJIT_MOV, TMP2, 0, SLJIT_IMM, (sljit_sw)PRIV(ucd_stage2));\n  OP1(SLJIT_MOV_U16, TMP2, 0, SLJIT_MEM2(TMP2, TMP1), 1);\n  OP2(SLJIT_SHL, TMP1, 0, TMP2, 0, SLJIT_IMM, 3);\n  OP2(SLJIT_SHL, TMP2, 0, TMP2, 0, SLJIT_IMM, 2);\n  OP2(SLJIT_ADD, TMP2, 0, TMP2, 0, TMP1, 0);\n\n  ccbegin = cc;\n\n  if (unicode_status & XCLASS_HAS_BIDICL)\n    {\n    OP1(SLJIT_MOV_U16, TMP1, 0, SLJIT_MEM1(TMP2), (sljit_sw)PRIV(ucd_records) + SLJIT_OFFSETOF(ucd_record, scriptx_bidiclass));\n    OP2(SLJIT_LSHR, TMP1, 0, TMP1, 0, SLJIT_IMM, UCD_BIDICLASS_SHIFT);\n\n    while (*cc != XCL_END)\n      {\n      if (*cc == XCL_SINGLE)\n        {\n        cc ++;\n        GETCHARINCTEST(c, cc);\n        }\n      else if (*cc == XCL_RANGE)\n        {\n        cc ++;\n        GETCHARINCTEST(c, cc);\n        GETCHARINCTEST(c, cc);\n        }\n      else\n        {\n        SLJIT_ASSERT(*cc == XCL_PROP || *cc == XCL_NOTPROP);\n        cc++;\n        if (*cc == PT_BIDICL)\n          {\n          compares--;\n          invertcmp = (compares == 0 && list != backtracks);\n          if (cc[-1] == XCL_NOTPROP)\n            invertcmp ^= 0x1;\n          jump = CMP(SLJIT_EQUAL ^ invertcmp, TMP1, 0, SLJIT_IMM, (int)cc[1]);\n          add_jump(compiler, compares > 0 ? list : backtracks, jump);\n          }\n        cc += 2;\n        }\n      }\n\n    cc = ccbegin;\n    }\n\n  if (unicode_status & XCLASS_HAS_BOOL)\n    {\n    OP1(SLJIT_MOV_U16, TMP1, 0, SLJIT_MEM1(TMP2), (sljit_sw)PRIV(ucd_records) + SLJIT_OFFSETOF(ucd_record, bprops));\n    OP2(SLJIT_AND, TMP1, 0, TMP1, 0, SLJIT_IMM, UCD_BPROPS_MASK);\n    OP2(SLJIT_SHL, TMP1, 0, TMP1, 0, SLJIT_IMM, 2);\n\n    while (*cc != XCL_END)\n      {\n      if (*cc == XCL_SINGLE)\n        {\n        cc ++;\n        GETCHARINCTEST(c, cc);\n        }\n      else if (*cc == XCL_RANGE)\n        {\n        cc ++;\n        GETCHARINCTEST(c, cc);\n        GETCHARINCTEST(c, cc);\n        }\n      else\n        {\n        SLJIT_ASSERT(*cc == XCL_PROP || *cc == XCL_NOTPROP);\n        cc++;\n        if (*cc == PT_BOOL)\n          {\n          compares--;\n          invertcmp = (compares == 0 && list != backtracks);\n          if (cc[-1] == XCL_NOTPROP)\n            invertcmp ^= 0x1;\n\n          OP2U(SLJIT_AND32 | SLJIT_SET_Z, SLJIT_MEM1(TMP1), (sljit_sw)(PRIV(ucd_boolprop_sets) + (cc[1] >> 5)), SLJIT_IMM, (sljit_sw)1 << (cc[1] & 0x1f));\n          add_jump(compiler, compares > 0 ? list : backtracks, JUMP(SLJIT_NOT_ZERO ^ invertcmp));\n          }\n        cc += 2;\n        }\n      }\n\n    cc = ccbegin;\n    }\n\n  if (unicode_status & XCLASS_HAS_SCRIPT)\n    {\n    OP1(SLJIT_MOV_U8, TMP1, 0, SLJIT_MEM1(TMP2), (sljit_sw)PRIV(ucd_records) + SLJIT_OFFSETOF(ucd_record, script));\n\n    while (*cc != XCL_END)\n      {\n      if (*cc == XCL_SINGLE)\n        {\n        cc ++;\n        GETCHARINCTEST(c, cc);\n        }\n      else if (*cc == XCL_RANGE)\n        {\n        cc ++;\n        GETCHARINCTEST(c, cc);\n        GETCHARINCTEST(c, cc);\n        }\n      else\n        {\n        SLJIT_ASSERT(*cc == XCL_PROP || *cc == XCL_NOTPROP);\n        cc++;\n        switch (*cc)\n          {\n          case PT_SCX:\n          if (cc[-1] == XCL_NOTPROP)\n            break;\n          /* Fall through */ \n\n          case PT_SC:\n          compares--;\n          invertcmp = (compares == 0 && list != backtracks);\n          if (cc[-1] == XCL_NOTPROP)\n            invertcmp ^= 0x1;\n\n          add_jump(compiler, compares > 0 ? list : backtracks, CMP(SLJIT_EQUAL ^ invertcmp, TMP1, 0, SLJIT_IMM, (int)cc[1]));\n          }\n        cc += 2;\n        }\n      }\n\n    cc = ccbegin;\n    }\n\n  if (unicode_status & XCLASS_HAS_SCRIPT_EXTENSION)\n    {\n    OP1(SLJIT_MOV_U16, TMP1, 0, SLJIT_MEM1(TMP2), (sljit_sw)PRIV(ucd_records) + SLJIT_OFFSETOF(ucd_record, scriptx_bidiclass));\n    OP2(SLJIT_AND, TMP1, 0, TMP1, 0, SLJIT_IMM, UCD_SCRIPTX_MASK);\n    OP2(SLJIT_SHL, TMP1, 0, TMP1, 0, SLJIT_IMM, 2);\n\n    if (unicode_status & XCLASS_SCRIPT_EXTENSION_NOTPROP)\n      {\n      if (unicode_status & XCLASS_HAS_TYPE)\n        {\n        if (unicode_status & XCLASS_SAVE_CHAR)\n          {\n          OP1(SLJIT_MOV, SLJIT_MEM1(SLJIT_SP), LOCALS0, TMP2, 0);\n          unicode_status |= XCLASS_SCRIPT_EXTENSION_RESTORE_LOCALS0;\n          }\n        else\n          {\n          OP1(SLJIT_MOV, RETURN_ADDR, 0, TMP2, 0);\n          unicode_status |= XCLASS_SCRIPT_EXTENSION_RESTORE_RETURN_ADDR;\n          }\n        }\n      OP1(SLJIT_MOV_U8, TMP2, 0, SLJIT_MEM1(TMP2), (sljit_sw)PRIV(ucd_records) + SLJIT_OFFSETOF(ucd_record, script));\n      }\n\n    while (*cc != XCL_END)\n      {\n      if (*cc == XCL_SINGLE)\n        {\n        cc ++;\n        GETCHARINCTEST(c, cc);\n        }\n      else if (*cc == XCL_RANGE)\n        {\n        cc ++;\n        GETCHARINCTEST(c, cc);\n        GETCHARINCTEST(c, cc);\n        }\n      else\n        {\n        SLJIT_ASSERT(*cc == XCL_PROP || *cc == XCL_NOTPROP);\n        cc++;\n        if (*cc == PT_SCX)\n          {\n          compares--;\n          invertcmp = (compares == 0 && list != backtracks);\n\n          jump = NULL;\n          if (cc[-1] == XCL_NOTPROP)\n            {\n            jump = CMP(SLJIT_EQUAL, TMP2, 0, SLJIT_IMM, (int)cc[1]);\n            if (invertcmp)\n              {\n              add_jump(compiler, backtracks, jump);\n              jump = NULL;\n              }\n            invertcmp ^= 0x1;\n            }\n\n          OP2U(SLJIT_AND32 | SLJIT_SET_Z, SLJIT_MEM1(TMP1), (sljit_sw)(PRIV(ucd_script_sets) + (cc[1] >> 5)), SLJIT_IMM, (sljit_sw)1 << (cc[1] & 0x1f));\n          add_jump(compiler, compares > 0 ? list : backtracks, JUMP(SLJIT_NOT_ZERO ^ invertcmp));\n\n          if (jump != NULL)\n            JUMPHERE(jump);\n          }\n        cc += 2;\n        }\n      }\n\n    if (unicode_status & XCLASS_SCRIPT_EXTENSION_RESTORE_LOCALS0)\n      OP1(SLJIT_MOV, TMP2, 0, SLJIT_MEM1(SLJIT_SP), LOCALS0);\n    else if (unicode_status & XCLASS_SCRIPT_EXTENSION_RESTORE_RETURN_ADDR)\n      OP1(SLJIT_MOV, TMP2, 0, RETURN_ADDR, 0);\n    cc = ccbegin;\n    }\n\n  if (unicode_status & XCLASS_SAVE_CHAR)\n    OP1(SLJIT_MOV, TMP1, 0, RETURN_ADDR, 0);\n\n  if (unicode_status & XCLASS_HAS_TYPE)\n    {\n    if (unicode_status & XCLASS_SAVE_CHAR)\n      typereg = RETURN_ADDR;\n\n    OP1(SLJIT_MOV_U8, typereg, 0, SLJIT_MEM1(TMP2), (sljit_sw)PRIV(ucd_records) + SLJIT_OFFSETOF(ucd_record, chartype));\n    }\n  }\n#endif /* SUPPORT_UNICODE */\n\n/* Generating code. */\ncharoffset = 0;\nnumberofcmps = 0;\n#ifdef SUPPORT_UNICODE\ntypeoffset = 0;\n#endif /* SUPPORT_UNICODE */\n\nwhile (*cc != XCL_END)\n  {\n  compares--;\n  invertcmp = (compares == 0 && list != backtracks);\n  jump = NULL;\n\n  if (*cc == XCL_SINGLE)\n    {\n    cc ++;\n    GETCHARINCTEST(c, cc);\n\n    if (numberofcmps < 3 && (*cc == XCL_SINGLE || *cc == XCL_RANGE))\n      {\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP1, 0, SLJIT_IMM, (sljit_sw)(c - charoffset));\n      OP_FLAGS(numberofcmps == 0 ? SLJIT_MOV : SLJIT_OR, TMP2, 0, SLJIT_EQUAL);\n      numberofcmps++;\n      }\n    else if (numberofcmps > 0)\n      {\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP1, 0, SLJIT_IMM, (sljit_sw)(c - charoffset));\n      OP_FLAGS(SLJIT_OR | SLJIT_SET_Z, TMP2, 0, SLJIT_EQUAL);\n      jump = JUMP(SLJIT_NOT_ZERO ^ invertcmp);\n      numberofcmps = 0;\n      }\n    else\n      {\n      jump = CMP(SLJIT_EQUAL ^ invertcmp, TMP1, 0, SLJIT_IMM, (sljit_sw)(c - charoffset));\n      numberofcmps = 0;\n      }\n    }\n  else if (*cc == XCL_RANGE)\n    {\n    cc ++;\n    GETCHARINCTEST(c, cc);\n    SET_CHAR_OFFSET(c);\n    GETCHARINCTEST(c, cc);\n\n    if (numberofcmps < 3 && (*cc == XCL_SINGLE || *cc == XCL_RANGE))\n      {\n      OP2U(SLJIT_SUB | SLJIT_SET_LESS_EQUAL, TMP1, 0, SLJIT_IMM, (sljit_sw)(c - charoffset));\n      OP_FLAGS(numberofcmps == 0 ? SLJIT_MOV : SLJIT_OR, TMP2, 0, SLJIT_LESS_EQUAL);\n      numberofcmps++;\n      }\n    else if (numberofcmps > 0)\n      {\n      OP2U(SLJIT_SUB | SLJIT_SET_LESS_EQUAL, TMP1, 0, SLJIT_IMM, (sljit_sw)(c - charoffset));\n      OP_FLAGS(SLJIT_OR | SLJIT_SET_Z, TMP2, 0, SLJIT_LESS_EQUAL);\n      jump = JUMP(SLJIT_NOT_ZERO ^ invertcmp);\n      numberofcmps = 0;\n      }\n    else\n      {\n      jump = CMP(SLJIT_LESS_EQUAL ^ invertcmp, TMP1, 0, SLJIT_IMM, (sljit_sw)(c - charoffset));\n      numberofcmps = 0;\n      }\n    }\n#ifdef SUPPORT_UNICODE\n  else\n    {\n    SLJIT_ASSERT(*cc == XCL_PROP || *cc == XCL_NOTPROP);\n    if (*cc == XCL_NOTPROP)\n      invertcmp ^= 0x1;\n    cc++;\n    switch(*cc)\n      {\n      case PT_ANY:\n      if (!invertcmp)\n        jump = JUMP(SLJIT_JUMP);\n      break;\n\n      case PT_LAMP:\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, typereg, 0, SLJIT_IMM, ucp_Lu - typeoffset);\n      OP_FLAGS(SLJIT_MOV, TMP2, 0, SLJIT_EQUAL);\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, typereg, 0, SLJIT_IMM, ucp_Ll - typeoffset);\n      OP_FLAGS(SLJIT_OR, TMP2, 0, SLJIT_EQUAL);\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, typereg, 0, SLJIT_IMM, ucp_Lt - typeoffset);\n      OP_FLAGS(SLJIT_OR | SLJIT_SET_Z, TMP2, 0, SLJIT_EQUAL);\n      jump = JUMP(SLJIT_NOT_ZERO ^ invertcmp);\n      break;\n\n      case PT_GC:\n      c = PRIV(ucp_typerange)[(int)cc[1] * 2];\n      SET_TYPE_OFFSET(c);\n      jump = CMP(SLJIT_LESS_EQUAL ^ invertcmp, typereg, 0, SLJIT_IMM, PRIV(ucp_typerange)[(int)cc[1] * 2 + 1] - c);\n      break;\n\n      case PT_PC:\n      jump = CMP(SLJIT_EQUAL ^ invertcmp, typereg, 0, SLJIT_IMM, (int)cc[1] - typeoffset);\n      break;\n\n      case PT_SC:\n      case PT_SCX:\n      case PT_BOOL:\n      case PT_BIDICL:\n      compares++;\n      /* Do nothing. */\n      break;\n\n      case PT_SPACE:\n      case PT_PXSPACE:\n      SET_CHAR_OFFSET(9);\n      OP2U(SLJIT_SUB | SLJIT_SET_LESS_EQUAL, TMP1, 0, SLJIT_IMM, 0xd - 0x9);\n      OP_FLAGS(SLJIT_MOV, TMP2, 0, SLJIT_LESS_EQUAL);\n\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP1, 0, SLJIT_IMM, 0x85 - 0x9);\n      OP_FLAGS(SLJIT_OR, TMP2, 0, SLJIT_EQUAL);\n\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP1, 0, SLJIT_IMM, 0x180e - 0x9);\n      OP_FLAGS(SLJIT_OR, TMP2, 0, SLJIT_EQUAL);\n\n      SET_TYPE_OFFSET(ucp_Zl);\n      OP2U(SLJIT_SUB | SLJIT_SET_LESS_EQUAL, typereg, 0, SLJIT_IMM, ucp_Zs - ucp_Zl);\n      OP_FLAGS(SLJIT_OR | SLJIT_SET_Z, TMP2, 0, SLJIT_LESS_EQUAL);\n      jump = JUMP(SLJIT_NOT_ZERO ^ invertcmp);\n      break;\n\n      case PT_WORD:\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP1, 0, SLJIT_IMM, (sljit_sw)(CHAR_UNDERSCORE - charoffset));\n      OP_FLAGS(SLJIT_MOV, TMP2, 0, SLJIT_EQUAL);\n      /* Fall through. */\n\n      case PT_ALNUM:\n      SET_TYPE_OFFSET(ucp_Ll);\n      OP2U(SLJIT_SUB | SLJIT_SET_LESS_EQUAL, typereg, 0, SLJIT_IMM, ucp_Lu - ucp_Ll);\n      OP_FLAGS((*cc == PT_ALNUM) ? SLJIT_MOV : SLJIT_OR, TMP2, 0, SLJIT_LESS_EQUAL);\n      SET_TYPE_OFFSET(ucp_Nd);\n      OP2U(SLJIT_SUB | SLJIT_SET_LESS_EQUAL, typereg, 0, SLJIT_IMM, ucp_No - ucp_Nd);\n      OP_FLAGS(SLJIT_OR | SLJIT_SET_Z, TMP2, 0, SLJIT_LESS_EQUAL);\n      jump = JUMP(SLJIT_NOT_ZERO ^ invertcmp);\n      break;\n\n      case PT_CLIST:\n      other_cases = PRIV(ucd_caseless_sets) + cc[1];\n\n      /* At least three characters are required.\n         Otherwise this case would be handled by the normal code path. */\n      SLJIT_ASSERT(other_cases[0] != NOTACHAR && other_cases[1] != NOTACHAR && other_cases[2] != NOTACHAR);\n      SLJIT_ASSERT(other_cases[0] < other_cases[1] && other_cases[1] < other_cases[2]);\n\n      /* Optimizing character pairs, if their difference is power of 2. */\n      if (is_powerof2(other_cases[1] ^ other_cases[0]))\n        {\n        if (charoffset == 0)\n          OP2(SLJIT_OR, TMP2, 0, TMP1, 0, SLJIT_IMM, other_cases[1] ^ other_cases[0]);\n        else\n          {\n          OP2(SLJIT_ADD, TMP2, 0, TMP1, 0, SLJIT_IMM, (sljit_sw)charoffset);\n          OP2(SLJIT_OR, TMP2, 0, TMP2, 0, SLJIT_IMM, other_cases[1] ^ other_cases[0]);\n          }\n        OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP2, 0, SLJIT_IMM, other_cases[1]);\n        OP_FLAGS(SLJIT_MOV, TMP2, 0, SLJIT_EQUAL);\n        other_cases += 2;\n        }\n      else if (is_powerof2(other_cases[2] ^ other_cases[1]))\n        {\n        if (charoffset == 0)\n          OP2(SLJIT_OR, TMP2, 0, TMP1, 0, SLJIT_IMM, other_cases[2] ^ other_cases[1]);\n        else\n          {\n          OP2(SLJIT_ADD, TMP2, 0, TMP1, 0, SLJIT_IMM, (sljit_sw)charoffset);\n          OP2(SLJIT_OR, TMP2, 0, TMP2, 0, SLJIT_IMM, other_cases[1] ^ other_cases[0]);\n          }\n        OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP2, 0, SLJIT_IMM, other_cases[2]);\n        OP_FLAGS(SLJIT_MOV, TMP2, 0, SLJIT_EQUAL);\n\n        OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP1, 0, SLJIT_IMM, (sljit_sw)(other_cases[0] - charoffset));\n        OP_FLAGS(SLJIT_OR | ((other_cases[3] == NOTACHAR) ? SLJIT_SET_Z : 0), TMP2, 0, SLJIT_EQUAL);\n\n        other_cases += 3;\n        }\n      else\n        {\n        OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP1, 0, SLJIT_IMM, (sljit_sw)(*other_cases++ - charoffset));\n        OP_FLAGS(SLJIT_MOV, TMP2, 0, SLJIT_EQUAL);\n        }\n\n      while (*other_cases != NOTACHAR)\n        {\n        OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP1, 0, SLJIT_IMM, (sljit_sw)(*other_cases++ - charoffset));\n        OP_FLAGS(SLJIT_OR | ((*other_cases == NOTACHAR) ? SLJIT_SET_Z : 0), TMP2, 0, SLJIT_EQUAL);\n        }\n      jump = JUMP(SLJIT_NOT_ZERO ^ invertcmp);\n      break;\n\n      case PT_UCNC:\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP1, 0, SLJIT_IMM, (sljit_sw)(CHAR_DOLLAR_SIGN - charoffset));\n      OP_FLAGS(SLJIT_MOV, TMP2, 0, SLJIT_EQUAL);\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP1, 0, SLJIT_IMM, (sljit_sw)(CHAR_COMMERCIAL_AT - charoffset));\n      OP_FLAGS(SLJIT_OR, TMP2, 0, SLJIT_EQUAL);\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP1, 0, SLJIT_IMM, (sljit_sw)(CHAR_GRAVE_ACCENT - charoffset));\n      OP_FLAGS(SLJIT_OR, TMP2, 0, SLJIT_EQUAL);\n\n      SET_CHAR_OFFSET(0xa0);\n      OP2U(SLJIT_SUB | SLJIT_SET_LESS_EQUAL, TMP1, 0, SLJIT_IMM, (sljit_sw)(0xd7ff - charoffset));\n      OP_FLAGS(SLJIT_OR, TMP2, 0, SLJIT_LESS_EQUAL);\n      SET_CHAR_OFFSET(0);\n      OP2U(SLJIT_SUB | SLJIT_SET_GREATER_EQUAL, TMP1, 0, SLJIT_IMM, 0xe000 - 0);\n      OP_FLAGS(SLJIT_OR | SLJIT_SET_Z, TMP2, 0, SLJIT_GREATER_EQUAL);\n      jump = JUMP(SLJIT_NOT_ZERO ^ invertcmp);\n      break;\n\n      case PT_PXGRAPH:\n      /* C and Z groups are the farthest two groups. */\n      SET_TYPE_OFFSET(ucp_Ll);\n      OP2U(SLJIT_SUB | SLJIT_SET_GREATER, typereg, 0, SLJIT_IMM, ucp_So - ucp_Ll);\n      OP_FLAGS(SLJIT_MOV, TMP2, 0, SLJIT_GREATER);\n\n      jump = CMP(SLJIT_NOT_EQUAL, typereg, 0, SLJIT_IMM, ucp_Cf - ucp_Ll);\n\n      /* In case of ucp_Cf, we overwrite the result. */\n      SET_CHAR_OFFSET(0x2066);\n      OP2U(SLJIT_SUB | SLJIT_SET_LESS_EQUAL, TMP1, 0, SLJIT_IMM, 0x2069 - 0x2066);\n      OP_FLAGS(SLJIT_MOV, TMP2, 0, SLJIT_LESS_EQUAL);\n\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP1, 0, SLJIT_IMM, 0x061c - 0x2066);\n      OP_FLAGS(SLJIT_OR, TMP2, 0, SLJIT_EQUAL);\n\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP1, 0, SLJIT_IMM, 0x180e - 0x2066);\n      OP_FLAGS(SLJIT_OR, TMP2, 0, SLJIT_EQUAL);\n\n      JUMPHERE(jump);\n      jump = CMP(SLJIT_ZERO ^ invertcmp, TMP2, 0, SLJIT_IMM, 0);\n      break;\n\n      case PT_PXPRINT:\n      /* C and Z groups are the farthest two groups. */\n      SET_TYPE_OFFSET(ucp_Ll);\n      OP2U(SLJIT_SUB | SLJIT_SET_GREATER, typereg, 0, SLJIT_IMM, ucp_So - ucp_Ll);\n      OP_FLAGS(SLJIT_MOV, TMP2, 0, SLJIT_GREATER);\n\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, typereg, 0, SLJIT_IMM, ucp_Zs - ucp_Ll);\n      OP_FLAGS(SLJIT_AND, TMP2, 0, SLJIT_NOT_EQUAL);\n\n      jump = CMP(SLJIT_NOT_EQUAL, typereg, 0, SLJIT_IMM, ucp_Cf - ucp_Ll);\n\n      /* In case of ucp_Cf, we overwrite the result. */\n      SET_CHAR_OFFSET(0x2066);\n      OP2U(SLJIT_SUB | SLJIT_SET_LESS_EQUAL, TMP1, 0, SLJIT_IMM, 0x2069 - 0x2066);\n      OP_FLAGS(SLJIT_MOV, TMP2, 0, SLJIT_LESS_EQUAL);\n\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP1, 0, SLJIT_IMM, 0x061c - 0x2066);\n      OP_FLAGS(SLJIT_OR, TMP2, 0, SLJIT_EQUAL);\n\n      JUMPHERE(jump);\n      jump = CMP(SLJIT_ZERO ^ invertcmp, TMP2, 0, SLJIT_IMM, 0);\n      break;\n\n      case PT_PXPUNCT:\n      SET_TYPE_OFFSET(ucp_Sc);\n      OP2U(SLJIT_SUB | SLJIT_SET_LESS_EQUAL, typereg, 0, SLJIT_IMM, ucp_So - ucp_Sc);\n      OP_FLAGS(SLJIT_MOV, TMP2, 0, SLJIT_LESS_EQUAL);\n\n      SET_CHAR_OFFSET(0);\n      OP2U(SLJIT_SUB | SLJIT_SET_LESS_EQUAL, TMP1, 0, SLJIT_IMM, 0x7f);\n      OP_FLAGS(SLJIT_AND, TMP2, 0, SLJIT_LESS_EQUAL);\n\n      SET_TYPE_OFFSET(ucp_Pc);\n      OP2U(SLJIT_SUB | SLJIT_SET_LESS_EQUAL, typereg, 0, SLJIT_IMM, ucp_Ps - ucp_Pc);\n      OP_FLAGS(SLJIT_OR | SLJIT_SET_Z, TMP2, 0, SLJIT_LESS_EQUAL);\n      jump = JUMP(SLJIT_NOT_ZERO ^ invertcmp);\n      break;\n\n      default:\n      SLJIT_UNREACHABLE();\n      break;\n      }\n    cc += 2;\n    }\n#endif /* SUPPORT_UNICODE */\n\n  if (jump != NULL)\n    add_jump(compiler, compares > 0 ? list : backtracks, jump);\n  }\n\nif (found != NULL)\n  set_jumps(found, LABEL());\n}",
        "func_hash": 183419698766008283102134937176756315954,
        "file_name": "pcre2_jit_compile.c",
        "file_hash": 284265016287060690142505784626516203619,
        "cwe": [
            "CWE-125"
        ],
        "cve": "CVE-2022-1586",
        "cve_desc": "An out-of-bounds read vulnerability was discovered in the PCRE2 library in the compile_xclass_matchingpath() function of the pcre2_jit_compile.c file. This involves a unicode property matching issue in JIT-compiled regular expressions. The issue occurs because the character was not fully read in case-less matching within JIT.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-1586",
        "func_name": "compile_xclass_matchingpath",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195274,
        "project": "tensorflow",
        "commit_id": "0a365c029e437be0349c31f8d4c9926b69fa3fa1",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/0a365c029e437be0349c31f8d4c9926b69fa3fa1",
        "commit_message": "Prevent null pointer dereference in constant folding.\n\nUnder certain conditions, an invalid protobuf saved model with invalid nodes would be loaded. During optimization phase, Grappler optimizer will then dereference a null pointer.\n\nPiperOrigin-RevId: 409683530\nChange-Id: I1f10340a7ec384bc9bc587300390f1078cf5caa0",
        "target": 1,
        "irrelevant": 1,
        "func_before": "bool ConstantFolding::MulConvPushDown(GraphDef* optimized_graph, NodeDef* node,\n                                      const GraphProperties& properties) {\n  // Push down multiplication on ConvND.\n  //                       *                  ConvND\n  //                     /   \\                /    \\\n  //                 ConvND  C2    -- >      X      *\n  //                  / \\                          / \\\n  //                 X  C1                       C1  C2\n  //\n  // where C1 and C2 are constants and X is non-constant.\n  //\n  // TODO(rmlarsen): Use PrepareConstantPushDown() to simplify this code.\n\n  if (!IsAnyMul(*node) || NumNonControlInputs(*node) != 2) return false;\n\n  NodeDef* mul_left_child = node_map_->GetNode(node->input(0));\n  NodeDef* mul_right_child = node_map_->GetNode(node->input(1));\n  // One child must be constant, and the second must be Conv op.\n  const bool left_child_is_constant = IsReallyConstant(*mul_left_child);\n  const bool right_child_is_constant = IsReallyConstant(*mul_right_child);\n  if (!left_child_is_constant && !right_child_is_constant) {\n    return false;\n  }\n  NodeDef* conv_node =\n      left_child_is_constant ? mul_right_child : mul_left_child;\n  if (!IsConv2D(*conv_node) && !IsConv3D(*conv_node)) {\n    return false;\n  }\n  if (node->device() != mul_left_child->device() ||\n      node->device() != mul_right_child->device()) {\n    return false;\n  }\n\n  // Make sure that it is safe to change the value of the convolution\n  // output.\n  if (conv_node->input_size() < 2 ||\n      NumNonControlOutputs(*conv_node, *node_map_) > 1 ||\n      nodes_to_preserve_.find(conv_node->name()) != nodes_to_preserve_.end()) {\n    return false;\n  }\n\n  // Identify the nodes to swap.\n  NodeDef* conv_left_child = node_map_->GetNode(conv_node->input(0));\n  NodeDef* conv_right_child = node_map_->GetNode(conv_node->input(1));\n  const bool conv_left_is_constant = IsReallyConstant(*conv_left_child);\n  const bool conv_right_is_constant = IsReallyConstant(*conv_right_child);\n  if (!conv_left_is_constant && !conv_right_is_constant) {\n    // At least one of the convolution inputs should be constant.\n    return false;\n  }\n  if (conv_left_is_constant && conv_right_is_constant) {\n    // Leverage regular constant folding to handle this.\n    return false;\n  }\n  const auto& mul_props = properties.GetOutputProperties(node->name());\n  const auto& conv_props = properties.GetOutputProperties(conv_node->name());\n  if (mul_props.empty() || conv_props.empty()) {\n    return false;\n  }\n  const auto& mul_shape = mul_props[0].shape();\n  const auto& conv_shape = conv_props[0].shape();\n  if (!ShapesSymbolicallyEqual(mul_shape, conv_shape)) {\n    return false;\n  }\n\n  const auto& input_props = properties.GetInputProperties(conv_node->name());\n  if (input_props.size() < 2) {\n    return false;\n  }\n  const auto& filter_shape = input_props[1].shape();\n\n  NodeDef* const_node =\n      left_child_is_constant ? mul_left_child : mul_right_child;\n  const auto& const_props = properties.GetOutputProperties(const_node->name());\n  if (const_props.empty()) {\n    return false;\n  }\n  const auto& const_shape = const_props[0].shape();\n  if (!IsValidConstShapeForMulConvPushDown(\n          conv_node->attr().at(\"data_format\").s(), filter_shape, const_shape)) {\n    return false;\n  }\n\n  string mul_new_name = AddPrefixToNodeName(\"merged_input\", conv_node->name());\n  if (node_map_->NodeExists(mul_new_name)) {\n    return false;\n  }\n  // Make sure we don't introduce loops in the graph by removing control\n  // dependencies from the conv2d node to c2.\n  string conv_const_input =\n      conv_left_is_constant ? conv_node->input(0) : conv_node->input(1);\n  if (MaybeRemoveControlInput(conv_node->name(), const_node, optimized_graph,\n                              node_map_.get())) {\n    // Add a control dep from c1 to c2 to ensure c2 is in the right frame\n    MaybeAddControlInput(conv_const_input, const_node, optimized_graph,\n                         node_map_.get());\n  }\n\n  conv_node->set_name(node->name());\n  node->set_name(mul_new_name);\n  if (conv_left_is_constant) {\n    node_map_->UpdateInput(conv_node->name(), node->input(0), mul_new_name);\n    conv_node->set_input(0, mul_new_name);\n  } else {\n    node_map_->UpdateInput(conv_node->name(), node->input(1), mul_new_name);\n    conv_node->set_input(1, mul_new_name);\n  }\n  NodeDef* conv_const_node =\n      conv_left_is_constant ? conv_left_child : conv_right_child;\n  if (left_child_is_constant) {\n    node->set_input(1, conv_const_node->name());\n  } else {\n    node->set_input(0, conv_const_node->name());\n  }\n  node_map_->AddNode(mul_new_name, node);\n\n  return true;\n}",
        "func_hash": 134451371039665673916173676790439576039,
        "file_name": "constant_folding.cc",
        "file_hash": 221573695858123615640237954647315751120,
        "cwe": [
            "CWE-476"
        ],
        "cve": "CVE-2022-23589",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. Under certain scenarios, Grappler component of TensorFlow can trigger a null pointer dereference. There are 2 places where this can occur, for the same malicious alteration of a `SavedModel` file (fixing the first one would trigger the same dereference in the second place). First, during constant folding, the `GraphDef` might not have the required nodes for the binary operation. If a node is missing, the correposning `mul_*child` would be null, and the dereference in the subsequent line would be incorrect. We have a similar issue during `IsIdentityConsumingSwitch`. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23589",
        "func_name": "ConstantFolding::MulConvPushDown",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195289,
        "project": "tensorflow",
        "commit_id": "adbbabdb0d3abb3cdeac69e38a96de1d678b24b3",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/adbbabdb0d3abb3cdeac69e38a96de1d678b24b3",
        "commit_message": "Further validate sparse tensor for `SparseCount`: indices must be valid within dense shape.\n\nPiperOrigin-RevId: 414888122\nChange-Id: I4552bd74c135ecd4bcb5448acc0a3ce9402d8286",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext* context) override {\n    const Tensor& indices = context->input(0);\n    const Tensor& values = context->input(1);\n    const Tensor& shape = context->input(2);\n    const Tensor& weights = context->input(3);\n    bool use_weights = weights.NumElements() > 0;\n\n    OP_REQUIRES(context, TensorShapeUtils::IsMatrix(indices.shape()),\n                errors::InvalidArgument(\n                    \"Input indices must be a 2-dimensional tensor. Got: \",\n                    indices.shape().DebugString()));\n    OP_REQUIRES(context, TensorShapeUtils::IsVector(values.shape()),\n                errors::InvalidArgument(\"Input values must be a vector. Got: \",\n                                        values.shape().DebugString()));\n    OP_REQUIRES(context, TensorShapeUtils::IsVector(shape.shape()),\n                errors::InvalidArgument(\"Input shape must be a vector. Got: \",\n                                        shape.shape().DebugString()));\n    OP_REQUIRES(context,\n                values.shape().dim_size(0) == indices.shape().dim_size(0),\n                errors::InvalidArgument(\n                    \"Number of values must match first dimension of indices.\",\n                    \"Got \", values.shape().dim_size(0),\n                    \" values, indices shape: \", indices.shape().DebugString()));\n    OP_REQUIRES(\n        context, shape.shape().dim_size(0) == indices.shape().dim_size(1),\n        errors::InvalidArgument(\n            \"Number of dimensions must match second dimension of indices.\",\n            \"Got \", shape.shape().dim_size(0),\n            \" dimensions, indices shape: \", indices.shape().DebugString()));\n    OP_REQUIRES(context, shape.NumElements() > 0,\n                errors::InvalidArgument(\n                    \"The shape argument requires at least one element.\"));\n\n    if (use_weights) {\n      OP_REQUIRES(\n          context, weights.shape() == values.shape(),\n          errors::InvalidArgument(\n              \"Weights and values must have the same shape. Weight shape: \",\n              weights.shape().DebugString(),\n              \"; values shape: \", values.shape().DebugString()));\n    }\n\n    bool is_1d = shape.NumElements() == 1;\n    auto shape_vector = shape.flat<int64_t>();\n    int num_batches = is_1d ? 1 : shape_vector(0);\n    int num_values = values.NumElements();\n\n    const auto indices_values = indices.matrix<int64_t>();\n    const auto values_values = values.flat<T>();\n    const auto weight_values = weights.flat<W>();\n\n    auto per_batch_counts = BatchedMap<W>(num_batches);\n\n    T max_value = 0;\n\n    for (int idx = 0; idx < num_values; ++idx) {\n      int batch = is_1d ? 0 : indices_values(idx, 0);\n      if (batch >= num_batches) {\n        OP_REQUIRES(context, batch < num_batches,\n                    errors::InvalidArgument(\n                        \"Indices value along the first dimension must be \",\n                        \"lower than the first index of the shape.\", \"Got \",\n                        batch, \" as batch and \", num_batches,\n                        \" as the first dimension of the shape.\"));\n      }\n      const auto& value = values_values(idx);\n      if (value >= 0 && (maxlength_ <= 0 || value < maxlength_)) {\n        if (binary_output_) {\n          per_batch_counts[batch][value] = 1;\n        } else if (use_weights) {\n          per_batch_counts[batch][value] += weight_values(idx);\n        } else {\n          per_batch_counts[batch][value]++;\n        }\n        if (value > max_value) {\n          max_value = value;\n        }\n      }\n    }\n\n    int num_output_values = GetOutputSize(max_value, maxlength_, minlength_);\n    OP_REQUIRES_OK(context, OutputSparse<W>(per_batch_counts, num_output_values,\n                                            is_1d, context));\n  }",
        "func_hash": 100138829425874082218930421940516836043,
        "file_name": "count_ops.cc",
        "file_hash": 221778566959720819887290009238961995785,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2022-21740",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The implementation of `SparseCountSparseOutput` is vulnerable to a heap overflow. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-21740",
        "func_name": "Compute",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195291,
        "project": "tensorflow",
        "commit_id": "ef1d027be116f25e25bb94a60da491c2cf55bd0b",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/ef1d027be116f25e25bb94a60da491c2cf55bd0b",
        "commit_message": "Prevent copying uninitialized data in `AssignOp`.\n\nThis prevents harder to debug undefined behaviors that cannot be traced back to the original tensor after assignments occur earlier in the graph execution. Several of these undefined behaviors are just reference bindings to null pointers, which are caught when running under ubsan/asan.\n\nPiperOrigin-RevId: 408654780\nChange-Id: Iad2ec40d43f5fd7ea016c20283356c12d5ddeab1",
        "target": 1,
        "irrelevant": 1,
        "func_before": "  void Compute(OpKernelContext* context) override {\n    const Tensor& rhs = context->input(1);\n\n    // We always return the input ref.\n    context->forward_ref_input_to_ref_output(0, 0);\n\n    // We can't always know how this value will be used downstream, so make\n    // conservative assumptions in specifying constraints on the memory\n    // allocation attributes, unless the Grappler graph analysis determined that\n    // it was safe not to.\n    AllocatorAttributes attr;\n    if (!relax_constraints_) {\n      attr.set_gpu_compatible(true);\n      attr.set_nic_compatible(true);\n    }\n\n    {\n      mutex_lock l(*context->input_ref_mutex(0));\n      const Tensor& old_lhs = context->mutable_input(0, /* lock_held */ true);\n      const bool same_shape = old_lhs.shape().IsSameSize(rhs.shape());\n      if (validate_shape_) {\n        OP_REQUIRES(context, same_shape,\n                    errors::InvalidArgument(\n                        \"Assign requires shapes of both tensors to match. \"\n                        \"lhs shape= \",\n                        old_lhs.shape().DebugString(),\n                        \" rhs shape= \", rhs.shape().DebugString()));\n      }\n\n      // In the code below we try to minimize the amount of memory allocation\n      // and copying by trying the following two shortcuts:\n      // 1. If the lhs is initialized and has the same number of elements as\n      //    the rhs we can avoid a memory allocation.\n      // 2. If we can reuse the rhs buffer we avoid both a memory allocation\n      //    and copying.\n\n      // 1. Try to copy into an existing buffer.\n      if (old_lhs.IsInitialized() &&\n          old_lhs.shape().num_elements() == rhs.shape().num_elements()) {\n        // The existing lhs tensor has already been initialized and the right\n        // hand side can fit in the underlying buffer.\n        Tensor reshaped_old_lhs;\n        if (same_shape) {\n          reshaped_old_lhs = old_lhs;\n        } else {\n          CHECK(reshaped_old_lhs.CopyFrom(old_lhs, rhs.shape()));\n          context->replace_ref_input(0, reshaped_old_lhs,\n                                     /* lock_held */ true);\n        }\n        if (use_exclusive_lock_) {\n          Copy(context, &reshaped_old_lhs, rhs);\n          return;\n        }\n      } else {\n        // 2. Try to reuse the rhs.\n        std::unique_ptr<Tensor> input_alias = context->forward_input(\n            1, OpKernelContext::Params::kNoReservation /*output_index*/,\n            rhs.dtype(), rhs.shape(), DEVICE_MEMORY, attr);\n        if (input_alias != nullptr) {\n          // Update the ref to point to the new buffer.\n          context->replace_ref_input(0, *input_alias, /* lock_held */ true);\n          return;\n        }\n\n        // Otherwise, create a new tensor whose shape matches the\n        // right hand side, hand off to lhs and copy the rhs into it.\n        Tensor copy_tensor;\n        OP_REQUIRES_OK(context,\n                       context->allocate_temp(old_lhs.dtype(), rhs.shape(),\n                                              &copy_tensor, attr));\n        // We track memory of variables in variable ops instead of in this\n        // assign op.\n        context->clear_recorded_memory();\n        context->replace_ref_input(0, copy_tensor, /* lock_held */ true);\n        if (use_exclusive_lock_) {\n          Copy(context, &copy_tensor, rhs);\n          return;\n        }\n      }\n    }\n\n    // The tensor has already been initialized and the right hand side\n    // matches the left hand side's shape. We have been told to do the\n    // copy outside the lock.\n    Tensor old_unlocked_lhs = context->mutable_input(0, /* lock_held */ false);\n    Copy(context, &old_unlocked_lhs, rhs);\n  }",
        "func_hash": 110563830933859876998490806365273446744,
        "file_name": "assign_op.h",
        "file_hash": 69919930869774703131816695670485389180,
        "cwe": [
            "CWE-908"
        ],
        "cve": "CVE-2022-23573",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The implementation of `AssignOp` can result in copying uninitialized data to a new tensor. This later results in undefined behavior. The implementation has a check that the left hand side of the assignment is initialized (to minimize number of allocations), but does not check that the right hand side is also initialized. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23573",
        "func_name": "Compute",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195293,
        "project": "mruby",
        "commit_id": "ae3c99767a27f5c6c584162e2adc6a5d0eb2c54e",
        "project_url": "https://github.com/mruby/mruby",
        "commit_url": "https://github.com/mruby/mruby/commit/ae3c99767a27f5c6c584162e2adc6a5d0eb2c54e",
        "commit_message": "codegen.c: fixed a bug in hash code generation with `!val`.",
        "target": 1,
        "irrelevant": 1,
        "func_before": "gen_hash(codegen_scope *s, node *tree, int val, int limit)\n{\n  int slimit = GEN_VAL_STACK_MAX;\n  if (cursp() >= GEN_LIT_ARY_MAX) slimit = INT16_MAX;\n  int len = 0;\n  mrb_bool update = FALSE;\n\n  while (tree) {\n    if (nint(tree->car->car->car) == NODE_KW_REST_ARGS) {\n      if (len > 0) {\n        pop_n(len*2);\n        if (!update) {\n          genop_2(s, OP_HASH, cursp(), len);\n        }\n        else {\n          pop();\n          genop_2(s, OP_HASHADD, cursp(), len);\n        }\n        push();\n      }\n      codegen(s, tree->car->cdr, val);\n      if (len > 0 || update) {\n        pop(); pop();\n        genop_1(s, OP_HASHCAT, cursp());\n        push();\n      }\n      update = TRUE;\n      len = 0;\n    }\n    else {\n      codegen(s, tree->car->car, val);\n      codegen(s, tree->car->cdr, val);\n      len++;\n    }\n    tree = tree->cdr;\n    if (val && cursp() >= slimit) {\n      pop_n(len*2);\n      if (!update) {\n        genop_2(s, OP_HASH, cursp(), len);\n      }\n      else {\n        pop();\n        genop_2(s, OP_HASHADD, cursp(), len);\n      }\n      push();\n      update = TRUE;\n      len = 0;\n    }\n  }\n  if (update) {\n    if (val && len > 0) {\n      pop_n(len*2+1);\n      genop_2(s, OP_HASHADD, cursp(), len);\n      push();\n    }\n    return -1;                  /* variable length */\n  }\n  return len;\n}",
        "func_hash": 193019522040384116683756187518117428466,
        "file_name": "codegen.c",
        "file_hash": 187346573288549092337421927147361320618,
        "cwe": [
            "CWE-476"
        ],
        "cve": "CVE-2022-0481",
        "cve_desc": "NULL Pointer Dereference in Homebrew mruby prior to 3.2.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-0481",
        "func_name": "gen_hash",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195294,
        "project": "tensorflow",
        "commit_id": "f57315566d7094f322b784947093406c2aea0d7d",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/f57315566d7094f322b784947093406c2aea0d7d",
        "commit_message": "Add a check for Key being scalar tensor for MapStage and OrderedMapStage ops.\n\nAccording to documentation[1][2], key must be int64 value, but this wasn't enforced and the ops would fail with check failure for non-scalar key value.\n\n[1]https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/ordered-map-stage\n[2]https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/map-stage\n\nPiperOrigin-RevId: 413822112\nChange-Id: I9d118faf990e6361900aa32272eff486ad9f0e2e",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext* ctx) override {\n    StagingMap<Ordered>* map = nullptr;\n    OP_REQUIRES_OK(ctx, GetStagingMap(ctx, def(), &map));\n    core::ScopedUnref scope(map);\n    typename StagingMap<Ordered>::OptionalTuple tuple;\n\n    const Tensor* key_tensor;\n    const Tensor* indices_tensor;\n    OpInputList values_tensor;\n\n    OP_REQUIRES_OK(ctx, ctx->input(\"key\", &key_tensor));\n    OP_REQUIRES_OK(ctx, ctx->input(\"indices\", &indices_tensor));\n    OP_REQUIRES_OK(ctx, ctx->input_list(\"values\", &values_tensor));\n    OP_REQUIRES(ctx, key_tensor->NumElements() > 0,\n                errors::InvalidArgument(\"key must not be empty\"));\n\n    // Create copy for insertion into Staging Area\n    Tensor key(*key_tensor);\n\n    // Create the tuple to store\n    for (std::size_t i = 0; i < values_tensor.size(); ++i) {\n      tuple.push_back(values_tensor[i]);\n    }\n\n    // Store the tuple in the map\n    OP_REQUIRES_OK(ctx, map->put(&key, indices_tensor, &tuple));\n  }",
        "func_hash": 121343016950748954777477429164526353429,
        "file_name": "map_stage_op.cc",
        "file_hash": 156634864064326951745718193254274952325,
        "cwe": [
            "CWE-843"
        ],
        "cve": "CVE-2022-21734",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The implementation of `MapStage` is vulnerable a `CHECK`-fail if the key tensor is not a scalar. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-21734",
        "func_name": "Compute",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195295,
        "project": "mruby",
        "commit_id": "c8c083cb750606b2da81582cd8e43b442bb143e6",
        "project_url": "https://github.com/mruby/mruby",
        "commit_url": "https://github.com/mruby/mruby/commit/c8c083cb750606b2da81582cd8e43b442bb143e6",
        "commit_message": "codegen.c: need to pack argument when `n==13` too.\n\nBecause we have extra 2 arguments coming (kw and rhs).",
        "target": 1,
        "irrelevant": 0,
        "func_before": "gen_assignment(codegen_scope *s, node *tree, node *rhs, int sp, int val)\n{\n  int idx;\n  int type = nint(tree->car);\n\n  switch (type) {\n  case NODE_GVAR:\n  case NODE_ARG:\n  case NODE_LVAR:\n  case NODE_IVAR:\n  case NODE_CVAR:\n  case NODE_CONST:\n  case NODE_NIL:\n  case NODE_MASGN:\n    if (rhs) {\n      codegen(s, rhs, VAL);\n      pop();\n      sp = cursp();\n    }\n    break;\n\n  case NODE_COLON2:\n  case NODE_CALL:\n  case NODE_SCALL:\n    /* keep evaluation order */\n    break;\n\n  case NODE_NVAR:\n    codegen_error(s, \"Can't assign to numbered parameter\");\n    break;\n\n  default:\n    codegen_error(s, \"unknown lhs\");\n    break;\n  }\n\n  tree = tree->cdr;\n  switch (type) {\n  case NODE_GVAR:\n    gen_setxv(s, OP_SETGV, sp, nsym(tree), val);\n    break;\n  case NODE_ARG:\n  case NODE_LVAR:\n    idx = lv_idx(s, nsym(tree));\n    if (idx > 0) {\n      if (idx != sp) {\n        gen_move(s, idx, sp, val);\n      }\n      break;\n    }\n    else {                      /* upvar */\n      gen_setupvar(s, sp, nsym(tree));\n    }\n    break;\n  case NODE_IVAR:\n    gen_setxv(s, OP_SETIV, sp, nsym(tree), val);\n    break;\n  case NODE_CVAR:\n    gen_setxv(s, OP_SETCV, sp, nsym(tree), val);\n    break;\n  case NODE_CONST:\n    gen_setxv(s, OP_SETCONST, sp, nsym(tree), val);\n    break;\n  case NODE_COLON2:\n    if (sp) {\n      gen_move(s, cursp(), sp, 0);\n    }\n    sp = cursp();\n    push();\n    codegen(s, tree->car, VAL);\n    if (rhs) {\n      codegen(s, rhs, VAL); pop();\n      gen_move(s, sp, cursp(), 0);\n    }\n    pop_n(2);\n    idx = new_sym(s, nsym(tree->cdr));\n    genop_2(s, OP_SETMCNST, sp, idx);\n    break;\n\n  case NODE_CALL:\n  case NODE_SCALL:\n    {\n      int noself = 0, safe = (type == NODE_SCALL), skip = 0, top, call, n = 0;\n      mrb_sym mid = nsym(tree->cdr->car);\n\n      top = cursp();\n      if (val || sp == cursp()) {\n        push();                   /* room for retval */\n      }\n      call = cursp();\n      if (!tree->car) {\n        noself = 1;\n        push();\n      }\n      else {\n        codegen(s, tree->car, VAL); /* receiver */\n      }\n      if (safe) {\n        int recv = cursp()-1;\n        gen_move(s, cursp(), recv, 1);\n        skip = genjmp2_0(s, OP_JMPNIL, cursp(), val);\n      }\n      tree = tree->cdr->cdr->car;\n      if (tree) {\n        if (tree->car) {            /* positional arguments */\n          n = gen_values(s, tree->car, VAL, (tree->cdr->car)?13:14);\n          if (n < 0) {              /* variable length */\n            n = 15;\n            push();\n          }\n        }\n        if (tree->cdr->car) {       /* keyword arguments */\n          if (n == 14) {\n            pop_n(n);\n            genop_2(s, OP_ARRAY, cursp(), n);\n            push();\n            n = 15;\n          }\n          gen_hash(s, tree->cdr->car->cdr, VAL, 0);\n          if (n < 14) {\n            n++;\n          }\n          else {\n            pop_n(2);\n            genop_2(s, OP_ARYPUSH, cursp(), 1);\n          }\n          push();\n        }\n      }\n      if (rhs) {\n        codegen(s, rhs, VAL);\n        pop();\n      }\n      else {\n        gen_move(s, cursp(), sp, 0);\n      }\n      if (val) {\n        gen_move(s, top, cursp(), 1);\n      }\n      if (n < 15) {\n        n++;\n        if (n == 15) {\n          pop_n(14);\n          genop_2(s, OP_ARRAY, cursp(), 15);\n        }\n      }\n      else {\n        pop();\n        genop_2(s, OP_ARYPUSH, cursp(), 1);\n      }\n      s->sp = call;\n      if (mid == MRB_OPSYM_2(s->mrb, aref) && n == 2) {\n        genop_1(s, OP_SETIDX, cursp());\n      }\n      else {\n        genop_3(s, noself ? OP_SSEND : OP_SEND, cursp(), new_sym(s, attrsym(s, mid)), n);\n      }\n      if (safe) {\n        dispatch(s, skip);\n      }\n      s->sp = top;\n    }\n    break;\n\n  case NODE_MASGN:\n    gen_massignment(s, tree->car, sp, val);\n    break;\n\n  /* splat without assignment */\n  case NODE_NIL:\n    break;\n\n  default:\n    codegen_error(s, \"unknown lhs\");\n    break;\n  }\n  if (val) push();\n}",
        "func_hash": 41954898060187653186067747247923282324,
        "file_name": "codegen.c",
        "file_hash": 166306575091061367964033452033729491771,
        "cwe": [
            "CWE-125"
        ],
        "cve": "CVE-2022-1276",
        "cve_desc": "Out-of-bounds Read in mrb_get_args in GitHub repository mruby/mruby prior to 3.2. Possible arbitrary code execution if being exploited.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-1276",
        "func_name": "gen_assignment",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195296,
        "project": "uWebSockets",
        "commit_id": "03fca626a95130ab80f86adada54b29d27242759",
        "project_url": "https://github.com/uWebSockets/uWebSockets",
        "commit_url": "https://github.com/uWebSockets/uWebSockets/commit/03fca626a95130ab80f86adada54b29d27242759",
        "commit_message": "Fix overflow of triggered topics",
        "target": 1,
        "irrelevant": 0,
        "func_before": "    void publish(Topic *iterator, size_t start, size_t stop, std::string_view topic, std::pair<std::string_view, std::string_view> message) {\n        /* If we already have 64 triggered topics make sure to drain it here */\n        if (numTriggeredTopics == 64) {\n            drain();\n        }\n\n        /* Iterate over all segments in given topic */\n        for (; stop != std::string::npos; start = stop + 1) {\n            stop = topic.find('/', start);\n            std::string_view segment = topic.substr(start, stop - start);\n\n            /* It is very important to disallow wildcards when publishing.\n             * We will not catch EVERY misuse this lazy way, but enough to hinder\n             * explosive recursion.\n             * Terminating wildcards MAY still get triggered along the way, if for\n             * instace the error is found late while iterating the topic segments. */\n            if (segment.length() == 1) {\n                if (segment[0] == '+' || segment[0] == '#') {\n                    return;\n                }\n            }\n\n            /* Do we have a terminating wildcard child? */\n            if (iterator->terminatingWildcardChild) {\n                iterator->terminatingWildcardChild->messages[messageId] = message;\n\n                /* Add this topic to triggered */\n                if (!iterator->terminatingWildcardChild->triggered) {\n                    triggeredTopics[numTriggeredTopics++] = iterator->terminatingWildcardChild;\n                    iterator->terminatingWildcardChild->triggered = true;\n                }\n            }\n\n            /* Do we have a wildcard child? */\n            if (iterator->wildcardChild) {\n                publish(iterator->wildcardChild, stop + 1, stop, topic, message);\n            }\n\n            std::map<std::string_view, Topic *>::iterator it = iterator->children.find(segment);\n            if (it == iterator->children.end()) {\n                /* Stop trying to match by exact string */\n                return;\n            }\n\n            iterator = it->second;\n        }\n\n        /* If we went all the way we matched exactly */\n        iterator->messages[messageId] = message;\n\n        /* Add this topic to triggered */\n        if (!iterator->triggered) {\n            triggeredTopics[numTriggeredTopics++] = iterator;\n            iterator->triggered = true;\n        }\n    }",
        "func_hash": 134169268379037550524482088626348972483,
        "file_name": "TopicTree.h",
        "file_hash": 203813195164088557620454025257855576407,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2020-36406",
        "cve_desc": "uWebSockets 18.11.0 and 18.12.0 has a stack-based buffer overflow in uWS::TopicTree::trimTree (called from uWS::TopicTree::unsubscribeAll). NOTE: the vendor's position is that this is \"a minor issue or not even an issue at all\" because the developer of an application (that uses uWebSockets) should not be allowing the large number of triggered topics to accumulate",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2020-36406",
        "func_name": "publish",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195302,
        "project": "radare2",
        "commit_id": "37897226a1a31f982bfefdc4aeefc2e50355c73c",
        "project_url": "https://github.com/radare/radare2",
        "commit_url": "https://github.com/radare/radare2/commit/37897226a1a31f982bfefdc4aeefc2e50355c73c",
        "commit_message": "Fix use-after-free in iobank rbtree usage ##io\n\n* See havoc4 bin for reproducer\n* Reported via huntr.dev by 'Cen Zhang'",
        "target": 1,
        "irrelevant": 1,
        "func_before": "R_API bool r_io_bank_map_add_top(RIO *io, const ut32 bankid, const ut32 mapid) {\n\tRIOBank *bank = r_io_bank_get (io, bankid);\n\tRIOMap *map = r_io_map_get (io, mapid);\n\tr_return_val_if_fail (io && bank && map, false);\n\tRIOMapRef *mapref = _mapref_from_map (map);\n\tif (!mapref) {\n\t\treturn false;\n\t}\n\tRIOSubMap *sm = r_io_submap_new (io, mapref);\n\tif (!sm) {\n\t\tfree (mapref);\n\t\treturn false;\n\t}\n\tRRBNode *entry = _find_entry_submap_node (bank, sm);\n\tif (!entry) {\n\t\t// no intersection with any submap, so just insert\n\t\tif (!r_crbtree_insert (bank->submaps, sm, _find_sm_by_from_vaddr_cb, NULL)) {\n\t\t\tfree (sm);\n\t\t\tfree (mapref);\n\t\t\treturn false;\n\t\t}\n\t\tr_list_append (bank->maprefs, mapref);\n\t\treturn true;\n\t}\n\tbank->last_used = NULL;\n\tRIOSubMap *bd = (RIOSubMap *)entry->data;\n\tif (r_io_submap_to (bd) == r_io_submap_to (sm) &&\n\t\tr_io_submap_from (bd) >= r_io_submap_from (sm)) {\n\t\t// _find_entry_submap_node guarantees, that there is no submap\n\t\t// prior to bd in the range of sm, so instead of deleting and inserting\n\t\t// we can just memcpy\n\t\tmemcpy (bd, sm, sizeof (RIOSubMap));\n\t\tfree (sm);\n\t\tr_list_append (bank->maprefs, mapref);\n\t\treturn true;\n\t}\n\tif (r_io_submap_from (bd) < r_io_submap_from (sm) &&\n\t\tr_io_submap_to (sm) < r_io_submap_to (bd)) {\n\t\t// split bd into 2 maps => bd and bdsm\n\t\tRIOSubMap *bdsm = R_NEWCOPY (RIOSubMap, bd);\n\t\tif (!bdsm) {\n\t\t\tfree (sm);\n\t\t\tfree (mapref);\n\t\t\treturn false;\n\t\t}\n\t\tr_io_submap_set_from (bdsm, r_io_submap_to (sm) + 1);\n\t\tr_io_submap_set_to (bd, r_io_submap_from (sm) - 1);\n\t\t// TODO: insert and check return value, before adjusting sm size\n\t\tif (!r_crbtree_insert (bank->submaps, sm, _find_sm_by_from_vaddr_cb, NULL)) {\n\t\t\tfree (sm);\n\t\t\tfree (bdsm);\n\t\t\tfree (mapref);\n\t\t\treturn false;\n\t\t}\n\t\tif (!r_crbtree_insert (bank->submaps, bdsm, _find_sm_by_from_vaddr_cb, NULL)) {\n\t\t\tr_crbtree_delete (bank->submaps, sm, _find_sm_by_from_vaddr_cb, NULL);\n\t\t\tfree (sm);\n\t\t\tfree (bdsm);\n\t\t\tfree (mapref);\n\t\t\treturn false;\n\t\t}\n\t\tr_list_append (bank->maprefs, mapref);\n\t\treturn true;\n\t}\n\n\t// guaranteed intersection\n\tif (r_io_submap_from (bd) < r_io_submap_from (sm)) {\n\t\tr_io_submap_set_to (bd, r_io_submap_from (sm) - 1);\n\t\tentry = r_rbnode_next (entry);\n\t}\n\twhile (entry && r_io_submap_to (((RIOSubMap *)entry->data)) <= r_io_submap_to (sm)) {\n\t\t//delete all submaps that are completly included in sm\n\t\tRRBNode *next = r_rbnode_next (entry);\n\t\t// this can be optimized, there is no need to do search here\n\t\tr_crbtree_delete (bank->submaps, entry->data, _find_sm_by_from_vaddr_cb, NULL);\n\t\tentry = next;\n\t}\n\tif (entry && r_io_submap_from (((RIOSubMap *)entry->data)) <= r_io_submap_to (sm)) {\n\t\tbd = (RIOSubMap *)entry->data;\n\t\tr_io_submap_set_from (bd, r_io_submap_to (sm) + 1);\n\t}\n\tif (!r_crbtree_insert (bank->submaps, sm, _find_sm_by_from_vaddr_cb, NULL)) {\n\t\tfree (sm);\n\t\tfree (mapref);\n\t\treturn false;\n\t}\n\tr_list_append (bank->maprefs, mapref);\n\treturn true;\n}",
        "func_hash": 263882270236510290912687350121854207445,
        "file_name": "io_bank.c",
        "file_hash": 277027272439454961064680108781981809665,
        "cwe": [
            "CWE-125"
        ],
        "cve": "CVE-2022-0139",
        "cve_desc": "Use After Free in GitHub repository radareorg/radare2 prior to 5.6.0.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-0139",
        "func_name": "r_io_bank_map_add_top",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195308,
        "project": "flatpak",
        "commit_id": "462fca2c666e0cd2b60d6d2593a7216a83047aaf",
        "project_url": "https://github.com/flatpak/flatpak",
        "commit_url": "https://github.com/flatpak/flatpak/commit/462fca2c666e0cd2b60d6d2593a7216a83047aaf",
        "commit_message": "run: Don't allow chroot()\n\nIf we don't allow pivot_root() then there seems no reason why we should\nallow chroot().\n\nPartially fixes GHSA-67h7-w3jq-vh4q.\n\nSigned-off-by: Simon McVittie <smcv@collabora.com>",
        "target": 1,
        "irrelevant": 0,
        "func_before": "setup_seccomp (FlatpakBwrap   *bwrap,\n               const char     *arch,\n               gulong          allowed_personality,\n               FlatpakRunFlags run_flags,\n               GError        **error)\n{\n  gboolean multiarch = (run_flags & FLATPAK_RUN_FLAG_MULTIARCH) != 0;\n  gboolean devel = (run_flags & FLATPAK_RUN_FLAG_DEVEL) != 0;\n\n  __attribute__((cleanup (cleanup_seccomp))) scmp_filter_ctx seccomp = NULL;\n\n  /**** BEGIN NOTE ON CODE SHARING\n   *\n   * There are today a number of different Linux container\n   * implementations.  That will likely continue for long into the\n   * future.  But we can still try to share code, and it's important\n   * to do so because it affects what library and application writers\n   * can do, and we should support code portability between different\n   * container tools.\n   *\n   * This syscall blocklist is copied from linux-user-chroot, which was in turn\n   * clearly influenced by the Sandstorm.io blocklist.\n   *\n   * If you make any changes here, I suggest sending the changes along\n   * to other sandbox maintainers.  Using the libseccomp list is also\n   * an appropriate venue:\n   * https://groups.google.com/forum/#!forum/libseccomp\n   *\n   * A non-exhaustive list of links to container tooling that might\n   * want to share this blocklist:\n   *\n   *  https://github.com/sandstorm-io/sandstorm\n   *    in src/sandstorm/supervisor.c++\n   *  https://github.com/flatpak/flatpak.git\n   *    in common/flatpak-run.c\n   *  https://git.gnome.org/browse/linux-user-chroot\n   *    in src/setup-seccomp.c\n   *\n   * Other useful resources:\n   * https://github.com/systemd/systemd/blob/HEAD/src/shared/seccomp-util.c\n   * https://github.com/moby/moby/blob/HEAD/profiles/seccomp/default.json\n   *\n   **** END NOTE ON CODE SHARING\n   */\n  struct\n  {\n    int                  scall;\n    int                  errnum;\n    struct scmp_arg_cmp *arg;\n  } syscall_blocklist[] = {\n    /* Block dmesg */\n    {SCMP_SYS (syslog), EPERM},\n    /* Useless old syscall */\n    {SCMP_SYS (uselib), EPERM},\n    /* Don't allow disabling accounting */\n    {SCMP_SYS (acct), EPERM},\n    /* 16-bit code is unnecessary in the sandbox, and modify_ldt is a\n       historic source of interesting information leaks. */\n    {SCMP_SYS (modify_ldt), EPERM},\n    /* Don't allow reading current quota use */\n    {SCMP_SYS (quotactl), EPERM},\n\n    /* Don't allow access to the kernel keyring */\n    {SCMP_SYS (add_key), EPERM},\n    {SCMP_SYS (keyctl), EPERM},\n    {SCMP_SYS (request_key), EPERM},\n\n    /* Scary VM/NUMA ops */\n    {SCMP_SYS (move_pages), EPERM},\n    {SCMP_SYS (mbind), EPERM},\n    {SCMP_SYS (get_mempolicy), EPERM},\n    {SCMP_SYS (set_mempolicy), EPERM},\n    {SCMP_SYS (migrate_pages), EPERM},\n\n    /* Don't allow subnamespace setups: */\n    {SCMP_SYS (unshare), EPERM},\n    {SCMP_SYS (setns), EPERM},\n    {SCMP_SYS (mount), EPERM},\n    {SCMP_SYS (umount), EPERM},\n    {SCMP_SYS (umount2), EPERM},\n    {SCMP_SYS (pivot_root), EPERM},\n#if defined(__s390__) || defined(__s390x__) || defined(__CRIS__)\n    /* Architectures with CONFIG_CLONE_BACKWARDS2: the child stack\n     * and flags arguments are reversed so the flags come second */\n    {SCMP_SYS (clone), EPERM, &SCMP_A1 (SCMP_CMP_MASKED_EQ, CLONE_NEWUSER, CLONE_NEWUSER)},\n#else\n    /* Normally the flags come first */\n    {SCMP_SYS (clone), EPERM, &SCMP_A0 (SCMP_CMP_MASKED_EQ, CLONE_NEWUSER, CLONE_NEWUSER)},\n#endif\n\n    /* Don't allow faking input to the controlling tty (CVE-2017-5226) */\n    {SCMP_SYS (ioctl), EPERM, &SCMP_A1 (SCMP_CMP_MASKED_EQ, 0xFFFFFFFFu, (int) TIOCSTI)},\n\n    /* seccomp can't look into clone3()'s struct clone_args to check whether\n     * the flags are OK, so we have no choice but to block clone3().\n     * Return ENOSYS so user-space will fall back to clone().\n     * (GHSA-67h7-w3jq-vh4q; see also https://github.com/moby/moby/commit/9f6b562d) */\n    {SCMP_SYS (clone3), ENOSYS},\n\n    /* New mount manipulation APIs can also change our VFS. There's no\n     * legitimate reason to do these in the sandbox, so block all of them\n     * rather than thinking about which ones might be dangerous.\n     * (GHSA-67h7-w3jq-vh4q) */\n    {SCMP_SYS (open_tree), ENOSYS},\n    {SCMP_SYS (move_mount), ENOSYS},\n    {SCMP_SYS (fsopen), ENOSYS},\n    {SCMP_SYS (fsconfig), ENOSYS},\n    {SCMP_SYS (fsmount), ENOSYS},\n    {SCMP_SYS (fspick), ENOSYS},\n    {SCMP_SYS (mount_setattr), ENOSYS},\n  };\n\n  struct\n  {\n    int                  scall;\n    int                  errnum;\n    struct scmp_arg_cmp *arg;\n  } syscall_nondevel_blocklist[] = {\n    /* Profiling operations; we expect these to be done by tools from outside\n     * the sandbox.  In particular perf has been the source of many CVEs.\n     */\n    {SCMP_SYS (perf_event_open), EPERM},\n    /* Don't allow you to switch to bsd emulation or whatnot */\n    {SCMP_SYS (personality), EPERM, &SCMP_A0 (SCMP_CMP_NE, allowed_personality)},\n    {SCMP_SYS (ptrace), EPERM}\n  };\n  /* Blocklist all but unix, inet, inet6 and netlink */\n  struct\n  {\n    int             family;\n    FlatpakRunFlags flags_mask;\n  } socket_family_allowlist[] = {\n    /* NOTE: Keep in numerical order */\n    { AF_UNSPEC, 0 },\n    { AF_LOCAL, 0 },\n    { AF_INET, 0 },\n    { AF_INET6, 0 },\n    { AF_NETLINK, 0 },\n    { AF_CAN, FLATPAK_RUN_FLAG_CANBUS },\n    { AF_BLUETOOTH, FLATPAK_RUN_FLAG_BLUETOOTH },\n  };\n  int last_allowed_family;\n  int i, r;\n  g_auto(GLnxTmpfile) seccomp_tmpf  = { 0, };\n\n  seccomp = seccomp_init (SCMP_ACT_ALLOW);\n  if (!seccomp)\n    return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Initialize seccomp failed\"));\n\n  if (arch != NULL)\n    {\n      uint32_t arch_id = 0;\n      const uint32_t *extra_arches = NULL;\n\n      if (strcmp (arch, \"i386\") == 0)\n        {\n          arch_id = SCMP_ARCH_X86;\n        }\n      else if (strcmp (arch, \"x86_64\") == 0)\n        {\n          arch_id = SCMP_ARCH_X86_64;\n          extra_arches = seccomp_x86_64_extra_arches;\n        }\n      else if (strcmp (arch, \"arm\") == 0)\n        {\n          arch_id = SCMP_ARCH_ARM;\n        }\n#ifdef SCMP_ARCH_AARCH64\n      else if (strcmp (arch, \"aarch64\") == 0)\n        {\n          arch_id = SCMP_ARCH_AARCH64;\n          extra_arches = seccomp_aarch64_extra_arches;\n        }\n#endif\n\n      /* We only really need to handle arches on multiarch systems.\n       * If only one arch is supported the default is fine */\n      if (arch_id != 0)\n        {\n          /* This *adds* the target arch, instead of replacing the\n             native one. This is not ideal, because we'd like to only\n             allow the target arch, but we can't really disallow the\n             native arch at this point, because then bubblewrap\n             couldn't continue running. */\n          r = seccomp_arch_add (seccomp, arch_id);\n          if (r < 0 && r != -EEXIST)\n            return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to add architecture to seccomp filter\"));\n\n          if (multiarch && extra_arches != NULL)\n            {\n              for (i = 0; extra_arches[i] != 0; i++)\n                {\n                  r = seccomp_arch_add (seccomp, extra_arches[i]);\n                  if (r < 0 && r != -EEXIST)\n                    return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to add multiarch architecture to seccomp filter\"));\n                }\n            }\n        }\n    }\n\n  /* TODO: Should we filter the kernel keyring syscalls in some way?\n   * We do want them to be used by desktop apps, but they could also perhaps\n   * leak system stuff or secrets from other apps.\n   */\n\n  for (i = 0; i < G_N_ELEMENTS (syscall_blocklist); i++)\n    {\n      int scall = syscall_blocklist[i].scall;\n      int errnum = syscall_blocklist[i].errnum;\n\n      g_return_val_if_fail (errnum == EPERM || errnum == ENOSYS, FALSE);\n\n      if (syscall_blocklist[i].arg)\n        r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (errnum), scall, 1, *syscall_blocklist[i].arg);\n      else\n        r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (errnum), scall, 0);\n      if (r < 0 && r == -EFAULT /* unknown syscall */)\n        return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to block syscall %d\"), scall);\n    }\n\n  if (!devel)\n    {\n      for (i = 0; i < G_N_ELEMENTS (syscall_nondevel_blocklist); i++)\n        {\n          int scall = syscall_nondevel_blocklist[i].scall;\n          int errnum = syscall_nondevel_blocklist[i].errnum;\n\n          g_return_val_if_fail (errnum == EPERM || errnum == ENOSYS, FALSE);\n\n          if (syscall_nondevel_blocklist[i].arg)\n            r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (errnum), scall, 1, *syscall_nondevel_blocklist[i].arg);\n          else\n            r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (errnum), scall, 0);\n\n          if (r < 0 && r == -EFAULT /* unknown syscall */)\n            return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to block syscall %d\"), scall);\n        }\n    }\n\n  /* Socket filtering doesn't work on e.g. i386, so ignore failures here\n   * However, we need to user seccomp_rule_add_exact to avoid libseccomp doing\n   * something else: https://github.com/seccomp/libseccomp/issues/8 */\n  last_allowed_family = -1;\n  for (i = 0; i < G_N_ELEMENTS (socket_family_allowlist); i++)\n    {\n      int family = socket_family_allowlist[i].family;\n      int disallowed;\n\n      if (socket_family_allowlist[i].flags_mask != 0 &&\n          (socket_family_allowlist[i].flags_mask & run_flags) != socket_family_allowlist[i].flags_mask)\n        continue;\n\n      for (disallowed = last_allowed_family + 1; disallowed < family; disallowed++)\n        {\n          /* Blocklist the in-between valid families */\n          seccomp_rule_add_exact (seccomp, SCMP_ACT_ERRNO (EAFNOSUPPORT), SCMP_SYS (socket), 1, SCMP_A0 (SCMP_CMP_EQ, disallowed));\n        }\n      last_allowed_family = family;\n    }\n  /* Blocklist the rest */\n  seccomp_rule_add_exact (seccomp, SCMP_ACT_ERRNO (EAFNOSUPPORT), SCMP_SYS (socket), 1, SCMP_A0 (SCMP_CMP_GE, last_allowed_family + 1));\n\n  if (!glnx_open_anonymous_tmpfile_full (O_RDWR | O_CLOEXEC, \"/tmp\", &seccomp_tmpf, error))\n    return FALSE;\n\n  if (seccomp_export_bpf (seccomp, seccomp_tmpf.fd) != 0)\n    return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to export bpf\"));\n\n  lseek (seccomp_tmpf.fd, 0, SEEK_SET);\n\n  flatpak_bwrap_add_args_data_fd (bwrap,\n                                  \"--seccomp\", glnx_steal_fd (&seccomp_tmpf.fd), NULL);\n\n  return TRUE;\n}",
        "func_hash": 116661486604620809625071911593237669795,
        "file_name": "flatpak-run.c",
        "file_hash": 32398709380082441128978861691951488575,
        "cwe": [
            "CWE-20"
        ],
        "cve": "CVE-2021-41133",
        "cve_desc": "Flatpak is a system for building, distributing, and running sandboxed desktop applications on Linux. In versions prior to 1.10.4 and 1.12.0, Flatpak apps with direct access to AF_UNIX sockets such as those used by Wayland, Pipewire or pipewire-pulse can trick portals and other host-OS services into treating the Flatpak app as though it was an ordinary, non-sandboxed host-OS process. They can do this by manipulating the VFS using recent mount-related syscalls that are not blocked by Flatpak's denylist seccomp filter, in order to substitute a crafted `/.flatpak-info` or make that file disappear entirely. Flatpak apps that act as clients for AF_UNIX sockets such as those used by Wayland, Pipewire or pipewire-pulse can escalate the privileges that the corresponding services will believe the Flatpak app has. Note that protocols that operate entirely over the D-Bus session bus (user bus), system bus or accessibility bus are not affected by this. This is due to the use of a proxy process `xdg-dbus-proxy`, whose VFS cannot be manipulated by the Flatpak app, when interacting with these buses. Patches exist for versions 1.10.4 and 1.12.0, and as of time of publication, a patch for version 1.8.2 is being planned. There are no workarounds aside from upgrading to a patched version.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-41133",
        "func_name": "setup_seccomp",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195309,
        "project": "squid",
        "commit_id": "5e2ea2b13bd98f53e29964ca26bb0d602a8a12b9",
        "project_url": "https://github.com/squid-cache/squid",
        "commit_url": "https://github.com/squid-cache/squid/commit/5e2ea2b13bd98f53e29964ca26bb0d602a8a12b9",
        "commit_message": "Improve handling of Gopher responses (#1022)",
        "target": 1,
        "irrelevant": 0,
        "func_before": "gopherToHTML(GopherStateData * gopherState, char *inbuf, int len)\n{\n    char *pos = inbuf;\n    char *lpos = NULL;\n    char *tline = NULL;\n    LOCAL_ARRAY(char, line, TEMP_BUF_SIZE);\n    LOCAL_ARRAY(char, tmpbuf, TEMP_BUF_SIZE);\n    char *name = NULL;\n    char *selector = NULL;\n    char *host = NULL;\n    char *port = NULL;\n    char *escaped_selector = NULL;\n    const char *icon_url = NULL;\n    char gtype;\n    StoreEntry *entry = NULL;\n\n    memset(tmpbuf, '\\0', TEMP_BUF_SIZE);\n    memset(line, '\\0', TEMP_BUF_SIZE);\n\n    entry = gopherState->entry;\n\n    if (gopherState->conversion == GopherStateData::HTML_INDEX_PAGE) {\n        char *html_url = html_quote(entry->url());\n        gopherHTMLHeader(entry, \"Gopher Index %s\", html_url);\n        storeAppendPrintf(entry,\n                          \"<p>This is a searchable Gopher index. Use the search\\n\"\n                          \"function of your browser to enter search terms.\\n\"\n                          \"<ISINDEX>\\n\");\n        gopherHTMLFooter(entry);\n        /* now let start sending stuff to client */\n        entry->flush();\n        gopherState->HTML_header_added = 1;\n\n        return;\n    }\n\n    if (gopherState->conversion == GopherStateData::HTML_CSO_PAGE) {\n        char *html_url = html_quote(entry->url());\n        gopherHTMLHeader(entry, \"CSO Search of %s\", html_url);\n        storeAppendPrintf(entry,\n                          \"<P>A CSO database usually contains a phonebook or\\n\"\n                          \"directory.  Use the search function of your browser to enter\\n\"\n                          \"search terms.</P><ISINDEX>\\n\");\n        gopherHTMLFooter(entry);\n        /* now let start sending stuff to client */\n        entry->flush();\n        gopherState->HTML_header_added = 1;\n\n        return;\n    }\n\n    String outbuf;\n\n    if (!gopherState->HTML_header_added) {\n        if (gopherState->conversion == GopherStateData::HTML_CSO_RESULT)\n            gopherHTMLHeader(entry, \"CSO Search Result\", NULL);\n        else\n            gopherHTMLHeader(entry, \"Gopher Menu\", NULL);\n\n        outbuf.append (\"<PRE>\");\n\n        gopherState->HTML_header_added = 1;\n\n        gopherState->HTML_pre = 1;\n    }\n\n    while (pos < inbuf + len) {\n        int llen;\n        int left = len - (pos - inbuf);\n        lpos = (char *)memchr(pos, '\\n', left);\n        if (lpos) {\n            ++lpos;             /* Next line is after \\n */\n            llen = lpos - pos;\n        } else {\n            llen = left;\n        }\n        if (gopherState->len + llen >= TEMP_BUF_SIZE) {\n            debugs(10, DBG_IMPORTANT, \"GopherHTML: Buffer overflow. Lost some data on URL: \" << entry->url()  );\n            llen = TEMP_BUF_SIZE - gopherState->len - 1;\n            gopherState->overflowed = true; // may already be true\n        }\n        if (!lpos) {\n            /* there is no complete line in inbuf */\n            /* copy it to temp buffer */\n            /* note: llen is adjusted above */\n            memcpy(gopherState->buf + gopherState->len, pos, llen);\n            gopherState->len += llen;\n            break;\n        }\n        if (gopherState->len != 0) {\n            /* there is something left from last tx. */\n            memcpy(line, gopherState->buf, gopherState->len);\n            memcpy(line + gopherState->len, pos, llen);\n            llen += gopherState->len;\n            gopherState->len = 0;\n        } else {\n            memcpy(line, pos, llen);\n        }\n        line[llen + 1] = '\\0';\n        /* move input to next line */\n        pos = lpos;\n\n        /* at this point. We should have one line in buffer to process */\n\n        if (*line == '.') {\n            /* skip it */\n            memset(line, '\\0', TEMP_BUF_SIZE);\n            continue;\n        }\n\n        switch (gopherState->conversion) {\n\n        case GopherStateData::HTML_INDEX_RESULT:\n\n        case GopherStateData::HTML_DIR: {\n            tline = line;\n            gtype = *tline;\n            ++tline;\n            name = tline;\n            selector = strchr(tline, TAB);\n\n            if (selector) {\n                *selector = '\\0';\n                ++selector;\n                host = strchr(selector, TAB);\n\n                if (host) {\n                    *host = '\\0';\n                    ++host;\n                    port = strchr(host, TAB);\n\n                    if (port) {\n                        char *junk;\n                        port[0] = ':';\n                        junk = strchr(host, TAB);\n\n                        if (junk)\n                            *junk++ = 0;    /* Chop port */\n                        else {\n                            junk = strchr(host, '\\r');\n\n                            if (junk)\n                                *junk++ = 0;    /* Chop port */\n                            else {\n                                junk = strchr(host, '\\n');\n\n                                if (junk)\n                                    *junk++ = 0;    /* Chop port */\n                            }\n                        }\n\n                        if ((port[1] == '0') && (!port[2]))\n                            port[0] = 0;    /* 0 means none */\n                    }\n\n                    /* escape a selector here */\n                    escaped_selector = xstrdup(rfc1738_escape_part(selector));\n\n                    switch (gtype) {\n\n                    case GOPHER_DIRECTORY:\n                        icon_url = mimeGetIconURL(\"internal-menu\");\n                        break;\n\n                    case GOPHER_HTML:\n\n                    case GOPHER_FILE:\n                        icon_url = mimeGetIconURL(\"internal-text\");\n                        break;\n\n                    case GOPHER_INDEX:\n\n                    case GOPHER_CSO:\n                        icon_url = mimeGetIconURL(\"internal-index\");\n                        break;\n\n                    case GOPHER_IMAGE:\n\n                    case GOPHER_GIF:\n\n                    case GOPHER_PLUS_IMAGE:\n                        icon_url = mimeGetIconURL(\"internal-image\");\n                        break;\n\n                    case GOPHER_SOUND:\n\n                    case GOPHER_PLUS_SOUND:\n                        icon_url = mimeGetIconURL(\"internal-sound\");\n                        break;\n\n                    case GOPHER_PLUS_MOVIE:\n                        icon_url = mimeGetIconURL(\"internal-movie\");\n                        break;\n\n                    case GOPHER_TELNET:\n\n                    case GOPHER_3270:\n                        icon_url = mimeGetIconURL(\"internal-telnet\");\n                        break;\n\n                    case GOPHER_BIN:\n\n                    case GOPHER_MACBINHEX:\n\n                    case GOPHER_DOSBIN:\n\n                    case GOPHER_UUENCODED:\n                        icon_url = mimeGetIconURL(\"internal-binary\");\n                        break;\n\n                    case GOPHER_INFO:\n                        icon_url = NULL;\n                        break;\n\n                    case GOPHER_WWW:\n                        icon_url = mimeGetIconURL(\"internal-link\");\n                        break;\n\n                    default:\n                        icon_url = mimeGetIconURL(\"internal-unknown\");\n                        break;\n                    }\n\n                    memset(tmpbuf, '\\0', TEMP_BUF_SIZE);\n\n                    if ((gtype == GOPHER_TELNET) || (gtype == GOPHER_3270)) {\n                        if (strlen(escaped_selector) != 0)\n                            snprintf(tmpbuf, TEMP_BUF_SIZE, \"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"telnet://%s@%s%s%s/\\\">%s</A>\\n\",\n                                     icon_url, escaped_selector, rfc1738_escape_part(host),\n                                     *port ? \":\" : \"\", port, html_quote(name));\n                        else\n                            snprintf(tmpbuf, TEMP_BUF_SIZE, \"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"telnet://%s%s%s/\\\">%s</A>\\n\",\n                                     icon_url, rfc1738_escape_part(host), *port ? \":\" : \"\",\n                                     port, html_quote(name));\n\n                    } else if (gtype == GOPHER_INFO) {\n                        snprintf(tmpbuf, TEMP_BUF_SIZE, \"\\t%s\\n\", html_quote(name));\n                    } else {\n                        if (strncmp(selector, \"GET /\", 5) == 0) {\n                            /* WWW link */\n                            snprintf(tmpbuf, TEMP_BUF_SIZE, \"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"http://%s/%s\\\">%s</A>\\n\",\n                                     icon_url, host, rfc1738_escape_unescaped(selector + 5), html_quote(name));\n                        } else if (gtype == GOPHER_WWW) {\n                            snprintf(tmpbuf, TEMP_BUF_SIZE, \"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"%s\\\">%s</A>\\n\",\n                                     icon_url, rfc1738_escape_unescaped(selector), html_quote(name));\n                        } else {\n                            /* Standard link */\n                            snprintf(tmpbuf, TEMP_BUF_SIZE, \"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"gopher://%s/%c%s\\\">%s</A>\\n\",\n                                     icon_url, host, gtype, escaped_selector, html_quote(name));\n                        }\n                    }\n\n                    safe_free(escaped_selector);\n                    outbuf.append(tmpbuf);\n                } else {\n                    memset(line, '\\0', TEMP_BUF_SIZE);\n                    continue;\n                }\n            } else {\n                memset(line, '\\0', TEMP_BUF_SIZE);\n                continue;\n            }\n\n            break;\n            }           /* HTML_DIR, HTML_INDEX_RESULT */\n\n        case GopherStateData::HTML_CSO_RESULT: {\n            if (line[0] == '-') {\n                int code, recno;\n                char *s_code, *s_recno, *result;\n\n                s_code = strtok(line + 1, \":\\n\");\n                s_recno = strtok(NULL, \":\\n\");\n                result = strtok(NULL, \"\\n\");\n\n                if (!result)\n                    break;\n\n                code = atoi(s_code);\n\n                recno = atoi(s_recno);\n\n                if (code != 200)\n                    break;\n\n                if (gopherState->cso_recno != recno) {\n                    snprintf(tmpbuf, TEMP_BUF_SIZE, \"</PRE><HR noshade size=\\\"1px\\\"><H2>Record# %d<br><i>%s</i></H2>\\n<PRE>\", recno, html_quote(result));\n                    gopherState->cso_recno = recno;\n                } else {\n                    snprintf(tmpbuf, TEMP_BUF_SIZE, \"%s\\n\", html_quote(result));\n                }\n\n                outbuf.append(tmpbuf);\n                break;\n            } else {\n                int code;\n                char *s_code, *result;\n\n                s_code = strtok(line, \":\");\n                result = strtok(NULL, \"\\n\");\n\n                if (!result)\n                    break;\n\n                code = atoi(s_code);\n\n                switch (code) {\n\n                case 200: {\n                    /* OK */\n                    /* Do nothing here */\n                    break;\n                }\n\n                case 102:   /* Number of matches */\n\n                case 501:   /* No Match */\n\n                case 502: { /* Too Many Matches */\n                    /* Print the message the server returns */\n                    snprintf(tmpbuf, TEMP_BUF_SIZE, \"</PRE><HR noshade size=\\\"1px\\\"><H2>%s</H2>\\n<PRE>\", html_quote(result));\n                    outbuf.append(tmpbuf);\n                    break;\n                }\n\n                }\n            }\n\n            break;\n            }           /* HTML_CSO_RESULT */\n        default:\n            break;      /* do nothing */\n\n        }           /* switch */\n\n    }               /* while loop */\n\n    if (outbuf.size() > 0) {\n        entry->append(outbuf.rawBuf(), outbuf.size());\n        /* now let start sending stuff to client */\n        entry->flush();\n    }\n\n    outbuf.clean();\n    return;\n}",
        "func_hash": 274182330078791984686066092776381139807,
        "file_name": "gopher.cc",
        "file_hash": 53940162348551394934251092714566998881,
        "cwe": [
            "CWE-400"
        ],
        "cve": "CVE-2021-46784",
        "cve_desc": "In Squid 3.x through 3.5.28, 4.x through 4.17, and 5.x before 5.6, due to improper buffer management, a Denial of Service can occur when processing long Gopher server responses.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-46784",
        "func_name": "gopherToHTML",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195328,
        "project": "gpac",
        "commit_id": "30ac5e5236b790accd1f25347eebf2dc8c6c1bcb",
        "project_url": "https://github.com/gpac/gpac",
        "commit_url": "https://github.com/gpac/gpac/commit/30ac5e5236b790accd1f25347eebf2dc8c6c1bcb",
        "commit_message": "fixed #1897",
        "target": 1,
        "irrelevant": 0,
        "func_before": "char *gf_text_get_utf8_line(char *szLine, u32 lineSize, FILE *txt_in, s32 unicode_type)\n{\n\tu32 i, j, len;\n\tchar *sOK;\n\tchar szLineConv[1024];\n\tunsigned short *sptr;\n\n\tmemset(szLine, 0, sizeof(char)*lineSize);\n\tsOK = gf_fgets(szLine, lineSize, txt_in);\n\tif (!sOK) return NULL;\n\tif (unicode_type<=1) {\n\t\tj=0;\n\t\tlen = (u32) strlen(szLine);\n\t\tfor (i=0; i<len; i++) {\n\t\t\tif (!unicode_type && (szLine[i] & 0x80)) {\n\t\t\t\t/*non UTF8 (likely some win-CP)*/\n\t\t\t\tif ((szLine[i+1] & 0xc0) != 0x80) {\n\t\t\t\t\tszLineConv[j] = 0xc0 | ( (szLine[i] >> 6) & 0x3 );\n\t\t\t\t\tj++;\n\t\t\t\t\tszLine[i] &= 0xbf;\n\t\t\t\t}\n\t\t\t\t/*UTF8 2 bytes char*/\n\t\t\t\telse if ( (szLine[i] & 0xe0) == 0xc0) {\n\t\t\t\t\tszLineConv[j] = szLine[i];\n\t\t\t\t\ti++;\n\t\t\t\t\tj++;\n\t\t\t\t}\n\t\t\t\t/*UTF8 3 bytes char*/\n\t\t\t\telse if ( (szLine[i] & 0xf0) == 0xe0) {\n\t\t\t\t\tszLineConv[j] = szLine[i];\n\t\t\t\t\ti++;\n\t\t\t\t\tj++;\n\t\t\t\t\tszLineConv[j] = szLine[i];\n\t\t\t\t\ti++;\n\t\t\t\t\tj++;\n\t\t\t\t}\n\t\t\t\t/*UTF8 4 bytes char*/\n\t\t\t\telse if ( (szLine[i] & 0xf8) == 0xf0) {\n\t\t\t\t\tszLineConv[j] = szLine[i];\n\t\t\t\t\ti++;\n\t\t\t\t\tj++;\n\t\t\t\t\tszLineConv[j] = szLine[i];\n\t\t\t\t\ti++;\n\t\t\t\t\tj++;\n\t\t\t\t\tszLineConv[j] = szLine[i];\n\t\t\t\t\ti++;\n\t\t\t\t\tj++;\n\t\t\t\t} else {\n\t\t\t\t\ti+=1;\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t}\n\t\t\tszLineConv[j] = szLine[i];\n\t\t\tj++;\n\t\t}\n\t\tszLineConv[j] = 0;\n\t\tstrcpy(szLine, szLineConv);\n\t\treturn sOK;\n\t}\n\n#ifdef GPAC_BIG_ENDIAN\n\tif (unicode_type==3)\n#else\n\tif (unicode_type==2)\n#endif\n\t{\n\t\ti=0;\n\t\twhile (1) {\n\t\t\tchar c;\n\t\t\tif (!szLine[i] && !szLine[i+1]) break;\n\t\t\tc = szLine[i+1];\n\t\t\tszLine[i+1] = szLine[i];\n\t\t\tszLine[i] = c;\n\t\t\ti+=2;\n\t\t}\n\t}\n\tsptr = (u16 *)szLine;\n\ti = (u32) gf_utf8_wcstombs(szLineConv, 1024, (const unsigned short **) &sptr);\n\tszLineConv[i] = 0;\n\tstrcpy(szLine, szLineConv);\n\t/*this is ugly indeed: since input is UTF16-LE, there are many chances the gf_fgets never reads the \\0 after a \\n*/\n\tif (unicode_type==3) gf_fgetc(txt_in);\n\treturn sOK;\n}",
        "func_hash": 117427486429117846714647428036887377373,
        "file_name": "load_text.c",
        "file_hash": 196742273187479774331460388493063544419,
        "cwe": [
            "CWE-415"
        ],
        "cve": "CVE-2021-40574",
        "cve_desc": "The binary MP4Box in Gpac 1.0.1 has a double-free vulnerability in the gf_text_get_utf8_line function in load_text.c, which allows attackers to cause a denial of service, even code execution and escalation of privileges.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-40574",
        "func_name": "gf_text_get_utf8_line",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195331,
        "project": "tensorflow",
        "commit_id": "08d7b00c0a5a20926363849f611729f53f3ec022",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/08d7b00c0a5a20926363849f611729f53f3ec022",
        "commit_message": "Fix Segfault in Concat V2 shape function.\n\nPiperOrigin-RevId: 412120654\nChange-Id: I3ff915faea694f9ad8b00024e9af2de9909011be",
        "target": 1,
        "irrelevant": 0,
        "func_before": "Status ConcatShapeHelper(InferenceContext* c, int start_value_index,\n                         int end_value_index, int dim_index) {\n  ShapeHandle unused;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(dim_index), 0, &unused));\n  const Tensor* concat_dim_t = c->input_tensor(dim_index);\n  if (concat_dim_t == nullptr) {\n    // Return an unknown shape with same rank as inputs, or an unknown rank\n    // if no input's rank is known.\n\n    // Find rank.\n    int32_t rank = InferenceContext::kUnknownRank;\n    for (int i = start_value_index; i < end_value_index; ++i) {\n      if (rank == InferenceContext::kUnknownRank) rank = c->Rank(c->input(i));\n      if (rank != InferenceContext::kUnknownRank) {\n        break;\n      }\n    }\n    if (rank == InferenceContext::kUnknownRank) {\n      c->set_output(0, c->UnknownShape());\n      return Status::OK();\n    } else if (rank == 0) {\n      return errors::InvalidArgument(\n          \"Can't concatenate scalars (use tf.stack instead)\");\n    } else {\n      for (int i = start_value_index; i < end_value_index; ++i) {\n        // Check that all the inputs are of the correct rank.\n        TF_RETURN_IF_ERROR(c->WithRank(c->input(i), rank, &unused));\n      }\n    }\n    // Build result of <rank> different unknown dims.\n    std::vector<DimensionHandle> dims;\n    dims.reserve(rank);\n    for (int i = 0; i < rank; ++i) dims.push_back(c->UnknownDim());\n    c->set_output(0, c->MakeShape(dims));\n    return Status::OK();\n  }\n\n  // Merge all the non-concat dims, and sum the concat dim to make an output\n  // shape.\n  int64_t concat_dim;\n  if (concat_dim_t->dtype() == DT_INT32) {\n    concat_dim = static_cast<int64_t>(concat_dim_t->flat<int32>()(0));\n  } else {\n    concat_dim = concat_dim_t->flat<int64_t>()(0);\n  }\n\n  // Minimum required number of dimensions.\n  const int min_rank = concat_dim < 0 ? -concat_dim : concat_dim + 1;\n\n  ShapeHandle output_before;\n  ShapeHandle output_after;\n\n  ShapeHandle input = c->input(end_value_index - 1);\n  TF_RETURN_IF_ERROR(c->WithRankAtLeast(input, min_rank, &input));\n  TF_RETURN_IF_ERROR(c->Subshape(input, 0, concat_dim, &output_before));\n  DimensionHandle output_middle = c->Dim(input, concat_dim);\n  if (concat_dim == -1) {\n    output_after = c->Scalar();  // no dimensions.\n  } else {\n    TF_RETURN_IF_ERROR(c->Subshape(input, concat_dim + 1, &output_after));\n  }\n\n  for (int i = end_value_index - 2; i >= start_value_index; --i) {\n    ShapeHandle before;\n    ShapeHandle after;\n    input = c->input(i);\n    TF_RETURN_IF_ERROR(c->WithRankAtLeast(input, min_rank, &input));\n    TF_RETURN_IF_ERROR(c->Subshape(input, 0, concat_dim, &before));\n    DimensionHandle middle = c->Dim(input, concat_dim);\n    if (concat_dim == -1) {\n      after = c->Scalar();\n    } else {\n      TF_RETURN_IF_ERROR(c->Subshape(input, concat_dim + 1, &after));\n    }\n\n    TF_RETURN_IF_ERROR(c->Merge(before, output_before, &output_before));\n    TF_RETURN_IF_ERROR(c->Add(output_middle, middle, &output_middle));\n    TF_RETURN_IF_ERROR(c->Merge(after, output_after, &output_after));\n  }\n\n  ShapeHandle s;\n  TF_RETURN_IF_ERROR(\n      c->Concatenate(output_before, c->Vector(output_middle), &s));\n  TF_RETURN_IF_ERROR(c->Concatenate(s, output_after, &s));\n  c->set_output(0, s);\n  return Status::OK();\n}",
        "func_hash": 115004012549325804010611397133680502113,
        "file_name": "common_shape_fns.cc",
        "file_hash": 114394888048780454732842913577124501919,
        "cwe": [
            "CWE-843"
        ],
        "cve": "CVE-2022-21731",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The implementation of shape inference for `ConcatV2` can be used to trigger a denial of service attack via a segfault caused by a type confusion. The `axis` argument is translated into `concat_dim` in the `ConcatShapeHelper` helper function. Then, a value for `min_rank` is computed based on `concat_dim`. This is then used to validate that the `values` tensor has at least the required rank. However, `WithRankAtLeast` receives the lower bound as a 64-bits value and then compares it against the maximum 32-bits integer value that could be represented. Due to the fact that `min_rank` is a 32-bits value and the value of `axis`, the `rank` argument is a negative value, so the error check is bypassed. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-21731",
        "func_name": "ConcatShapeHelper",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195334,
        "project": "gpac",
        "commit_id": "b03c9f252526bb42fbd1b87b9f5e339c3cf2390a",
        "project_url": "https://github.com/gpac/gpac",
        "commit_url": "https://github.com/gpac/gpac/commit/b03c9f252526bb42fbd1b87b9f5e339c3cf2390a",
        "commit_message": "fixed #1890",
        "target": 1,
        "irrelevant": 1,
        "func_before": "GF_Err iloc_box_read(GF_Box *s, GF_BitStream *bs)\n{\n\tu32 item_count, extent_count, i, j;\n\tGF_ItemLocationBox *ptr = (GF_ItemLocationBox *)s;\n\n\tISOM_DECREASE_SIZE(ptr, 2)\n\tptr->offset_size = gf_bs_read_int(bs, 4);\n\tptr->length_size = gf_bs_read_int(bs, 4);\n\tptr->base_offset_size = gf_bs_read_int(bs, 4);\n\tif (ptr->version == 1 || ptr->version == 2) {\n\t\tptr->index_size = gf_bs_read_int(bs, 4);\n\t} else {\n\t\tgf_bs_read_int(bs, 4);\n\t}\n\tif (ptr->version < 2) {\n\t\tISOM_DECREASE_SIZE(ptr, 2)\n\t\titem_count = gf_bs_read_u16(bs);\n\t} else {\n\t\tISOM_DECREASE_SIZE(ptr, 4)\n\t\titem_count = gf_bs_read_u32(bs);\n\t}\n\n\tfor (i = 0; i < item_count; i++) {\n\t\tGF_ItemLocationEntry *location_entry = (GF_ItemLocationEntry *)gf_malloc(sizeof(GF_ItemLocationEntry));\n\t\tif (!location_entry) return GF_OUT_OF_MEM;\n\n\t\tgf_list_add(ptr->location_entries, location_entry);\n\t\tif (ptr->version < 2) {\n\t\t\tISOM_DECREASE_SIZE(ptr, 2)\n\t\t\tlocation_entry->item_ID = gf_bs_read_u16(bs);\n\t\t} else {\n\t\t\tISOM_DECREASE_SIZE(ptr, 4)\n\t\t\tlocation_entry->item_ID = gf_bs_read_u32(bs);\n\t\t}\n\t\tif (ptr->version == 1 || ptr->version == 2) {\n\t\t\tISOM_DECREASE_SIZE(ptr, 2)\n\t\t\tlocation_entry->construction_method = gf_bs_read_u16(bs);\n\t\t}\n\t\telse {\n\t\t\tlocation_entry->construction_method = 0;\n\t\t}\n\t\tISOM_DECREASE_SIZE(ptr, (2 + ptr->base_offset_size) )\n\t\tlocation_entry->data_reference_index = gf_bs_read_u16(bs);\n\t\tlocation_entry->base_offset = gf_bs_read_int(bs, 8*ptr->base_offset_size);\n#ifndef GPAC_DISABLE_ISOM_WRITE\n\t\tlocation_entry->original_base_offset = location_entry->base_offset;\n#endif\n\n\t\tISOM_DECREASE_SIZE(ptr, 2)\n\t\textent_count = gf_bs_read_u16(bs);\n\t\tlocation_entry->extent_entries = gf_list_new();\n\t\tfor (j = 0; j < extent_count; j++) {\n\t\t\tGF_ItemExtentEntry *extent_entry = (GF_ItemExtentEntry *)gf_malloc(sizeof(GF_ItemExtentEntry));\n\t\t\tif (!extent_entry) return GF_OUT_OF_MEM;\n\t\t\t\n\t\t\tgf_list_add(location_entry->extent_entries, extent_entry);\n\t\t\tif ((ptr->version == 1 || ptr->version == 2) && ptr->index_size > 0) {\n\t\t\t\tISOM_DECREASE_SIZE(ptr, ptr->index_size)\n\t\t\t\textent_entry->extent_index = gf_bs_read_int(bs, 8 * ptr->index_size);\n\t\t\t}\n\t\t\telse {\n\t\t\t\textent_entry->extent_index = 0;\n\t\t\t}\n\t\t\tISOM_DECREASE_SIZE(ptr, (ptr->offset_size+ptr->length_size) )\n\n\t\t\textent_entry->extent_offset = gf_bs_read_int(bs, 8*ptr->offset_size);\n\t\t\textent_entry->extent_length = gf_bs_read_int(bs, 8*ptr->length_size);\n#ifndef GPAC_DISABLE_ISOM_WRITE\n\t\t\textent_entry->original_extent_offset = extent_entry->extent_offset;\n#endif\n\t\t}\n\t}\n\treturn GF_OK;\n}",
        "func_hash": 85275035202223574859308673912965262169,
        "file_name": "box_code_meta.c",
        "file_hash": 315220373545459860670428553876078791185,
        "cwe": [
            "CWE-415"
        ],
        "cve": "CVE-2021-40573",
        "cve_desc": "The binary MP4Box in Gpac 1.0.1 has a double-free vulnerability in the gf_list_del function in list.c, which allows attackers to cause a denial of service.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-40573",
        "func_name": "iloc_box_read",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195338,
        "project": "gpac",
        "commit_id": "5ce0c906ed8599d218036b18b78e8126a496f137",
        "project_url": "https://github.com/gpac/gpac",
        "commit_url": "https://github.com/gpac/gpac/commit/5ce0c906ed8599d218036b18b78e8126a496f137",
        "commit_message": "fixed #1892",
        "target": 1,
        "irrelevant": 1,
        "func_before": "static void naludmx_queue_param_set(GF_NALUDmxCtx *ctx, char *data, u32 size, u32 ps_type, s32 ps_id)\n{\n\tGF_List *list = NULL, *alt_list = NULL;\n\tGF_NALUFFParam *sl;\n\tu32 i, count;\n\tu32 crc = gf_crc_32(data, size);\n\n\tif (ctx->codecid==GF_CODECID_HEVC) {\n\t\tswitch (ps_type) {\n\t\tcase GF_HEVC_NALU_VID_PARAM:\n\t\t\tif (!ctx->vps) ctx->vps = gf_list_new();\n\t\t\tlist = ctx->vps;\n\t\t\tbreak;\n\t\tcase GF_HEVC_NALU_SEQ_PARAM:\n\t\t\tlist = ctx->sps;\n\t\t\tbreak;\n\t\tcase GF_HEVC_NALU_PIC_PARAM:\n\t\t\tlist = ctx->pps;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tassert(0);\n\t\t\treturn;\n\t\t}\n\t} else if (ctx->codecid==GF_CODECID_VVC) {\n\t\tswitch (ps_type) {\n\t\tcase GF_VVC_NALU_VID_PARAM:\n\t\t\tif (!ctx->vps) ctx->vps = gf_list_new();\n\t\t\tlist = ctx->vps;\n\t\t\tbreak;\n\t\tcase GF_VVC_NALU_SEQ_PARAM:\n\t\t\tlist = ctx->sps;\n\t\t\tbreak;\n\t\tcase GF_VVC_NALU_PIC_PARAM:\n\t\t\tlist = ctx->pps;\n\t\t\tbreak;\n\t\tcase GF_VVC_NALU_DEC_PARAM:\n\t\t\tif (!ctx->vvc_dci) ctx->vvc_dci = gf_list_new();\n\t\t\tlist = ctx->vvc_dci;\n\t\t\tbreak;\n\t\tcase GF_VVC_NALU_APS_PREFIX:\n\t\t\tif (!ctx->vvc_aps_pre) ctx->vvc_aps_pre = gf_list_new();\n\t\t\tlist = ctx->vvc_aps_pre;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tassert(0);\n\t\t\treturn;\n\t\t}\n\t} else {\n\t\tswitch (ps_type) {\n\t\tcase GF_AVC_NALU_SVC_SUBSEQ_PARAM:\n\t\tcase GF_AVC_NALU_SEQ_PARAM:\n\t\t\tlist = ctx->sps;\n\t\t\tbreak;\n\t\tcase GF_AVC_NALU_PIC_PARAM:\n\t\t\tlist = ctx->pps;\n\t\t\talt_list = ctx->pps_svc;\n\t\t\tbreak;\n\t\tcase GF_AVC_NALU_SEQ_PARAM_EXT:\n\t\t\tif (!ctx->sps_ext) ctx->sps_ext = gf_list_new();\n\t\t\tlist = ctx->sps_ext;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tassert(0);\n\t\t\treturn;\n\t\t}\n\t}\n\tsl = NULL;\n\tcount = gf_list_count(list);\n\tfor (i=0; i<count; i++) {\n\t\tsl = gf_list_get(list, i);\n\t\tif (sl->id != ps_id) {\n\t\t\tsl = NULL;\n\t\t\tcontinue;\n\t\t}\n\t\t//same ID, same CRC, we don't change our state\n\t\tif (sl->crc == crc) return;\n\t\tbreak;\n\t}\n\t//handle alt PPS list for SVC\n\tif (!sl && alt_list) {\n\t\tcount = gf_list_count(alt_list);\n\t\tfor (i=0; i<count; i++) {\n\t\t\tsl = gf_list_get(alt_list, i);\n\t\t\tif (sl->id != ps_id) {\n\t\t\t\tsl = NULL;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\t//same ID, same CRC, we don't change our state\n\t\t\tif (sl->crc == crc) return;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (sl) {\n\t\t//otherwise we keep this new param set\n\t\tsl->data = gf_realloc(sl->data, size);\n\t\tmemcpy(sl->data, data, size);\n\t\tsl->size = size;\n\t\tsl->crc = crc;\n\t\tctx->ps_modified = GF_TRUE;\n\t\treturn;\n\t}\n\t//TODO we might want to purge the list after a while !!\n\n\tGF_SAFEALLOC(sl, GF_NALUFFParam);\n\tif (!sl) return;\n\tsl->data = gf_malloc(sizeof(char) * size);\n\tif (!sl->data) {\n\t\tgf_free(sl);\n\t\treturn;\n\t}\n\tmemcpy(sl->data, data, size);\n\tsl->size = size;\n\tsl->id = ps_id;\n\tsl->crc = crc;\n\n\tctx->ps_modified = GF_TRUE;\n\tgf_list_add(list, sl);\n}",
        "func_hash": 290272188072466406075146604851063657628,
        "file_name": "reframe_nalu.c",
        "file_hash": 268905417897981194112099324827197288724,
        "cwe": [
            "CWE-476"
        ],
        "cve": "CVE-2021-40563",
        "cve_desc": "A Segmentation fault exists casued by null pointer dereference exists in Gpac through 1.0.1 via the naludmx_create_avc_decoder_config function in reframe_nalu.c when using mp4box, which causes a denial of service.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-40563",
        "func_name": "naludmx_queue_param_set",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195340,
        "project": "tensorflow",
        "commit_id": "e952a89b7026b98fe8cbe626514a93ed68b7c510",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/e952a89b7026b98fe8cbe626514a93ed68b7c510",
        "commit_message": "Prevent overflow in sparse dense cwise ops.\n\nPiperOrigin-RevId: 415543171\nChange-Id: I22dab7c41be2121ab5efe5403ca0e2f9b7cb24b8",
        "target": 1,
        "irrelevant": 1,
        "func_before": "  void Compute(OpKernelContext *ctx) override {\n    const Tensor *indices_t, *values_t, *shape_t, *dense_t;\n    OP_REQUIRES_OK(ctx, ctx->input(\"sp_indices\", &indices_t));\n    OP_REQUIRES_OK(ctx, ctx->input(\"sp_values\", &values_t));\n    OP_REQUIRES_OK(ctx, ctx->input(\"sp_shape\", &shape_t));\n    OP_REQUIRES_OK(ctx, ctx->input(\"dense\", &dense_t));\n\n    // Validations.\n    OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(indices_t->shape()),\n                errors::InvalidArgument(\n                    \"Input sp_indices should be a matrix but received shape: \",\n                    indices_t->shape().DebugString()));\n    OP_REQUIRES(ctx,\n                TensorShapeUtils::IsVector(values_t->shape()) &&\n                    TensorShapeUtils::IsVector(shape_t->shape()),\n                errors::InvalidArgument(\n                    \"Inputs sp_values and sp_shape should be vectors \"\n                    \"but received shapes: \",\n                    values_t->shape().DebugString(), \" and \",\n                    shape_t->shape().DebugString()));\n    OP_REQUIRES(\n        ctx, TensorShapeUtils::IsVector(shape_t->shape()),\n        errors::InvalidArgument(\"Input sp_shape must be a vector. Got: \",\n                                shape_t->shape().DebugString()));\n    OP_REQUIRES(\n        ctx, values_t->dim_size(0) == indices_t->dim_size(0),\n        errors::InvalidArgument(\n            \"The first dimension of values and indices should match. (\",\n            values_t->dim_size(0), \" vs. \", indices_t->dim_size(0), \")\"));\n    OP_REQUIRES(\n        ctx, shape_t->shape().dim_size(0) == indices_t->shape().dim_size(1),\n        errors::InvalidArgument(\n            \"Number of dimensions must match second dimension of indices. \",\n            \"Got \", shape_t->shape().dim_size(0),\n            \" dimensions, indices shape: \", indices_t->shape().DebugString()));\n    OP_REQUIRES(ctx, shape_t->NumElements() > 0,\n                errors::InvalidArgument(\n                    \"The shape argument requires at least one element.\"));\n\n    const auto indices_mat = indices_t->matrix<int64_t>();\n    const auto shape_vec = shape_t->vec<int64_t>();\n    const auto lhs_dims = BCast::FromShape(TensorShape(shape_vec));\n    const auto rhs_dims = BCast::FromShape(dense_t->shape());\n    BCast b(lhs_dims, rhs_dims, false);  // false for keeping the same num dims.\n\n    // True iff (size(lhs) >= size(rhs)) and all dims in lhs is greater or equal\n    // to dims in rhs (from right to left).\n    auto VecGreaterEq = [](ArraySlice<int64_t> lhs, ArraySlice<int64_t> rhs) {\n      if (lhs.size() < rhs.size()) return false;\n      for (size_t i = 0; i < rhs.size(); ++i) {\n        if (lhs[lhs.size() - 1 - i] < rhs[rhs.size() - 1 - i]) return false;\n      }\n      return true;\n    };\n    OP_REQUIRES(ctx, VecGreaterEq(lhs_dims, rhs_dims) && b.IsValid(),\n                errors::InvalidArgument(\n                    \"SparseDenseBinaryOpShared broadcasts dense to sparse \"\n                    \"only; got incompatible shapes: [\",\n                    absl::StrJoin(lhs_dims, \",\"), \"] vs. [\",\n                    absl::StrJoin(rhs_dims, \",\"), \"]\"));\n\n    Tensor *output_values = nullptr;\n    Tensor dense_gathered;\n    const int64_t nnz = indices_t->dim_size(0);\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_output(0, TensorShape({nnz}), &output_values));\n    OP_REQUIRES_OK(\n        ctx, ctx->allocate_temp(DataTypeToEnum<T>::value, TensorShape({nnz}),\n                                &dense_gathered));\n    bool op_is_div = false;\n    if (absl::StrContains(ctx->op_kernel().type_string_view(), \"Div\")) {\n      op_is_div = true;\n    }\n    // Pulls relevant entries from the dense side, with reshape and broadcasting\n    // *of the dense side* taken into account.  Use a TensorRef to avoid blowing\n    // up memory.\n    //\n    // We can directly use the sparse indices to look up dense side, because\n    // \"b.y_reshape()\" and \"b.y_bcast()\" are guaranteed to have rank \"ndims\".\n    auto dense_gathered_flat = dense_gathered.flat<T>();\n    const int ndims = lhs_dims.size();\n    switch (ndims) {\n#define CASE(NDIM)                                                             \\\n  case NDIM: {                                                                 \\\n    TensorRef<Eigen::Tensor<const T, NDIM, Eigen::RowMajor>> rhs_ref =         \\\n        dense_t->shaped<T, NDIM>(b.y_reshape())                                \\\n            .broadcast(BCast::ToIndexArray<NDIM>(b.y_bcast()));                \\\n    Eigen::array<Eigen::DenseIndex, NDIM> idx;                                 \\\n    bool indices_valid = true;                                                 \\\n    for (int i = 0; i < nnz; ++i) {                                            \\\n      for (int d = 0; d < NDIM; ++d) {                                         \\\n        idx[d] = internal::SubtleMustCopy(indices_mat(i, d));                  \\\n        if (!FastBoundsCheck(idx[d], rhs_ref.dimension(d))) {                  \\\n          indices_valid = false;                                               \\\n        }                                                                      \\\n      }                                                                        \\\n      OP_REQUIRES(                                                             \\\n          ctx, indices_valid,                                                  \\\n          errors::InvalidArgument(\"Provided indices are out-of-bounds w.r.t. \" \\\n                                  \"dense side with broadcasted shape\"));       \\\n      dense_gathered_flat(i) = rhs_ref.coeff(idx);                             \\\n      if (op_is_div) {                                                         \\\n        OP_REQUIRES(ctx, dense_gathered_flat(i) != 0,                          \\\n                    errors::InvalidArgument(                                   \\\n                        \"SparseDenseCwiseDiv cannot divide by zero,\"           \\\n                        \"but input dense tensor contains zero \"));             \\\n      }                                                                        \\\n    }                                                                          \\\n    break;                                                                     \\\n  }\n\n      CASE(1);\n      CASE(2);\n      CASE(3);\n      CASE(4);\n      CASE(5);\n      default:\n        OP_REQUIRES(\n            ctx, false,\n            errors::InvalidArgument(\"Only tensors with ranks between 1 and 5 \"\n                                    \"are currently supported.  Tensor rank: \",\n                                    ndims));\n#undef CASE\n    }\n\n    output_values->flat<T>().device(ctx->eigen_device<Device>()) =\n        values_t->flat<T>().binaryExpr(dense_gathered_flat,\n                                       typename Functor::func());\n  }",
        "func_hash": 171281295800875024521736226102204042037,
        "file_name": "sparse_dense_binary_op_shared.cc",
        "file_hash": 32986558098184077015668984064800916453,
        "cwe": [
            "CWE-190"
        ],
        "cve": "CVE-2022-23567",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The implementations of `Sparse*Cwise*` ops are vulnerable to integer overflows. These can be used to trigger large allocations (so, OOM based denial of service) or `CHECK`-fails when building new `TensorShape` objects (so, assert failures based denial of service). We are missing some validation on the shapes of the input tensors as well as directly constructing a large `TensorShape` with user-provided dimensions. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23567",
        "func_name": "Compute",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195341,
        "project": "tensorflow",
        "commit_id": "b9bd6cfd1c50e6807846af9a86f9b83cafc9c8ae",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/b9bd6cfd1c50e6807846af9a86f9b83cafc9c8ae",
        "commit_message": "Prevent integer overflow in `OpLevelCostEstimator::CalculateOutputSize`.\n\nIn order to not change the API, we return a negative value in case of overflow. A better fix is to change the API to return a status instead.\n\nPiperOrigin-RevId: 408701427\nChange-Id: Idf31e7f0bf18ca824d084fdd355e1f653f145c20",
        "target": 1,
        "irrelevant": 1,
        "func_before": "int64_t OpLevelCostEstimator::CalculateOutputSize(const OpInfo& op_info,\n                                                  bool* found_unknown_shapes) {\n  int64_t total_output_size = 0;\n  // Use float as default for calculations.\n  for (const auto& output : op_info.outputs()) {\n    DataType dt = output.dtype();\n    const auto& original_output_shape = output.shape();\n    int64_t output_size = DataTypeSize(BaseType(dt));\n    int num_dims = std::max(1, original_output_shape.dim_size());\n    auto output_shape = MaybeGetMinimumShape(original_output_shape, num_dims,\n                                             found_unknown_shapes);\n    for (const auto& dim : output_shape.dim()) {\n      output_size *= dim.size();\n    }\n    total_output_size += output_size;\n    VLOG(1) << \"Output Size: \" << output_size\n            << \" Total Output Size:\" << total_output_size;\n  }\n  return total_output_size;\n}",
        "func_hash": 227979151511968058279234771045953567425,
        "file_name": "op_level_cost_estimator.cc",
        "file_hash": 48778957117537504326053940607597623217,
        "cwe": [
            "CWE-190"
        ],
        "cve": "CVE-2022-23576",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The implementation of `OpLevelCostEstimator::CalculateOutputSize` is vulnerable to an integer overflow if an attacker can create an operation which would involve tensors with large enough number of elements. We can have a large enough number of dimensions in `output_shape.dim()` or just a small number of dimensions being large enough to cause an overflow in the multiplication. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23576",
        "func_name": "OpLevelCostEstimator::CalculateOutputSize",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195343,
        "project": "tensorflow",
        "commit_id": "002408c3696b173863228223d535f9de72a101a9",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/002408c3696b173863228223d535f9de72a101a9",
        "commit_message": "Add negative bound check for row and column pooling_sequence in FractionalAvgPoolGrad op to avoid out of bound heap access\n\nPiperOrigin-RevId: 413837346\nChange-Id: I2b86034101df31bee161abcb781755e236c7bccd",
        "target": 1,
        "irrelevant": 1,
        "func_before": "  void Compute(OpKernelContext* context) override {\n    // Here's the basic idea:\n    // Batch and depth dimension are independent from row and col dimension. And\n    // because FractionalAvgPool currently only support pooling along row and\n    // col, we can basically think of this 4D tensor backpropagation as\n    // operation of a series of 2D planes.\n    //\n    // For each element of a 'slice' (2D plane) of output_backprop, we need to\n    // figure out its contributors when doing FractionalAvgPool operation. This\n    // can be done based on row_pooling_sequence, col_pooling_seq and\n    // overlapping.\n    // Once we figure out the original contributors, we just need to evenly\n    // divide the value of this element among these contributors.\n    //\n    // Internally, we divide the out_backprop tensor and store it in a temporary\n    // tensor of double type. And cast it to the corresponding type.\n    typedef Eigen::Map<const Eigen::Matrix<T, Eigen::Dynamic, Eigen::Dynamic>>\n        ConstEigenMatrixMap;\n    typedef Eigen::Map<Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic>>\n        EigenDoubleMatrixMap;\n\n    // Grab the inputs.\n    const Tensor& orig_input_tensor_shape = context->input(0);\n    OP_REQUIRES(context,\n                orig_input_tensor_shape.dims() == 1 &&\n                    orig_input_tensor_shape.NumElements() == 4,\n                errors::InvalidArgument(\"original input tensor shape must be\"\n                                        \"1-dimensional and 4 elements\"));\n    const Tensor& out_backprop = context->input(1);\n    const Tensor& row_seq_tensor = context->input(2);\n    const Tensor& col_seq_tensor = context->input(3);\n\n    const int64_t out_batch = out_backprop.dim_size(0);\n    const int64_t out_rows = out_backprop.dim_size(1);\n    const int64_t out_cols = out_backprop.dim_size(2);\n    const int64_t out_depth = out_backprop.dim_size(3);\n\n    OP_REQUIRES(context, row_seq_tensor.NumElements() > out_rows,\n                errors::InvalidArgument(\"Given out_backprop shape \",\n                                        out_backprop.shape().DebugString(),\n                                        \", row_seq_tensor must have at least \",\n                                        out_rows + 1, \" elements, but got \",\n                                        row_seq_tensor.NumElements()));\n    OP_REQUIRES(context, col_seq_tensor.NumElements() > out_cols,\n                errors::InvalidArgument(\"Given out_backprop shape \",\n                                        out_backprop.shape().DebugString(),\n                                        \", col_seq_tensor must have at least \",\n                                        out_cols + 1, \" elements, but got \",\n                                        col_seq_tensor.NumElements()));\n\n    auto row_seq_tensor_flat = row_seq_tensor.flat<int64_t>();\n    auto col_seq_tensor_flat = col_seq_tensor.flat<int64_t>();\n    auto orig_input_tensor_shape_flat = orig_input_tensor_shape.flat<int64_t>();\n\n    const int64_t in_batch = orig_input_tensor_shape_flat(0);\n    const int64_t in_rows = orig_input_tensor_shape_flat(1);\n    const int64_t in_cols = orig_input_tensor_shape_flat(2);\n    const int64_t in_depth = orig_input_tensor_shape_flat(3);\n    OP_REQUIRES(\n        context, in_batch != 0,\n        errors::InvalidArgument(\"Batch dimension of input must not be 0\"));\n    OP_REQUIRES(\n        context, in_rows != 0,\n        errors::InvalidArgument(\"Rows dimension of input must not be 0\"));\n    OP_REQUIRES(\n        context, in_cols != 0,\n        errors::InvalidArgument(\"Columns dimension of input must not be 0\"));\n    OP_REQUIRES(\n        context, in_depth != 0,\n        errors::InvalidArgument(\"Depth dimension of input must not be 0\"));\n\n    constexpr int tensor_in_and_out_dims = 4;\n    // Transform orig_input_tensor_shape into TensorShape\n    TensorShape in_shape;\n    for (auto i = 0; i < tensor_in_and_out_dims; ++i) {\n      in_shape.AddDim(orig_input_tensor_shape_flat(i));\n    }\n\n    // Create intermediate in_backprop.\n    Tensor in_backprop_tensor_temp;\n    OP_REQUIRES_OK(context, context->forward_input_or_allocate_temp(\n                                {0}, DataTypeToEnum<double>::v(), in_shape,\n                                &in_backprop_tensor_temp));\n    in_backprop_tensor_temp.flat<double>().setZero();\n    // Transform 4D tensor to 2D matrix.\n    EigenDoubleMatrixMap in_backprop_tensor_temp_mat(\n        in_backprop_tensor_temp.flat<double>().data(), in_depth,\n        in_cols * in_rows * in_batch);\n    ConstEigenMatrixMap out_backprop_mat(out_backprop.flat<T>().data(),\n                                         out_depth,\n                                         out_cols * out_rows * out_batch);\n    // Loop through each element of out_backprop and evenly distribute the\n    // element to the corresponding pooling cell.\n    const int64_t in_max_row_index = in_rows - 1;\n    const int64_t in_max_col_index = in_cols - 1;\n    for (int64_t b = 0; b < out_batch; ++b) {\n      for (int64_t r = 0; r < out_rows; ++r) {\n        const int64_t in_row_start = row_seq_tensor_flat(r);\n        int64_t in_row_end = overlapping_ ? row_seq_tensor_flat(r + 1)\n                                          : row_seq_tensor_flat(r + 1) - 1;\n        in_row_end = std::min(in_row_end, in_max_row_index);\n        for (int64_t c = 0; c < out_cols; ++c) {\n          const int64_t in_col_start = col_seq_tensor_flat(c);\n          int64_t in_col_end = overlapping_ ? col_seq_tensor_flat(c + 1)\n                                            : col_seq_tensor_flat(c + 1) - 1;\n          in_col_end = std::min(in_col_end, in_max_col_index);\n\n          const int64_t num_elements_in_pooling_cell =\n              (in_row_end - in_row_start + 1) * (in_col_end - in_col_start + 1);\n          const int64_t out_index = (b * out_rows + r) * out_cols + c;\n          // Now we can evenly distribute out_backprop(b, h, w, *) to\n          // in_backprop(b, hs:he, ws:we, *).\n          for (int64_t in_r = in_row_start; in_r <= in_row_end; ++in_r) {\n            for (int64_t in_c = in_col_start; in_c <= in_col_end; ++in_c) {\n              const int64_t in_index = (b * in_rows + in_r) * in_cols + in_c;\n              // Walk through each channel (depth).\n              for (int64_t d = 0; d < out_depth; ++d) {\n                const double out_backprop_element = static_cast<double>(\n                    out_backprop_mat.coeffRef(d, out_index));\n                double& in_backprop_ref =\n                    in_backprop_tensor_temp_mat.coeffRef(d, in_index);\n                in_backprop_ref +=\n                    out_backprop_element / num_elements_in_pooling_cell;\n              }\n            }\n          }\n        }\n      }\n    }\n\n    // Depending on the type, cast double to type T.\n    Tensor* in_backprop_tensor = nullptr;\n    OP_REQUIRES_OK(context, context->forward_input_or_allocate_output(\n                                {0}, 0, in_shape, &in_backprop_tensor));\n    auto in_backprop_tensor_flat = in_backprop_tensor->flat<T>();\n    auto in_backprop_tensor_temp_flat = in_backprop_tensor_temp.flat<double>();\n    for (int64_t i = 0; i < in_backprop_tensor_flat.size(); ++i) {\n      in_backprop_tensor_flat(i) =\n          static_cast<T>(in_backprop_tensor_temp_flat(i));\n    }\n  }",
        "func_hash": 91555834572386312187860770421206034544,
        "file_name": "fractional_avg_pool_op.cc",
        "file_hash": 221866619851129952189561551151828727755,
        "cwe": [
            "CWE-125"
        ],
        "cve": "CVE-2022-21730",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The implementation of `FractionalAvgPoolGrad` does not consider cases where the input tensors are invalid allowing an attacker to read from outside of bounds of heap. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-21730",
        "func_name": "Compute",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 197318,
        "project": "tensorflow",
        "commit_id": "cff267650c6a1b266e4b4500f69fbc49cdd773c5",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/cff267650c6a1b266e4b4500f69fbc49cdd773c5",
        "commit_message": "Fix tf.raw_ops.DeleteSessionTensor vulnerability with invalid `handle`.\n\nCheck that `handle` input is actually a scalar before treating it as such.\n\nPiperOrigin-RevId: 445228994",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor& handle = ctx->input(0);\n    const string& name = handle.scalar<tstring>()();\n    auto session_state = ctx->session_state();\n    OP_REQUIRES(ctx, session_state != nullptr,\n                errors::FailedPrecondition(\n                    \"DeleteSessionTensor called on null session state\"));\n    OP_REQUIRES_OK(ctx, session_state->DeleteTensor(name));\n  }",
        "func_hash": 169160525191336828594160871802042029438,
        "file_name": "session_ops.cc",
        "file_hash": 314434656782851829699760158294919826764,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2022-29194",
        "cve_desc": "TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, the implementation of `tf.raw_ops.DeleteSessionTensor` does not fully validate the input arguments. This results in a `CHECK`-failure which can be used to trigger a denial of service attack. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-29194",
        "func_name": "Compute",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 197326,
        "project": "tensorflow",
        "commit_id": "f09caa532b6e1ac8d2aa61b7832c78c5b79300c6",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/f09caa532b6e1ac8d2aa61b7832c78c5b79300c6",
        "commit_message": "Fix EinsumHelper::ParseEquation to avoid uninitialized accesses.\n\nEinsumHelper::ParseEquation is supposed to return true or false in\ninput_has_ellipsis and output_has_ellipsis to indicate whether there is\nellipsis in the inputs and output. Previously, when there is no ellipsis in the\ninputs or output, the routine doesn't assign false to the variables. This\nchange initializes the two variables with false to fix the problem.\nPiperOrigin-RevId: 391772004\nChange-Id: I17b6c88aadef4131470378e48cced054bf252e86",
        "target": 1,
        "irrelevant": 1,
        "func_before": "  static Status ParseEquation(const string& equation,\n                              OperandLabels* input_labels,\n                              Labels* output_labels,\n                              std::vector<DimensionType>* label_types,\n                              OperandLabelCounts* input_label_counts,\n                              LabelCounts* output_label_counts,\n                              gtl::InlinedVector<bool, 2>* input_has_ellipsis,\n                              bool* output_has_ellipsis) {\n    gtl::InlinedVector<string, 2> input_str;\n    string output_str;\n    TF_RETURN_IF_ERROR(ParseEinsumEquation(equation, &input_str, &output_str));\n\n    // Temporary map from single character labels to (consecutive) integer\n    // labels.\n    absl::flat_hash_map<char, int> label_mapping;\n    int num_inputs = input_str.size();\n    input_labels->resize(num_inputs);\n\n    // Map from single characters to integer labels.\n    for (int i = 0; i < num_inputs; ++i) {\n      MapToLabels(input_str[i], &input_labels->at(i), &label_mapping);\n    }\n    MapToLabels(output_str, output_labels, &label_mapping);\n\n    // Compute counts for input and output labels.\n    int num_labels = label_mapping.size();\n    input_label_counts->resize(num_inputs);\n    input_has_ellipsis->resize(num_inputs);\n    for (int i = 0; i < num_inputs; ++i) {\n      input_label_counts->at(i).resize(num_labels);\n      for (const int label : input_labels->at(i)) {\n        if (label != kEllipsisLabel)\n          input_label_counts->at(i)[label] += 1;\n        else\n          input_has_ellipsis->at(i) = true;\n      }\n    }\n    output_label_counts->resize(num_labels);\n    for (const int label : *output_labels) {\n      if (label != kEllipsisLabel)\n        output_label_counts->at(label) += 1;\n      else\n        *output_has_ellipsis = true;\n    }\n\n    // Map each label to a unique DimensionType.\n    label_types->resize(num_labels);\n    for (int label = 0; label < num_labels; ++label) {\n      if (label == kEllipsisLabel) continue;\n      bool removed = (*output_label_counts)[label] == 0;\n      bool unique = num_inputs == 1 || (*input_label_counts)[0][label] == 0 ||\n                    (*input_label_counts)[1][label] == 0;\n      (*label_types)[label] = GetDimensionType(removed, unique);\n    }\n    return Status::OK();\n  }",
        "func_hash": 245883315476396879421677768643467596549,
        "file_name": "einsum_op_impl.h",
        "file_hash": 325930431028150928108252149027684363493,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2021-41201",
        "cve_desc": "TensorFlow is an open source platform for machine learning. In affeced versions during execution, `EinsumHelper::ParseEquation()` is supposed to set the flags in `input_has_ellipsis` vector and `*output_has_ellipsis` boolean to indicate whether there is ellipsis in the corresponding inputs and output. However, the code only changes these flags to `true` and never assigns `false`. This results in unitialized variable access if callers assume that `EinsumHelper::ParseEquation()` always sets these flags. The fix will be included in TensorFlow 2.7.0. We will also cherrypick this commit on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-41201",
        "func_name": "ParseEquation",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 197359,
        "project": "tensorflow",
        "commit_id": "68867bf01239d9e1048f98cbad185bf4761bedd3",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/68867bf01239d9e1048f98cbad185bf4761bedd3",
        "commit_message": "Prevent unitialized variable use in grappler.\n\nPiperOrigin-RevId: 399702928\nChange-Id: Id7e75451fbff297692dfb687f60ea04b25c96b24",
        "target": 1,
        "irrelevant": 1,
        "func_before": "Status AutoParallel::Initialize(const GrapplerItem& item) {\n  num_gpus_ = GetNumAvailableGPUs();\n  LOG(INFO) << \"Number of GPUs: \" << num_gpus_;\n  item_ = &item;\n  graph_ = item.graph;\n  LOG(INFO) << \"Original graph size: \" << graph_.node_size();\n  if (item.fetch.empty()) {\n    return Status(error::INVALID_ARGUMENT, \"No fetch nodes provided.\");\n  }\n\n  if (item.MainVariables().empty()) {\n    return Status(error::INVALID_ARGUMENT, \"No variables provided.\");\n  }\n\n  for (const auto& init : item.init_ops) {\n    VLOG(1) << \"Init node: \" << init;\n  }\n\n  for (const auto& fetch : item.fetch) {\n    VLOG(1) << \"Fetch node: \" << fetch;\n  }\n\n  for (const auto& var : item.MainVariables()) {\n    VLOG(2) << \"Variable: \" << var->name();\n  }\n\n  const std::set<string> apply_gradients_ops = {\"ApplyGradientDescent\",\n                                                \"ApplyProximalGradientDescent\",\n                                                \"ApplyAdadelta\",\n                                                \"ApplyAdagrad\",\n                                                \"ApplyProximalAdagrad\",\n                                                \"ApplyAdagradDA\",\n                                                \"ApplyFtrl\",\n                                                \"ApplyMomentum\",\n                                                \"ApplyAdam\",\n                                                \"ApplyRMSProp\",\n                                                \"ApplyCenteredRMSProp\"};\n  for (int i = 0; i < graph_.node_size(); i++) {\n    all_nodes_.insert(\n        std::make_pair(graph_.node(i).name(), graph_.mutable_node(i)));\n    if (apply_gradients_ops.find(graph_.node(i).op()) !=\n        apply_gradients_ops.end()) {\n      apply_gradients_nodes_.insert(graph_.node(i).name());\n      VLOG(2) << \"Apply gradients node: \" << graph_.node(i).name();\n    }\n  }\n\n  auto div_const_node = AddNodeDivConst();\n  all_nodes_.insert(std::make_pair(div_const_node->name(), div_const_node));\n  std::map<string, int> gradient_pos = {{\"ApplyGradientDescent\", 2},\n                                        {\"ApplyProximalGradientDescent\", 4},\n                                        {\"ApplyAdadelta\", 6},\n                                        {\"ApplyAdagrad\", 3},\n                                        {\"ApplyProximalAdagrad\", 5},\n                                        {\"ApplyAdagradDA\", 3},\n                                        {\"ApplyFtrl\", 3},\n                                        {\"ApplyMomentum\", 3},\n                                        {\"ApplyAdam\", 9},\n                                        {\"ApplyRMSProp\", 7},\n                                        {\"ApplyCenteredRMSProp\", 8}};\n  for (const auto& apply_gradient_node_name : apply_gradients_nodes_) {\n    auto apply_gradients_op = all_nodes_[apply_gradient_node_name]->op();\n    auto apply_gradients_node = all_nodes_[apply_gradient_node_name];\n\n    auto div_node = AddNodeDiv(\n        apply_gradient_node_name,\n        apply_gradients_node->input(gradient_pos[apply_gradients_op]),\n        div_const_node->name());\n    all_nodes_.insert(std::make_pair(div_node->name(), div_node));\n    *apply_gradients_node->mutable_input(gradient_pos[apply_gradients_op]) =\n        div_node->name();\n  }\n  LOG(INFO) << \"Graph size after adding div nodes: \" << all_nodes_.size();\n\n  std::vector<const NodeDef*> train_nodes;\n  TF_RETURN_IF_ERROR(ComputeTransitiveFanin(graph_, item.fetch, &train_nodes));\n  LOG(INFO) << \"Number of training nodes: \" << train_nodes.size();\n\n  const NodeDef* dequeue_node;\n  for (const auto& train_node : train_nodes) {\n    if (IsDequeueOp(*train_node)) {\n      dequeue_node = train_node;\n      break;\n    }\n  }\n\n  std::vector<const NodeDef*> input_nodes;\n  if (dequeue_node) {\n    LOG(INFO) << \"Dequeue node: \" << dequeue_node->name();\n    TF_RETURN_IF_ERROR(ComputeTransitiveFanin(graph_, {dequeue_node->name()},\n                                              {}, &input_nodes));\n  }\n  LOG(INFO) << \"Number of input nodes: \" << input_nodes.size();\n\n  std::set<string> dont_replicate_nodes;\n  for (const auto& variable : item.MainVariables()) {\n    dont_replicate_nodes.insert(variable->name());\n  }\n\n  for (const auto& init : item.init_ops) {\n    dont_replicate_nodes.insert(NodeName(init));\n  }\n\n  // Don't replicate all input nodes, except the dequeue node.\n  for (const auto& input_node : input_nodes) {\n    if (input_node->name() != dequeue_node->name()) {\n      dont_replicate_nodes.insert(input_node->name());\n    }\n  }\n\n  for (const auto& node : train_nodes) {\n    if (dont_replicate_nodes.find(node->name()) == dont_replicate_nodes.end()) {\n      replica_nodes_.insert(node->name());\n    }\n  }\n  LOG(INFO) << \"Number of replica nodes: \" << replica_nodes_.size();\n\n  for (const auto& node : all_nodes_) {\n    if (replica_nodes_.find(node.first) == replica_nodes_.end()) {\n      shared_nodes_.insert(node.first);\n    }\n  }\n  LOG(INFO) << \"Number of shared nodes: \" << shared_nodes_.size();\n  return Status::OK();\n}",
        "func_hash": 251567762309539032923316029186493191559,
        "file_name": "auto_parallel.cc",
        "file_hash": 291637818016549468794962575194747709507,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2021-41225",
        "cve_desc": "TensorFlow is an open source platform for machine learning. In affected versions TensorFlow's Grappler optimizer has a use of unitialized variable. If the `train_nodes` vector (obtained from the saved model that gets optimized) does not contain a `Dequeue` node, then `dequeue_node` is left unitialized. The fix will be included in TensorFlow 2.7.0. We will also cherrypick this commit on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-41225",
        "func_name": "AutoParallel::Initialize",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 197395,
        "project": "tensorflow",
        "commit_id": "4071d8e2f6c45c1955a811fee757ca2adbe462c1",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/4071d8e2f6c45c1955a811fee757ca2adbe462c1",
        "commit_message": "Fix FPE issue with `tf.raw_ops.Reverse`.\n\nPiperOrigin-RevId: 371176973\nChange-Id: Ic6d483bfc95313ec2299c2d1c956cfe96c96626c",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext* context) override {\n    const Tensor& input = context->input(0);\n    const Tensor& dims = context->input(1);\n\n    if (TensorShapeUtils::IsScalar(input.shape())) {\n      context->set_output(0, input);\n    } else {\n      const int input_dims = input.dims();\n      OP_REQUIRES(context, TensorShapeUtils::IsVector(dims.shape()),\n                  errors::InvalidArgument(\"'dims' must be 1-dimension, not \",\n                                          dims.dims()));\n\n      OP_REQUIRES(\n          context, input_dims == dims.dim_size(0),\n          errors::InvalidArgument(\n              \"'dims' must have the same number of values as 'input' has \"\n              \"dimensions. 'input' has \",\n              input_dims, \"'dims' has \", dims.dim_size(0), \" values\"));\n      OP_REQUIRES(context, input_dims <= 8,\n                  errors::Unimplemented(\n                      \"reverse is not implemented for tensors of rank > 8.\"));\n\n      Tensor* output = nullptr;\n      OP_REQUIRES_OK(context,\n                     context->allocate_output(0, input.shape(), &output));\n\n#define HANDLE_REVERSE(NDIMS)                                               \\\n  case NDIMS:                                                               \\\n    HandleReverseCase<Device, T, NDIMS>(context, dims.vec<bool>(), output); \\\n    return;\n\n      switch (input_dims) {\n        HANDLE_REVERSE(0);\n        HANDLE_REVERSE(1);\n        HANDLE_REVERSE(2);\n        HANDLE_REVERSE(3);\n        HANDLE_REVERSE(4);\n        HANDLE_REVERSE(5);\n        HANDLE_REVERSE(6);\n        HANDLE_REVERSE(7);\n        HANDLE_REVERSE(8);\n      }\n#undef HANDLE_REVERSE\n    }\n  }",
        "func_hash": 320359893140451578623172737965362672352,
        "file_name": "reverse_op.cc",
        "file_hash": 11850357512767152498311955295464965693,
        "cwe": [
            "CWE-369"
        ],
        "cve": "CVE-2021-29556",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. An attacker can cause a denial of service via a FPE runtime error in `tf.raw_ops.Reverse`. This is because the implementation(https://github.com/tensorflow/tensorflow/blob/36229ea9e9451dac14a8b1f4711c435a1d84a594/tensorflow/core/kernels/reverse_op.cc#L75-L76) performs a division based on the first dimension of the tensor argument. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-29556",
        "func_name": "Compute",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 197466,
        "project": "tensorflow",
        "commit_id": "9e82dce6e6bd1f36a57e08fa85af213e2b2f2622",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/9e82dce6e6bd1f36a57e08fa85af213e2b2f2622",
        "commit_message": "Fix NPE in restoring code.\n\nPiperOrigin-RevId: 388303253\nChange-Id: Ia8c68568cb854bca538909a182b31a618d68ce55",
        "target": 1,
        "irrelevant": 0,
        "func_before": "void RestoreTensor(OpKernelContext* context,\n                   checkpoint::TensorSliceReader::OpenTableFunction open_func,\n                   int preferred_shard, bool restore_slice, int restore_index) {\n  const Tensor& file_pattern_t = context->input(0);\n  {\n    const int64_t size = file_pattern_t.NumElements();\n    OP_REQUIRES(\n        context, size == 1,\n        errors::InvalidArgument(\n            \"Input 0 (file_pattern) must be a string scalar; got a tensor of \",\n            size, \"elements\"));\n  }\n  const string& file_pattern = file_pattern_t.flat<tstring>()(0);\n\n  const Tensor& tensor_name_t = context->input(1);\n  const string& tensor_name = tensor_name_t.flat<tstring>()(restore_index);\n\n  // If we cannot find a cached reader we will allocate our own.\n  std::unique_ptr<checkpoint::TensorSliceReader> allocated_reader;\n\n  const checkpoint::TensorSliceReader* reader = nullptr;\n\n  if (context->slice_reader_cache()) {\n    reader = context->slice_reader_cache()->GetReader(file_pattern, open_func,\n                                                      preferred_shard);\n  }\n  if (!reader) {\n    allocated_reader.reset(new checkpoint::TensorSliceReader(\n        file_pattern, open_func, preferred_shard));\n    reader = allocated_reader.get();\n  }\n  OP_REQUIRES_OK(context, CHECK_NOTNULL(reader)->status());\n\n  // Get the shape and type from the save file.\n  DataType type;\n  TensorShape saved_shape;\n  OP_REQUIRES(\n      context, reader->HasTensor(tensor_name, &saved_shape, &type),\n      errors::NotFound(\"Tensor name \\\"\", tensor_name,\n                       \"\\\" not found in checkpoint files \", file_pattern));\n  OP_REQUIRES(\n      context, type == context->expected_output_dtype(restore_index),\n      errors::InvalidArgument(\"Expected to restore a tensor of type \",\n                              DataTypeString(context->expected_output_dtype(0)),\n                              \", got a tensor of type \", DataTypeString(type),\n                              \" instead: tensor_name = \", tensor_name));\n\n  // Shape of the output and slice to load.\n  TensorShape output_shape(saved_shape);\n  TensorSlice slice_to_load(saved_shape.dims());\n  if (restore_slice) {\n    const tstring& shape_spec =\n        context->input(2).flat<tstring>()(restore_index);\n    if (!shape_spec.empty()) {\n      TensorShape parsed_shape;\n      OP_REQUIRES_OK(context, checkpoint::ParseShapeAndSlice(\n                                  shape_spec, &parsed_shape, &slice_to_load,\n                                  &output_shape));\n      OP_REQUIRES(\n          context, parsed_shape.IsSameSize(saved_shape),\n          errors::InvalidArgument(\n              \"Shape in shape_and_slice spec does not match the shape in the \"\n              \"save file: \",\n              parsed_shape.DebugString(),\n              \", save file shape: \", saved_shape.DebugString()));\n    }\n  }\n\n  Tensor* t = nullptr;\n  OP_REQUIRES_OK(context,\n                 context->allocate_output(restore_index, output_shape, &t));\n\n  if (output_shape.num_elements() == 0) return;\n\n#define READER_COPY(T)                                                \\\n  case DataTypeToEnum<T>::value:                                      \\\n    OP_REQUIRES(context,                                              \\\n                reader->CopySliceData(tensor_name, slice_to_load,     \\\n                                      t->flat<T>().data()),           \\\n                errors::InvalidArgument(\"Error copying slice data\")); \\\n    break;\n\n  switch (type) {\n    TF_CALL_SAVE_RESTORE_TYPES(READER_COPY)\n    default:\n      context->SetStatus(errors::Unimplemented(\n          \"Restoring data type \", DataTypeString(type), \" not yet supported\"));\n  }\n#undef READER_COPY\n}",
        "func_hash": 252467620619020665053463064048093339685,
        "file_name": "save_restore_tensor.cc",
        "file_hash": 5161981891248921294380940461341356456,
        "cwe": [
            "CWE-476"
        ],
        "cve": "CVE-2021-37639",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. When restoring tensors via raw APIs, if the tensor name is not provided, TensorFlow can be tricked into dereferencing a null pointer. Alternatively, attackers can read memory outside the bounds of heap allocated data by providing some tensor names but not enough for a successful restoration. The [implementation](https://github.com/tensorflow/tensorflow/blob/47a06f40411a69c99f381495f490536972152ac0/tensorflow/core/kernels/save_restore_tensor.cc#L158-L159) retrieves the tensor list corresponding to the `tensor_name` user controlled input and immediately retrieves the tensor at the restoration index (controlled via `preferred_shard` argument). This occurs without validating that the provided list has enough values. If the list is empty this results in dereferencing a null pointer (undefined behavior). If, however, the list has some elements, if the restoration index is outside the bounds this results in heap OOB read. We have patched the issue in GitHub commit 9e82dce6e6bd1f36a57e08fa85af213e2b2f2622. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37639",
        "func_name": "RestoreTensor",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 197499,
        "project": "gpac",
        "commit_id": "dc7de8d3d604426c7a6e628d90cb9fb88e7b4c2c",
        "project_url": "https://github.com/gpac/gpac",
        "commit_url": "https://github.com/gpac/gpac/commit/dc7de8d3d604426c7a6e628d90cb9fb88e7b4c2c",
        "commit_message": "fixed #2212",
        "target": 1,
        "irrelevant": 1,
        "func_before": "GF_Err BD_DecMFFieldVec(GF_BifsDecoder * codec, GF_BitStream *bs, GF_Node *node, GF_FieldInfo *field, Bool is_mem_com)\n{\n\tGF_Err e;\n\tu32 NbBits, nbFields;\n\tu32 i;\n\tGF_ChildNodeItem *last;\n\tu8 qp_local, qp_on, initial_qp;\n\tGF_FieldInfo sffield;\n\n\tmemset(&sffield, 0, sizeof(GF_FieldInfo));\n\tsffield.fieldIndex = field->fieldIndex;\n\tsffield.fieldType = gf_sg_vrml_get_sf_type(field->fieldType);\n\tsffield.NDTtype = field->NDTtype;\n\tsffield.name = field->name;\n\n\tinitial_qp = qp_local = qp_on = 0;\n\n\t//vector description - alloc the MF size before\n\tNbBits = gf_bs_read_int(bs, 5);\n\tnbFields = gf_bs_read_int(bs, NbBits);\n\n\tif (codec->ActiveQP) {\n\t\tinitial_qp = 1;\n\t\t/*this is for QP 14*/\n\t\tgf_bifs_dec_qp14_set_length(codec, nbFields);\n\t}\n\n\tif (field->fieldType != GF_SG_VRML_MFNODE) {\n\t\te = gf_sg_vrml_mf_alloc(field->far_ptr, field->fieldType, nbFields);\n\t\tif (e) return e;\n\n\t\tfor (i=0; i<nbFields; i++) {\n\t\t\te = gf_sg_vrml_mf_get_item(field->far_ptr, field->fieldType, & sffield.far_ptr, i);\n\t\t\tif (e) return e;\n\t\t\te = gf_bifs_dec_sf_field(codec, bs, node, &sffield, GF_FALSE);\n\t\t\tif (e) return e;\n\t\t}\n\t} else {\n\t\tlast = NULL;\n\t\tfor (i=0; i<nbFields; i++) {\n\t\t\tGF_Node *new_node = gf_bifs_dec_node(codec, bs, field->NDTtype);\n\t\t\tif (new_node) {\n\t\t\t\te = gf_node_register(new_node, is_mem_com ? NULL : node);\n\t\t\t\tif (e) return e;\n\n\t\t\t\tif (node) {\n\t\t\t\t\t/*special case for QP, register as the current QP*/\n\t\t\t\t\tif (gf_node_get_tag(new_node) == TAG_MPEG4_QuantizationParameter) {\n\t\t\t\t\t\tqp_local = ((M_QuantizationParameter *)new_node)->isLocal;\n\t\t\t\t\t\t/*we have a QP in the same scope, remove previous\n\t\t\t\t\t\tNB: we assume this is the right behavior, the spec doesn't say\n\t\t\t\t\t\twhether QP is cumulative or not*/\n\t\t\t\t\t\tif (qp_on) gf_bifs_dec_qp_remove(codec, GF_FALSE);\n\n\t\t\t\t\t\te = gf_bifs_dec_qp_set(codec, new_node);\n\t\t\t\t\t\tif (e) return e;\n\t\t\t\t\t\tqp_on = 1;\n\t\t\t\t\t\tif (qp_local) qp_local = 2;\n\t\t\t\t\t\tif (codec->force_keep_qp) {\n\t\t\t\t\t\t\te = gf_node_list_add_child_last(field->far_ptr, new_node, &last);\n\t\t\t\t\t\t\tif (e) return e;\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tgf_node_register(new_node, NULL);\n\t\t\t\t\t\t\tgf_node_unregister(new_node, node);\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\te = gf_node_list_add_child_last(field->far_ptr, new_node, &last);\n\t\t\t\t\t\tif (e) return e;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t/*proto coding*/\n\t\t\t\telse if (codec->pCurrentProto) {\n\t\t\t\t\t/*TO DO: what happens if this is a QP node on the interface ?*/\n\t\t\t\t\te = gf_node_list_add_child_last( (GF_ChildNodeItem **)field->far_ptr, new_node, &last);\n\t\t\t\t\tif (e) return e;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn codec->LastError ? codec->LastError : GF_NON_COMPLIANT_BITSTREAM;\n\t\t\t}\n\t\t}\n\t\t/*according to the spec, the QP applies to the current node itself, not just children.\n\t\tIf IsLocal is TRUE remove the node*/\n\t\tif (qp_on && qp_local) {\n\t\t\tif (qp_local == 2) {\n//\t\t\t\tqp_local = 1;\n\t\t\t} else {\n\t\t\t\t//ask to get rid of QP and reactivate if we had a QP when entering the node\n\t\t\t\tgf_bifs_dec_qp_remove(codec, initial_qp);\n//\t\t\t\tqp_local = 0;\n\t\t\t}\n\t\t}\n\t}\n\t/*finally delete the QP if any (local or not) as we get out of this node*/\n\tif (qp_on) gf_bifs_dec_qp_remove(codec, GF_TRUE);\n\treturn GF_OK;\n}",
        "func_hash": 181633592491715085539951152559525218380,
        "file_name": "field_decode.c",
        "file_hash": 27053036293524314453415412309723108309,
        "cwe": [
            "CWE-416"
        ],
        "cve": "CVE-2022-2453",
        "cve_desc": "Use After Free in GitHub repository gpac/gpac prior to 2.1-DEV.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-2453",
        "func_name": "BD_DecMFFieldVec",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 197511,
        "project": "libjpeg",
        "commit_id": "187035b9726710b4fe11d565c7808975c930895d",
        "project_url": "https://github.com/thorfdbg/libjpeg",
        "commit_url": "https://github.com/thorfdbg/libjpeg/commit/187035b9726710b4fe11d565c7808975c930895d",
        "commit_message": "The code now checks for consistency of the MCU sizes across\nhierarchical levels, and fails in case they are different.",
        "target": 1,
        "irrelevant": 1,
        "func_before": "void HierarchicalBitmapRequester::PrepareForDecoding(void)\n{\n#if ACCUSOFT_CODE\n\n  UBYTE i;\n\n  BuildCommon();\n\n  if (m_ppDecodingMCU == NULL) {\n    m_ppDecodingMCU = (struct Line **)m_pEnviron->AllocMem(sizeof(struct Line *) * m_ucCount*8);\n    memset(m_ppDecodingMCU,0,sizeof(struct Line *) * m_ucCount * 8);\n  }\n\n  if (m_ppUpsampler == NULL) {\n    m_ppUpsampler = (class UpsamplerBase **)m_pEnviron->AllocMem(sizeof(class UpsamplerBase *) * m_ucCount);\n    memset(m_ppUpsampler,0,sizeof(class Upsampler *) * m_ucCount);\n\n    for(i = 0;i < m_ucCount;i++) {\n      class Component *comp = m_pFrame->ComponentOf(i);\n      UBYTE sx = comp->SubXOf();\n      UBYTE sy = comp->SubYOf();\n\n      if (sx > 1 || sy > 1) {\n        m_ppUpsampler[i] = UpsamplerBase::CreateUpsampler(m_pEnviron,sx,sy,\n                                                          m_ulPixelWidth,m_ulPixelHeight,\n                                                          m_pFrame->TablesOf()->isChromaCentered());\n        m_bSubsampling   = true;\n      }\n    }\n  }\n\n  if (m_pLargestScale)\n    m_pLargestScale->PrepareForDecoding();\n#endif\n}",
        "func_hash": 63468052144489012470048601021040613418,
        "file_name": "hierarchicalbitmaprequester.cpp",
        "file_hash": 34345221108539770458549868924228630502,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2022-31796",
        "cve_desc": "libjpeg 1.63 has a heap-based buffer over-read in HierarchicalBitmapRequester::FetchRegion in hierarchicalbitmaprequester.cpp because the MCU size can be different between allocation and use.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-31796",
        "func_name": "HierarchicalBitmapRequester::PrepareForDecoding",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 197517,
        "project": "glewlwyd",
        "commit_id": "0efd112bb62f566877750ad62ee828bff579b4e2",
        "project_url": "https://github.com/babelouest/glewlwyd",
        "commit_url": "https://github.com/babelouest/glewlwyd/commit/0efd112bb62f566877750ad62ee828bff579b4e2",
        "commit_message": "Fix fido2 signature validation bug",
        "target": 1,
        "irrelevant": 1,
        "func_before": "static json_t * check_attestation_fido_u2f(json_t * j_params, unsigned char * credential_id, size_t credential_id_len, unsigned char * cert_x, size_t cert_x_len, unsigned char * cert_y, size_t cert_y_len, cbor_item_t * att_stmt, unsigned char * rpid_hash, size_t rpid_hash_len, const unsigned char * client_data) {\n  json_t * j_error = json_array(), * j_return;\n  cbor_item_t * key = NULL, * x5c = NULL, * sig = NULL, * att_cert = NULL;\n  int i, ret;\n  char * message = NULL;\n  gnutls_pubkey_t pubkey = NULL;\n  gnutls_x509_crt_t cert = NULL;\n  gnutls_datum_t cert_dat, data, signature, cert_issued_by;\n  unsigned char data_signed[200], client_data_hash[32], cert_export[32], cert_export_b64[64];\n  size_t data_signed_offset = 0, client_data_hash_len = 32, cert_export_len = 32, cert_export_b64_len = 0;\n  \n  if (j_error != NULL) {\n    do {\n      if (gnutls_x509_crt_init(&cert)) {\n        json_array_append_new(j_error, json_string(\"check_attestation_fido_u2f - Error gnutls_x509_crt_init\"));\n        break;\n      }\n      if (gnutls_pubkey_init(&pubkey)) {\n        json_array_append_new(j_error, json_string(\"check_attestation_fido_u2f - Error gnutls_pubkey_init\"));\n        break;\n      }\n      \n      // Step 1\n      if (att_stmt == NULL || !cbor_isa_map(att_stmt) || cbor_map_size(att_stmt) != 2) {\n        json_array_append_new(j_error, json_string(\"CBOR map value 'attStmt' invalid format\"));\n        break;\n      }\n      for (i=0; i<2; i++) {\n        key = cbor_map_handle(att_stmt)[i].key;\n        if (cbor_isa_string(key)) {\n          if (0 == o_strncmp((const char *)cbor_string_handle(key), \"x5c\", MIN(o_strlen(\"x5c\"), cbor_string_length(key)))) {\n            x5c = cbor_map_handle(att_stmt)[i].value;\n          } else if (0 == o_strncmp((const char *)cbor_string_handle(key), \"sig\", MIN(o_strlen(\"sig\"), cbor_string_length(key)))) {\n            sig = cbor_map_handle(att_stmt)[i].value;\n          } else {\n            message = msprintf(\"attStmt map element %d key is not valid: '%.*s'\", i, cbor_string_length(key), cbor_string_handle(key));\n            json_array_append_new(j_error, json_string(message));\n            o_free(message);\n            break;\n          }\n        } else {\n          message = msprintf(\"attStmt map element %d key is not a string\", i);\n          json_array_append_new(j_error, json_string(message));\n          o_free(message);\n          break;\n        }\n      }\n      if (x5c == NULL || !cbor_isa_array(x5c) || cbor_array_size(x5c) != 1) {\n        json_array_append_new(j_error, json_string(\"CBOR map value 'x5c' invalid format\"));\n        break;\n      }\n      att_cert = cbor_array_get(x5c, 0);\n      cert_dat.data = cbor_bytestring_handle(att_cert);\n      cert_dat.size = cbor_bytestring_length(att_cert);\n      if ((ret = gnutls_x509_crt_import(cert, &cert_dat, GNUTLS_X509_FMT_DER)) < 0) {\n        json_array_append_new(j_error, json_string(\"Error importing x509 certificate\"));\n        y_log_message(Y_LOG_LEVEL_DEBUG, \"check_attestation_fido_u2f - Error gnutls_pcert_import_x509_raw: %d\", ret);\n        break;\n      }\n      if (json_object_get(j_params, \"root-ca-list\") != json_null() && validate_certificate_from_root(j_params, cert, x5c) != G_OK) {\n        json_array_append_new(j_error, json_string(\"Unrecognized certificate authority\"));\n        if (gnutls_x509_crt_get_issuer_dn2(cert, &cert_issued_by) >= 0) {\n          message = msprintf(\"Unrecognized certificate autohority: %.*s\", cert_issued_by.size, cert_issued_by.data);\n          y_log_message(Y_LOG_LEVEL_DEBUG, \"check_attestation_fido_u2f - %s\", message);\n          o_free(message);\n          gnutls_free(cert_issued_by.data);\n        } else {\n          y_log_message(Y_LOG_LEVEL_DEBUG, \"check_attestation_fido_u2f - Unrecognized certificate autohority (unable to get issuer dn)\");\n        }\n        break;\n      }\n      if ((ret = gnutls_pubkey_import_x509(pubkey, cert, 0)) < 0) {\n        json_array_append_new(j_error, json_string(\"Error importing x509 certificate\"));\n        y_log_message(Y_LOG_LEVEL_DEBUG, \"check_attestation_fido_u2f - Error gnutls_pubkey_import_x509: %d\", ret);\n        break;\n      }\n      if ((ret = gnutls_x509_crt_get_key_id(cert, GNUTLS_KEYID_USE_SHA256, cert_export, &cert_export_len)) < 0) {\n        json_array_append_new(j_error, json_string(\"Error exporting x509 certificate\"));\n        y_log_message(Y_LOG_LEVEL_DEBUG, \"check_attestation_fido_u2f - Error gnutls_x509_crt_get_key_id: %d\", ret);\n        break;\n      }\n      if (!o_base64_encode(cert_export, cert_export_len, cert_export_b64, &cert_export_b64_len)) {\n        json_array_append_new(j_error, json_string(\"Internal error\"));\n        y_log_message(Y_LOG_LEVEL_DEBUG, \"check_attestation_fido_u2f - Error o_base64_encode cert_export\");\n        break;\n      }\n      if (!generate_digest_raw(digest_SHA256, client_data, o_strlen((char *)client_data), client_data_hash, &client_data_hash_len)) {\n        json_array_append_new(j_error, json_string(\"Internal error\"));\n        y_log_message(Y_LOG_LEVEL_ERROR, \"check_attestation_fido_u2f - Error generate_digest_raw client_data\");\n        break;\n      }\n\n      if (sig == NULL || !cbor_isa_bytestring(sig)) {\n        json_array_append_new(j_error, json_string(\"Error sig is not a bytestring\"));\n        break;\n      }\n      \n      // Build bytestring to verify signature\n      data_signed[0] = 0x0;\n      data_signed_offset = 1;\n      \n      memcpy(data_signed+data_signed_offset, rpid_hash, rpid_hash_len);\n      data_signed_offset += rpid_hash_len;\n      \n      memcpy(data_signed+data_signed_offset, client_data_hash, client_data_hash_len);\n      data_signed_offset+=client_data_hash_len;\n      \n      memcpy(data_signed+data_signed_offset, credential_id, credential_id_len);\n      data_signed_offset+=credential_id_len;\n      \n      data_signed[data_signed_offset] = 0x04;\n      data_signed_offset++;\n      \n      memcpy(data_signed+data_signed_offset, cert_x, cert_x_len);\n      data_signed_offset+=cert_x_len;\n      \n      memcpy(data_signed+data_signed_offset, cert_y, cert_y_len);\n      data_signed_offset+=cert_y_len;\n        \n      // Let's verify sig over data_signed\n      data.data = data_signed;\n      data.size = data_signed_offset;\n      \n      signature.data = cbor_bytestring_handle(sig);\n      signature.size = cbor_bytestring_length(sig);\n      \n      if (gnutls_pubkey_verify_data2(pubkey, GNUTLS_SIGN_ECDSA_SHA256, 0, &data, &signature)) {\n        json_array_append_new(j_error, json_string(\"Invalid signature\"));\n      }\n      \n    } while (0);\n    \n    if (json_array_size(j_error)) {\n      j_return = json_pack(\"{sisO}\", \"result\", G_ERROR_PARAM, \"error\", j_error);\n    } else {\n      j_return = json_pack(\"{sis{ss%}}\", \"result\", G_OK, \"data\", \"certificate\", cert_export_b64, cert_export_b64_len);\n    }\n    json_decref(j_error);\n    gnutls_pubkey_deinit(pubkey);\n    gnutls_x509_crt_deinit(cert);\n    if (att_cert != NULL) {\n      cbor_decref(&att_cert);\n    }\n    \n  } else {\n    y_log_message(Y_LOG_LEVEL_ERROR, \"check_attestation_fido_u2f - Error allocating resources for j_error\");\n    j_return = json_pack(\"{si}\", \"result\", G_ERROR);\n  }\n  return j_return;\n}",
        "func_hash": 49651774096588820525757021354786445533,
        "file_name": "webauthn.c",
        "file_hash": 936897033794891929844876941061119587,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2021-40818",
        "cve_desc": "scheme/webauthn.c in Glewlwyd SSO server through 2.5.3 has a buffer overflow during FIDO2 signature validation in webauthn registration.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-40818",
        "func_name": "check_attestation_fido_u2f",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 197518,
        "project": "tensorflow",
        "commit_id": "098e7762d909bac47ce1dbabe6dfd06294cb9d58",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/098e7762d909bac47ce1dbabe6dfd06294cb9d58",
        "commit_message": "Fix tf.raw_ops.QuantizeAndDequantizeV4Grad vulnerability with invalid input_min or input_max.\n\nCheck that argument is actually a scalar before treating it as such.\n\nPiperOrigin-RevId: 445198280",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor& gradient = ctx->input(0);\n    const Tensor& input = ctx->input(1);\n    Tensor* input_backprop = nullptr;\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_output(0, input.shape(), &input_backprop));\n    OP_REQUIRES(\n        ctx, axis_ >= -1,\n        errors::InvalidArgument(\"Axis must be at least -1. Found \", axis_));\n    OP_REQUIRES(ctx, (axis_ == -1 || axis_ < input.shape().dims()),\n                errors::InvalidArgument(\n                    \"Axis should be -1 or 0 or a positive value less than \",\n                    input.shape().dims(), \"but given axis value was \", axis_));\n\n    OP_REQUIRES(\n        ctx, input.IsSameSize(gradient),\n        errors::InvalidArgument(\"gradient and input must be the same size\"));\n    const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);\n    const Tensor& input_min_tensor = ctx->input(2);\n    OP_REQUIRES(ctx,\n                input_min_tensor.dims() == 0 || input_min_tensor.dims() == 1,\n                errors::InvalidArgument(\n                    \"Input min tensor must have dimension 1. Recieved \",\n                    input_min_tensor.dims(), \".\"));\n    const Tensor& input_max_tensor = ctx->input(3);\n    OP_REQUIRES(ctx,\n                input_max_tensor.dims() == 0 || input_max_tensor.dims() == 1,\n                errors::InvalidArgument(\n                    \"Input max tensor must have dimension 1. Recieved \",\n                    input_max_tensor.dims(), \".\"));\n    if (axis_ != -1) {\n      OP_REQUIRES(\n          ctx, input_min_tensor.dim_size(0) == depth,\n          errors::InvalidArgument(\"min has incorrect size, expected \", depth,\n                                  \" was \", input_min_tensor.dim_size(0)));\n      OP_REQUIRES(\n          ctx, input_max_tensor.dim_size(0) == depth,\n          errors::InvalidArgument(\"max has incorrect size, expected \", depth,\n                                  \" was \", input_max_tensor.dim_size(0)));\n    }\n\n    TensorShape min_max_shape(input_min_tensor.shape());\n    Tensor* input_min_backprop;\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_output(1, min_max_shape, &input_min_backprop));\n\n    Tensor* input_max_backprop;\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_output(2, min_max_shape, &input_max_backprop));\n\n    if (axis_ == -1) {\n      functor::QuantizeAndDequantizeOneScaleGradientFunctor<Device, T> f;\n      f(ctx->eigen_device<Device>(), gradient.template flat<T>(),\n        input.template flat<T>(), input_min_tensor.scalar<T>(),\n        input_max_tensor.scalar<T>(), input_backprop->template flat<T>(),\n        input_min_backprop->template scalar<T>(),\n        input_max_backprop->template scalar<T>());\n    } else {\n      functor::QuantizeAndDequantizePerChannelGradientFunctor<Device, T> f;\n      f(ctx->eigen_device<Device>(),\n        gradient.template flat_inner_outer_dims<T, 3>(axis_ - 1),\n        input.template flat_inner_outer_dims<T, 3>(axis_ - 1),\n        &input_min_tensor, &input_max_tensor,\n        input_backprop->template flat_inner_outer_dims<T, 3>(axis_ - 1),\n        input_min_backprop->template flat<T>(),\n        input_max_backprop->template flat<T>());\n    }\n  }",
        "func_hash": 234673676615434385684756936171703208879,
        "file_name": "quantize_and_dequantize_op.cc",
        "file_hash": 339380707229520344979853528458088260159,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2022-29192",
        "cve_desc": "TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, the implementation of `tf.raw_ops.QuantizeAndDequantizeV4Grad` does not fully validate the input arguments. This results in a `CHECK`-failure which can be used to trigger a denial of service attack. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-29192",
        "func_name": "Compute",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 197565,
        "project": "wolfMQTT",
        "commit_id": "84d4b53122e0fa0280c7872350b89d5777dabbb2",
        "project_url": "https://github.com/wolfSSL/wolfMQTT",
        "commit_url": "https://github.com/wolfSSL/wolfMQTT/commit/84d4b53122e0fa0280c7872350b89d5777dabbb2",
        "commit_message": "Fix wolfmqtt-fuzzer: Null-dereference WRITE in MqttProps_Free",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static int MqttClient_WaitType(MqttClient *client, void *packet_obj,\n    byte wait_type, word16 wait_packet_id, int timeout_ms)\n{\n    int rc;\n    word16 packet_id;\n    MqttPacketType packet_type;\n#ifdef WOLFMQTT_MULTITHREAD\n    MqttPendResp *pendResp;\n    int readLocked;\n#endif\n    MqttMsgStat* mms_stat;\n    int waitMatchFound;\n\n    if (client == NULL || packet_obj == NULL) {\n        return MQTT_CODE_ERROR_BAD_ARG;\n    }\n\n    /* all packet type structures must have MqttMsgStat at top */\n    mms_stat = (MqttMsgStat*)packet_obj;\n\nwait_again:\n\n    /* initialize variables */\n    packet_id = 0;\n    packet_type = MQTT_PACKET_TYPE_RESERVED;\n#ifdef WOLFMQTT_MULTITHREAD\n    pendResp = NULL;\n    readLocked = 0;\n#endif\n    waitMatchFound = 0;\n\n#ifdef WOLFMQTT_DEBUG_CLIENT\n    PRINTF(\"MqttClient_WaitType: Type %s (%d), ID %d\",\n        MqttPacket_TypeDesc((MqttPacketType)wait_type),\n            wait_type, wait_packet_id);\n#endif\n\n    switch ((int)*mms_stat)\n    {\n        case MQTT_MSG_BEGIN:\n        {\n        #ifdef WOLFMQTT_MULTITHREAD\n            /* Lock recv socket mutex */\n            rc = wm_SemLock(&client->lockRecv);\n            if (rc != 0) {\n                PRINTF(\"MqttClient_WaitType: recv lock error!\");\n                return rc;\n            }\n            readLocked = 1;\n        #endif\n\n            /* reset the packet state */\n            client->packet.stat = MQTT_PK_BEGIN;\n        }\n        FALL_THROUGH;\n\n    #ifdef WOLFMQTT_V5\n        case MQTT_MSG_AUTH:\n    #endif\n        case MQTT_MSG_WAIT:\n        {\n        #ifdef WOLFMQTT_MULTITHREAD\n            /* Check to see if packet type and id have already completed */\n            pendResp = NULL;\n            rc = wm_SemLock(&client->lockClient);\n            if (rc == 0) {\n                if (MqttClient_RespList_Find(client, (MqttPacketType)wait_type, \n                    wait_packet_id, &pendResp)) {\n                    if (pendResp->packetDone) {\n                        /* pending response is already done, so return */\n                        rc = pendResp->packet_ret;\n                    #ifdef WOLFMQTT_DEBUG_CLIENT\n                        PRINTF(\"PendResp already Done %p: Rc %d\", pendResp, rc);\n                    #endif\n                        MqttClient_RespList_Remove(client, pendResp);\n                        wm_SemUnlock(&client->lockClient);\n                        wm_SemUnlock(&client->lockRecv);\n                        return rc;\n                    }\n                }\n                wm_SemUnlock(&client->lockClient);\n            }\n            else {\n                break; /* error */\n            }\n        #endif /* WOLFMQTT_MULTITHREAD */\n\n            *mms_stat = MQTT_MSG_WAIT;\n\n            /* Wait for packet */\n            rc = MqttPacket_Read(client, client->rx_buf, client->rx_buf_len,\n                    timeout_ms);\n            /* handle failure */\n            if (rc <= 0) {\n                break;\n            }\n\n            /* capture length read */\n            client->packet.buf_len = rc;\n\n            /* Decode Packet - get type and id */\n            rc = MqttClient_DecodePacket(client, client->rx_buf,\n                client->packet.buf_len, NULL, &packet_type, NULL, &packet_id);\n            if (rc < 0) {\n                break;\n            }\n\n        #ifdef WOLFMQTT_DEBUG_CLIENT\n            PRINTF(\"Read Packet: Len %d, Type %d, ID %d\",\n                client->packet.buf_len, packet_type, packet_id);\n        #endif\n\n            *mms_stat = MQTT_MSG_READ;\n        }\n        FALL_THROUGH;\n\n        case MQTT_MSG_READ:\n        case MQTT_MSG_READ_PAYLOAD:\n        {\n            MqttPacketType use_packet_type;\n            void* use_packet_obj;\n\n        #ifdef WOLFMQTT_MULTITHREAD\n            readLocked = 1; /* if in this state read is locked */\n        #endif\n\n            /* read payload state only happens for publish messages */\n            if (*mms_stat == MQTT_MSG_READ_PAYLOAD) {\n                packet_type = MQTT_PACKET_TYPE_PUBLISH;\n            }\n\n            /* Determine if we received data for this request */\n            if ((wait_type == MQTT_PACKET_TYPE_ANY ||\n                 wait_type == packet_type ||\n                 MqttIsPubRespPacket(packet_type) == MqttIsPubRespPacket(wait_type)) &&\n               (wait_packet_id == 0 || wait_packet_id == packet_id))\n            {\n                use_packet_obj = packet_obj;\n                waitMatchFound = 1;\n            }\n            else {\n                /* use generic packet object */\n                use_packet_obj = &client->msg;\n            }\n            use_packet_type = packet_type;\n\n        #ifdef WOLFMQTT_MULTITHREAD\n            /* Check to see if we have a pending response for this packet */\n            pendResp = NULL;\n            rc = wm_SemLock(&client->lockClient);\n            if (rc == 0) {\n                if (MqttClient_RespList_Find(client, packet_type, packet_id,\n                                                               &pendResp)) {\n                    /* we found packet match this incoming read packet */\n                    pendResp->packetProcessing = 1;\n                    use_packet_obj = pendResp->packet_obj;\n                    use_packet_type = pendResp->packet_type;\n                    /* req from another thread... not a match */\n                    waitMatchFound = 0;\n                }\n                wm_SemUnlock(&client->lockClient);\n            }\n            else {\n                break; /* error */\n            }\n        #endif /* WOLFMQTT_MULTITHREAD */\n\n            /* Perform packet handling for publish callback and QoS */\n            rc = MqttClient_HandlePacket(client, use_packet_type,\n                use_packet_obj, timeout_ms);\n\n        #ifdef WOLFMQTT_NONBLOCK\n            if (rc == MQTT_CODE_CONTINUE) {\n                /* we have received some data, so keep the recv\n                    mutex lock active and return */\n                return rc;\n            }\n        #endif\n\n            /* handle success case */\n            if (rc >= 0) {\n                rc = MQTT_CODE_SUCCESS;\n            }\n\n        #ifdef WOLFMQTT_MULTITHREAD\n            if (pendResp) {\n                /* Mark pending response entry done */\n                if (wm_SemLock(&client->lockClient) == 0) {\n                    pendResp->packetDone = 1;\n                    pendResp->packet_ret = rc;\n                #ifdef WOLFMQTT_DEBUG_CLIENT\n                    PRINTF(\"PendResp Done %p\", pendResp);\n                #endif\n                    pendResp = NULL;\n                    wm_SemUnlock(&client->lockClient);\n                }\n            }\n        #endif /* WOLFMQTT_MULTITHREAD */\n            break;\n        }\n\n        case MQTT_MSG_WRITE:\n        case MQTT_MSG_WRITE_PAYLOAD:\n        default:\n        {\n        #ifdef WOLFMQTT_DEBUG_CLIENT\n            PRINTF(\"MqttClient_WaitType: Invalid state %d!\", *mms_stat);\n        #endif\n            rc = MQTT_CODE_ERROR_STAT;\n            break;\n        }\n    } /* switch (*mms_stat) */\n\n#ifdef WOLFMQTT_NONBLOCK\n    if (rc != MQTT_CODE_CONTINUE)\n#endif\n    {\n        /* reset state */\n        *mms_stat = MQTT_MSG_BEGIN;\n    }\n\n#ifdef WOLFMQTT_MULTITHREAD\n    if (readLocked) {\n        wm_SemUnlock(&client->lockRecv);\n    }\n#endif\n    if (rc < 0) {\n    #ifdef WOLFMQTT_DEBUG_CLIENT\n        PRINTF(\"MqttClient_WaitType: Failure: %s (%d)\",\n            MqttClient_ReturnCodeToString(rc), rc);\n    #endif\n        return rc;\n    }\n\n    if (!waitMatchFound) {\n        /* if we get here, then the we are still waiting for a packet */\n        goto wait_again;\n    }\n\n    return rc;\n}",
        "func_hash": 2988390772969394657723865827973366134,
        "file_name": "mqtt_client.c",
        "file_hash": 187905589318508952285873561463064501412,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2021-45936",
        "cve_desc": "wolfSSL wolfMQTT 1.9 has a heap-based buffer overflow in MqttDecode_Disconnect (called from MqttClient_DecodePacket and MqttClient_WaitType).",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-45936",
        "func_name": "MqttClient_WaitType",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 197593,
        "project": "njs",
        "commit_id": "ad48705bf1f04b4221a5f5b07715ac48b3160d53",
        "project_url": "https://github.com/nginx/njs",
        "commit_url": "https://github.com/nginx/njs/commit/ad48705bf1f04b4221a5f5b07715ac48b3160d53",
        "commit_message": "Fixed frame allocation from an awaited frame.\n\nnjs_function_frame_save() is used to save the awaited frame when \"await\"\ninstruction is encountered. The saving was done as a memcpy() of\nexisting runtime frame.\n\nnjs_function_frame_alloc() is used to alloc a new function frame, this\nfunction tries to use a spare preallocated memory from the previous\nframe first.  Previously, this function might result in \"use-after-free\"\nwhen invoked from a restored frame saved with njs_function_frame_save().\nBecause njs_function_frame_save() left pointers to the spare memory of\nthe original frame which may be already free when saved frame is\nrestored.\n\nThe fix is to erase fields for the spare memory from the saved frame.\n\nThis closes #469 issue on Github.",
        "target": 1,
        "irrelevant": 1,
        "func_before": "njs_function_frame_save(njs_vm_t *vm, njs_frame_t *frame, u_char *pc)\n{\n    size_t              value_count, n;\n    njs_value_t         *start, *end, *p, **new, *value, **local;\n    njs_function_t      *function;\n    njs_native_frame_t  *active, *native;\n\n    *frame = *vm->active_frame;\n    frame->previous_active_frame = NULL;\n\n    native = &frame->native;\n\n    active = &vm->active_frame->native;\n    value_count = njs_function_frame_value_count(active);\n\n    function = active->function;\n\n    new = (njs_value_t **) ((u_char *) native + NJS_FRAME_SIZE);\n    value = (njs_value_t *) (new + value_count\n                             + function->u.lambda->temp);\n\n\n    native->arguments = value;\n    native->arguments_offset = value + (function->args_offset - 1);\n    native->local = new + njs_function_frame_args_count(active);\n    native->temp = new + value_count;\n    native->pc = pc;\n\n    start = njs_function_frame_values(active, &end);\n    p = native->arguments;\n\n    while (start < end) {\n        *p = *start++;\n        *new++ = p++;\n    }\n\n    /* Move all arguments. */\n\n    p = native->arguments;\n    local = native->local + function->args_offset;\n\n    for (n = 0; n < function->args_count; n++) {\n        if (!njs_is_valid(p)) {\n            njs_set_undefined(p);\n        }\n\n        *local++ = p++;\n    }\n\n    return NJS_OK;\n}",
        "func_hash": 163196677430813133926152837345587363595,
        "file_name": "njs_function.c",
        "file_hash": 84952023387586829721392975850477495397,
        "cwe": [
            "CWE-416"
        ],
        "cve": "CVE-2022-27007",
        "cve_desc": "nginx njs 0.7.2 is affected suffers from Use-after-free in njs_function_frame_alloc() when it try to invoke from a restored frame saved with njs_function_frame_save().",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-27007",
        "func_name": "njs_function_frame_save",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 197615,
        "project": "tensorflow",
        "commit_id": "abcced051cb1bd8fb05046ac3b6023a7ebcc4578",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/abcced051cb1bd8fb05046ac3b6023a7ebcc4578",
        "commit_message": "Prevent crashes when loading tensor slices with unsupported types.\n\nAlso fix the `Tensor(const TensorShape&)` constructor swapping the LOG(FATAL)\nmessages for the unset and unsupported types.\n\nPiperOrigin-RevId: 392695027\nChange-Id: I4beda7db950db951d273e3259a7c8534ece49354",
        "target": 1,
        "irrelevant": 0,
        "func_before": "Status TensorSliceReader::GetTensor(\n    const string& name, std::unique_ptr<tensorflow::Tensor>* out_tensor) const {\n  DataType type;\n  TensorShape shape;\n  TensorSlice slice;\n  {\n    mutex_lock l(mu_);\n    const TensorSliceSet* tss = gtl::FindPtrOrNull(tensors_, name);\n    if (tss == nullptr) {\n      return errors::NotFound(name, \" not found in checkpoint file\");\n    }\n\n    if (tss->Slices().size() > 1) {\n      // TODO(sherrym): Support multi-slice checkpoints.\n      return errors::Unimplemented(\"Sliced checkpoints are not supported\");\n    }\n\n    type = tss->type();\n    shape = tss->shape();\n    slice = tss->Slices().begin()->second.slice;\n  }\n\n  std::unique_ptr<tensorflow::Tensor> t(new tensorflow::Tensor(type, shape));\n  bool success = false;\n\n#define READER_COPY(dt)                                                  \\\n  case dt:                                                               \\\n    success = CopySliceData(name, slice,                                 \\\n                            t->flat<EnumToDataType<dt>::Type>().data()); \\\n    break;\n\n  switch (type) {\n    READER_COPY(DT_FLOAT);\n    READER_COPY(DT_DOUBLE);\n    READER_COPY(DT_INT32);\n    READER_COPY(DT_UINT8);\n    READER_COPY(DT_INT16);\n    READER_COPY(DT_INT8);\n    READER_COPY(DT_INT64);\n    READER_COPY(DT_STRING);\n    default:\n      return errors::Unimplemented(\"Data type not supported\");\n  }\n#undef READER_COPY\n\n  if (!success) {\n    return errors::NotFound(name, \" not found in checkpoint file\");\n  }\n  std::swap(*out_tensor, t);\n\n  return Status::OK();\n}",
        "func_hash": 280007427282291482813273164813512992579,
        "file_name": "tensor_slice_reader.cc",
        "file_hash": 18697630540874284571835582575505228006,
        "cwe": [
            "CWE-345"
        ],
        "cve": "CVE-2021-41203",
        "cve_desc": "TensorFlow is an open source platform for machine learning. In affected versions an attacker can trigger undefined behavior, integer overflows, segfaults and `CHECK`-fail crashes if they can change saved checkpoints from outside of TensorFlow. This is because the checkpoints loading infrastructure is missing validation for invalid file formats. The fixes will be included in TensorFlow 2.7.0. We will also cherrypick these commits on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-41203",
        "func_name": "TensorSliceReader::GetTensor",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 197621,
        "project": "tensorflow",
        "commit_id": "e84c975313e8e8e38bb2ea118196369c45c51378",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/e84c975313e8e8e38bb2ea118196369c45c51378",
        "commit_message": "In tf.raw_ops.BoostedTreesSparseCalculateBestFeatureSplit, limit stat_dim in stats_summary_indices to under stats_dims in stats_summary_shape\n\nPiperOrigin-RevId: 387171191\nChange-Id: I83ca8a75b22aa78c037e8b98779da6cced16bfaa",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext* const context) override {\n    // node_id_range\n    const Tensor* node_id_range_t;\n    OP_REQUIRES_OK(context, context->input(\"node_id_range\", &node_id_range_t));\n    const auto node_id_range = node_id_range_t->vec<int32>();\n    const int32_t node_id_first = node_id_range(0);  // inclusive\n    const int32_t node_id_last = node_id_range(1);   // exclusive\n\n    const Tensor* stats_summary_indices_t;\n    OP_REQUIRES_OK(context, context->input(\"stats_summary_indices\",\n                                           &stats_summary_indices_t));\n    const auto stats_summary_indices = stats_summary_indices_t->matrix<int32>();\n    const int32_t num_sparse_entries = stats_summary_indices_t->dim_size(0);\n\n    const Tensor* stats_summary_values_t;\n    OP_REQUIRES_OK(context, context->input(\"stats_summary_values\",\n                                           &stats_summary_values_t));\n    const auto stats_summary_values = stats_summary_values_t->vec<float>();\n\n    const Tensor* stats_summary_shape_t;\n    OP_REQUIRES_OK(\n        context, context->input(\"stats_summary_shape\", &stats_summary_shape_t));\n    const auto stats_summary_shape = stats_summary_shape_t->vec<int32>();\n    const int32_t num_buckets = stats_summary_shape(2) - 1;\n    const int32_t stats_dims = stats_summary_shape(3);\n\n    const Tensor* l1_t;\n    OP_REQUIRES_OK(context, context->input(\"l1\", &l1_t));\n    const auto l1 = l1_t->scalar<float>()();\n\n    const Tensor* l2_t;\n    OP_REQUIRES_OK(context, context->input(\"l2\", &l2_t));\n    const auto l2 = l2_t->scalar<float>()();\n\n    const Tensor* tree_complexity_t;\n    OP_REQUIRES_OK(context,\n                   context->input(\"tree_complexity\", &tree_complexity_t));\n    const auto tree_complexity = tree_complexity_t->scalar<float>()();\n\n    const Tensor* min_node_weight_t;\n    OP_REQUIRES_OK(context,\n                   context->input(\"min_node_weight\", &min_node_weight_t));\n    const auto min_node_weight = min_node_weight_t->scalar<float>()();\n\n    std::vector<int32> output_node_ids;\n    std::vector<float> output_gains;\n    std::vector<int32> output_feature_dimensions;\n    std::vector<int32> output_thresholds;\n    std::vector<float> output_left_node_contribs;\n    std::vector<float> output_right_node_contribs;\n    std::vector<string> output_split_types;\n\n    FeatureMap f_map;\n\n    int32_t previous_node_id = -1;\n    for (int idx = 0; idx < num_sparse_entries; ++idx) {\n      int32_t node_id = stats_summary_indices(idx, 0);\n      if (node_id != previous_node_id) {\n        process_node(f_map, &output_node_ids, &output_gains,\n                     &output_feature_dimensions, &output_thresholds,\n                     &output_left_node_contribs, &output_right_node_contribs,\n                     &output_split_types, previous_node_id, min_node_weight, l1,\n                     l2, num_buckets);\n        f_map.clear();\n      }\n      previous_node_id = node_id;\n      DCHECK_LE(node_id_first, node_id);\n      DCHECK_LT(node_id, node_id_last);\n      const int32_t feature_dim = stats_summary_indices(idx, 1);\n      const int32_t bucket_id = stats_summary_indices(idx, 2);\n      const int32_t stat_dim = stats_summary_indices(idx, 3);\n      std::pair<FeatureMapIterator, bool> const& f_insert_result = f_map.insert(\n          FeatureMapIterator::value_type(feature_dim, BucketMap()));\n      auto& b_map = f_insert_result.first->second;\n      std::pair<BucketMapIterator, bool> const& b_insert_result =\n          b_map.insert(BucketMapIterator::value_type(\n              bucket_id, std::vector<float>(stats_dims)));\n      auto& stats = b_insert_result.first->second;\n      stats[stat_dim] = stats_summary_values(idx);\n    }  // for node_id\n    // process the last node id\n    process_node(f_map, &output_node_ids, &output_gains,\n                 &output_feature_dimensions, &output_thresholds,\n                 &output_left_node_contribs, &output_right_node_contribs,\n                 &output_split_types, previous_node_id, min_node_weight, l1, l2,\n                 num_buckets);\n\n    const int num_nodes = output_node_ids.size();\n    // output_node_ids\n    Tensor* output_node_ids_t = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(\"node_ids\", {num_nodes},\n                                                     &output_node_ids_t));\n    auto output_node_ids_vec = output_node_ids_t->vec<int32>();\n\n    // output_gains\n    Tensor* output_gains_t;\n    OP_REQUIRES_OK(context, context->allocate_output(\"gains\", {num_nodes},\n                                                     &output_gains_t));\n    auto output_gains_vec = output_gains_t->vec<float>();\n\n    // output_feature_dimensions\n    Tensor* output_feature_dimension_t;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(\"feature_dimensions\", {num_nodes},\n                                            &output_feature_dimension_t));\n    auto output_feature_dimensions_vec =\n        output_feature_dimension_t->vec<int32>();\n\n    // output_thresholds\n    Tensor* output_thresholds_t;\n    OP_REQUIRES_OK(context, context->allocate_output(\"thresholds\", {num_nodes},\n                                                     &output_thresholds_t));\n    auto output_thresholds_vec = output_thresholds_t->vec<int32>();\n\n    // output_left_node_contribs\n    Tensor* output_left_node_contribs_t;\n    OP_REQUIRES_OK(\n        context, context->allocate_output(\"left_node_contribs\", {num_nodes, 1},\n                                          &output_left_node_contribs_t));\n    auto output_left_node_contribs_matrix =\n        output_left_node_contribs_t->matrix<float>();\n\n    // output_right_node_contribs\n    Tensor* output_right_node_contribs_t;\n    OP_REQUIRES_OK(\n        context, context->allocate_output(\"right_node_contribs\", {num_nodes, 1},\n                                          &output_right_node_contribs_t));\n    auto output_right_node_contribs_matrix =\n        output_right_node_contribs_t->matrix<float>();\n\n    // split type\n    Tensor* output_split_types_t;\n    OP_REQUIRES_OK(\n        context, context->allocate_output(\"split_with_default_directions\",\n                                          {num_nodes}, &output_split_types_t));\n    auto output_split_types_vec = output_split_types_t->vec<tstring>();\n\n    // Sets output tensors from vectors.\n    for (int i = 0; i < num_nodes; ++i) {\n      output_node_ids_vec(i) = output_node_ids[i];\n      // Adjust the gains to penalize by tree complexity.\n      output_gains_vec(i) = output_gains[i] - tree_complexity;\n      output_feature_dimensions_vec(i) = output_feature_dimensions[i];\n      output_thresholds_vec(i) = output_thresholds[i];\n      // TODO(crawles): change this for multi-class.\n      output_left_node_contribs_matrix(i, 0) = output_left_node_contribs[i];\n      output_right_node_contribs_matrix(i, 0) = output_right_node_contribs[i];\n      output_split_types_vec(i) = output_split_types[i];\n    }\n  }",
        "func_hash": 69206211534814304835270711364278354354,
        "file_name": "stats_ops.cc",
        "file_hash": 316049476660529142907096006231459788339,
        "cwe": [
            "CWE-369"
        ],
        "cve": "CVE-2021-37664",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions an attacker can read from outside of bounds of heap allocated data by sending specially crafted illegal arguments to `BoostedTreesSparseCalculateBestFeatureSplit`. The [implementation](https://github.com/tensorflow/tensorflow/blob/84d053187cb80d975ef2b9684d4b61981bca0c41/tensorflow/core/kernels/boosted_trees/stats_ops.cc) needs to validate that each value in `stats_summary_indices` is in range. We have patched the issue in GitHub commit e84c975313e8e8e38bb2ea118196369c45c51378. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37664",
        "func_name": "Compute",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 197632,
        "project": "njs",
        "commit_id": "6a40a85ff239497c6458c7dbef18f6a2736fe992",
        "project_url": "https://github.com/nginx/njs",
        "commit_url": "https://github.com/nginx/njs/commit/6a40a85ff239497c6458c7dbef18f6a2736fe992",
        "commit_message": "Fixed type confusion bug while resolving promises.\n\nPreviously, the internal function njs_promise_perform_then() which\nimplements PerformPromiseThen() expects its first argument to always be\na promise instance.  This assertion might be invalid because the\nfunctions corresponding to Promise.prototype.then() and\nPromise.resolve() incorrectly verified their arguments.\n\nSpecifically, the functions recognized their first argument as promise\nif it was an object which was an Promise or had Promise object in its\nprototype chain.  The later condition is not correct because internal\nslots are not inherited according to the spec.\n\nThis closes #447 issue in Github.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "njs_promise_perform_then(njs_vm_t *vm, njs_value_t *value,\n    njs_value_t *fulfilled, njs_value_t *rejected,\n    njs_promise_capability_t *capability)\n{\n    njs_int_t               ret;\n    njs_value_t             arguments[2];\n    njs_promise_t           *promise;\n    njs_function_t          *function;\n    njs_promise_data_t      *data;\n    njs_promise_reaction_t  *fulfilled_reaction, *rejected_reaction;\n\n    if (!njs_is_function(fulfilled)) {\n        fulfilled = njs_value_arg(&njs_value_undefined);\n    }\n\n    if (!njs_is_function(rejected)) {\n        rejected = njs_value_arg(&njs_value_undefined);\n    }\n\n    promise = njs_promise(value);\n    data = njs_data(&promise->value);\n\n    fulfilled_reaction = njs_mp_alloc(vm->mem_pool,\n                                      sizeof(njs_promise_reaction_t));\n    if (njs_slow_path(fulfilled_reaction == NULL)) {\n        njs_memory_error(vm);\n        return NJS_ERROR;\n    }\n\n    fulfilled_reaction->capability = capability;\n    fulfilled_reaction->handler = *fulfilled;\n    fulfilled_reaction->type = NJS_PROMISE_FULFILL;\n\n    rejected_reaction = njs_mp_alloc(vm->mem_pool,\n                                     sizeof(njs_promise_reaction_t));\n    if (njs_slow_path(rejected_reaction == NULL)) {\n        njs_memory_error(vm);\n        return NJS_ERROR;\n    }\n\n    rejected_reaction->capability = capability;\n    rejected_reaction->handler = *rejected;\n    rejected_reaction->type = NJS_PROMISE_REJECTED;\n\n    if (data->state == NJS_PROMISE_PENDING) {\n        njs_queue_insert_tail(&data->fulfill_queue, &fulfilled_reaction->link);\n        njs_queue_insert_tail(&data->reject_queue, &rejected_reaction->link);\n\n    } else {\n        function = njs_promise_create_function(vm,\n                                               sizeof(njs_promise_context_t));\n        function->u.native = njs_promise_reaction_job;\n\n        if (data->state == NJS_PROMISE_REJECTED) {\n            njs_set_data(&arguments[0], rejected_reaction, 0);\n\n            ret = njs_promise_host_rejection_tracker(vm, promise,\n                                                     NJS_PROMISE_HANDLE);\n            if (njs_slow_path(ret != NJS_OK)) {\n                return ret;\n            }\n\n        } else {\n            njs_set_data(&arguments[0], fulfilled_reaction, 0);\n        }\n\n        arguments[1] = data->result;\n\n        ret = njs_promise_add_event(vm, function, arguments, 2);\n        if (njs_slow_path(ret != NJS_OK)) {\n            return ret;\n        }\n    }\n\n    data->is_handled = 1;\n\n    if (capability == NULL) {\n        njs_vm_retval_set(vm, &njs_value_undefined);\n\n    } else {\n        njs_vm_retval_set(vm, &capability->promise);\n    }\n\n    return NJS_OK;\n}",
        "func_hash": 181580372713190612781917074071493405711,
        "file_name": "njs_promise.c",
        "file_hash": 261469139723432841860734117510139062920,
        "cwe": [
            "CWE-269"
        ],
        "cve": "CVE-2021-46463",
        "cve_desc": "njs through 0.7.1, used in NGINX, was discovered to contain a control flow hijack caused by a Type Confusion vulnerability in njs_promise_perform_then().",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-46463",
        "func_name": "njs_promise_perform_then",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 197666,
        "project": "njs",
        "commit_id": "eafe4c7a326b163612f10861392622b5da5b1792",
        "project_url": "https://github.com/nginx/njs",
        "commit_url": "https://github.com/nginx/njs/commit/eafe4c7a326b163612f10861392622b5da5b1792",
        "commit_message": "Fixed Array.prototype.lastIndexOf() with unicode string as \"this\".\n\nPreviously, when lastIndexOf() was called with unicode string as \"this\"\nargument and a negative \"fromIndex\" argument null-pointer dererence\nmight occur because njs_string_offset() was called with invalid index\nvalue whereas njs_string_offset() should always be called with valid\nindex argument.\n\nThe fix is to verify that from index is valid.\n\nThis closes #482 issue on Github.",
        "target": 1,
        "irrelevant": 1,
        "func_before": "njs_object_iterate_reverse(njs_vm_t *vm, njs_iterator_args_t *args,\n    njs_iterator_handler_t handler)\n{\n    double              idx;\n    int64_t             i, from, to, length;\n    njs_int_t           ret;\n    njs_array_t         *array, *keys;\n    njs_value_t         *entry, *value, prop, character, string_obj;\n    const u_char        *p, *end, *pos;\n    njs_string_prop_t   string_prop;\n    njs_object_value_t  *object;\n\n    value = args->value;\n    from = args->from;\n    to = args->to;\n\n    if (njs_is_array(value)) {\n        array = njs_array(value);\n\n        from += 1;\n\n        while (from-- > to) {\n            if (njs_slow_path(!array->object.fast_array)) {\n                goto process_object;\n            }\n\n            if (njs_fast_path(from < array->length\n                              && njs_is_valid(&array->start[from])))\n            {\n                ret = handler(vm, args, &array->start[from], from);\n\n            } else {\n                entry = njs_value_arg(&njs_value_invalid);\n                ret = njs_value_property_i64(vm, value, from, &prop);\n                if (njs_slow_path(ret != NJS_DECLINED)) {\n                    if (ret == NJS_ERROR) {\n                        return NJS_ERROR;\n                    }\n\n                    entry = &prop;\n                }\n\n                ret = handler(vm, args, entry, from);\n            }\n\n            if (njs_slow_path(ret != NJS_OK)) {\n                if (ret == NJS_DONE) {\n                    return NJS_DONE;\n                }\n\n                return NJS_ERROR;\n            }\n        }\n\n        return NJS_OK;\n    }\n\n    if (njs_is_string(value) || njs_is_object_string(value)) {\n\n        if (njs_is_string(value)) {\n            object = njs_object_value_alloc(vm, NJS_OBJ_TYPE_STRING, 0, value);\n            if (njs_slow_path(object == NULL)) {\n                return NJS_ERROR;\n            }\n\n            njs_set_object_value(&string_obj, object);\n\n            args->value = &string_obj;\n        }\n        else {\n            value = njs_object_value(value);\n        }\n\n        length = njs_string_prop(&string_prop, value);\n        end = string_prop.start + string_prop.size;\n\n        if ((size_t) length == string_prop.size) {\n            /* Byte or ASCII string. */\n\n            p = string_prop.start + from;\n\n            i = from + 1;\n\n            while (i-- > to) {\n                /* This cannot fail. */\n                (void) njs_string_new(vm, &character, p, 1, 1);\n\n                ret = handler(vm, args, &character, i);\n                if (njs_slow_path(ret != NJS_OK)) {\n                    if (ret == NJS_DONE) {\n                        return NJS_DONE;\n                    }\n\n                    return NJS_ERROR;\n                }\n\n                p--;\n            }\n\n        } else {\n            /* UTF-8 string. */\n\n            p = njs_string_offset(string_prop.start, end, from);\n            p = njs_utf8_next(p, end);\n\n            i = from + 1;\n\n            while (i-- > to) {\n                pos = njs_utf8_prev(p);\n\n                /* This cannot fail. */\n                (void) njs_string_new(vm, &character, pos, p - pos , 1);\n\n                ret = handler(vm, args, &character, i);\n                if (njs_slow_path(ret != NJS_OK)) {\n                    if (ret == NJS_DONE) {\n                        return NJS_DONE;\n                    }\n\n                    return NJS_ERROR;\n                }\n\n                p = pos;\n            }\n        }\n\n        return NJS_OK;\n    }\n\n    if (!njs_is_object(value)) {\n        return NJS_OK;\n    }\n\nprocess_object:\n\n    if (!njs_fast_object(from - to)) {\n        keys = njs_array_indices(vm, value);\n        if (njs_slow_path(keys == NULL)) {\n            return NJS_ERROR;\n        }\n\n        i = keys->length;\n\n        while (i > 0) {\n            idx = njs_string_to_index(&keys->start[--i]);\n\n            if (idx < to || idx > from) {\n                continue;\n            }\n\n            ret = njs_iterator_object_handler(vm, handler, args,\n                                              &keys->start[i], idx);\n            if (njs_slow_path(ret != NJS_OK)) {\n                njs_array_destroy(vm, keys);\n                return ret;\n            }\n        }\n\n        njs_array_destroy(vm, keys);\n\n        return NJS_OK;\n    }\n\n    i = from + 1;\n\n    while (i-- > to) {\n        ret = njs_iterator_object_handler(vm, handler, args, NULL, i);\n        if (njs_slow_path(ret != NJS_OK)) {\n            return ret;\n        }\n    }\n\n    return NJS_OK;\n}",
        "func_hash": 204015889704330628062672866949061415790,
        "file_name": "njs_iterator.c",
        "file_hash": 335799250908607269245401986160656951958,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2022-31307",
        "cve_desc": "Nginx NJS v0.7.2 was discovered to contain a segmentation violation in the function njs_string_offset at src/njs_string.c.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-31307",
        "func_name": "njs_object_iterate_reverse",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 197719,
        "project": "tensorflow",
        "commit_id": "be7a4de6adfbd303ce08be4332554dff70362612",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/be7a4de6adfbd303ce08be4332554dff70362612",
        "commit_message": "Ensure non-empty rt_nested_splits in tf.raw_ops.RaggedTensorToVariant\n\nPiperOrigin-RevId: 387664237\nChange-Id: Ia1700c34b5610873d63561abc86e23b46ead93b3",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext* context) override {\n    // Read ragged_splits inputs.\n    OpInputList ragged_nested_splits_in;\n    OP_REQUIRES_OK(context, context->input_list(\"rt_nested_splits\",\n                                                &ragged_nested_splits_in));\n    const int ragged_nested_splits_len = ragged_nested_splits_in.size();\n    RaggedTensorVariant batched_ragged_input;\n    // Read ragged_values input.\n    batched_ragged_input.set_values(context->input(ragged_nested_splits_len));\n    batched_ragged_input.mutable_nested_splits()->reserve(\n        ragged_nested_splits_len);\n    for (int i = 0; i < ragged_nested_splits_len; i++) {\n      batched_ragged_input.append_splits(ragged_nested_splits_in[i]);\n    }\n\n    if (!batched_input_) {\n      // Encode as a Scalar Variant Tensor.\n      Tensor* encoded_scalar;\n      OP_REQUIRES_OK(context, context->allocate_output(0, TensorShape({}),\n                                                       &encoded_scalar));\n      encoded_scalar->scalar<Variant>()() = std::move(batched_ragged_input);\n      return;\n    }\n\n    // Unbatch the Ragged Tensor and encode the components.\n    std::vector<RaggedTensorVariant> unbatched_ragged_input;\n    auto batched_splits_top_vec =\n        batched_ragged_input.splits(0).vec<SPLIT_TYPE>();\n    int num_components = batched_splits_top_vec.size() - 1;\n    OP_REQUIRES(context, num_components >= 0,\n                errors::Internal(\"Invalid split argument.\"));\n    OP_REQUIRES_OK(context, UnbatchRaggedZerothDim<VALUE_TYPE, SPLIT_TYPE>(\n                                batched_ragged_input, &unbatched_ragged_input));\n\n    // Bundle the encoded scalar Variant Tensors into a rank-1 Variant Tensor.\n    Tensor* encoded_vector;\n    int output_size = unbatched_ragged_input.size();\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(0, TensorShape({output_size}),\n                                            &encoded_vector));\n    auto encoded_vector_t = encoded_vector->vec<Variant>();\n    for (int i = 0; i < output_size; i++) {\n      encoded_vector_t(i) = unbatched_ragged_input[i];\n    }\n  }",
        "func_hash": 87089111367695740407726211981017748791,
        "file_name": "ragged_tensor_to_variant_op.cc",
        "file_hash": 103790733078302023163492154550355279185,
        "cwe": [
            "CWE-125"
        ],
        "cve": "CVE-2021-37666",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions an attacker can cause undefined behavior via binding a reference to null pointer in `tf.raw_ops.RaggedTensorToVariant`. The [implementation](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/core/kernels/ragged_tensor_to_variant_op.cc#L129) has an incomplete validation of the splits values, missing the case when the argument would be empty. We have patched the issue in GitHub commit be7a4de6adfbd303ce08be4332554dff70362612. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37666",
        "func_name": "Compute",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 197748,
        "project": "tensorflow",
        "commit_id": "c79ba87153ee343401dbe9d1954d7f79e521eb14",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/c79ba87153ee343401dbe9d1954d7f79e521eb14",
        "commit_message": "Make Transpose's shape inference function validate that negative `perm` values are within the tensor's rank.\n\nPiperOrigin-RevId: 403252853\nChange-Id: Ia6b31b45b237312668bb31c2c3b3c7bbce2d2610",
        "target": 1,
        "irrelevant": 1,
        "func_before": "Status TransposeShapeFn(InferenceContext* c) {\n  ShapeHandle input = c->input(0);\n  ShapeHandle perm_shape = c->input(1);\n  const Tensor* perm = c->input_tensor(1);\n  DimensionHandle perm_elems = c->NumElements(perm_shape);\n  // If we don't have rank information on the input or value information on\n  // perm we can't return any shape information, otherwise we have enough\n  // information to at least find the rank of the output.\n  if (!c->RankKnown(input) && !c->ValueKnown(perm_elems) && perm == nullptr) {\n    c->set_output(0, c->UnknownShape());\n    return Status::OK();\n  }\n\n  // Find our value of the rank.\n  int64_t rank;\n  if (c->RankKnown(input)) {\n    rank = c->Rank(input);\n  } else if (c->ValueKnown(perm_elems)) {\n    rank = c->Value(perm_elems);\n  } else {\n    rank = perm->NumElements();\n  }\n  if (!c->RankKnown(input) && rank < 2) {\n    // A permutation array containing a single element is ambiguous. It could\n    // indicate either a scalar or a 1-dimensional array, both of which the\n    // transpose op returns unchanged.\n    c->set_output(0, input);\n    return Status::OK();\n  }\n\n  std::vector<DimensionHandle> dims;\n  dims.resize(rank);\n  TF_RETURN_IF_ERROR(c->WithRank(input, rank, &input));\n  // Ensure that perm is a vector and has rank elements.\n  TF_RETURN_IF_ERROR(c->WithRank(perm_shape, 1, &perm_shape));\n  TF_RETURN_IF_ERROR(c->WithValue(perm_elems, rank, &perm_elems));\n\n  // If we know the rank of the input and the value of perm, we can return\n  // all shape information, otherwise we can only return rank information,\n  // but no information for the dimensions.\n  if (perm != nullptr) {\n    std::vector<int64_t> data;\n    if (perm->dtype() == DT_INT32) {\n      data = AsInt64<int32>(perm, rank);\n    } else {\n      data = AsInt64<int64_t>(perm, rank);\n    }\n\n    for (int32_t i = 0; i < rank; ++i) {\n      int64_t in_idx = data[i];\n      if (in_idx >= rank) {\n        return errors::InvalidArgument(\"perm dim \", in_idx,\n                                       \" is out of range of input rank \", rank);\n      }\n      dims[i] = c->Dim(input, in_idx);\n    }\n  } else {\n    for (int i = 0; i < rank; ++i) {\n      dims[i] = c->UnknownDim();\n    }\n  }\n\n  c->set_output(0, c->MakeShape(dims));\n  return Status::OK();\n}",
        "func_hash": 264434210200699405161022303469799474263,
        "file_name": "array_ops.cc",
        "file_hash": 212731692545100279573003636737252061446,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2021-41216",
        "cve_desc": "TensorFlow is an open source platform for machine learning. In affected versions the shape inference function for `Transpose` is vulnerable to a heap buffer overflow. This occurs whenever `perm` contains negative elements. The shape inference function does not validate that the indices in `perm` are all valid. The fix will be included in TensorFlow 2.7.0. We will also cherrypick this commit on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-41216",
        "func_name": "TransposeShapeFn",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 197760,
        "project": "tensorflow",
        "commit_id": "bb6a0383ed553c286f87ca88c207f6774d5c4a8f",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/bb6a0383ed553c286f87ca88c207f6774d5c4a8f",
        "commit_message": "Prevent heap OOB read in TFLite's `gather_nd.cc`.\n\nPassing negative indices is illegal but there was a missing check so that resulted in OOB accesses.\n\nPiperOrigin-RevId: 387208551\nChange-Id: I6b7a8a62d3e7c13a16d81619e5bc23ae2cdbc7fd",
        "target": 1,
        "irrelevant": 1,
        "func_before": "TfLiteStatus EvalGatherNd(TfLiteContext* context, const TfLiteTensor* params,\n                          const TfLiteTensor* indices, TfLiteTensor* output) {\n  switch (params->type) {\n    case kTfLiteFloat32:\n      return GatherNd<float, IndicesT>(params, indices, output);\n    case kTfLiteUInt8:\n      return GatherNd<uint8_t, IndicesT>(params, indices, output);\n    case kTfLiteInt8:\n      return GatherNd<int8_t, IndicesT>(params, indices, output);\n    case kTfLiteInt16:\n      return GatherNd<int16_t, IndicesT>(params, indices, output);\n    case kTfLiteInt32:\n      return GatherNd<int32_t, IndicesT>(params, indices, output);\n    case kTfLiteInt64:\n      return GatherNd<int64_t, IndicesT>(params, indices, output);\n    case kTfLiteString:\n      return GatherNdString<IndicesT>(params, indices, output);\n    default:\n      context->ReportError(context,\n                           \"Params type '%s' are not supported by gather_nd.\",\n                           TfLiteTypeGetName(params->type));\n      return kTfLiteError;\n  }\n}",
        "func_hash": 33385980683805390111226215596644506391,
        "file_name": "gather_nd.cc",
        "file_hash": 316439389085787575038399494263818469682,
        "cwe": [
            "CWE-125"
        ],
        "cve": "CVE-2021-37687",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions TFLite's [`GatherNd` implementation](https://github.com/tensorflow/tensorflow/blob/149562d49faa709ea80df1d99fc41d005b81082a/tensorflow/lite/kernels/gather_nd.cc#L124) does not support negative indices but there are no checks for this situation. Hence, an attacker can read arbitrary data from the heap by carefully crafting a model with negative values in `indices`. Similar issue exists in [`Gather` implementation](https://github.com/tensorflow/tensorflow/blob/149562d49faa709ea80df1d99fc41d005b81082a/tensorflow/lite/kernels/gather.cc). We have patched the issue in GitHub commits bb6a0383ed553c286f87ca88c207f6774d5c4a8f and eb921122119a6b6e470ee98b89e65d721663179d. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37687",
        "func_name": "EvalGatherNd",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 197796,
        "project": "qemu",
        "commit_id": "f9a70e79391f6d7c2a912d785239ee8effc1922d",
        "project_url": "https://github.com/bonzini/qemu",
        "commit_url": "https://github.com/qemu/qemu/commit/f9a70e79391f6d7c2a912d785239ee8effc1922d",
        "commit_message": "ui/vnc: limit client_cut_text msg payload size\n\ncurrently a malicious client could define a payload\nsize of 2^32 - 1 bytes and send up to that size of\ndata to the vnc server. The server would allocated\nthat amount of memory which could easily create an\nout of memory condition.\n\nThis patch limits the payload size to 1MB max.\n\nPlease note that client_cut_text messages are currently\nsilently ignored.\n\nSigned-off-by: Peter Lieven <pl@kamp.de>\nSigned-off-by: Gerd Hoffmann <kraxel@redhat.com>",
        "target": 1,
        "irrelevant": 1,
        "func_before": "static int protocol_client_msg(VncState *vs, uint8_t *data, size_t len)\n{\n    int i;\n    uint16_t limit;\n    VncDisplay *vd = vs->vd;\n\n    if (data[0] > 3) {\n        update_displaychangelistener(&vd->dcl, VNC_REFRESH_INTERVAL_BASE);\n    }\n\n    switch (data[0]) {\n    case VNC_MSG_CLIENT_SET_PIXEL_FORMAT:\n        if (len == 1)\n            return 20;\n\n        set_pixel_format(vs, read_u8(data, 4), read_u8(data, 5),\n                         read_u8(data, 6), read_u8(data, 7),\n                         read_u16(data, 8), read_u16(data, 10),\n                         read_u16(data, 12), read_u8(data, 14),\n                         read_u8(data, 15), read_u8(data, 16));\n        break;\n    case VNC_MSG_CLIENT_SET_ENCODINGS:\n        if (len == 1)\n            return 4;\n\n        if (len == 4) {\n            limit = read_u16(data, 2);\n            if (limit > 0)\n                return 4 + (limit * 4);\n        } else\n            limit = read_u16(data, 2);\n\n        for (i = 0; i < limit; i++) {\n            int32_t val = read_s32(data, 4 + (i * 4));\n            memcpy(data + 4 + (i * 4), &val, sizeof(val));\n        }\n\n        set_encodings(vs, (int32_t *)(data + 4), limit);\n        break;\n    case VNC_MSG_CLIENT_FRAMEBUFFER_UPDATE_REQUEST:\n        if (len == 1)\n            return 10;\n\n        framebuffer_update_request(vs,\n                                   read_u8(data, 1), read_u16(data, 2), read_u16(data, 4),\n                                   read_u16(data, 6), read_u16(data, 8));\n        break;\n    case VNC_MSG_CLIENT_KEY_EVENT:\n        if (len == 1)\n            return 8;\n\n        key_event(vs, read_u8(data, 1), read_u32(data, 4));\n        break;\n    case VNC_MSG_CLIENT_POINTER_EVENT:\n        if (len == 1)\n            return 6;\n\n        pointer_event(vs, read_u8(data, 1), read_u16(data, 2), read_u16(data, 4));\n        break;\n    case VNC_MSG_CLIENT_CUT_TEXT:\n        if (len == 1)\n            return 8;\n\n        if (len == 8) {\n            uint32_t dlen = read_u32(data, 4);\n            if (dlen > 0)\n                return 8 + dlen;\n        }\n\n        client_cut_text(vs, read_u32(data, 4), data + 8);\n        break;\n    case VNC_MSG_CLIENT_QEMU:\n        if (len == 1)\n            return 2;\n\n        switch (read_u8(data, 1)) {\n        case VNC_MSG_CLIENT_QEMU_EXT_KEY_EVENT:\n            if (len == 2)\n                return 12;\n\n            ext_key_event(vs, read_u16(data, 2),\n                          read_u32(data, 4), read_u32(data, 8));\n            break;\n        case VNC_MSG_CLIENT_QEMU_AUDIO:\n            if (len == 2)\n                return 4;\n\n            switch (read_u16 (data, 2)) {\n            case VNC_MSG_CLIENT_QEMU_AUDIO_ENABLE:\n                audio_add(vs);\n                break;\n            case VNC_MSG_CLIENT_QEMU_AUDIO_DISABLE:\n                audio_del(vs);\n                break;\n            case VNC_MSG_CLIENT_QEMU_AUDIO_SET_FORMAT:\n                if (len == 4)\n                    return 10;\n                switch (read_u8(data, 4)) {\n                case 0: vs->as.fmt = AUD_FMT_U8; break;\n                case 1: vs->as.fmt = AUD_FMT_S8; break;\n                case 2: vs->as.fmt = AUD_FMT_U16; break;\n                case 3: vs->as.fmt = AUD_FMT_S16; break;\n                case 4: vs->as.fmt = AUD_FMT_U32; break;\n                case 5: vs->as.fmt = AUD_FMT_S32; break;\n                default:\n                    printf(\"Invalid audio format %d\\n\", read_u8(data, 4));\n                    vnc_client_error(vs);\n                    break;\n                }\n                vs->as.nchannels = read_u8(data, 5);\n                if (vs->as.nchannels != 1 && vs->as.nchannels != 2) {\n                    printf(\"Invalid audio channel coount %d\\n\",\n                           read_u8(data, 5));\n                    vnc_client_error(vs);\n                    break;\n                }\n                vs->as.freq = read_u32(data, 6);\n                break;\n            default:\n                printf (\"Invalid audio message %d\\n\", read_u8(data, 4));\n                vnc_client_error(vs);\n                break;\n            }\n            break;\n\n        default:\n            printf(\"Msg: %d\\n\", read_u16(data, 0));\n            vnc_client_error(vs);\n            break;\n        }\n        break;\n    default:\n        printf(\"Msg: %d\\n\", data[0]);\n        vnc_client_error(vs);\n        break;\n    }\n\n    vnc_read_when(vs, protocol_client_msg, 1);\n    return 0;\n}",
        "func_hash": 26933609972946502173706391662270420555,
        "file_name": "vnc.c",
        "file_hash": 161585493204485691727376098595593068159,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2015-5239",
        "cve_desc": "Integer overflow in the VNC display driver in QEMU before 2.1.0 allows attachers to cause a denial of service (process crash) via a CLIENT_CUT_TEXT message, which triggers an infinite loop.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2015-5239",
        "func_name": "protocol_client_msg",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 197801,
        "project": "tensorflow",
        "commit_id": "368af875869a204b4ac552b9ddda59f6a46a56ec",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/368af875869a204b4ac552b9ddda59f6a46a56ec",
        "commit_message": "Avoid buffer overflow when loading tensors with insufficient data from checkpoints.\n\n`CopyDataFromTensorSliceToTensorSlice` does not (and cannot conveniently)\nprovide any bounds checking on its own, so the size is instead checked prior\nto passing unvalidated data to that function.\n\nPiperOrigin-RevId: 392971286\nChange-Id: If2073b36d4d5eedd386329f56729395fd7effee1",
        "target": 1,
        "irrelevant": 1,
        "func_before": "bool TensorSliceReader::CopySliceData(const string& name,\n                                      const TensorSlice& slice, T* data) const {\n  std::vector<std::pair<TensorSlice, string>> details;\n  const TensorSliceSet* tss;\n  {\n    mutex_lock l(mu_);\n    tss = FindTensorSlice(name, slice, &details);\n    if (!tss && !all_shards_loaded_) {\n      VLOG(1) << \"Did not find slice in preferred shard, loading all shards.\"\n              << name << \": \" << slice.DebugString();\n      LoadAllShards();\n      tss = FindTensorSlice(name, slice, &details);\n    }\n    if (!tss) {\n      // No such tensor\n      return false;\n    }\n  }\n  // We have the data -- copy it over.\n  string value;\n  for (const auto& x : details) {\n    const TensorSlice& slice_s = x.first;\n    const string& fname = x.second;\n    int idx = gtl::FindWithDefault(fname_to_index_, fname, -1);\n    CHECK_GE(idx, 0) << \"Failed to find the index for filename \" << fname;\n    // We read a record in the corresponding sstable\n    const string key = EncodeTensorNameSlice(name, slice_s);\n    if (!sss_[idx]->Get(key, &value)) {\n      VLOG(1) << \"Failed to seek to the record for tensor \" << name\n              << \", slice \" << slice_s.DebugString()\n              << \": computed key = \" << key;\n      return false;\n    }\n    SavedTensorSlices sts;\n    if (!ParseProtoUnlimited(&sts, value)) {\n      VLOG(1) << \"Failed to parse the record for tensor \" << name << \", slice \"\n              << slice_s.DebugString() << \": computed key = \" << key;\n      return false;\n    }\n    CopyDataFromTensorSliceToTensorSlice(\n        tss->shape(), slice_s, slice,\n        checkpoint::TensorProtoData<T>(sts.data().data()), data);\n  }\n  return true;\n}",
        "func_hash": 253938811692403617918500480067513726895,
        "file_name": "tensor_slice_reader.h",
        "file_hash": 240433137636754905402215095789731366712,
        "cwe": [
            "CWE-345"
        ],
        "cve": "CVE-2021-41203",
        "cve_desc": "TensorFlow is an open source platform for machine learning. In affected versions an attacker can trigger undefined behavior, integer overflows, segfaults and `CHECK`-fail crashes if they can change saved checkpoints from outside of TensorFlow. This is because the checkpoints loading infrastructure is missing validation for invalid file formats. The fixes will be included in TensorFlow 2.7.0. We will also cherrypick these commits on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-41203",
        "func_name": "TensorSliceReader::CopySliceData",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 196587,
        "project": "tensorflow",
        "commit_id": "4aacb30888638da75023e6601149415b39763d76",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/4aacb30888638da75023e6601149415b39763d76",
        "commit_message": "Disallow division by zero FPE in `tf.raw_ops.ResourceScatterDiv`\n\nHad to update a test that was broken.\n\nPiperOrigin-RevId: 388516976\nChange-Id: Ic358e6bf0559e011539974d453fc7aa18b427e9c",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void DoCompute(OpKernelContext* c) {\n    core::RefCountPtr<Var> v;\n    OP_REQUIRES_OK(c, LookupResource(c, HandleFromInput(c, 0), &v));\n    Tensor* params = v->tensor();\n    const Tensor& indices = c->input(1);\n    const Tensor& updates = c->input(2);\n\n    // Check that rank(updates.shape) = rank(indices.shape + params.shape[1:])\n    OP_REQUIRES(c,\n                updates.dims() == 0 ||\n                    updates.dims() == indices.dims() + params->dims() - 1,\n                errors::InvalidArgument(\n                    \"Must have updates.shape = indices.shape + \"\n                    \"params.shape[1:] or updates.shape = [], got \",\n                    \"updates.shape \", updates.shape().DebugString(),\n                    \", indices.shape \", indices.shape().DebugString(),\n                    \", params.shape \", params->shape().DebugString()));\n\n    // Check that we have enough index space\n    const int64_t N_big = indices.NumElements();\n    OP_REQUIRES(\n        c, N_big <= std::numeric_limits<Index>::max(),\n        errors::InvalidArgument(\"indices has too many elements for \",\n                                DataTypeString(DataTypeToEnum<Index>::v()),\n                                \" indexing: \", N_big, \" > \",\n                                std::numeric_limits<Index>::max()));\n    const Index N = static_cast<Index>(N_big);\n    OP_REQUIRES(\n        c, params->dim_size(0) <= std::numeric_limits<Index>::max(),\n        errors::InvalidArgument(\"params.shape[0] too large for \",\n                                DataTypeString(DataTypeToEnum<Index>::v()),\n                                \" indexing: \", params->dim_size(0), \" > \",\n                                std::numeric_limits<Index>::max()));\n\n    if (N > 0) {\n      auto indices_flat = indices.flat<Index>();\n      auto params_flat = params->flat_outer_dims<T>();\n      if (TensorShapeUtils::IsScalar(updates.shape())) {\n        const auto update = updates.scalar<T>();\n\n        functor::ScatterScalarFunctor<Device, T, Index, op> functor;\n        const Index bad_i = functor(c, c->template eigen_device<Device>(),\n                                    params_flat, update, indices_flat);\n        OP_REQUIRES(c, bad_i < 0,\n                    errors::InvalidArgument(\n                        \"indices\", SliceDebugString(indices.shape(), bad_i),\n                        \" = \", indices_flat(bad_i), \" is not in [0, \",\n                        params->dim_size(0), \")\"));\n      } else {\n        int64_t num_updates = updates.NumElements();\n        OP_REQUIRES(\n            c, TensorShapeUtils::StartsWith(updates.shape(), indices.shape()),\n            errors::InvalidArgument(\n                \"The shape of indices (\", indices.shape().DebugString(),\n                \") must be a prefix of the shape of updates (\",\n                updates.shape().DebugString(), \")\"));\n        auto updates_flat = updates.shaped<T, 2>({N, num_updates / N});\n\n        functor::ScatterFunctor<Device, T, Index, op> functor;\n        const Index bad_i = functor(c, c->template eigen_device<Device>(),\n                                    params_flat, updates_flat, indices_flat);\n        OP_REQUIRES(c, bad_i < 0,\n                    errors::InvalidArgument(\n                        \"indices\", SliceDebugString(indices.shape(), bad_i),\n                        \" = \", indices_flat(bad_i), \" is not in [0, \",\n                        params->dim_size(0), \")\"));\n      }\n    }\n  }",
        "func_hash": 322924980951140877428129021875471736973,
        "file_name": "resource_variable_ops.cc",
        "file_hash": 290989719174845979221072798512679804902,
        "cwe": [
            "CWE-369"
        ],
        "cve": "CVE-2021-37642",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions the implementation of `tf.raw_ops.ResourceScatterDiv` is vulnerable to a division by 0 error. The [implementation](https://github.com/tensorflow/tensorflow/blob/8d72537c6abf5a44103b57b9c2e22c14f5f49698/tensorflow/core/kernels/resource_variable_ops.cc#L865) uses a common class for all binary operations but fails to treat the division by 0 case separately. We have patched the issue in GitHub commit 4aacb30888638da75023e6601149415b39763d76. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37642",
        "func_name": "DoCompute",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 196611,
        "project": "booth",
        "commit_id": "35bf0b7b048d715f671eb68974fb6b4af6528c67",
        "project_url": "https://github.com/ClusterLabs/booth",
        "commit_url": "https://github.com/ClusterLabs/booth/commit/35bf0b7b048d715f671eb68974fb6b4af6528c67",
        "commit_message": "Revert \"Refactor: main: substitute is_auth_req macro\"\n\nThis reverts commit da79b8ba28ad4837a0fee13e5f8fb6f89fe0e24c.\n\nauthfile != authkey\n\nSigned-off-by: Jan Friesse <jfriesse@redhat.com>",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static int setup_config(int type)\n{\n\tint rv;\n\n\trv = read_config(cl.configfile, type);\n\tif (rv < 0)\n\t\tgoto out;\n\n\tif (is_auth_req()) {\n\t\trv = read_authkey();\n\t\tif (rv < 0)\n\t\t\tgoto out;\n#if HAVE_LIBGCRYPT\n\t\tif (!gcry_check_version(NULL)) {\n\t\t\tlog_error(\"gcry_check_version\");\n\t\t\trv = -ENOENT;\n\t\t\tgoto out;\n\t\t}\n\t\tgcry_control(GCRYCTL_DISABLE_SECMEM, 0);\n\t\tgcry_control(GCRYCTL_INITIALIZATION_FINISHED, 0);\n#endif\n\t}\n\n\t/* Set \"local\" pointer, ignoring errors. */\n\tif (cl.type == DAEMON && cl.site[0]) {\n\t\tif (!find_site_by_name(cl.site, &local, 1)) {\n\t\t\tlog_error(\"Cannot find \\\"%s\\\" in the configuration.\",\n\t\t\t\t\tcl.site);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tlocal->local = 1;\n\t} else\n\t\tfind_myself(NULL, type == CLIENT || type == GEOSTORE);\n\n\n\trv = check_config(type);\n\tif (rv < 0)\n\t\tgoto out;\n\n\n\t/* Per default the PID file name is derived from the\n\t * configuration name. */\n\tif (!cl.lockfile[0]) {\n\t\tsnprintf(cl.lockfile, sizeof(cl.lockfile)-1,\n\t\t\t\t\"%s/%s.pid\", BOOTH_RUN_DIR, booth_conf->name);\n\t}\n\nout:\n\treturn rv;\n}",
        "func_hash": 170997267947585139967201027163993257008,
        "file_name": "main.c",
        "file_hash": 4814718832295442874488153140310945385,
        "cwe": [
            "CWE-284"
        ],
        "cve": "CVE-2022-2553",
        "cve_desc": "The authfile directive in the booth config file is ignored, preventing use of authentication in communications from node to node. As a result, nodes that do not have the correct authentication key are not prevented from communicating with other nodes in the cluster.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-2553",
        "func_name": "setup_config",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 196620,
        "project": "tensorflow",
        "commit_id": "20cb18724b0bf6c09071a3f53434c4eec53cc147",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/20cb18724b0bf6c09071a3f53434c4eec53cc147",
        "commit_message": "Allow 0 for number of segments in `unsorted_segment_join_op.cc`\n\nRelated to the fix for #55305\n\nPiperOrigin-RevId: 443157549",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext* context) override {\n    const Tensor& input = context->input(0);\n    const TensorShape& input_shape = input.shape();\n    const int32_t input_dims = input_shape.dims();\n\n    const Tensor& segment_id = context->input(1);\n    const TensorShape& segment_id_shape = segment_id.shape();\n    const int32_t segment_dims = segment_id_shape.dims();\n\n    const Tensor& num_segments_tensor = context->input(2);\n    OP_REQUIRES(context, num_segments_tensor.NumElements() != 0,\n                errors::InvalidArgument(\"Number of segments cannot be empty.\"));\n    auto num_segments = num_segments_tensor.scalar<NUM_SEGMENTS_TYPE>()();\n\n    OP_REQUIRES(context, num_segments > 0,\n                errors::InvalidArgument(\"Number of segments must be positive\"));\n    OP_REQUIRES(context, segment_dims != 0,\n                errors::InvalidArgument(\"Segment_id cannot have rank 0\"));\n\n    OP_REQUIRES(\n        context, segment_dims <= input_dims,\n        errors::OutOfRange(\"Invalid segment_id rank \", segment_dims,\n                           \" for input with \", input_dims, \" dimension(s)\"));\n    for (auto i = 0; i < segment_dims; i++) {\n      OP_REQUIRES(\n          context, segment_id_shape.dim_size(i) == input_shape.dim_size(i),\n          errors::InvalidArgument(\n              \"Segment dimension is \", segment_id_shape.dim_size(i),\n              \" while input dimension is \", input_dims, \" in rank \", i));\n    }\n\n    // Making output tensor.\n    Tensor* output_tensor = nullptr;\n    TensorShape output_shape =\n        GetOutputShape(input_shape, segment_id_shape, num_segments);\n    OP_REQUIRES_OK(context, context->allocate_output(\"output\", output_shape,\n                                                     &output_tensor));\n\n    // Preparating flat tensors.\n    auto output_flat = output_tensor->flat<tstring>();\n    auto flat_segment_id = segment_id.flat<INDICES_TYPE>();\n    auto flat_input = input.flat<tstring>();\n\n    for (int i = 0; i < flat_segment_id.size(); i++) {\n      OP_REQUIRES(\n          context,\n          ((flat_segment_id(i) < num_segments) && (flat_segment_id(i) >= 0)),\n          errors::InvalidArgument(\n              \"segment_ids are not allowed to exceed num_segments or\"\n              \" to have negative values.\"));\n    }\n\n    int64_t big_stride;\n    int64_t small_stride;\n    std::tie(big_stride, small_stride) =\n        GetStrides<INDICES_TYPE>(input_shape, segment_id_shape);\n    auto relative_offset_set =\n        GetFlattenedRelativeOffsets<INDICES_TYPE>(small_stride, big_stride);\n    for (auto start_offset = 0; start_offset < big_stride; start_offset++) {\n      for (auto i = 0; i < relative_offset_set.size(); i++) {\n        auto output_index = start_offset + flat_segment_id(i) * big_stride;\n        auto offset = start_offset + relative_offset_set[i];\n        if (output_flat(output_index).length() != 0)\n          output_flat(output_index).append(separator_.c_str());\n        output_flat(output_index).append(flat_input(offset));\n      }\n    }\n  }",
        "func_hash": 251373873884125985828265662891142387006,
        "file_name": "unsorted_segment_join_op.cc",
        "file_hash": 311353858985009725519986545827875705855,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2022-29204",
        "cve_desc": "TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, the implementation of `tf.raw_ops.UnsortedSegmentJoin` does not fully validate the input arguments. This results in a `CHECK`-failure which can be used to trigger a denial of service attack. The code assumes `num_segments` is a positive scalar but there is no validation. Since this value is used to allocate the output tensor, a negative value would result in a `CHECK`-failure (assertion failure), as per TFSA-2021-198. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-29204",
        "func_name": "Compute",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 196621,
        "project": "mruby",
        "commit_id": "b1d0296a937fe278239bdfac840a3fd0e93b3ee9",
        "project_url": "https://github.com/mruby/mruby",
        "commit_url": "https://github.com/mruby/mruby/commit/b1d0296a937fe278239bdfac840a3fd0e93b3ee9",
        "commit_message": "class.c: clear method cache after `remove_method`.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "mrb_remove_method(mrb_state *mrb, struct RClass *c, mrb_sym mid)\n{\n  mt_tbl *h;\n\n  MRB_CLASS_ORIGIN(c);\n  h = c->mt;\n\n  if (h && mt_del(mrb, h, mid)) return;\n  mrb_name_error(mrb, mid, \"method '%n' not defined in %C\", mid, c);\n}",
        "func_hash": 310092184444521797404238692578019888834,
        "file_name": "class.c",
        "file_hash": null,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2022-1286",
        "cve_desc": "heap-buffer-overflow in mrb_vm_exec in mruby/mruby in GitHub repository mruby/mruby prior to 3.2. Possible arbitrary code execution if being exploited.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-1286",
        "func_name": "mrb_remove_method",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 196629,
        "project": "tensorflow",
        "commit_id": "579261dcd446385831fe4f7457d802a59685121d",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/579261dcd446385831fe4f7457d802a59685121d",
        "commit_message": "Fix crash in MatrixSolve when inputs have different batch dimensions.\n\nBefore, the process would crash or certain elements would be silently ignored. Now an InvalidArgument is raised.\n\nPiperOrigin-RevId: 384844020\nChange-Id: Iba44417e383bdd0e1abc4012bfca83b2377dd335",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void ComputeAsync(OpKernelContext* context, DoneCallback done) final {\n    const Tensor& input = context->input(0);\n    const Tensor& rhs = context->input(1);\n    const int ndims = input.dims();\n    const int64 n = input.dim_size(ndims - 1);\n    const int64 nrhs = rhs.dim_size(ndims - 1);\n    // Validate inputs.\n    OP_REQUIRES_ASYNC(\n        context, ndims >= 2,\n        errors::InvalidArgument(\"Input must have rank >= 2, got \", ndims),\n        done);\n    OP_REQUIRES_ASYNC(context, rhs.dims() == ndims,\n                      errors::InvalidArgument(\n                          \"Input and right-hand side must have same rank, got \",\n                          ndims, \" != \", rhs.dims()),\n                      done);\n    OP_REQUIRES_ASYNC(\n        context, input.dim_size(ndims - 2) == n,\n        errors::InvalidArgument(\"Input matrices must be squares, got\",\n                                input.dim_size(ndims - 2), \" != \", n),\n        done);\n    OP_REQUIRES_ASYNC(context, rhs.dim_size(ndims - 2) == n,\n                      errors::InvalidArgument(\n                          \"Input matrix and right-hand side must have the \"\n                          \"same number of rows, got\",\n                          n, \" != \", rhs.dim_size(ndims - 2)),\n                      done);\n\n    // Allocate output.\n    Tensor* output;\n    OP_REQUIRES_OK_ASYNC(\n        context,\n        context->forward_input_or_allocate_output({1}, 0, rhs.shape(), &output),\n        done);\n\n    // To be consistent with the MatrixInverse op, we define the solution for\n    // an empty set of equations as the empty matrix.\n    if (input.NumElements() == 0 || rhs.NumElements() == 0) {\n      done();\n      return;\n    }\n\n    // TODO(rmlarsen): Convert to std::make_unique when available.\n    std::unique_ptr<CudaSolver> solver(new CudaSolver(context));\n\n    // Make a copy of the input for the factorization step, or, if adjoint_ is\n    // false, try to reuse the input buffer if this op owns it exclusively.\n    Tensor input_copy;\n    const GPUDevice& device = context->eigen_device<GPUDevice>();\n    if (adjoint_) {\n      // For the adjoint case, it is simpler to always make a transposed copy up\n      // front.\n      OP_REQUIRES_OK_ASYNC(\n          context,\n          solver->allocate_scoped_tensor(DataTypeToEnum<Scalar>::value,\n                                         input.shape(), &input_copy),\n          done);\n      OP_REQUIRES_OK_ASYNC(context,\n                           DoMatrixTranspose(device, input, &input_copy), done);\n    } else {\n      OP_REQUIRES_OK_ASYNC(\n          context,\n          solver->forward_input_or_allocate_scoped_tensor(\n              {0}, DataTypeToEnum<Scalar>::value, input.shape(), &input_copy),\n          done);\n      if (!input.SharesBufferWith(input_copy)) {\n        device.memcpy(input_copy.flat<Scalar>().data(),\n                      input.flat<Scalar>().data(),\n                      input.NumElements() * sizeof(Scalar));\n      }\n    }\n    auto input_copy_reshaped = input_copy.template flat_inner_dims<Scalar, 3>();\n    const int64 batch_size = input_copy_reshaped.dimension(0);\n\n    // Allocate pivots on the device.\n    Tensor pivots;\n    OP_REQUIRES_OK_ASYNC(\n        context,\n        solver->allocate_scoped_tensor(DataTypeToEnum<int>::value,\n                                       TensorShape{batch_size, n}, &pivots),\n        done);\n    auto pivots_mat = pivots.template matrix<int>();\n\n    // 1. Compute the partially pivoted LU factorization(s) of the\n    // matrix/matrices.\n    std::vector<DeviceLapackInfo> dev_info;\n    auto input_copy_ptrs = solver->GetScratchSpace<uint8>(\n        sizeof(Scalar*) * batch_size, \"input_copt_ptrs\",\n        /* on_host */ true);\n    const int kMaxMatrixSizeToBatchSizeRatio = 128;\n    const bool use_batched_solver =\n        n <= kMaxMatrixSizeToBatchSizeRatio * batch_size;\n    if (use_batched_solver) {\n      // For small matrices or large batch sizes, we use the batched interface\n      // from cuBlas.\n      const Scalar** input_copy_ptrs_base =\n          reinterpret_cast<const Scalar**>(input_copy_ptrs.mutable_data());\n      for (int batch = 0; batch < batch_size; ++batch) {\n        input_copy_ptrs_base[batch] = &input_copy_reshaped(batch, 0, 0);\n      }\n      dev_info.push_back(\n          solver->GetDeviceLapackInfo(batch_size, \"getrfBatched\"));\n      OP_REQUIRES_OK_ASYNC(\n          context,\n          solver->GetrfBatched(n, input_copy_ptrs_base, n, pivots_mat.data(),\n                               &dev_info.back(), batch_size),\n          done);\n    } else {\n      // For small batch sizes or large matrices, we use the non-batched\n      // interface from cuSolver, which is much faster for large matrices.\n      dev_info.push_back(solver->GetDeviceLapackInfo(batch_size, \"getrf\"));\n      for (int batch = 0; batch < batch_size; ++batch) {\n        OP_REQUIRES_OK_ASYNC(\n            context,\n            solver->Getrf(n, n, &input_copy_reshaped(batch, 0, 0), n,\n                          &pivots_mat(batch, 0), &dev_info.back()(batch)),\n            done);\n      }\n    }\n\n    // 2. Make a transposed copy of the right-hand sides. This is necessary\n    // because cuBLAS assumes column-major storage while TensorFlow TF uses\n    // row-major.\n    TensorShape transposed_rhs_shape(rhs.shape());\n    transposed_rhs_shape.RemoveLastDims(2);\n    transposed_rhs_shape.AddDim(nrhs);\n    transposed_rhs_shape.AddDim(n);\n    Tensor transposed_rhs;\n    OP_REQUIRES_OK_ASYNC(\n        context,\n        solver->allocate_scoped_tensor(DataTypeToEnum<Scalar>::value,\n                                       transposed_rhs_shape, &transposed_rhs),\n        done);\n    if (nrhs > 1) {\n      OP_REQUIRES_OK_ASYNC(\n          context, DoMatrixTranspose(device, rhs, &transposed_rhs), done);\n    } else {\n      device.memcpy(transposed_rhs.flat<Scalar>().data(),\n                    rhs.flat<Scalar>().data(),\n                    rhs.NumElements() * sizeof(Scalar));\n    }\n\n    // 3. Solve op(A) X = B (in column major form).\n    // We use a trick here: If adjoint_ is true, we converted A to column major\n    // form above. If adjoint is false then I leave A in row-major form and use\n    // trans_a = CUBLAS_OP_T to effectively transform it to column-major on the\n    // fly. (This means that we actually use the LU-factorization of A^T in that\n    // case, but that is equally good for solving AX=B). This way we save an\n    // explicit transpose in the more common case of adjoint_ == false.\n    auto input_copy_ptr_array = solver->GetScratchSpace<uint8>(\n        sizeof(Scalar*) * batch_size, \"input_copy_ptr_array\",\n        /* on_host */ true);\n    auto transposed_rhs_ptr_array = solver->GetScratchSpace<uint8>(\n        sizeof(Scalar*) * batch_size, \"transposed_rhs_ptr_array\",\n        /* on_host */ true);\n    auto transposed_rhs_reshaped =\n        transposed_rhs.template flat_inner_dims<Scalar, 3>();\n    if (use_batched_solver) {\n      const Scalar** input_copy_ptrs_base =\n          reinterpret_cast<const Scalar**>(input_copy_ptr_array.mutable_data());\n      const Scalar** transposed_rhs_ptrs_base =\n          reinterpret_cast<const Scalar**>(\n              transposed_rhs_ptr_array.mutable_data());\n      for (int batch = 0; batch < batch_size; ++batch) {\n        input_copy_ptrs_base[batch] = &input_copy_reshaped(batch, 0, 0);\n        transposed_rhs_ptrs_base[batch] = &transposed_rhs_reshaped(batch, 0, 0);\n      }\n      int host_info = 0;\n      OP_REQUIRES_OK_ASYNC(\n          context,\n          solver->GetrsBatched(adjoint_ ? CUBLAS_OP_C : CUBLAS_OP_T, n, nrhs,\n                               input_copy_ptrs_base, n, pivots_mat.data(),\n                               transposed_rhs_ptrs_base, n, &host_info,\n                               batch_size),\n          done);\n      OP_REQUIRES_ASYNC(\n          context, host_info == 0,\n          errors::InvalidArgument(\"The \", -host_info,\n                                  \"'th argument to cublas*getrsBatched had \"\n                                  \"an illegal value.\"),\n          done);\n    } else {\n      dev_info.push_back(solver->GetDeviceLapackInfo(batch_size, \"getrs\"));\n      for (int batch = 0; batch < batch_size; ++batch) {\n        OP_REQUIRES_OK_ASYNC(\n            context,\n            solver->Getrs(adjoint_ ? CUBLAS_OP_C : CUBLAS_OP_T, n, nrhs,\n                          &input_copy_reshaped(batch, 0, 0), n,\n                          &pivots_mat(batch, 0),\n                          &transposed_rhs_reshaped(batch, 0, 0), n,\n                          &dev_info.back()(batch)),\n            done);\n      }\n    }\n\n    // 4. Transpose X to get the final result in row-major form.\n    if (nrhs > 1) {\n      OP_REQUIRES_OK_ASYNC(\n          context, DoMatrixTranspose(device, transposed_rhs, output), done);\n    } else {\n      device.memcpy(output->flat<Scalar>().data(),\n                    transposed_rhs.flat<Scalar>().data(),\n                    transposed_rhs.NumElements() * sizeof(Scalar));\n    }\n\n    // Callback for checking info after kernels finish. Also capture the\n    // temporary Tensors/ScratchSpace so they don't get deallocated before the\n    // kernels run. TODO(rmlarsen): Use move capture once C++14 becomes\n    // available.\n    auto info_checker = [context, done, dev_info](\n                            const Status& status,\n                            const std::vector<HostLapackInfo>& host_infos) {\n      if (!status.ok() && errors::IsInvalidArgument(status) &&\n          !host_infos.empty()) {\n        for (int i = 0; i < host_infos[0].size(); ++i) {\n          // Match the CPU error message for singular matrices. Otherwise\n          // just print the original error message from the status below.\n          OP_REQUIRES_ASYNC(context, host_infos[0].data()[i] <= 0,\n                            errors::InvalidArgument(kErrMsg), done);\n        }\n      }\n      OP_REQUIRES_OK_ASYNC(context, status, done);\n      done();\n    };\n    CudaSolver::CheckLapackInfoAndDeleteSolverAsync(std::move(solver), dev_info,\n                                                    std::move(info_checker));\n  }",
        "func_hash": 232512673394609281083836207268567643755,
        "file_name": "matrix_solve_op.cc",
        "file_hash": 18056043033202767652193305242094140715,
        "cwe": [
            "CWE-354"
        ],
        "cve": "CVE-2021-41206",
        "cve_desc": "TensorFlow is an open source platform for machine learning. In affected versions several TensorFlow operations are missing validation for the shapes of the tensor arguments involved in the call. Depending on the API, this can result in undefined behavior and segfault or `CHECK`-fail related crashes but in some scenarios writes and reads from heap populated arrays are also possible. We have discovered these issues internally via tooling while working on improving/testing GPU op determinism. As such, we don't have reproducers and there will be multiple fixes for these issues. These fixes will be included in TensorFlow 2.7.0. We will also cherrypick these commits on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-41206",
        "func_name": "ComputeAsync",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 196689,
        "project": "tensorflow",
        "commit_id": "cebe3c45d76357d201c65bdbbf0dbe6e8a63bbdb",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/cebe3c45d76357d201c65bdbbf0dbe6e8a63bbdb",
        "commit_message": "Fix tf.raw_ops.StagePeek vulnerability with invalid `index`.\n\nCheck that input is actually a scalar before treating it as such.\n\nPiperOrigin-RevId: 445524908",
        "target": 1,
        "irrelevant": 1,
        "func_before": "  void Compute(OpKernelContext* ctx) override {\n    Buffer* buf = nullptr;\n    OP_REQUIRES_OK(ctx, GetBuffer(ctx, def(), &buf));\n    core::ScopedUnref scope(buf);\n    Buffer::Tuple tuple;\n\n    std::size_t index = ctx->input(0).scalar<int>()();\n\n    OP_REQUIRES_OK(ctx, buf->Peek(index, &tuple));\n\n    OP_REQUIRES(\n        ctx, tuple.size() == (size_t)ctx->num_outputs(),\n        errors::InvalidArgument(\"Mismatch stage/unstage: \", tuple.size(),\n                                \" vs. \", ctx->num_outputs()));\n\n    for (size_t i = 0; i < tuple.size(); ++i) {\n      ctx->set_output(i, tuple[i]);\n    }\n  }",
        "func_hash": 321476459442808105718031824942985787186,
        "file_name": "stage_op.cc",
        "file_hash": 203338145673187111221975146552959312769,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2022-29195",
        "cve_desc": "TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, the implementation of `tf.raw_ops.StagePeek` does not fully validate the input arguments. This results in a `CHECK`-failure which can be used to trigger a denial of service attack. The code assumes `index` is a scalar but there is no validation for this before accessing its value. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-29195",
        "func_name": "Compute",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 196691,
        "project": "gpac",
        "commit_id": "71460d72ec07df766dab0a4d52687529f3efcf0a",
        "project_url": "https://github.com/gpac/gpac",
        "commit_url": "https://github.com/gpac/gpac/commit/71460d72ec07df766dab0a4d52687529f3efcf0a",
        "commit_message": "fixed #1876",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static GF_Err isoffin_process(GF_Filter *filter)\n{\n\tISOMReader *read = gf_filter_get_udta(filter);\n\tu32 i, count = gf_list_count(read->channels);\n\tBool is_active = GF_FALSE;\n\tBool in_is_eos = GF_FALSE;\n\tBool check_forced_end = GF_FALSE;\n\tBool has_new_data = GF_FALSE;\n\tu64 min_offset_plus_one = 0;\n\tu32 nb_forced_end=0;\n\tif (read->in_error)\n\t\treturn read->in_error;\n\n\tif (read->pid) {\n\t\tBool fetch_input = GF_TRUE;\n\n\t\t//we failed at loading the init segment during a dash switch, retry\n\t\tif (!read->is_partial_download && !read->mem_load_mode && (read->moov_not_loaded==2) ) {\n\t\t\tisoffin_configure_pid(filter, read->pid, GF_FALSE);\n\t\t\tif (read->moov_not_loaded) return GF_OK;\n\t\t}\n\t\tif (read->mem_load_mode==2) {\n\t\t\tif (!read->force_fetch && read->mem_blob.size > read->mstore_size) {\n\t\t\t\tfetch_input = GF_FALSE;\n\t\t\t}\n\t\t\tread->force_fetch = GF_FALSE;\n\t\t}\n\t\twhile (fetch_input) {\n\t\t\tGF_FilterPacket *pck = gf_filter_pid_get_packet(read->pid);\n\t\t\tif (!pck) {\n\t\t\t\t//we issued a seek, wait for the first packet to be received before fetching channels\n\t\t\t\t//otherwise we could end up reading from the wrong cache\n\t\t\t\tif (read->wait_for_source) {\n\t\t\t\t\t//something went wrong during the seek request\n\t\t\t\t\tif (gf_filter_pid_is_eos(read->pid))\n\t\t\t\t\t\treturn GF_EOS;\n\t\t\t\t\treturn GF_OK;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tread->wait_for_source = GF_FALSE;\n\n\t\t\tif (read->mem_load_mode) {\n\t\t\t\tu32 data_size;\n\t\t\t\tconst u8 *pck_data = gf_filter_pck_get_data(pck, &data_size);\n\t\t\t\tisoffin_push_buffer(filter, read, pck_data, data_size);\n\t\t\t}\n\t\t\t//we just had a switch but init seg is not completely done: input packet is only a part of the init, drop it\n\t\t\telse if (read->moov_not_loaded==2) {\n\t\t\t\tgf_filter_pid_drop_packet(read->pid);\n\t\t\t\treturn GF_OK;\n\t\t\t}\n\t\t\tgf_filter_pid_drop_packet(read->pid);\n\t\t\thas_new_data = GF_TRUE;\n\t\t\tif (read->in_error)\n\t\t\t\treturn read->in_error;\n\t\t}\n\t\tif (gf_filter_pid_is_eos(read->pid)) {\n\t\t\tread->input_loaded = GF_TRUE;\n\t\t\tin_is_eos = GF_TRUE;\n\t\t}\n\t\tif (read->input_is_stop) {\n\t\t\tread->input_loaded = GF_TRUE;\n\t\t\tin_is_eos = GF_TRUE;\n\t\t\tread->input_is_stop = GF_FALSE;\n\t\t}\n\t\tif (!read->frag_type && read->input_loaded) {\n\t\t\tin_is_eos = GF_TRUE;\n\t\t}\n        //segment is invalid, wait for eos on input an send eos on all channels\n        if (read->invalid_segment) {\n            if (!in_is_eos) return GF_OK;\n            read->invalid_segment = GF_FALSE;\n\n            for (i=0; i<count; i++) {\n                ISOMChannel *ch = gf_list_get(read->channels, i);\n                if (!ch->playing) {\n                    continue;\n                }\n                if (!ch->eos_sent) {\n                    ch->eos_sent = GF_TRUE;\n                    gf_filter_pid_set_eos(ch->pid);\n                }\n            }\n            read->eos_signaled = GF_TRUE;\n            return GF_EOS;\n        }\n\t} else if (read->extern_mov) {\n\t\tin_is_eos = GF_TRUE;\n\t\tread->input_loaded = GF_TRUE;\n\t}\n\tif (read->moov_not_loaded==1) {\n\t\tif (read->mem_load_mode)\n\t\t\treturn GF_OK;\n\t\tread->moov_not_loaded = GF_FALSE;\n\t\treturn isoffin_setup(filter, read);\n\t}\n\n\tif (read->refresh_fragmented) {\n\t\tconst GF_PropertyValue *prop;\n\n\t\tif (in_is_eos) {\n\t\t\tread->refresh_fragmented = GF_FALSE;\n\t\t} else {\n\t\t\tprop = gf_filter_pid_get_property(read->pid, GF_PROP_PID_FILE_CACHED);\n\t\t\tif (prop && prop->value.boolean)\n\t\t\t\tread->refresh_fragmented = GF_FALSE;\n\t\t}\n\n\t\tif (has_new_data) {\n\t\t\tu64 bytesMissing=0;\n\t\t\tGF_Err e;\n\t\t\tconst char *new_url = NULL;\n\t\t\tprop = gf_filter_pid_get_property(read->pid, GF_PROP_PID_FILEPATH);\n\t\t\tif (prop) new_url = prop->value.string;\n\n\t\t\te = gf_isom_refresh_fragmented(read->mov, &bytesMissing, new_url);\n\n\t\t\tif (e && (e!= GF_ISOM_INCOMPLETE_FILE)) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_DASH, (\"[IsoMedia] Failed to refresh current segment: %s\\n\", gf_error_to_string(e) ));\n\t\t\t\tread->refresh_fragmented = GF_FALSE;\n\t\t\t} else {\n\t\t\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_DASH, (\"[IsoMedia] Refreshing current segment at UTC \"LLU\" - \"LLU\" bytes still missing - input is EOS %d\\n\", gf_net_get_utc(), bytesMissing, in_is_eos));\n\t\t\t}\n\n\t\t\tif (!read->refresh_fragmented && (e==GF_ISOM_INCOMPLETE_FILE)) {\n\t\t\t\tGF_LOG(GF_LOG_WARNING, GF_LOG_DASH, (\"[IsoMedia] Incomplete Segment received - \"LLU\" bytes missing but EOF found\\n\", bytesMissing ));\n\t\t\t}\n\n#ifndef GPAC_DISABLE_LOG\n\t\t\tif (gf_log_tool_level_on(GF_LOG_DASH, GF_LOG_DEBUG)) {\n\t\t\t\tfor (i=0; i<count; i++) {\n\t\t\t\t\tISOMChannel *ch = gf_list_get(read->channels, i);\n\t\t\t\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_DASH, (\"[IsoMedia] refresh track %d fragment - cur sample %d - new sample count %d\\n\", ch->track, ch->sample_num, gf_isom_get_sample_count(ch->owner->mov, ch->track) ));\n\t\t\t\t}\n\t\t\t}\n#endif\n\t\t\tisor_check_producer_ref_time(read);\n\t\t\tif (!read->frag_type)\n\t\t\t\tread->refresh_fragmented = GF_FALSE;\n\t\t}\n\t}\n\n\tfor (i=0; i<count; i++) {\n\t\tu8 *data;\n\t\tu32 nb_pck=50;\n\t\tISOMChannel *ch;\n\t\tch = gf_list_get(read->channels, i);\n\t\tif (!ch->playing) {\n\t\t\tnb_forced_end++;\n\t\t\tcontinue;\n\t\t}\n\t\t//eos not sent on this channel, we are active\n\t\tif (!ch->eos_sent)\n\t\t\tis_active = GF_TRUE;\n\n\t\twhile (nb_pck) {\n\t\t\tch->sample_data_offset = 0;\n\t\t\tif (!read->full_segment_flush && gf_filter_pid_would_block(ch->pid) )\n\t\t\t\tbreak;\n\n\t\t\tif (ch->item_id) {\n\t\t\t\tisor_reader_get_sample_from_item(ch);\n\t\t\t} else {\n\t\t\t\tisor_reader_get_sample(ch);\n\t\t\t}\n\n\t\t\tif (read->stsd && (ch->last_sample_desc_index != read->stsd) && ch->sample) {\n\t\t\t\tisor_reader_release_sample(ch);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (ch->sample) {\n\t\t\t\tu32 sample_dur;\n\t\t\t\tu8 dep_flags;\n\t\t\t\tu8 *subs_buf;\n\t\t\t\tu32 subs_buf_size;\n\t\t\t\tGF_FilterPacket *pck;\n\t\t\t\tif (ch->needs_pid_reconfig) {\n\t\t\t\t\tisor_update_channel_config(ch);\n\t\t\t\t\tch->needs_pid_reconfig = GF_FALSE;\n\t\t\t\t}\n\n\t\t\t\t//we have at least two samples, update GF_PROP_PID_HAS_SYNC if needed\n\t\t\t\tif (ch->check_has_rap && (gf_isom_get_sample_count(ch->owner->mov, ch->track)>1) && (gf_isom_has_sync_points(ch->owner->mov, ch->track)==1)) {\n\t\t\t\t\tch->check_has_rap = GF_FALSE;\n\t\t\t\t\tch->has_rap = GF_TRUE;\n\t\t\t\t\tgf_filter_pid_set_property(ch->pid, GF_PROP_PID_HAS_SYNC, &PROP_BOOL(ch->has_rap) );\n\t\t\t\t}\n\n\t\t\t\t//strip param sets from payload, trigger reconfig if needed\n\t\t\t\tisor_reader_check_config(ch);\n\n\t\t\t\tif (read->nodata) {\n\t\t\t\t\tpck = gf_filter_pck_new_shared(ch->pid, NULL, ch->sample->dataLength, NULL);\n\t\t\t\t\tif (!pck) return GF_OUT_OF_MEM;\n\t\t\t\t} else {\n\t\t\t\t\tpck = gf_filter_pck_new_alloc(ch->pid, ch->sample->dataLength, &data);\n\t\t\t\t\tif (!pck) return GF_OUT_OF_MEM;\n\n\t\t\t\t\tmemcpy(data, ch->sample->data, ch->sample->dataLength);\n\t\t\t\t}\n\t\t\t\tgf_filter_pck_set_dts(pck, ch->dts);\n\t\t\t\tgf_filter_pck_set_cts(pck, ch->cts);\n\t\t\t\tif (ch->sample->IsRAP==-1) {\n\t\t\t\t\tgf_filter_pck_set_sap(pck, GF_FILTER_SAP_1);\n\t\t\t\t\tch->redundant = 1;\n\t\t\t\t} else {\n\t\t\t\t\tgf_filter_pck_set_sap(pck, (GF_FilterSAPType) ch->sample->IsRAP);\n\t\t\t\t}\n\n\t\t\t\tif (ch->sap_3)\n\t\t\t\t\tgf_filter_pck_set_sap(pck, GF_FILTER_SAP_3);\n\t\t\t\telse if (ch->sap_4_type) {\n\t\t\t\t\tgf_filter_pck_set_sap(pck, (ch->sap_4_type==GF_ISOM_SAMPLE_PREROLL) ? GF_FILTER_SAP_4_PROL : GF_FILTER_SAP_4);\n\t\t\t\t\tgf_filter_pck_set_roll_info(pck, ch->roll);\n\t\t\t\t}\n\n\t\t\t\tsample_dur = ch->au_duration;\n\t\t\t\tif (ch->sample->nb_pack)\n\t\t\t\t\tsample_dur *= ch->sample->nb_pack;\n\t\t\t\tgf_filter_pck_set_duration(pck, sample_dur);\n\t\t\t\tgf_filter_pck_set_seek_flag(pck, ch->seek_flag);\n\n\t\t\t\t//for now we only signal xPS mask for non-sap\n\t\t\t\tif (ch->xps_mask && !gf_filter_pck_get_sap(pck) ) {\n\t\t\t\t\tgf_filter_pck_set_property(pck, GF_PROP_PCK_XPS_MASK, &PROP_UINT(ch->xps_mask) );\n\t\t\t\t}\n\n\t\t\t\tdep_flags = ch->isLeading;\n\t\t\t\tdep_flags <<= 2;\n\t\t\t\tdep_flags |= ch->dependsOn;\n\t\t\t\tdep_flags <<= 2;\n\t\t\t\tdep_flags |= ch->dependedOn;\n\t\t\t\tdep_flags <<= 2;\n\t\t\t\tdep_flags |= ch->redundant;\n\n\t\t\t\tif (dep_flags)\n\t\t\t\t\tgf_filter_pck_set_dependency_flags(pck, dep_flags);\n\n\t\t\t\tgf_filter_pck_set_crypt_flags(pck, ch->pck_encrypted ? GF_FILTER_PCK_CRYPT : 0);\n\t\t\t\tgf_filter_pck_set_seq_num(pck, ch->sample_num);\n\n\n\t\t\t\tsubs_buf = gf_isom_sample_get_subsamples_buffer(read->mov, ch->track, ch->sample_num, &subs_buf_size);\n\t\t\t\tif (subs_buf) {\n\t\t\t\t\tgf_filter_pck_set_property(pck, GF_PROP_PCK_SUBS, &PROP_DATA_NO_COPY(subs_buf, subs_buf_size) );\n\t\t\t\t}\n\n\t\t\t\tif (ch->sai_buffer && ch->pck_encrypted) {\n\t\t\t\t\tassert(ch->sai_buffer_size);\n\t\t\t\t\tgf_filter_pck_set_property(pck, GF_PROP_PCK_CENC_SAI, &PROP_DATA(ch->sai_buffer, ch->sai_buffer_size) );\n\t\t\t\t}\n\n\t\t\t\tif (read->sigfrag) {\n\t\t\t\t\tGF_ISOFragmentBoundaryInfo finfo;\n\t\t\t\t\tif (gf_isom_sample_is_fragment_start(read->mov, ch->track, ch->sample_num, &finfo) ) {\n\t\t\t\t\t\tu64 start=0;\n\t\t\t\t\t\tu32 traf_start = finfo.seg_start_plus_one ? 2 : 1;\n\n\t\t\t\t\t\tif (finfo.seg_start_plus_one)\n\t\t\t\t\t\t\tgf_filter_pck_set_property(pck, GF_PROP_PCK_CUE_START, &PROP_BOOL(GF_TRUE));\n\n\t\t\t\t\t\tgf_filter_pck_set_property(pck, GF_PROP_PCK_FRAG_START, &PROP_UINT(traf_start));\n\n\t\t\t\t\t\tstart = finfo.frag_start;\n\t\t\t\t\t\tif (finfo.seg_start_plus_one) start = finfo.seg_start_plus_one-1;\n\t\t\t\t\t\tgf_filter_pck_set_property(pck, GF_PROP_PCK_FRAG_RANGE, &PROP_FRAC64_INT(start, finfo.mdat_end));\n\t\t\t\t\t\tif (finfo.moof_template) {\n\t\t\t\t\t\t\tgf_filter_pck_set_property(pck, GF_PROP_PCK_MOOF_TEMPLATE, &PROP_DATA((u8 *)finfo.moof_template, finfo.moof_template_size));\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (finfo.sidx_end) {\n\t\t\t\t\t\t\tgf_filter_pck_set_property(pck, GF_PROP_PCK_SIDX_RANGE, &PROP_FRAC64_INT(finfo.sidx_start , finfo.sidx_end));\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tif (read->seg_name_changed) {\n\t\t\t\t\t\t\tconst GF_PropertyValue *p = gf_filter_pid_get_property(read->pid, GF_PROP_PID_URL);\n\t\t\t\t\t\t\tread->seg_name_changed = GF_FALSE;\n\t\t\t\t\t\t\tif (p && p->value.string) {\n\t\t\t\t\t\t\t\tgf_filter_pck_set_property(pck, GF_PROP_PID_URL, &PROP_STRING(p->value.string));\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (ch->sender_ntp) {\n\t\t\t\t\tgf_filter_pck_set_property(pck, GF_PROP_PCK_SENDER_NTP, &PROP_LONGUINT(ch->sender_ntp));\n\t\t\t\t\tif (ch->ntp_at_server_ntp) {\n\t\t\t\t\t\tgf_filter_pck_set_property(pck, GF_PROP_PCK_RECEIVER_NTP, &PROP_LONGUINT(ch->ntp_at_server_ntp));\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tch->eos_sent = GF_FALSE;\n\n\t\t\t\t//this might not be the true end of stream\n\t\t\t\tif ((ch->streamType==GF_STREAM_AUDIO) && (ch->sample_num == gf_isom_get_sample_count(read->mov, ch->track))) {\n\t\t\t\t\tgf_filter_pck_set_property(pck, GF_PROP_PCK_END_RANGE, &PROP_BOOL(GF_TRUE));\n\t\t\t\t}\n\n\t\t\t\tgf_filter_pck_send(pck);\n\t\t\t\tisor_reader_release_sample(ch);\n\n\t\t\t\tch->last_valid_sample_data_offset = ch->sample_data_offset;\n\t\t\t\tnb_pck--;\n\t\t\t} else if (ch->last_state==GF_EOS) {\n\t\t\t\tif (ch->playing == 2) {\n\t\t\t\t\tif (in_is_eos) {\n\t\t\t\t\t\tch->playing = GF_FALSE;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tnb_forced_end++;\n\t\t\t\t\t\tcheck_forced_end = GF_TRUE;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (in_is_eos && !ch->eos_sent) {\n\t\t\t\t\tvoid *tfrf;\n\t\t\t\t\tconst void *gf_isom_get_tfrf(GF_ISOFile *movie, u32 trackNumber);\n\n\t\t\t\t\tch->eos_sent = GF_TRUE;\n\t\t\t\t\tread->eos_signaled = GF_TRUE;\n\n\t\t\t\t\ttfrf = (void *) gf_isom_get_tfrf(read->mov, ch->track);\n\t\t\t\t\tif (tfrf) {\n\t\t\t\t\t\tgf_filter_pid_set_info_str(ch->pid, \"smooth_tfrf\", &PROP_POINTER(tfrf) );\n\t\t\t\t\t\tch->last_has_tfrf = GF_TRUE;\n\t\t\t\t\t} else if (ch->last_has_tfrf) {\n\t\t\t\t\t\tgf_filter_pid_set_info_str(ch->pid, \"smooth_tfrf\", NULL);\n\t\t\t\t\t\tch->last_has_tfrf = GF_FALSE;\n\t\t\t\t\t}\n\n\t\t\t\t\tgf_filter_pid_set_eos(ch->pid);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t} else {\n\t\t\t\tread->force_fetch = GF_TRUE;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (!min_offset_plus_one || (min_offset_plus_one - 1 > ch->last_valid_sample_data_offset))\n\t\t\tmin_offset_plus_one = 1 + ch->last_valid_sample_data_offset;\n\t}\n\tif (read->mem_load_mode && min_offset_plus_one) {\n\t\tisoffin_purge_mem(read, min_offset_plus_one-1);\n\t}\n\n\t//we reached end of playback due to play range request, we must send eos - however for safety reason with DASH, we first need to cancel the input\n\tif (read->pid && check_forced_end && (nb_forced_end==count)) {\n\t\t//abort input\n\t\tGF_FilterEvent evt;\n\t\tGF_FEVT_INIT(evt, GF_FEVT_STOP, read->pid);\n\t\tgf_filter_pid_send_event(read->pid, &evt);\n\t}\n\n\n\tif (!is_active) {\n\t\treturn GF_EOS;\n\t}\n\t//if (in_is_eos)\n//\tgf_filter_ask_rt_reschedule(filter, 1);\n\treturn GF_OK;\n\n}",
        "func_hash": 245491994913846374509516795584789756192,
        "file_name": "isoffin_read.c",
        "file_hash": 80320074166992838039801529564251755054,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2021-40592",
        "cve_desc": "GPAC version before commit 71460d72ec07df766dab0a4d52687529f3efcf0a (version v1.0.1 onwards) contains loop with unreachable exit condition ('infinite loop') vulnerability in ISOBMFF reader filter, isoffin_read.c. Function isoffin_process() can result in DoS by infinite loop. To exploit, the victim must open a specially crafted mp4 file.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-40592",
        "func_name": "isoffin_process",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 196698,
        "project": "tensorflow",
        "commit_id": "67bfd9feeecfb3c61d80f0e46d89c170fbee682b",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/67bfd9feeecfb3c61d80f0e46d89c170fbee682b",
        "commit_message": "Make SparseFillEmptyRows validate that the length of `values` must be equal to the number of index tuples.\n\nPiperOrigin-RevId: 399969549\nChange-Id: I3c2f2ca1c1d2cc88bb5951c6958b38c16e9436c8",
        "target": 1,
        "irrelevant": 0,
        "func_before": "void SparseFillEmptyRowsOpImpl(OpKernelContext* context,\n                               AsyncOpKernel::DoneCallback done = nullptr) {\n  // Note that setting this empty lambda as the default parameter value directly\n  // can cause strange compiler/linker errors, so we do it like this instead.\n  if (!done) {\n    done = [] {};\n  }\n\n  const int kIndicesInput = 0;\n  const int kValuesInput = 1;\n  const int kDenseShapeInput = 2;\n  const int kDefaultValueInput = 3;\n\n  const Tensor& indices_t = context->input(kIndicesInput);\n  const Tensor& values_t = context->input(kValuesInput);\n  const Tensor& dense_shape_t = context->input(kDenseShapeInput);\n  const Tensor& default_value_t = context->input(kDefaultValueInput);\n\n  OP_REQUIRES_ASYNC(\n      context, TensorShapeUtils::IsVector(dense_shape_t.shape()),\n      errors::InvalidArgument(\"dense_shape must be a vector, saw: \",\n                              dense_shape_t.shape().DebugString()),\n      done);\n  OP_REQUIRES_ASYNC(context, TensorShapeUtils::IsMatrix(indices_t.shape()),\n                    errors::InvalidArgument(\"indices must be a matrix, saw: \",\n                                            indices_t.shape().DebugString()),\n                    done);\n  OP_REQUIRES_ASYNC(context, TensorShapeUtils::IsVector(values_t.shape()),\n                    errors::InvalidArgument(\"values must be a vector, saw: \",\n                                            values_t.shape().DebugString()),\n                    done);\n  OP_REQUIRES_ASYNC(\n      context, TensorShapeUtils::IsScalar(default_value_t.shape()),\n      errors::InvalidArgument(\"default_value must be a scalar, saw: \",\n                              default_value_t.shape().DebugString()),\n      done);\n  // TODO(ebrevdo): add shape checks between values, indices,\n  // Also add check that dense rank > 0.\n  OP_REQUIRES_ASYNC(context, dense_shape_t.NumElements() != 0,\n                    errors::InvalidArgument(\"Dense shape cannot be empty.\"),\n                    done);\n\n  using FunctorType = functor::SparseFillEmptyRows<Device, T, Tindex>;\n  OP_REQUIRES_OK_ASYNC(context,\n                       FunctorType()(context, default_value_t, indices_t,\n                                     values_t, dense_shape_t, done),\n                       done);\n}",
        "func_hash": 163337242627579814226114932816582213259,
        "file_name": "sparse_fill_empty_rows_op.cc",
        "file_hash": 115550743256362209093747086328381163455,
        "cwe": [
            "CWE-125"
        ],
        "cve": "CVE-2021-41224",
        "cve_desc": "TensorFlow is an open source platform for machine learning. In affected versions the implementation of `SparseFillEmptyRows` can be made to trigger a heap OOB access. This occurs whenever the size of `indices` does not match the size of `values`. The fix will be included in TensorFlow 2.7.0. We will also cherrypick this commit on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-41224",
        "func_name": "SparseFillEmptyRowsOpImpl",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 196705,
        "project": "tensorflow",
        "commit_id": "11ced8467eccad9c7cb94867708be8fa5c66c730",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/11ced8467eccad9c7cb94867708be8fa5c66c730",
        "commit_message": "Fix UB in SparseTensorDenseAdd\n\nAdded more input validation to avoid nullptr dereferencing and array index\nout of bounds issues.\n\nPiperOrigin-RevId: 446192704",
        "target": 1,
        "irrelevant": 0,
        "func_before": "Status ValidateInputs(const Tensor *a_indices, const Tensor *a_values,\n                      const Tensor *a_shape, const Tensor *b) {\n  if (!TensorShapeUtils::IsMatrix(a_indices->shape())) {\n    return errors::InvalidArgument(\n        \"Input a_indices should be a matrix but received shape: \",\n        a_indices->shape().DebugString());\n  }\n  if (!TensorShapeUtils::IsVector(a_values->shape()) ||\n      !TensorShapeUtils::IsVector(a_shape->shape())) {\n    return errors::InvalidArgument(\n        \"Inputs a_values and a_shape should be vectors \"\n        \"but received shapes: \",\n        a_values->shape().DebugString(), \" and \",\n        a_shape->shape().DebugString());\n  }\n  if (a_shape->NumElements() != b->dims()) {\n    return errors::InvalidArgument(\n        \"Two operands have different ranks; received: \", a_shape->NumElements(),\n        \" and \", b->dims());\n  }\n  const auto a_shape_flat = a_shape->flat<Index>();\n  for (int i = 0; i < b->dims(); ++i) {\n    if (a_shape_flat(i) != b->dim_size(i)) {\n      return errors::InvalidArgument(\n          \"Dimension \", i,\n          \" does not equal (no broadcasting is supported): sparse side \",\n          a_shape_flat(i), \" vs dense side \", b->dim_size(i));\n    }\n  }\n  return Status::OK();\n}",
        "func_hash": 308425823880781073775676879611190785715,
        "file_name": "sparse_tensor_dense_add_op.cc",
        "file_hash": 91198918327439956509177796541242214319,
        "cwe": [
            "CWE-20"
        ],
        "cve": "CVE-2022-29206",
        "cve_desc": "TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, the implementation of `tf.raw_ops.SparseTensorDenseAdd` does not fully validate the input arguments. In this case, a reference gets bound to a `nullptr` during kernel execution. This is undefined behavior. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-29206",
        "func_name": "ValidateInputs",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 196726,
        "project": "njs",
        "commit_id": "8b39afdad9a0761e0a5d4af1a762bd9a6daef572",
        "project_url": "https://github.com/nginx/njs",
        "commit_url": "https://github.com/nginx/njs/commit/8b39afdad9a0761e0a5d4af1a762bd9a6daef572",
        "commit_message": "Fixed Array.prototype.sort() when arr size is changed in a comparator.\n\nThis fixed #468 issue on Github.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "njs_array_prototype_sort(njs_vm_t *vm, njs_value_t *args, njs_uint_t nargs,\n    njs_index_t unused)\n{\n    int64_t                i, und, len, nlen, length;\n    njs_int_t              ret, fast_path;\n    njs_array_t            *array;\n    njs_value_t            *this, *comparefn, *start, *strings;\n    njs_array_sort_ctx_t   ctx;\n    njs_array_sort_slot_t  *p, *end, *slots, *nslots;\n\n    comparefn = njs_arg(args, nargs, 1);\n\n    if (njs_is_defined(comparefn)) {\n        if (njs_slow_path(!njs_is_function(comparefn))) {\n            njs_type_error(vm, \"comparefn must be callable or undefined\");\n            return NJS_ERROR;\n        }\n\n        ctx.function = njs_function(comparefn);\n\n    } else {\n        ctx.function = NULL;\n    }\n\n    this = njs_argument(args, 0);\n\n    ret = njs_value_to_object(vm, this);\n    if (njs_slow_path(ret != NJS_OK)) {\n        return ret;\n    }\n\n    ret = njs_value_length(vm, this, &length);\n    if (njs_slow_path(ret != NJS_OK)) {\n        return ret;\n    }\n\n    if (njs_slow_path(length < 2)) {\n        vm->retval = *this;\n        return NJS_OK;\n    }\n\n    slots = NULL;\n    ctx.vm = vm;\n    ctx.strings.separate = 0;\n    ctx.strings.pointer = 0;\n    ctx.exception = 0;\n\n    fast_path = njs_is_fast_array(this);\n\n    if (njs_fast_path(fast_path)) {\n        array = njs_array(this);\n        start = array->start;\n\n        slots = njs_mp_alloc(vm->mem_pool,\n                             sizeof(njs_array_sort_slot_t) * length);\n        if (njs_slow_path(slots == NULL)) {\n                return NJS_ERROR;\n        }\n\n        und = 0;\n        p = slots;\n\n        for (i = 0; i < length; i++) {\n            if (njs_slow_path(!njs_is_valid(&start[i]))) {\n                fast_path = 0;\n                njs_mp_free(vm->mem_pool, slots);\n                slots = NULL;\n                goto slow_path;\n            }\n\n            if (njs_slow_path(njs_is_undefined(&start[i]))) {\n                und++;\n                continue;\n            }\n\n            p->value = start[i];\n            p->pos = i;\n            p->str = NULL;\n            p++;\n        }\n\n        len = p - slots;\n\n    } else {\n\nslow_path:\n\n        und = 0;\n        p = NULL;\n        end = NULL;\n\n        for (i = 0; i < length; i++) {\n            if (p >= end) {\n                nlen = njs_min(njs_max((p - slots) * 2, 8), length);\n                nslots = njs_mp_alloc(vm->mem_pool,\n                                      sizeof(njs_array_sort_slot_t) * nlen);\n                if (njs_slow_path(nslots == NULL)) {\n                    njs_memory_error(vm);\n                    return NJS_ERROR;\n                }\n\n                if (slots != NULL) {\n                    p = (void *) njs_cpymem(nslots, slots,\n                                  sizeof(njs_array_sort_slot_t) * (p - slots));\n                    njs_mp_free(vm->mem_pool, slots);\n\n                } else {\n                    p = nslots;\n                }\n\n                slots = nslots;\n                end = slots + nlen;\n            }\n\n            ret = njs_value_property_i64(vm, this, i, &p->value);\n            if (njs_slow_path(ret == NJS_ERROR)) {\n                ret = NJS_ERROR;\n                goto exception;\n            }\n\n            if (ret == NJS_DECLINED) {\n                continue;\n            }\n\n            if (njs_is_undefined(&p->value)) {\n                und++;\n                continue;\n            }\n\n            p->pos = i;\n            p->str = NULL;\n            p++;\n        }\n\n        len = p - slots;\n    }\n\n    strings = njs_arr_init(vm->mem_pool, &ctx.strings, NULL, len + 1,\n                           sizeof(njs_value_t));\n    if (njs_slow_path(strings == NULL)) {\n        ret = NJS_ERROR;\n        goto exception;\n    }\n\n    njs_qsort(slots, len, sizeof(njs_array_sort_slot_t), njs_array_compare,\n              &ctx);\n\n    if (ctx.exception) {\n        ret = NJS_ERROR;\n        goto exception;\n    }\n\n    if (njs_fast_path(fast_path)) {\n        array = njs_array(this);\n        start = array->start;\n\n        for (i = 0; i < len; i++) {\n            start[i] = slots[i].value;\n        }\n\n        for (i = len; und-- > 0; i++) {\n            start[i] = njs_value_undefined;\n        }\n\n    } else {\n        for (i = 0; i < len; i++) {\n            if (slots[i].pos != i) {\n                ret = njs_value_property_i64_set(vm, this, i, &slots[i].value);\n                if (njs_slow_path(ret == NJS_ERROR)) {\n                    goto exception;\n                }\n            }\n        }\n\n        for (i = len; und-- > 0; i++) {\n            ret = njs_value_property_i64_set(vm, this, i,\n                                          njs_value_arg(&njs_value_undefined));\n            if (njs_slow_path(ret == NJS_ERROR)) {\n                goto exception;\n            }\n        }\n\n        for (; i < length; i++) {\n            ret = njs_value_property_i64_delete(vm, this, i, NULL);\n            if (njs_slow_path(ret == NJS_ERROR)) {\n                goto exception;\n            }\n        }\n    }\n\n    vm->retval = *this;\n\n    ret = NJS_OK;\n\nexception:\n\n    if (slots != NULL) {\n        njs_mp_free(vm->mem_pool, slots);\n    }\n\n    njs_arr_destroy(&ctx.strings);\n\n    return ret;\n}",
        "func_hash": 315762575953614180704363033015743212537,
        "file_name": "njs_array.c",
        "file_hash": 304271490911532501655096631912999183260,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2022-29780",
        "cve_desc": "Nginx NJS v0.7.2 was discovered to contain a segmentation violation in the function njs_array_prototype_sort at src/njs_array.c.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-29780",
        "func_name": "njs_array_prototype_sort",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 196790,
        "project": "tensorflow",
        "commit_id": "a4e138660270e7599793fa438cd7b2fc2ce215a6",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/a4e138660270e7599793fa438cd7b2fc2ce215a6",
        "commit_message": "Add remaining validation to `sdca_internal.cc`\n\nPiperOrigin-RevId: 387738010\nChange-Id: I28eedcfd87a53aaf34deb075acea1f8c95470808",
        "target": 1,
        "irrelevant": 0,
        "func_before": "Status Examples::Initialize(OpKernelContext* const context,\n                            const ModelWeights& weights,\n                            const int num_sparse_features,\n                            const int num_sparse_features_with_values,\n                            const int num_dense_features) {\n  num_features_ = num_sparse_features + num_dense_features;\n\n  OpInputList sparse_example_indices_inputs;\n  TF_RETURN_IF_ERROR(context->input_list(\"sparse_example_indices\",\n                                         &sparse_example_indices_inputs));\n  if (sparse_example_indices_inputs.size() != num_sparse_features)\n    return errors::InvalidArgument(\n        \"Expected \", num_sparse_features,\n        \" tensors in sparse_example_indices but got \",\n        sparse_example_indices_inputs.size());\n  OpInputList sparse_feature_indices_inputs;\n  TF_RETURN_IF_ERROR(context->input_list(\"sparse_feature_indices\",\n                                         &sparse_feature_indices_inputs));\n  if (sparse_feature_indices_inputs.size() != num_sparse_features)\n    return errors::InvalidArgument(\n        \"Expected \", num_sparse_features,\n        \" tensors in sparse_feature_indices but got \",\n        sparse_feature_indices_inputs.size());\n  OpInputList sparse_feature_values_inputs;\n  if (num_sparse_features_with_values > 0) {\n    TF_RETURN_IF_ERROR(context->input_list(\"sparse_feature_values\",\n                                           &sparse_feature_values_inputs));\n    if (sparse_feature_values_inputs.size() != num_sparse_features_with_values)\n      return errors::InvalidArgument(\n          \"Expected \", num_sparse_features_with_values,\n          \" tensors in sparse_feature_values but got \",\n          sparse_feature_values_inputs.size());\n  }\n\n  const Tensor* example_weights_t;\n  TF_RETURN_IF_ERROR(context->input(\"example_weights\", &example_weights_t));\n  auto example_weights = example_weights_t->flat<float>();\n\n  if (example_weights.size() >= std::numeric_limits<int>::max()) {\n    return errors::InvalidArgument(strings::Printf(\n        \"Too many examples in a mini-batch: %zu > %d\", example_weights.size(),\n        std::numeric_limits<int>::max()));\n  }\n\n  // The static_cast here is safe since num_examples can be at max an int.\n  const int num_examples = static_cast<int>(example_weights.size());\n  const Tensor* example_labels_t;\n  TF_RETURN_IF_ERROR(context->input(\"example_labels\", &example_labels_t));\n  auto example_labels = example_labels_t->flat<float>();\n\n  OpInputList dense_features_inputs;\n  TF_RETURN_IF_ERROR(\n      context->input_list(\"dense_features\", &dense_features_inputs));\n\n  examples_.clear();\n  examples_.resize(num_examples);\n  probabilities_.resize(num_examples);\n  sampled_index_.resize(num_examples);\n  sampled_count_.resize(num_examples);\n  for (int example_id = 0; example_id < num_examples; ++example_id) {\n    Example* const example = &examples_[example_id];\n    example->sparse_features_.resize(num_sparse_features);\n    example->dense_vectors_.resize(num_dense_features);\n    example->example_weight_ = example_weights(example_id);\n    example->example_label_ = example_labels(example_id);\n  }\n  const DeviceBase::CpuWorkerThreads& worker_threads =\n      *context->device()->tensorflow_cpu_worker_threads();\n  TF_RETURN_IF_ERROR(CreateSparseFeatureRepresentation(\n      worker_threads, num_examples, num_sparse_features, weights,\n      sparse_example_indices_inputs, sparse_feature_indices_inputs,\n      sparse_feature_values_inputs, &examples_));\n  TF_RETURN_IF_ERROR(CreateDenseFeatureRepresentation(\n      worker_threads, num_examples, num_dense_features, weights,\n      dense_features_inputs, &examples_));\n  TF_RETURN_IF_ERROR(ComputeSquaredNormPerExample(\n      worker_threads, num_examples, num_sparse_features, num_dense_features,\n      &examples_));\n  return Status::OK();\n}",
        "func_hash": 183156860369052380668778554351089179754,
        "file_name": "sdca_internal.cc",
        "file_hash": 189786435377355636606855329054946360663,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2021-37672",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions an attacker can read from outside of bounds of heap allocated data by sending specially crafted illegal arguments to `tf.raw_ops.SdcaOptimizerV2`. The [implementation](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/core/kernels/sdca_internal.cc#L320-L353) does not check that the length of `example_labels` is the same as the number of examples. We have patched the issue in GitHub commit a4e138660270e7599793fa438cd7b2fc2ce215a6. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37672",
        "func_name": "Examples::Initialize",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 196801,
        "project": "gpac",
        "commit_id": "f5a038e6893019ee471b6a57490cf7a495673816",
        "project_url": "https://github.com/gpac/gpac",
        "commit_url": "https://github.com/gpac/gpac/commit/f5a038e6893019ee471b6a57490cf7a495673816",
        "commit_message": "fixed #1885",
        "target": 1,
        "irrelevant": 0,
        "func_before": "GF_Err gf_hinter_finalize(GF_ISOFile *file, GF_SDP_IODProfile IOD_Profile, u32 bandwidth)\n{\n\tu32 i, sceneT, odT, descIndex, size, size64;\n\tGF_InitialObjectDescriptor *iod;\n\tGF_SLConfig slc;\n\tGF_ISOSample *samp;\n\tBool remove_ocr;\n\tu8 *buffer;\n\tchar buf64[5000], sdpLine[5100];\n\n\n\tgf_isom_sdp_clean(file);\n\n\tif (bandwidth) {\n\t\tsprintf(buf64, \"b=AS:%d\", bandwidth);\n\t\tgf_isom_sdp_add_line(file, buf64);\n\t}\n    //xtended attribute for copyright\n    if (gf_sys_is_test_mode()) {\n        sprintf(buf64, \"a=x-copyright: %s\", \"MP4/3GP File hinted with GPAC - (c) Telecom ParisTech (http://gpac.io)\");\n    } else {\n        sprintf(buf64, \"a=x-copyright: MP4/3GP File hinted with GPAC %s - %s\", gf_gpac_version(), gf_gpac_copyright() );\n    }\n\tgf_isom_sdp_add_line(file, buf64);\n\n\tif (IOD_Profile == GF_SDP_IOD_NONE) return GF_OK;\n\n\todT = sceneT = 0;\n\tfor (i=0; i<gf_isom_get_track_count(file); i++) {\n\t\tif (!gf_isom_is_track_in_root_od(file, i+1)) continue;\n\t\tswitch (gf_isom_get_media_type(file,i+1)) {\n\t\tcase GF_ISOM_MEDIA_OD:\n\t\t\todT = i+1;\n\t\t\tbreak;\n\t\tcase GF_ISOM_MEDIA_SCENE:\n\t\t\tsceneT = i+1;\n\t\t\tbreak;\n\t\t}\n\t}\n\tremove_ocr = 0;\n\tif (IOD_Profile == GF_SDP_IOD_ISMA_STRICT) {\n\t\tIOD_Profile = GF_SDP_IOD_ISMA;\n\t\tremove_ocr = 1;\n\t}\n\n\t/*if we want ISMA like iods, we need at least BIFS */\n\tif ( (IOD_Profile == GF_SDP_IOD_ISMA) && !sceneT ) return GF_BAD_PARAM;\n\n\t/*do NOT change PLs, we assume they are correct*/\n\tiod = (GF_InitialObjectDescriptor *) gf_isom_get_root_od(file);\n\tif (!iod) return GF_NOT_SUPPORTED;\n\n\t/*rewrite an IOD with good SL config - embbed data if possible*/\n\tif (IOD_Profile == GF_SDP_IOD_ISMA) {\n\t\tGF_ESD *esd;\n\t\tBool is_ok = 1;\n\t\twhile (gf_list_count(iod->ESDescriptors)) {\n\t\t\tesd = (GF_ESD*)gf_list_get(iod->ESDescriptors, 0);\n\t\t\tgf_odf_desc_del((GF_Descriptor *) esd);\n\t\t\tgf_list_rem(iod->ESDescriptors, 0);\n\t\t}\n\n\n\t\t/*get OD esd, and embbed stream data if possible*/\n\t\tif (odT) {\n\t\t\tesd = gf_isom_get_esd(file, odT, 1);\n\t\t\tif (gf_isom_get_sample_count(file, odT)==1) {\n\t\t\t\tsamp = gf_isom_get_sample(file, odT, 1, &descIndex);\n\t\t\t\tif (samp && gf_hinter_can_embbed_data(samp->data, samp->dataLength, GF_STREAM_OD)) {\n\t\t\t\t\tInitSL_NULL(&slc);\n\t\t\t\t\tslc.predefined = 0;\n\t\t\t\t\tslc.hasRandomAccessUnitsOnlyFlag = 1;\n\t\t\t\t\tslc.timeScale = slc.timestampResolution = gf_isom_get_media_timescale(file, odT);\n\t\t\t\t\tslc.OCRResolution = 1000;\n\t\t\t\t\tslc.startCTS = samp->DTS+samp->CTS_Offset;\n\t\t\t\t\tslc.startDTS = samp->DTS;\n\t\t\t\t\t//set the SL for future extraction\n\t\t\t\t\tgf_isom_set_extraction_slc(file, odT, 1, &slc);\n\n\t\t\t\t\tsize64 = gf_base64_encode(samp->data, samp->dataLength, buf64, 2000);\n\t\t\t\t\tbuf64[size64] = 0;\n\t\t\t\t\tsprintf(sdpLine, \"data:application/mpeg4-od-au;base64,%s\", buf64);\n\n\t\t\t\t\tif (esd->decoderConfig) {\n\t\t\t\t\t\tesd->decoderConfig->avgBitrate = 0;\n\t\t\t\t\t\tesd->decoderConfig->bufferSizeDB = samp->dataLength;\n\t\t\t\t\t\tesd->decoderConfig->maxBitrate = 0;\n\t\t\t\t\t}\n\t\t\t\t\tsize64 = (u32) strlen(sdpLine)+1;\n\t\t\t\t\tesd->URLString = (char*)gf_malloc(sizeof(char) * size64);\n\t\t\t\t\tstrcpy(esd->URLString, sdpLine);\n\t\t\t\t} else {\n\t\t\t\t\tGF_LOG(GF_LOG_WARNING, GF_LOG_RTP, (\"[rtp hinter] OD sample too large to be embedded in IOD - ISMA disabled\\n\"));\n\t\t\t\t\tis_ok = 0;\n\t\t\t\t}\n\t\t\t\tgf_isom_sample_del(&samp);\n\t\t\t}\n\t\t\tif (remove_ocr) esd->OCRESID = 0;\n\t\t\telse if (esd->OCRESID == esd->ESID) esd->OCRESID = 0;\n\n\t\t\t//OK, add this to our IOD\n\t\t\tgf_list_add(iod->ESDescriptors, esd);\n\t\t}\n\n\t\tesd = gf_isom_get_esd(file, sceneT, 1);\n\t\tif (gf_isom_get_sample_count(file, sceneT)==1) {\n\t\t\tsamp = gf_isom_get_sample(file, sceneT, 1, &descIndex);\n\t\t\tif (samp && gf_hinter_can_embbed_data(samp->data, samp->dataLength, GF_STREAM_SCENE)) {\n\n\t\t\t\tslc.timeScale = slc.timestampResolution = gf_isom_get_media_timescale(file, sceneT);\n\t\t\t\tslc.OCRResolution = 1000;\n\t\t\t\tslc.startCTS = samp->DTS+samp->CTS_Offset;\n\t\t\t\tslc.startDTS = samp->DTS;\n\t\t\t\t//set the SL for future extraction\n\t\t\t\tgf_isom_set_extraction_slc(file, sceneT, 1, &slc);\n\t\t\t\t//encode in Base64 the sample\n\t\t\t\tsize64 = gf_base64_encode(samp->data, samp->dataLength, buf64, 2000);\n\t\t\t\tbuf64[size64] = 0;\n\t\t\t\tsprintf(sdpLine, \"data:application/mpeg4-bifs-au;base64,%s\", buf64);\n\n\t\t\t\tif (esd->decoderConfig) {\n\t\t\t\t\tesd->decoderConfig->avgBitrate = 0;\n\t\t\t\t\tesd->decoderConfig->bufferSizeDB = samp->dataLength;\n\t\t\t\t\tesd->decoderConfig->maxBitrate = 0;\n\t\t\t\t}\n\t\t\t\tesd->URLString = (char*)gf_malloc(sizeof(char) * (strlen(sdpLine)+1));\n\t\t\t\tstrcpy(esd->URLString, sdpLine);\n\t\t\t} else {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_RTP, (\"[rtp hinter] Scene description sample too large to be embedded in IOD - ISMA disabled\\n\"));\n\t\t\t\tis_ok = 0;\n\t\t\t}\n\t\t\tgf_isom_sample_del(&samp);\n\t\t}\n\t\tif (remove_ocr) esd->OCRESID = 0;\n\t\telse if (esd->OCRESID == esd->ESID) esd->OCRESID = 0;\n\n\t\tgf_list_add(iod->ESDescriptors, esd);\n\n\t\tif (is_ok) {\n\t\t\tu32 has_a, has_v, has_i_a, has_i_v;\n\t\t\thas_a = has_v = has_i_a = has_i_v = 0;\n\t\t\tfor (i=0; i<gf_isom_get_track_count(file); i++) {\n\t\t\t\tesd = gf_isom_get_esd(file, i+1, 1);\n\t\t\t\tif (!esd) continue;\n\t\t\t\tif (esd->decoderConfig) {\n\t\t\t\t\tif (esd->decoderConfig->streamType==GF_STREAM_VISUAL) {\n\t\t\t\t\t\tif (esd->decoderConfig->objectTypeIndication==GF_CODECID_MPEG4_PART2) has_i_v ++;\n\t\t\t\t\t\telse has_v++;\n\t\t\t\t\t} else if (esd->decoderConfig->streamType==GF_STREAM_AUDIO) {\n\t\t\t\t\t\tif (esd->decoderConfig->objectTypeIndication==GF_CODECID_AAC_MPEG4) has_i_a ++;\n\t\t\t\t\t\telse has_a++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tgf_odf_desc_del((GF_Descriptor *)esd);\n\t\t\t}\n\t\t\t/*only 1 MPEG-4 visual max and 1 MPEG-4 audio max for ISMA compliancy*/\n\t\t\tif (!has_v && !has_a && (has_i_v<=1) && (has_i_a<=1)) {\n\t\t\t\tsprintf(sdpLine, \"a=isma-compliance:1,1.0,1\");\n\t\t\t\tgf_isom_sdp_add_line(file, sdpLine);\n\t\t\t}\n\t\t}\n\t}\n\n\t//encode the IOD\n\tbuffer = NULL;\n\tsize = 0;\n\tgf_odf_desc_write((GF_Descriptor *) iod, &buffer, &size);\n\tgf_odf_desc_del((GF_Descriptor *)iod);\n\n\t//encode in Base64 the iod\n\tsize64 = gf_base64_encode(buffer, size, buf64, 2000);\n\tbuf64[size64] = 0;\n\tgf_free(buffer);\n\n\tsprintf(sdpLine, \"a=mpeg4-iod:\\\"data:application/mpeg4-iod;base64,%s\\\"\", buf64);\n\tgf_isom_sdp_add_line(file, sdpLine);\n\n\treturn GF_OK;\n}",
        "func_hash": 123828913884454942556959015680908121097,
        "file_name": "isom_hinter.c",
        "file_hash": 94306079889139284150664165649647698827,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2021-40567",
        "cve_desc": "Segmentation fault vulnerability exists in Gpac through 1.0.1 via the gf_odf_size_descriptor function in desc_private.c when using mp4box, which causes a denial of service.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-40567",
        "func_name": "gf_hinter_finalize",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 196805,
        "project": "mruby",
        "commit_id": "aaa28a508903041dd7399d4159a8ace9766b022f",
        "project_url": "https://github.com/mruby/mruby",
        "commit_url": "https://github.com/mruby/mruby/commit/aaa28a508903041dd7399d4159a8ace9766b022f",
        "commit_message": "vm.c: stack may be reallocated in functions calls.\n\nProbably due to recursive VM calls via `mrb_funcall()`.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "mrb_vm_exec(mrb_state *mrb, const struct RProc *proc, const mrb_code *pc)\n{\n  /* mrb_assert(MRB_PROC_CFUNC_P(proc)) */\n  const mrb_irep *irep = proc->body.irep;\n  const mrb_pool_value *pool = irep->pool;\n  const mrb_sym *syms = irep->syms;\n  mrb_code insn;\n  int ai = mrb_gc_arena_save(mrb);\n  struct mrb_jmpbuf *prev_jmp = mrb->jmp;\n  struct mrb_jmpbuf c_jmp;\n  uint32_t a;\n  uint16_t b;\n  uint16_t c;\n  mrb_sym mid;\n  const struct mrb_irep_catch_handler *ch;\n\n#ifdef DIRECT_THREADED\n  static const void * const optable[] = {\n#define OPCODE(x,_) &&L_OP_ ## x,\n#include \"mruby/ops.h\"\n#undef OPCODE\n  };\n#endif\n\n  mrb_bool exc_catched = FALSE;\nRETRY_TRY_BLOCK:\n\n  MRB_TRY(&c_jmp) {\n\n  if (exc_catched) {\n    exc_catched = FALSE;\n    mrb_gc_arena_restore(mrb, ai);\n    if (mrb->exc && mrb->exc->tt == MRB_TT_BREAK)\n      goto L_BREAK;\n    goto L_RAISE;\n  }\n  mrb->jmp = &c_jmp;\n  mrb_vm_ci_proc_set(mrb->c->ci, proc);\n\n#define regs (mrb->c->ci->stack)\n  INIT_DISPATCH {\n    CASE(OP_NOP, Z) {\n      /* do nothing */\n      NEXT;\n    }\n\n    CASE(OP_MOVE, BB) {\n      regs[a] = regs[b];\n      NEXT;\n    }\n\n    CASE(OP_LOADL, BB) {\n      switch (pool[b].tt) {   /* number */\n      case IREP_TT_INT32:\n        regs[a] = mrb_int_value(mrb, (mrb_int)pool[b].u.i32);\n        break;\n      case IREP_TT_INT64:\n#if defined(MRB_INT64)\n        regs[a] = mrb_int_value(mrb, (mrb_int)pool[b].u.i64);\n        break;\n#else\n#if defined(MRB_64BIT)\n        if (INT32_MIN <= pool[b].u.i64 && pool[b].u.i64 <= INT32_MAX) {\n          regs[a] = mrb_int_value(mrb, (mrb_int)pool[b].u.i64);\n          break;\n        }\n#endif\n        goto L_INT_OVERFLOW;\n#endif\n      case IREP_TT_BIGINT:\n        goto L_INT_OVERFLOW;\n#ifndef MRB_NO_FLOAT\n      case IREP_TT_FLOAT:\n        regs[a] = mrb_float_value(mrb, pool[b].u.f);\n        break;\n#endif\n      default:\n        /* should not happen (tt:string) */\n        regs[a] = mrb_nil_value();\n        break;\n      }\n      NEXT;\n    }\n\n    CASE(OP_LOADI, BB) {\n      SET_FIXNUM_VALUE(regs[a], b);\n      NEXT;\n    }\n\n    CASE(OP_LOADINEG, BB) {\n      SET_FIXNUM_VALUE(regs[a], -b);\n      NEXT;\n    }\n\n    CASE(OP_LOADI__1,B) goto L_LOADI;\n    CASE(OP_LOADI_0,B) goto L_LOADI;\n    CASE(OP_LOADI_1,B) goto L_LOADI;\n    CASE(OP_LOADI_2,B) goto L_LOADI;\n    CASE(OP_LOADI_3,B) goto L_LOADI;\n    CASE(OP_LOADI_4,B) goto L_LOADI;\n    CASE(OP_LOADI_5,B) goto L_LOADI;\n    CASE(OP_LOADI_6,B) goto L_LOADI;\n    CASE(OP_LOADI_7, B) {\n    L_LOADI:\n      SET_FIXNUM_VALUE(regs[a], (mrb_int)insn - (mrb_int)OP_LOADI_0);\n      NEXT;\n    }\n\n    CASE(OP_LOADI16, BS) {\n      SET_FIXNUM_VALUE(regs[a], (mrb_int)(int16_t)b);\n      NEXT;\n    }\n\n    CASE(OP_LOADI32, BSS) {\n      SET_INT_VALUE(mrb, regs[a], (int32_t)(((uint32_t)b<<16)+c));\n      NEXT;\n    }\n\n    CASE(OP_LOADSYM, BB) {\n      SET_SYM_VALUE(regs[a], syms[b]);\n      NEXT;\n    }\n\n    CASE(OP_LOADNIL, B) {\n      SET_NIL_VALUE(regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_LOADSELF, B) {\n      regs[a] = regs[0];\n      NEXT;\n    }\n\n    CASE(OP_LOADT, B) {\n      SET_TRUE_VALUE(regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_LOADF, B) {\n      SET_FALSE_VALUE(regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETGV, BB) {\n      mrb_value val = mrb_gv_get(mrb, syms[b]);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETGV, BB) {\n      mrb_gv_set(mrb, syms[b], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETSV, BB) {\n      mrb_value val = mrb_vm_special_get(mrb, syms[b]);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETSV, BB) {\n      mrb_vm_special_set(mrb, syms[b], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETIV, BB) {\n      regs[a] = mrb_iv_get(mrb, regs[0], syms[b]);\n      NEXT;\n    }\n\n    CASE(OP_SETIV, BB) {\n      mrb_iv_set(mrb, regs[0], syms[b], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETCV, BB) {\n      mrb_value val;\n      val = mrb_vm_cv_get(mrb, syms[b]);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETCV, BB) {\n      mrb_vm_cv_set(mrb, syms[b], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETIDX, B) {\n      mrb_value va = regs[a], vb = regs[a+1];\n      switch (mrb_type(va)) {\n      case MRB_TT_ARRAY:\n        if (!mrb_integer_p(vb)) goto getidx_fallback;\n        regs[a] = mrb_ary_entry(va, mrb_integer(vb));\n        break;\n      case MRB_TT_HASH:\n        regs[a] = mrb_hash_get(mrb, va, vb);\n        break;\n      case MRB_TT_STRING:\n        switch (mrb_type(vb)) {\n        case MRB_TT_INTEGER:\n        case MRB_TT_STRING:\n        case MRB_TT_RANGE:\n          regs[a] = mrb_str_aref(mrb, va, vb, mrb_undef_value());\n          break;\n        default:\n          goto getidx_fallback;\n        }\n        break;\n      default:\n      getidx_fallback:\n        mid = MRB_OPSYM(aref);\n        goto L_SEND_SYM;\n      }\n      NEXT;\n    }\n\n    CASE(OP_SETIDX, B) {\n      c = 2;\n      mid = MRB_OPSYM(aset);\n      SET_NIL_VALUE(regs[a+3]);\n      goto L_SENDB_SYM;\n    }\n\n    CASE(OP_GETCONST, BB) {\n      regs[a] = mrb_vm_const_get(mrb, syms[b]);\n      NEXT;\n    }\n\n    CASE(OP_SETCONST, BB) {\n      mrb_vm_const_set(mrb, syms[b], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETMCNST, BB) {\n      regs[a] = mrb_const_get(mrb, regs[a], syms[b]);\n      NEXT;\n    }\n\n    CASE(OP_SETMCNST, BB) {\n      mrb_const_set(mrb, regs[a+1], syms[b], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETUPVAR, BBB) {\n      mrb_value *regs_a = regs + a;\n      struct REnv *e = uvenv(mrb, c);\n\n      if (e && b < MRB_ENV_LEN(e)) {\n        *regs_a = e->stack[b];\n      }\n      else {\n        *regs_a = mrb_nil_value();\n      }\n      NEXT;\n    }\n\n    CASE(OP_SETUPVAR, BBB) {\n      struct REnv *e = uvenv(mrb, c);\n\n      if (e) {\n        mrb_value *regs_a = regs + a;\n\n        if (b < MRB_ENV_LEN(e)) {\n          e->stack[b] = *regs_a;\n          mrb_write_barrier(mrb, (struct RBasic*)e);\n        }\n      }\n      NEXT;\n    }\n\n    CASE(OP_JMP, S) {\n      pc += (int16_t)a;\n      JUMP;\n    }\n    CASE(OP_JMPIF, BS) {\n      if (mrb_test(regs[a])) {\n        pc += (int16_t)b;\n        JUMP;\n      }\n      NEXT;\n    }\n    CASE(OP_JMPNOT, BS) {\n      if (!mrb_test(regs[a])) {\n        pc += (int16_t)b;\n        JUMP;\n      }\n      NEXT;\n    }\n    CASE(OP_JMPNIL, BS) {\n      if (mrb_nil_p(regs[a])) {\n        pc += (int16_t)b;\n        JUMP;\n      }\n      NEXT;\n    }\n\n    CASE(OP_JMPUW, S) {\n      a = (uint32_t)((pc - irep->iseq) + (int16_t)a);\n      CHECKPOINT_RESTORE(RBREAK_TAG_JUMP) {\n        struct RBreak *brk = (struct RBreak*)mrb->exc;\n        mrb_value target = mrb_break_value_get(brk);\n        mrb_assert(mrb_integer_p(target));\n        a = (uint32_t)mrb_integer(target);\n        mrb_assert(a >= 0 && a < irep->ilen);\n      }\n      CHECKPOINT_MAIN(RBREAK_TAG_JUMP) {\n        ch = catch_handler_find(mrb, mrb->c->ci, pc, MRB_CATCH_FILTER_ENSURE);\n        if (ch) {\n          /* avoiding a jump from a catch handler into the same handler */\n          if (a < mrb_irep_catch_handler_unpack(ch->begin) || a >= mrb_irep_catch_handler_unpack(ch->end)) {\n            THROW_TAGGED_BREAK(mrb, RBREAK_TAG_JUMP, proc, mrb_fixnum_value(a));\n          }\n        }\n      }\n      CHECKPOINT_END(RBREAK_TAG_JUMP);\n\n      mrb->exc = NULL; /* clear break object */\n      pc = irep->iseq + a;\n      JUMP;\n    }\n\n    CASE(OP_EXCEPT, B) {\n      mrb_value exc;\n\n      if (mrb->exc == NULL) {\n        exc = mrb_nil_value();\n      }\n      else {\n        switch (mrb->exc->tt) {\n        case MRB_TT_BREAK:\n        case MRB_TT_EXCEPTION:\n          exc = mrb_obj_value(mrb->exc);\n          break;\n        default:\n          mrb_assert(!\"bad mrb_type\");\n          exc = mrb_nil_value();\n          break;\n        }\n        mrb->exc = NULL;\n      }\n      regs[a] = exc;\n      NEXT;\n    }\n    CASE(OP_RESCUE, BB) {\n      mrb_value exc = regs[a];  /* exc on stack */\n      mrb_value e = regs[b];\n      struct RClass *ec;\n\n      switch (mrb_type(e)) {\n      case MRB_TT_CLASS:\n      case MRB_TT_MODULE:\n        break;\n      default:\n        {\n          mrb_value exc;\n\n          exc = mrb_exc_new_lit(mrb, E_TYPE_ERROR,\n                                    \"class or module required for rescue clause\");\n          mrb_exc_set(mrb, exc);\n          goto L_RAISE;\n        }\n      }\n      ec = mrb_class_ptr(e);\n      regs[b] = mrb_bool_value(mrb_obj_is_kind_of(mrb, exc, ec));\n      NEXT;\n    }\n\n    CASE(OP_RAISEIF, B) {\n      mrb_value exc = regs[a];\n      if (mrb_break_p(exc)) {\n        mrb->exc = mrb_obj_ptr(exc);\n        goto L_BREAK;\n      }\n      mrb_exc_set(mrb, exc);\n      if (mrb->exc) {\n        goto L_RAISE;\n      }\n      NEXT;\n    }\n\n    CASE(OP_SSEND, BBB) {\n      regs[a] = regs[0];\n      insn = OP_SEND;\n    }\n    goto L_SENDB;\n\n    CASE(OP_SSENDB, BBB) {\n      regs[a] = regs[0];\n    }\n    goto L_SENDB;\n\n    CASE(OP_SEND, BBB)\n    goto L_SENDB;\n\n    L_SEND_SYM:\n    c = 1;\n    /* push nil after arguments */\n    SET_NIL_VALUE(regs[a+2]);\n    goto L_SENDB_SYM;\n\n    CASE(OP_SENDB, BBB)\n    L_SENDB:\n    mid = syms[b];\n    L_SENDB_SYM:\n    {\n      mrb_callinfo *ci = mrb->c->ci;\n      mrb_method_t m;\n      struct RClass *cls;\n      mrb_value recv, blk;\n\n      ARGUMENT_NORMALIZE(a, &c, insn);\n\n      recv = regs[a];\n      cls = mrb_class(mrb, recv);\n      m = mrb_method_search_vm(mrb, &cls, mid);\n      if (MRB_METHOD_UNDEF_P(m)) {\n        m = prepare_missing(mrb, recv, mid, &cls, a, &c, blk, 0);\n        mid = MRB_SYM(method_missing);\n      }\n\n      /* push callinfo */\n      ci = cipush(mrb, a, 0, cls, NULL, mid, c);\n\n      if (MRB_METHOD_CFUNC_P(m)) {\n        if (MRB_METHOD_PROC_P(m)) {\n          struct RProc *p = MRB_METHOD_PROC(m);\n\n          mrb_vm_ci_proc_set(ci, p);\n          recv = p->body.func(mrb, recv);\n        }\n        else {\n          if (MRB_METHOD_NOARG_P(m)) {\n            check_method_noarg(mrb, ci);\n          }\n          recv = MRB_METHOD_FUNC(m)(mrb, recv);\n        }\n        mrb_gc_arena_shrink(mrb, ai);\n        if (mrb->exc) goto L_RAISE;\n        ci = mrb->c->ci;\n        if (mrb_proc_p(blk)) {\n          struct RProc *p = mrb_proc_ptr(blk);\n          if (p && !MRB_PROC_STRICT_P(p) && MRB_PROC_ENV(p) == mrb_vm_ci_env(&ci[-1])) {\n            p->flags |= MRB_PROC_ORPHAN;\n          }\n        }\n        if (!ci->u.target_class) { /* return from context modifying method (resume/yield) */\n          if (ci->cci == CINFO_RESUMED) {\n            mrb->jmp = prev_jmp;\n            return recv;\n          }\n          else {\n            mrb_assert(!MRB_PROC_CFUNC_P(ci[-1].proc));\n            proc = ci[-1].proc;\n            irep = proc->body.irep;\n            pool = irep->pool;\n            syms = irep->syms;\n          }\n        }\n        ci->stack[0] = recv;\n        /* pop stackpos */\n        ci = cipop(mrb);\n        pc = ci->pc;\n      }\n      else {\n        /* setup environment for calling method */\n        mrb_vm_ci_proc_set(ci, (proc = MRB_METHOD_PROC(m)));\n        irep = proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n        mrb_stack_extend(mrb, (irep->nregs < 4) ? 4 : irep->nregs);\n        pc = irep->iseq;\n      }\n    }\n    JUMP;\n\n    CASE(OP_CALL, Z) {\n      mrb_callinfo *ci = mrb->c->ci;\n      mrb_value recv = ci->stack[0];\n      struct RProc *m = mrb_proc_ptr(recv);\n\n      /* replace callinfo */\n      ci->u.target_class = MRB_PROC_TARGET_CLASS(m);\n      mrb_vm_ci_proc_set(ci, m);\n      if (MRB_PROC_ENV_P(m)) {\n        ci->mid = MRB_PROC_ENV(m)->mid;\n      }\n\n      /* prepare stack */\n      if (MRB_PROC_CFUNC_P(m)) {\n        recv = MRB_PROC_CFUNC(m)(mrb, recv);\n        mrb_gc_arena_shrink(mrb, ai);\n        if (mrb->exc) goto L_RAISE;\n        /* pop stackpos */\n        ci = cipop(mrb);\n        pc = ci->pc;\n        ci[1].stack[0] = recv;\n        irep = mrb->c->ci->proc->body.irep;\n      }\n      else {\n        /* setup environment for calling method */\n        proc = m;\n        irep = m->body.irep;\n        if (!irep) {\n          mrb->c->ci->stack[0] = mrb_nil_value();\n          a = 0;\n          c = OP_R_NORMAL;\n          goto L_OP_RETURN_BODY;\n        }\n        mrb_int nargs = mrb_ci_bidx(ci)+1;\n        if (nargs < irep->nregs) {\n          mrb_stack_extend(mrb, irep->nregs);\n          stack_clear(regs+nargs, irep->nregs-nargs);\n        }\n        if (MRB_PROC_ENV_P(m)) {\n          regs[0] = MRB_PROC_ENV(m)->stack[0];\n        }\n        pc = irep->iseq;\n      }\n      pool = irep->pool;\n      syms = irep->syms;\n      JUMP;\n    }\n\n    CASE(OP_SUPER, BB) {\n      mrb_method_t m;\n      struct RClass *cls;\n      mrb_callinfo *ci = mrb->c->ci;\n      mrb_value recv, blk;\n      const struct RProc *p = ci->proc;\n      mrb_sym mid = ci->mid;\n      struct RClass* target_class = MRB_PROC_TARGET_CLASS(p);\n\n      if (MRB_PROC_ENV_P(p) && p->e.env->mid && p->e.env->mid != mid) { /* alias support */\n        mid = p->e.env->mid;    /* restore old mid */\n      }\n\n      if (mid == 0 || !target_class) {\n        mrb_value exc = mrb_exc_new_lit(mrb, E_NOMETHOD_ERROR, \"super called outside of method\");\n        mrb_exc_set(mrb, exc);\n        goto L_RAISE;\n      }\n      if (target_class->flags & MRB_FL_CLASS_IS_PREPENDED) {\n        target_class = mrb_vm_ci_target_class(ci);\n      }\n      else if (target_class->tt == MRB_TT_MODULE) {\n        target_class = mrb_vm_ci_target_class(ci);\n        if (target_class->tt != MRB_TT_ICLASS) {\n          goto super_typeerror;\n        }\n      }\n      recv = regs[0];\n      if (!mrb_obj_is_kind_of(mrb, recv, target_class)) {\n      super_typeerror: ;\n        mrb_value exc = mrb_exc_new_lit(mrb, E_TYPE_ERROR,\n                                            \"self has wrong type to call super in this context\");\n        mrb_exc_set(mrb, exc);\n        goto L_RAISE;\n      }\n\n      ARGUMENT_NORMALIZE(a, &b, OP_SUPER);\n\n      cls = target_class->super;\n      m = mrb_method_search_vm(mrb, &cls, mid);\n      if (MRB_METHOD_UNDEF_P(m)) {\n        m = prepare_missing(mrb, recv, mid, &cls, a, &b, blk, 1);\n        mid = MRB_SYM(method_missing);\n      }\n\n      /* push callinfo */\n      ci = cipush(mrb, a, 0, cls, NULL, mid, b);\n\n      /* prepare stack */\n      ci->stack[0] = recv;\n\n      if (MRB_METHOD_CFUNC_P(m)) {\n        mrb_value v;\n\n        if (MRB_METHOD_PROC_P(m)) {\n          mrb_vm_ci_proc_set(ci, MRB_METHOD_PROC(m));\n        }\n        v = MRB_METHOD_CFUNC(m)(mrb, recv);\n        mrb_gc_arena_restore(mrb, ai);\n        if (mrb->exc) goto L_RAISE;\n        ci = mrb->c->ci;\n        mrb_assert(!mrb_break_p(v));\n        if (!mrb_vm_ci_target_class(ci)) { /* return from context modifying method (resume/yield) */\n          if (ci->cci == CINFO_RESUMED) {\n            mrb->jmp = prev_jmp;\n            return v;\n          }\n          else {\n            mrb_assert(!MRB_PROC_CFUNC_P(ci[-1].proc));\n            proc = ci[-1].proc;\n            irep = proc->body.irep;\n            pool = irep->pool;\n            syms = irep->syms;\n          }\n        }\n        mrb->c->ci->stack[0] = v;\n        ci = cipop(mrb);\n        pc = ci->pc;\n      }\n      else {\n        /* setup environment for calling method */\n        mrb_vm_ci_proc_set(ci, (proc = MRB_METHOD_PROC(m)));\n        irep = proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n        mrb_stack_extend(mrb, (irep->nregs < 4) ? 4 : irep->nregs);\n        pc = irep->iseq;\n      }\n      JUMP;\n    }\n\n    CASE(OP_ARGARY, BS) {\n      mrb_int m1 = (b>>11)&0x3f;\n      mrb_int r  = (b>>10)&0x1;\n      mrb_int m2 = (b>>5)&0x1f;\n      mrb_int kd = (b>>4)&0x1;\n      mrb_int lv = (b>>0)&0xf;\n      mrb_value *stack;\n\n      if (mrb->c->ci->mid == 0 || mrb_vm_ci_target_class(mrb->c->ci) == NULL) {\n        mrb_value exc;\n\n      L_NOSUPER:\n        exc = mrb_exc_new_lit(mrb, E_NOMETHOD_ERROR, \"super called outside of method\");\n        mrb_exc_set(mrb, exc);\n        goto L_RAISE;\n      }\n      if (lv == 0) stack = regs + 1;\n      else {\n        struct REnv *e = uvenv(mrb, lv-1);\n        if (!e) goto L_NOSUPER;\n        if (MRB_ENV_LEN(e) <= m1+r+m2+1)\n          goto L_NOSUPER;\n        stack = e->stack + 1;\n      }\n      if (r == 0) {\n        regs[a] = mrb_ary_new_from_values(mrb, m1+m2, stack);\n      }\n      else {\n        mrb_value *pp = NULL;\n        struct RArray *rest;\n        mrb_int len = 0;\n\n        if (mrb_array_p(stack[m1])) {\n          struct RArray *ary = mrb_ary_ptr(stack[m1]);\n\n          pp = ARY_PTR(ary);\n          len = ARY_LEN(ary);\n        }\n        regs[a] = mrb_ary_new_capa(mrb, m1+len+m2);\n        rest = mrb_ary_ptr(regs[a]);\n        if (m1 > 0) {\n          stack_copy(ARY_PTR(rest), stack, m1);\n        }\n        if (len > 0) {\n          stack_copy(ARY_PTR(rest)+m1, pp, len);\n        }\n        if (m2 > 0) {\n          stack_copy(ARY_PTR(rest)+m1+len, stack+m1+1, m2);\n        }\n        ARY_SET_LEN(rest, m1+len+m2);\n      }\n      if (kd) {\n        regs[a+1] = stack[m1+r+m2];\n        regs[a+2] = stack[m1+r+m2+1];\n      }\n      else {\n        regs[a+1] = stack[m1+r+m2];\n      }\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_ENTER, W) {\n      mrb_int m1 = MRB_ASPEC_REQ(a);\n      mrb_int o  = MRB_ASPEC_OPT(a);\n      mrb_int r  = MRB_ASPEC_REST(a);\n      mrb_int m2 = MRB_ASPEC_POST(a);\n      mrb_int kd = (MRB_ASPEC_KEY(a) > 0 || MRB_ASPEC_KDICT(a))? 1 : 0;\n      /* unused\n      int b  = MRB_ASPEC_BLOCK(a);\n      */\n      mrb_int const len = m1 + o + r + m2;\n\n      mrb_callinfo *ci = mrb->c->ci;\n      mrb_int argc = ci->n;\n      mrb_value *argv = regs+1;\n      mrb_value * const argv0 = argv;\n      mrb_int const kw_pos = len + kd;    /* where kwhash should be */\n      mrb_int const blk_pos = kw_pos + 1; /* where block should be */\n      mrb_value blk = regs[mrb_ci_bidx(ci)];\n      mrb_value kdict = mrb_nil_value();\n\n      /* keyword arguments */\n      if (ci->nk > 0) {\n        mrb_int kidx = mrb_ci_kidx(ci);\n        kdict = regs[kidx];\n        if (!mrb_hash_p(kdict) || mrb_hash_size(mrb, kdict) == 0) {\n          kdict = mrb_nil_value();\n          ci->nk = 0;\n        }\n      }\n      if (!kd && !mrb_nil_p(kdict)) {\n        if (argc < 14) {\n          ci->n++;\n          argc++;    /* include kdict in normal arguments */\n        }\n        else if (argc == 14) {\n          /* pack arguments and kdict */\n          regs[1] = mrb_ary_new_from_values(mrb, argc+1, &regs[1]);\n          argc = ci->n = 15;\n        }\n        else {/* argc == 15 */\n          /* push kdict to packed arguments */\n          mrb_ary_push(mrb, regs[1], regs[2]);\n        }\n        ci->nk = 0;\n      }\n      if (kd && MRB_ASPEC_KEY(a) > 0 && mrb_hash_p(kdict)) {\n        kdict = mrb_hash_dup(mrb, kdict);\n      }\n\n      /* arguments is passed with Array */\n      if (argc == 15) {\n        struct RArray *ary = mrb_ary_ptr(regs[1]);\n        argv = ARY_PTR(ary);\n        argc = (int)ARY_LEN(ary);\n        mrb_gc_protect(mrb, regs[1]);\n      }\n\n      /* strict argument check */\n      if (ci->proc && MRB_PROC_STRICT_P(ci->proc)) {\n        if (argc < m1 + m2 || (r == 0 && argc > len)) {\n          argnum_error(mrb, m1+m2);\n          goto L_RAISE;\n        }\n      }\n      /* extract first argument array to arguments */\n      else if (len > 1 && argc == 1 && mrb_array_p(argv[0])) {\n        mrb_gc_protect(mrb, argv[0]);\n        argc = (int)RARRAY_LEN(argv[0]);\n        argv = RARRAY_PTR(argv[0]);\n      }\n\n      /* rest arguments */\n      mrb_value rest = mrb_nil_value();\n      if (argc < len) {\n        mrb_int mlen = m2;\n        if (argc < m1+m2) {\n          mlen = m1 < argc ? argc - m1 : 0;\n        }\n\n        /* copy mandatory and optional arguments */\n        if (argv0 != argv && argv) {\n          value_move(&regs[1], argv, argc-mlen); /* m1 + o */\n        }\n        if (argc < m1) {\n          stack_clear(&regs[argc+1], m1-argc);\n        }\n        /* copy post mandatory arguments */\n        if (mlen) {\n          value_move(&regs[len-m2+1], &argv[argc-mlen], mlen);\n        }\n        if (mlen < m2) {\n          stack_clear(&regs[len-m2+mlen+1], m2-mlen);\n        }\n        /* initialize rest arguments with empty Array */\n        if (r) {\n          rest = mrb_ary_new_capa(mrb, 0);\n          regs[m1+o+1] = rest;\n        }\n        /* skip initializer of passed arguments */\n        if (o > 0 && argc > m1+m2)\n          pc += (argc - m1 - m2)*3;\n      }\n      else {\n        mrb_int rnum = 0;\n        if (argv0 != argv) {\n          value_move(&regs[1], argv, m1+o);\n        }\n        if (r) {\n          rnum = argc-m1-o-m2;\n          rest = mrb_ary_new_from_values(mrb, rnum, argv+m1+o);\n          regs[m1+o+1] = rest;\n        }\n        if (m2 > 0 && argc-m2 > m1) {\n          value_move(&regs[m1+o+r+1], &argv[m1+o+rnum], m2);\n        }\n        pc += o*3;\n      }\n\n      /* need to be update blk first to protect blk from GC */\n      regs[blk_pos] = blk;              /* move block */\n      if (kd) {\n        if (mrb_nil_p(kdict))\n          kdict = mrb_hash_new_capa(mrb, 0);\n        regs[kw_pos] = kdict;           /* set kwhash */\n      }\n\n      /* format arguments for generated code */\n      mrb->c->ci->n = len;\n\n      /* clear local (but non-argument) variables */\n      if (irep->nlocals-blk_pos-1 > 0) {\n        stack_clear(&regs[blk_pos+1], irep->nlocals-blk_pos-1);\n      }\n      JUMP;\n    }\n\n    CASE(OP_KARG, BB) {\n      mrb_value k = mrb_symbol_value(syms[b]);\n      mrb_int kidx = mrb_ci_kidx(mrb->c->ci);\n      mrb_value kdict;\n\n      if (kidx < 0 || !mrb_hash_p(kdict=regs[kidx]) || !mrb_hash_key_p(mrb, kdict, k)) {\n        mrb_value str = mrb_format(mrb, \"missing keyword: %v\", k);\n        mrb_exc_set(mrb, mrb_exc_new_str(mrb, E_ARGUMENT_ERROR, str));\n        goto L_RAISE;\n      }\n      regs[a] = mrb_hash_get(mrb, kdict, k);\n      mrb_hash_delete_key(mrb, kdict, k);\n      NEXT;\n    }\n\n    CASE(OP_KEY_P, BB) {\n      mrb_value k = mrb_symbol_value(syms[b]);\n      mrb_int kidx = mrb_ci_kidx(mrb->c->ci);\n      mrb_value kdict;\n      mrb_bool key_p = FALSE;\n\n      if (kidx >= 0 && mrb_hash_p(kdict=regs[kidx])) {\n        key_p = mrb_hash_key_p(mrb, kdict, k);\n      }\n      regs[a] = mrb_bool_value(key_p);\n      NEXT;\n    }\n\n    CASE(OP_KEYEND, Z) {\n      mrb_int kidx = mrb_ci_kidx(mrb->c->ci);\n      mrb_value kdict;\n\n      if (kidx >= 0 && mrb_hash_p(kdict=regs[kidx]) && !mrb_hash_empty_p(mrb, kdict)) {\n        mrb_value keys = mrb_hash_keys(mrb, kdict);\n        mrb_value key1 = RARRAY_PTR(keys)[0];\n        mrb_value str = mrb_format(mrb, \"unknown keyword: %v\", key1);\n        mrb_exc_set(mrb, mrb_exc_new_str(mrb, E_ARGUMENT_ERROR, str));\n        goto L_RAISE;\n      }\n      NEXT;\n    }\n\n    CASE(OP_BREAK, B) {\n      c = OP_R_BREAK;\n      goto L_RETURN;\n    }\n    CASE(OP_RETURN_BLK, B) {\n      c = OP_R_RETURN;\n      goto L_RETURN;\n    }\n    CASE(OP_RETURN, B)\n    c = OP_R_NORMAL;\n    L_RETURN:\n    {\n      mrb_callinfo *ci;\n\n      ci = mrb->c->ci;\n      if (ci->mid) {\n        mrb_value blk = regs[mrb_ci_bidx(ci)];\n\n        if (mrb_proc_p(blk)) {\n          struct RProc *p = mrb_proc_ptr(blk);\n\n          if (!MRB_PROC_STRICT_P(p) &&\n              ci > mrb->c->cibase && MRB_PROC_ENV(p) == mrb_vm_ci_env(&ci[-1])) {\n            p->flags |= MRB_PROC_ORPHAN;\n          }\n        }\n      }\n\n      if (mrb->exc) {\n      L_RAISE:\n        ci = mrb->c->ci;\n        if (ci == mrb->c->cibase) {\n          ch = catch_handler_find(mrb, ci, pc, MRB_CATCH_FILTER_ALL);\n          if (ch == NULL) goto L_FTOP;\n          goto L_CATCH;\n        }\n        while ((ch = catch_handler_find(mrb, ci, pc, MRB_CATCH_FILTER_ALL)) == NULL) {\n          ci = cipop(mrb);\n          if (ci[1].cci == CINFO_SKIP && prev_jmp) {\n            mrb->jmp = prev_jmp;\n            MRB_THROW(prev_jmp);\n          }\n          pc = ci[0].pc;\n          if (ci == mrb->c->cibase) {\n            ch = catch_handler_find(mrb, ci, pc, MRB_CATCH_FILTER_ALL);\n            if (ch == NULL) {\n            L_FTOP:             /* fiber top */\n              if (mrb->c == mrb->root_c) {\n                mrb->c->ci->stack = mrb->c->stbase;\n                goto L_STOP;\n              }\n              else {\n                struct mrb_context *c = mrb->c;\n\n                c->status = MRB_FIBER_TERMINATED;\n                mrb->c = c->prev;\n                c->prev = NULL;\n                goto L_RAISE;\n              }\n            }\n            break;\n          }\n        }\n      L_CATCH:\n        if (ch == NULL) goto L_STOP;\n        if (FALSE) {\n        L_CATCH_TAGGED_BREAK: /* from THROW_TAGGED_BREAK() or UNWIND_ENSURE() */\n          ci = mrb->c->ci;\n        }\n        proc = ci->proc;\n        irep = proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n        mrb_stack_extend(mrb, irep->nregs);\n        pc = irep->iseq + mrb_irep_catch_handler_unpack(ch->target);\n      }\n      else {\n        mrb_int acc;\n        mrb_value v;\n\n        ci = mrb->c->ci;\n        v = regs[a];\n        mrb_gc_protect(mrb, v);\n        switch (c) {\n        case OP_R_RETURN:\n          /* Fall through to OP_R_NORMAL otherwise */\n          if (ci->cci == CINFO_NONE && MRB_PROC_ENV_P(proc) && !MRB_PROC_STRICT_P(proc)) {\n            const struct RProc *dst;\n            mrb_callinfo *cibase;\n            cibase = mrb->c->cibase;\n            dst = top_proc(mrb, proc);\n\n            if (MRB_PROC_ENV_P(dst)) {\n              struct REnv *e = MRB_PROC_ENV(dst);\n\n              if (!MRB_ENV_ONSTACK_P(e) || (e->cxt && e->cxt != mrb->c)) {\n                localjump_error(mrb, LOCALJUMP_ERROR_RETURN);\n                goto L_RAISE;\n              }\n            }\n            /* check jump destination */\n            while (cibase <= ci && ci->proc != dst) {\n              if (ci->cci > CINFO_NONE) { /* jump cross C boundary */\n                localjump_error(mrb, LOCALJUMP_ERROR_RETURN);\n                goto L_RAISE;\n              }\n              ci--;\n            }\n            if (ci <= cibase) { /* no jump destination */\n              localjump_error(mrb, LOCALJUMP_ERROR_RETURN);\n              goto L_RAISE;\n            }\n            ci = mrb->c->ci;\n            while (cibase <= ci && ci->proc != dst) {\n              CHECKPOINT_RESTORE(RBREAK_TAG_RETURN_BLOCK) {\n                cibase = mrb->c->cibase;\n                dst = top_proc(mrb, proc);\n              }\n              CHECKPOINT_MAIN(RBREAK_TAG_RETURN_BLOCK) {\n                UNWIND_ENSURE(mrb, ci, pc, RBREAK_TAG_RETURN_BLOCK, proc, v);\n              }\n              CHECKPOINT_END(RBREAK_TAG_RETURN_BLOCK);\n              ci = cipop(mrb);\n              pc = ci->pc;\n            }\n            proc = ci->proc;\n            mrb->exc = NULL; /* clear break object */\n            break;\n          }\n          /* fallthrough */\n        case OP_R_NORMAL:\n        NORMAL_RETURN:\n          if (ci == mrb->c->cibase) {\n            struct mrb_context *c;\n            c = mrb->c;\n\n            if (!c->prev) { /* toplevel return */\n              regs[irep->nlocals] = v;\n              goto CHECKPOINT_LABEL_MAKE(RBREAK_TAG_STOP);\n            }\n            if (!c->vmexec && c->prev->ci == c->prev->cibase) {\n              mrb_value exc = mrb_exc_new_lit(mrb, E_FIBER_ERROR, \"double resume\");\n              mrb_exc_set(mrb, exc);\n              goto L_RAISE;\n            }\n            CHECKPOINT_RESTORE(RBREAK_TAG_RETURN_TOPLEVEL) {\n              c = mrb->c;\n            }\n            CHECKPOINT_MAIN(RBREAK_TAG_RETURN_TOPLEVEL) {\n              UNWIND_ENSURE(mrb, ci, pc, RBREAK_TAG_RETURN_TOPLEVEL, proc, v);\n            }\n            CHECKPOINT_END(RBREAK_TAG_RETURN_TOPLEVEL);\n            /* automatic yield at the end */\n            c->status = MRB_FIBER_TERMINATED;\n            mrb->c = c->prev;\n            mrb->c->status = MRB_FIBER_RUNNING;\n            c->prev = NULL;\n            if (c->vmexec) {\n              mrb_gc_arena_restore(mrb, ai);\n              c->vmexec = FALSE;\n              mrb->jmp = prev_jmp;\n              return v;\n            }\n            ci = mrb->c->ci;\n          }\n          CHECKPOINT_RESTORE(RBREAK_TAG_RETURN) {\n            /* do nothing */\n          }\n          CHECKPOINT_MAIN(RBREAK_TAG_RETURN) {\n            UNWIND_ENSURE(mrb, ci, pc, RBREAK_TAG_RETURN, proc, v);\n          }\n          CHECKPOINT_END(RBREAK_TAG_RETURN);\n          mrb->exc = NULL; /* clear break object */\n          break;\n        case OP_R_BREAK:\n          if (MRB_PROC_STRICT_P(proc)) goto NORMAL_RETURN;\n          if (MRB_PROC_ORPHAN_P(proc)) {\n            mrb_value exc;\n\n          L_BREAK_ERROR:\n            exc = mrb_exc_new_lit(mrb, E_LOCALJUMP_ERROR,\n                                      \"break from proc-closure\");\n            mrb_exc_set(mrb, exc);\n            goto L_RAISE;\n          }\n          if (!MRB_PROC_ENV_P(proc) || !MRB_ENV_ONSTACK_P(MRB_PROC_ENV(proc))) {\n            goto L_BREAK_ERROR;\n          }\n          else {\n            struct REnv *e = MRB_PROC_ENV(proc);\n\n            if (e->cxt != mrb->c) {\n              goto L_BREAK_ERROR;\n            }\n          }\n          CHECKPOINT_RESTORE(RBREAK_TAG_BREAK) {\n            /* do nothing */\n          }\n          CHECKPOINT_MAIN(RBREAK_TAG_BREAK) {\n            UNWIND_ENSURE(mrb, ci, pc, RBREAK_TAG_BREAK, proc, v);\n          }\n          CHECKPOINT_END(RBREAK_TAG_BREAK);\n          /* break from fiber block */\n          if (ci == mrb->c->cibase && ci->pc) {\n            struct mrb_context *c = mrb->c;\n\n            mrb->c = c->prev;\n            c->prev = NULL;\n            ci = mrb->c->ci;\n          }\n          if (ci->cci > CINFO_NONE) {\n            ci = cipop(mrb);\n            mrb_gc_arena_restore(mrb, ai);\n            mrb->c->vmexec = FALSE;\n            mrb->exc = (struct RObject*)break_new(mrb, RBREAK_TAG_BREAK, proc, v);\n            mrb->jmp = prev_jmp;\n            MRB_THROW(prev_jmp);\n          }\n          if (FALSE) {\n            struct RBreak *brk;\n\n          L_BREAK:\n            brk = (struct RBreak*)mrb->exc;\n            proc = mrb_break_proc_get(brk);\n            v = mrb_break_value_get(brk);\n            ci = mrb->c->ci;\n\n            switch (mrb_break_tag_get(brk)) {\n#define DISPATCH_CHECKPOINTS(n, i) case n: goto CHECKPOINT_LABEL_MAKE(n);\n              RBREAK_TAG_FOREACH(DISPATCH_CHECKPOINTS)\n#undef DISPATCH_CHECKPOINTS\n              default:\n                mrb_assert(!\"wrong break tag\");\n            }\n          }\n          while (mrb->c->cibase < ci && ci[-1].proc != proc->upper) {\n            if (ci[-1].cci == CINFO_SKIP) {\n              goto L_BREAK_ERROR;\n            }\n            CHECKPOINT_RESTORE(RBREAK_TAG_BREAK_UPPER) {\n              /* do nothing */\n            }\n            CHECKPOINT_MAIN(RBREAK_TAG_BREAK_UPPER) {\n              UNWIND_ENSURE(mrb, ci, pc, RBREAK_TAG_BREAK_UPPER, proc, v);\n            }\n            CHECKPOINT_END(RBREAK_TAG_BREAK_UPPER);\n            ci = cipop(mrb);\n            pc = ci->pc;\n          }\n          CHECKPOINT_RESTORE(RBREAK_TAG_BREAK_INTARGET) {\n            /* do nothing */\n          }\n          CHECKPOINT_MAIN(RBREAK_TAG_BREAK_INTARGET) {\n            UNWIND_ENSURE(mrb, ci, pc, RBREAK_TAG_BREAK_INTARGET, proc, v);\n          }\n          CHECKPOINT_END(RBREAK_TAG_BREAK_INTARGET);\n          if (ci == mrb->c->cibase) {\n            goto L_BREAK_ERROR;\n          }\n          mrb->exc = NULL; /* clear break object */\n          break;\n        default:\n          /* cannot happen */\n          break;\n        }\n        mrb_assert(ci == mrb->c->ci);\n        mrb_assert(mrb->exc == NULL);\n\n        if (mrb->c->vmexec && !mrb_vm_ci_target_class(ci)) {\n          mrb_gc_arena_restore(mrb, ai);\n          mrb->c->vmexec = FALSE;\n          mrb->jmp = prev_jmp;\n          return v;\n        }\n        acc = ci->cci;\n        ci = cipop(mrb);\n        if (acc == CINFO_SKIP || acc == CINFO_DIRECT) {\n          mrb_gc_arena_restore(mrb, ai);\n          mrb->jmp = prev_jmp;\n          return v;\n        }\n        pc = ci->pc;\n        DEBUG(fprintf(stderr, \"from :%s\\n\", mrb_sym_name(mrb, ci->mid)));\n        proc = ci->proc;\n        irep = proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n\n        ci[1].stack[0] = v;\n        mrb_gc_arena_restore(mrb, ai);\n      }\n      JUMP;\n    }\n\n    CASE(OP_BLKPUSH, BS) {\n      int m1 = (b>>11)&0x3f;\n      int r  = (b>>10)&0x1;\n      int m2 = (b>>5)&0x1f;\n      int kd = (b>>4)&0x1;\n      int lv = (b>>0)&0xf;\n      mrb_value *stack;\n\n      if (lv == 0) stack = regs + 1;\n      else {\n        struct REnv *e = uvenv(mrb, lv-1);\n        if (!e || (!MRB_ENV_ONSTACK_P(e) && e->mid == 0) ||\n            MRB_ENV_LEN(e) <= m1+r+m2+1) {\n          localjump_error(mrb, LOCALJUMP_ERROR_YIELD);\n          goto L_RAISE;\n        }\n        stack = e->stack + 1;\n      }\n      if (mrb_nil_p(stack[m1+r+m2+kd])) {\n        localjump_error(mrb, LOCALJUMP_ERROR_YIELD);\n        goto L_RAISE;\n      }\n      regs[a] = stack[m1+r+m2+kd];\n      NEXT;\n    }\n\n  L_INT_OVERFLOW:\n    {\n      mrb_value exc = mrb_exc_new_lit(mrb, E_RANGE_ERROR, \"integer overflow\");\n      mrb_exc_set(mrb, exc);\n    }\n    goto L_RAISE;\n\n#define TYPES2(a,b) ((((uint16_t)(a))<<8)|(((uint16_t)(b))&0xff))\n#define OP_MATH(op_name)                                                    \\\n  /* need to check if op is overridden */                                   \\\n  switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {                  \\\n    OP_MATH_CASE_INTEGER(op_name);                                          \\\n    OP_MATH_CASE_FLOAT(op_name, integer, float);                            \\\n    OP_MATH_CASE_FLOAT(op_name, float,  integer);                           \\\n    OP_MATH_CASE_FLOAT(op_name, float,  float);                             \\\n    OP_MATH_CASE_STRING_##op_name();                                        \\\n    default:                                                                \\\n      mid = MRB_OPSYM(op_name);                                             \\\n      goto L_SEND_SYM;                                                      \\\n  }                                                                         \\\n  NEXT;\n#define OP_MATH_CASE_INTEGER(op_name)                                       \\\n  case TYPES2(MRB_TT_INTEGER, MRB_TT_INTEGER):                              \\\n    {                                                                       \\\n      mrb_int x = mrb_integer(regs[a]), y = mrb_integer(regs[a+1]), z;      \\\n      if (mrb_int_##op_name##_overflow(x, y, &z))                           \\\n        OP_MATH_OVERFLOW_INT();                                             \\\n      else                                                                  \\\n        SET_INT_VALUE(mrb,regs[a], z);                                      \\\n    }                                                                       \\\n    break\n#ifdef MRB_NO_FLOAT\n#define OP_MATH_CASE_FLOAT(op_name, t1, t2) (void)0\n#else\n#define OP_MATH_CASE_FLOAT(op_name, t1, t2)                                     \\\n  case TYPES2(OP_MATH_TT_##t1, OP_MATH_TT_##t2):                                \\\n    {                                                                           \\\n      mrb_float z = mrb_##t1(regs[a]) OP_MATH_OP_##op_name mrb_##t2(regs[a+1]); \\\n      SET_FLOAT_VALUE(mrb, regs[a], z);                                         \\\n    }                                                                           \\\n    break\n#endif\n#define OP_MATH_OVERFLOW_INT() goto L_INT_OVERFLOW\n#define OP_MATH_CASE_STRING_add()                                           \\\n  case TYPES2(MRB_TT_STRING, MRB_TT_STRING):                                \\\n    regs[a] = mrb_str_plus(mrb, regs[a], regs[a+1]);                        \\\n    mrb_gc_arena_restore(mrb, ai);                                          \\\n    break\n#define OP_MATH_CASE_STRING_sub() (void)0\n#define OP_MATH_CASE_STRING_mul() (void)0\n#define OP_MATH_OP_add +\n#define OP_MATH_OP_sub -\n#define OP_MATH_OP_mul *\n#define OP_MATH_TT_integer MRB_TT_INTEGER\n#define OP_MATH_TT_float   MRB_TT_FLOAT\n\n    CASE(OP_ADD, B) {\n      OP_MATH(add);\n    }\n\n    CASE(OP_SUB, B) {\n      OP_MATH(sub);\n    }\n\n    CASE(OP_MUL, B) {\n      OP_MATH(mul);\n    }\n\n    CASE(OP_DIV, B) {\n#ifndef MRB_NO_FLOAT\n      mrb_float x, y, f;\n#endif\n\n      /* need to check if op is overridden */\n      switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\n      case TYPES2(MRB_TT_INTEGER,MRB_TT_INTEGER):\n        {\n          mrb_int x = mrb_integer(regs[a]);\n          mrb_int y = mrb_integer(regs[a+1]);\n          mrb_int div = mrb_div_int(mrb, x, y);\n          SET_INT_VALUE(mrb, regs[a], div);\n        }\n        NEXT;\n#ifndef MRB_NO_FLOAT\n      case TYPES2(MRB_TT_INTEGER,MRB_TT_FLOAT):\n        x = (mrb_float)mrb_integer(regs[a]);\n        y = mrb_float(regs[a+1]);\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_INTEGER):\n        x = mrb_float(regs[a]);\n        y = (mrb_float)mrb_integer(regs[a+1]);\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_FLOAT):\n        x = mrb_float(regs[a]);\n        y = mrb_float(regs[a+1]);\n        break;\n#endif\n      default:\n        mid = MRB_OPSYM(div);\n        goto L_SEND_SYM;\n      }\n\n#ifndef MRB_NO_FLOAT\n      f = mrb_div_float(x, y);\n      SET_FLOAT_VALUE(mrb, regs[a], f);\n#endif\n      NEXT;\n    }\n\n#define OP_MATHI(op_name)                                                   \\\n  /* need to check if op is overridden */                                   \\\n  switch (mrb_type(regs[a])) {                                              \\\n    OP_MATHI_CASE_INTEGER(op_name);                                         \\\n    OP_MATHI_CASE_FLOAT(op_name);                                           \\\n    default:                                                                \\\n      SET_INT_VALUE(mrb,regs[a+1], b);                                      \\\n      mid = MRB_OPSYM(op_name);                                             \\\n      goto L_SEND_SYM;                                                      \\\n  }                                                                         \\\n  NEXT;\n#define OP_MATHI_CASE_INTEGER(op_name)                                      \\\n  case MRB_TT_INTEGER:                                                      \\\n    {                                                                       \\\n      mrb_int x = mrb_integer(regs[a]), y = (mrb_int)b, z;                  \\\n      if (mrb_int_##op_name##_overflow(x, y, &z))                           \\\n        OP_MATH_OVERFLOW_INT();                                             \\\n      else                                                                  \\\n        SET_INT_VALUE(mrb,regs[a], z);                                      \\\n    }                                                                       \\\n    break\n#ifdef MRB_NO_FLOAT\n#define OP_MATHI_CASE_FLOAT(op_name) (void)0\n#else\n#define OP_MATHI_CASE_FLOAT(op_name)                                        \\\n  case MRB_TT_FLOAT:                                                        \\\n    {                                                                       \\\n      mrb_float z = mrb_float(regs[a]) OP_MATH_OP_##op_name b;              \\\n      SET_FLOAT_VALUE(mrb, regs[a], z);                                     \\\n    }                                                                       \\\n    break\n#endif\n\n    CASE(OP_ADDI, BB) {\n      OP_MATHI(add);\n    }\n\n    CASE(OP_SUBI, BB) {\n      OP_MATHI(sub);\n    }\n\n#define OP_CMP_BODY(op,v1,v2) (v1(regs[a]) op v2(regs[a+1]))\n\n#ifdef MRB_NO_FLOAT\n#define OP_CMP(op,sym) do {\\\n  int result;\\\n  /* need to check if - is overridden */\\\n  switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\\\n  case TYPES2(MRB_TT_INTEGER,MRB_TT_INTEGER):\\\n    result = OP_CMP_BODY(op,mrb_fixnum,mrb_fixnum);\\\n    break;\\\n  default:\\\n    mid = MRB_OPSYM(sym);\\\n    goto L_SEND_SYM;\\\n  }\\\n  if (result) {\\\n    SET_TRUE_VALUE(regs[a]);\\\n  }\\\n  else {\\\n    SET_FALSE_VALUE(regs[a]);\\\n  }\\\n} while(0)\n#else\n#define OP_CMP(op, sym) do {\\\n  int result;\\\n  /* need to check if - is overridden */\\\n  switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\\\n  case TYPES2(MRB_TT_INTEGER,MRB_TT_INTEGER):\\\n    result = OP_CMP_BODY(op,mrb_fixnum,mrb_fixnum);\\\n    break;\\\n  case TYPES2(MRB_TT_INTEGER,MRB_TT_FLOAT):\\\n    result = OP_CMP_BODY(op,mrb_fixnum,mrb_float);\\\n    break;\\\n  case TYPES2(MRB_TT_FLOAT,MRB_TT_INTEGER):\\\n    result = OP_CMP_BODY(op,mrb_float,mrb_fixnum);\\\n    break;\\\n  case TYPES2(MRB_TT_FLOAT,MRB_TT_FLOAT):\\\n    result = OP_CMP_BODY(op,mrb_float,mrb_float);\\\n    break;\\\n  default:\\\n    mid = MRB_OPSYM(sym);\\\n    goto L_SEND_SYM;\\\n  }\\\n  if (result) {\\\n    SET_TRUE_VALUE(regs[a]);\\\n  }\\\n  else {\\\n    SET_FALSE_VALUE(regs[a]);\\\n  }\\\n} while(0)\n#endif\n\n    CASE(OP_EQ, B) {\n      if (mrb_obj_eq(mrb, regs[a], regs[a+1])) {\n        SET_TRUE_VALUE(regs[a]);\n      }\n      else {\n        OP_CMP(==,eq);\n      }\n      NEXT;\n    }\n\n    CASE(OP_LT, B) {\n      OP_CMP(<,lt);\n      NEXT;\n    }\n\n    CASE(OP_LE, B) {\n      OP_CMP(<=,le);\n      NEXT;\n    }\n\n    CASE(OP_GT, B) {\n      OP_CMP(>,gt);\n      NEXT;\n    }\n\n    CASE(OP_GE, B) {\n      OP_CMP(>=,ge);\n      NEXT;\n    }\n\n    CASE(OP_ARRAY, BB) {\n      regs[a] = mrb_ary_new_from_values(mrb, b, &regs[a]);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n    CASE(OP_ARRAY2, BBB) {\n      regs[a] = mrb_ary_new_from_values(mrb, c, &regs[b]);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_ARYCAT, B) {\n      mrb_value splat = mrb_ary_splat(mrb, regs[a+1]);\n      if (mrb_nil_p(regs[a])) {\n        regs[a] = splat;\n      }\n      else {\n        mrb_assert(mrb_array_p(regs[a]));\n        mrb_ary_concat(mrb, regs[a], splat);\n      }\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_ARYPUSH, BB) {\n      mrb_assert(mrb_array_p(regs[a]));\n      for (mrb_int i=0; i<b; i++) {\n        mrb_ary_push(mrb, regs[a], regs[a+i+1]);\n      }\n      NEXT;\n    }\n\n    CASE(OP_ARYDUP, B) {\n      mrb_value ary = regs[a];\n      if (mrb_array_p(ary)) {\n        ary = mrb_ary_new_from_values(mrb, RARRAY_LEN(ary), RARRAY_PTR(ary));\n      }\n      else {\n        ary = mrb_ary_new_from_values(mrb, 1, &ary);\n      }\n      regs[a] = ary;\n      NEXT;\n    }\n\n    CASE(OP_AREF, BBB) {\n      mrb_value v = regs[b];\n\n      if (!mrb_array_p(v)) {\n        if (c == 0) {\n          regs[a] = v;\n        }\n        else {\n          SET_NIL_VALUE(regs[a]);\n        }\n      }\n      else {\n        v = mrb_ary_ref(mrb, v, c);\n        regs[a] = v;\n      }\n      NEXT;\n    }\n\n    CASE(OP_ASET, BBB) {\n      mrb_assert(mrb_array_p(regs[a]));\n      mrb_ary_set(mrb, regs[b], c, regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_APOST, BBB) {\n      mrb_value v = regs[a];\n      int pre  = b;\n      int post = c;\n      struct RArray *ary;\n      int len, idx;\n\n      if (!mrb_array_p(v)) {\n        v = mrb_ary_new_from_values(mrb, 1, &regs[a]);\n      }\n      ary = mrb_ary_ptr(v);\n      len = (int)ARY_LEN(ary);\n      if (len > pre + post) {\n        v = mrb_ary_new_from_values(mrb, len - pre - post, ARY_PTR(ary)+pre);\n        regs[a++] = v;\n        while (post--) {\n          regs[a++] = ARY_PTR(ary)[len-post-1];\n        }\n      }\n      else {\n        v = mrb_ary_new_capa(mrb, 0);\n        regs[a++] = v;\n        for (idx=0; idx+pre<len; idx++) {\n          regs[a+idx] = ARY_PTR(ary)[pre+idx];\n        }\n        while (idx < post) {\n          SET_NIL_VALUE(regs[a+idx]);\n          idx++;\n        }\n      }\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_INTERN, B) {\n      mrb_assert(mrb_string_p(regs[a]));\n      mrb_sym sym = mrb_intern_str(mrb, regs[a]);\n      regs[a] = mrb_symbol_value(sym);\n      NEXT;\n    }\n\n    CASE(OP_SYMBOL, BB) {\n      size_t len;\n      mrb_sym sym;\n\n      mrb_assert((pool[b].tt&IREP_TT_NFLAG)==0);\n      len = pool[b].tt >> 2;\n      if (pool[b].tt & IREP_TT_SFLAG) {\n        sym = mrb_intern_static(mrb, pool[b].u.str, len);\n      }\n      else {\n        sym  = mrb_intern(mrb, pool[b].u.str, len);\n      }\n      regs[a] = mrb_symbol_value(sym);\n      NEXT;\n    }\n\n    CASE(OP_STRING, BB) {\n      mrb_int len;\n\n      mrb_assert((pool[b].tt&IREP_TT_NFLAG)==0);\n      len = pool[b].tt >> 2;\n      if (pool[b].tt & IREP_TT_SFLAG) {\n        regs[a] = mrb_str_new_static(mrb, pool[b].u.str, len);\n      }\n      else {\n        regs[a] = mrb_str_new(mrb, pool[b].u.str, len);\n      }\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_STRCAT, B) {\n      mrb_assert(mrb_string_p(regs[a]));\n      mrb_str_concat(mrb, regs[a], regs[a+1]);\n      NEXT;\n    }\n\n    CASE(OP_HASH, BB) {\n      mrb_value hash = mrb_hash_new_capa(mrb, b);\n      int i;\n      int lim = a+b*2;\n\n      for (i=a; i<lim; i+=2) {\n        mrb_hash_set(mrb, hash, regs[i], regs[i+1]);\n      }\n      regs[a] = hash;\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_HASHADD, BB) {\n      mrb_value hash;\n      int i;\n      int lim = a+b*2+1;\n\n      hash = regs[a];\n      mrb_ensure_hash_type(mrb, hash);\n      for (i=a+1; i<lim; i+=2) {\n        mrb_hash_set(mrb, hash, regs[i], regs[i+1]);\n      }\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n    CASE(OP_HASHCAT, B) {\n      mrb_value hash = regs[a];\n\n      mrb_assert(mrb_hash_p(hash));\n      mrb_hash_merge(mrb, hash, regs[a+1]);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_LAMBDA, BB)\n    c = OP_L_LAMBDA;\n    L_MAKE_LAMBDA:\n    {\n      struct RProc *p;\n      const mrb_irep *nirep = irep->reps[b];\n\n      if (c & OP_L_CAPTURE) {\n        p = mrb_closure_new(mrb, nirep);\n      }\n      else {\n        p = mrb_proc_new(mrb, nirep);\n        p->flags |= MRB_PROC_SCOPE;\n      }\n      if (c & OP_L_STRICT) p->flags |= MRB_PROC_STRICT;\n      regs[a] = mrb_obj_value(p);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n    CASE(OP_BLOCK, BB) {\n      c = OP_L_BLOCK;\n      goto L_MAKE_LAMBDA;\n    }\n    CASE(OP_METHOD, BB) {\n      c = OP_L_METHOD;\n      goto L_MAKE_LAMBDA;\n    }\n\n    CASE(OP_RANGE_INC, B) {\n      regs[a] = mrb_range_new(mrb, regs[a], regs[a+1], FALSE);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_RANGE_EXC, B) {\n      regs[a] = mrb_range_new(mrb, regs[a], regs[a+1], TRUE);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_OCLASS, B) {\n      regs[a] = mrb_obj_value(mrb->object_class);\n      NEXT;\n    }\n\n    CASE(OP_CLASS, BB) {\n      struct RClass *c = 0, *baseclass;\n      mrb_value base, super;\n      mrb_sym id = syms[b];\n\n      base = regs[a];\n      super = regs[a+1];\n      if (mrb_nil_p(base)) {\n        baseclass = MRB_PROC_TARGET_CLASS(mrb->c->ci->proc);\n        if (!baseclass) baseclass = mrb->object_class;\n        base = mrb_obj_value(baseclass);\n      }\n      c = mrb_vm_define_class(mrb, base, super, id);\n      regs[a] = mrb_obj_value(c);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_MODULE, BB) {\n      struct RClass *cls = 0, *baseclass;\n      mrb_value base;\n      mrb_sym id = syms[b];\n\n      base = regs[a];\n      if (mrb_nil_p(base)) {\n        baseclass = MRB_PROC_TARGET_CLASS(mrb->c->ci->proc);\n        if (!baseclass) baseclass = mrb->object_class;\n        base = mrb_obj_value(baseclass);\n      }\n      cls = mrb_vm_define_module(mrb, base, id);\n      regs[a] = mrb_obj_value(cls);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_EXEC, BB)\n    {\n      mrb_value recv = regs[a];\n      struct RProc *p;\n      const mrb_irep *nirep = irep->reps[b];\n\n      /* prepare closure */\n      p = mrb_proc_new(mrb, nirep);\n      p->c = NULL;\n      mrb_field_write_barrier(mrb, (struct RBasic*)p, (struct RBasic*)proc);\n      MRB_PROC_SET_TARGET_CLASS(p, mrb_class_ptr(recv));\n      p->flags |= MRB_PROC_SCOPE;\n\n      /* prepare call stack */\n      cipush(mrb, a, 0, mrb_class_ptr(recv), p, 0, 0);\n\n      irep = p->body.irep;\n      pool = irep->pool;\n      syms = irep->syms;\n      mrb_stack_extend(mrb, irep->nregs);\n      stack_clear(regs+1, irep->nregs-1);\n      pc = irep->iseq;\n      JUMP;\n    }\n\n    CASE(OP_DEF, BB) {\n      struct RClass *target = mrb_class_ptr(regs[a]);\n      struct RProc *p = mrb_proc_ptr(regs[a+1]);\n      mrb_method_t m;\n      mrb_sym mid = syms[b];\n\n      MRB_METHOD_FROM_PROC(m, p);\n      mrb_define_method_raw(mrb, target, mid, m);\n      mrb_method_added(mrb, target, mid);\n      mrb_gc_arena_restore(mrb, ai);\n      regs[a] = mrb_symbol_value(mid);\n      NEXT;\n    }\n\n    CASE(OP_SCLASS, B) {\n      regs[a] = mrb_singleton_class(mrb, regs[a]);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_TCLASS, B) {\n      struct RClass *target = check_target_class(mrb);\n      if (!target) goto L_RAISE;\n      regs[a] = mrb_obj_value(target);\n      NEXT;\n    }\n\n    CASE(OP_ALIAS, BB) {\n      struct RClass *target = check_target_class(mrb);\n\n      if (!target) goto L_RAISE;\n      mrb_alias_method(mrb, target, syms[a], syms[b]);\n      mrb_method_added(mrb, target, syms[a]);\n      NEXT;\n    }\n    CASE(OP_UNDEF, B) {\n      struct RClass *target = check_target_class(mrb);\n\n      if (!target) goto L_RAISE;\n      mrb_undef_method_id(mrb, target, syms[a]);\n      NEXT;\n    }\n\n    CASE(OP_DEBUG, Z) {\n      FETCH_BBB();\n#ifdef MRB_USE_DEBUG_HOOK\n      mrb->debug_op_hook(mrb, irep, pc, regs);\n#else\n#ifndef MRB_NO_STDIO\n      printf(\"OP_DEBUG %d %d %d\\n\", a, b, c);\n#else\n      abort();\n#endif\n#endif\n      NEXT;\n    }\n\n    CASE(OP_ERR, B) {\n      size_t len = pool[a].tt >> 2;\n      mrb_value exc;\n\n      mrb_assert((pool[a].tt&IREP_TT_NFLAG)==0);\n      exc = mrb_exc_new(mrb, E_LOCALJUMP_ERROR, pool[a].u.str, len);\n      mrb_exc_set(mrb, exc);\n      goto L_RAISE;\n    }\n\n    CASE(OP_EXT1, Z) {\n      insn = READ_B();\n      switch (insn) {\n#define OPCODE(insn,ops) case OP_ ## insn: FETCH_ ## ops ## _1(); mrb->c->ci->pc = pc; goto L_OP_ ## insn ## _BODY;\n#include \"mruby/ops.h\"\n#undef OPCODE\n      }\n      pc--;\n      NEXT;\n    }\n    CASE(OP_EXT2, Z) {\n      insn = READ_B();\n      switch (insn) {\n#define OPCODE(insn,ops) case OP_ ## insn: FETCH_ ## ops ## _2(); mrb->c->ci->pc = pc; goto L_OP_ ## insn ## _BODY;\n#include \"mruby/ops.h\"\n#undef OPCODE\n      }\n      pc--;\n      NEXT;\n    }\n    CASE(OP_EXT3, Z) {\n      uint8_t insn = READ_B();\n      switch (insn) {\n#define OPCODE(insn,ops) case OP_ ## insn: FETCH_ ## ops ## _3(); mrb->c->ci->pc = pc; goto L_OP_ ## insn ## _BODY;\n#include \"mruby/ops.h\"\n#undef OPCODE\n      }\n      pc--;\n      NEXT;\n    }\n\n    CASE(OP_STOP, Z) {\n      /*        stop VM */\n      CHECKPOINT_RESTORE(RBREAK_TAG_STOP) {\n        /* do nothing */\n      }\n      CHECKPOINT_MAIN(RBREAK_TAG_STOP) {\n        UNWIND_ENSURE(mrb, mrb->c->ci, pc, RBREAK_TAG_STOP, proc, mrb_nil_value());\n      }\n      CHECKPOINT_END(RBREAK_TAG_STOP);\n    L_STOP:\n      mrb->jmp = prev_jmp;\n      if (mrb->exc) {\n        mrb_assert(mrb->exc->tt == MRB_TT_EXCEPTION);\n        return mrb_obj_value(mrb->exc);\n      }\n      return regs[irep->nlocals];\n    }\n  }\n  END_DISPATCH;\n#undef regs\n  }\n  MRB_CATCH(&c_jmp) {\n    mrb_callinfo *ci = mrb->c->ci;\n    while (ci > mrb->c->cibase && ci->cci == CINFO_DIRECT) {\n      ci = cipop(mrb);\n    }\n    exc_catched = TRUE;\n    pc = ci->pc;\n    goto RETRY_TRY_BLOCK;\n  }\n  MRB_END_EXC(&c_jmp);\n}",
        "func_hash": 48104799339109897868762377500628330824,
        "file_name": "vm.c",
        "file_hash": 254712077563543563381285441661557243082,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2022-1071",
        "cve_desc": "User after free in mrb_vm_exec in GitHub repository mruby/mruby prior to 3.2.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-1071",
        "func_name": "mrb_vm_exec",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 196817,
        "project": "njs",
        "commit_id": "81af26364c21c196dd21fb5e14c7fa9ce7debd17",
        "project_url": "https://github.com/nginx/njs",
        "commit_url": "https://github.com/nginx/njs/commit/81af26364c21c196dd21fb5e14c7fa9ce7debd17",
        "commit_message": "Fixed Object.defineProperty() when a recursive descriptor is provided.\n\nThis closes #481 issue on Github.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "njs_array_convert_to_slow_array(njs_vm_t *vm, njs_array_t *array)\n{\n    uint32_t           i, length;\n    njs_value_t        index, value;\n    njs_object_prop_t  *prop;\n\n    njs_set_array(&value, array);\n    array->object.fast_array = 0;\n\n    length = array->length;\n\n    for (i = 0; i < length; i++) {\n        if (njs_is_valid(&array->start[i])) {\n            njs_uint32_to_string(&index, i);\n            prop = njs_object_property_add(vm, &value, &index, 0);\n            if (njs_slow_path(prop == NULL)) {\n                return NJS_ERROR;\n            }\n\n            prop->value = array->start[i];\n        }\n    }\n\n    /* GC: release value. */\n\n    njs_mp_free(vm->mem_pool, array->start);\n    array->start = NULL;\n\n    return NJS_OK;\n}",
        "func_hash": 135038301213614089320274160983601202248,
        "file_name": "njs_array.c",
        "file_hash": 27861953644579332654826088207600556930,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2022-31306",
        "cve_desc": "Nginx NJS v0.7.2 was discovered to contain a segmentation violation in the function njs_array_convert_to_slow_array at src/njs_array.c.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-31306",
        "func_name": "njs_array_convert_to_slow_array",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 196829,
        "project": "tensorflow",
        "commit_id": "9a133d73ae4b4664d22bd1aa6d654fec13c52ee1",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/9a133d73ae4b4664d22bd1aa6d654fec13c52ee1",
        "commit_message": "Prevent segfault in `GetSessionHandle{,V2}`.\n\nIn eager mode, session state is null.\n\nPiperOrigin-RevId: 332548597\nChange-Id: If094812c2e094044220b9ba28f7d7601be042f38",
        "target": 1,
        "irrelevant": 1,
        "func_before": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor& val = ctx->input(0);\n    int64 id = ctx->session_state()->GetNewId();\n    TensorStore::TensorAndKey tk{val, id, requested_device()};\n    OP_REQUIRES_OK(ctx, ctx->tensor_store()->AddTensor(name(), tk));\n\n    Tensor* handle = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, TensorShape({}), &handle));\n    if (ctx->expected_output_dtype(0) == DT_RESOURCE) {\n      ResourceHandle resource_handle = MakeResourceHandle<Tensor>(\n          ctx, SessionState::kTensorHandleResourceTypeName,\n          tk.GetHandle(name()));\n      resource_handle.set_maybe_type_name(\n          SessionState::kTensorHandleResourceTypeName);\n      handle->scalar<ResourceHandle>()() = resource_handle;\n    } else {\n      // Legacy behavior in V1.\n      handle->flat<tstring>().setConstant(tk.GetHandle(name()));\n    }\n  }",
        "func_hash": 265136132776865637405047291994320353020,
        "file_name": "session_ops.cc",
        "file_hash": 301236181949638816884177571060128580318,
        "cwe": [
            "CWE-476"
        ],
        "cve": "CVE-2020-15204",
        "cve_desc": "In eager mode, TensorFlow before versions 1.15.4, 2.0.3, 2.1.2, 2.2.1 and 2.3.1 does not set the session state. Hence, calling `tf.raw_ops.GetSessionHandle` or `tf.raw_ops.GetSessionHandleV2` results in a null pointer dereference In linked snippet, in eager mode, `ctx->session_state()` returns `nullptr`. Since code immediately dereferences this, we get a segmentation fault. The issue is patched in commit 9a133d73ae4b4664d22bd1aa6d654fec13c52ee1, and is released in TensorFlow versions 1.15.4, 2.0.3, 2.1.2, 2.2.1, or 2.3.1.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2020-15204",
        "func_name": "Compute",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 196834,
        "project": "tensorflow",
        "commit_id": "701cfaca222a82afbeeb17496bd718baa65a67d2",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/701cfaca222a82afbeeb17496bd718baa65a67d2",
        "commit_message": "Fix heap out of bounds error in tf.raw_ops.SparseCountSparseOutput shape inference when it is called with invalid inputs, and add a test for it.\n\nPiperOrigin-RevId: 405766415\nChange-Id: I77d244ef35f351ef7b6f821efd959cac2c66db24",
        "target": 1,
        "irrelevant": 0,
        "func_before": "Status SparseCountSparseOutputShapeFn(InferenceContext *c) {\n  auto rank = c->Dim(c->input(0), 1);\n  auto nvals = c->UnknownDim();\n  c->set_output(0, c->Matrix(nvals, rank));  // out.indices\n  c->set_output(1, c->Vector(nvals));        // out.values\n  c->set_output(2, c->Vector(rank));         // out.dense_shape\n  return Status::OK();\n}",
        "func_hash": 288638774639466658606082764141579193752,
        "file_name": "count_ops.cc",
        "file_hash": 285251304555239344227100279342018211632,
        "cwe": [
            "CWE-125"
        ],
        "cve": "CVE-2021-41210",
        "cve_desc": "TensorFlow is an open source platform for machine learning. In affected versions the shape inference functions for `SparseCountSparseOutput` can trigger a read outside of bounds of heap allocated array. The fix will be included in TensorFlow 2.7.0. We will also cherrypick this commit on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-41210",
        "func_name": "SparseCountSparseOutputShapeFn",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 196841,
        "project": "furnace",
        "commit_id": "0eb02422d5161767e9983bdaa5c429762d3477ce",
        "project_url": "https://github.com/tildearrow/furnace",
        "commit_url": "https://github.com/tildearrow/furnace/commit/0eb02422d5161767e9983bdaa5c429762d3477ce",
        "commit_message": "fix possible pattern crash\n\nissue #325",
        "target": 1,
        "irrelevant": 0,
        "func_before": "inline void FurnaceGUI::patternRow(int i, bool isPlaying, float lineHeight, int chans, int ord, const DivPattern** patCache) {\n  static char id[32];\n  bool selectedRow=(i>=sel1.y && i<=sel2.y);\n  ImGui::TableNextRow(0,lineHeight);\n  ImGui::TableNextColumn();\n  float cursorPosY=ImGui::GetCursorPos().y-ImGui::GetScrollY();\n  // check if the row is visible\n  if (cursorPosY<-lineHeight || cursorPosY>ImGui::GetWindowSize().y) {\n    return;\n  }\n  // check if we are in range\n  if (ord<0 || ord>=e->song.ordersLen) {\n    return;\n  }\n  if (i<0 || i>=e->song.patLen) {\n    return;\n  }\n  bool isPushing=false;\n  ImVec4 activeColor=uiColors[GUI_COLOR_PATTERN_ACTIVE];\n  ImVec4 inactiveColor=uiColors[GUI_COLOR_PATTERN_INACTIVE];\n  ImVec4 rowIndexColor=uiColors[GUI_COLOR_PATTERN_ROW_INDEX];\n  if (e->song.hilightB>0 && !(i%e->song.hilightB)) {\n    activeColor=uiColors[GUI_COLOR_PATTERN_ACTIVE_HI2];\n    inactiveColor=uiColors[GUI_COLOR_PATTERN_INACTIVE_HI2];\n    rowIndexColor=uiColors[GUI_COLOR_PATTERN_ROW_INDEX_HI2];\n  } else if (e->song.hilightA>0 && !(i%e->song.hilightA)) {\n    activeColor=uiColors[GUI_COLOR_PATTERN_ACTIVE_HI1];\n    inactiveColor=uiColors[GUI_COLOR_PATTERN_INACTIVE_HI1];\n    rowIndexColor=uiColors[GUI_COLOR_PATTERN_ROW_INDEX_HI1];\n  }\n  // check overflow highlight\n  if (settings.overflowHighlight) {\n    if (edit && cursor.y==i) {\n      ImGui::TableSetBgColor(ImGuiTableBgTarget_RowBg0,ImGui::GetColorU32(uiColors[GUI_COLOR_EDITING]));\n    } else if (isPlaying && oldRow==i) {\n      ImGui::TableSetBgColor(ImGuiTableBgTarget_RowBg0,ImGui::GetColorU32(uiColors[GUI_COLOR_PATTERN_PLAY_HEAD]));\n    } else if (e->song.hilightB>0 && !(i%e->song.hilightB)) {\n      ImGui::TableSetBgColor(ImGuiTableBgTarget_RowBg0,ImGui::GetColorU32(uiColors[GUI_COLOR_PATTERN_HI_2]));\n    } else if (e->song.hilightA>0 && !(i%e->song.hilightA)) {\n      ImGui::TableSetBgColor(ImGuiTableBgTarget_RowBg0,ImGui::GetColorU32(uiColors[GUI_COLOR_PATTERN_HI_1]));\n    }\n  } else {\n    isPushing=true;\n    if (edit && cursor.y==i) {\n      ImGui::PushStyleColor(ImGuiCol_Header,ImGui::GetColorU32(uiColors[GUI_COLOR_EDITING]));\n    } else if (isPlaying && oldRow==i) {\n      ImGui::PushStyleColor(ImGuiCol_Header,ImGui::GetColorU32(uiColors[GUI_COLOR_PATTERN_PLAY_HEAD]));\n    } else if (e->song.hilightB>0 && !(i%e->song.hilightB)) {\n      ImGui::PushStyleColor(ImGuiCol_Header,ImGui::GetColorU32(uiColors[GUI_COLOR_PATTERN_HI_2]));\n    } else if (e->song.hilightA>0 && !(i%e->song.hilightA)) {\n      ImGui::PushStyleColor(ImGuiCol_Header,ImGui::GetColorU32(uiColors[GUI_COLOR_PATTERN_HI_1]));\n    } else {\n      isPushing=false;\n    }\n  }\n  // row number\n  if (settings.patRowsBase==1) {\n    ImGui::TextColored(rowIndexColor,\" %.2X \",i);\n  } else {\n    ImGui::TextColored(rowIndexColor,\"%3d \",i);\n  }\n  // for each column\n  for (int j=0; j<chans; j++) {\n    // check if channel is not hidden\n    if (!e->song.chanShow[j]) {\n      patChanX[j]=ImGui::GetCursorPosX();\n      continue;\n    }\n    int chanVolMax=e->getMaxVolumeChan(j);\n    if (chanVolMax<1) chanVolMax=1;\n    const DivPattern* pat=patCache[j];\n    ImGui::TableNextColumn();\n    patChanX[j]=ImGui::GetCursorPosX();\n\n    // selection highlight flags\n    int sel1XSum=sel1.xCoarse*32+sel1.xFine;\n    int sel2XSum=sel2.xCoarse*32+sel2.xFine;\n    int j32=j*32;\n    bool selectedNote=selectedRow && (j32>=sel1XSum && j32<=sel2XSum);\n    bool selectedIns=selectedRow && (j32+1>=sel1XSum && j32+1<=sel2XSum);\n    bool selectedVol=selectedRow && (j32+2>=sel1XSum && j32+2<=sel2XSum);\n    bool cursorNote=(cursor.y==i && cursor.xCoarse==j && cursor.xFine==0);\n    bool cursorIns=(cursor.y==i && cursor.xCoarse==j && cursor.xFine==1);\n    bool cursorVol=(cursor.y==i && cursor.xCoarse==j && cursor.xFine==2);\n\n    // note\n    sprintf(id,\"%s##PN_%d_%d\",noteName(pat->data[i][0],pat->data[i][1]),i,j);\n    if (pat->data[i][0]==0 && pat->data[i][1]==0) {\n      ImGui::PushStyleColor(ImGuiCol_Text,inactiveColor);\n    } else {\n      ImGui::PushStyleColor(ImGuiCol_Text,activeColor);\n    }\n    if (cursorNote) {\n      ImGui::PushStyleColor(ImGuiCol_Header,uiColors[GUI_COLOR_PATTERN_CURSOR]);\n      ImGui::PushStyleColor(ImGuiCol_HeaderActive,uiColors[GUI_COLOR_PATTERN_CURSOR_ACTIVE]);\n      ImGui::PushStyleColor(ImGuiCol_HeaderHovered,uiColors[GUI_COLOR_PATTERN_CURSOR_HOVER]);\n      ImGui::Selectable(id,true,ImGuiSelectableFlags_NoPadWithHalfSpacing,threeChars);\n      demandX=ImGui::GetCursorPosX();\n      ImGui::PopStyleColor(3);\n    } else {\n      if (selectedNote) ImGui::PushStyleColor(ImGuiCol_Header,uiColors[GUI_COLOR_PATTERN_SELECTION]);\n      ImGui::Selectable(id,isPushing || selectedNote,ImGuiSelectableFlags_NoPadWithHalfSpacing,threeChars);\n      if (selectedNote) ImGui::PopStyleColor();\n    }\n    if (ImGui::IsItemClicked()) {\n      startSelection(j,0,i);\n    }\n    if (ImGui::IsItemHovered(ImGuiHoveredFlags_AllowWhenBlockedByActiveItem)) {\n      updateSelection(j,0,i);\n    }\n    ImGui::PopStyleColor();\n\n    // the following is only visible when the channel is not collapsed\n    if (!e->song.chanCollapse[j]) {\n      // instrument\n      if (pat->data[i][2]==-1) {\n        ImGui::PushStyleColor(ImGuiCol_Text,inactiveColor);\n        sprintf(id,\"..##PI_%d_%d\",i,j);\n      } else {\n        if (pat->data[i][2]<0 || pat->data[i][2]>=e->song.insLen) {\n          ImGui::PushStyleColor(ImGuiCol_Text,uiColors[GUI_COLOR_PATTERN_INS_ERROR]);\n        } else {\n          DivInstrumentType t=e->song.ins[pat->data[i][2]]->type;\n          if (t!=DIV_INS_AMIGA && t!=e->getPreferInsType(j)) {\n            ImGui::PushStyleColor(ImGuiCol_Text,uiColors[GUI_COLOR_PATTERN_INS_WARN]);\n          } else {\n            ImGui::PushStyleColor(ImGuiCol_Text,uiColors[GUI_COLOR_PATTERN_INS]);\n          }\n        }\n        sprintf(id,\"%.2X##PI_%d_%d\",pat->data[i][2],i,j);\n      }\n      ImGui::SameLine(0.0f,0.0f);\n      if (cursorIns) {\n        ImGui::PushStyleColor(ImGuiCol_Header,uiColors[GUI_COLOR_PATTERN_CURSOR]);\n        ImGui::PushStyleColor(ImGuiCol_HeaderActive,uiColors[GUI_COLOR_PATTERN_CURSOR_ACTIVE]);\n        ImGui::PushStyleColor(ImGuiCol_HeaderHovered,uiColors[GUI_COLOR_PATTERN_CURSOR_HOVER]);\n        ImGui::Selectable(id,true,ImGuiSelectableFlags_NoPadWithHalfSpacing,twoChars);\n        demandX=ImGui::GetCursorPosX();\n        ImGui::PopStyleColor(3);\n      } else {\n        if (selectedIns) ImGui::PushStyleColor(ImGuiCol_Header,uiColors[GUI_COLOR_PATTERN_SELECTION]);\n        ImGui::Selectable(id,isPushing || selectedIns,ImGuiSelectableFlags_NoPadWithHalfSpacing,twoChars);\n        if (selectedIns) ImGui::PopStyleColor();\n      }\n      if (ImGui::IsItemClicked()) {\n        startSelection(j,1,i);\n      }\n      if (ImGui::IsItemHovered(ImGuiHoveredFlags_AllowWhenBlockedByActiveItem)) {\n        updateSelection(j,1,i);\n      }\n      ImGui::PopStyleColor();\n\n      // volume\n      if (pat->data[i][3]==-1) {\n        sprintf(id,\"..##PV_%d_%d\",i,j);\n        ImGui::PushStyleColor(ImGuiCol_Text,inactiveColor);\n      } else {\n        int volColor=(pat->data[i][3]*127)/chanVolMax;\n        if (volColor>127) volColor=127;\n        if (volColor<0) volColor=0;\n        sprintf(id,\"%.2X##PV_%d_%d\",pat->data[i][3],i,j);\n        ImGui::PushStyleColor(ImGuiCol_Text,volColors[volColor]);\n      }\n      ImGui::SameLine(0.0f,0.0f);\n      if (cursorVol) {\n        ImGui::PushStyleColor(ImGuiCol_Header,uiColors[GUI_COLOR_PATTERN_CURSOR]);\n        ImGui::PushStyleColor(ImGuiCol_HeaderActive,uiColors[GUI_COLOR_PATTERN_CURSOR_ACTIVE]);\n        ImGui::PushStyleColor(ImGuiCol_HeaderHovered,uiColors[GUI_COLOR_PATTERN_CURSOR_HOVER]);\n        ImGui::Selectable(id,true,ImGuiSelectableFlags_NoPadWithHalfSpacing,twoChars);\n        demandX=ImGui::GetCursorPosX();\n        ImGui::PopStyleColor(3);\n      } else {\n        if (selectedVol) ImGui::PushStyleColor(ImGuiCol_Header,uiColors[GUI_COLOR_PATTERN_SELECTION]);\n        ImGui::Selectable(id,isPushing || selectedVol,ImGuiSelectableFlags_NoPadWithHalfSpacing,twoChars);\n        if (selectedVol) ImGui::PopStyleColor();\n      }\n      if (ImGui::IsItemClicked()) {\n        startSelection(j,2,i);\n      }\n      if (ImGui::IsItemHovered(ImGuiHoveredFlags_AllowWhenBlockedByActiveItem)) {\n        updateSelection(j,2,i);\n      }\n      ImGui::PopStyleColor();\n\n      // effects\n      for (int k=0; k<e->song.pat[j].effectRows; k++) {\n        int index=4+(k<<1);\n        bool selectedEffect=selectedRow && (j32+index-1>=sel1XSum && j32+index-1<=sel2XSum);\n        bool selectedEffectVal=selectedRow && (j32+index>=sel1XSum && j32+index<=sel2XSum);\n        bool cursorEffect=(cursor.y==i && cursor.xCoarse==j && cursor.xFine==index-1);\n        bool cursorEffectVal=(cursor.y==i && cursor.xCoarse==j && cursor.xFine==index);\n        \n        // effect\n        if (pat->data[i][index]==-1) {\n          sprintf(id,\"..##PE%d_%d_%d\",k,i,j);\n          ImGui::PushStyleColor(ImGuiCol_Text,inactiveColor);\n        } else {\n          sprintf(id,\"%.2X##PE%d_%d_%d\",pat->data[i][index],k,i,j);\n          if (pat->data[i][index]<0x10) {\n            ImGui::PushStyleColor(ImGuiCol_Text,uiColors[fxColors[pat->data[i][index]]]);\n          } else if (pat->data[i][index]<0x20) {\n            ImGui::PushStyleColor(ImGuiCol_Text,uiColors[GUI_COLOR_PATTERN_EFFECT_SYS_PRIMARY]);\n          } else if (pat->data[i][index]<0x30) {\n            ImGui::PushStyleColor(ImGuiCol_Text,uiColors[GUI_COLOR_PATTERN_EFFECT_SYS_SECONDARY]);\n          } else if (pat->data[i][index]<0x48) {\n            ImGui::PushStyleColor(ImGuiCol_Text,uiColors[GUI_COLOR_PATTERN_EFFECT_SYS_PRIMARY]);\n          } else if (pat->data[i][index]<0x90) {\n            ImGui::PushStyleColor(ImGuiCol_Text,uiColors[GUI_COLOR_PATTERN_EFFECT_INVALID]);\n          } else if (pat->data[i][index]<0xa0) {\n            ImGui::PushStyleColor(ImGuiCol_Text,uiColors[GUI_COLOR_PATTERN_EFFECT_MISC]);\n          } else if (pat->data[i][index]<0xc0) {\n            ImGui::PushStyleColor(ImGuiCol_Text,uiColors[GUI_COLOR_PATTERN_EFFECT_INVALID]);\n          } else if (pat->data[i][index]<0xd0) {\n            ImGui::PushStyleColor(ImGuiCol_Text,uiColors[GUI_COLOR_PATTERN_EFFECT_SPEED]);\n          } else if (pat->data[i][index]<0xe0) {\n            ImGui::PushStyleColor(ImGuiCol_Text,uiColors[GUI_COLOR_PATTERN_EFFECT_INVALID]);\n          } else {\n            ImGui::PushStyleColor(ImGuiCol_Text,uiColors[extFxColors[pat->data[i][index]-0xe0]]);\n          }\n        }\n        ImGui::SameLine(0.0f,0.0f);\n        if (cursorEffect) {\n          ImGui::PushStyleColor(ImGuiCol_Header,uiColors[GUI_COLOR_PATTERN_CURSOR]);  \n          ImGui::PushStyleColor(ImGuiCol_HeaderActive,uiColors[GUI_COLOR_PATTERN_CURSOR_ACTIVE]);\n          ImGui::PushStyleColor(ImGuiCol_HeaderHovered,uiColors[GUI_COLOR_PATTERN_CURSOR_HOVER]);\n          ImGui::Selectable(id,true,ImGuiSelectableFlags_NoPadWithHalfSpacing,twoChars);\n          demandX=ImGui::GetCursorPosX();\n          ImGui::PopStyleColor(3);\n        } else {\n          if (selectedEffect) ImGui::PushStyleColor(ImGuiCol_Header,uiColors[GUI_COLOR_PATTERN_SELECTION]);\n          ImGui::Selectable(id,isPushing || selectedEffect,ImGuiSelectableFlags_NoPadWithHalfSpacing,twoChars);\n          if (selectedEffect) ImGui::PopStyleColor();\n        }\n        if (ImGui::IsItemClicked()) {\n          startSelection(j,index-1,i);\n        }\n        if (ImGui::IsItemHovered(ImGuiHoveredFlags_AllowWhenBlockedByActiveItem)) {\n          updateSelection(j,index-1,i);\n        }\n\n        // effect value\n        if (pat->data[i][index+1]==-1) {\n          sprintf(id,\"..##PF%d_%d_%d\",k,i,j);\n        } else {\n          sprintf(id,\"%.2X##PF%d_%d_%d\",pat->data[i][index+1],k,i,j);\n        }\n        ImGui::SameLine(0.0f,0.0f);\n        if (cursorEffectVal) {\n          ImGui::PushStyleColor(ImGuiCol_Header,uiColors[GUI_COLOR_PATTERN_CURSOR]);  \n          ImGui::PushStyleColor(ImGuiCol_HeaderActive,uiColors[GUI_COLOR_PATTERN_CURSOR_ACTIVE]);\n          ImGui::PushStyleColor(ImGuiCol_HeaderHovered,uiColors[GUI_COLOR_PATTERN_CURSOR_HOVER]);\n          ImGui::Selectable(id,true,ImGuiSelectableFlags_NoPadWithHalfSpacing,twoChars);\n          demandX=ImGui::GetCursorPosX();\n          ImGui::PopStyleColor(3);\n        } else {\n          if (selectedEffectVal) ImGui::PushStyleColor(ImGuiCol_Header,uiColors[GUI_COLOR_PATTERN_SELECTION]);\n          ImGui::Selectable(id,isPushing || selectedEffectVal,ImGuiSelectableFlags_NoPadWithHalfSpacing,twoChars);\n          if (selectedEffectVal) ImGui::PopStyleColor();\n        }\n        if (ImGui::IsItemClicked()) {\n          startSelection(j,index,i);\n        }\n        if (ImGui::IsItemHovered(ImGuiHoveredFlags_AllowWhenBlockedByActiveItem)) {\n          updateSelection(j,index,i);\n        }\n        ImGui::PopStyleColor();\n      }\n    }\n  }\n  if (isPushing) {\n    ImGui::PopStyleColor();\n  }\n  ImGui::TableNextColumn();\n  patChanX[chans]=ImGui::GetCursorPosX();\n}",
        "func_hash": 17036366544095628794236625993100848883,
        "file_name": "pattern.cpp",
        "file_hash": 65197606135408680585944772278654686188,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2022-1289",
        "cve_desc": "A denial of service vulnerability was found in tildearrow Furnace. It has been classified as problematic. This is due to an incomplete fix of CVE-2022-1211. It is possible to initiate the attack remotely but it requires user interaction. The issue got fixed with the patch 0eb02422d5161767e9983bdaa5c429762d3477ce.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-1289",
        "func_name": "FurnaceGUI::patternRow",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 196846,
        "project": "tensorflow",
        "commit_id": "1e206baedf8bef0334cca3eb92bab134ef525a28",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/1e206baedf8bef0334cca3eb92bab134ef525a28",
        "commit_message": "Prevent a division by 0 in division ops.\n\nPiperOrigin-RevId: 385223169\nChange-Id: Ia4228960b5d2aa44480385f74bdd70d21a3613c3",
        "target": 1,
        "irrelevant": 0,
        "func_before": "TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n  auto* params = reinterpret_cast<TfLiteDivParams*>(node->builtin_data);\n  OpData* data = reinterpret_cast<OpData*>(node->user_data);\n\n  const TfLiteTensor* input1;\n  TF_LITE_ENSURE_OK(context,\n                    GetInputSafe(context, node, kInputTensor1, &input1));\n  const TfLiteTensor* input2;\n  TF_LITE_ENSURE_OK(context,\n                    GetInputSafe(context, node, kInputTensor2, &input2));\n  TfLiteTensor* output;\n  TF_LITE_ENSURE_OK(context,\n                    GetOutputSafe(context, node, kOutputTensor, &output));\n\n  if (output->type == kTfLiteFloat32 || output->type == kTfLiteInt32) {\n    EvalDiv<kernel_type>(context, node, params, data, input1, input2, output);\n  } else if (output->type == kTfLiteUInt8) {\n    TF_LITE_ENSURE_OK(\n        context, EvalQuantized<kernel_type>(context, node, params, data, input1,\n                                            input2, output));\n  } else {\n    context->ReportError(\n        context,\n        \"Div only supports FLOAT32, INT32 and quantized UINT8 now, got %d.\",\n        output->type);\n    return kTfLiteError;\n  }\n\n  return kTfLiteOk;\n}",
        "func_hash": 74793210691338682931219587955813295204,
        "file_name": "div.cc",
        "file_hash": 136615346340517059112870142252291864399,
        "cwe": [
            "CWE-369"
        ],
        "cve": "CVE-2021-37683",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions the implementation of division in TFLite is [vulnerable to a division by 0 error](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/lite/kernels/div.cc). There is no check that the divisor tensor does not contain zero elements. We have patched the issue in GitHub commit 1e206baedf8bef0334cca3eb92bab134ef525a28. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37683",
        "func_name": "Eval",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 196860,
        "project": "gpac",
        "commit_id": "a51f951b878c2b73c1d8e2f1518c7cdc5fb82c3f",
        "project_url": "https://github.com/gpac/gpac",
        "commit_url": "https://github.com/gpac/gpac/commit/a51f951b878c2b73c1d8e2f1518c7cdc5fb82c3f",
        "commit_message": "fixed #1782 (fuzz)",
        "target": 1,
        "irrelevant": 0,
        "func_before": "GF_Err afra_box_read(GF_Box *s, GF_BitStream *bs)\n{\n\tunsigned int i;\n\tGF_AdobeFragRandomAccessBox *ptr = (GF_AdobeFragRandomAccessBox *)s;\n\n\tISOM_DECREASE_SIZE(ptr, 9)\n\tptr->long_ids = gf_bs_read_int(bs, 1);\n\tptr->long_offsets = gf_bs_read_int(bs, 1);\n\tptr->global_entries = gf_bs_read_int(bs, 1);\n\tptr->reserved = gf_bs_read_int(bs, 5);\n\tptr->time_scale = gf_bs_read_u32(bs);\n\n\tptr->entry_count = gf_bs_read_u32(bs);\n\tif (ptr->size / ( (ptr->long_offsets ? 16 : 12) ) < ptr->entry_count)\n\t\treturn GF_ISOM_INVALID_FILE;\n\n\tfor (i=0; i<ptr->entry_count; i++) {\n\t\tGF_AfraEntry *ae = gf_malloc(sizeof(GF_AfraEntry));\n\t\tif (!ae) return GF_OUT_OF_MEM;\n\n\t\tISOM_DECREASE_SIZE(ptr, 8)\n\t\tae->time = gf_bs_read_u64(bs);\n\t\tif (ptr->long_offsets) {\n\t\t\tISOM_DECREASE_SIZE(ptr, 8)\n\t\t\tae->offset = gf_bs_read_u64(bs);\n\t\t} else {\n\t\t\tISOM_DECREASE_SIZE(ptr, 4)\n\t\t\tae->offset = gf_bs_read_u32(bs);\n\t\t}\n\n\t\tgf_list_insert(ptr->local_access_entries, ae, i);\n\t}\n\n\tif (ptr->global_entries) {\n\t\tISOM_DECREASE_SIZE(ptr, 4)\n\t\tptr->global_entry_count = gf_bs_read_u32(bs);\n\t\tfor (i=0; i<ptr->global_entry_count; i++) {\n\t\t\tGF_GlobalAfraEntry *ae = gf_malloc(sizeof(GF_GlobalAfraEntry));\n\t\t\tif (!ae) return GF_OUT_OF_MEM;\n\t\t\tISOM_DECREASE_SIZE(ptr, 8)\n\t\t\tae->time = gf_bs_read_u64(bs);\n\t\t\tif (ptr->long_ids) {\n\t\t\t\tISOM_DECREASE_SIZE(ptr, 8)\n\t\t\t\tae->segment = gf_bs_read_u32(bs);\n\t\t\t\tae->fragment = gf_bs_read_u32(bs);\n\t\t\t} else {\n\t\t\t\tISOM_DECREASE_SIZE(ptr, 4)\n\t\t\t\tae->segment = gf_bs_read_u16(bs);\n\t\t\t\tae->fragment = gf_bs_read_u16(bs);\n\t\t\t}\n\t\t\tif (ptr->long_offsets) {\n\t\t\t\tISOM_DECREASE_SIZE(ptr, 16)\n\t\t\t\tae->afra_offset = gf_bs_read_u64(bs);\n\t\t\t\tae->offset_from_afra = gf_bs_read_u64(bs);\n\t\t\t} else {\n\t\t\t\tISOM_DECREASE_SIZE(ptr, 8)\n\t\t\t\tae->afra_offset = gf_bs_read_u32(bs);\n\t\t\t\tae->offset_from_afra = gf_bs_read_u32(bs);\n\t\t\t}\n\n\t\t\tgf_list_insert(ptr->global_access_entries, ae, i);\n\t\t}\n\t}\n\n\treturn GF_OK;\n}",
        "func_hash": 312927211426500504617752335989791880756,
        "file_name": "box_code_adobe.c",
        "file_hash": null,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2021-33361",
        "cve_desc": "Memory leak in the afra_box_read function in MP4Box in GPAC 1.0.1 allows attackers to read memory via a crafted file.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-33361",
        "func_name": "afra_box_read",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 196885,
        "project": "tensorflow",
        "commit_id": "9e62869465573cb2d9b5053f1fa02a81fce21d69",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/9e62869465573cb2d9b5053f1fa02a81fce21d69",
        "commit_message": "Add more validation to `RequantizationRangePerChannel`.\n\nPiperOrigin-RevId: 387693946\nChange-Id: Ife8dcbdb021bec4787eef6a4361dd08f17c14bd6",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor& input = ctx->input(kInputTensorIndex);\n    const Tensor& input_min = ctx->input(kInputMinIndex);\n    const Tensor& input_max = ctx->input(kInputMaxIndex);\n\n    const size_t depth = input_max.NumElements();\n    OP_REQUIRES(\n        ctx, input_min.dim_size(0) == depth,\n        errors::InvalidArgument(\"input_min has incorrect size, expected \",\n                                depth, \" was \", input_min.dim_size(0)));\n    OP_REQUIRES(\n        ctx, input_max.dim_size(0) == depth,\n        errors::InvalidArgument(\"input_max has incorrect size, expected \",\n                                depth, \" was \", input_max.dim_size(0)));\n\n    const float* input_min_data = input_min.flat<float>().data();\n    const float* input_max_data = input_max.flat<float>().data();\n    std::vector<float> ranges(depth);\n    bool is_non_negative = true;\n    Eigen::array<int, 2> shuffling({1, 0});\n    auto input_matrix = input.flat_inner_dims<qint32>();\n\n    // TODO: verify performance of not transposing and finding the min max\n    // directly from input_matrix vs the one presented below of transposing and\n    // using the transposed matrix as the transposing operation in itself might\n    // be more costly.\n    // Note that this operation is a calibration step for quantization and will\n    // cease to exist in the final inference graph(will exist as a const node).\n    auto transposed_input = input_matrix.shuffle(shuffling);\n\n    // Find the ranges of each channel in parallel.\n    float out_min_max = std::numeric_limits<float>::min();\n\n#ifdef ENABLE_ONEDNN_OPENMP\n#ifdef _MSC_VER\n#pragma omp parallel for\n#else\n#pragma omp parallel for reduction(max : out_min_max)\n#endif\n#endif  // ENABLE_ONEDNN_OPENMP\n    // TODO: Add eigen parallel_for\n    for (int64_t i = 0; i < depth; ++i) {\n      Eigen::Tensor<qint32, 0, Eigen::RowMajor> min =\n          transposed_input.chip<0>(i).minimum();\n      Eigen::Tensor<qint32, 0, Eigen::RowMajor> max =\n          transposed_input.chip<0>(i).maximum();\n      const int32_t min_per_channel = min();\n      const int32_t max_per_channel = max();\n      const int32_t abs_max =\n          std::max(std::abs(min_per_channel), std::abs(max_per_channel));\n      float scale =\n          std::max(std::abs(input_min_data[i]), std::abs(input_max_data[i]));\n      ranges[i] =\n          scale * static_cast<float>(abs_max) / static_cast<float>(1L << 31);\n      if (min_per_channel < 0) is_non_negative = false;\n\n      // Thread-local out_min_max.\n      out_min_max = std::max(out_min_max, ranges[i]);\n    }\n\n    // All local out_min_max gets max-reduced into one global out_min_max at\n    // the end of the loop by specifying reduction(max:out_min_max) along with\n    // omp parallel for.\n\n    // Fixing max to clip_value_max_ (example 6.0 to support relu6)\n    if (out_min_max > clip_value_max_) out_min_max = clip_value_max_;\n\n    Tensor* output_min = nullptr;\n    Tensor* output_max = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->allocate_output(kOutputMinIndex, {}, &output_min));\n    OP_REQUIRES_OK(ctx, ctx->allocate_output(kOutputMaxIndex, {}, &output_max));\n    output_min->flat<float>()(0) = is_non_negative ? 0.0f : -out_min_max;\n    output_max->flat<float>()(0) = out_min_max;\n  }",
        "func_hash": 260350269729869693096839937488434150493,
        "file_name": "mkl_requantization_range_per_channel_op.cc",
        "file_hash": 184757242449876370761844438653930390458,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2021-37665",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions due to incomplete validation in MKL implementation of requantization, an attacker can trigger undefined behavior via binding a reference to a null pointer or can access data outside the bounds of heap allocated arrays. The [implementation](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/core/kernels/mkl/mkl_requantization_range_per_channel_op.cc) does not validate the dimensions of the `input` tensor. A similar issue occurs in `MklRequantizePerChannelOp`. The [implementation](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/core/kernels/mkl/mkl_requantize_per_channel_op.cc) does not perform full validation for all the input arguments. We have patched the issue in GitHub commit 9e62869465573cb2d9b5053f1fa02a81fce21d69 and in the Github commit 203214568f5bc237603dbab6e1fd389f1572f5c9. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37665",
        "func_name": "Compute",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195691,
        "project": "mruby",
        "commit_id": "a4d97934d51cb88954cc49161dc1d151f64afb6b",
        "project_url": "https://github.com/mruby/mruby",
        "commit_url": "https://github.com/mruby/mruby/commit/a4d97934d51cb88954cc49161dc1d151f64afb6b",
        "commit_message": "vm.c: check if target_class is NULL (when prepended).",
        "target": 1,
        "irrelevant": 0,
        "func_before": "mrb_vm_exec(mrb_state *mrb, const struct RProc *proc, const mrb_code *pc)\n{\n  /* mrb_assert(MRB_PROC_CFUNC_P(proc)) */\n  const mrb_irep *irep = proc->body.irep;\n  const mrb_pool_value *pool = irep->pool;\n  const mrb_sym *syms = irep->syms;\n  mrb_code insn;\n  int ai = mrb_gc_arena_save(mrb);\n  struct mrb_jmpbuf *prev_jmp = mrb->jmp;\n  struct mrb_jmpbuf c_jmp;\n  uint32_t a;\n  uint16_t b;\n  uint16_t c;\n  mrb_sym mid;\n  const struct mrb_irep_catch_handler *ch;\n\n#ifdef DIRECT_THREADED\n  static const void * const optable[] = {\n#define OPCODE(x,_) &&L_OP_ ## x,\n#include \"mruby/ops.h\"\n#undef OPCODE\n  };\n#endif\n\n  mrb_bool exc_catched = FALSE;\nRETRY_TRY_BLOCK:\n\n  MRB_TRY(&c_jmp) {\n\n  if (exc_catched) {\n    exc_catched = FALSE;\n    mrb_gc_arena_restore(mrb, ai);\n    if (mrb->exc && mrb->exc->tt == MRB_TT_BREAK)\n      goto L_BREAK;\n    goto L_RAISE;\n  }\n  mrb->jmp = &c_jmp;\n  mrb_vm_ci_proc_set(mrb->c->ci, proc);\n\n#define regs (mrb->c->ci->stack)\n  INIT_DISPATCH {\n    CASE(OP_NOP, Z) {\n      /* do nothing */\n      NEXT;\n    }\n\n    CASE(OP_MOVE, BB) {\n      regs[a] = regs[b];\n      NEXT;\n    }\n\n    CASE(OP_LOADL, BB) {\n      switch (pool[b].tt) {   /* number */\n      case IREP_TT_INT32:\n        regs[a] = mrb_int_value(mrb, (mrb_int)pool[b].u.i32);\n        break;\n      case IREP_TT_INT64:\n#if defined(MRB_INT64)\n        regs[a] = mrb_int_value(mrb, (mrb_int)pool[b].u.i64);\n        break;\n#else\n#if defined(MRB_64BIT)\n        if (INT32_MIN <= pool[b].u.i64 && pool[b].u.i64 <= INT32_MAX) {\n          regs[a] = mrb_int_value(mrb, (mrb_int)pool[b].u.i64);\n          break;\n        }\n#endif\n        goto L_INT_OVERFLOW;\n#endif\n      case IREP_TT_BIGINT:\n#ifdef MRB_USE_BIGINT\n        {\n          const char *s = pool[b].u.str;\n          regs[a] = mrb_bint_new_str(mrb, s+2, (mrb_int)s[0], (mrb_int)s[1]);\n        }\n        break;\n#else\n        goto L_INT_OVERFLOW;\n#endif\n#ifndef MRB_NO_FLOAT\n      case IREP_TT_FLOAT:\n        regs[a] = mrb_float_value(mrb, pool[b].u.f);\n        break;\n#endif\n      default:\n        /* should not happen (tt:string) */\n        regs[a] = mrb_nil_value();\n        break;\n      }\n      NEXT;\n    }\n\n    CASE(OP_LOADI, BB) {\n      SET_FIXNUM_VALUE(regs[a], b);\n      NEXT;\n    }\n\n    CASE(OP_LOADINEG, BB) {\n      SET_FIXNUM_VALUE(regs[a], -b);\n      NEXT;\n    }\n\n    CASE(OP_LOADI__1,B) goto L_LOADI;\n    CASE(OP_LOADI_0,B) goto L_LOADI;\n    CASE(OP_LOADI_1,B) goto L_LOADI;\n    CASE(OP_LOADI_2,B) goto L_LOADI;\n    CASE(OP_LOADI_3,B) goto L_LOADI;\n    CASE(OP_LOADI_4,B) goto L_LOADI;\n    CASE(OP_LOADI_5,B) goto L_LOADI;\n    CASE(OP_LOADI_6,B) goto L_LOADI;\n    CASE(OP_LOADI_7, B) {\n    L_LOADI:\n      SET_FIXNUM_VALUE(regs[a], (mrb_int)insn - (mrb_int)OP_LOADI_0);\n      NEXT;\n    }\n\n    CASE(OP_LOADI16, BS) {\n      SET_FIXNUM_VALUE(regs[a], (mrb_int)(int16_t)b);\n      NEXT;\n    }\n\n    CASE(OP_LOADI32, BSS) {\n      SET_INT_VALUE(mrb, regs[a], (int32_t)(((uint32_t)b<<16)+c));\n      NEXT;\n    }\n\n    CASE(OP_LOADSYM, BB) {\n      SET_SYM_VALUE(regs[a], syms[b]);\n      NEXT;\n    }\n\n    CASE(OP_LOADNIL, B) {\n      SET_NIL_VALUE(regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_LOADSELF, B) {\n      regs[a] = regs[0];\n      NEXT;\n    }\n\n    CASE(OP_LOADT, B) {\n      SET_TRUE_VALUE(regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_LOADF, B) {\n      SET_FALSE_VALUE(regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETGV, BB) {\n      mrb_value val = mrb_gv_get(mrb, syms[b]);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETGV, BB) {\n      mrb_gv_set(mrb, syms[b], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETSV, BB) {\n      mrb_value val = mrb_vm_special_get(mrb, syms[b]);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETSV, BB) {\n      mrb_vm_special_set(mrb, syms[b], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETIV, BB) {\n      regs[a] = mrb_iv_get(mrb, regs[0], syms[b]);\n      NEXT;\n    }\n\n    CASE(OP_SETIV, BB) {\n      mrb_iv_set(mrb, regs[0], syms[b], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETCV, BB) {\n      mrb_value val;\n      val = mrb_vm_cv_get(mrb, syms[b]);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETCV, BB) {\n      mrb_vm_cv_set(mrb, syms[b], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETIDX, B) {\n      mrb_value va = regs[a], vb = regs[a+1];\n      switch (mrb_type(va)) {\n      case MRB_TT_ARRAY:\n        if (!mrb_integer_p(vb)) goto getidx_fallback;\n        regs[a] = mrb_ary_entry(va, mrb_integer(vb));\n        break;\n      case MRB_TT_HASH:\n        va = mrb_hash_get(mrb, va, vb);\n        regs[a] = va;\n        break;\n      case MRB_TT_STRING:\n        switch (mrb_type(vb)) {\n        case MRB_TT_INTEGER:\n        case MRB_TT_STRING:\n        case MRB_TT_RANGE:\n          va = mrb_str_aref(mrb, va, vb, mrb_undef_value());\n          regs[a] = va;\n          break;\n        default:\n          goto getidx_fallback;\n        }\n        break;\n      default:\n      getidx_fallback:\n        mid = MRB_OPSYM(aref);\n        goto L_SEND_SYM;\n      }\n      NEXT;\n    }\n\n    CASE(OP_SETIDX, B) {\n      c = 2;\n      mid = MRB_OPSYM(aset);\n      SET_NIL_VALUE(regs[a+3]);\n      goto L_SENDB_SYM;\n    }\n\n    CASE(OP_GETCONST, BB) {\n      mrb_value v = mrb_vm_const_get(mrb, syms[b]);\n      regs[a] = v;\n      NEXT;\n    }\n\n    CASE(OP_SETCONST, BB) {\n      mrb_vm_const_set(mrb, syms[b], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETMCNST, BB) {\n      mrb_value v = mrb_const_get(mrb, regs[a], syms[b]);\n      regs[a] = v;\n      NEXT;\n    }\n\n    CASE(OP_SETMCNST, BB) {\n      mrb_const_set(mrb, regs[a+1], syms[b], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETUPVAR, BBB) {\n      mrb_value *regs_a = regs + a;\n      struct REnv *e = uvenv(mrb, c);\n\n      if (e && b < MRB_ENV_LEN(e)) {\n        *regs_a = e->stack[b];\n      }\n      else {\n        *regs_a = mrb_nil_value();\n      }\n      NEXT;\n    }\n\n    CASE(OP_SETUPVAR, BBB) {\n      struct REnv *e = uvenv(mrb, c);\n\n      if (e) {\n        mrb_value *regs_a = regs + a;\n\n        if (b < MRB_ENV_LEN(e)) {\n          e->stack[b] = *regs_a;\n          mrb_write_barrier(mrb, (struct RBasic*)e);\n        }\n      }\n      NEXT;\n    }\n\n    CASE(OP_JMP, S) {\n      pc += (int16_t)a;\n      JUMP;\n    }\n    CASE(OP_JMPIF, BS) {\n      if (mrb_test(regs[a])) {\n        pc += (int16_t)b;\n        JUMP;\n      }\n      NEXT;\n    }\n    CASE(OP_JMPNOT, BS) {\n      if (!mrb_test(regs[a])) {\n        pc += (int16_t)b;\n        JUMP;\n      }\n      NEXT;\n    }\n    CASE(OP_JMPNIL, BS) {\n      if (mrb_nil_p(regs[a])) {\n        pc += (int16_t)b;\n        JUMP;\n      }\n      NEXT;\n    }\n\n    CASE(OP_JMPUW, S) {\n      a = (uint32_t)((pc - irep->iseq) + (int16_t)a);\n      CHECKPOINT_RESTORE(RBREAK_TAG_JUMP) {\n        struct RBreak *brk = (struct RBreak*)mrb->exc;\n        mrb_value target = mrb_break_value_get(brk);\n        mrb_assert(mrb_integer_p(target));\n        a = (uint32_t)mrb_integer(target);\n        mrb_assert(a >= 0 && a < irep->ilen);\n      }\n      CHECKPOINT_MAIN(RBREAK_TAG_JUMP) {\n        ch = catch_handler_find(mrb, mrb->c->ci, pc, MRB_CATCH_FILTER_ENSURE);\n        if (ch) {\n          /* avoiding a jump from a catch handler into the same handler */\n          if (a < mrb_irep_catch_handler_unpack(ch->begin) || a >= mrb_irep_catch_handler_unpack(ch->end)) {\n            THROW_TAGGED_BREAK(mrb, RBREAK_TAG_JUMP, proc, mrb_fixnum_value(a));\n          }\n        }\n      }\n      CHECKPOINT_END(RBREAK_TAG_JUMP);\n\n      mrb->exc = NULL; /* clear break object */\n      pc = irep->iseq + a;\n      JUMP;\n    }\n\n    CASE(OP_EXCEPT, B) {\n      mrb_value exc;\n\n      if (mrb->exc == NULL) {\n        exc = mrb_nil_value();\n      }\n      else {\n        switch (mrb->exc->tt) {\n        case MRB_TT_BREAK:\n        case MRB_TT_EXCEPTION:\n          exc = mrb_obj_value(mrb->exc);\n          break;\n        default:\n          mrb_assert(!\"bad mrb_type\");\n          exc = mrb_nil_value();\n          break;\n        }\n        mrb->exc = NULL;\n      }\n      regs[a] = exc;\n      NEXT;\n    }\n    CASE(OP_RESCUE, BB) {\n      mrb_value exc = regs[a];  /* exc on stack */\n      mrb_value e = regs[b];\n      struct RClass *ec;\n\n      switch (mrb_type(e)) {\n      case MRB_TT_CLASS:\n      case MRB_TT_MODULE:\n        break;\n      default:\n        {\n          mrb_value exc;\n\n          exc = mrb_exc_new_lit(mrb, E_TYPE_ERROR,\n                                    \"class or module required for rescue clause\");\n          mrb_exc_set(mrb, exc);\n          goto L_RAISE;\n        }\n      }\n      ec = mrb_class_ptr(e);\n      regs[b] = mrb_bool_value(mrb_obj_is_kind_of(mrb, exc, ec));\n      NEXT;\n    }\n\n    CASE(OP_RAISEIF, B) {\n      mrb_value exc = regs[a];\n      if (mrb_break_p(exc)) {\n        mrb->exc = mrb_obj_ptr(exc);\n        goto L_BREAK;\n      }\n      mrb_exc_set(mrb, exc);\n      if (mrb->exc) {\n        goto L_RAISE;\n      }\n      NEXT;\n    }\n\n    CASE(OP_SSEND, BBB) {\n      regs[a] = regs[0];\n      insn = OP_SEND;\n    }\n    goto L_SENDB;\n\n    CASE(OP_SSENDB, BBB) {\n      regs[a] = regs[0];\n    }\n    goto L_SENDB;\n\n    CASE(OP_SEND, BBB)\n    goto L_SENDB;\n\n    L_SEND_SYM:\n    c = 1;\n    /* push nil after arguments */\n    SET_NIL_VALUE(regs[a+2]);\n    goto L_SENDB_SYM;\n\n    CASE(OP_SENDB, BBB)\n    L_SENDB:\n    mid = syms[b];\n    L_SENDB_SYM:\n    {\n      mrb_callinfo *ci = mrb->c->ci;\n      mrb_method_t m;\n      struct RClass *cls;\n      mrb_value recv, blk;\n\n      ARGUMENT_NORMALIZE(a, &c, insn);\n\n      recv = regs[a];\n      cls = mrb_class(mrb, recv);\n      m = mrb_method_search_vm(mrb, &cls, mid);\n      if (MRB_METHOD_UNDEF_P(m)) {\n        m = prepare_missing(mrb, recv, mid, &cls, a, &c, blk, 0);\n        mid = MRB_SYM(method_missing);\n      }\n\n      /* push callinfo */\n      ci = cipush(mrb, a, 0, cls, NULL, mid, c);\n\n      if (MRB_METHOD_CFUNC_P(m)) {\n        if (MRB_METHOD_PROC_P(m)) {\n          struct RProc *p = MRB_METHOD_PROC(m);\n\n          mrb_vm_ci_proc_set(ci, p);\n          recv = p->body.func(mrb, recv);\n        }\n        else {\n          if (MRB_METHOD_NOARG_P(m)) {\n            check_method_noarg(mrb, ci);\n          }\n          recv = MRB_METHOD_FUNC(m)(mrb, recv);\n        }\n        mrb_gc_arena_shrink(mrb, ai);\n        if (mrb->exc) goto L_RAISE;\n        ci = mrb->c->ci;\n        if (mrb_proc_p(blk)) {\n          struct RProc *p = mrb_proc_ptr(blk);\n          if (p && !MRB_PROC_STRICT_P(p) && MRB_PROC_ENV(p) == mrb_vm_ci_env(&ci[-1])) {\n            p->flags |= MRB_PROC_ORPHAN;\n          }\n        }\n        if (!ci->u.target_class) { /* return from context modifying method (resume/yield) */\n          if (ci->cci == CINFO_RESUMED) {\n            mrb->jmp = prev_jmp;\n            return recv;\n          }\n          else {\n            mrb_assert(!MRB_PROC_CFUNC_P(ci[-1].proc));\n            proc = ci[-1].proc;\n            irep = proc->body.irep;\n            pool = irep->pool;\n            syms = irep->syms;\n          }\n        }\n        ci->stack[0] = recv;\n        /* pop stackpos */\n        ci = cipop(mrb);\n        pc = ci->pc;\n      }\n      else {\n        /* setup environment for calling method */\n        mrb_vm_ci_proc_set(ci, (proc = MRB_METHOD_PROC(m)));\n        irep = proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n        mrb_stack_extend(mrb, (irep->nregs < 4) ? 4 : irep->nregs);\n        pc = irep->iseq;\n      }\n    }\n    JUMP;\n\n    CASE(OP_CALL, Z) {\n      mrb_callinfo *ci = mrb->c->ci;\n      mrb_value recv = ci->stack[0];\n      struct RProc *m = mrb_proc_ptr(recv);\n\n      /* replace callinfo */\n      ci->u.target_class = MRB_PROC_TARGET_CLASS(m);\n      mrb_vm_ci_proc_set(ci, m);\n      if (MRB_PROC_ENV_P(m)) {\n        ci->mid = MRB_PROC_ENV(m)->mid;\n      }\n\n      /* prepare stack */\n      if (MRB_PROC_CFUNC_P(m)) {\n        recv = MRB_PROC_CFUNC(m)(mrb, recv);\n        mrb_gc_arena_shrink(mrb, ai);\n        if (mrb->exc) goto L_RAISE;\n        /* pop stackpos */\n        ci = cipop(mrb);\n        pc = ci->pc;\n        ci[1].stack[0] = recv;\n        irep = mrb->c->ci->proc->body.irep;\n      }\n      else {\n        /* setup environment for calling method */\n        proc = m;\n        irep = m->body.irep;\n        if (!irep) {\n          mrb->c->ci->stack[0] = mrb_nil_value();\n          a = 0;\n          c = OP_R_NORMAL;\n          goto L_OP_RETURN_BODY;\n        }\n        mrb_int nargs = mrb_ci_bidx(ci)+1;\n        if (nargs < irep->nregs) {\n          mrb_stack_extend(mrb, irep->nregs);\n          stack_clear(regs+nargs, irep->nregs-nargs);\n        }\n        if (MRB_PROC_ENV_P(m)) {\n          regs[0] = MRB_PROC_ENV(m)->stack[0];\n        }\n        pc = irep->iseq;\n      }\n      pool = irep->pool;\n      syms = irep->syms;\n      JUMP;\n    }\n\n    CASE(OP_SUPER, BB) {\n      mrb_method_t m;\n      struct RClass *cls;\n      mrb_callinfo *ci = mrb->c->ci;\n      mrb_value recv, blk;\n      const struct RProc *p = ci->proc;\n      mrb_sym mid = ci->mid;\n      struct RClass* target_class = MRB_PROC_TARGET_CLASS(p);\n\n      if (MRB_PROC_ENV_P(p) && p->e.env->mid && p->e.env->mid != mid) { /* alias support */\n        mid = p->e.env->mid;    /* restore old mid */\n      }\n\n      if (mid == 0 || !target_class) {\n        mrb_value exc = mrb_exc_new_lit(mrb, E_NOMETHOD_ERROR, \"super called outside of method\");\n        mrb_exc_set(mrb, exc);\n        goto L_RAISE;\n      }\n      if (target_class->flags & MRB_FL_CLASS_IS_PREPENDED) {\n        target_class = mrb_vm_ci_target_class(ci);\n      }\n      else if (target_class->tt == MRB_TT_MODULE) {\n        target_class = mrb_vm_ci_target_class(ci);\n        if (!target_class || target_class->tt != MRB_TT_ICLASS) {\n          goto super_typeerror;\n        }\n      }\n      recv = regs[0];\n      if (!mrb_obj_is_kind_of(mrb, recv, target_class)) {\n      super_typeerror: ;\n        mrb_value exc = mrb_exc_new_lit(mrb, E_TYPE_ERROR,\n                                            \"self has wrong type to call super in this context\");\n        mrb_exc_set(mrb, exc);\n        goto L_RAISE;\n      }\n\n      ARGUMENT_NORMALIZE(a, &b, OP_SUPER);\n\n      cls = target_class->super;\n      m = mrb_method_search_vm(mrb, &cls, mid);\n      if (MRB_METHOD_UNDEF_P(m)) {\n        m = prepare_missing(mrb, recv, mid, &cls, a, &b, blk, 1);\n        mid = MRB_SYM(method_missing);\n      }\n\n      /* push callinfo */\n      ci = cipush(mrb, a, 0, cls, NULL, mid, b);\n\n      /* prepare stack */\n      ci->stack[0] = recv;\n\n      if (MRB_METHOD_CFUNC_P(m)) {\n        mrb_value v;\n\n        if (MRB_METHOD_PROC_P(m)) {\n          mrb_vm_ci_proc_set(ci, MRB_METHOD_PROC(m));\n        }\n        v = MRB_METHOD_CFUNC(m)(mrb, recv);\n        mrb_gc_arena_restore(mrb, ai);\n        if (mrb->exc) goto L_RAISE;\n        ci = mrb->c->ci;\n        mrb_assert(!mrb_break_p(v));\n        if (!mrb_vm_ci_target_class(ci)) { /* return from context modifying method (resume/yield) */\n          if (ci->cci == CINFO_RESUMED) {\n            mrb->jmp = prev_jmp;\n            return v;\n          }\n          else {\n            mrb_assert(!MRB_PROC_CFUNC_P(ci[-1].proc));\n            proc = ci[-1].proc;\n            irep = proc->body.irep;\n            pool = irep->pool;\n            syms = irep->syms;\n          }\n        }\n        mrb->c->ci->stack[0] = v;\n        ci = cipop(mrb);\n        pc = ci->pc;\n      }\n      else {\n        /* setup environment for calling method */\n        mrb_vm_ci_proc_set(ci, (proc = MRB_METHOD_PROC(m)));\n        irep = proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n        mrb_stack_extend(mrb, (irep->nregs < 4) ? 4 : irep->nregs);\n        pc = irep->iseq;\n      }\n      JUMP;\n    }\n\n    CASE(OP_ARGARY, BS) {\n      mrb_int m1 = (b>>11)&0x3f;\n      mrb_int r  = (b>>10)&0x1;\n      mrb_int m2 = (b>>5)&0x1f;\n      mrb_int kd = (b>>4)&0x1;\n      mrb_int lv = (b>>0)&0xf;\n      mrb_value *stack;\n\n      if (mrb->c->ci->mid == 0 || mrb_vm_ci_target_class(mrb->c->ci) == NULL) {\n        mrb_value exc;\n\n      L_NOSUPER:\n        exc = mrb_exc_new_lit(mrb, E_NOMETHOD_ERROR, \"super called outside of method\");\n        mrb_exc_set(mrb, exc);\n        goto L_RAISE;\n      }\n      if (lv == 0) stack = regs + 1;\n      else {\n        struct REnv *e = uvenv(mrb, lv-1);\n        if (!e) goto L_NOSUPER;\n        if (MRB_ENV_LEN(e) <= m1+r+m2+1)\n          goto L_NOSUPER;\n        stack = e->stack + 1;\n      }\n      if (r == 0) {\n        regs[a] = mrb_ary_new_from_values(mrb, m1+m2, stack);\n      }\n      else {\n        mrb_value *pp = NULL;\n        struct RArray *rest;\n        mrb_int len = 0;\n\n        if (mrb_array_p(stack[m1])) {\n          struct RArray *ary = mrb_ary_ptr(stack[m1]);\n\n          pp = ARY_PTR(ary);\n          len = ARY_LEN(ary);\n        }\n        regs[a] = mrb_ary_new_capa(mrb, m1+len+m2);\n        rest = mrb_ary_ptr(regs[a]);\n        if (m1 > 0) {\n          stack_copy(ARY_PTR(rest), stack, m1);\n        }\n        if (len > 0) {\n          stack_copy(ARY_PTR(rest)+m1, pp, len);\n        }\n        if (m2 > 0) {\n          stack_copy(ARY_PTR(rest)+m1+len, stack+m1+1, m2);\n        }\n        ARY_SET_LEN(rest, m1+len+m2);\n      }\n      if (kd) {\n        regs[a+1] = stack[m1+r+m2];\n        regs[a+2] = stack[m1+r+m2+1];\n      }\n      else {\n        regs[a+1] = stack[m1+r+m2];\n      }\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_ENTER, W) {\n      mrb_int m1 = MRB_ASPEC_REQ(a);\n      mrb_int o  = MRB_ASPEC_OPT(a);\n      mrb_int r  = MRB_ASPEC_REST(a);\n      mrb_int m2 = MRB_ASPEC_POST(a);\n      mrb_int kd = (MRB_ASPEC_KEY(a) > 0 || MRB_ASPEC_KDICT(a))? 1 : 0;\n      /* unused\n      int b  = MRB_ASPEC_BLOCK(a);\n      */\n      mrb_int const len = m1 + o + r + m2;\n\n      mrb_callinfo *ci = mrb->c->ci;\n      mrb_int argc = ci->n;\n      mrb_value *argv = regs+1;\n      mrb_value * const argv0 = argv;\n      mrb_int const kw_pos = len + kd;    /* where kwhash should be */\n      mrb_int const blk_pos = kw_pos + 1; /* where block should be */\n      mrb_value blk = regs[mrb_ci_bidx(ci)];\n      mrb_value kdict = mrb_nil_value();\n\n      /* keyword arguments */\n      if (ci->nk > 0) {\n        mrb_int kidx = mrb_ci_kidx(ci);\n        kdict = regs[kidx];\n        if (!mrb_hash_p(kdict) || mrb_hash_size(mrb, kdict) == 0) {\n          kdict = mrb_nil_value();\n          ci->nk = 0;\n        }\n      }\n      if (!kd && !mrb_nil_p(kdict)) {\n        if (argc < 14) {\n          ci->n++;\n          argc++;    /* include kdict in normal arguments */\n        }\n        else if (argc == 14) {\n          /* pack arguments and kdict */\n          regs[1] = mrb_ary_new_from_values(mrb, argc+1, &regs[1]);\n          argc = ci->n = 15;\n        }\n        else {/* argc == 15 */\n          /* push kdict to packed arguments */\n          mrb_ary_push(mrb, regs[1], regs[2]);\n        }\n        ci->nk = 0;\n      }\n      if (kd && MRB_ASPEC_KEY(a) > 0 && mrb_hash_p(kdict)) {\n        kdict = mrb_hash_dup(mrb, kdict);\n      }\n\n      /* arguments is passed with Array */\n      if (argc == 15) {\n        struct RArray *ary = mrb_ary_ptr(regs[1]);\n        argv = ARY_PTR(ary);\n        argc = (int)ARY_LEN(ary);\n        mrb_gc_protect(mrb, regs[1]);\n      }\n\n      /* strict argument check */\n      if (ci->proc && MRB_PROC_STRICT_P(ci->proc)) {\n        if (argc < m1 + m2 || (r == 0 && argc > len)) {\n          argnum_error(mrb, m1+m2);\n          goto L_RAISE;\n        }\n      }\n      /* extract first argument array to arguments */\n      else if (len > 1 && argc == 1 && mrb_array_p(argv[0])) {\n        mrb_gc_protect(mrb, argv[0]);\n        argc = (int)RARRAY_LEN(argv[0]);\n        argv = RARRAY_PTR(argv[0]);\n      }\n\n      /* rest arguments */\n      mrb_value rest = mrb_nil_value();\n      if (argc < len) {\n        mrb_int mlen = m2;\n        if (argc < m1+m2) {\n          mlen = m1 < argc ? argc - m1 : 0;\n        }\n\n        /* copy mandatory and optional arguments */\n        if (argv0 != argv && argv) {\n          value_move(&regs[1], argv, argc-mlen); /* m1 + o */\n        }\n        if (argc < m1) {\n          stack_clear(&regs[argc+1], m1-argc);\n        }\n        /* copy post mandatory arguments */\n        if (mlen) {\n          value_move(&regs[len-m2+1], &argv[argc-mlen], mlen);\n        }\n        if (mlen < m2) {\n          stack_clear(&regs[len-m2+mlen+1], m2-mlen);\n        }\n        /* initialize rest arguments with empty Array */\n        if (r) {\n          rest = mrb_ary_new_capa(mrb, 0);\n          regs[m1+o+1] = rest;\n        }\n        /* skip initializer of passed arguments */\n        if (o > 0 && argc > m1+m2)\n          pc += (argc - m1 - m2)*3;\n      }\n      else {\n        mrb_int rnum = 0;\n        if (argv0 != argv) {\n          value_move(&regs[1], argv, m1+o);\n        }\n        if (r) {\n          rnum = argc-m1-o-m2;\n          rest = mrb_ary_new_from_values(mrb, rnum, argv+m1+o);\n          regs[m1+o+1] = rest;\n        }\n        if (m2 > 0 && argc-m2 > m1) {\n          value_move(&regs[m1+o+r+1], &argv[m1+o+rnum], m2);\n        }\n        pc += o*3;\n      }\n\n      /* need to be update blk first to protect blk from GC */\n      regs[blk_pos] = blk;              /* move block */\n      if (kd) {\n        if (mrb_nil_p(kdict))\n          kdict = mrb_hash_new_capa(mrb, 0);\n        regs[kw_pos] = kdict;           /* set kwhash */\n      }\n\n      /* format arguments for generated code */\n      mrb->c->ci->n = (uint8_t)len;\n\n      /* clear local (but non-argument) variables */\n      if (irep->nlocals-blk_pos-1 > 0) {\n        stack_clear(&regs[blk_pos+1], irep->nlocals-blk_pos-1);\n      }\n      JUMP;\n    }\n\n    CASE(OP_KARG, BB) {\n      mrb_value k = mrb_symbol_value(syms[b]);\n      mrb_int kidx = mrb_ci_kidx(mrb->c->ci);\n      mrb_value kdict, v;\n\n      if (kidx < 0 || !mrb_hash_p(kdict=regs[kidx]) || !mrb_hash_key_p(mrb, kdict, k)) {\n        mrb_value str = mrb_format(mrb, \"missing keyword: %v\", k);\n        mrb_exc_set(mrb, mrb_exc_new_str(mrb, E_ARGUMENT_ERROR, str));\n        goto L_RAISE;\n      }\n      v = mrb_hash_get(mrb, kdict, k);\n      regs[a] = v;\n      mrb_hash_delete_key(mrb, kdict, k);\n      NEXT;\n    }\n\n    CASE(OP_KEY_P, BB) {\n      mrb_value k = mrb_symbol_value(syms[b]);\n      mrb_int kidx = mrb_ci_kidx(mrb->c->ci);\n      mrb_value kdict;\n      mrb_bool key_p = FALSE;\n\n      if (kidx >= 0 && mrb_hash_p(kdict=regs[kidx])) {\n        key_p = mrb_hash_key_p(mrb, kdict, k);\n      }\n      regs[a] = mrb_bool_value(key_p);\n      NEXT;\n    }\n\n    CASE(OP_KEYEND, Z) {\n      mrb_int kidx = mrb_ci_kidx(mrb->c->ci);\n      mrb_value kdict;\n\n      if (kidx >= 0 && mrb_hash_p(kdict=regs[kidx]) && !mrb_hash_empty_p(mrb, kdict)) {\n        mrb_value keys = mrb_hash_keys(mrb, kdict);\n        mrb_value key1 = RARRAY_PTR(keys)[0];\n        mrb_value str = mrb_format(mrb, \"unknown keyword: %v\", key1);\n        mrb_exc_set(mrb, mrb_exc_new_str(mrb, E_ARGUMENT_ERROR, str));\n        goto L_RAISE;\n      }\n      NEXT;\n    }\n\n    CASE(OP_BREAK, B) {\n      c = OP_R_BREAK;\n      goto L_RETURN;\n    }\n    CASE(OP_RETURN_BLK, B) {\n      c = OP_R_RETURN;\n      goto L_RETURN;\n    }\n    CASE(OP_RETURN, B)\n    c = OP_R_NORMAL;\n    L_RETURN:\n    {\n      mrb_callinfo *ci;\n\n      ci = mrb->c->ci;\n      if (ci->mid) {\n        mrb_value blk = regs[mrb_ci_bidx(ci)];\n\n        if (mrb_proc_p(blk)) {\n          struct RProc *p = mrb_proc_ptr(blk);\n\n          if (!MRB_PROC_STRICT_P(p) &&\n              ci > mrb->c->cibase && MRB_PROC_ENV(p) == mrb_vm_ci_env(&ci[-1])) {\n            p->flags |= MRB_PROC_ORPHAN;\n          }\n        }\n      }\n\n      if (mrb->exc) {\n      L_RAISE:\n        ci = mrb->c->ci;\n        if (ci == mrb->c->cibase) {\n          ch = catch_handler_find(mrb, ci, pc, MRB_CATCH_FILTER_ALL);\n          if (ch == NULL) goto L_FTOP;\n          goto L_CATCH;\n        }\n        while ((ch = catch_handler_find(mrb, ci, pc, MRB_CATCH_FILTER_ALL)) == NULL) {\n          ci = cipop(mrb);\n          if (ci[1].cci == CINFO_SKIP && prev_jmp) {\n            mrb->jmp = prev_jmp;\n            MRB_THROW(prev_jmp);\n          }\n          pc = ci[0].pc;\n          if (ci == mrb->c->cibase) {\n            ch = catch_handler_find(mrb, ci, pc, MRB_CATCH_FILTER_ALL);\n            if (ch == NULL) {\n            L_FTOP:             /* fiber top */\n              if (mrb->c == mrb->root_c) {\n                mrb->c->ci->stack = mrb->c->stbase;\n                goto L_STOP;\n              }\n              else {\n                struct mrb_context *c = mrb->c;\n\n                c->status = MRB_FIBER_TERMINATED;\n                mrb->c = c->prev;\n                c->prev = NULL;\n                goto L_RAISE;\n              }\n            }\n            break;\n          }\n        }\n      L_CATCH:\n        if (ch == NULL) goto L_STOP;\n        if (FALSE) {\n        L_CATCH_TAGGED_BREAK: /* from THROW_TAGGED_BREAK() or UNWIND_ENSURE() */\n          ci = mrb->c->ci;\n        }\n        proc = ci->proc;\n        irep = proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n        mrb_stack_extend(mrb, irep->nregs);\n        pc = irep->iseq + mrb_irep_catch_handler_unpack(ch->target);\n      }\n      else {\n        mrb_int acc;\n        mrb_value v;\n\n        ci = mrb->c->ci;\n        v = regs[a];\n        mrb_gc_protect(mrb, v);\n        switch (c) {\n        case OP_R_RETURN:\n          /* Fall through to OP_R_NORMAL otherwise */\n          if (ci->cci == CINFO_NONE && MRB_PROC_ENV_P(proc) && !MRB_PROC_STRICT_P(proc)) {\n            const struct RProc *dst;\n            mrb_callinfo *cibase;\n            cibase = mrb->c->cibase;\n            dst = top_proc(mrb, proc);\n\n            if (MRB_PROC_ENV_P(dst)) {\n              struct REnv *e = MRB_PROC_ENV(dst);\n\n              if (!MRB_ENV_ONSTACK_P(e) || (e->cxt && e->cxt != mrb->c)) {\n                localjump_error(mrb, LOCALJUMP_ERROR_RETURN);\n                goto L_RAISE;\n              }\n            }\n            /* check jump destination */\n            while (cibase <= ci && ci->proc != dst) {\n              if (ci->cci > CINFO_NONE) { /* jump cross C boundary */\n                localjump_error(mrb, LOCALJUMP_ERROR_RETURN);\n                goto L_RAISE;\n              }\n              ci--;\n            }\n            if (ci <= cibase) { /* no jump destination */\n              localjump_error(mrb, LOCALJUMP_ERROR_RETURN);\n              goto L_RAISE;\n            }\n            ci = mrb->c->ci;\n            while (cibase <= ci && ci->proc != dst) {\n              CHECKPOINT_RESTORE(RBREAK_TAG_RETURN_BLOCK) {\n                cibase = mrb->c->cibase;\n                dst = top_proc(mrb, proc);\n              }\n              CHECKPOINT_MAIN(RBREAK_TAG_RETURN_BLOCK) {\n                UNWIND_ENSURE(mrb, ci, pc, RBREAK_TAG_RETURN_BLOCK, proc, v);\n              }\n              CHECKPOINT_END(RBREAK_TAG_RETURN_BLOCK);\n              ci = cipop(mrb);\n              pc = ci->pc;\n            }\n            proc = ci->proc;\n            mrb->exc = NULL; /* clear break object */\n            break;\n          }\n          /* fallthrough */\n        case OP_R_NORMAL:\n        NORMAL_RETURN:\n          if (ci == mrb->c->cibase) {\n            struct mrb_context *c;\n            c = mrb->c;\n\n            if (!c->prev) { /* toplevel return */\n              regs[irep->nlocals] = v;\n              goto CHECKPOINT_LABEL_MAKE(RBREAK_TAG_STOP);\n            }\n            if (!c->vmexec && c->prev->ci == c->prev->cibase) {\n              mrb_value exc = mrb_exc_new_lit(mrb, E_FIBER_ERROR, \"double resume\");\n              mrb_exc_set(mrb, exc);\n              goto L_RAISE;\n            }\n            CHECKPOINT_RESTORE(RBREAK_TAG_RETURN_TOPLEVEL) {\n              c = mrb->c;\n            }\n            CHECKPOINT_MAIN(RBREAK_TAG_RETURN_TOPLEVEL) {\n              UNWIND_ENSURE(mrb, ci, pc, RBREAK_TAG_RETURN_TOPLEVEL, proc, v);\n            }\n            CHECKPOINT_END(RBREAK_TAG_RETURN_TOPLEVEL);\n            /* automatic yield at the end */\n            c->status = MRB_FIBER_TERMINATED;\n            mrb->c = c->prev;\n            mrb->c->status = MRB_FIBER_RUNNING;\n            c->prev = NULL;\n            if (c->vmexec) {\n              mrb_gc_arena_restore(mrb, ai);\n              c->vmexec = FALSE;\n              mrb->jmp = prev_jmp;\n              return v;\n            }\n            ci = mrb->c->ci;\n          }\n          CHECKPOINT_RESTORE(RBREAK_TAG_RETURN) {\n            /* do nothing */\n          }\n          CHECKPOINT_MAIN(RBREAK_TAG_RETURN) {\n            UNWIND_ENSURE(mrb, ci, pc, RBREAK_TAG_RETURN, proc, v);\n          }\n          CHECKPOINT_END(RBREAK_TAG_RETURN);\n          mrb->exc = NULL; /* clear break object */\n          break;\n        case OP_R_BREAK:\n          if (MRB_PROC_STRICT_P(proc)) goto NORMAL_RETURN;\n          if (MRB_PROC_ORPHAN_P(proc)) {\n            mrb_value exc;\n\n          L_BREAK_ERROR:\n            exc = mrb_exc_new_lit(mrb, E_LOCALJUMP_ERROR,\n                                      \"break from proc-closure\");\n            mrb_exc_set(mrb, exc);\n            goto L_RAISE;\n          }\n          if (!MRB_PROC_ENV_P(proc) || !MRB_ENV_ONSTACK_P(MRB_PROC_ENV(proc))) {\n            goto L_BREAK_ERROR;\n          }\n          else {\n            struct REnv *e = MRB_PROC_ENV(proc);\n\n            if (e->cxt != mrb->c) {\n              goto L_BREAK_ERROR;\n            }\n          }\n          CHECKPOINT_RESTORE(RBREAK_TAG_BREAK) {\n            /* do nothing */\n          }\n          CHECKPOINT_MAIN(RBREAK_TAG_BREAK) {\n            UNWIND_ENSURE(mrb, ci, pc, RBREAK_TAG_BREAK, proc, v);\n          }\n          CHECKPOINT_END(RBREAK_TAG_BREAK);\n          /* break from fiber block */\n          if (ci == mrb->c->cibase && ci->pc) {\n            struct mrb_context *c = mrb->c;\n\n            mrb->c = c->prev;\n            c->prev = NULL;\n            ci = mrb->c->ci;\n          }\n          if (ci->cci > CINFO_NONE) {\n            ci = cipop(mrb);\n            mrb->exc = (struct RObject*)break_new(mrb, RBREAK_TAG_BREAK, proc, v);\n            mrb_gc_arena_restore(mrb, ai);\n            mrb->c->vmexec = FALSE;\n            mrb->jmp = prev_jmp;\n            MRB_THROW(prev_jmp);\n          }\n          if (FALSE) {\n            struct RBreak *brk;\n\n          L_BREAK:\n            brk = (struct RBreak*)mrb->exc;\n            proc = mrb_break_proc_get(brk);\n            v = mrb_break_value_get(brk);\n            ci = mrb->c->ci;\n\n            switch (mrb_break_tag_get(brk)) {\n#define DISPATCH_CHECKPOINTS(n, i) case n: goto CHECKPOINT_LABEL_MAKE(n);\n              RBREAK_TAG_FOREACH(DISPATCH_CHECKPOINTS)\n#undef DISPATCH_CHECKPOINTS\n              default:\n                mrb_assert(!\"wrong break tag\");\n            }\n          }\n          while (mrb->c->cibase < ci && ci[-1].proc != proc->upper) {\n            if (ci[-1].cci == CINFO_SKIP) {\n              goto L_BREAK_ERROR;\n            }\n            CHECKPOINT_RESTORE(RBREAK_TAG_BREAK_UPPER) {\n              /* do nothing */\n            }\n            CHECKPOINT_MAIN(RBREAK_TAG_BREAK_UPPER) {\n              UNWIND_ENSURE(mrb, ci, pc, RBREAK_TAG_BREAK_UPPER, proc, v);\n            }\n            CHECKPOINT_END(RBREAK_TAG_BREAK_UPPER);\n            ci = cipop(mrb);\n            pc = ci->pc;\n          }\n          CHECKPOINT_RESTORE(RBREAK_TAG_BREAK_INTARGET) {\n            /* do nothing */\n          }\n          CHECKPOINT_MAIN(RBREAK_TAG_BREAK_INTARGET) {\n            UNWIND_ENSURE(mrb, ci, pc, RBREAK_TAG_BREAK_INTARGET, proc, v);\n          }\n          CHECKPOINT_END(RBREAK_TAG_BREAK_INTARGET);\n          if (ci == mrb->c->cibase) {\n            goto L_BREAK_ERROR;\n          }\n          mrb->exc = NULL; /* clear break object */\n          break;\n        default:\n          /* cannot happen */\n          break;\n        }\n        mrb_assert(ci == mrb->c->ci);\n        mrb_assert(mrb->exc == NULL);\n\n        if (mrb->c->vmexec && !mrb_vm_ci_target_class(ci)) {\n          mrb_gc_arena_restore(mrb, ai);\n          mrb->c->vmexec = FALSE;\n          mrb->jmp = prev_jmp;\n          return v;\n        }\n        acc = ci->cci;\n        ci = cipop(mrb);\n        if (acc == CINFO_SKIP || acc == CINFO_DIRECT) {\n          mrb_gc_arena_restore(mrb, ai);\n          mrb->jmp = prev_jmp;\n          return v;\n        }\n        pc = ci->pc;\n        DEBUG(fprintf(stderr, \"from :%s\\n\", mrb_sym_name(mrb, ci->mid)));\n        proc = ci->proc;\n        irep = proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n\n        ci[1].stack[0] = v;\n        mrb_gc_arena_restore(mrb, ai);\n      }\n      JUMP;\n    }\n\n    CASE(OP_BLKPUSH, BS) {\n      int m1 = (b>>11)&0x3f;\n      int r  = (b>>10)&0x1;\n      int m2 = (b>>5)&0x1f;\n      int kd = (b>>4)&0x1;\n      int lv = (b>>0)&0xf;\n      mrb_value *stack;\n\n      if (lv == 0) stack = regs + 1;\n      else {\n        struct REnv *e = uvenv(mrb, lv-1);\n        if (!e || (!MRB_ENV_ONSTACK_P(e) && e->mid == 0) ||\n            MRB_ENV_LEN(e) <= m1+r+m2+1) {\n          localjump_error(mrb, LOCALJUMP_ERROR_YIELD);\n          goto L_RAISE;\n        }\n        stack = e->stack + 1;\n      }\n      if (mrb_nil_p(stack[m1+r+m2+kd])) {\n        localjump_error(mrb, LOCALJUMP_ERROR_YIELD);\n        goto L_RAISE;\n      }\n      regs[a] = stack[m1+r+m2+kd];\n      NEXT;\n    }\n\n#if !defined(MRB_USE_BIGINT) || defined(MRB_INT32)\n  L_INT_OVERFLOW:\n    {\n      mrb_value exc = mrb_exc_new_lit(mrb, E_RANGE_ERROR, \"integer overflow\");\n      mrb_exc_set(mrb, exc);\n    }\n    goto L_RAISE;\n#endif\n\n#define TYPES2(a,b) ((((uint16_t)(a))<<8)|(((uint16_t)(b))&0xff))\n#define OP_MATH(op_name)                                                    \\\n  /* need to check if op is overridden */                                   \\\n  switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {                  \\\n    OP_MATH_CASE_INTEGER(op_name);                                          \\\n    OP_MATH_CASE_FLOAT(op_name, integer, float);                            \\\n    OP_MATH_CASE_FLOAT(op_name, float,  integer);                           \\\n    OP_MATH_CASE_FLOAT(op_name, float,  float);                             \\\n    OP_MATH_CASE_STRING_##op_name();                                        \\\n    default:                                                                \\\n      mid = MRB_OPSYM(op_name);                                             \\\n      goto L_SEND_SYM;                                                      \\\n  }                                                                         \\\n  NEXT;\n#define OP_MATH_CASE_INTEGER(op_name)                                       \\\n  case TYPES2(MRB_TT_INTEGER, MRB_TT_INTEGER):                              \\\n    {                                                                       \\\n      mrb_int x = mrb_integer(regs[a]), y = mrb_integer(regs[a+1]), z;      \\\n      if (mrb_int_##op_name##_overflow(x, y, &z)) {                         \\\n        OP_MATH_OVERFLOW_INT(op_name,x,y);                                  \\\n      }                                                                     \\\n      else                                                                  \\\n        SET_INT_VALUE(mrb,regs[a], z);                                      \\\n    }                                                                       \\\n    break\n#ifdef MRB_NO_FLOAT\n#define OP_MATH_CASE_FLOAT(op_name, t1, t2) (void)0\n#else\n#define OP_MATH_CASE_FLOAT(op_name, t1, t2)                                     \\\n  case TYPES2(OP_MATH_TT_##t1, OP_MATH_TT_##t2):                                \\\n    {                                                                           \\\n      mrb_float z = mrb_##t1(regs[a]) OP_MATH_OP_##op_name mrb_##t2(regs[a+1]); \\\n      SET_FLOAT_VALUE(mrb, regs[a], z);                                         \\\n    }                                                                           \\\n    break\n#endif\n#ifdef MRB_USE_BIGINT\n#define OP_MATH_OVERFLOW_INT(op,x,y) regs[a] = mrb_bint_##op##_ii(mrb,x,y)\n#else\n#define OP_MATH_OVERFLOW_INT(op,x,y) goto L_INT_OVERFLOW\n#endif\n#define OP_MATH_CASE_STRING_add()                                           \\\n  case TYPES2(MRB_TT_STRING, MRB_TT_STRING):                                \\\n    regs[a] = mrb_str_plus(mrb, regs[a], regs[a+1]);                        \\\n    mrb_gc_arena_restore(mrb, ai);                                          \\\n    break\n#define OP_MATH_CASE_STRING_sub() (void)0\n#define OP_MATH_CASE_STRING_mul() (void)0\n#define OP_MATH_OP_add +\n#define OP_MATH_OP_sub -\n#define OP_MATH_OP_mul *\n#define OP_MATH_TT_integer MRB_TT_INTEGER\n#define OP_MATH_TT_float   MRB_TT_FLOAT\n\n    CASE(OP_ADD, B) {\n      OP_MATH(add);\n    }\n\n    CASE(OP_SUB, B) {\n      OP_MATH(sub);\n    }\n\n    CASE(OP_MUL, B) {\n      OP_MATH(mul);\n    }\n\n    CASE(OP_DIV, B) {\n#ifndef MRB_NO_FLOAT\n      mrb_float x, y, f;\n#endif\n\n      /* need to check if op is overridden */\n      switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\n      case TYPES2(MRB_TT_INTEGER,MRB_TT_INTEGER):\n        {\n          mrb_int x = mrb_integer(regs[a]);\n          mrb_int y = mrb_integer(regs[a+1]);\n          mrb_int div = mrb_div_int(mrb, x, y);\n          SET_INT_VALUE(mrb, regs[a], div);\n        }\n        NEXT;\n#ifndef MRB_NO_FLOAT\n      case TYPES2(MRB_TT_INTEGER,MRB_TT_FLOAT):\n        x = (mrb_float)mrb_integer(regs[a]);\n        y = mrb_float(regs[a+1]);\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_INTEGER):\n        x = mrb_float(regs[a]);\n        y = (mrb_float)mrb_integer(regs[a+1]);\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_FLOAT):\n        x = mrb_float(regs[a]);\n        y = mrb_float(regs[a+1]);\n        break;\n#endif\n      default:\n        mid = MRB_OPSYM(div);\n        goto L_SEND_SYM;\n      }\n\n#ifndef MRB_NO_FLOAT\n      f = mrb_div_float(x, y);\n      SET_FLOAT_VALUE(mrb, regs[a], f);\n#endif\n      NEXT;\n    }\n\n#define OP_MATHI(op_name)                                                   \\\n  /* need to check if op is overridden */                                   \\\n  switch (mrb_type(regs[a])) {                                              \\\n    OP_MATHI_CASE_INTEGER(op_name);                                         \\\n    OP_MATHI_CASE_FLOAT(op_name);                                           \\\n    default:                                                                \\\n      SET_INT_VALUE(mrb,regs[a+1], b);                                      \\\n      mid = MRB_OPSYM(op_name);                                             \\\n      goto L_SEND_SYM;                                                      \\\n  }                                                                         \\\n  NEXT;\n#define OP_MATHI_CASE_INTEGER(op_name)                                      \\\n  case MRB_TT_INTEGER:                                                      \\\n    {                                                                       \\\n      mrb_int x = mrb_integer(regs[a]), y = (mrb_int)b, z;                  \\\n      if (mrb_int_##op_name##_overflow(x, y, &z)) {                         \\\n        OP_MATH_OVERFLOW_INT(op_name,x,y);                                  \\\n      }                                                                     \\\n      else                                                                  \\\n        SET_INT_VALUE(mrb,regs[a], z);                                      \\\n    }                                                                       \\\n    break\n#ifdef MRB_NO_FLOAT\n#define OP_MATHI_CASE_FLOAT(op_name) (void)0\n#else\n#define OP_MATHI_CASE_FLOAT(op_name)                                        \\\n  case MRB_TT_FLOAT:                                                        \\\n    {                                                                       \\\n      mrb_float z = mrb_float(regs[a]) OP_MATH_OP_##op_name b;              \\\n      SET_FLOAT_VALUE(mrb, regs[a], z);                                     \\\n    }                                                                       \\\n    break\n#endif\n\n    CASE(OP_ADDI, BB) {\n      OP_MATHI(add);\n    }\n\n    CASE(OP_SUBI, BB) {\n      OP_MATHI(sub);\n    }\n\n#define OP_CMP_BODY(op,v1,v2) (v1(regs[a]) op v2(regs[a+1]))\n\n#ifdef MRB_NO_FLOAT\n#define OP_CMP(op,sym) do {\\\n  int result;\\\n  /* need to check if - is overridden */\\\n  switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\\\n  case TYPES2(MRB_TT_INTEGER,MRB_TT_INTEGER):\\\n    result = OP_CMP_BODY(op,mrb_fixnum,mrb_fixnum);\\\n    break;\\\n  default:\\\n    mid = MRB_OPSYM(sym);\\\n    goto L_SEND_SYM;\\\n  }\\\n  if (result) {\\\n    SET_TRUE_VALUE(regs[a]);\\\n  }\\\n  else {\\\n    SET_FALSE_VALUE(regs[a]);\\\n  }\\\n} while(0)\n#else\n#define OP_CMP(op, sym) do {\\\n  int result;\\\n  /* need to check if - is overridden */\\\n  switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\\\n  case TYPES2(MRB_TT_INTEGER,MRB_TT_INTEGER):\\\n    result = OP_CMP_BODY(op,mrb_fixnum,mrb_fixnum);\\\n    break;\\\n  case TYPES2(MRB_TT_INTEGER,MRB_TT_FLOAT):\\\n    result = OP_CMP_BODY(op,mrb_fixnum,mrb_float);\\\n    break;\\\n  case TYPES2(MRB_TT_FLOAT,MRB_TT_INTEGER):\\\n    result = OP_CMP_BODY(op,mrb_float,mrb_fixnum);\\\n    break;\\\n  case TYPES2(MRB_TT_FLOAT,MRB_TT_FLOAT):\\\n    result = OP_CMP_BODY(op,mrb_float,mrb_float);\\\n    break;\\\n  default:\\\n    mid = MRB_OPSYM(sym);\\\n    goto L_SEND_SYM;\\\n  }\\\n  if (result) {\\\n    SET_TRUE_VALUE(regs[a]);\\\n  }\\\n  else {\\\n    SET_FALSE_VALUE(regs[a]);\\\n  }\\\n} while(0)\n#endif\n\n    CASE(OP_EQ, B) {\n      if (mrb_obj_eq(mrb, regs[a], regs[a+1])) {\n        SET_TRUE_VALUE(regs[a]);\n      }\n      else {\n        OP_CMP(==,eq);\n      }\n      NEXT;\n    }\n\n    CASE(OP_LT, B) {\n      OP_CMP(<,lt);\n      NEXT;\n    }\n\n    CASE(OP_LE, B) {\n      OP_CMP(<=,le);\n      NEXT;\n    }\n\n    CASE(OP_GT, B) {\n      OP_CMP(>,gt);\n      NEXT;\n    }\n\n    CASE(OP_GE, B) {\n      OP_CMP(>=,ge);\n      NEXT;\n    }\n\n    CASE(OP_ARRAY, BB) {\n      regs[a] = mrb_ary_new_from_values(mrb, b, &regs[a]);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n    CASE(OP_ARRAY2, BBB) {\n      regs[a] = mrb_ary_new_from_values(mrb, c, &regs[b]);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_ARYCAT, B) {\n      mrb_value splat = mrb_ary_splat(mrb, regs[a+1]);\n      if (mrb_nil_p(regs[a])) {\n        regs[a] = splat;\n      }\n      else {\n        mrb_assert(mrb_array_p(regs[a]));\n        mrb_ary_concat(mrb, regs[a], splat);\n      }\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_ARYPUSH, BB) {\n      mrb_assert(mrb_array_p(regs[a]));\n      for (mrb_int i=0; i<b; i++) {\n        mrb_ary_push(mrb, regs[a], regs[a+i+1]);\n      }\n      NEXT;\n    }\n\n    CASE(OP_ARYDUP, B) {\n      mrb_value ary = regs[a];\n      if (mrb_array_p(ary)) {\n        ary = mrb_ary_new_from_values(mrb, RARRAY_LEN(ary), RARRAY_PTR(ary));\n      }\n      else {\n        ary = mrb_ary_new_from_values(mrb, 1, &ary);\n      }\n      regs[a] = ary;\n      NEXT;\n    }\n\n    CASE(OP_AREF, BBB) {\n      mrb_value v = regs[b];\n\n      if (!mrb_array_p(v)) {\n        if (c == 0) {\n          regs[a] = v;\n        }\n        else {\n          SET_NIL_VALUE(regs[a]);\n        }\n      }\n      else {\n        v = mrb_ary_ref(mrb, v, c);\n        regs[a] = v;\n      }\n      NEXT;\n    }\n\n    CASE(OP_ASET, BBB) {\n      mrb_assert(mrb_array_p(regs[a]));\n      mrb_ary_set(mrb, regs[b], c, regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_APOST, BBB) {\n      mrb_value v = regs[a];\n      int pre  = b;\n      int post = c;\n      struct RArray *ary;\n      int len, idx;\n\n      if (!mrb_array_p(v)) {\n        v = mrb_ary_new_from_values(mrb, 1, &regs[a]);\n      }\n      ary = mrb_ary_ptr(v);\n      len = (int)ARY_LEN(ary);\n      if (len > pre + post) {\n        v = mrb_ary_new_from_values(mrb, len - pre - post, ARY_PTR(ary)+pre);\n        regs[a++] = v;\n        while (post--) {\n          regs[a++] = ARY_PTR(ary)[len-post-1];\n        }\n      }\n      else {\n        v = mrb_ary_new_capa(mrb, 0);\n        regs[a++] = v;\n        for (idx=0; idx+pre<len; idx++) {\n          regs[a+idx] = ARY_PTR(ary)[pre+idx];\n        }\n        while (idx < post) {\n          SET_NIL_VALUE(regs[a+idx]);\n          idx++;\n        }\n      }\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_INTERN, B) {\n      mrb_assert(mrb_string_p(regs[a]));\n      mrb_sym sym = mrb_intern_str(mrb, regs[a]);\n      regs[a] = mrb_symbol_value(sym);\n      NEXT;\n    }\n\n    CASE(OP_SYMBOL, BB) {\n      size_t len;\n      mrb_sym sym;\n\n      mrb_assert((pool[b].tt&IREP_TT_NFLAG)==0);\n      len = pool[b].tt >> 2;\n      if (pool[b].tt & IREP_TT_SFLAG) {\n        sym = mrb_intern_static(mrb, pool[b].u.str, len);\n      }\n      else {\n        sym  = mrb_intern(mrb, pool[b].u.str, len);\n      }\n      regs[a] = mrb_symbol_value(sym);\n      NEXT;\n    }\n\n    CASE(OP_STRING, BB) {\n      mrb_int len;\n\n      mrb_assert((pool[b].tt&IREP_TT_NFLAG)==0);\n      len = pool[b].tt >> 2;\n      if (pool[b].tt & IREP_TT_SFLAG) {\n        regs[a] = mrb_str_new_static(mrb, pool[b].u.str, len);\n      }\n      else {\n        regs[a] = mrb_str_new(mrb, pool[b].u.str, len);\n      }\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_STRCAT, B) {\n      mrb_assert(mrb_string_p(regs[a]));\n      mrb_str_concat(mrb, regs[a], regs[a+1]);\n      NEXT;\n    }\n\n    CASE(OP_HASH, BB) {\n      mrb_value hash = mrb_hash_new_capa(mrb, b);\n      int i;\n      int lim = a+b*2;\n\n      for (i=a; i<lim; i+=2) {\n        mrb_hash_set(mrb, hash, regs[i], regs[i+1]);\n      }\n      regs[a] = hash;\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_HASHADD, BB) {\n      mrb_value hash;\n      int i;\n      int lim = a+b*2+1;\n\n      hash = regs[a];\n      mrb_ensure_hash_type(mrb, hash);\n      for (i=a+1; i<lim; i+=2) {\n        mrb_hash_set(mrb, hash, regs[i], regs[i+1]);\n      }\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n    CASE(OP_HASHCAT, B) {\n      mrb_value hash = regs[a];\n\n      mrb_assert(mrb_hash_p(hash));\n      mrb_hash_merge(mrb, hash, regs[a+1]);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_LAMBDA, BB)\n    c = OP_L_LAMBDA;\n    L_MAKE_LAMBDA:\n    {\n      struct RProc *p;\n      const mrb_irep *nirep = irep->reps[b];\n\n      if (c & OP_L_CAPTURE) {\n        p = mrb_closure_new(mrb, nirep);\n      }\n      else {\n        p = mrb_proc_new(mrb, nirep);\n        p->flags |= MRB_PROC_SCOPE;\n      }\n      if (c & OP_L_STRICT) p->flags |= MRB_PROC_STRICT;\n      regs[a] = mrb_obj_value(p);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n    CASE(OP_BLOCK, BB) {\n      c = OP_L_BLOCK;\n      goto L_MAKE_LAMBDA;\n    }\n    CASE(OP_METHOD, BB) {\n      c = OP_L_METHOD;\n      goto L_MAKE_LAMBDA;\n    }\n\n    CASE(OP_RANGE_INC, B) {\n      mrb_value v = mrb_range_new(mrb, regs[a], regs[a+1], FALSE);\n      regs[a] = v;\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_RANGE_EXC, B) {\n      mrb_value v = mrb_range_new(mrb, regs[a], regs[a+1], TRUE);\n      regs[a] = v;\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_OCLASS, B) {\n      regs[a] = mrb_obj_value(mrb->object_class);\n      NEXT;\n    }\n\n    CASE(OP_CLASS, BB) {\n      struct RClass *c = 0, *baseclass;\n      mrb_value base, super;\n      mrb_sym id = syms[b];\n\n      base = regs[a];\n      super = regs[a+1];\n      if (mrb_nil_p(base)) {\n        baseclass = MRB_PROC_TARGET_CLASS(mrb->c->ci->proc);\n        if (!baseclass) baseclass = mrb->object_class;\n        base = mrb_obj_value(baseclass);\n      }\n      c = mrb_vm_define_class(mrb, base, super, id);\n      regs[a] = mrb_obj_value(c);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_MODULE, BB) {\n      struct RClass *cls = 0, *baseclass;\n      mrb_value base;\n      mrb_sym id = syms[b];\n\n      base = regs[a];\n      if (mrb_nil_p(base)) {\n        baseclass = MRB_PROC_TARGET_CLASS(mrb->c->ci->proc);\n        if (!baseclass) baseclass = mrb->object_class;\n        base = mrb_obj_value(baseclass);\n      }\n      cls = mrb_vm_define_module(mrb, base, id);\n      regs[a] = mrb_obj_value(cls);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_EXEC, BB)\n    {\n      mrb_value recv = regs[a];\n      struct RProc *p;\n      const mrb_irep *nirep = irep->reps[b];\n\n      /* prepare closure */\n      p = mrb_proc_new(mrb, nirep);\n      p->c = NULL;\n      mrb_field_write_barrier(mrb, (struct RBasic*)p, (struct RBasic*)proc);\n      MRB_PROC_SET_TARGET_CLASS(p, mrb_class_ptr(recv));\n      p->flags |= MRB_PROC_SCOPE;\n\n      /* prepare call stack */\n      cipush(mrb, a, 0, mrb_class_ptr(recv), p, 0, 0);\n\n      irep = p->body.irep;\n      pool = irep->pool;\n      syms = irep->syms;\n      mrb_stack_extend(mrb, irep->nregs);\n      stack_clear(regs+1, irep->nregs-1);\n      pc = irep->iseq;\n      JUMP;\n    }\n\n    CASE(OP_DEF, BB) {\n      struct RClass *target = mrb_class_ptr(regs[a]);\n      struct RProc *p = mrb_proc_ptr(regs[a+1]);\n      mrb_method_t m;\n      mrb_sym mid = syms[b];\n\n      MRB_METHOD_FROM_PROC(m, p);\n      mrb_define_method_raw(mrb, target, mid, m);\n      mrb_method_added(mrb, target, mid);\n      mrb_gc_arena_restore(mrb, ai);\n      regs[a] = mrb_symbol_value(mid);\n      NEXT;\n    }\n\n    CASE(OP_SCLASS, B) {\n      regs[a] = mrb_singleton_class(mrb, regs[a]);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_TCLASS, B) {\n      struct RClass *target = check_target_class(mrb);\n      if (!target) goto L_RAISE;\n      regs[a] = mrb_obj_value(target);\n      NEXT;\n    }\n\n    CASE(OP_ALIAS, BB) {\n      struct RClass *target = check_target_class(mrb);\n\n      if (!target) goto L_RAISE;\n      mrb_alias_method(mrb, target, syms[a], syms[b]);\n      mrb_method_added(mrb, target, syms[a]);\n      NEXT;\n    }\n    CASE(OP_UNDEF, B) {\n      struct RClass *target = check_target_class(mrb);\n\n      if (!target) goto L_RAISE;\n      mrb_undef_method_id(mrb, target, syms[a]);\n      NEXT;\n    }\n\n    CASE(OP_DEBUG, Z) {\n      FETCH_BBB();\n#ifdef MRB_USE_DEBUG_HOOK\n      mrb->debug_op_hook(mrb, irep, pc, regs);\n#else\n#ifndef MRB_NO_STDIO\n      printf(\"OP_DEBUG %d %d %d\\n\", a, b, c);\n#else\n      abort();\n#endif\n#endif\n      NEXT;\n    }\n\n    CASE(OP_ERR, B) {\n      size_t len = pool[a].tt >> 2;\n      mrb_value exc;\n\n      mrb_assert((pool[a].tt&IREP_TT_NFLAG)==0);\n      exc = mrb_exc_new(mrb, E_LOCALJUMP_ERROR, pool[a].u.str, len);\n      mrb_exc_set(mrb, exc);\n      goto L_RAISE;\n    }\n\n    CASE(OP_EXT1, Z) {\n      insn = READ_B();\n      switch (insn) {\n#define OPCODE(insn,ops) case OP_ ## insn: FETCH_ ## ops ## _1(); mrb->c->ci->pc = pc; goto L_OP_ ## insn ## _BODY;\n#include \"mruby/ops.h\"\n#undef OPCODE\n      }\n      pc--;\n      NEXT;\n    }\n    CASE(OP_EXT2, Z) {\n      insn = READ_B();\n      switch (insn) {\n#define OPCODE(insn,ops) case OP_ ## insn: FETCH_ ## ops ## _2(); mrb->c->ci->pc = pc; goto L_OP_ ## insn ## _BODY;\n#include \"mruby/ops.h\"\n#undef OPCODE\n      }\n      pc--;\n      NEXT;\n    }\n    CASE(OP_EXT3, Z) {\n      uint8_t insn = READ_B();\n      switch (insn) {\n#define OPCODE(insn,ops) case OP_ ## insn: FETCH_ ## ops ## _3(); mrb->c->ci->pc = pc; goto L_OP_ ## insn ## _BODY;\n#include \"mruby/ops.h\"\n#undef OPCODE\n      }\n      pc--;\n      NEXT;\n    }\n\n    CASE(OP_STOP, Z) {\n      /*        stop VM */\n      CHECKPOINT_RESTORE(RBREAK_TAG_STOP) {\n        /* do nothing */\n      }\n      CHECKPOINT_MAIN(RBREAK_TAG_STOP) {\n        UNWIND_ENSURE(mrb, mrb->c->ci, pc, RBREAK_TAG_STOP, proc, mrb_nil_value());\n      }\n      CHECKPOINT_END(RBREAK_TAG_STOP);\n    L_STOP:\n      mrb->jmp = prev_jmp;\n      if (mrb->exc) {\n        mrb_assert(mrb->exc->tt == MRB_TT_EXCEPTION);\n        return mrb_obj_value(mrb->exc);\n      }\n      return regs[irep->nlocals];\n    }\n  }\n  END_DISPATCH;\n#undef regs\n  }\n  MRB_CATCH(&c_jmp) {\n    mrb_callinfo *ci = mrb->c->ci;\n    while (ci > mrb->c->cibase && ci->cci == CINFO_DIRECT) {\n      ci = cipop(mrb);\n    }\n    exc_catched = TRUE;\n    pc = ci->pc;\n    goto RETRY_TRY_BLOCK;\n  }\n  MRB_END_EXC(&c_jmp);\n}",
        "func_hash": 44658455618798852770197569753613577766,
        "file_name": "vm.c",
        "file_hash": 164058079299968555060167307813659313262,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2022-1427",
        "cve_desc": "Out-of-bounds Read in mrb_obj_is_kind_of in in GitHub repository mruby/mruby prior to 3.2. # Impact: Possible arbitrary code execution if being exploited.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-1427",
        "func_name": "mrb_vm_exec",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195692,
        "project": "FreeRTOS-Kernel",
        "commit_id": "47338393f1f79558f6144213409f09f81d7c4837",
        "project_url": "https://github.com/FreeRTOS/FreeRTOS-Kernel",
        "commit_url": "https://github.com/FreeRTOS/FreeRTOS-Kernel/commit/47338393f1f79558f6144213409f09f81d7c4837",
        "commit_message": "add assert for addition overflow on queue creation (#225)",
        "target": 1,
        "irrelevant": 1,
        "func_before": "    QueueHandle_t xQueueGenericCreate( const UBaseType_t uxQueueLength,\r\n                                       const UBaseType_t uxItemSize,\r\n                                       const uint8_t ucQueueType )\r\n    {\r\n        Queue_t * pxNewQueue;\r\n        size_t xQueueSizeInBytes;\r\n        uint8_t * pucQueueStorage;\r\n\r\n        configASSERT( uxQueueLength > ( UBaseType_t ) 0 );\r\n\r\n        /* Allocate enough space to hold the maximum number of items that\r\n         * can be in the queue at any time.  It is valid for uxItemSize to be\r\n         * zero in the case the queue is used as a semaphore. */\r\n        xQueueSizeInBytes = ( size_t ) ( uxQueueLength * uxItemSize ); /*lint !e961 MISRA exception as the casts are only redundant for some ports. */\r\n\r\n        /* Check for multiplication overflow. */\r\n        configASSERT( ( uxItemSize == 0 ) || ( uxQueueLength == ( xQueueSizeInBytes / uxItemSize ) ) );\r\n\r\n        /* Allocate the queue and storage area.  Justification for MISRA\r\n         * deviation as follows:  pvPortMalloc() always ensures returned memory\r\n         * blocks are aligned per the requirements of the MCU stack.  In this case\r\n         * pvPortMalloc() must return a pointer that is guaranteed to meet the\r\n         * alignment requirements of the Queue_t structure - which in this case\r\n         * is an int8_t *.  Therefore, whenever the stack alignment requirements\r\n         * are greater than or equal to the pointer to char requirements the cast\r\n         * is safe.  In other cases alignment requirements are not strict (one or\r\n         * two bytes). */\r\n        pxNewQueue = ( Queue_t * ) pvPortMalloc( sizeof( Queue_t ) + xQueueSizeInBytes ); /*lint !e9087 !e9079 see comment above. */\r\n\r\n        if( pxNewQueue != NULL )\r\n        {\r\n            /* Jump past the queue structure to find the location of the queue\r\n             * storage area. */\r\n            pucQueueStorage = ( uint8_t * ) pxNewQueue;\r\n            pucQueueStorage += sizeof( Queue_t ); /*lint !e9016 Pointer arithmetic allowed on char types, especially when it assists conveying intent. */\r\n\r\n            #if ( configSUPPORT_STATIC_ALLOCATION == 1 )\r\n                {\r\n                    /* Queues can be created either statically or dynamically, so\r\n                     * note this task was created dynamically in case it is later\r\n                     * deleted. */\r\n                    pxNewQueue->ucStaticallyAllocated = pdFALSE;\r\n                }\r\n            #endif /* configSUPPORT_STATIC_ALLOCATION */\r\n\r\n            prvInitialiseNewQueue( uxQueueLength, uxItemSize, pucQueueStorage, ucQueueType, pxNewQueue );\r\n        }\r\n        else\r\n        {\r\n            traceQUEUE_CREATE_FAILED( ucQueueType );\r\n            mtCOVERAGE_TEST_MARKER();\r\n        }\r\n\r\n        return pxNewQueue;\r\n    }\r",
        "func_hash": 278728915886701481135388633284092658774,
        "file_name": "queue.c",
        "file_hash": 44156660200315650828929819637760261927,
        "cwe": [
            "CWE-200"
        ],
        "cve": "CVE-2021-31571",
        "cve_desc": "The kernel in Amazon Web Services FreeRTOS before 10.4.3 has an integer overflow in queue.c for queue creation.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-31571",
        "func_name": "xQueueGenericCreate",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195720,
        "project": "mvfst",
        "commit_id": "a67083ff4b8dcbb7ee2839da6338032030d712b0",
        "project_url": "https://github.com/facebookincubator/mvfst",
        "commit_url": "https://github.com/facebookincubator/mvfst/commit/a67083ff4b8dcbb7ee2839da6338032030d712b0",
        "commit_message": "Close connection if we derive an extra 1-rtt write cipher\n\nSummary: Fixes CVE-2021-24029\n\nReviewed By: mjoras, lnicco\n\nDifferential Revision: D26613890\n\nfbshipit-source-id: 19bb2be2c731808144e1a074ece313fba11f1945",
        "target": 1,
        "irrelevant": 0,
        "func_before": "void updateHandshakeState(QuicServerConnectionState& conn) {\n  // Zero RTT read cipher is available after chlo is processed with the\n  // condition that early data attempt is accepted.\n  auto handshakeLayer = conn.serverHandshakeLayer;\n  auto zeroRttReadCipher = handshakeLayer->getZeroRttReadCipher();\n  auto zeroRttHeaderCipher = handshakeLayer->getZeroRttReadHeaderCipher();\n  // One RTT write cipher is available at Fizz layer after chlo is processed.\n  // However, the cipher is only exported to QUIC if early data attempt is\n  // accepted. Otherwise, the cipher will be available after cfin is\n  // processed.\n  auto oneRttWriteCipher = handshakeLayer->getOneRttWriteCipher();\n  // One RTT read cipher is available after cfin is processed.\n  auto oneRttReadCipher = handshakeLayer->getOneRttReadCipher();\n\n  auto oneRttWriteHeaderCipher = handshakeLayer->getOneRttWriteHeaderCipher();\n  auto oneRttReadHeaderCipher = handshakeLayer->getOneRttReadHeaderCipher();\n\n  if (zeroRttReadCipher) {\n    if (conn.qLogger) {\n      conn.qLogger->addTransportStateUpdate(kDerivedZeroRttReadCipher);\n    }\n    QUIC_TRACE(fst_trace, conn, \"derived 0-rtt read cipher\");\n    conn.readCodec->setZeroRttReadCipher(std::move(zeroRttReadCipher));\n  }\n  if (zeroRttHeaderCipher) {\n    conn.readCodec->setZeroRttHeaderCipher(std::move(zeroRttHeaderCipher));\n  }\n  if (oneRttWriteHeaderCipher) {\n    conn.oneRttWriteHeaderCipher = std::move(oneRttWriteHeaderCipher);\n  }\n  if (oneRttReadHeaderCipher) {\n    conn.readCodec->setOneRttHeaderCipher(std::move(oneRttReadHeaderCipher));\n  }\n\n  if (oneRttWriteCipher) {\n    if (conn.qLogger) {\n      conn.qLogger->addTransportStateUpdate(kDerivedOneRttWriteCipher);\n    }\n    QUIC_TRACE(fst_trace, conn, \"derived 1-rtt write cipher\");\n    CHECK(!conn.oneRttWriteCipher.get());\n    conn.oneRttWriteCipher = std::move(oneRttWriteCipher);\n\n    updatePacingOnKeyEstablished(conn);\n\n    // We negotiate the transport parameters whenever we have the 1-RTT write\n    // keys available.\n    auto clientParams = handshakeLayer->getClientTransportParams();\n    if (!clientParams) {\n      throw QuicTransportException(\n          \"No client transport params\",\n          TransportErrorCode::TRANSPORT_PARAMETER_ERROR);\n    }\n    processClientInitialParams(conn, std::move(*clientParams));\n  }\n  if (oneRttReadCipher) {\n    if (conn.qLogger) {\n      conn.qLogger->addTransportStateUpdate(kDerivedOneRttReadCipher);\n    }\n    QUIC_TRACE(fst_trace, conn, \"derived 1-rtt read cipher\");\n    // Clear limit because CFIN is received at this point\n    conn.writableBytesLimit = folly::none;\n    conn.readCodec->setOneRttReadCipher(std::move(oneRttReadCipher));\n  }\n  auto handshakeReadCipher = handshakeLayer->getHandshakeReadCipher();\n  auto handshakeReadHeaderCipher =\n      handshakeLayer->getHandshakeReadHeaderCipher();\n  if (handshakeReadCipher) {\n    CHECK(handshakeReadHeaderCipher);\n    conn.readCodec->setHandshakeReadCipher(std::move(handshakeReadCipher));\n    conn.readCodec->setHandshakeHeaderCipher(\n        std::move(handshakeReadHeaderCipher));\n  }\n  if (handshakeLayer->isHandshakeDone()) {\n    CHECK(conn.oneRttWriteCipher);\n    if (conn.version != QuicVersion::MVFST_D24 && !conn.sentHandshakeDone) {\n      sendSimpleFrame(conn, HandshakeDoneFrame());\n      conn.sentHandshakeDone = true;\n    }\n  }\n}",
        "func_hash": 43735419078414129480912957086830640484,
        "file_name": "ServerStateMachine.cpp",
        "file_hash": 9223824505720776904271246874049398430,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2021-24029",
        "cve_desc": "A packet of death scenario is possible in mvfst via a specially crafted message during a QUIC session, which causes a crash via a failed assertion. Per QUIC specification, this particular message should be treated as a connection error. This issue affects mvfst versions prior to commit a67083ff4b8dcbb7ee2839da6338032030d712b0 and proxygen versions prior to v2021.03.15.00.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-24029",
        "func_name": "updateHandshakeState",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195740,
        "project": "libjpeg",
        "commit_id": "4746b577931e926a49e50de9720a4946de3069a7",
        "project_url": "https://github.com/thorfdbg/libjpeg",
        "commit_url": "https://github.com/thorfdbg/libjpeg/commit/4746b577931e926a49e50de9720a4946de3069a7",
        "commit_message": "Fixed handling of empty JPEG-LS scans.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "bool SampleInterleavedLSScan::ParseMCU(void)\n{\n#if ACCUSOFT_CODE\n  int lines             = m_ulRemaining[0]; // total number of MCU lines processed.\n  UBYTE preshift        = m_ucLowBit + FractionalColorBitsOf();\n  struct Line *line[4];\n  UBYTE cx;\n\n  //\n  // If a DNL marker is present, the number of remaining lines is zero. Fix it.\n  if (m_pFrame->HeightOf() == 0) {\n    assert(lines == 0);\n    lines = 8;\n  }\n  //\n  // A \"MCU\" in respect to the code organization is eight lines.\n  if (lines > 8) {\n    lines = 8;\n  }\n  if (m_pFrame->HeightOf() > 0)\n    m_ulRemaining[0] -= lines;\n  assert(lines > 0);\n  assert(m_ucCount < 4);\n\n  //\n  // Fill the line pointers.\n  for(cx = 0;cx < m_ucCount;cx++) {\n    line[cx] = CurrentLine(cx);\n  }\n\n  // Loop over lines and columns\n  do {\n    LONG length = m_ulWidth[0];\n    LONG *lp[4];\n\n    // Get the line pointers and initialize the internal backup lines.\n    for(cx = 0;cx < m_ucCount;cx++) {\n      lp[cx] = line[cx]->m_pData;\n      StartLine(cx);\n    }\n\n    if (BeginReadMCU(m_Stream.ByteStreamOf())) { \n      // No error handling strategy. No RST in scans. Bummer!\n      do {\n        LONG a[4],b[4],c[4],d[4]; // neighbouring values.\n        LONG d1[4],d2[4],d3[4];   // local gradients.\n        bool isrun = true;\n      \n        for(cx = 0;cx < m_ucCount;cx++) {\n          GetContext(cx,a[cx],b[cx],c[cx],d[cx]);\n\n          d1[cx]  = d[cx] - b[cx];    // compute local gradients\n          d2[cx]  = b[cx] - c[cx];\n          d3[cx]  = c[cx] - a[cx];\n\n          //\n          // Run mode only if the run condition is met for all components\n          if (isrun && !isRunMode(d1[cx],d2[cx],d3[cx]))\n            isrun = false;\n        }\n        \n        if (isrun) {\n          LONG run = DecodeRun(length,m_lRunIndex[0]);\n          //\n          // Now fill the data.\n          while(run) {\n            // Update so that the next process gets the correct value.\n            // There is one sample per component.\n            for(cx = 0;cx < m_ucCount;cx++) {\n              UpdateContext(cx,a[cx]);\n              // And insert the value into the target line as well.\n              *lp[cx]++ = a[cx] << preshift;\n            }\n            run--,length--;\n            // As long as there are pixels on the line.\n          }\n          //\n          // More data on the line? I.e. the run did not cover the full m_lJ samples?\n          // Now decode the run interruption sample. The rtype is here always zero.\n          if (length) {\n            bool negative; // the sign variable\n            LONG errval;   // the prediction error\n            LONG merr;     // the mapped error (symbol)\n            LONG rx;       // the reconstructed value\n            UBYTE k;       // golomb parameter\n            //\n            // Decode the interrupting pixels.\n            for(cx = 0;cx < m_ucCount;cx++) {\n              // Get the neighbourhood.\n              GetContext(cx,a[cx],b[cx],c[cx],d[cx]);\n              // The prediction mode is always false, but the sign information\n              // is required.\n              negative = a[cx] > b[cx];\n              // Get the golomb parameter for run interruption coding.\n              k       = GolombParameter(false);\n              // Golomb-decode the error symbol. It is always using the common\n              // run index.\n              merr    = GolombDecode(k,m_lLimit - m_lJ[m_lRunIndex[0]] - 1);\n              // Inverse the error mapping procedure.\n              errval  = InverseErrorMapping(merr,ErrorMappingOffset(false,merr != 0,k));\n              // Compute the reconstructed value.\n              rx      = Reconstruct(negative,b[cx],errval);\n              // Update so that the next process gets the correct value.\n              UpdateContext(cx,rx);\n              // Fill in the value into the line\n              *lp[cx]++ = rx << preshift;\n              // Update the variables of the run mode.\n              UpdateState(false,errval);\n            }\n            // Update the run index now. This is not part of\n            // EncodeRun because the non-reduced run-index is\n            // required for the golomb coder length limit. \n            if (m_lRunIndex[0] > 0)\n              m_lRunIndex[0]--;\n          } else break; // end of line.\n        } else {\n          UWORD ctxt;\n          bool  negative; // the sign variable.\n          LONG  px;       // the predicted variable.\n          LONG  rx;       // the reconstructed value.\n          LONG  errval;   // the error value.\n          LONG  merr;     // the mapped error value.\n          UBYTE k;        // the Golomb parameter.\n          //\n          for(cx = 0;cx < m_ucCount;cx++) {\n            // Quantize the gradients.\n            d1[cx]  = QuantizedGradient(d1[cx]);\n            d2[cx]  = QuantizedGradient(d2[cx]);\n            d3[cx]  = QuantizedGradient(d3[cx]);\n            // Compute the context.\n            ctxt    = Context(negative,d1[cx],d2[cx],d3[cx]); \n            // Compute the predicted value.\n            px      = Predict(a[cx],b[cx],c[cx]);\n            // Correct the prediction.\n            px      = CorrectPrediction(ctxt,negative,px);\n            // Compute the golomb parameter k from the context.\n            k       = GolombParameter(ctxt);\n            // Decode the error symbol.\n            merr    = GolombDecode(k,m_lLimit);\n            // Inverse the error symbol into an error value.\n            errval  = InverseErrorMapping(merr,ErrorMappingOffset(ctxt,k));\n            // Update the variables.\n            UpdateState(ctxt,errval);\n            // Compute the reconstructed value.\n            rx      = Reconstruct(negative,px,errval);\n            // Update so that the next process gets the correct value.\n            UpdateContext(cx,rx);\n            // And insert the value into the target line as well.\n            *lp[cx]++ = rx << preshift;\n          }\n        }\n      } while(--length);\n    } // No error handling here.\n    //\n    // Advance the line pointers.\n    for(cx = 0;cx < m_ucCount;cx++) {\n      EndLine(cx);\n      line[cx] = line[cx]->m_pNext;\n    }\n    //\n  } while(--lines);\n  //\n  // If this is the last line, gobble up all the\n  // bits from bitstuffing the last byte may have left.\n  // As SkipStuffing is idempotent, we can also do that\n  // all the time.\n  m_Stream.SkipStuffing();\n#endif  \n  return false;\n}",
        "func_hash": 262161649015079801638874313151941212550,
        "file_name": "sampleinterleavedlsscan.cpp",
        "file_hash": null,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2022-32978",
        "cve_desc": "There is an assertion failure in SingleComponentLSScan::ParseMCU in singlecomponentlsscan.cpp in libjpeg before 1.64 via an empty JPEG-LS scan.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-32978",
        "func_name": "SampleInterleavedLSScan::ParseMCU",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195741,
        "project": "libjpeg",
        "commit_id": "4746b577931e926a49e50de9720a4946de3069a7",
        "project_url": "https://github.com/thorfdbg/libjpeg",
        "commit_url": "https://github.com/thorfdbg/libjpeg/commit/4746b577931e926a49e50de9720a4946de3069a7",
        "commit_message": "Fixed handling of empty JPEG-LS scans.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "bool SingleComponentLSScan::ParseMCU(void)\n{ \n#if ACCUSOFT_CODE\n  int lines             = m_ulRemaining[0]; // total number of MCU lines processed.\n  UBYTE preshift        = m_ucLowBit + FractionalColorBitsOf();\n  struct Line *line     = CurrentLine(0);\n  \n  //\n  // If a DNL marker is present, the number of remaining lines is zero. Fix it.\n  if (m_pFrame->HeightOf() == 0) {\n    assert(lines == 0);\n    lines = 8;\n  }\n\n  assert(m_ucCount == 1);\n\n  //\n  // A \"MCU\" in respect to the code organization is eight lines.\n  if (lines > 8) {\n    lines = 8;\n  }\n  if (m_pFrame->HeightOf() > 0)\n    m_ulRemaining[0] -= lines;\n  \n  assert(lines > 0);\n\n  // Loop over lines and columns\n  do {\n    LONG length = m_ulWidth[0];\n    LONG *lp    = line->m_pData;\n\n#ifdef DEBUG_LS\n    int xpos    = 0;\n    static int linenumber = 0;\n    printf(\"\\n%4d : \",++linenumber);\n#endif\n     \n    StartLine(0);\n    if (BeginReadMCU(m_Stream.ByteStreamOf())) { // No error handling strategy. No RST in scans. Bummer!\n      do {\n        LONG a,b,c,d;   // neighbouring values.\n        LONG d1,d2,d3;  // local gradients.\n      \n        GetContext(0,a,b,c,d);\n        d1  = d - b;    // compute local gradients\n        d2  = b - c;\n        d3  = c - a;\n        \n        if (isRunMode(d1,d2,d3)) {\n          LONG run = DecodeRun(length,m_lRunIndex[0]);\n          //\n          // Now fill the data.\n          while(run) {\n            // Update so that the next process gets the correct value.\n            UpdateContext(0,a);\n            // And insert the value into the target line as well.\n            *lp++ = a << preshift;\n#ifdef DEBUG_LS\n            printf(\"%4d:<%2x> \",xpos++,a);\n#endif\n            run--,length--;\n            // As long as there are pixels on the line.\n          }\n          //\n          // More data on the line? I.e. the run did not cover the full m_lJ samples?\n          // Now decode the run interruption sample.\n          if (length) {\n            bool negative; // the sign variable\n            bool rtype;    // run interruption type\n            LONG errval;   // the prediction error\n            LONG merr;     // the mapped error (symbol)\n            LONG rx;       // the reconstructed value\n            UBYTE k;       // golomb parameter\n            // Get the neighbourhood.\n            GetContext(0,a,b,c,d);\n            // Get the prediction mode.\n            rtype  = InterruptedPredictionMode(negative,a,b);\n            // Get the golomb parameter for run interruption coding.\n            k      = GolombParameter(rtype);\n            // Golomb-decode the error symbol.\n            merr   = GolombDecode(k,m_lLimit - m_lJ[m_lRunIndex[0]] - 1);\n            // Inverse the error mapping procedure.\n            errval = InverseErrorMapping(merr + rtype,ErrorMappingOffset(rtype,rtype || merr,k));\n            // Compute the reconstructed value.\n            rx     = Reconstruct(negative,rtype?a:b,errval);\n            // Update so that the next process gets the correct value.\n            UpdateContext(0,rx);\n            // Fill in the value into the line\n            *lp    = rx << preshift;\n#ifdef DEBUG_LS\n            printf(\"%4d:<%2x> \",xpos++,*lp);\n#endif\n            // Update the variables of the run mode.\n            UpdateState(rtype,errval);\n            // Update the run index now. This is not part of\n            // EncodeRun because the non-reduced run-index is\n            // required for the golomb coder length limit. \n            if (m_lRunIndex[0] > 0)\n              m_lRunIndex[0]--;\n          } else break; // end of line.\n        } else {\n          UWORD ctxt;\n          bool  negative; // the sign variable.\n          LONG  px;       // the predicted variable.\n          LONG  rx;       // the reconstructed value.\n          LONG  errval;   // the error value.\n          LONG  merr;     // the mapped error value.\n          UBYTE k;        // the Golomb parameter.\n          // Quantize the gradients.\n          d1     = QuantizedGradient(d1);\n          d2     = QuantizedGradient(d2);\n          d3     = QuantizedGradient(d3);\n          // Compute the context.\n          ctxt   = Context(negative,d1,d2,d3); \n          // Compute the predicted value.\n          px     = Predict(a,b,c);\n          // Correct the prediction.\n          px     = CorrectPrediction(ctxt,negative,px);\n          // Compute the golomb parameter k from the context.\n          k      = GolombParameter(ctxt);\n          // Decode the error symbol.\n          merr   = GolombDecode(k,m_lLimit);\n          // Inverse the error symbol into an error value.\n          errval = InverseErrorMapping(merr,ErrorMappingOffset(ctxt,k));\n          // Update the variables.\n          UpdateState(ctxt,errval);\n          // Compute the reconstructed value.\n          rx     = Reconstruct(negative,px,errval);\n          // Update so that the next process gets the correct value.\n          UpdateContext(0,rx);\n          // And insert the value into the target line as well.\n          *lp    = rx << preshift;\n#ifdef DEBUG_LS\n          printf(\"%4d:<%2x> \",xpos++,*lp);\n#endif\n        }\n      } while(++lp,--length);\n    } // No error handling here.\n    EndLine(0);\n    line = line->m_pNext;\n  } while(--lines); \n  //\n  // If this is the last line, gobble up all the\n  // bits from bitstuffing the last byte may have left.\n  // As SkipStuffing is idempotent, we can also do that\n  // all the time.\n  m_Stream.SkipStuffing();\n#endif  \n  return false;\n}",
        "func_hash": 62606079555374024593923514521759457355,
        "file_name": "singlecomponentlsscan.cpp",
        "file_hash": null,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2022-32978",
        "cve_desc": "There is an assertion failure in SingleComponentLSScan::ParseMCU in singlecomponentlsscan.cpp in libjpeg before 1.64 via an empty JPEG-LS scan.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-32978",
        "func_name": "SingleComponentLSScan::ParseMCU",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195742,
        "project": "gpac",
        "commit_id": "37592ad86c6ca934d34740012213e467acc4a3b0",
        "project_url": "https://github.com/gpac/gpac",
        "commit_url": "https://github.com/gpac/gpac/commit/37592ad86c6ca934d34740012213e467acc4a3b0",
        "commit_message": "fixed #2163",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static GF_Err gf_isom_parse_movie_boxes_internal(GF_ISOFile *mov, u32 *boxType, u64 *bytesMissing, Bool progressive_mode)\n{\n\tGF_Box *a;\n\tu64 totSize, mdat_end=0;\n\tGF_Err e = GF_OK;\n\n#ifndef\tGPAC_DISABLE_ISOM_FRAGMENTS\n\tif (mov->single_moof_mode && mov->single_moof_state == 2) {\n\t\treturn e;\n\t}\n\n\t/*restart from where we stopped last*/\n\ttotSize = mov->current_top_box_start;\n\tif (mov->bytes_removed) {\n\t\tassert(totSize >= mov->bytes_removed);\n\t\ttotSize -= mov->bytes_removed;\n\t}\n\tgf_bs_seek(mov->movieFileMap->bs, totSize);\n#endif\n\n\n\t/*while we have some data, parse our boxes*/\n\twhile (gf_bs_available(mov->movieFileMap->bs)) {\n\t\t*bytesMissing = 0;\n#ifndef\tGPAC_DISABLE_ISOM_FRAGMENTS\n\t\tmov->current_top_box_start = gf_bs_get_position(mov->movieFileMap->bs) + mov->bytes_removed;\n\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_CONTAINER, (\"[iso file] Parsing a top-level box at position %d\\n\", mov->current_top_box_start));\n#endif\n\n\t\te = gf_isom_parse_root_box(&a, mov->movieFileMap->bs, boxType, bytesMissing, progressive_mode);\n\n\t\tif (e >= 0) {\n\n\t\t} else if (e == GF_ISOM_INCOMPLETE_FILE) {\n\t\t\t/*our mdat is uncomplete, only valid for READ ONLY files...*/\n\t\t\tif (mov->openMode != GF_ISOM_OPEN_READ) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[iso file] Incomplete MDAT while file is not read-only\\n\"));\n\t\t\t\treturn GF_ISOM_INVALID_FILE;\n\t\t\t}\n\t\t\tif ((mov->openMode == GF_ISOM_OPEN_READ) && !progressive_mode) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[iso file] Incomplete file while reading for dump - aborting parsing\\n\"));\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\treturn e;\n\t\t} else {\n\t\t\treturn e;\n\t\t}\n\n\t\tswitch (a->type) {\n\t\t/*MOOV box*/\n\t\tcase GF_ISOM_BOX_TYPE_MOOV:\n\t\t\tif (mov->moov) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[iso file] Duplicate MOOV detected!\\n\"));\n\t\t\t\tgf_isom_box_del(a);\n\t\t\t\treturn GF_ISOM_INVALID_FILE;\n\t\t\t}\n\t\t\tmov->moov = (GF_MovieBox *)a;\n\t\t\tmov->original_moov_offset = mov->current_top_box_start;\n\t\t\t/*set our pointer to the movie*/\n\t\t\tmov->moov->mov = mov;\n#ifndef GPAC_DISABLE_ISOM_FRAGMENTS\n\t\t\tif (mov->moov->mvex) mov->moov->mvex->mov = mov;\n\n#ifdef GF_ENABLE_CTRN\n\t\t\tif (! (mov->FragmentsFlags & GF_ISOM_FRAG_READ_DEBUG)) {\n\t\t\t\tgf_isom_setup_traf_inheritance(mov);\n\t\t\t}\n#endif\n\n#endif\n\t\t\te = gf_list_add(mov->TopBoxes, a);\n\t\t\tif (e) return e;\n\n\t\t\ttotSize += a->size;\n\n            if (!mov->moov->mvhd) {\n                GF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[iso file] Missing MovieHeaderBox\\n\"));\n                return GF_ISOM_INVALID_FILE;\n            }\n\n            if (mov->meta) {\n\t\t\t\tgf_isom_meta_restore_items_ref(mov, mov->meta);\n\t\t\t}\n\n\t\t\t//dump senc info in dump mode\n\t\t\tif (mov->FragmentsFlags & GF_ISOM_FRAG_READ_DEBUG) {\n\t\t\t\tu32 k;\n\t\t\t\tfor (k=0; k<gf_list_count(mov->moov->trackList); k++) {\n\t\t\t\t\tGF_TrackBox *trak = (GF_TrackBox *)gf_list_get(mov->moov->trackList, k);\n\n\t\t\t\t\tif (trak->sample_encryption) {\n\t\t\t\t\t\te = senc_Parse(mov->movieFileMap->bs, trak, NULL, trak->sample_encryption);\n\t\t\t\t\t\tif (e) return e;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tu32 k;\n\t\t\t\tfor (k=0; k<gf_list_count(mov->moov->trackList); k++) {\n\t\t\t\t\tGF_TrackBox *trak = (GF_TrackBox *)gf_list_get(mov->moov->trackList, k);\n\t\t\t\t\tif (trak->Media->information->sampleTable->sampleGroups) {\n\t\t\t\t\t\tconvert_compact_sample_groups(trak->Media->information->sampleTable->child_boxes, trak->Media->information->sampleTable->sampleGroups);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n            if (mdat_end && mov->signal_frag_bounds && !(mov->FragmentsFlags & GF_ISOM_FRAG_READ_DEBUG) ) {\n                gf_isom_push_mdat_end(mov, mdat_end);\n                mdat_end=0;\n            }\n\t\t\tbreak;\n\n\t\t/*META box*/\n\t\tcase GF_ISOM_BOX_TYPE_META:\n\t\t\tif (mov->meta) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[iso file] Duplicate META detected!\\n\"));\n\t\t\t\tgf_isom_box_del(a);\n\t\t\t\treturn GF_ISOM_INVALID_FILE;\n\t\t\t}\n\t\t\tmov->meta = (GF_MetaBox *)a;\n\t\t\tmov->original_meta_offset = mov->current_top_box_start;\n\t\t\te = gf_list_add(mov->TopBoxes, a);\n\t\t\tif (e) {\n\t\t\t\treturn e;\n\t\t\t}\n\t\t\ttotSize += a->size;\n\t\t\tgf_isom_meta_restore_items_ref(mov, mov->meta);\n\t\t\tbreak;\n\n\t\t/*we only keep the MDAT in READ for dump purposes*/\n\t\tcase GF_ISOM_BOX_TYPE_MDAT:\n\t\t\tif (!mov->first_data_toplevel_offset) {\n\t\t\t\tmov->first_data_toplevel_offset = mov->current_top_box_start;\n\t\t\t\tmov->first_data_toplevel_size = a->size;\n\t\t\t}\n\t\t\ttotSize += a->size;\n\n#ifndef\tGPAC_DISABLE_ISOM_FRAGMENTS\n\t\t\tif (mov->emsgs) {\n\t\t\t\tgf_isom_box_array_del(mov->emsgs);\n\t\t\t\tmov->emsgs = NULL;\n\t\t\t}\n#endif\n\n\t\t\tif (mov->openMode == GF_ISOM_OPEN_READ) {\n\t\t\t\tif (!mov->mdat) {\n\t\t\t\t\tmov->mdat = (GF_MediaDataBox *) a;\n\t\t\t\t\te = gf_list_add(mov->TopBoxes, mov->mdat);\n\t\t\t\t\tif (e) {\n\t\t\t\t\t\treturn e;\n\t\t\t\t\t}\n\t\t\t\t}\n#ifndef\tGPAC_DISABLE_ISOM_FRAGMENTS\n\t\t\t\telse if (mov->FragmentsFlags & GF_ISOM_FRAG_READ_DEBUG) gf_list_add(mov->TopBoxes, a);\n#endif\n\t\t\t\telse gf_isom_box_del(a); //in other modes we don't care\n\n\n\t\t\t\tif (mov->signal_frag_bounds && !(mov->FragmentsFlags & GF_ISOM_FRAG_READ_DEBUG) ) {\n                    mdat_end = gf_bs_get_position(mov->movieFileMap->bs);\n                    if (mov->moov) {\n                        gf_isom_push_mdat_end(mov, mdat_end);\n                        mdat_end=0;\n                    }\n\t\t\t\t}\n\t\t\t}\n\t\t\t/*if we don't have any MDAT yet, create one (edit-write mode)\n\t\t\tWe only work with one mdat, but we're puting it at the place\n\t\t\tof the first mdat found when opening a file for editing*/\n\t\t\telse if (!mov->mdat && (mov->openMode != GF_ISOM_OPEN_READ) && (mov->openMode != GF_ISOM_OPEN_KEEP_FRAGMENTS)) {\n\t\t\t\tgf_isom_box_del(a);\n\t\t\t\tmov->mdat = (GF_MediaDataBox *) gf_isom_box_new(GF_ISOM_BOX_TYPE_MDAT);\n\t\t\t\tif (!mov->mdat) return GF_OUT_OF_MEM;\n\t\t\t\te = gf_list_add(mov->TopBoxes, mov->mdat);\n\t\t\t\tif (e) {\n\t\t\t\t\treturn e;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tgf_isom_box_del(a);\n\t\t\t}\n\t\t\tbreak;\n\t\tcase GF_ISOM_BOX_TYPE_FTYP:\n\t\t\t/*ONE AND ONLY ONE FTYP*/\n\t\t\tif (mov->brand) {\n\t\t\t\tgf_isom_box_del(a);\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[iso file] Duplicate 'ftyp' detected!\\n\"));\n\t\t\t\treturn GF_ISOM_INVALID_FILE;\n\t\t\t}\n\t\t\tmov->brand = (GF_FileTypeBox *)a;\n\t\t\ttotSize += a->size;\n\t\t\te = gf_list_add(mov->TopBoxes, a);\n\t\t\tif (e) return e;\n\t\t\tbreak;\n\n\t\tcase GF_ISOM_BOX_TYPE_OTYP:\n\t\t\t/*ONE AND ONLY ONE FTYP*/\n\t\t\tif (mov->otyp) {\n\t\t\t\tgf_isom_box_del(a);\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[iso file] Duplicate 'otyp' detected!\\n\"));\n\t\t\t\treturn GF_ISOM_INVALID_FILE;\n\t\t\t}\n\n\t\t\tif (mov->FragmentsFlags & GF_ISOM_FRAG_READ_DEBUG) {\n\t\t\t\tmov->otyp = (GF_Box *)a;\n\t\t\t\ttotSize += a->size;\n\t\t\t\te = gf_list_add(mov->TopBoxes, a);\n\t\t\t\tif (e) return e;\n\t\t\t} else {\n\t\t\t\tGF_FileTypeBox *brand = (GF_FileTypeBox *) gf_isom_box_find_child(a->child_boxes, GF_ISOM_BOX_TYPE_FTYP);\n\t\t\t\tif (brand) {\n\t\t\t\t\ts32 pos;\n\t\t\t\t\tgf_list_del_item(a->child_boxes, brand);\n\t\t\t\t\tpos = gf_list_del_item(mov->TopBoxes, mov->brand);\n\t\t\t\t\tgf_isom_box_del((GF_Box *) mov->brand);\n\t\t\t\t\tmov->brand = brand;\n\t\t\t\t\tif (pos<0) pos=0;\n\t\t\t\t\tgf_list_insert(mov->TopBoxes, brand, pos);\n\t\t\t\t}\n\t\t\t\tgf_isom_box_del(a);\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase GF_ISOM_BOX_TYPE_PDIN:\n\t\t\t/*ONE AND ONLY ONE PDIN*/\n\t\t\tif (mov->pdin) {\n\t\t\t\tgf_isom_box_del(a);\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[iso file] Duplicate 'pdin'' detected!\\n\"));\n\t\t\t\treturn GF_ISOM_INVALID_FILE;\n\t\t\t}\n\t\t\tmov->pdin = (GF_ProgressiveDownloadBox *) a;\n\t\t\ttotSize += a->size;\n\t\t\te = gf_list_add(mov->TopBoxes, a);\n\t\t\tif (e) return e;\n\t\t\tbreak;\n\n\n#ifndef\tGPAC_DISABLE_ISOM_FRAGMENTS\n\t\tcase GF_ISOM_BOX_TYPE_STYP:\n\t\t{\n\t\t\tu32 brand = ((GF_FileTypeBox *)a)->majorBrand;\n\t\t\tswitch (brand) {\n\t\t\tcase GF_ISOM_BRAND_SISX:\n\t\t\tcase GF_ISOM_BRAND_RISX:\n\t\t\tcase GF_ISOM_BRAND_SSSS:\n\t\t\t\tmov->is_index_segment = GF_TRUE;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\t/*fall-through*/\n\n\t\tcase GF_ISOM_BOX_TYPE_SIDX:\n\t\tcase GF_ISOM_BOX_TYPE_SSIX:\n\t\t\tif (mov->moov && !mov->first_data_toplevel_offset) {\n\t\t\t\tmov->first_data_toplevel_offset = mov->current_top_box_start;\n\t\t\t\tmov->first_data_toplevel_size = a->size;\n\t\t\t}\n\t\t\ttotSize += a->size;\n\t\t\tif (mov->FragmentsFlags & GF_ISOM_FRAG_READ_DEBUG) {\n\t\t\t\te = gf_list_add(mov->TopBoxes, a);\n\t\t\t\tif (e) return e;\n\t\t\t} else if (mov->signal_frag_bounds && !(mov->FragmentsFlags & GF_ISOM_FRAG_READ_DEBUG)  && (mov->openMode!=GF_ISOM_OPEN_KEEP_FRAGMENTS)\n\t\t\t) {\n\t\t\t\tif (a->type==GF_ISOM_BOX_TYPE_SIDX) {\n\t\t\t\t\tif (mov->root_sidx) gf_isom_box_del( (GF_Box *) mov->root_sidx);\n\t\t\t\t\tmov->root_sidx = (GF_SegmentIndexBox *) a;\n\t\t\t\t\tmov->sidx_start_offset = mov->current_top_box_start;\n\t\t\t\t\tmov->sidx_end_offset = gf_bs_get_position(mov->movieFileMap->bs);\n\n\t\t\t\t}\n\t\t\t\telse if (a->type==GF_ISOM_BOX_TYPE_STYP) {\n\t\t\t\t\tmov->styp_start_offset = mov->current_top_box_start;\n\n\t\t\t\t\tif (mov->seg_styp) gf_isom_box_del(mov->seg_styp);\n\t\t\t\t\tmov->seg_styp = a;\n\t\t\t\t} else if (a->type==GF_ISOM_BOX_TYPE_SSIX) {\n\t\t\t\t\tif (mov->seg_ssix) gf_isom_box_del(mov->seg_ssix);\n\t\t\t\t\tmov->seg_ssix = a;\n\t\t\t\t} else {\n\t\t\t\t\tgf_isom_box_del(a);\n\t\t\t\t}\n\t\t\t\tgf_isom_push_mdat_end(mov, mov->current_top_box_start);\n\t\t\t} else if (!mov->NextMoofNumber && (a->type==GF_ISOM_BOX_TYPE_SIDX)) {\n\t\t\t\tif (mov->main_sidx) gf_isom_box_del( (GF_Box *) mov->main_sidx);\n\t\t\t\tmov->main_sidx = (GF_SegmentIndexBox *) a;\n\t\t\t\tmov->main_sidx_end_pos = mov->current_top_box_start + a->size;\n\t\t\t} else {\n\t\t\t\tgf_isom_box_del(a);\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase GF_ISOM_BOX_TYPE_MOOF:\n\t\t\t//no support for inplace rewrite for fragmented files\n\t\t\tgf_isom_disable_inplace_rewrite(mov);\n\t\t\tif (!mov->moov) {\n\t\t\t\tGF_LOG(mov->moof ? GF_LOG_DEBUG : GF_LOG_WARNING, GF_LOG_CONTAINER, (\"[iso file] Movie fragment but no moov (yet) - possibly broken parsing!\\n\"));\n\t\t\t}\n\t\t\tif (mov->single_moof_mode) {\n\t\t\t\tmov->single_moof_state++;\n\t\t\t\tif (mov->single_moof_state > 1) {\n\t\t\t\t\tgf_isom_box_del(a);\n\t\t\t\t\treturn GF_OK;\n\t\t\t\t}\n\t\t\t}\n\t\t\t((GF_MovieFragmentBox *)a)->mov = mov;\n\n\t\t\ttotSize += a->size;\n\t\t\tmov->moof = (GF_MovieFragmentBox *) a;\n\n\t\t\t/*some smooth streaming streams contain a SDTP under the TRAF: this is incorrect, convert it*/\n\t\t\tFixTrackID(mov);\n\t\t\tif (! (mov->FragmentsFlags & GF_ISOM_FRAG_READ_DEBUG)) {\n\t\t\t\tFixSDTPInTRAF(mov->moof);\n\t\t\t} else {\n\t\t\t\tu32 k;\n\t\t\t\tfor (k=0; k<gf_list_count(mov->moof->TrackList); k++) {\n\t\t\t\t\tGF_TrackFragmentBox *traf = (GF_TrackFragmentBox *)gf_list_get(mov->moof->TrackList, k);\n\t\t\t\t\tif (traf->sampleGroups) {\n\t\t\t\t\t\tconvert_compact_sample_groups(traf->child_boxes, traf->sampleGroups);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t/*read & debug: store at root level*/\n\t\t\tif (mov->FragmentsFlags & GF_ISOM_FRAG_READ_DEBUG) {\n\t\t\t\tu32 k;\n\t\t\t\tgf_list_add(mov->TopBoxes, a);\n\t\t\t\t/*also update pointers to trex for debug*/\n\t\t\t\tif (mov->moov) {\n\t\t\t\t\tfor (k=0; k<gf_list_count(mov->moof->TrackList); k++) {\n\t\t\t\t\t\tGF_TrackFragmentBox *traf = gf_list_get(mov->moof->TrackList, k);\n\t\t\t\t\t\tif (traf->tfhd && mov->moov->mvex && mov->moov->mvex->TrackExList) {\n\t\t\t\t\t\t\tGF_TrackBox *trak = gf_isom_get_track_from_id(mov->moov, traf->tfhd->trackID);\n\t\t\t\t\t\t\tu32 j=0;\n\t\t\t\t\t\t\twhile ((traf->trex = (GF_TrackExtendsBox*)gf_list_enum(mov->moov->mvex->TrackExList, &j))) {\n\t\t\t\t\t\t\t\tif (traf->trex->trackID == traf->tfhd->trackID) {\n\t\t\t\t\t\t\t\t\tif (!traf->trex->track) traf->trex->track = trak;\n\t\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\ttraf->trex = NULL;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\t//we should only parse senc/psec when no saiz/saio is present, otherwise we fetch the info directly\n\t\t\t\t\t\tif (traf->trex && traf->tfhd && traf->trex->track && traf->sample_encryption) {\n\t\t\t\t\t\t\tGF_TrackBox *trak = GetTrackbyID(mov->moov, traf->tfhd->trackID);\n\t\t\t\t\t\t\tif (trak) {\n\t\t\t\t\t\t\t\ttrak->current_traf_stsd_idx = traf->tfhd->sample_desc_index ? traf->tfhd->sample_desc_index : traf->trex->def_sample_desc_index;\n\t\t\t\t\t\t\t\te = senc_Parse(mov->movieFileMap->bs, trak, traf, traf->sample_encryption);\n\t\t\t\t\t\t\t\tif (e) return e;\n\t\t\t\t\t\t\t\ttrak->current_traf_stsd_idx = 0;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tfor (k=0; k<gf_list_count(mov->moof->TrackList); k++) {\n\t\t\t\t\t\tGF_TrackFragmentBox *traf = gf_list_get(mov->moof->TrackList, k);\n\t\t\t\t\t\tif (traf->sample_encryption) {\n\t\t\t\t\t\t\te = senc_Parse(mov->movieFileMap->bs, NULL, traf, traf->sample_encryption);\n\t\t\t\t\t\t\tif (e) return e;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t}\n\t\t\t} else if (mov->openMode==GF_ISOM_OPEN_KEEP_FRAGMENTS) {\n\t\t\t\tmov->NextMoofNumber = mov->moof->mfhd->sequence_number+1;\n\t\t\t\tmov->moof = NULL;\n\t\t\t\tgf_isom_box_del(a);\n\t\t\t} else {\n\t\t\t\t/*merge all info*/\n\t\t\t\te = MergeFragment((GF_MovieFragmentBox *)a, mov);\n\t\t\t\tgf_isom_box_del(a);\n\t\t\t\tif (e) return e;\n\t\t\t}\n\n\t\t\t//done with moov\n\t\t\tif (mov->root_sidx) {\n\t\t\t\tgf_isom_box_del((GF_Box *) mov->root_sidx);\n\t\t\t\tmov->root_sidx = NULL;\n\t\t\t}\n\t\t\tif (mov->root_ssix) {\n\t\t\t\tgf_isom_box_del(mov->seg_ssix);\n\t\t\t\tmov->root_ssix = NULL;\n\t\t\t}\n\t\t\tif (mov->seg_styp) {\n\t\t\t\tgf_isom_box_del(mov->seg_styp);\n\t\t\t\tmov->seg_styp = NULL;\n\t\t\t}\n\t\t\tmov->sidx_start_offset = 0;\n\t\t\tmov->sidx_end_offset = 0;\n\t\t\tmov->styp_start_offset = 0;\n\t\t\tbreak;\n#endif\n\t\tcase GF_ISOM_BOX_TYPE_UNKNOWN:\n\t\t{\n\t\t\tGF_UnknownBox *box = (GF_UnknownBox*)a;\n\t\t\tif (box->original_4cc == GF_ISOM_BOX_TYPE_JP) {\n\t\t\t\tu8 *c = (u8 *) box->data;\n\t\t\t\tif ((box->dataSize==4) && (GF_4CC(c[0],c[1],c[2],c[3])==(u32)0x0D0A870A))\n\t\t\t\t\tmov->is_jp2 = 1;\n\t\t\t\tgf_isom_box_del(a);\n\t\t\t} else {\n\t\t\t\te = gf_list_add(mov->TopBoxes, a);\n\t\t\t\tif (e) return e;\n\t\t\t}\n\t\t}\n\t\tbreak;\n\n\t\tcase GF_ISOM_BOX_TYPE_PRFT:\n#ifndef GPAC_DISABLE_ISOM_FRAGMENTS\n\t\t\tif (!(mov->FragmentsFlags & GF_ISOM_FRAG_READ_DEBUG)) {\n\t\t\t\t//keep the last one read\n\t\t\t\tif (mov->last_producer_ref_time)\n\t\t\t\t\tgf_isom_box_del(a);\n\t\t\t\telse\n\t\t\t\t\tmov->last_producer_ref_time = (GF_ProducerReferenceTimeBox *)a;\n\t\t\t\tbreak;\n\t\t\t}\n#endif\n\t\t//fallthrough\n\t\tcase GF_ISOM_BOX_TYPE_EMSG:\n#ifndef GPAC_DISABLE_ISOM_FRAGMENTS\n\t\t\tif (! (mov->FragmentsFlags & GF_ISOM_FRAG_READ_DEBUG)) {\n\t\t\t\tif (!mov->emsgs) mov->emsgs = gf_list_new();\n\t\t\t\tgf_list_add(mov->emsgs, a);\n\t\t\t\tbreak;\n\t\t\t}\n#endif\n\t\tcase GF_ISOM_BOX_TYPE_MFRA:\n\t\tcase GF_ISOM_BOX_TYPE_MFRO:\n\t\t\t//only keep for dump mode, otherwise we ignore these boxes and we don't want to carry them over in non-fragmented file\n\t\t\tif (! (mov->FragmentsFlags & GF_ISOM_FRAG_READ_DEBUG)) {\n\t\t\t\ttotSize += a->size;\n\t\t\t\tgf_isom_box_del(a);\n\t\t\t\tbreak;\n\t\t\t}\n\t\tdefault:\n\t\t\ttotSize += a->size;\n\t\t\te = gf_list_add(mov->TopBoxes, a);\n\t\t\tif (e) return e;\n\t\t\tbreak;\n\t\t}\n\n#ifndef\tGPAC_DISABLE_ISOM_FRAGMENTS\n\t\t/*remember where we left, in case we append an entire number of movie fragments*/\n\t\tmov->current_top_box_start = gf_bs_get_position(mov->movieFileMap->bs) + mov->bytes_removed;\n#endif\n\t}\n\n\t/*we need at least moov or meta*/\n\tif (!mov->moov && !mov->meta\n#ifndef GPAC_DISABLE_ISOM_FRAGMENTS\n\t        && !mov->moof && !mov->is_index_segment\n#endif\n\t   ) {\n\t\treturn GF_ISOM_INCOMPLETE_FILE;\n\t}\n\t/*we MUST have movie header*/\n\tif (!gf_opts_get_bool(\"core\", \"no-check\")) {\n\t\tif (mov->moov && !mov->moov->mvhd) {\n\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[iso file] Missing MVHD in MOOV!\\n\"));\n\t\t\treturn GF_ISOM_INVALID_FILE;\n\t\t}\n\n\t\t/*we MUST have meta handler*/\n\t\tif (mov->meta && !mov->meta->handler) {\n\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[iso file] Missing handler in META!\\n\"));\n\t\t\treturn GF_ISOM_INVALID_FILE;\n\t\t}\n\t}\n\n#ifndef GPAC_DISABLE_ISOM_WRITE\n\n\tif (mov->moov) {\n\t\t/*set the default interleaving time*/\n\t\tmov->interleavingTime = mov->moov->mvhd->timeScale;\n\n#ifndef\tGPAC_DISABLE_ISOM_FRAGMENTS\n\t\t/*in edit mode with successfully loaded fragments, delete all fragment signaling since\n\t\tfile is no longer fragmented*/\n\t\tif ((mov->openMode > GF_ISOM_OPEN_READ) && (mov->openMode != GF_ISOM_OPEN_KEEP_FRAGMENTS) && mov->moov->mvex) {\n\t\t\tgf_isom_box_del_parent(&mov->moov->child_boxes, (GF_Box *)mov->moov->mvex);\n\t\t\tmov->moov->mvex = NULL;\n\t\t}\n#endif\n\n\t}\n\n\t//create a default mdat if none was found\n\tif (!mov->mdat && (mov->openMode != GF_ISOM_OPEN_READ) && (mov->openMode != GF_ISOM_OPEN_KEEP_FRAGMENTS)) {\n\t\tmov->mdat = (GF_MediaDataBox *) gf_isom_box_new(GF_ISOM_BOX_TYPE_MDAT);\n\t\tif (!mov->mdat) return GF_OUT_OF_MEM;\n\t\te = gf_list_add(mov->TopBoxes, mov->mdat);\n\t\tif (e) return e;\n\t}\n#endif /*GPAC_DISABLE_ISOM_WRITE*/\n\n\treturn GF_OK;\n}",
        "func_hash": 68912157747726016692935177449045975431,
        "file_name": "isom_intern.c",
        "file_hash": null,
        "cwe": [
            "CWE-476"
        ],
        "cve": "CVE-2022-29340",
        "cve_desc": "GPAC 2.1-DEV-rev87-g053aae8-master. has a Null Pointer Dereference vulnerability in gf_isom_parse_movie_boxes_internal due to improper return value handling of GF_SKIP_BOX, which causes a Denial of Service. This vulnerability was fixed in commit 37592ad.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-29340",
        "func_name": "gf_isom_parse_movie_boxes_internal",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195752,
        "project": "tensorflow",
        "commit_id": "02cc160e29d20631de3859c6653184e3f876b9d7",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/02cc160e29d20631de3859c6653184e3f876b9d7",
        "commit_message": "Prevent nullptr deref in SparseTensorSliceDataset\n\nThe arguments must determine a valid sparse tensor. This means that when indices are empty then the values must be empty too (and the reverse).\n\nAlso added test, by modifying existing test with empty sparse tensor to now run with an invalid sparse tensor input.\n\nPiperOrigin-RevId: 388562757\nChange-Id: Id8b54cd7c2316025b4f9a77292c8fb5344d17609",
        "target": 1,
        "irrelevant": 1,
        "func_before": "  void MakeDataset(OpKernelContext* ctx, DatasetBase** output) override {\n    // Create a new SparseTensorSliceDatasetOp::Dataset, insert it in\n    // the step container, and return it as the output.\n    const Tensor* indices;\n    OP_REQUIRES_OK(ctx, ctx->input(\"indices\", &indices));\n    const Tensor* values;\n    OP_REQUIRES_OK(ctx, ctx->input(\"values\", &values));\n    const Tensor* dense_shape;\n    OP_REQUIRES_OK(ctx, ctx->input(\"dense_shape\", &dense_shape));\n\n    OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(indices->shape()),\n                errors::InvalidArgument(\n                    \"Input indices should be a matrix but received shape \",\n                    indices->shape().DebugString()));\n    OP_REQUIRES(ctx, TensorShapeUtils::IsVector(values->shape()),\n                errors::InvalidArgument(\n                    \"Input values should be a vector but received shape \",\n                    indices->shape().DebugString()));\n    OP_REQUIRES(ctx, TensorShapeUtils::IsVector(dense_shape->shape()),\n                errors::InvalidArgument(\n                    \"Input shape should be a vector but received shape \",\n                    dense_shape->shape().DebugString()));\n\n    // We currently ensure that `sparse_tensor` is ordered in the\n    // batch dimension.\n    // TODO(mrry): Investigate ways to avoid this unconditional check\n    // if we can be sure that the sparse tensor was produced in an\n    // appropriate order (e.g. by `tf.parse_example()` or a Dataset\n    // that batches elements into rows of a SparseTensor).\n    int64_t previous_batch_index = -1;\n    for (int64_t i = 0; i < indices->dim_size(0); ++i) {\n      int64_t next_batch_index = indices->matrix<int64>()(i, 0);\n      OP_REQUIRES(\n          ctx, next_batch_index >= previous_batch_index,\n          errors::Unimplemented(\"The SparseTensor must be ordered in the batch \"\n                                \"dimension; handling arbitrarily ordered input \"\n                                \"is not currently supported.\"));\n      previous_batch_index = next_batch_index;\n    }\n    gtl::InlinedVector<int64, 8> std_order(dense_shape->NumElements(), 0);\n    sparse::SparseTensor tensor;\n    OP_REQUIRES_OK(\n        ctx, sparse::SparseTensor::Create(\n                 *indices, *values, TensorShape(dense_shape->vec<int64>()),\n                 std_order, &tensor));\n    *output = new Dataset<T>(ctx, std::move(tensor));\n  }",
        "func_hash": 111818826187244494245403789873500831419,
        "file_name": "sparse_tensor_slice_dataset_op.cc",
        "file_hash": 152047584060469134260687844063366554733,
        "cwe": [
            "CWE-476"
        ],
        "cve": "CVE-2021-37647",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. When a user does not supply arguments that determine a valid sparse tensor, `tf.raw_ops.SparseTensorSliceDataset` implementation can be made to dereference a null pointer. The [implementation](https://github.com/tensorflow/tensorflow/blob/8d72537c6abf5a44103b57b9c2e22c14f5f49698/tensorflow/core/kernels/data/sparse_tensor_slice_dataset_op.cc#L240-L251) has some argument validation but fails to consider the case when either `indices` or `values` are provided for an empty sparse tensor when the other is not. If `indices` is empty, then [code that performs validation](https://github.com/tensorflow/tensorflow/blob/8d72537c6abf5a44103b57b9c2e22c14f5f49698/tensorflow/core/kernels/data/sparse_tensor_slice_dataset_op.cc#L260-L261) (i.e., checking that the indices are monotonically increasing) results in a null pointer dereference. If `indices` as provided by the user is empty, then `indices` in the C++ code above is backed by an empty `std::vector`, hence calling `indices->dim_size(0)` results in null pointer dereferencing (same as calling `std::vector::at()` on an empty vector). We have patched the issue in GitHub commit 02cc160e29d20631de3859c6653184e3f876b9d7. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37647",
        "func_name": "MakeDataset",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195768,
        "project": "tensorflow",
        "commit_id": "8a84f7a2b5a2b27ecf88d25bad9ac777cd2f7992",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/8a84f7a2b5a2b27ecf88d25bad9ac777cd2f7992",
        "commit_message": "Ensure num_streams >= 0 in tf.raw_ops.BoostedTreesCreateQuantileStreamResource\n\nPiperOrigin-RevId: 387452765\nChange-Id: I9990c760e177fabca6a3b9b4612ceeaeeba51495",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext* context) override {\n    // Only create one, if one does not exist already. Report status for all\n    // other exceptions. If one already exists, it unrefs the new one.\n    // An epsilon value of zero could cause performance issues and is therefore,\n    // disallowed.\n    const Tensor* epsilon_t;\n    OP_REQUIRES_OK(context, context->input(kEpsilonName, &epsilon_t));\n    float epsilon = epsilon_t->scalar<float>()();\n    OP_REQUIRES(\n        context, epsilon > 0,\n        errors::InvalidArgument(\"An epsilon value of zero is not allowed.\"));\n\n    const Tensor* num_streams_t;\n    OP_REQUIRES_OK(context, context->input(kNumStreamsName, &num_streams_t));\n    int64_t num_streams = num_streams_t->scalar<int64>()();\n\n    auto result =\n        new QuantileStreamResource(epsilon, max_elements_, num_streams);\n    auto status = CreateResource(context, HandleFromInput(context, 0), result);\n    if (!status.ok() && status.code() != tensorflow::error::ALREADY_EXISTS) {\n      OP_REQUIRES(context, false, status);\n    }\n  }",
        "func_hash": 313445736659793184747687838118492710807,
        "file_name": "quantile_ops.cc",
        "file_hash": 107616464713850423069668018637690909159,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2021-37661",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions an attacker can cause a denial of service in `boosted_trees_create_quantile_stream_resource` by using negative arguments. The [implementation](https://github.com/tensorflow/tensorflow/blob/84d053187cb80d975ef2b9684d4b61981bca0c41/tensorflow/core/kernels/boosted_trees/quantile_ops.cc#L96) does not validate that `num_streams` only contains non-negative numbers. In turn, [this results in using this value to allocate memory](https://github.com/tensorflow/tensorflow/blob/84d053187cb80d975ef2b9684d4b61981bca0c41/tensorflow/core/kernels/boosted_trees/quantiles/quantile_stream_resource.h#L31-L40). However, `reserve` receives an unsigned integer so there is an implicit conversion from a negative value to a large positive unsigned. This results in a crash from the standard library. We have patched the issue in GitHub commit 8a84f7a2b5a2b27ecf88d25bad9ac777cd2f7992. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37661",
        "func_name": "Compute",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195800,
        "project": "deark",
        "commit_id": "62acb7753b0e3c0d3ab3c15057b0a65222313334",
        "project_url": "https://github.com/jsummers/deark",
        "commit_url": "https://github.com/jsummers/deark/commit/62acb7753b0e3c0d3ab3c15057b0a65222313334",
        "commit_message": "pict,macrsrc: Fixed a bug that could cause division by 0\n\nFound by F. \u00c7elik.",
        "target": 1,
        "irrelevant": 1,
        "func_before": "void fmtutil_macbitmap_read_pixmap_only_fields(deark *c, dbuf *f, struct fmtutil_macbitmap_info *bi,\n\ti64 pos)\n{\n\ti64 pixmap_version;\n\ti64 pack_size;\n\ti64 plane_bytes;\n\ti64 n;\n\n\tde_dbg(c, \"additional PixMap header fields, at %d\", (int)pos);\n\tde_dbg_indent(c, 1);\n\n\tpixmap_version = dbuf_getu16be(f, pos+0);\n\tde_dbg(c, \"pixmap version: %d\", (int)pixmap_version);\n\n\tbi->packing_type = dbuf_getu16be(f, pos+2);\n\tde_dbg(c, \"packing type: %d\", (int)bi->packing_type);\n\n\tpack_size = dbuf_getu32be(f, pos+4);\n\tde_dbg(c, \"pixel data length: %d\", (int)pack_size);\n\n\tbi->hdpi = pict_read_fixed(f, pos+8);\n\tbi->vdpi = pict_read_fixed(f, pos+12);\n\tde_dbg(c, \"dpi: %.2f\"DE_CHAR_TIMES\"%.2f\", bi->hdpi, bi->vdpi);\n\n\tbi->pixeltype = dbuf_getu16be(f, pos+16);\n\tbi->pixelsize = dbuf_getu16be(f, pos+18);\n\tbi->cmpcount = dbuf_getu16be(f, pos+20);\n\tbi->cmpsize = dbuf_getu16be(f, pos+22);\n\tde_dbg(c, \"pixel type=%d, bits/pixel=%d, components/pixel=%d, bits/comp=%d\",\n\t\t(int)bi->pixeltype, (int)bi->pixelsize, (int)bi->cmpcount, (int)bi->cmpsize);\n\n\tbi->pdwidth = (bi->rowbytes*8)/bi->pixelsize;\n\tif(bi->pdwidth < bi->npwidth) {\n\t\tbi->pdwidth = bi->npwidth;\n\t}\n\n\tplane_bytes = dbuf_getu32be(f, pos+24);\n\tde_dbg(c, \"plane bytes: %d\", (int)plane_bytes);\n\n\tbi->pmTable = (u32)dbuf_getu32be(f, pos+28);\n\tde_dbg(c, \"pmTable: 0x%08x\", (unsigned int)bi->pmTable);\n\n\tn = dbuf_getu32be(f, pos+32);\n\tde_dbg(c, \"pmReserved: 0x%08x\", (unsigned int)n);\n\n\tde_dbg_indent(c, -1);\n}",
        "func_hash": 203544519943268578056087775697493086183,
        "file_name": "fmtutil.c",
        "file_hash": 198892381443353894699781903058114971913,
        "cwe": [
            "CWE-369"
        ],
        "cve": "CVE-2021-28856",
        "cve_desc": "In Deark before v1.5.8, a specially crafted input file can cause a division by zero in (src/fmtutil.c) because of the value of pixelsize.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-28856",
        "func_name": "fmtutil_macbitmap_read_pixmap_only_fields",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195801,
        "project": "php-src",
        "commit_id": "0c8a2a2cd1056b7dc403eacb5d2c0eec6ce47c6f",
        "project_url": "https://github.com/php/php-src",
        "commit_url": "https://github.com/php/php-src/commit/0c8a2a2cd1056b7dc403eacb5d2c0eec6ce47c6f",
        "commit_message": "Fix for bug #72790 and bug #72799\n\n(cherry picked from commit a14fdb9746262549bbbb96abb87338bacd147e1b)\n\nConflicts:\n\text/wddx/wddx.c",
        "target": 1,
        "irrelevant": 0,
        "func_before": " */\nstatic void php_wddx_pop_element(void *user_data, const XML_Char *name)\n{\n\tst_entry \t\t\t*ent1, *ent2;\n\twddx_stack \t\t\t*stack = (wddx_stack *)user_data;\n\tHashTable \t\t\t*target_hash;\n\tzend_class_entry \t*pce;\n\tzval\t\t\t\tobj;\n\n/* OBJECTS_FIXME */\n\tif (stack->top == 0) {\n\t\treturn;\n\t}\n\n\tif (!strcmp((char *)name, EL_STRING) || !strcmp((char *)name, EL_NUMBER) ||\n\t\t!strcmp((char *)name, EL_BOOLEAN) || !strcmp((char *)name, EL_NULL) ||\n\t  \t!strcmp((char *)name, EL_ARRAY) || !strcmp((char *)name, EL_STRUCT) ||\n\t\t!strcmp((char *)name, EL_RECORDSET) || !strcmp((char *)name, EL_BINARY) ||\n\t\t!strcmp((char *)name, EL_DATETIME)) {\n\t\twddx_stack_top(stack, (void**)&ent1);\n\n\t\tif (Z_TYPE(ent1->data) == IS_UNDEF) {\n\t\t\tif (stack->top > 1) {\n\t\t\t\tstack->top--;\n\t\t\t} else {\n\t\t\t\tstack->done = 1;\n\t\t\t}\n\t\t\tefree(ent1);\n\t\t\treturn;\n\t\t}\n\n\t\tif (!strcmp((char *)name, EL_BINARY)) {\n\t\t\tzend_string *new_str = php_base64_decode(\n\t\t\t\t(unsigned char *)Z_STRVAL(ent1->data), Z_STRLEN(ent1->data));\n\t\t\tzval_ptr_dtor(&ent1->data);\n\t\t\tZVAL_STR(&ent1->data, new_str);\n\t\t}\n\n\t\t/* Call __wakeup() method on the object. */\n\t\tif (Z_TYPE(ent1->data) == IS_OBJECT) {\n\t\t\tzval fname, retval;\n\n\t\t\tZVAL_STRING(&fname, \"__wakeup\");\n\n\t\t\tcall_user_function_ex(NULL, &ent1->data, &fname, &retval, 0, 0, 0, NULL);\n\n\t\t\tzval_ptr_dtor(&fname);\n\t\t\tzval_ptr_dtor(&retval);\n\t\t}\n\n\t\tif (stack->top > 1) {\n\t\t\tstack->top--;\n\t\t\twddx_stack_top(stack, (void**)&ent2);\n\n\t\t\t/* if non-existent field */\n\t\t\tif (ent2->type == ST_FIELD && Z_ISUNDEF(ent2->data)) {\n\t\t\t\tzval_ptr_dtor(&ent1->data);\n\t\t\t\tefree(ent1);\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tif (Z_TYPE(ent2->data) == IS_ARRAY || Z_TYPE(ent2->data) == IS_OBJECT) {\n\t\t\t\ttarget_hash = HASH_OF(&ent2->data);\n\n\t\t\t\tif (ent1->varname) {\n\t\t\t\t\tif (!strcmp(ent1->varname, PHP_CLASS_NAME_VAR) &&\n\t\t\t\t\t\tZ_TYPE(ent1->data) == IS_STRING && Z_STRLEN(ent1->data) &&\n\t\t\t\t\t\tent2->type == ST_STRUCT && Z_TYPE(ent2->data) == IS_ARRAY) {\n\t\t\t\t\t\tzend_bool incomplete_class = 0;\n\n\t\t\t\t\t\tzend_str_tolower(Z_STRVAL(ent1->data), Z_STRLEN(ent1->data));\n\t\t\t\t\t\tzend_string_forget_hash_val(Z_STR(ent1->data));\n\t\t\t\t\t\tif ((pce = zend_hash_find_ptr(EG(class_table), Z_STR(ent1->data))) == NULL) {\n\t\t\t\t\t\t\tincomplete_class = 1;\n\t\t\t\t\t\t\tpce = PHP_IC_ENTRY;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t/* Initialize target object */\n\t\t\t\t\t\tobject_init_ex(&obj, pce);\n\n\t\t\t\t\t\t/* Merge current hashtable with object's default properties */\n\t\t\t\t\t\tzend_hash_merge(Z_OBJPROP(obj),\n\t\t\t\t\t\t\t\t\t\tZ_ARRVAL(ent2->data),\n\t\t\t\t\t\t\t\t\t\tzval_add_ref, 0);\n\n\t\t\t\t\t\tif (incomplete_class) {\n\t\t\t\t\t\t\tphp_store_class_name(&obj, Z_STRVAL(ent1->data), Z_STRLEN(ent1->data));\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t/* Clean up old array entry */\n\t\t\t\t\t\tzval_ptr_dtor(&ent2->data);\n\n\t\t\t\t\t\t/* Set stack entry to point to the newly created object */\n\t\t\t\t\t\tZVAL_COPY_VALUE(&ent2->data, &obj);\n\n\t\t\t\t\t\t/* Clean up class name var entry */\n\t\t\t\t\t\tzval_ptr_dtor(&ent1->data);\n\t\t\t\t\t} else if (Z_TYPE(ent2->data) == IS_OBJECT) {\n\t\t\t\t\t\tzend_class_entry *old_scope = EG(scope);\n\n\t\t\t\t\t\tEG(scope) = Z_OBJCE(ent2->data);\n\t\t\t\t\t\tadd_property_zval(&ent2->data, ent1->varname, &ent1->data);\n\t\t\t\t\t\tif Z_REFCOUNTED(ent1->data) Z_DELREF(ent1->data);\n\t\t\t\t\t\tEG(scope) = old_scope;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tzend_symtable_str_update(target_hash, ent1->varname, strlen(ent1->varname), &ent1->data);\n\t\t\t\t\t}\n\t\t\t\t\tefree(ent1->varname);\n\t\t\t\t} else\t{\n\t\t\t\t\tzend_hash_next_index_insert(target_hash, &ent1->data);\n\t\t\t\t}\n\t\t\t}\n\t\t\tefree(ent1);\n\t\t} else {\n\t\t\tstack->done = 1;\n\t\t}\n\t} else if (!strcmp((char *)name, EL_VAR) && stack->varname) {\n\t\tefree(stack->varname);\n\t\tstack->varname = NULL;\n\t} else if (!strcmp((char *)name, EL_FIELD)) {\n\t\tst_entry *ent;\n\t\twddx_stack_top(stack, (void **)&ent);\n\t\tefree(ent);\n\t\tstack->top--;\n\t}",
        "func_hash": 195456627139063255714886732829389598772,
        "file_name": "wddx.c",
        "file_hash": 202333767268853724294318351879930678985,
        "cwe": [
            "CWE-476"
        ],
        "cve": "CVE-2016-7132",
        "cve_desc": "ext/wddx/wddx.c in PHP before 5.6.25 and 7.x before 7.0.10 allows remote attackers to cause a denial of service (NULL pointer dereference and application crash) or possibly have unspecified other impact via an invalid wddxPacket XML document that is mishandled in a wddx_deserialize call, as demonstrated by a stray element inside a boolean element, leading to incorrect pop processing.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2016-7132",
        "func_name": "php_wddx_pop_element",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195908,
        "project": "linux",
        "commit_id": "e4571b8c5e9ffa1e85c0c671995bd4dcc5c75091",
        "project_url": "https://github.com/torvalds/linux",
        "commit_url": "https://github.com/torvalds/linux/commit/e4571b8c5e9ffa1e85c0c671995bd4dcc5c75091",
        "commit_message": "btrfs: fix NULL pointer dereference when deleting device by invalid id\n\n[BUG]\nIt's easy to trigger NULL pointer dereference, just by removing a\nnon-existing device id:\n\n # mkfs.btrfs -f -m single -d single /dev/test/scratch1 \\\n\t\t\t\t     /dev/test/scratch2\n # mount /dev/test/scratch1 /mnt/btrfs\n # btrfs device remove 3 /mnt/btrfs\n\nThen we have the following kernel NULL pointer dereference:\n\n BUG: kernel NULL pointer dereference, address: 0000000000000000\n #PF: supervisor read access in kernel mode\n #PF: error_code(0x0000) - not-present page\n PGD 0 P4D 0\n Oops: 0000 [#1] PREEMPT SMP NOPTI\n CPU: 9 PID: 649 Comm: btrfs Not tainted 5.14.0-rc3-custom+ #35\n Hardware name: QEMU Standard PC (Q35 + ICH9, 2009), BIOS 0.0.0 02/06/2015\n RIP: 0010:btrfs_rm_device+0x4de/0x6b0 [btrfs]\n  btrfs_ioctl+0x18bb/0x3190 [btrfs]\n  ? lock_is_held_type+0xa5/0x120\n  ? find_held_lock.constprop.0+0x2b/0x80\n  ? do_user_addr_fault+0x201/0x6a0\n  ? lock_release+0xd2/0x2d0\n  ? __x64_sys_ioctl+0x83/0xb0\n  __x64_sys_ioctl+0x83/0xb0\n  do_syscall_64+0x3b/0x90\n  entry_SYSCALL_64_after_hwframe+0x44/0xae\n\n[CAUSE]\nCommit a27a94c2b0c7 (\"btrfs: Make btrfs_find_device_by_devspec return\nbtrfs_device directly\") moves the \"missing\" device path check into\nbtrfs_rm_device().\n\nBut btrfs_rm_device() itself can have case where it only receives\n@devid, with NULL as @device_path.\n\nIn that case, calling strcmp() on NULL will trigger the NULL pointer\ndereference.\n\nBefore that commit, we handle the \"missing\" case inside\nbtrfs_find_device_by_devspec(), which will not check @device_path at all\nif @devid is provided, thus no way to trigger the bug.\n\n[FIX]\nBefore calling strcmp(), also make sure @device_path is not NULL.\n\nFixes: a27a94c2b0c7 (\"btrfs: Make btrfs_find_device_by_devspec return btrfs_device directly\")\nCC: stable@vger.kernel.org # 5.4+\nReported-by: butt3rflyh4ck <butterflyhuangxx@gmail.com>\nReviewed-by: Anand Jain <anand.jain@oracle.com>\nSigned-off-by: Qu Wenruo <wqu@suse.com>\nReviewed-by: David Sterba <dsterba@suse.com>\nSigned-off-by: David Sterba <dsterba@suse.com>",
        "target": 1,
        "irrelevant": 1,
        "func_before": "int btrfs_rm_device(struct btrfs_fs_info *fs_info, const char *device_path,\n\t\t    u64 devid)\n{\n\tstruct btrfs_device *device;\n\tstruct btrfs_fs_devices *cur_devices;\n\tstruct btrfs_fs_devices *fs_devices = fs_info->fs_devices;\n\tu64 num_devices;\n\tint ret = 0;\n\n\tmutex_lock(&uuid_mutex);\n\n\tnum_devices = btrfs_num_devices(fs_info);\n\n\tret = btrfs_check_raid_min_devices(fs_info, num_devices - 1);\n\tif (ret)\n\t\tgoto out;\n\n\tdevice = btrfs_find_device_by_devspec(fs_info, devid, device_path);\n\n\tif (IS_ERR(device)) {\n\t\tif (PTR_ERR(device) == -ENOENT &&\n\t\t    strcmp(device_path, \"missing\") == 0)\n\t\t\tret = BTRFS_ERROR_DEV_MISSING_NOT_FOUND;\n\t\telse\n\t\t\tret = PTR_ERR(device);\n\t\tgoto out;\n\t}\n\n\tif (btrfs_pinned_by_swapfile(fs_info, device)) {\n\t\tbtrfs_warn_in_rcu(fs_info,\n\t\t  \"cannot remove device %s (devid %llu) due to active swapfile\",\n\t\t\t\t  rcu_str_deref(device->name), device->devid);\n\t\tret = -ETXTBSY;\n\t\tgoto out;\n\t}\n\n\tif (test_bit(BTRFS_DEV_STATE_REPLACE_TGT, &device->dev_state)) {\n\t\tret = BTRFS_ERROR_DEV_TGT_REPLACE;\n\t\tgoto out;\n\t}\n\n\tif (test_bit(BTRFS_DEV_STATE_WRITEABLE, &device->dev_state) &&\n\t    fs_info->fs_devices->rw_devices == 1) {\n\t\tret = BTRFS_ERROR_DEV_ONLY_WRITABLE;\n\t\tgoto out;\n\t}\n\n\tif (test_bit(BTRFS_DEV_STATE_WRITEABLE, &device->dev_state)) {\n\t\tmutex_lock(&fs_info->chunk_mutex);\n\t\tlist_del_init(&device->dev_alloc_list);\n\t\tdevice->fs_devices->rw_devices--;\n\t\tmutex_unlock(&fs_info->chunk_mutex);\n\t}\n\n\tmutex_unlock(&uuid_mutex);\n\tret = btrfs_shrink_device(device, 0);\n\tif (!ret)\n\t\tbtrfs_reada_remove_dev(device);\n\tmutex_lock(&uuid_mutex);\n\tif (ret)\n\t\tgoto error_undo;\n\n\t/*\n\t * TODO: the superblock still includes this device in its num_devices\n\t * counter although write_all_supers() is not locked out. This\n\t * could give a filesystem state which requires a degraded mount.\n\t */\n\tret = btrfs_rm_dev_item(device);\n\tif (ret)\n\t\tgoto error_undo;\n\n\tclear_bit(BTRFS_DEV_STATE_IN_FS_METADATA, &device->dev_state);\n\tbtrfs_scrub_cancel_dev(device);\n\n\t/*\n\t * the device list mutex makes sure that we don't change\n\t * the device list while someone else is writing out all\n\t * the device supers. Whoever is writing all supers, should\n\t * lock the device list mutex before getting the number of\n\t * devices in the super block (super_copy). Conversely,\n\t * whoever updates the number of devices in the super block\n\t * (super_copy) should hold the device list mutex.\n\t */\n\n\t/*\n\t * In normal cases the cur_devices == fs_devices. But in case\n\t * of deleting a seed device, the cur_devices should point to\n\t * its own fs_devices listed under the fs_devices->seed.\n\t */\n\tcur_devices = device->fs_devices;\n\tmutex_lock(&fs_devices->device_list_mutex);\n\tlist_del_rcu(&device->dev_list);\n\n\tcur_devices->num_devices--;\n\tcur_devices->total_devices--;\n\t/* Update total_devices of the parent fs_devices if it's seed */\n\tif (cur_devices != fs_devices)\n\t\tfs_devices->total_devices--;\n\n\tif (test_bit(BTRFS_DEV_STATE_MISSING, &device->dev_state))\n\t\tcur_devices->missing_devices--;\n\n\tbtrfs_assign_next_active_device(device, NULL);\n\n\tif (device->bdev) {\n\t\tcur_devices->open_devices--;\n\t\t/* remove sysfs entry */\n\t\tbtrfs_sysfs_remove_device(device);\n\t}\n\n\tnum_devices = btrfs_super_num_devices(fs_info->super_copy) - 1;\n\tbtrfs_set_super_num_devices(fs_info->super_copy, num_devices);\n\tmutex_unlock(&fs_devices->device_list_mutex);\n\n\t/*\n\t * at this point, the device is zero sized and detached from\n\t * the devices list.  All that's left is to zero out the old\n\t * supers and free the device.\n\t */\n\tif (test_bit(BTRFS_DEV_STATE_WRITEABLE, &device->dev_state))\n\t\tbtrfs_scratch_superblocks(fs_info, device->bdev,\n\t\t\t\t\t  device->name->str);\n\n\tbtrfs_close_bdev(device);\n\tsynchronize_rcu();\n\tbtrfs_free_device(device);\n\n\tif (cur_devices->open_devices == 0) {\n\t\tlist_del_init(&cur_devices->seed_list);\n\t\tclose_fs_devices(cur_devices);\n\t\tfree_fs_devices(cur_devices);\n\t}\n\nout:\n\tmutex_unlock(&uuid_mutex);\n\treturn ret;\n\nerror_undo:\n\tbtrfs_reada_undo_remove_dev(device);\n\tif (test_bit(BTRFS_DEV_STATE_WRITEABLE, &device->dev_state)) {\n\t\tmutex_lock(&fs_info->chunk_mutex);\n\t\tlist_add(&device->dev_alloc_list,\n\t\t\t &fs_devices->alloc_list);\n\t\tdevice->fs_devices->rw_devices++;\n\t\tmutex_unlock(&fs_info->chunk_mutex);\n\t}\n\tgoto out;\n}",
        "func_hash": 109862119097507194285189243526662049352,
        "file_name": "volumes.c",
        "file_hash": 327977751785202812455417482244318484271,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2021-3739",
        "cve_desc": "A NULL pointer dereference flaw was found in the btrfs_rm_device function in fs/btrfs/volumes.c in the Linux Kernel, where triggering the bug requires \u2018CAP_SYS_ADMIN\u2019. This flaw allows a local attacker to crash the system or leak kernel internal information. The highest threat from this vulnerability is to system availability.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-3739",
        "func_name": "btrfs_rm_device",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195909,
        "project": "ImageMagick",
        "commit_id": "d072ed6aff835c174e856ce3a428163c0da9e8f4",
        "project_url": "https://github.com/ImageMagick/ImageMagick",
        "commit_url": "https://github.com/ImageMagick/ImageMagick/commit/d072ed6aff835c174e856ce3a428163c0da9e8f4",
        "commit_message": "Skip MNG CLIP chunk with out-of-range object IDs",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static Image *ReadOneMNGImage(MngInfo* mng_info, const ImageInfo *image_info,\n     ExceptionInfo *exception)\n{\n  char\n    page_geometry[MagickPathExtent];\n\n  Image\n    *image;\n\n  MagickBooleanType\n    logging;\n\n  volatile int\n    first_mng_object,\n    object_id,\n    term_chunk_found,\n    skip_to_iend;\n\n  volatile ssize_t\n    image_count=0;\n\n  MagickBooleanType\n    status;\n\n  MagickOffsetType\n    offset;\n\n  MngBox\n    default_fb,\n    fb,\n    previous_fb;\n\n#if defined(MNG_INSERT_LAYERS)\n  PixelInfo\n    mng_background_color;\n#endif\n\n  register unsigned char\n    *p;\n\n  register ssize_t\n    i;\n\n  size_t\n    count;\n\n  ssize_t\n    loop_level;\n\n  volatile short\n    skipping_loop;\n\n#if defined(MNG_INSERT_LAYERS)\n  unsigned int\n    mandatory_back=0;\n#endif\n\n  volatile unsigned int\n#ifdef MNG_OBJECT_BUFFERS\n    mng_background_object=0,\n#endif\n    mng_type=0;   /* 0: PNG or JNG; 1: MNG; 2: MNG-LC; 3: MNG-VLC */\n\n  size_t\n    default_frame_timeout,\n    frame_timeout,\n#if defined(MNG_INSERT_LAYERS)\n    image_height,\n    image_width,\n#endif\n    length;\n\n  /* These delays are all measured in image ticks_per_second,\n   * not in MNG ticks_per_second\n   */\n  volatile size_t\n    default_frame_delay,\n    final_delay,\n    final_image_delay,\n    frame_delay,\n#if defined(MNG_INSERT_LAYERS)\n    insert_layers,\n#endif\n    mng_iterations=1,\n    simplicity=0,\n    subframe_height=0,\n    subframe_width=0;\n\n  previous_fb.top=0;\n  previous_fb.bottom=0;\n  previous_fb.left=0;\n  previous_fb.right=0;\n  default_fb.top=0;\n  default_fb.bottom=0;\n  default_fb.left=0;\n  default_fb.right=0;\n\n  logging=LogMagickEvent(CoderEvent,GetMagickModule(),\n    \"  Enter ReadOneMNGImage()\");\n\n  image=mng_info->image;\n\n  if (LocaleCompare(image_info->magick,\"MNG\") == 0)\n    {\n      char\n        magic_number[MagickPathExtent];\n\n      /* Verify MNG signature.  */\n      count=(size_t) ReadBlob(image,8,(unsigned char *) magic_number);\n      if (memcmp(magic_number,\"\\212MNG\\r\\n\\032\\n\",8) != 0)\n        ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n\n      /* Initialize some nonzero members of the MngInfo structure.  */\n      for (i=0; i < MNG_MAX_OBJECTS; i++)\n      {\n        mng_info->object_clip[i].right=(ssize_t) PNG_UINT_31_MAX;\n        mng_info->object_clip[i].bottom=(ssize_t) PNG_UINT_31_MAX;\n      }\n      mng_info->exists[0]=MagickTrue;\n    }\n\n  skipping_loop=(-1);\n  first_mng_object=MagickTrue;\n  mng_type=0;\n#if defined(MNG_INSERT_LAYERS)\n  insert_layers=MagickFalse; /* should be False during convert or mogrify */\n#endif\n  default_frame_delay=0;\n  default_frame_timeout=0;\n  frame_delay=0;\n  final_delay=1;\n  mng_info->ticks_per_second=1UL*image->ticks_per_second;\n  object_id=0;\n  skip_to_iend=MagickFalse;\n  term_chunk_found=MagickFalse;\n  mng_info->framing_mode=1;\n#if defined(MNG_INSERT_LAYERS)\n  mandatory_back=MagickFalse;\n#endif\n#if defined(MNG_INSERT_LAYERS)\n  mng_background_color=image->background_color;\n#endif\n  default_fb=mng_info->frame;\n  previous_fb=mng_info->frame;\n  do\n  {\n    char\n      type[MagickPathExtent];\n\n    if (LocaleCompare(image_info->magick,\"MNG\") == 0)\n      {\n        unsigned char\n          *chunk;\n\n        /*\n          Read a new chunk.\n        */\n        type[0]='\\0';\n        (void) ConcatenateMagickString(type,\"errr\",MagickPathExtent);\n        length=ReadBlobMSBLong(image);\n        count=(size_t) ReadBlob(image,4,(unsigned char *) type);\n\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n           \"  Reading MNG chunk type %c%c%c%c, length: %.20g\",\n           type[0],type[1],type[2],type[3],(double) length);\n\n        if (length > PNG_UINT_31_MAX)\n          {\n            status=MagickFalse;\n            break;\n          }\n\n        if (count == 0)\n          ThrowReaderException(CorruptImageError,\"CorruptImage\");\n\n        p=NULL;\n        chunk=(unsigned char *) NULL;\n\n        if (length != 0)\n          {\n            if (length > GetBlobSize(image))\n              ThrowReaderException(CorruptImageError,\n                \"InsufficientImageDataInFile\");\n            chunk=(unsigned char *) AcquireQuantumMemory(length+\n             MagickPathExtent,sizeof(*chunk));\n\n            if (chunk == (unsigned char *) NULL)\n              ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n\n            for (i=0; i < (ssize_t) length; i++)\n            {\n              int\n                c;\n\n              c=ReadBlobByte(image);\n              if (c == EOF)\n                break;\n              chunk[i]=(unsigned char) c;\n            }\n\n            p=chunk;\n          }\n\n        (void) ReadBlobMSBLong(image);  /* read crc word */\n\n#if !defined(JNG_SUPPORTED)\n        if (memcmp(type,mng_JHDR,4) == 0)\n          {\n            skip_to_iend=MagickTrue;\n\n            if (mng_info->jhdr_warning == 0)\n              (void) ThrowMagickException(exception,GetMagickModule(),\n                CoderError,\"JNGCompressNotSupported\",\"`%s'\",image->filename);\n\n            mng_info->jhdr_warning++;\n          }\n#endif\n        if (memcmp(type,mng_DHDR,4) == 0)\n          {\n            skip_to_iend=MagickTrue;\n\n            if (mng_info->dhdr_warning == 0)\n              (void) ThrowMagickException(exception,GetMagickModule(),\n                CoderError,\"DeltaPNGNotSupported\",\"`%s'\",image->filename);\n\n            mng_info->dhdr_warning++;\n          }\n        if (memcmp(type,mng_MEND,4) == 0)\n          break;\n\n        if (skip_to_iend)\n          {\n            if (memcmp(type,mng_IEND,4) == 0)\n              skip_to_iend=MagickFalse;\n\n            if (length != 0)\n              chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  Skip to IEND.\");\n\n            continue;\n          }\n\n        if (memcmp(type,mng_MHDR,4) == 0)\n          {\n            if (length != 28)\n              {\n                chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n                ThrowReaderException(CorruptImageError,\"CorruptImage\");\n              }\n\n            mng_info->mng_width=(size_t) ((p[0] << 24) | (p[1] << 16) |\n                (p[2] << 8) | p[3]);\n\n            mng_info->mng_height=(size_t) ((p[4] << 24) | (p[5] << 16) |\n                (p[6] << 8) | p[7]);\n\n            if (logging != MagickFalse)\n              {\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"  MNG width: %.20g\",(double) mng_info->mng_width);\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"  MNG height: %.20g\",(double) mng_info->mng_height);\n              }\n\n            p+=8;\n            mng_info->ticks_per_second=(size_t) mng_get_long(p);\n\n            if (mng_info->ticks_per_second == 0)\n              default_frame_delay=0;\n\n            else\n              default_frame_delay=1UL*image->ticks_per_second/\n                mng_info->ticks_per_second;\n\n            frame_delay=default_frame_delay;\n            simplicity=0;\n\n            p+=16;\n            simplicity=(size_t) mng_get_long(p);\n\n            mng_type=1;    /* Full MNG */\n\n            if ((simplicity != 0) && ((simplicity | 11) == 11))\n              mng_type=2; /* LC */\n\n            if ((simplicity != 0) && ((simplicity | 9) == 9))\n              mng_type=3; /* VLC */\n\n#if defined(MNG_INSERT_LAYERS)\n            if (mng_type != 3)\n              insert_layers=MagickTrue;\n#endif\n            if (GetAuthenticPixelQueue(image) != (Quantum *) NULL)\n              {\n                /* Allocate next image structure.  */\n                AcquireNextImage(image_info,image,exception);\n\n                if (GetNextImageInList(image) == (Image *) NULL)\n                  return((Image *) NULL);\n\n                image=SyncNextImageInList(image);\n                mng_info->image=image;\n              }\n\n            if ((mng_info->mng_width > 65535L) ||\n                (mng_info->mng_height > 65535L))\n              {\n                chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n                ThrowReaderException(ImageError,\"WidthOrHeightExceedsLimit\");\n              }\n\n            (void) FormatLocaleString(page_geometry,MagickPathExtent,\n              \"%.20gx%.20g+0+0\",(double) mng_info->mng_width,(double)\n              mng_info->mng_height);\n\n            mng_info->frame.left=0;\n            mng_info->frame.right=(ssize_t) mng_info->mng_width;\n            mng_info->frame.top=0;\n            mng_info->frame.bottom=(ssize_t) mng_info->mng_height;\n            mng_info->clip=default_fb=previous_fb=mng_info->frame;\n\n            for (i=0; i < MNG_MAX_OBJECTS; i++)\n              mng_info->object_clip[i]=mng_info->frame;\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_TERM,4) == 0)\n          {\n            int\n              repeat=0;\n\n            if (length != 0)\n              repeat=p[0];\n\n            if (repeat == 3)\n              {\n                final_delay=(png_uint_32) mng_get_long(&p[2]);\n                mng_iterations=(png_uint_32) mng_get_long(&p[6]);\n\n                if (mng_iterations == PNG_UINT_31_MAX)\n                  mng_iterations=0;\n\n                image->iterations=mng_iterations;\n                term_chunk_found=MagickTrue;\n              }\n\n            if (logging != MagickFalse)\n              {\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"    repeat=%d,  final_delay=%.20g,  iterations=%.20g\",\n                  repeat,(double) final_delay, (double) image->iterations);\n              }\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n        if (memcmp(type,mng_DEFI,4) == 0)\n          {\n            if (mng_type == 3)\n              (void) ThrowMagickException(exception,GetMagickModule(),\n                CoderError,\"DEFI chunk found in MNG-VLC datastream\",\"`%s'\",\n                image->filename);\n\n            if (length < 2)\n              {\n                if (chunk)\n                  chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n                ThrowReaderException(CorruptImageError,\"CorruptImage\");\n              }\n\n            object_id=(p[0] << 8) | p[1];\n\n            if (mng_type == 2 && object_id != 0)\n              (void) ThrowMagickException(exception,GetMagickModule(),\n                CoderError,\"Nonzero object_id in MNG-LC datastream\",\"`%s'\",\n                image->filename);\n\n            if (object_id > MNG_MAX_OBJECTS)\n              {\n                /*\n                  Instead of using a warning we should allocate a larger\n                  MngInfo structure and continue.\n                */\n                (void) ThrowMagickException(exception,GetMagickModule(),\n                  CoderError,\"object id too large\",\"`%s'\",image->filename);\n                object_id=MNG_MAX_OBJECTS;\n              }\n\n            if (mng_info->exists[object_id])\n              if (mng_info->frozen[object_id])\n                {\n                  chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n                  (void) ThrowMagickException(exception,\n                    GetMagickModule(),CoderError,\n                    \"DEFI cannot redefine a frozen MNG object\",\"`%s'\",\n                    image->filename);\n                  continue;\n                }\n\n            mng_info->exists[object_id]=MagickTrue;\n\n            if (length > 2)\n              mng_info->invisible[object_id]=p[2];\n\n            /*\n              Extract object offset info.\n            */\n            if (length > 11)\n              {\n                mng_info->x_off[object_id]=(ssize_t) ((p[4] << 24) |\n                    (p[5] << 16) | (p[6] << 8) | p[7]);\n\n                mng_info->y_off[object_id]=(ssize_t) ((p[8] << 24) |\n                    (p[9] << 16) | (p[10] << 8) | p[11]);\n\n                if (logging != MagickFalse)\n                  {\n                    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                      \"  x_off[%d]: %.20g,  y_off[%d]: %.20g\",\n                      object_id,(double) mng_info->x_off[object_id],\n                      object_id,(double) mng_info->y_off[object_id]);\n                  }\n              }\n\n            /*\n              Extract object clipping info.\n            */\n            if (length > 27)\n              mng_info->object_clip[object_id]=mng_read_box(mng_info->frame,0,\n                &p[12]);\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n        if (memcmp(type,mng_bKGD,4) == 0)\n          {\n            mng_info->have_global_bkgd=MagickFalse;\n\n            if (length > 5)\n              {\n                mng_info->mng_global_bkgd.red=\n                  ScaleShortToQuantum((unsigned short) ((p[0] << 8) | p[1]));\n\n                mng_info->mng_global_bkgd.green=\n                  ScaleShortToQuantum((unsigned short) ((p[2] << 8) | p[3]));\n\n                mng_info->mng_global_bkgd.blue=\n                  ScaleShortToQuantum((unsigned short) ((p[4] << 8) | p[5]));\n\n                mng_info->have_global_bkgd=MagickTrue;\n              }\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n        if (memcmp(type,mng_BACK,4) == 0)\n          {\n#if defined(MNG_INSERT_LAYERS)\n            if (length > 6)\n              mandatory_back=p[6];\n\n            else\n              mandatory_back=0;\n\n            if (mandatory_back && length > 5)\n              {\n                mng_background_color.red=\n                    ScaleShortToQuantum((unsigned short) ((p[0] << 8) | p[1]));\n\n                mng_background_color.green=\n                    ScaleShortToQuantum((unsigned short) ((p[2] << 8) | p[3]));\n\n                mng_background_color.blue=\n                    ScaleShortToQuantum((unsigned short) ((p[4] << 8) | p[5]));\n\n                mng_background_color.alpha=OpaqueAlpha;\n              }\n\n#ifdef MNG_OBJECT_BUFFERS\n            if (length > 8)\n              mng_background_object=(p[7] << 8) | p[8];\n#endif\n#endif\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_PLTE,4) == 0)\n          {\n            /* Read global PLTE.  */\n\n            if (length && (length < 769))\n              {\n                if (mng_info->global_plte == (png_colorp) NULL)\n                  mng_info->global_plte=(png_colorp) AcquireQuantumMemory(256,\n                    sizeof(*mng_info->global_plte));\n\n                for (i=0; i < (ssize_t) (length/3); i++)\n                {\n                  mng_info->global_plte[i].red=p[3*i];\n                  mng_info->global_plte[i].green=p[3*i+1];\n                  mng_info->global_plte[i].blue=p[3*i+2];\n                }\n\n                mng_info->global_plte_length=(unsigned int) (length/3);\n              }\n#ifdef MNG_LOOSE\n            for ( ; i < 256; i++)\n            {\n              mng_info->global_plte[i].red=i;\n              mng_info->global_plte[i].green=i;\n              mng_info->global_plte[i].blue=i;\n            }\n\n            if (length != 0)\n              mng_info->global_plte_length=256;\n#endif\n            else\n              mng_info->global_plte_length=0;\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_tRNS,4) == 0)\n          {\n            /* read global tRNS */\n\n            if (length > 0 && length < 257)\n              for (i=0; i < (ssize_t) length; i++)\n                mng_info->global_trns[i]=p[i];\n\n#ifdef MNG_LOOSE\n            for ( ; i < 256; i++)\n              mng_info->global_trns[i]=255;\n#endif\n            mng_info->global_trns_length=(unsigned int) length;\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n        if (memcmp(type,mng_gAMA,4) == 0)\n          {\n            if (length == 4)\n              {\n                ssize_t\n                  igamma;\n\n                igamma=mng_get_long(p);\n                mng_info->global_gamma=((float) igamma)*0.00001;\n                mng_info->have_global_gama=MagickTrue;\n              }\n\n            else\n              mng_info->have_global_gama=MagickFalse;\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_cHRM,4) == 0)\n          {\n            /* Read global cHRM */\n\n            if (length == 32)\n              {\n                mng_info->global_chrm.white_point.x=0.00001*mng_get_long(p);\n                mng_info->global_chrm.white_point.y=0.00001*mng_get_long(&p[4]);\n                mng_info->global_chrm.red_primary.x=0.00001*mng_get_long(&p[8]);\n                mng_info->global_chrm.red_primary.y=0.00001*\n                  mng_get_long(&p[12]);\n                mng_info->global_chrm.green_primary.x=0.00001*\n                  mng_get_long(&p[16]);\n                mng_info->global_chrm.green_primary.y=0.00001*\n                  mng_get_long(&p[20]);\n                mng_info->global_chrm.blue_primary.x=0.00001*\n                  mng_get_long(&p[24]);\n                mng_info->global_chrm.blue_primary.y=0.00001*\n                  mng_get_long(&p[28]);\n                mng_info->have_global_chrm=MagickTrue;\n              }\n            else\n              mng_info->have_global_chrm=MagickFalse;\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_sRGB,4) == 0)\n          {\n            /*\n              Read global sRGB.\n            */\n            if (length != 0)\n              {\n                mng_info->global_srgb_intent=\n                  Magick_RenderingIntent_from_PNG_RenderingIntent(p[0]);\n                mng_info->have_global_srgb=MagickTrue;\n              }\n            else\n              mng_info->have_global_srgb=MagickFalse;\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_iCCP,4) == 0)\n          {\n            /* To do: */\n\n            /*\n              Read global iCCP.\n            */\n            if (length != 0)\n              chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n            continue;\n          }\n\n        if (memcmp(type,mng_FRAM,4) == 0)\n          {\n            if (mng_type == 3)\n              (void) ThrowMagickException(exception,GetMagickModule(),\n                CoderError,\"FRAM chunk found in MNG-VLC datastream\",\"`%s'\",\n                image->filename);\n\n            if ((mng_info->framing_mode == 2) || (mng_info->framing_mode == 4))\n              image->delay=frame_delay;\n\n            frame_delay=default_frame_delay;\n            frame_timeout=default_frame_timeout;\n            fb=default_fb;\n\n            if (length != 0)\n              if (p[0])\n                mng_info->framing_mode=p[0];\n\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"    Framing_mode=%d\",mng_info->framing_mode);\n\n            if (length > 6)\n              {\n                /* Note the delay and frame clipping boundaries.  */\n\n                p++; /* framing mode */\n\n                while (*p && ((p-chunk) < (ssize_t) length))\n                  p++;  /* frame name */\n\n                p++;  /* frame name terminator */\n\n                if ((p-chunk) < (ssize_t) (length-4))\n                  {\n                    int\n                      change_delay,\n                      change_timeout,\n                      change_clipping;\n\n                    change_delay=(*p++);\n                    change_timeout=(*p++);\n                    change_clipping=(*p++);\n                    p++; /* change_sync */\n\n                    if (change_delay)\n                      {\n                        frame_delay=1UL*image->ticks_per_second*\n                          mng_get_long(p);\n\n                        if (mng_info->ticks_per_second != 0)\n                          frame_delay/=mng_info->ticks_per_second;\n\n                        else\n                          frame_delay=PNG_UINT_31_MAX;\n\n                        if (change_delay == 2)\n                          default_frame_delay=frame_delay;\n\n                        p+=4;\n\n                        if (logging != MagickFalse)\n                          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                            \"    Framing_delay=%.20g\",(double) frame_delay);\n                      }\n\n                    if (change_timeout)\n                      {\n                        frame_timeout=1UL*image->ticks_per_second*\n                          mng_get_long(p);\n\n                        if (mng_info->ticks_per_second != 0)\n                          frame_timeout/=mng_info->ticks_per_second;\n\n                        else\n                          frame_timeout=PNG_UINT_31_MAX;\n\n                        if (change_timeout == 2)\n                          default_frame_timeout=frame_timeout;\n\n                        p+=4;\n\n                        if (logging != MagickFalse)\n                          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                            \"    Framing_timeout=%.20g\",(double) frame_timeout);\n                      }\n\n                    if (change_clipping)\n                      {\n                        fb=mng_read_box(previous_fb,(char) p[0],&p[1]);\n                        p+=17;\n                        previous_fb=fb;\n\n                        if (logging != MagickFalse)\n                          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                            \"    Frame_clip: L=%.20g R=%.20g T=%.20g B=%.20g\",\n                            (double) fb.left,(double) fb.right,(double) fb.top,\n                            (double) fb.bottom);\n\n                        if (change_clipping == 2)\n                          default_fb=fb;\n                      }\n                  }\n              }\n            mng_info->clip=fb;\n            mng_info->clip=mng_minimum_box(fb,mng_info->frame);\n\n            subframe_width=(size_t) (mng_info->clip.right\n               -mng_info->clip.left);\n\n            subframe_height=(size_t) (mng_info->clip.bottom\n               -mng_info->clip.top);\n            /*\n              Insert a background layer behind the frame if framing_mode is 4.\n            */\n#if defined(MNG_INSERT_LAYERS)\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"   subframe_width=%.20g, subframe_height=%.20g\",(double)\n                subframe_width,(double) subframe_height);\n\n            if (insert_layers && (mng_info->framing_mode == 4) &&\n                (subframe_width) && (subframe_height))\n              {\n                /* Allocate next image structure.  */\n                if (GetAuthenticPixelQueue(image) != (Quantum *) NULL)\n                  {\n                    AcquireNextImage(image_info,image,exception);\n\n                    if (GetNextImageInList(image) == (Image *) NULL)\n                      return(DestroyImageList(image));\n\n                    image=SyncNextImageInList(image);\n                  }\n\n                mng_info->image=image;\n\n                if (term_chunk_found)\n                  {\n                    image->start_loop=MagickTrue;\n                    image->iterations=mng_iterations;\n                    term_chunk_found=MagickFalse;\n                  }\n\n                else\n                    image->start_loop=MagickFalse;\n\n                image->columns=subframe_width;\n                image->rows=subframe_height;\n                image->page.width=subframe_width;\n                image->page.height=subframe_height;\n                image->page.x=mng_info->clip.left;\n                image->page.y=mng_info->clip.top;\n                image->background_color=mng_background_color;\n                image->alpha_trait=UndefinedPixelTrait;\n                image->delay=0;\n                (void) SetImageBackgroundColor(image,exception);\n\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"  Insert backgd layer, L=%.20g, R=%.20g T=%.20g, B=%.20g\",\n                    (double) mng_info->clip.left,\n                    (double) mng_info->clip.right,\n                    (double) mng_info->clip.top,\n                    (double) mng_info->clip.bottom);\n              }\n#endif\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_CLIP,4) == 0)\n          {\n            unsigned int\n              first_object,\n              last_object;\n\n            /*\n              Read CLIP.\n            */\n            if (length > 3)\n              {\n                first_object=(p[0] << 8) | p[1];\n                last_object=(p[2] << 8) | p[3];\n                p+=4;\n\n                for (i=(int) first_object; i <= (int) last_object; i++)\n                {\n                  if (mng_info->exists[i] && !mng_info->frozen[i])\n                    {\n                      MngBox\n                        box;\n\n                      box=mng_info->object_clip[i];\n                      if ((p-chunk) < (ssize_t) (length-17))\n                        mng_info->object_clip[i]=\n                           mng_read_box(box,(char) p[0],&p[1]);\n                    }\n                }\n\n              }\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_SAVE,4) == 0)\n          {\n            for (i=1; i < MNG_MAX_OBJECTS; i++)\n              if (mng_info->exists[i])\n                {\n                 mng_info->frozen[i]=MagickTrue;\n#ifdef MNG_OBJECT_BUFFERS\n                 if (mng_info->ob[i] != (MngBuffer *) NULL)\n                    mng_info->ob[i]->frozen=MagickTrue;\n#endif\n                }\n\n            if (length != 0)\n              chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n            continue;\n          }\n\n        if ((memcmp(type,mng_DISC,4) == 0) || (memcmp(type,mng_SEEK,4) == 0))\n          {\n            /* Read DISC or SEEK.  */\n\n            if ((length == 0) || !memcmp(type,mng_SEEK,4))\n              {\n                for (i=1; i < MNG_MAX_OBJECTS; i++)\n                  MngInfoDiscardObject(mng_info,i);\n              }\n\n            else\n              {\n                register ssize_t\n                  j;\n\n                for (j=1; j < (ssize_t) length; j+=2)\n                {\n                  i=p[j-1] << 8 | p[j];\n                  MngInfoDiscardObject(mng_info,i);\n                }\n              }\n\n            if (length != 0)\n              chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n            continue;\n          }\n\n        if (memcmp(type,mng_MOVE,4) == 0)\n          {\n            size_t\n              first_object,\n              last_object;\n\n            /* read MOVE */\n\n            if (length > 3)\n            {\n              first_object=(p[0] << 8) | p[1];\n              last_object=(p[2] << 8) | p[3];\n              p+=4;\n\n              for (i=(ssize_t) first_object; i <= (ssize_t) last_object; i++)\n              {\n                if ((i < 0) || (i >= MNG_MAX_OBJECTS))\n                  continue;\n\n                if (mng_info->exists[i] && !mng_info->frozen[i] &&\n                    (p-chunk) < (ssize_t) (length-8))\n                  {\n                    MngPair\n                      new_pair;\n\n                    MngPair\n                      old_pair;\n\n                    old_pair.a=mng_info->x_off[i];\n                    old_pair.b=mng_info->y_off[i];\n                    new_pair=mng_read_pair(old_pair,(int) p[0],&p[1]);\n                    mng_info->x_off[i]=new_pair.a;\n                    mng_info->y_off[i]=new_pair.b;\n                  }\n              }\n            }\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_LOOP,4) == 0)\n          {\n            ssize_t loop_iters=1;\n            if (length > 4)\n              {\n                loop_level=chunk[0];\n                mng_info->loop_active[loop_level]=1;  /* mark loop active */\n\n                /* Record starting point.  */\n                loop_iters=mng_get_long(&chunk[1]);\n\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"  LOOP level %.20g has %.20g iterations \",\n                    (double) loop_level, (double) loop_iters);\n\n                if (loop_iters == 0)\n                  skipping_loop=loop_level;\n\n                else\n                  {\n                    mng_info->loop_jump[loop_level]=TellBlob(image);\n                    mng_info->loop_count[loop_level]=loop_iters;\n                  }\n\n                mng_info->loop_iteration[loop_level]=0;\n              }\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_ENDL,4) == 0)\n          {\n            if (length > 0)\n              {\n                loop_level=chunk[0];\n\n                if (skipping_loop > 0)\n                  {\n                    if (skipping_loop == loop_level)\n                      {\n                        /*\n                          Found end of zero-iteration loop.\n                        */\n                        skipping_loop=(-1);\n                        mng_info->loop_active[loop_level]=0;\n                      }\n                  }\n\n                else\n                  {\n                    if (mng_info->loop_active[loop_level] == 1)\n                      {\n                        mng_info->loop_count[loop_level]--;\n                        mng_info->loop_iteration[loop_level]++;\n\n                        if (logging != MagickFalse)\n                          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                          \"  ENDL: LOOP level %.20g has %.20g remaining iters\",\n                            (double) loop_level,(double)\n                            mng_info->loop_count[loop_level]);\n\n                        if (mng_info->loop_count[loop_level] != 0)\n                          {\n                            offset=\n                              SeekBlob(image,mng_info->loop_jump[loop_level],\n                              SEEK_SET);\n\n                            if (offset < 0)\n                              {\n                                chunk=(unsigned char *) RelinquishMagickMemory(\n                                  chunk);\n                                ThrowReaderException(CorruptImageError,\n                                  \"ImproperImageHeader\");\n                              }\n                          }\n\n                        else\n                          {\n                            short\n                              last_level;\n\n                            /*\n                              Finished loop.\n                            */\n                            mng_info->loop_active[loop_level]=0;\n                            last_level=(-1);\n                            for (i=0; i < loop_level; i++)\n                              if (mng_info->loop_active[i] == 1)\n                                last_level=(short) i;\n                            loop_level=last_level;\n                          }\n                      }\n                  }\n              }\n\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_CLON,4) == 0)\n          {\n            if (mng_info->clon_warning == 0)\n              (void) ThrowMagickException(exception,GetMagickModule(),\n                CoderError,\"CLON is not implemented yet\",\"`%s'\",\n                image->filename);\n\n            mng_info->clon_warning++;\n          }\n\n        if (memcmp(type,mng_MAGN,4) == 0)\n          {\n            png_uint_16\n              magn_first,\n              magn_last,\n              magn_mb,\n              magn_ml,\n              magn_mr,\n              magn_mt,\n              magn_mx,\n              magn_my,\n              magn_methx,\n              magn_methy;\n\n            if (length > 1)\n              magn_first=(p[0] << 8) | p[1];\n\n            else\n              magn_first=0;\n\n            if (length > 3)\n              magn_last=(p[2] << 8) | p[3];\n\n            else\n              magn_last=magn_first;\n#ifndef MNG_OBJECT_BUFFERS\n            if (magn_first || magn_last)\n              if (mng_info->magn_warning == 0)\n                {\n                  (void) ThrowMagickException(exception,\n                     GetMagickModule(),CoderError,\n                     \"MAGN is not implemented yet for nonzero objects\",\n                     \"`%s'\",image->filename);\n\n                   mng_info->magn_warning++;\n                }\n#endif\n            if (length > 4)\n              magn_methx=p[4];\n\n            else\n              magn_methx=0;\n\n            if (length > 6)\n              magn_mx=(p[5] << 8) | p[6];\n\n            else\n              magn_mx=1;\n\n            if (magn_mx == 0)\n              magn_mx=1;\n\n            if (length > 8)\n              magn_my=(p[7] << 8) | p[8];\n\n            else\n              magn_my=magn_mx;\n\n            if (magn_my == 0)\n              magn_my=1;\n\n            if (length > 10)\n              magn_ml=(p[9] << 8) | p[10];\n\n            else\n              magn_ml=magn_mx;\n\n            if (magn_ml == 0)\n              magn_ml=1;\n\n            if (length > 12)\n              magn_mr=(p[11] << 8) | p[12];\n\n            else\n              magn_mr=magn_mx;\n\n            if (magn_mr == 0)\n              magn_mr=1;\n\n            if (length > 14)\n              magn_mt=(p[13] << 8) | p[14];\n\n            else\n              magn_mt=magn_my;\n\n            if (magn_mt == 0)\n              magn_mt=1;\n\n            if (length > 16)\n              magn_mb=(p[15] << 8) | p[16];\n\n            else\n              magn_mb=magn_my;\n\n            if (magn_mb == 0)\n              magn_mb=1;\n\n            if (length > 17)\n              magn_methy=p[17];\n\n            else\n              magn_methy=magn_methx;\n\n\n            if (magn_methx > 5 || magn_methy > 5)\n              if (mng_info->magn_warning == 0)\n                {\n                  (void) ThrowMagickException(exception,\n                     GetMagickModule(),CoderError,\n                     \"Unknown MAGN method in MNG datastream\",\"`%s'\",\n                     image->filename);\n\n                   mng_info->magn_warning++;\n                }\n#ifdef MNG_OBJECT_BUFFERS\n          /* Magnify existing objects in the range magn_first to magn_last */\n#endif\n            if (magn_first == 0 || magn_last == 0)\n              {\n                /* Save the magnification factors for object 0 */\n                mng_info->magn_mb=magn_mb;\n                mng_info->magn_ml=magn_ml;\n                mng_info->magn_mr=magn_mr;\n                mng_info->magn_mt=magn_mt;\n                mng_info->magn_mx=magn_mx;\n                mng_info->magn_my=magn_my;\n                mng_info->magn_methx=magn_methx;\n                mng_info->magn_methy=magn_methy;\n              }\n          }\n\n        if (memcmp(type,mng_PAST,4) == 0)\n          {\n            if (mng_info->past_warning == 0)\n              (void) ThrowMagickException(exception,GetMagickModule(),\n                CoderError,\"PAST is not implemented yet\",\"`%s'\",\n                image->filename);\n\n            mng_info->past_warning++;\n          }\n\n        if (memcmp(type,mng_SHOW,4) == 0)\n          {\n            if (mng_info->show_warning == 0)\n              (void) ThrowMagickException(exception,GetMagickModule(),\n                CoderError,\"SHOW is not implemented yet\",\"`%s'\",\n                image->filename);\n\n            mng_info->show_warning++;\n          }\n\n        if (memcmp(type,mng_sBIT,4) == 0)\n          {\n            if (length < 4)\n              mng_info->have_global_sbit=MagickFalse;\n\n            else\n              {\n                mng_info->global_sbit.gray=p[0];\n                mng_info->global_sbit.red=p[0];\n                mng_info->global_sbit.green=p[1];\n                mng_info->global_sbit.blue=p[2];\n                mng_info->global_sbit.alpha=p[3];\n                mng_info->have_global_sbit=MagickTrue;\n             }\n          }\n        if (memcmp(type,mng_pHYs,4) == 0)\n          {\n            if (length > 8)\n              {\n                mng_info->global_x_pixels_per_unit=\n                    (size_t) mng_get_long(p);\n                mng_info->global_y_pixels_per_unit=\n                    (size_t) mng_get_long(&p[4]);\n                mng_info->global_phys_unit_type=p[8];\n                mng_info->have_global_phys=MagickTrue;\n              }\n\n            else\n              mng_info->have_global_phys=MagickFalse;\n          }\n        if (memcmp(type,mng_pHYg,4) == 0)\n          {\n            if (mng_info->phyg_warning == 0)\n              (void) ThrowMagickException(exception,GetMagickModule(),\n                CoderError,\"pHYg is not implemented.\",\"`%s'\",image->filename);\n\n            mng_info->phyg_warning++;\n          }\n        if (memcmp(type,mng_BASI,4) == 0)\n          {\n            skip_to_iend=MagickTrue;\n\n            if (mng_info->basi_warning == 0)\n              (void) ThrowMagickException(exception,GetMagickModule(),\n                CoderError,\"BASI is not implemented yet\",\"`%s'\",\n                image->filename);\n\n            mng_info->basi_warning++;\n#ifdef MNG_BASI_SUPPORTED\n            basi_width=(size_t) ((p[0] << 24) | (p[1] << 16) |\n               (p[2] << 8) | p[3]);\n            basi_height=(size_t) ((p[4] << 24) | (p[5] << 16) |\n               (p[6] << 8) | p[7]);\n            basi_color_type=p[8];\n            basi_compression_method=p[9];\n            basi_filter_type=p[10];\n            basi_interlace_method=p[11];\n            if (length > 11)\n              basi_red=(p[12] << 8) & p[13];\n\n            else\n              basi_red=0;\n\n            if (length > 13)\n              basi_green=(p[14] << 8) & p[15];\n\n            else\n              basi_green=0;\n\n            if (length > 15)\n              basi_blue=(p[16] << 8) & p[17];\n\n            else\n              basi_blue=0;\n\n            if (length > 17)\n              basi_alpha=(p[18] << 8) & p[19];\n\n            else\n              {\n                if (basi_sample_depth == 16)\n                  basi_alpha=65535L;\n                else\n                  basi_alpha=255;\n              }\n\n            if (length > 19)\n              basi_viewable=p[20];\n\n            else\n              basi_viewable=0;\n\n#endif\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n\n        if (memcmp(type,mng_IHDR,4)\n#if defined(JNG_SUPPORTED)\n            && memcmp(type,mng_JHDR,4)\n#endif\n            )\n          {\n            /* Not an IHDR or JHDR chunk */\n            if (length != 0)\n              chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n            continue;\n          }\n/* Process IHDR */\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  Processing %c%c%c%c chunk\",type[0],type[1],type[2],type[3]);\n\n        mng_info->exists[object_id]=MagickTrue;\n        mng_info->viewable[object_id]=MagickTrue;\n\n        if (mng_info->invisible[object_id])\n          {\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  Skipping invisible object\");\n\n            skip_to_iend=MagickTrue;\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            continue;\n          }\n#if defined(MNG_INSERT_LAYERS)\n        if (length < 8)\n          {\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n            ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n          }\n\n        image_width=(size_t) mng_get_long(p);\n        image_height=(size_t) mng_get_long(&p[4]);\n#endif\n        chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n        /*\n          Insert a transparent background layer behind the entire animation\n          if it is not full screen.\n        */\n#if defined(MNG_INSERT_LAYERS)\n        if (insert_layers && mng_type && first_mng_object)\n          {\n            if ((mng_info->clip.left > 0) || (mng_info->clip.top > 0) ||\n                (image_width < mng_info->mng_width) ||\n                (mng_info->clip.right < (ssize_t) mng_info->mng_width) ||\n                (image_height < mng_info->mng_height) ||\n                (mng_info->clip.bottom < (ssize_t) mng_info->mng_height))\n              {\n                if (GetAuthenticPixelQueue(image) != (Quantum *) NULL)\n                  {\n                    /*\n                      Allocate next image structure.\n                    */\n                    AcquireNextImage(image_info,image,exception);\n\n                    if (GetNextImageInList(image) == (Image *) NULL)\n                      return(DestroyImageList(image));\n\n                    image=SyncNextImageInList(image);\n                  }\n                mng_info->image=image;\n\n                if (term_chunk_found)\n                  {\n                    image->start_loop=MagickTrue;\n                    image->iterations=mng_iterations;\n                    term_chunk_found=MagickFalse;\n                  }\n\n                else\n                    image->start_loop=MagickFalse;\n\n                /* Make a background rectangle.  */\n\n                image->delay=0;\n                image->columns=mng_info->mng_width;\n                image->rows=mng_info->mng_height;\n                image->page.width=mng_info->mng_width;\n                image->page.height=mng_info->mng_height;\n                image->page.x=0;\n                image->page.y=0;\n                image->background_color=mng_background_color;\n                (void) SetImageBackgroundColor(image,exception);\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"  Inserted transparent background layer, W=%.20g, H=%.20g\",\n                    (double) mng_info->mng_width,(double) mng_info->mng_height);\n              }\n          }\n        /*\n          Insert a background layer behind the upcoming image if\n          framing_mode is 3, and we haven't already inserted one.\n        */\n        if (insert_layers && (mng_info->framing_mode == 3) &&\n                (subframe_width) && (subframe_height) && (simplicity == 0 ||\n                (simplicity & 0x08)))\n          {\n            if (GetAuthenticPixelQueue(image) != (Quantum *) NULL)\n            {\n              /*\n                Allocate next image structure.\n              */\n              AcquireNextImage(image_info,image,exception);\n\n              if (GetNextImageInList(image) == (Image *) NULL)\n                return(DestroyImageList(image));\n\n              image=SyncNextImageInList(image);\n            }\n\n            mng_info->image=image;\n\n            if (term_chunk_found)\n              {\n                image->start_loop=MagickTrue;\n                image->iterations=mng_iterations;\n                term_chunk_found=MagickFalse;\n              }\n\n            else\n                image->start_loop=MagickFalse;\n\n            image->delay=0;\n            image->columns=subframe_width;\n            image->rows=subframe_height;\n            image->page.width=subframe_width;\n            image->page.height=subframe_height;\n            image->page.x=mng_info->clip.left;\n            image->page.y=mng_info->clip.top;\n            image->background_color=mng_background_color;\n            image->alpha_trait=UndefinedPixelTrait;\n            (void) SetImageBackgroundColor(image,exception);\n\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  Insert background layer, L=%.20g, R=%.20g T=%.20g, B=%.20g\",\n                (double) mng_info->clip.left,(double) mng_info->clip.right,\n                (double) mng_info->clip.top,(double) mng_info->clip.bottom);\n          }\n#endif /* MNG_INSERT_LAYERS */\n        first_mng_object=MagickFalse;\n\n        if (GetAuthenticPixelQueue(image) != (Quantum *) NULL)\n          {\n            /*\n              Allocate next image structure.\n            */\n            AcquireNextImage(image_info,image,exception);\n\n            if (GetNextImageInList(image) == (Image *) NULL)\n              return(DestroyImageList(image));\n\n            image=SyncNextImageInList(image);\n          }\n        mng_info->image=image;\n        status=SetImageProgress(image,LoadImagesTag,TellBlob(image),\n          GetBlobSize(image));\n\n        if (status == MagickFalse)\n          break;\n\n        if (term_chunk_found)\n          {\n            image->start_loop=MagickTrue;\n            term_chunk_found=MagickFalse;\n          }\n\n        else\n            image->start_loop=MagickFalse;\n\n        if (mng_info->framing_mode == 1 || mng_info->framing_mode == 3)\n          {\n            image->delay=frame_delay;\n            frame_delay=default_frame_delay;\n          }\n\n        else\n          image->delay=0;\n\n        image->page.width=mng_info->mng_width;\n        image->page.height=mng_info->mng_height;\n        image->page.x=mng_info->x_off[object_id];\n        image->page.y=mng_info->y_off[object_id];\n        image->iterations=mng_iterations;\n\n        /*\n          Seek back to the beginning of the IHDR or JHDR chunk's length field.\n        */\n\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  Seeking back to beginning of %c%c%c%c chunk\",type[0],type[1],\n            type[2],type[3]);\n\n        offset=SeekBlob(image,-((ssize_t) length+12),SEEK_CUR);\n\n        if (offset < 0)\n          ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n      }\n\n    mng_info->image=image;\n    mng_info->mng_type=mng_type;\n    mng_info->object_id=object_id;\n\n    if (memcmp(type,mng_IHDR,4) == 0)\n      image=ReadOnePNGImage(mng_info,image_info,exception);\n\n#if defined(JNG_SUPPORTED)\n    else\n      image=ReadOneJNGImage(mng_info,image_info,exception);\n#endif\n\n    if (image == (Image *) NULL)\n      {\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"exit ReadJNGImage() with error\");\n\n        return((Image *) NULL);\n      }\n\n    if (image->columns == 0 || image->rows == 0)\n      {\n        (void) CloseBlob(image);\n        return(DestroyImageList(image));\n      }\n\n    mng_info->image=image;\n\n    if (mng_type)\n      {\n        MngBox\n          crop_box;\n\n        if (mng_info->magn_methx || mng_info->magn_methy)\n          {\n            png_uint_32\n               magnified_height,\n               magnified_width;\n\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  Processing MNG MAGN chunk\");\n\n            if (mng_info->magn_methx == 1)\n              {\n                magnified_width=mng_info->magn_ml;\n\n                if (image->columns > 1)\n                   magnified_width += mng_info->magn_mr;\n\n                if (image->columns > 2)\n                   magnified_width += (png_uint_32)\n                      ((image->columns-2)*(mng_info->magn_mx));\n              }\n\n            else\n              {\n                magnified_width=(png_uint_32) image->columns;\n\n                if (image->columns > 1)\n                   magnified_width += mng_info->magn_ml-1;\n\n                if (image->columns > 2)\n                   magnified_width += mng_info->magn_mr-1;\n\n                if (image->columns > 3)\n                   magnified_width += (png_uint_32)\n                      ((image->columns-3)*(mng_info->magn_mx-1));\n              }\n\n            if (mng_info->magn_methy == 1)\n              {\n                magnified_height=mng_info->magn_mt;\n\n                if (image->rows > 1)\n                   magnified_height += mng_info->magn_mb;\n\n                if (image->rows > 2)\n                   magnified_height += (png_uint_32)\n                      ((image->rows-2)*(mng_info->magn_my));\n              }\n\n            else\n              {\n                magnified_height=(png_uint_32) image->rows;\n\n                if (image->rows > 1)\n                   magnified_height += mng_info->magn_mt-1;\n\n                if (image->rows > 2)\n                   magnified_height += mng_info->magn_mb-1;\n\n                if (image->rows > 3)\n                   magnified_height += (png_uint_32)\n                      ((image->rows-3)*(mng_info->magn_my-1));\n              }\n\n            if (magnified_height > image->rows ||\n                magnified_width > image->columns)\n              {\n                Image\n                  *large_image;\n\n                int\n                  yy;\n\n                Quantum\n                  *next,\n                  *prev;\n\n                png_uint_16\n                  magn_methx,\n                  magn_methy;\n\n                ssize_t\n                  m,\n                  y;\n\n                register Quantum\n                  *n,\n                  *q;\n\n                register ssize_t\n                  x;\n\n                /* Allocate next image structure.  */\n\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"    Allocate magnified image\");\n\n                AcquireNextImage(image_info,image,exception);\n\n                if (GetNextImageInList(image) == (Image *) NULL)\n                  return(DestroyImageList(image));\n\n                large_image=SyncNextImageInList(image);\n\n                large_image->columns=magnified_width;\n                large_image->rows=magnified_height;\n\n                magn_methx=mng_info->magn_methx;\n                magn_methy=mng_info->magn_methy;\n\n#if (MAGICKCORE_QUANTUM_DEPTH > 16)\n#define QM unsigned short\n                if (magn_methx != 1 || magn_methy != 1)\n                  {\n                  /*\n                     Scale pixels to unsigned shorts to prevent\n                     overflow of intermediate values of interpolations\n                  */\n                     for (y=0; y < (ssize_t) image->rows; y++)\n                     {\n                       q=GetAuthenticPixels(image,0,y,image->columns,1,\n                          exception);\n\n                       for (x=(ssize_t) image->columns-1; x >= 0; x--)\n                       {\n                          SetPixelRed(image,ScaleQuantumToShort(\n                            GetPixelRed(image,q)),q);\n                          SetPixelGreen(image,ScaleQuantumToShort(\n                            GetPixelGreen(image,q)),q);\n                          SetPixelBlue(image,ScaleQuantumToShort(\n                            GetPixelBlue(image,q)),q);\n                          SetPixelAlpha(image,ScaleQuantumToShort(\n                            GetPixelAlpha(image,q)),q);\n                          q+=GetPixelChannels(image);\n                       }\n\n                       if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                         break;\n                     }\n                  }\n#else\n#define QM Quantum\n#endif\n\n                if (image->alpha_trait != UndefinedPixelTrait)\n                   (void) SetImageBackgroundColor(large_image,exception);\n\n                else\n                  {\n                    large_image->background_color.alpha=OpaqueAlpha;\n                    (void) SetImageBackgroundColor(large_image,exception);\n\n                    if (magn_methx == 4)\n                      magn_methx=2;\n\n                    if (magn_methx == 5)\n                      magn_methx=3;\n\n                    if (magn_methy == 4)\n                      magn_methy=2;\n\n                    if (magn_methy == 5)\n                      magn_methy=3;\n                  }\n\n                /* magnify the rows into the right side of the large image */\n\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"    Magnify the rows to %.20g\",\n                    (double) large_image->rows);\n                m=(ssize_t) mng_info->magn_mt;\n                yy=0;\n                length=(size_t) GetPixelChannels(image)*image->columns;\n                next=(Quantum *) AcquireQuantumMemory(length,sizeof(*next));\n                prev=(Quantum *) AcquireQuantumMemory(length,sizeof(*prev));\n\n                if ((prev == (Quantum *) NULL) ||\n                    (next == (Quantum *) NULL))\n                  {\n                     image=DestroyImageList(image);\n                     ThrowReaderException(ResourceLimitError,\n                       \"MemoryAllocationFailed\");\n                  }\n\n                n=GetAuthenticPixels(image,0,0,image->columns,1,exception);\n                (void) CopyMagickMemory(next,n,length);\n\n                for (y=0; y < (ssize_t) image->rows; y++)\n                {\n                  if (y == 0)\n                    m=(ssize_t) mng_info->magn_mt;\n\n                  else if (magn_methy > 1 && y == (ssize_t) image->rows-2)\n                    m=(ssize_t) mng_info->magn_mb;\n\n                  else if (magn_methy <= 1 && y == (ssize_t) image->rows-1)\n                    m=(ssize_t) mng_info->magn_mb;\n\n                  else if (magn_methy > 1 && y == (ssize_t) image->rows-1)\n                    m=1;\n\n                  else\n                    m=(ssize_t) mng_info->magn_my;\n\n                  n=prev;\n                  prev=next;\n                  next=n;\n\n                  if (y < (ssize_t) image->rows-1)\n                    {\n                      n=GetAuthenticPixels(image,0,y+1,image->columns,1,\n                          exception);\n                      (void) CopyMagickMemory(next,n,length);\n                    }\n\n                  for (i=0; i < m; i++, yy++)\n                  {\n                    register Quantum\n                      *pixels;\n\n                    assert(yy < (ssize_t) large_image->rows);\n                    pixels=prev;\n                    n=next;\n                    q=GetAuthenticPixels(large_image,0,yy,large_image->columns,\n                      1,exception);\n                    q+=(large_image->columns-image->columns)*\n                      GetPixelChannels(large_image);\n\n                    for (x=(ssize_t) image->columns-1; x >= 0; x--)\n                    {\n                      /* To do: get color as function of indexes[x] */\n                      /*\n                      if (image->storage_class == PseudoClass)\n                        {\n                        }\n                      */\n\n                      if (magn_methy <= 1)\n                        {\n                          /* replicate previous */\n                          SetPixelRed(large_image,GetPixelRed(image,pixels),q);\n                          SetPixelGreen(large_image,GetPixelGreen(image,\n                             pixels),q);\n                          SetPixelBlue(large_image,GetPixelBlue(image,\n                             pixels),q);\n                          SetPixelAlpha(large_image,GetPixelAlpha(image,\n                             pixels),q);\n                        }\n\n                      else if (magn_methy == 2 || magn_methy == 4)\n                        {\n                          if (i == 0)\n                            {\n                              SetPixelRed(large_image,GetPixelRed(image,\n                                 pixels),q);\n                              SetPixelGreen(large_image,GetPixelGreen(image,\n                                 pixels),q);\n                              SetPixelBlue(large_image,GetPixelBlue(image,\n                                 pixels),q);\n                              SetPixelAlpha(large_image,GetPixelAlpha(image,\n                                 pixels),q);\n                            }\n\n                          else\n                            {\n                              /* Interpolate */\n                              SetPixelRed(large_image,((QM) (((ssize_t)\n                                 (2*i*(GetPixelRed(image,n)\n                                 -GetPixelRed(image,pixels)+m))/\n                                 ((ssize_t) (m*2))\n                                 +GetPixelRed(image,pixels)))),q);\n                              SetPixelGreen(large_image,((QM) (((ssize_t)\n                                 (2*i*(GetPixelGreen(image,n)\n                                 -GetPixelGreen(image,pixels)+m))/\n                                 ((ssize_t) (m*2))\n                                 +GetPixelGreen(image,pixels)))),q);\n                              SetPixelBlue(large_image,((QM) (((ssize_t)\n                                 (2*i*(GetPixelBlue(image,n)\n                                 -GetPixelBlue(image,pixels)+m))/\n                                 ((ssize_t) (m*2))\n                                 +GetPixelBlue(image,pixels)))),q);\n\n                              if (image->alpha_trait != UndefinedPixelTrait)\n                                 SetPixelAlpha(large_image, ((QM) (((ssize_t)\n                                    (2*i*(GetPixelAlpha(image,n)\n                                    -GetPixelAlpha(image,pixels)+m))\n                                    /((ssize_t) (m*2))+\n                                   GetPixelAlpha(image,pixels)))),q);\n                            }\n\n                          if (magn_methy == 4)\n                            {\n                              /* Replicate nearest */\n                              if (i <= ((m+1) << 1))\n                                 SetPixelAlpha(large_image,GetPixelAlpha(image,\n                                    pixels),q);\n                              else\n                                 SetPixelAlpha(large_image,GetPixelAlpha(image,\n                                    n),q);\n                            }\n                        }\n\n                      else /* if (magn_methy == 3 || magn_methy == 5) */\n                        {\n                          /* Replicate nearest */\n                          if (i <= ((m+1) << 1))\n                          {\n                             SetPixelRed(large_image,GetPixelRed(image,\n                                    pixels),q);\n                             SetPixelGreen(large_image,GetPixelGreen(image,\n                                    pixels),q);\n                             SetPixelBlue(large_image,GetPixelBlue(image,\n                                    pixels),q);\n                             SetPixelAlpha(large_image,GetPixelAlpha(image,\n                                    pixels),q);\n                          }\n\n                          else\n                          {\n                             SetPixelRed(large_image,GetPixelRed(image,n),q);\n                             SetPixelGreen(large_image,GetPixelGreen(image,n),\n                                    q);\n                             SetPixelBlue(large_image,GetPixelBlue(image,n),\n                                    q);\n                             SetPixelAlpha(large_image,GetPixelAlpha(image,n),\n                                    q);\n                          }\n\n                          if (magn_methy == 5)\n                            {\n                              SetPixelAlpha(large_image,(QM) (((ssize_t) (2*i*\n                                 (GetPixelAlpha(image,n)\n                                 -GetPixelAlpha(image,pixels))\n                                 +m))/((ssize_t) (m*2))\n                                 +GetPixelAlpha(image,pixels)),q);\n                            }\n                        }\n                      n+=GetPixelChannels(image);\n                      q+=GetPixelChannels(large_image);\n                      pixels+=GetPixelChannels(image);\n                    } /* x */\n\n                    if (SyncAuthenticPixels(large_image,exception) == 0)\n                      break;\n\n                  } /* i */\n                } /* y */\n\n                prev=(Quantum *) RelinquishMagickMemory(prev);\n                next=(Quantum *) RelinquishMagickMemory(next);\n\n                length=image->columns;\n\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"    Delete original image\");\n\n                DeleteImageFromList(&image);\n\n                image=large_image;\n\n                mng_info->image=image;\n\n                /* magnify the columns */\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"    Magnify the columns to %.20g\",\n                    (double) image->columns);\n\n                for (y=0; y < (ssize_t) image->rows; y++)\n                {\n                  register Quantum\n                    *pixels;\n\n                  q=GetAuthenticPixels(image,0,y,image->columns,1,exception);\n                  pixels=q+(image->columns-length)*GetPixelChannels(image);\n                  n=pixels+GetPixelChannels(image);\n\n                  for (x=(ssize_t) (image->columns-length);\n                    x < (ssize_t) image->columns; x++)\n                  {\n                    /* To do: Rewrite using Get/Set***PixelChannel() */\n\n                    if (x == (ssize_t) (image->columns-length))\n                      m=(ssize_t) mng_info->magn_ml;\n\n                    else if (magn_methx > 1 && x == (ssize_t) image->columns-2)\n                      m=(ssize_t) mng_info->magn_mr;\n\n                    else if (magn_methx <= 1 &&\n                        x == (ssize_t) image->columns-1)\n                      m=(ssize_t) mng_info->magn_mr;\n\n                    else if (magn_methx > 1 && x == (ssize_t) image->columns-1)\n                      m=1;\n\n                    else\n                      m=(ssize_t) mng_info->magn_mx;\n\n                    for (i=0; i < m; i++)\n                    {\n                      if (magn_methx <= 1)\n                        {\n                          /* replicate previous */\n                          SetPixelRed(image,GetPixelRed(image,pixels),q);\n                          SetPixelGreen(image,GetPixelGreen(image,pixels),q);\n                          SetPixelBlue(image,GetPixelBlue(image,pixels),q);\n                          SetPixelAlpha(image,GetPixelAlpha(image,pixels),q);\n                        }\n\n                      else if (magn_methx == 2 || magn_methx == 4)\n                        {\n                          if (i == 0)\n                          {\n                            SetPixelRed(image,GetPixelRed(image,pixels),q);\n                            SetPixelGreen(image,GetPixelGreen(image,pixels),q);\n                            SetPixelBlue(image,GetPixelBlue(image,pixels),q);\n                            SetPixelAlpha(image,GetPixelAlpha(image,pixels),q);\n                          }\n\n                          /* To do: Rewrite using Get/Set***PixelChannel() */\n                          else\n                            {\n                              /* Interpolate */\n                              SetPixelRed(image,(QM) ((2*i*(\n                                 GetPixelRed(image,n)\n                                 -GetPixelRed(image,pixels))+m)\n                                 /((ssize_t) (m*2))+\n                                 GetPixelRed(image,pixels)),q);\n\n                              SetPixelGreen(image,(QM) ((2*i*(\n                                 GetPixelGreen(image,n)\n                                 -GetPixelGreen(image,pixels))+m)\n                                 /((ssize_t) (m*2))+\n                                 GetPixelGreen(image,pixels)),q);\n\n                              SetPixelBlue(image,(QM) ((2*i*(\n                                 GetPixelBlue(image,n)\n                                 -GetPixelBlue(image,pixels))+m)\n                                 /((ssize_t) (m*2))+\n                                 GetPixelBlue(image,pixels)),q);\n                              if (image->alpha_trait != UndefinedPixelTrait)\n                                 SetPixelAlpha(image,(QM) ((2*i*(\n                                   GetPixelAlpha(image,n)\n                                   -GetPixelAlpha(image,pixels))+m)\n                                   /((ssize_t) (m*2))+\n                                   GetPixelAlpha(image,pixels)),q);\n                            }\n\n                          if (magn_methx == 4)\n                            {\n                              /* Replicate nearest */\n                              if (i <= ((m+1) << 1))\n                              {\n                                 SetPixelAlpha(image,\n                                   GetPixelAlpha(image,pixels)+0,q);\n                              }\n                              else\n                              {\n                                 SetPixelAlpha(image,\n                                   GetPixelAlpha(image,n)+0,q);\n                              }\n                            }\n                        }\n\n                      else /* if (magn_methx == 3 || magn_methx == 5) */\n                        {\n                          /* Replicate nearest */\n                          if (i <= ((m+1) << 1))\n                          {\n                             SetPixelRed(image,GetPixelRed(image,pixels),q);\n                             SetPixelGreen(image,GetPixelGreen(image,\n                                 pixels),q);\n                             SetPixelBlue(image,GetPixelBlue(image,pixels),q);\n                             SetPixelAlpha(image,GetPixelAlpha(image,\n                                 pixels),q);\n                          }\n\n                          else\n                          {\n                             SetPixelRed(image,GetPixelRed(image,n),q);\n                             SetPixelGreen(image,GetPixelGreen(image,n),q);\n                             SetPixelBlue(image,GetPixelBlue(image,n),q);\n                             SetPixelAlpha(image,GetPixelAlpha(image,n),q);\n                          }\n\n                          if (magn_methx == 5)\n                            {\n                              /* Interpolate */\n                              SetPixelAlpha(image,\n                                 (QM) ((2*i*( GetPixelAlpha(image,n)\n                                 -GetPixelAlpha(image,pixels))+m)/\n                                 ((ssize_t) (m*2))\n                                 +GetPixelAlpha(image,pixels)),q);\n                            }\n                        }\n                      q+=GetPixelChannels(image);\n                    }\n                    n+=GetPixelChannels(image);\n                  }\n\n                  if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                    break;\n                }\n#if (MAGICKCORE_QUANTUM_DEPTH > 16)\n              if (magn_methx != 1 || magn_methy != 1)\n                {\n                /*\n                   Rescale pixels to Quantum\n                */\n                   for (y=0; y < (ssize_t) image->rows; y++)\n                   {\n                     q=GetAuthenticPixels(image,0,y,image->columns,1,\n                       exception);\n\n                     for (x=(ssize_t) image->columns-1; x >= 0; x--)\n                     {\n                        SetPixelRed(image,ScaleShortToQuantum(\n                          GetPixelRed(image,q)),q);\n                        SetPixelGreen(image,ScaleShortToQuantum(\n                          GetPixelGreen(image,q)),q);\n                        SetPixelBlue(image,ScaleShortToQuantum(\n                          GetPixelBlue(image,q)),q);\n                        SetPixelAlpha(image,ScaleShortToQuantum(\n                          GetPixelAlpha(image,q)),q);\n                        q+=GetPixelChannels(image);\n                     }\n\n                     if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                       break;\n                   }\n                }\n#endif\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"  Finished MAGN processing\");\n              }\n          }\n\n        /*\n          Crop_box is with respect to the upper left corner of the MNG.\n        */\n        crop_box.left=mng_info->image_box.left+mng_info->x_off[object_id];\n        crop_box.right=mng_info->image_box.right+mng_info->x_off[object_id];\n        crop_box.top=mng_info->image_box.top+mng_info->y_off[object_id];\n        crop_box.bottom=mng_info->image_box.bottom+mng_info->y_off[object_id];\n        crop_box=mng_minimum_box(crop_box,mng_info->clip);\n        crop_box=mng_minimum_box(crop_box,mng_info->frame);\n        crop_box=mng_minimum_box(crop_box,mng_info->object_clip[object_id]);\n        if ((crop_box.left != (mng_info->image_box.left\n            +mng_info->x_off[object_id])) ||\n            (crop_box.right != (mng_info->image_box.right\n            +mng_info->x_off[object_id])) ||\n            (crop_box.top != (mng_info->image_box.top\n            +mng_info->y_off[object_id])) ||\n            (crop_box.bottom != (mng_info->image_box.bottom\n            +mng_info->y_off[object_id])))\n          {\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  Crop the PNG image\");\n\n            if ((crop_box.left < crop_box.right) &&\n                (crop_box.top < crop_box.bottom))\n              {\n                Image\n                  *im;\n\n                RectangleInfo\n                  crop_info;\n\n                /*\n                  Crop_info is with respect to the upper left corner of\n                  the image.\n                */\n                crop_info.x=(crop_box.left-mng_info->x_off[object_id]);\n                crop_info.y=(crop_box.top-mng_info->y_off[object_id]);\n                crop_info.width=(size_t) (crop_box.right-crop_box.left);\n                crop_info.height=(size_t) (crop_box.bottom-crop_box.top);\n                image->page.width=image->columns;\n                image->page.height=image->rows;\n                image->page.x=0;\n                image->page.y=0;\n                im=CropImage(image,&crop_info,exception);\n\n                if (im != (Image *) NULL)\n                  {\n                    image->columns=im->columns;\n                    image->rows=im->rows;\n                    im=DestroyImage(im);\n                    image->page.width=image->columns;\n                    image->page.height=image->rows;\n                    image->page.x=crop_box.left;\n                    image->page.y=crop_box.top;\n                  }\n              }\n\n            else\n              {\n                /*\n                  No pixels in crop area.  The MNG spec still requires\n                  a layer, though, so make a single transparent pixel in\n                  the top left corner.\n                */\n                image->columns=1;\n                image->rows=1;\n                image->colors=2;\n                (void) SetImageBackgroundColor(image,exception);\n                image->page.width=1;\n                image->page.height=1;\n                image->page.x=0;\n                image->page.y=0;\n              }\n          }\n#ifndef PNG_READ_EMPTY_PLTE_SUPPORTED\n        image=mng_info->image;\n#endif\n      }\n\n#if (MAGICKCORE_QUANTUM_DEPTH > 16)\n      /* PNG does not handle depths greater than 16 so reduce it even\n       * if lossy.\n       */\n      if (image->depth > 16)\n         image->depth=16;\n#endif\n\n#if (MAGICKCORE_QUANTUM_DEPTH > 8)\n      if (image->depth > 8)\n        {\n          /* To do: fill low byte properly */\n          image->depth=16;\n        }\n\n      if (LosslessReduceDepthOK(image,exception) != MagickFalse)\n         image->depth = 8;\n#endif\n\n      if (image_info->number_scenes != 0)\n        {\n          if (mng_info->scenes_found >\n             (ssize_t) (image_info->first_scene+image_info->number_scenes))\n            break;\n        }\n\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  Finished reading image datastream.\");\n\n  } while (LocaleCompare(image_info->magick,\"MNG\") == 0);\n\n  (void) CloseBlob(image);\n\n  if (logging != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"  Finished reading all image datastreams.\");\n\n#if defined(MNG_INSERT_LAYERS)\n  if (insert_layers && !mng_info->image_found && (mng_info->mng_width) &&\n       (mng_info->mng_height))\n    {\n      /*\n        Insert a background layer if nothing else was found.\n      */\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  No images found.  Inserting a background layer.\");\n\n      if (GetAuthenticPixelQueue(image) != (Quantum *) NULL)\n        {\n          /*\n            Allocate next image structure.\n          */\n          AcquireNextImage(image_info,image,exception);\n          if (GetNextImageInList(image) == (Image *) NULL)\n            {\n              if (logging != MagickFalse)\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"  Allocation failed, returning NULL.\");\n\n              return(DestroyImageList(image));;\n            }\n          image=SyncNextImageInList(image);\n        }\n      image->columns=mng_info->mng_width;\n      image->rows=mng_info->mng_height;\n      image->page.width=mng_info->mng_width;\n      image->page.height=mng_info->mng_height;\n      image->page.x=0;\n      image->page.y=0;\n      image->background_color=mng_background_color;\n      image->alpha_trait=UndefinedPixelTrait;\n\n      if (image_info->ping == MagickFalse)\n        (void) SetImageBackgroundColor(image,exception);\n\n      mng_info->image_found++;\n    }\n#endif\n  image->iterations=mng_iterations;\n\n  if (mng_iterations == 1)\n    image->start_loop=MagickTrue;\n\n  while (GetPreviousImageInList(image) != (Image *) NULL)\n  {\n    image_count++;\n    if (image_count > 10*mng_info->image_found)\n      {\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\"  No beginning\");\n\n        (void) ThrowMagickException(exception,GetMagickModule(),\n          CoderError,\"Linked list is corrupted, beginning of list not found\",\n          \"`%s'\",image_info->filename);\n\n        return(DestroyImageList(image));\n      }\n\n    image=GetPreviousImageInList(image);\n\n    if (GetNextImageInList(image) == (Image *) NULL)\n      {\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\"  Corrupt list\");\n\n        (void) ThrowMagickException(exception,GetMagickModule(),\n          CoderError,\"Linked list is corrupted; next_image is NULL\",\"`%s'\",\n          image_info->filename);\n      }\n  }\n\n  if (mng_info->ticks_per_second && mng_info->image_found > 1 &&\n             GetNextImageInList(image) ==\n     (Image *) NULL)\n    {\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  First image null\");\n\n      (void) ThrowMagickException(exception,GetMagickModule(),\n        CoderError,\"image->next for first image is NULL but shouldn't be.\",\n        \"`%s'\",image_info->filename);\n    }\n\n  if (mng_info->image_found == 0)\n    {\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  No visible images found.\");\n\n      (void) ThrowMagickException(exception,GetMagickModule(),\n        CoderError,\"No visible images in file\",\"`%s'\",image_info->filename);\n\n      return(DestroyImageList(image));\n    }\n\n  if (mng_info->ticks_per_second)\n    final_delay=1UL*MagickMax(image->ticks_per_second,1L)*\n            final_delay/mng_info->ticks_per_second;\n\n  else\n    image->start_loop=MagickTrue;\n\n  /* Find final nonzero image delay */\n  final_image_delay=0;\n\n  while (GetNextImageInList(image) != (Image *) NULL)\n    {\n      if (image->delay)\n        final_image_delay=image->delay;\n\n      image=GetNextImageInList(image);\n    }\n\n  if (final_delay < final_image_delay)\n    final_delay=final_image_delay;\n\n  image->delay=final_delay;\n\n  if (logging != MagickFalse)\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"  image->delay=%.20g, final_delay=%.20g\",(double) image->delay,\n        (double) final_delay);\n\n  if (logging != MagickFalse)\n    {\n      int\n        scene;\n\n      scene=0;\n      image=GetFirstImageInList(image);\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"  Before coalesce:\");\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"    scene 0 delay=%.20g\",(double) image->delay);\n\n      while (GetNextImageInList(image) != (Image *) NULL)\n      {\n        image=GetNextImageInList(image);\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"    scene %.20g delay=%.20g\",(double) scene++,\n          (double) image->delay);\n      }\n    }\n\n  image=GetFirstImageInList(image);\n#ifdef MNG_COALESCE_LAYERS\n  if (insert_layers)\n    {\n      Image\n        *next_image,\n        *next;\n\n      size_t\n        scene;\n\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  Coalesce Images\");\n\n      scene=image->scene;\n      next_image=CoalesceImages(image,exception);\n\n      if (next_image == (Image *) NULL)\n        ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n\n      image=DestroyImageList(image);\n      image=next_image;\n\n      for (next=image; next != (Image *) NULL; next=next_image)\n      {\n         next->page.width=mng_info->mng_width;\n         next->page.height=mng_info->mng_height;\n         next->page.x=0;\n         next->page.y=0;\n         next->scene=scene++;\n         next_image=GetNextImageInList(next);\n\n         if (next_image == (Image *) NULL)\n           break;\n\n         if (next->delay == 0)\n           {\n             scene--;\n             next_image->previous=GetPreviousImageInList(next);\n             if (GetPreviousImageInList(next) == (Image *) NULL)\n               image=next_image;\n             else\n               next->previous->next=next_image;\n             next=DestroyImage(next);\n           }\n      }\n    }\n#endif\n\n  while (GetNextImageInList(image) != (Image *) NULL)\n      image=GetNextImageInList(image);\n\n  image->dispose=BackgroundDispose;\n\n  if (logging != MagickFalse)\n    {\n      int\n        scene;\n\n      scene=0;\n      image=GetFirstImageInList(image);\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"  After coalesce:\");\n\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"    scene 0 delay=%.20g dispose=%.20g\",(double) image->delay,\n        (double) image->dispose);\n\n      while (GetNextImageInList(image) != (Image *) NULL)\n      {\n        image=GetNextImageInList(image);\n\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"    scene %.20g delay=%.20g dispose=%.20g\",(double) scene++,\n          (double) image->delay,(double) image->dispose);\n      }\n   }\n\n  if (logging != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"  exit ReadOneMNGImage();\");\n\n  return(image);\n}",
        "func_hash": 112335411773175147602521832461985951659,
        "file_name": "png.c",
        "file_hash": 320300249685897026258566713334395171716,
        "cwe": [
            "CWE-125"
        ],
        "cve": "CVE-2017-13139",
        "cve_desc": "In ImageMagick before 6.9.9-0 and 7.x before 7.0.6-1, the ReadOneMNGImage function in coders/png.c has an out-of-bounds read with the MNG CLIP chunk.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2017-13139",
        "func_name": "ReadOneMNGImage",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195954,
        "project": "pjproject",
        "commit_id": "9fae8f43accef8ea65d4a8ae9cdf297c46cfe29a",
        "project_url": "https://github.com/pjsip/pjproject",
        "commit_url": "https://github.com/pjsip/pjproject/commit/9fae8f43accef8ea65d4a8ae9cdf297c46cfe29a",
        "commit_message": "Merge pull request from GHSA-p6g5-v97c-w5q4\n\n* Prevent heap buffer overflow when parsing DNS packets\n\n* Make sure packet parsing doesn't advance beyond max/end\n\n* Update checks\n\n* Remove  check\n\nCo-authored-by: sauwming <ming@teluu.com>",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static pj_status_t parse_query(pj_dns_parsed_query *q, pj_pool_t *pool,\n\t\t\t       const pj_uint8_t *pkt, const pj_uint8_t *start,\n\t\t\t       const pj_uint8_t *max, int *parsed_len)\n{\n    const pj_uint8_t *p = start;\n    int name_len, name_part_len;\n    pj_status_t status;\n\n    /* Get the length of the name */\n    status = get_name_len(0, pkt, start, max, &name_part_len, &name_len);\n    if (status != PJ_SUCCESS)\n\treturn status;\n\n    /* Allocate memory for the name */\n    q->name.ptr = (char*) pj_pool_alloc(pool, name_len+4);\n    q->name.slen = 0;\n\n    /* Get the name */\n    status = get_name(0, pkt, start, max, &q->name);\n    if (status != PJ_SUCCESS)\n\treturn status;\n\n    p = (start + name_part_len);\n\n    /* Get the type */\n    pj_memcpy(&q->type, p, 2);\n    q->type = pj_ntohs(q->type);\n    p += 2;\n\n    /* Get the class */\n    pj_memcpy(&q->dnsclass, p, 2);\n    q->dnsclass = pj_ntohs(q->dnsclass);\n    p += 2;\n\n    *parsed_len = (int)(p - start);\n\n    return PJ_SUCCESS;\n}",
        "func_hash": 135450072303259419822933820270333517166,
        "file_name": "dns.c",
        "file_hash": 253652259492393007596255371845847130395,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2022-24793",
        "cve_desc": "PJSIP is a free and open source multimedia communication library written in C. A buffer overflow vulnerability in versions 2.12 and prior affects applications that use PJSIP DNS resolution. It doesn't affect PJSIP users who utilize an external resolver. This vulnerability is related to CVE-2023-27585. The difference is that this issue is in parsing the query record `parse_rr()`, while the issue in CVE-2023-27585 is in `parse_query()`. A patch is available in the `master` branch of the `pjsip/pjproject` GitHub repository. A workaround is to disable DNS resolution in PJSIP config (by setting `nameserver_count` to zero) or use an external resolver instead.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-24793",
        "func_name": "parse_query",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195965,
        "project": "tensorflow",
        "commit_id": "30721cf564cb029d34535446d6a5a6357bebc8e7",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/30721cf564cb029d34535446d6a5a6357bebc8e7",
        "commit_message": "Fix tf.raw_ops.EditDistance vulnerability with negative indices.\n\nCheck that indices are non-negative. Fix several identical code sites.\nClean up grammar in error message.\n\nPiperOrigin-RevId: 445442017",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor* hypothesis_indices;\n    const Tensor* hypothesis_values;\n    const Tensor* hypothesis_shape;\n    const Tensor* truth_indices;\n    const Tensor* truth_values;\n    const Tensor* truth_shape;\n    OP_REQUIRES_OK(ctx, ctx->input(\"hypothesis_indices\", &hypothesis_indices));\n    OP_REQUIRES_OK(ctx, ctx->input(\"hypothesis_values\", &hypothesis_values));\n    OP_REQUIRES_OK(ctx, ctx->input(\"hypothesis_shape\", &hypothesis_shape));\n    OP_REQUIRES_OK(ctx, ctx->input(\"truth_indices\", &truth_indices));\n    OP_REQUIRES_OK(ctx, ctx->input(\"truth_values\", &truth_values));\n    OP_REQUIRES_OK(ctx, ctx->input(\"truth_shape\", &truth_shape));\n\n    OP_REQUIRES_OK(\n        ctx, ValidateShapes(ctx, *hypothesis_indices, *hypothesis_values,\n                            *hypothesis_shape, *truth_indices, *truth_values,\n                            *truth_shape));\n\n    TensorShape hypothesis_st_shape;\n    OP_REQUIRES_OK(ctx,\n                   TensorShapeUtils::MakeShape(\n                       hypothesis_shape->vec<int64_t>().data(),\n                       hypothesis_shape->NumElements(), &hypothesis_st_shape));\n    TensorShape truth_st_shape;\n    OP_REQUIRES_OK(ctx, TensorShapeUtils::MakeShape(\n                            truth_shape->vec<int64_t>().data(),\n                            truth_shape->NumElements(), &truth_st_shape));\n\n    // Assume indices are sorted in row-major order.\n    std::vector<int64_t> sorted_order(truth_st_shape.dims());\n    std::iota(sorted_order.begin(), sorted_order.end(), 0);\n\n    sparse::SparseTensor hypothesis;\n    OP_REQUIRES_OK(ctx, sparse::SparseTensor::Create(\n                            *hypothesis_indices, *hypothesis_values,\n                            hypothesis_st_shape, sorted_order, &hypothesis));\n\n    sparse::SparseTensor truth;\n    OP_REQUIRES_OK(ctx, sparse::SparseTensor::Create(\n                            *truth_indices, *truth_values, truth_st_shape,\n                            sorted_order, &truth));\n\n    // Group dims 0, 1, ..., RANK - 1.  The very last dim is assumed\n    // to store the variable length sequences.\n    std::vector<int64_t> group_dims(truth_st_shape.dims() - 1);\n    std::iota(group_dims.begin(), group_dims.end(), 0);\n\n    TensorShape output_shape;\n    for (int d = 0; d < static_cast<int>(group_dims.size()); ++d) {\n      output_shape.AddDim(std::max(hypothesis_st_shape.dim_size(d),\n                                   truth_st_shape.dim_size(d)));\n    }\n    const auto output_elements = output_shape.num_elements();\n    OP_REQUIRES(\n        ctx, output_elements > 0,\n        errors::InvalidArgument(\"Got output shape \", output_shape.DebugString(),\n                                \" which has 0 elements\"));\n\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->allocate_output(\"output\", output_shape, &output));\n    auto output_t = output->flat<float>();\n    output_t.setZero();\n\n    std::vector<int64_t> output_strides(output_shape.dims());\n    output_strides[output_shape.dims() - 1] = 1;\n    for (int d = output_shape.dims() - 2; d >= 0; --d) {\n      output_strides[d] = output_strides[d + 1] * output_shape.dim_size(d + 1);\n    }\n\n    auto hypothesis_grouper = hypothesis.group(group_dims);\n    auto truth_grouper = truth.group(group_dims);\n\n    auto hypothesis_iter = hypothesis_grouper.begin();\n    auto truth_iter = truth_grouper.begin();\n\n    auto cmp = std::equal_to<T>();\n\n    while (hypothesis_iter != hypothesis_grouper.end() &&\n           truth_iter != truth_grouper.end()) {\n      sparse::Group truth_i = *truth_iter;\n      sparse::Group hypothesis_j = *hypothesis_iter;\n      std::vector<int64_t> g_truth = truth_i.group();\n      std::vector<int64_t> g_hypothesis = hypothesis_j.group();\n      auto truth_seq = truth_i.values<T>();\n      auto hypothesis_seq = hypothesis_j.values<T>();\n\n      if (g_truth == g_hypothesis) {\n        auto loc = std::inner_product(g_truth.begin(), g_truth.end(),\n                                      output_strides.begin(), int64_t{0});\n        OP_REQUIRES(\n            ctx, loc < output_elements,\n            errors::Internal(\"Got an inner product \", loc,\n                             \" which would require in writing to outside of \"\n                             \"the buffer for the output tensor (max elements \",\n                             output_elements, \")\"));\n        output_t(loc) =\n            gtl::LevenshteinDistance<T>(truth_seq, hypothesis_seq, cmp);\n        if (normalize_) output_t(loc) /= truth_seq.size();\n\n        ++hypothesis_iter;\n        ++truth_iter;\n      } else if (g_truth > g_hypothesis) {  // zero-length truth\n        auto loc = std::inner_product(g_hypothesis.begin(), g_hypothesis.end(),\n                                      output_strides.begin(), int64_t{0});\n        OP_REQUIRES(\n            ctx, loc < output_elements,\n            errors::Internal(\"Got an inner product \", loc,\n                             \" which would require in writing to outside of \"\n                             \"the buffer for the output tensor (max elements \",\n                             output_elements, \")\"));\n        output_t(loc) = hypothesis_seq.size();\n        if (normalize_ && output_t(loc) != 0.0f) {\n          output_t(loc) = std::numeric_limits<float>::infinity();\n        }\n        ++hypothesis_iter;\n      } else {  // zero-length hypothesis\n        auto loc = std::inner_product(g_truth.begin(), g_truth.end(),\n                                      output_strides.begin(), int64_t{0});\n        OP_REQUIRES(\n            ctx, loc < output_elements,\n            errors::Internal(\"Got an inner product \", loc,\n                             \" which would require in writing to outside of \"\n                             \"the buffer for the output tensor (max elements \",\n                             output_elements, \")\"));\n        output_t(loc) = (normalize_) ? 1.0 : truth_seq.size();\n        ++truth_iter;\n      }\n    }\n    while (hypothesis_iter != hypothesis_grouper.end()) {  // zero-length truths\n      sparse::Group hypothesis_j = *hypothesis_iter;\n      std::vector<int64_t> g_hypothesis = hypothesis_j.group();\n      auto hypothesis_seq = hypothesis_j.values<T>();\n      auto loc = std::inner_product(g_hypothesis.begin(), g_hypothesis.end(),\n                                    output_strides.begin(), int64_t{0});\n      OP_REQUIRES(\n          ctx, loc < output_elements,\n          errors::Internal(\"Got an inner product \", loc,\n                           \" which would require in writing to outside of the \"\n                           \"buffer for the output tensor (max elements \",\n                           output_elements, \")\"));\n      output_t(loc) = hypothesis_seq.size();\n      if (normalize_ && output_t(loc) != 0.0f) {\n        output_t(loc) = std::numeric_limits<float>::infinity();\n      }\n      ++hypothesis_iter;\n    }\n    while (truth_iter != truth_grouper.end()) {  // missing hypotheses\n      sparse::Group truth_i = *truth_iter;\n      std::vector<int64_t> g_truth = truth_i.group();\n      auto truth_seq = truth_i.values<T>();\n      auto loc = std::inner_product(g_truth.begin(), g_truth.end(),\n                                    output_strides.begin(), int64_t{0});\n      OP_REQUIRES(\n          ctx, loc < output_elements,\n          errors::Internal(\"Got an inner product \", loc,\n                           \" which would require in writing to outside of the \"\n                           \"buffer for the output tensor (max elements \",\n                           output_elements, \")\"));\n      output_t(loc) = (normalize_) ? 1.0 : truth_seq.size();\n      ++truth_iter;\n    }\n  }",
        "func_hash": 330908344605810468129440704571471984591,
        "file_name": "edit_distance_op.cc",
        "file_hash": 218278977682570302037113861275408263141,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2022-29208",
        "cve_desc": "TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, the implementation of `tf.raw_ops.EditDistance` has incomplete validation. Users can pass negative values to cause a segmentation fault based denial of service. In multiple places throughout the code, one may compute an index for a write operation. However, the existing validation only checks against the upper bound of the array. Hence, it is possible to write before the array by massaging the input to generate negative values for `loc`. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-29208",
        "func_name": "Compute",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195984,
        "project": "gpac",
        "commit_id": "3dbe11b37d65c8472faf0654410068e5500b3adb",
        "project_url": "https://github.com/gpac/gpac",
        "commit_url": "https://github.com/gpac/gpac/commit/3dbe11b37d65c8472faf0654410068e5500b3adb",
        "commit_message": "fixed #2175",
        "target": 1,
        "irrelevant": 1,
        "func_before": "GF_Err diST_box_read(GF_Box *s, GF_BitStream *bs)\n{\n\tu32 i;\n\tchar str[1024];\n\tGF_DIMSScriptTypesBox *p = (GF_DIMSScriptTypesBox *)s;\n\n\ti=0;\n\tstr[0]=0;\n\twhile (1) {\n\t\tstr[i] = gf_bs_read_u8(bs);\n\t\tif (!str[i]) break;\n\t\ti++;\n\t}\n\tISOM_DECREASE_SIZE(p, i);\n\n\tp->content_script_types = gf_strdup(str);\n\treturn GF_OK;\n}",
        "func_hash": 337508066102203205232219987774332438264,
        "file_name": "box_code_3gpp.c",
        "file_hash": 236995747067078276861335410375287788449,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2022-1441",
        "cve_desc": "MP4Box is a component of GPAC-2.0.0, which is a widely-used third-party package on RPM Fusion. When MP4Box tries to parse a MP4 file, it calls the function `diST_box_read()` to read from video. In this function, it allocates a buffer `str` with fixed length. However, content read from `bs` is controllable by user, so is the length, which causes a buffer overflow.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-1441",
        "func_name": "diST_box_read",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 196231,
        "project": "tensorflow",
        "commit_id": "b619c6f865715ca3b15ef1842b5b95edbaa710ad",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/b619c6f865715ca3b15ef1842b5b95edbaa710ad",
        "commit_message": "Use BuildTensorShapeBase when parsing unverified TensorShapes during checkpoint loading.\n\nThis avoids crashing when the TensorShape has negative dimensions.\n\nPiperOrigin-RevId: 392769882\nChange-Id: Id1f7ae7fcf8142193556af47abfda81b13d3cce4",
        "target": 1,
        "irrelevant": 0,
        "func_before": "void TensorSliceReader::LoadShard(int shard) const {\n  CHECK_LT(shard, sss_.size());\n  if (sss_[shard] || !status_.ok()) {\n    return;  // Already loaded, or invalid.\n  }\n  string value;\n  SavedTensorSlices sts;\n  const string fname = fnames_[shard];\n  VLOG(1) << \"Reading meta data from file \" << fname << \"...\";\n  Table* table;\n  Status s = open_function_(fname, &table);\n  if (!s.ok()) {\n    status_ = errors::DataLoss(\"Unable to open table file \", fname, \": \",\n                               s.ToString());\n    return;\n  }\n  sss_[shard].reset(table);\n  if (!(table->Get(kSavedTensorSlicesKey, &value) &&\n        ParseProtoUnlimited(&sts, value))) {\n    status_ = errors::Internal(\n        \"Failed to find the saved tensor slices at the beginning of the \"\n        \"checkpoint file: \",\n        fname);\n    return;\n  }\n  status_ = CheckVersions(sts.meta().versions(), TF_CHECKPOINT_VERSION,\n                          TF_CHECKPOINT_VERSION_MIN_PRODUCER, \"Checkpoint\",\n                          \"checkpoint\");\n  if (!status_.ok()) return;\n  for (const SavedSliceMeta& ssm : sts.meta().tensor()) {\n    TensorShape ssm_shape(ssm.shape());\n    for (const TensorSliceProto& tsp : ssm.slice()) {\n      TensorSlice ss_slice(tsp);\n      status_ = RegisterTensorSlice(ssm.name(), ssm_shape, ssm.type(), fname,\n                                    ss_slice, &tensors_);\n      if (!status_.ok()) return;\n    }\n  }\n}",
        "func_hash": 142353236440749935149556768782118562464,
        "file_name": "tensor_slice_reader.cc",
        "file_hash": 273719145932163646554963802660605302118,
        "cwe": [
            "CWE-369"
        ],
        "cve": "CVE-2021-41203",
        "cve_desc": "TensorFlow is an open source platform for machine learning. In affected versions an attacker can trigger undefined behavior, integer overflows, segfaults and `CHECK`-fail crashes if they can change saved checkpoints from outside of TensorFlow. This is because the checkpoints loading infrastructure is missing validation for invalid file formats. The fixes will be included in TensorFlow 2.7.0. We will also cherrypick these commits on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-41203",
        "func_name": "TensorSliceReader::LoadShard",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 196276,
        "project": "lsquic",
        "commit_id": "a74702c630e108125e71898398737baec8f02238",
        "project_url": "https://github.com/litespeedtech/lsquic",
        "commit_url": "https://github.com/litespeedtech/lsquic/commit/a74702c630e108125e71898398737baec8f02238",
        "commit_message": "Release 3.1.0",
        "target": 1,
        "irrelevant": 0,
        "func_before": "lsquic_qeh_settings (struct qpack_enc_hdl *qeh, unsigned max_table_size,\n             unsigned dyn_table_size, unsigned max_risked_streams, int server)\n{\n    enum lsqpack_enc_opts enc_opts;\n\n    assert(qeh->qeh_flags & QEH_INITIALIZED);\n\n    if (qeh->qeh_flags & QEH_HAVE_SETTINGS)\n    {\n        LSQ_WARN(\"settings already set\");\n        return -1;\n    }\n\n    enc_opts = LSQPACK_ENC_OPT_STAGE_2\n             | (server ? LSQPACK_ENC_OPT_SERVER : 0);\n    qeh->qeh_tsu_sz = sizeof(qeh->qeh_tsu_buf);\n    if (0 != lsqpack_enc_init(&qeh->qeh_encoder, (void *) qeh->qeh_conn,\n                max_table_size, dyn_table_size, max_risked_streams, enc_opts,\n                qeh->qeh_tsu_buf, &qeh->qeh_tsu_sz))\n    {\n        LSQ_INFO(\"could not initialize QPACK encoder\");\n        return -1;\n    }\n    LSQ_DEBUG(\"%zu-byte post-init TSU\", qeh->qeh_tsu_sz);\n    qeh->qeh_flags |= QEH_HAVE_SETTINGS;\n    qeh->qeh_max_prefix_size =\n                        lsqpack_enc_header_block_prefix_size(&qeh->qeh_encoder);\n    LSQ_DEBUG(\"have settings: max table size=%u; dyn table size=%u; max risked \"\n        \"streams=%u\", max_table_size, dyn_table_size, max_risked_streams);\n    if (qeh->qeh_enc_sm_out)\n        qeh_begin_out(qeh);\n    return 0;\n}",
        "func_hash": 304358665951404548699605657299704903588,
        "file_name": "lsquic_qenc_hdl.c",
        "file_hash": null,
        "cwe": [
            "CWE-269"
        ],
        "cve": "CVE-2022-30592",
        "cve_desc": "liblsquic/lsquic_qenc_hdl.c in LiteSpeed QUIC (aka LSQUIC) before 3.1.0 mishandles MAX_TABLE_CAPACITY.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-30592",
        "func_name": "lsquic_qeh_settings",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 196316,
        "project": "barebox",
        "commit_id": "0a9f9a7410681e55362f8311537ebc7be9ad0fbe",
        "project_url": "https://github.com/saschahauer/barebox",
        "commit_url": "https://github.com/saschahauer/barebox/commit/0a9f9a7410681e55362f8311537ebc7be9ad0fbe",
        "commit_message": "crypto: digest: use crypto_memneq()\n\nWhen verifying a digest it is important not to leak timing information\nthrough memcmp(). Use crypto_memneq() instead.\n\nSigned-off-by: Sascha Hauer <s.hauer@pengutronix.de>",
        "target": 1,
        "irrelevant": 1,
        "func_before": "int digest_generic_verify(struct digest *d, const unsigned char *md)\n{\n\tint ret;\n\tint len = digest_length(d);\n\tunsigned char *tmp;\n\n\ttmp = xmalloc(len);\n\n\tret = digest_final(d, tmp);\n\tif (ret)\n\t\tgoto end;\n\n\tret = memcmp(md, tmp, len);\n\tret = ret ? -EINVAL : 0;\nend:\n\tfree(tmp);\n\treturn ret;\n}",
        "func_hash": 71480685616976545176363965575731858659,
        "file_name": "digest.c",
        "file_hash": 309636649404648894565051311749383985179,
        "cwe": [
            "CWE-200"
        ],
        "cve": "CVE-2021-37847",
        "cve_desc": "crypto/digest.c in Pengutronix barebox through 2021.07.0 leaks timing information because memcmp is used during digest verification.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37847",
        "func_name": "digest_generic_verify",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 196328,
        "project": "vim",
        "commit_id": "409510c588b1eec1ae33511ae97a21eb8e110895",
        "project_url": "https://github.com/vim/vim",
        "commit_url": "https://github.com/vim/vim/commit/409510c588b1eec1ae33511ae97a21eb8e110895",
        "commit_message": "patch 8.2.5050: using freed memory when searching for pattern in path\n\nProblem:    Using freed memory when searching for pattern in path.\nSolution:   Make a copy of the line.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "find_pattern_in_path(\n    char_u\t*ptr,\t\t// pointer to search pattern\n    int\t\tdir UNUSED,\t// direction of expansion\n    int\t\tlen,\t\t// length of search pattern\n    int\t\twhole,\t\t// match whole words only\n    int\t\tskip_comments,\t// don't match inside comments\n    int\t\ttype,\t\t// Type of search; are we looking for a type?\n\t\t\t\t// a macro?\n    long\tcount,\n    int\t\taction,\t\t// What to do when we find it\n    linenr_T\tstart_lnum,\t// first line to start searching\n    linenr_T\tend_lnum)\t// last line for searching\n{\n    SearchedFile *files;\t\t// Stack of included files\n    SearchedFile *bigger;\t\t// When we need more space\n    int\t\tmax_path_depth = 50;\n    long\tmatch_count = 1;\n\n    char_u\t*pat;\n    char_u\t*new_fname;\n    char_u\t*curr_fname = curbuf->b_fname;\n    char_u\t*prev_fname = NULL;\n    linenr_T\tlnum;\n    int\t\tdepth;\n    int\t\tdepth_displayed;\t// For type==CHECK_PATH\n    int\t\told_files;\n    int\t\talready_searched;\n    char_u\t*file_line;\n    char_u\t*line;\n    char_u\t*p;\n    char_u\tsave_char;\n    int\t\tdefine_matched;\n    regmatch_T\tregmatch;\n    regmatch_T\tincl_regmatch;\n    regmatch_T\tdef_regmatch;\n    int\t\tmatched = FALSE;\n    int\t\tdid_show = FALSE;\n    int\t\tfound = FALSE;\n    int\t\ti;\n    char_u\t*already = NULL;\n    char_u\t*startp = NULL;\n    char_u\t*inc_opt = NULL;\n#if defined(FEAT_QUICKFIX)\n    win_T\t*curwin_save = NULL;\n#endif\n\n    regmatch.regprog = NULL;\n    incl_regmatch.regprog = NULL;\n    def_regmatch.regprog = NULL;\n\n    file_line = alloc(LSIZE);\n    if (file_line == NULL)\n\treturn;\n\n    if (type != CHECK_PATH && type != FIND_DEFINE\n\t    // when CONT_SOL is set compare \"ptr\" with the beginning of the\n\t    // line is faster than quote_meta/regcomp/regexec \"ptr\" -- Acevedo\n\t    && !compl_status_sol())\n    {\n\tpat = alloc(len + 5);\n\tif (pat == NULL)\n\t    goto fpip_end;\n\tsprintf((char *)pat, whole ? \"\\\\<%.*s\\\\>\" : \"%.*s\", len, ptr);\n\t// ignore case according to p_ic, p_scs and pat\n\tregmatch.rm_ic = ignorecase(pat);\n\tregmatch.regprog = vim_regcomp(pat, magic_isset() ? RE_MAGIC : 0);\n\tvim_free(pat);\n\tif (regmatch.regprog == NULL)\n\t    goto fpip_end;\n    }\n    inc_opt = (*curbuf->b_p_inc == NUL) ? p_inc : curbuf->b_p_inc;\n    if (*inc_opt != NUL)\n    {\n\tincl_regmatch.regprog = vim_regcomp(inc_opt,\n\t\t\t\t\t\t magic_isset() ? RE_MAGIC : 0);\n\tif (incl_regmatch.regprog == NULL)\n\t    goto fpip_end;\n\tincl_regmatch.rm_ic = FALSE;\t// don't ignore case in incl. pat.\n    }\n    if (type == FIND_DEFINE && (*curbuf->b_p_def != NUL || *p_def != NUL))\n    {\n\tdef_regmatch.regprog = vim_regcomp(*curbuf->b_p_def == NUL\n\t\t\t   ? p_def : curbuf->b_p_def,\n\t\t\t\t\t\t magic_isset() ? RE_MAGIC : 0);\n\tif (def_regmatch.regprog == NULL)\n\t    goto fpip_end;\n\tdef_regmatch.rm_ic = FALSE;\t// don't ignore case in define pat.\n    }\n    files = lalloc_clear(max_path_depth * sizeof(SearchedFile), TRUE);\n    if (files == NULL)\n\tgoto fpip_end;\n    old_files = max_path_depth;\n    depth = depth_displayed = -1;\n\n    lnum = start_lnum;\n    if (end_lnum > curbuf->b_ml.ml_line_count)\n\tend_lnum = curbuf->b_ml.ml_line_count;\n    if (lnum > end_lnum)\t\t// do at least one line\n\tlnum = end_lnum;\n    line = ml_get(lnum);\n\n    for (;;)\n    {\n\tif (incl_regmatch.regprog != NULL\n\t\t&& vim_regexec(&incl_regmatch, line, (colnr_T)0))\n\t{\n\t    char_u *p_fname = (curr_fname == curbuf->b_fname)\n\t\t\t\t\t      ? curbuf->b_ffname : curr_fname;\n\n\t    if (inc_opt != NULL && strstr((char *)inc_opt, \"\\\\zs\") != NULL)\n\t\t// Use text from '\\zs' to '\\ze' (or end) of 'include'.\n\t\tnew_fname = find_file_name_in_path(incl_regmatch.startp[0],\n\t\t       (int)(incl_regmatch.endp[0] - incl_regmatch.startp[0]),\n\t\t\t\t FNAME_EXP|FNAME_INCL|FNAME_REL, 1L, p_fname);\n\t    else\n\t\t// Use text after match with 'include'.\n\t\tnew_fname = file_name_in_line(incl_regmatch.endp[0], 0,\n\t\t\t     FNAME_EXP|FNAME_INCL|FNAME_REL, 1L, p_fname, NULL);\n\t    already_searched = FALSE;\n\t    if (new_fname != NULL)\n\t    {\n\t\t// Check whether we have already searched in this file\n\t\tfor (i = 0;; i++)\n\t\t{\n\t\t    if (i == depth + 1)\n\t\t\ti = old_files;\n\t\t    if (i == max_path_depth)\n\t\t\tbreak;\n\t\t    if (fullpathcmp(new_fname, files[i].name, TRUE, TRUE)\n\t\t\t\t\t\t\t\t    & FPC_SAME)\n\t\t    {\n\t\t\tif (type != CHECK_PATH\n\t\t\t\t&& action == ACTION_SHOW_ALL\n\t\t\t\t&& files[i].matched)\n\t\t\t{\n\t\t\t    msg_putchar('\\n');\t    // cursor below last one\n\t\t\t    if (!got_int)\t    // don't display if 'q'\n\t\t\t\t\t\t    // typed at \"--more--\"\n\t\t\t\t\t\t    // message\n\t\t\t    {\n\t\t\t\tmsg_home_replace_hl(new_fname);\n\t\t\t\tmsg_puts(_(\" (includes previously listed match)\"));\n\t\t\t\tprev_fname = NULL;\n\t\t\t    }\n\t\t\t}\n\t\t\tVIM_CLEAR(new_fname);\n\t\t\talready_searched = TRUE;\n\t\t\tbreak;\n\t\t    }\n\t\t}\n\t    }\n\n\t    if (type == CHECK_PATH && (action == ACTION_SHOW_ALL\n\t\t\t\t || (new_fname == NULL && !already_searched)))\n\t    {\n\t\tif (did_show)\n\t\t    msg_putchar('\\n');\t    // cursor below last one\n\t\telse\n\t\t{\n\t\t    gotocmdline(TRUE);\t    // cursor at status line\n\t\t    msg_puts_title(_(\"--- Included files \"));\n\t\t    if (action != ACTION_SHOW_ALL)\n\t\t\tmsg_puts_title(_(\"not found \"));\n\t\t    msg_puts_title(_(\"in path ---\\n\"));\n\t\t}\n\t\tdid_show = TRUE;\n\t\twhile (depth_displayed < depth && !got_int)\n\t\t{\n\t\t    ++depth_displayed;\n\t\t    for (i = 0; i < depth_displayed; i++)\n\t\t\tmsg_puts(\"  \");\n\t\t    msg_home_replace(files[depth_displayed].name);\n\t\t    msg_puts(\" -->\\n\");\n\t\t}\n\t\tif (!got_int)\t\t    // don't display if 'q' typed\n\t\t\t\t\t    // for \"--more--\" message\n\t\t{\n\t\t    for (i = 0; i <= depth_displayed; i++)\n\t\t\tmsg_puts(\"  \");\n\t\t    if (new_fname != NULL)\n\t\t    {\n\t\t\t// using \"new_fname\" is more reliable, e.g., when\n\t\t\t// 'includeexpr' is set.\n\t\t\tmsg_outtrans_attr(new_fname, HL_ATTR(HLF_D));\n\t\t    }\n\t\t    else\n\t\t    {\n\t\t\t/*\n\t\t\t * Isolate the file name.\n\t\t\t * Include the surrounding \"\" or <> if present.\n\t\t\t */\n\t\t\tif (inc_opt != NULL\n\t\t\t\t   && strstr((char *)inc_opt, \"\\\\zs\") != NULL)\n\t\t\t{\n\t\t\t    // pattern contains \\zs, use the match\n\t\t\t    p = incl_regmatch.startp[0];\n\t\t\t    i = (int)(incl_regmatch.endp[0]\n\t\t\t\t\t\t   - incl_regmatch.startp[0]);\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t    // find the file name after the end of the match\n\t\t\t    for (p = incl_regmatch.endp[0];\n\t\t\t\t\t\t  *p && !vim_isfilec(*p); p++)\n\t\t\t\t;\n\t\t\t    for (i = 0; vim_isfilec(p[i]); i++)\n\t\t\t\t;\n\t\t\t}\n\n\t\t\tif (i == 0)\n\t\t\t{\n\t\t\t    // Nothing found, use the rest of the line.\n\t\t\t    p = incl_regmatch.endp[0];\n\t\t\t    i = (int)STRLEN(p);\n\t\t\t}\n\t\t\t// Avoid checking before the start of the line, can\n\t\t\t// happen if \\zs appears in the regexp.\n\t\t\telse if (p > line)\n\t\t\t{\n\t\t\t    if (p[-1] == '\"' || p[-1] == '<')\n\t\t\t    {\n\t\t\t\t--p;\n\t\t\t\t++i;\n\t\t\t    }\n\t\t\t    if (p[i] == '\"' || p[i] == '>')\n\t\t\t\t++i;\n\t\t\t}\n\t\t\tsave_char = p[i];\n\t\t\tp[i] = NUL;\n\t\t\tmsg_outtrans_attr(p, HL_ATTR(HLF_D));\n\t\t\tp[i] = save_char;\n\t\t    }\n\n\t\t    if (new_fname == NULL && action == ACTION_SHOW_ALL)\n\t\t    {\n\t\t\tif (already_searched)\n\t\t\t    msg_puts(_(\"  (Already listed)\"));\n\t\t\telse\n\t\t\t    msg_puts(_(\"  NOT FOUND\"));\n\t\t    }\n\t\t}\n\t\tout_flush();\t    // output each line directly\n\t    }\n\n\t    if (new_fname != NULL)\n\t    {\n\t\t// Push the new file onto the file stack\n\t\tif (depth + 1 == old_files)\n\t\t{\n\t\t    bigger = ALLOC_MULT(SearchedFile, max_path_depth * 2);\n\t\t    if (bigger != NULL)\n\t\t    {\n\t\t\tfor (i = 0; i <= depth; i++)\n\t\t\t    bigger[i] = files[i];\n\t\t\tfor (i = depth + 1; i < old_files + max_path_depth; i++)\n\t\t\t{\n\t\t\t    bigger[i].fp = NULL;\n\t\t\t    bigger[i].name = NULL;\n\t\t\t    bigger[i].lnum = 0;\n\t\t\t    bigger[i].matched = FALSE;\n\t\t\t}\n\t\t\tfor (i = old_files; i < max_path_depth; i++)\n\t\t\t    bigger[i + max_path_depth] = files[i];\n\t\t\told_files += max_path_depth;\n\t\t\tmax_path_depth *= 2;\n\t\t\tvim_free(files);\n\t\t\tfiles = bigger;\n\t\t    }\n\t\t}\n\t\tif ((files[depth + 1].fp = mch_fopen((char *)new_fname, \"r\"))\n\t\t\t\t\t\t\t\t    == NULL)\n\t\t    vim_free(new_fname);\n\t\telse\n\t\t{\n\t\t    if (++depth == old_files)\n\t\t    {\n\t\t\t/*\n\t\t\t * lalloc() for 'bigger' must have failed above.  We\n\t\t\t * will forget one of our already visited files now.\n\t\t\t */\n\t\t\tvim_free(files[old_files].name);\n\t\t\t++old_files;\n\t\t    }\n\t\t    files[depth].name = curr_fname = new_fname;\n\t\t    files[depth].lnum = 0;\n\t\t    files[depth].matched = FALSE;\n\t\t    if (action == ACTION_EXPAND)\n\t\t    {\n\t\t\tmsg_hist_off = TRUE;\t// reset in msg_trunc_attr()\n\t\t\tvim_snprintf((char*)IObuff, IOSIZE,\n\t\t\t\t_(\"Scanning included file: %s\"),\n\t\t\t\t(char *)new_fname);\n\t\t\tmsg_trunc_attr((char *)IObuff, TRUE, HL_ATTR(HLF_R));\n\t\t    }\n\t\t    else if (p_verbose >= 5)\n\t\t    {\n\t\t\tverbose_enter();\n\t\t\tsmsg(_(\"Searching included file %s\"),\n\t\t\t\t\t\t\t   (char *)new_fname);\n\t\t\tverbose_leave();\n\t\t    }\n\n\t\t}\n\t    }\n\t}\n\telse\n\t{\n\t    /*\n\t     * Check if the line is a define (type == FIND_DEFINE)\n\t     */\n\t    p = line;\nsearch_line:\n\t    define_matched = FALSE;\n\t    if (def_regmatch.regprog != NULL\n\t\t\t      && vim_regexec(&def_regmatch, line, (colnr_T)0))\n\t    {\n\t\t/*\n\t\t * Pattern must be first identifier after 'define', so skip\n\t\t * to that position before checking for match of pattern.  Also\n\t\t * don't let it match beyond the end of this identifier.\n\t\t */\n\t\tp = def_regmatch.endp[0];\n\t\twhile (*p && !vim_iswordc(*p))\n\t\t    p++;\n\t\tdefine_matched = TRUE;\n\t    }\n\n\t    /*\n\t     * Look for a match.  Don't do this if we are looking for a\n\t     * define and this line didn't match define_prog above.\n\t     */\n\t    if (def_regmatch.regprog == NULL || define_matched)\n\t    {\n\t\tif (define_matched || compl_status_sol())\n\t\t{\n\t\t    // compare the first \"len\" chars from \"ptr\"\n\t\t    startp = skipwhite(p);\n\t\t    if (p_ic)\n\t\t\tmatched = !MB_STRNICMP(startp, ptr, len);\n\t\t    else\n\t\t\tmatched = !STRNCMP(startp, ptr, len);\n\t\t    if (matched && define_matched && whole\n\t\t\t\t\t\t  && vim_iswordc(startp[len]))\n\t\t\tmatched = FALSE;\n\t\t}\n\t\telse if (regmatch.regprog != NULL\n\t\t\t && vim_regexec(&regmatch, line, (colnr_T)(p - line)))\n\t\t{\n\t\t    matched = TRUE;\n\t\t    startp = regmatch.startp[0];\n\t\t    /*\n\t\t     * Check if the line is not a comment line (unless we are\n\t\t     * looking for a define).  A line starting with \"# define\"\n\t\t     * is not considered to be a comment line.\n\t\t     */\n\t\t    if (!define_matched && skip_comments)\n\t\t    {\n\t\t\tif ((*line != '#' ||\n\t\t\t\tSTRNCMP(skipwhite(line + 1), \"define\", 6) != 0)\n\t\t\t\t&& get_leader_len(line, NULL, FALSE, TRUE))\n\t\t\t    matched = FALSE;\n\n\t\t\t/*\n\t\t\t * Also check for a \"/ *\" or \"/ /\" before the match.\n\t\t\t * Skips lines like \"int backwards;  / * normal index\n\t\t\t * * /\" when looking for \"normal\".\n\t\t\t * Note: Doesn't skip \"/ *\" in comments.\n\t\t\t */\n\t\t\tp = skipwhite(line);\n\t\t\tif (matched\n\t\t\t\t|| (p[0] == '/' && p[1] == '*') || p[0] == '*')\n\t\t\t    for (p = line; *p && p < startp; ++p)\n\t\t\t    {\n\t\t\t\tif (matched\n\t\t\t\t\t&& p[0] == '/'\n\t\t\t\t\t&& (p[1] == '*' || p[1] == '/'))\n\t\t\t\t{\n\t\t\t\t    matched = FALSE;\n\t\t\t\t    // After \"//\" all text is comment\n\t\t\t\t    if (p[1] == '/')\n\t\t\t\t\tbreak;\n\t\t\t\t    ++p;\n\t\t\t\t}\n\t\t\t\telse if (!matched && p[0] == '*' && p[1] == '/')\n\t\t\t\t{\n\t\t\t\t    // Can find match after \"* /\".\n\t\t\t\t    matched = TRUE;\n\t\t\t\t    ++p;\n\t\t\t\t}\n\t\t\t    }\n\t\t    }\n\t\t}\n\t    }\n\t}\n\tif (matched)\n\t{\n\t    if (action == ACTION_EXPAND)\n\t    {\n\t\tint\tcont_s_ipos = FALSE;\n\t\tint\tadd_r;\n\t\tchar_u\t*aux;\n\n\t\tif (depth == -1 && lnum == curwin->w_cursor.lnum)\n\t\t    break;\n\t\tfound = TRUE;\n\t\taux = p = startp;\n\t\tif (compl_status_adding())\n\t\t{\n\t\t    p += ins_compl_len();\n\t\t    if (vim_iswordp(p))\n\t\t\tgoto exit_matched;\n\t\t    p = find_word_start(p);\n\t\t}\n\t\tp = find_word_end(p);\n\t\ti = (int)(p - aux);\n\n\t\tif (compl_status_adding() && i == ins_compl_len())\n\t\t{\n\t\t    // IOSIZE > compl_length, so the STRNCPY works\n\t\t    STRNCPY(IObuff, aux, i);\n\n\t\t    // Get the next line: when \"depth\" < 0  from the current\n\t\t    // buffer, otherwise from the included file.  Jump to\n\t\t    // exit_matched when past the last line.\n\t\t    if (depth < 0)\n\t\t    {\n\t\t\tif (lnum >= end_lnum)\n\t\t\t    goto exit_matched;\n\t\t\tline = ml_get(++lnum);\n\t\t    }\n\t\t    else if (vim_fgets(line = file_line,\n\t\t\t\t\t\t      LSIZE, files[depth].fp))\n\t\t\tgoto exit_matched;\n\n\t\t    // we read a line, set \"already\" to check this \"line\" later\n\t\t    // if depth >= 0 we'll increase files[depth].lnum far\n\t\t    // below  -- Acevedo\n\t\t    already = aux = p = skipwhite(line);\n\t\t    p = find_word_start(p);\n\t\t    p = find_word_end(p);\n\t\t    if (p > aux)\n\t\t    {\n\t\t\tif (*aux != ')' && IObuff[i-1] != TAB)\n\t\t\t{\n\t\t\t    if (IObuff[i-1] != ' ')\n\t\t\t\tIObuff[i++] = ' ';\n\t\t\t    // IObuf =~ \"\\(\\k\\|\\i\\).* \", thus i >= 2\n\t\t\t    if (p_js\n\t\t\t\t&& (IObuff[i-2] == '.'\n\t\t\t\t    || (vim_strchr(p_cpo, CPO_JOINSP) == NULL\n\t\t\t\t\t&& (IObuff[i-2] == '?'\n\t\t\t\t\t    || IObuff[i-2] == '!'))))\n\t\t\t\tIObuff[i++] = ' ';\n\t\t\t}\n\t\t\t// copy as much as possible of the new word\n\t\t\tif (p - aux >= IOSIZE - i)\n\t\t\t    p = aux + IOSIZE - i - 1;\n\t\t\tSTRNCPY(IObuff + i, aux, p - aux);\n\t\t\ti += (int)(p - aux);\n\t\t\tcont_s_ipos = TRUE;\n\t\t    }\n\t\t    IObuff[i] = NUL;\n\t\t    aux = IObuff;\n\n\t\t    if (i == ins_compl_len())\n\t\t\tgoto exit_matched;\n\t\t}\n\n\t\tadd_r = ins_compl_add_infercase(aux, i, p_ic,\n\t\t\tcurr_fname == curbuf->b_fname ? NULL : curr_fname,\n\t\t\tdir, cont_s_ipos);\n\t\tif (add_r == OK)\n\t\t    // if dir was BACKWARD then honor it just once\n\t\t    dir = FORWARD;\n\t\telse if (add_r == FAIL)\n\t\t    break;\n\t    }\n\t    else if (action == ACTION_SHOW_ALL)\n\t    {\n\t\tfound = TRUE;\n\t\tif (!did_show)\n\t\t    gotocmdline(TRUE);\t\t// cursor at status line\n\t\tif (curr_fname != prev_fname)\n\t\t{\n\t\t    if (did_show)\n\t\t\tmsg_putchar('\\n');\t// cursor below last one\n\t\t    if (!got_int)\t\t// don't display if 'q' typed\n\t\t\t\t\t\t// at \"--more--\" message\n\t\t\tmsg_home_replace_hl(curr_fname);\n\t\t    prev_fname = curr_fname;\n\t\t}\n\t\tdid_show = TRUE;\n\t\tif (!got_int)\n\t\t    show_pat_in_path(line, type, TRUE, action,\n\t\t\t    (depth == -1) ? NULL : files[depth].fp,\n\t\t\t    (depth == -1) ? &lnum : &files[depth].lnum,\n\t\t\t    match_count++);\n\n\t\t// Set matched flag for this file and all the ones that\n\t\t// include it\n\t\tfor (i = 0; i <= depth; ++i)\n\t\t    files[i].matched = TRUE;\n\t    }\n\t    else if (--count <= 0)\n\t    {\n\t\tfound = TRUE;\n\t\tif (depth == -1 && lnum == curwin->w_cursor.lnum\n#if defined(FEAT_QUICKFIX)\n\t\t\t\t\t\t      && g_do_tagpreview == 0\n#endif\n\t\t\t\t\t\t      )\n\t\t    emsg(_(e_match_is_on_current_line));\n\t\telse if (action == ACTION_SHOW)\n\t\t{\n\t\t    show_pat_in_path(line, type, did_show, action,\n\t\t\t(depth == -1) ? NULL : files[depth].fp,\n\t\t\t(depth == -1) ? &lnum : &files[depth].lnum, 1L);\n\t\t    did_show = TRUE;\n\t\t}\n\t\telse\n\t\t{\n#ifdef FEAT_GUI\n\t\t    need_mouse_correct = TRUE;\n#endif\n#if defined(FEAT_QUICKFIX)\n\t\t    // \":psearch\" uses the preview window\n\t\t    if (g_do_tagpreview != 0)\n\t\t    {\n\t\t\tcurwin_save = curwin;\n\t\t\tprepare_tagpreview(TRUE, TRUE, FALSE);\n\t\t    }\n#endif\n\t\t    if (action == ACTION_SPLIT)\n\t\t    {\n\t\t\tif (win_split(0, 0) == FAIL)\n\t\t\t    break;\n\t\t\tRESET_BINDING(curwin);\n\t\t    }\n\t\t    if (depth == -1)\n\t\t    {\n\t\t\t// match in current file\n#if defined(FEAT_QUICKFIX)\n\t\t\tif (g_do_tagpreview != 0)\n\t\t\t{\n\t\t\t    if (!win_valid(curwin_save))\n\t\t\t\tbreak;\n\t\t\t    if (!GETFILE_SUCCESS(getfile(\n\t\t\t\t\t   curwin_save->w_buffer->b_fnum, NULL,\n\t\t\t\t\t\t     NULL, TRUE, lnum, FALSE)))\n\t\t\t\tbreak;\t// failed to jump to file\n\t\t\t}\n\t\t\telse\n#endif\n\t\t\t    setpcmark();\n\t\t\tcurwin->w_cursor.lnum = lnum;\n\t\t\tcheck_cursor();\n\t\t    }\n\t\t    else\n\t\t    {\n\t\t\tif (!GETFILE_SUCCESS(getfile(\n\t\t\t\t\t0, files[depth].name, NULL, TRUE,\n\t\t\t\t\t\t    files[depth].lnum, FALSE)))\n\t\t\t    break;\t// failed to jump to file\n\t\t\t// autocommands may have changed the lnum, we don't\n\t\t\t// want that here\n\t\t\tcurwin->w_cursor.lnum = files[depth].lnum;\n\t\t    }\n\t\t}\n\t\tif (action != ACTION_SHOW)\n\t\t{\n\t\t    curwin->w_cursor.col = (colnr_T)(startp - line);\n\t\t    curwin->w_set_curswant = TRUE;\n\t\t}\n\n#if defined(FEAT_QUICKFIX)\n\t\tif (g_do_tagpreview != 0\n\t\t\t   && curwin != curwin_save && win_valid(curwin_save))\n\t\t{\n\t\t    // Return cursor to where we were\n\t\t    validate_cursor();\n\t\t    redraw_later(VALID);\n\t\t    win_enter(curwin_save, TRUE);\n\t\t}\n# ifdef FEAT_PROP_POPUP\n\t\telse if (WIN_IS_POPUP(curwin))\n\t\t    // can't keep focus in popup window\n\t\t    win_enter(firstwin, TRUE);\n# endif\n#endif\n\t\tbreak;\n\t    }\nexit_matched:\n\t    matched = FALSE;\n\t    // look for other matches in the rest of the line if we\n\t    // are not at the end of it already\n\t    if (def_regmatch.regprog == NULL\n\t\t    && action == ACTION_EXPAND\n\t\t    && !compl_status_sol()\n\t\t    && *startp != NUL\n\t\t    && *(p = startp + mb_ptr2len(startp)) != NUL)\n\t\tgoto search_line;\n\t}\n\tline_breakcheck();\n\tif (action == ACTION_EXPAND)\n\t    ins_compl_check_keys(30, FALSE);\n\tif (got_int || ins_compl_interrupted())\n\t    break;\n\n\t/*\n\t * Read the next line.  When reading an included file and encountering\n\t * end-of-file, close the file and continue in the file that included\n\t * it.\n\t */\n\twhile (depth >= 0 && !already\n\t\t&& vim_fgets(line = file_line, LSIZE, files[depth].fp))\n\t{\n\t    fclose(files[depth].fp);\n\t    --old_files;\n\t    files[old_files].name = files[depth].name;\n\t    files[old_files].matched = files[depth].matched;\n\t    --depth;\n\t    curr_fname = (depth == -1) ? curbuf->b_fname\n\t\t\t\t       : files[depth].name;\n\t    if (depth < depth_displayed)\n\t\tdepth_displayed = depth;\n\t}\n\tif (depth >= 0)\t\t// we could read the line\n\t{\n\t    files[depth].lnum++;\n\t    // Remove any CR and LF from the line.\n\t    i = (int)STRLEN(line);\n\t    if (i > 0 && line[i - 1] == '\\n')\n\t\tline[--i] = NUL;\n\t    if (i > 0 && line[i - 1] == '\\r')\n\t\tline[--i] = NUL;\n\t}\n\telse if (!already)\n\t{\n\t    if (++lnum > end_lnum)\n\t\tbreak;\n\t    line = ml_get(lnum);\n\t}\n\talready = NULL;\n    }\n    // End of big for (;;) loop.\n\n    // Close any files that are still open.\n    for (i = 0; i <= depth; i++)\n    {\n\tfclose(files[i].fp);\n\tvim_free(files[i].name);\n    }\n    for (i = old_files; i < max_path_depth; i++)\n\tvim_free(files[i].name);\n    vim_free(files);\n\n    if (type == CHECK_PATH)\n    {\n\tif (!did_show)\n\t{\n\t    if (action != ACTION_SHOW_ALL)\n\t\tmsg(_(\"All included files were found\"));\n\t    else\n\t\tmsg(_(\"No included files\"));\n\t}\n    }\n    else if (!found && action != ACTION_EXPAND)\n    {\n\tif (got_int || ins_compl_interrupted())\n\t    emsg(_(e_interrupted));\n\telse if (type == FIND_DEFINE)\n\t    emsg(_(e_couldnt_find_definition));\n\telse\n\t    emsg(_(e_couldnt_find_pattern));\n    }\n    if (action == ACTION_SHOW || action == ACTION_SHOW_ALL)\n\tmsg_end();\n\nfpip_end:\n    vim_free(file_line);\n    vim_regfree(regmatch.regprog);\n    vim_regfree(incl_regmatch.regprog);\n    vim_regfree(def_regmatch.regprog);\n}",
        "func_hash": 123923862521809134964983633516065480238,
        "file_name": "search.c",
        "file_hash": 229512534202460810065416633781657256150,
        "cwe": [
            "CWE-416"
        ],
        "cve": "CVE-2022-1968",
        "cve_desc": "Use After Free in GitHub repository vim/vim prior to 8.2.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-1968",
        "func_name": "find_pattern_in_path",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 196578,
        "project": "vim",
        "commit_id": "44db8213d38c39877d2148eff6a72f4beccfb94e",
        "project_url": "https://github.com/vim/vim",
        "commit_url": "https://github.com/vim/vim/commit/44db8213d38c39877d2148eff6a72f4beccfb94e",
        "commit_message": "patch 8.2.4219: reading before the start of the line\n\nProblem:    Reading before the start of the line.\nSolution:   Check boundary before trying to read the character.",
        "target": 1,
        "irrelevant": 1,
        "func_before": "yank_copy_line(struct block_def *bd, long y_idx, int exclude_trailing_space)\n{\n    char_u\t*pnew;\n\n    if (exclude_trailing_space)\n\tbd->endspaces = 0;\n    if ((pnew = alloc(bd->startspaces + bd->endspaces + bd->textlen + 1))\n\t\t\t\t\t\t\t\t      == NULL)\n\treturn FAIL;\n    y_current->y_array[y_idx] = pnew;\n    vim_memset(pnew, ' ', (size_t)bd->startspaces);\n    pnew += bd->startspaces;\n    mch_memmove(pnew, bd->textstart, (size_t)bd->textlen);\n    pnew += bd->textlen;\n    vim_memset(pnew, ' ', (size_t)bd->endspaces);\n    pnew += bd->endspaces;\n    if (exclude_trailing_space)\n    {\n\tint s = bd->textlen + bd->endspaces;\n\n\twhile (VIM_ISWHITE(*(bd->textstart + s - 1)) && s > 0)\n\t{\n\t    s = s - (*mb_head_off)(bd->textstart, bd->textstart + s - 1) - 1;\n\t    pnew--;\n\t}\n    }\n    *pnew = NUL;\n    return OK;\n}",
        "func_hash": 329046653104270093704788517563971777510,
        "file_name": "register.c",
        "file_hash": 197045442768005159362544298682780980387,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2022-0407",
        "cve_desc": "Heap-based Buffer Overflow in GitHub repository vim/vim prior to 8.2.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-0407",
        "func_name": "yank_copy_line",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 197808,
        "project": "mruby",
        "commit_id": "47068ae07a5fa3aa9a1879cdfe98a9ce0f339299",
        "project_url": "https://github.com/mruby/mruby",
        "commit_url": "https://github.com/mruby/mruby/commit/47068ae07a5fa3aa9a1879cdfe98a9ce0f339299",
        "commit_message": "vm.c: packed arguments length may be zero for `send` method.",
        "target": 1,
        "irrelevant": 1,
        "func_before": "mrb_f_send(mrb_state *mrb, mrb_value self)\n{\n  mrb_sym name;\n  mrb_value block, *regs;\n  mrb_method_t m;\n  struct RClass *c;\n  mrb_callinfo *ci = mrb->c->ci;\n  int n = ci->n;\n\n  if (ci->cci > CINFO_NONE) {\n  funcall:;\n    const mrb_value *argv;\n    mrb_int argc;\n    mrb_get_args(mrb, \"n*&\", &name, &argv, &argc, &block);\n    return mrb_funcall_with_block(mrb, self, name, argc, argv, block);\n  }\n\n  regs = mrb->c->ci->stack+1;\n\n  if (n == 0) {\n    mrb_argnum_error(mrb, 0, 1, -1);\n  }\n  else if (n == 15) {\n    name = mrb_obj_to_sym(mrb, RARRAY_PTR(regs[0])[0]);\n  }\n  else {\n    name = mrb_obj_to_sym(mrb, regs[0]);\n  }\n\n  c = mrb_class(mrb, self);\n  m = mrb_method_search_vm(mrb, &c, name);\n  if (MRB_METHOD_UNDEF_P(m)) {            /* call method_mising */\n    goto funcall;\n  }\n\n  ci->mid = name;\n  ci->u.target_class = c;\n  /* remove first symbol from arguments */\n  if (n == 15) {     /* variable length arguments */\n    regs[0] = mrb_ary_subseq(mrb, regs[0], 1, RARRAY_LEN(regs[0]) - 1);\n  }\n  else { /* n > 0 */\n    for (int i=0; i<n; i++) {\n      regs[i] = regs[i+1];\n    }\n    regs[n] = regs[n+1];        /* copy kdict or block */\n    if (ci->nk > 0) {\n      regs[n+1] = regs[n+2];    /* copy block */\n    }\n    ci->n--;\n  }\n\n  if (MRB_METHOD_CFUNC_P(m)) {\n    if (MRB_METHOD_NOARG_P(m)) {\n      check_method_noarg(mrb, ci);\n    }\n\n    if (MRB_METHOD_PROC_P(m)) {\n      mrb_vm_ci_proc_set(ci, MRB_METHOD_PROC(m));\n    }\n    return MRB_METHOD_CFUNC(m)(mrb, self);\n  }\n  return exec_irep(mrb, self, MRB_METHOD_PROC(m));\n}",
        "func_hash": 242172053441945825561730661416191930474,
        "file_name": "vm.c",
        "file_hash": 295571119031657653721791727608298010275,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2022-0631",
        "cve_desc": "Heap-based Buffer Overflow in Homebrew mruby prior to 3.2.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-0631",
        "func_name": "mrb_f_send",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 197824,
        "project": "gpac",
        "commit_id": "c535bad50d5812d27ee5b22b54371bddec411514",
        "project_url": "https://github.com/gpac/gpac",
        "commit_url": "https://github.com/gpac/gpac/commit/c535bad50d5812d27ee5b22b54371bddec411514",
        "commit_message": "fixed #2194",
        "target": 1,
        "irrelevant": 1,
        "func_before": "static GF_Err BM_ParseGlobalQuantizer(GF_BifsDecoder *codec, GF_BitStream *bs, GF_List *com_list)\n{\n\tGF_Node *node;\n\tGF_Command *com;\n\tGF_CommandField *inf;\n\tnode = gf_bifs_dec_node(codec, bs, NDT_SFWorldNode);\n\tif (!node) return GF_NON_COMPLIANT_BITSTREAM;\n\n\t/*reset global QP*/\n\tif (codec->scenegraph->global_qp) {\n\t\tgf_node_unregister(codec->scenegraph->global_qp, NULL);\n\t}\n\tcodec->ActiveQP = NULL;\n\tcodec->scenegraph->global_qp = NULL;\n\n\tif (gf_node_get_tag(node) != TAG_MPEG4_QuantizationParameter) {\n\t\tgf_node_unregister(node, NULL);\n\t\treturn GF_NON_COMPLIANT_BITSTREAM;\n\t}\n\n\t/*register global QP*/\n\tcodec->ActiveQP = (M_QuantizationParameter *) node;\n\tcodec->ActiveQP->isLocal = 0;\n\tcodec->scenegraph->global_qp = node;\n\n\t/*register TWICE: once for the command, and for the scenegraph globalQP*/\n\tnode->sgprivate->num_instances = 2;\n\n\tcom = gf_sg_command_new(codec->current_graph, GF_SG_GLOBAL_QUANTIZER);\n\tinf = gf_sg_command_field_new(com);\n\tinf->new_node = node;\n\tinf->field_ptr = &inf->new_node;\n\tinf->fieldType = GF_SG_VRML_SFNODE;\n\tgf_list_add(com_list, com);\n\treturn GF_OK;\n}",
        "func_hash": 227330749119032349040137878791232526501,
        "file_name": "memory_decoder.c",
        "file_hash": 144617483436873036933597599292760665537,
        "cwe": [
            "CWE-416"
        ],
        "cve": "CVE-2022-1795",
        "cve_desc": "Use After Free in GitHub repository gpac/gpac prior to v2.1.0-DEV.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-1795",
        "func_name": "BM_ParseGlobalQuantizer",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 197826,
        "project": "tensorflow",
        "commit_id": "7731e8dfbe4a56773be5dc94d631611211156659",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/7731e8dfbe4a56773be5dc94d631611211156659",
        "commit_message": "Don't constant-fold DT_RESOURCE constants.\n\nPiperOrigin-RevId: 391803952\nChange-Id: I0ea3ec31d3e7dfda0f03b4027a237f08d00a3091",
        "target": 1,
        "irrelevant": 0,
        "func_before": "bool IsConstantFoldable(\n    const Node* n,\n    const std::unordered_map<string, std::vector<PartialTensorShape>>*\n        shape_map,\n    const std::function<bool(const Node*)>& consider,\n    int64_t max_constant_size_in_bytes,\n    std::unordered_map<const Node*, std::vector<Tensor>>*\n        shape_replacement_map) {\n  if (n->IsConstant()) {\n    return true;\n  }\n  if (MaybeReplaceShapeOp(n, shape_map, shape_replacement_map)) {\n    return true;\n  }\n  if (n->op_def().is_stateful()) {\n    return false;\n  }\n  if (consider && !consider(n)) {\n    return false;\n  }\n  if (shape_map != nullptr) {\n    // We can skip the node if an output is known to be oversized.\n    auto shape_it = shape_map->find(n->name());\n    if (shape_it != shape_map->end()) {\n      for (int64_t i = 0; i < shape_it->second.size(); ++i) {\n        const auto& out_shape = shape_it->second[i];\n        if (out_shape.IsFullyDefined() &&\n            out_shape.num_elements() * DataTypeSize(n->output_type(i)) >\n                max_constant_size_in_bytes) {\n          return false;\n        }\n      }\n    }\n  }\n  if (n->IsControlFlow() || n->IsSend() || n->IsRecv()) {\n    return false;\n  }\n  // TODO(yuanbyu): For now disable these session handle operations.\n  if (n->IsGetSessionHandle() || n->IsGetSessionTensor() ||\n      n->IsDeleteSessionTensor()) {\n    return false;\n  }\n  if (n->IsSource()) {\n    return false;\n  }\n  if (n->IsSink()) {\n    return false;\n  }\n  if (n->IsFakeParam()) {\n    return false;\n  }\n  // Since constant-folding runs on the CPU, do not attempt to constant-fold\n  // operators that have no CPU kernel. Also implies that we will not\n  // constant-fold functions.\n  // TODO(phawkins): allow constant-folding for functions; functions may\n  // be arbitrarily expensive to execute.\n  if (!KernelDefAvailable(DeviceType(DEVICE_CPU), n->def())) {\n    return false;\n  }\n  // Do not constant fold nodes which will be allocated by ScopedAllocator.\n  // This is because the constant-folding graph will not contain the\n  // `_ScopedAllocator` node, and that is necessary to be able to run a node\n  // that will use this allocator.\n  if (n->attrs().Find(kScopedAllocatorAttrName) != nullptr) {\n    VLOG(2) << \"Skip node [\" << n->DebugString()\n            << \"] for constant folding due to scoped allocator\";\n    return false;\n  }\n  return true;\n}",
        "func_hash": 116289485656616917830363077368123441202,
        "file_name": "constant_folding.cc",
        "file_hash": 46768745532828534791253050765124097339,
        "cwe": [
            "CWE-824"
        ],
        "cve": "CVE-2021-41204",
        "cve_desc": "TensorFlow is an open source platform for machine learning. In affected versions during TensorFlow's Grappler optimizer phase, constant folding might attempt to deep copy a resource tensor. This results in a segfault, as these tensors are supposed to not change. The fix will be included in TensorFlow 2.7.0. We will also cherrypick this commit on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-41204",
        "func_name": "IsConstantFoldable",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 197893,
        "project": "tensorflow",
        "commit_id": "eb921122119a6b6e470ee98b89e65d721663179d",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/eb921122119a6b6e470ee98b89e65d721663179d",
        "commit_message": "Prevent heap OOB read in TFLite's `gather.cc`.\n\nPassing negative indices is illegal but there was a missing check so that resulted in OOB accesses.\n\nPiperOrigin-RevId: 387231300\nChange-Id: I3111b54b2f232638d795be17efc46abe4ede6bf8",
        "target": 1,
        "irrelevant": 1,
        "func_before": "TfLiteStatus Gather(const TfLiteGatherParams& params, const TfLiteTensor* input,\n                    const TfLiteTensor* positions, TfLiteTensor* output) {\n  tflite::GatherParams op_params;\n  op_params.axis = params.axis;\n  op_params.batch_dims = params.batch_dims;\n  optimized_ops::Gather(op_params, GetTensorShape(input),\n                        GetTensorData<InputT>(input), GetTensorShape(positions),\n                        GetTensorData<PositionsT>(positions),\n                        GetTensorShape(output), GetTensorData<InputT>(output));\n  return kTfLiteOk;\n}",
        "func_hash": 291153190876322119376469189416083053275,
        "file_name": "gather.cc",
        "file_hash": 109151045550446368977897795663338855851,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2021-37687",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions TFLite's [`GatherNd` implementation](https://github.com/tensorflow/tensorflow/blob/149562d49faa709ea80df1d99fc41d005b81082a/tensorflow/lite/kernels/gather_nd.cc#L124) does not support negative indices but there are no checks for this situation. Hence, an attacker can read arbitrary data from the heap by carefully crafting a model with negative values in `indices`. Similar issue exists in [`Gather` implementation](https://github.com/tensorflow/tensorflow/blob/149562d49faa709ea80df1d99fc41d005b81082a/tensorflow/lite/kernels/gather.cc). We have patched the issue in GitHub commits bb6a0383ed553c286f87ca88c207f6774d5c4a8f and eb921122119a6b6e470ee98b89e65d721663179d. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37687",
        "func_name": "Gather",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 197898,
        "project": "tensorflow",
        "commit_id": "96f364a1ca3009f98980021c4b32be5fdcca33a1",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/96f364a1ca3009f98980021c4b32be5fdcca33a1",
        "commit_message": "Validate axis input in tf.raw_ops.QuantizeAndDequantizeV4Grad\n\nPiperOrigin-RevId: 388291385\nChange-Id: I3bab68dc61d935afa96c0da021a7b722c6dc8dc8",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor& gradient = ctx->input(0);\n    const Tensor& input = ctx->input(1);\n    Tensor* input_backprop = nullptr;\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_output(0, input.shape(), &input_backprop));\n\n    OP_REQUIRES(\n        ctx, input.IsSameSize(gradient),\n        errors::InvalidArgument(\"gradient and input must be the same size\"));\n    const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);\n    const Tensor& input_min_tensor = ctx->input(2);\n    OP_REQUIRES(ctx,\n                input_min_tensor.dims() == 0 || input_min_tensor.dims() == 1,\n                errors::InvalidArgument(\n                    \"Input min tensor must have dimension 1. Recieved \",\n                    input_min_tensor.dims(), \".\"));\n    const Tensor& input_max_tensor = ctx->input(3);\n    OP_REQUIRES(ctx,\n                input_max_tensor.dims() == 0 || input_max_tensor.dims() == 1,\n                errors::InvalidArgument(\n                    \"Input max tensor must have dimension 1. Recieved \",\n                    input_max_tensor.dims(), \".\"));\n    if (axis_ != -1) {\n      OP_REQUIRES(\n          ctx, input_min_tensor.dim_size(0) == depth,\n          errors::InvalidArgument(\"min has incorrect size, expected \", depth,\n                                  \" was \", input_min_tensor.dim_size(0)));\n      OP_REQUIRES(\n          ctx, input_max_tensor.dim_size(0) == depth,\n          errors::InvalidArgument(\"max has incorrect size, expected \", depth,\n                                  \" was \", input_max_tensor.dim_size(0)));\n    }\n\n    TensorShape min_max_shape(input_min_tensor.shape());\n    Tensor* input_min_backprop;\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_output(1, min_max_shape, &input_min_backprop));\n\n    Tensor* input_max_backprop;\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_output(2, min_max_shape, &input_max_backprop));\n\n    if (axis_ == -1) {\n      functor::QuantizeAndDequantizeOneScaleGradientFunctor<Device, T> f;\n      f(ctx->eigen_device<Device>(), gradient.template flat<T>(),\n        input.template flat<T>(), input_min_tensor.scalar<T>(),\n        input_max_tensor.scalar<T>(), input_backprop->template flat<T>(),\n        input_min_backprop->template scalar<T>(),\n        input_max_backprop->template scalar<T>());\n    } else {\n      functor::QuantizeAndDequantizePerChannelGradientFunctor<Device, T> f;\n      f(ctx->eigen_device<Device>(),\n        gradient.template flat_inner_outer_dims<T, 3>(axis_ - 1),\n        input.template flat_inner_outer_dims<T, 3>(axis_ - 1),\n        &input_min_tensor, &input_max_tensor,\n        input_backprop->template flat_inner_outer_dims<T, 3>(axis_ - 1),\n        input_min_backprop->template flat<T>(),\n        input_max_backprop->template flat<T>());\n    }\n  }",
        "func_hash": 29737241678039524897017482046018335676,
        "file_name": "quantize_and_dequantize_op.cc",
        "file_hash": 111820661822757211423774352328292852595,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2021-37645",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions the implementation of `tf.raw_ops.QuantizeAndDequantizeV4Grad` is vulnerable to an integer overflow issue caused by converting a signed integer value to an unsigned one and then allocating memory based on this value. The [implementation](https://github.com/tensorflow/tensorflow/blob/8d72537c6abf5a44103b57b9c2e22c14f5f49698/tensorflow/core/kernels/quantize_and_dequantize_op.cc#L126) uses the `axis` value as the size argument to `absl::InlinedVector` constructor. But, the constructor uses an unsigned type for the argument, so the implicit conversion transforms the negative value to a large integer. We have patched the issue in GitHub commit 96f364a1ca3009f98980021c4b32be5fdcca33a1. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, and TensorFlow 2.4.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37645",
        "func_name": "Compute",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 197973,
        "project": "crun",
        "commit_id": "1aeeed2e4fdeffb4875c0d0b439915894594c8c6",
        "project_url": "https://github.com/containers/crun",
        "commit_url": "https://github.com/containers/crun/commit/1aeeed2e4fdeffb4875c0d0b439915894594c8c6",
        "commit_message": "exec: --cap do not set inheritable capabilities\n\nCloses: CVE-2022-27650\n\nSigned-off-by: Giuseppe Scrivano <gscrivan@redhat.com>",
        "target": 1,
        "irrelevant": 0,
        "func_before": "crun_command_exec (struct crun_global_arguments *global_args, int argc, char **argv, libcrun_error_t *err)\n{\n  int first_arg = 0, ret = 0;\n  libcrun_context_t crun_context = {\n    0,\n  };\n  cleanup_process_schema runtime_spec_schema_config_schema_process *process = NULL;\n  struct libcrun_container_exec_options_s exec_opts;\n\n  memset (&exec_opts, 0, sizeof (exec_opts));\n  exec_opts.struct_size = sizeof (exec_opts);\n\n  crun_context.preserve_fds = 0;\n  crun_context.listen_fds = 0;\n\n  argp_parse (&run_argp, argc, argv, ARGP_IN_ORDER, &first_arg, &exec_options);\n  crun_assert_n_args (argc - first_arg, exec_options.process ? 1 : 2, -1);\n\n  ret = init_libcrun_context (&crun_context, argv[first_arg], global_args, err);\n  if (UNLIKELY (ret < 0))\n    return ret;\n\n  crun_context.detach = exec_options.detach;\n  crun_context.console_socket = exec_options.console_socket;\n  crun_context.pid_file = exec_options.pid_file;\n  crun_context.preserve_fds = exec_options.preserve_fds;\n\n  if (getenv (\"LISTEN_FDS\"))\n    {\n      crun_context.listen_fds = strtoll (getenv (\"LISTEN_FDS\"), NULL, 10);\n      crun_context.preserve_fds += crun_context.listen_fds;\n    }\n\n  if (exec_options.process)\n    exec_opts.path = exec_options.process;\n  else\n    {\n      process = xmalloc0 (sizeof (*process));\n      int i;\n\n      process->args_len = argc;\n      process->args = xmalloc0 ((argc + 1) * sizeof (*process->args));\n      for (i = 0; i < argc - first_arg; i++)\n        process->args[i] = xstrdup (argv[first_arg + i + 1]);\n      process->args[i] = NULL;\n      if (exec_options.cwd)\n        process->cwd = exec_options.cwd;\n      process->terminal = exec_options.tty;\n      process->env = exec_options.env;\n      process->env_len = exec_options.env_size;\n      process->user = make_oci_process_user (exec_options.user);\n\n      if (exec_options.process_label != NULL)\n        process->selinux_label = exec_options.process_label;\n\n      if (exec_options.apparmor != NULL)\n        process->apparmor_profile = exec_options.apparmor;\n\n      if (exec_options.cap_size > 0)\n        {\n          runtime_spec_schema_config_schema_process_capabilities *capabilities\n              = xmalloc (sizeof (runtime_spec_schema_config_schema_process_capabilities));\n\n          capabilities->effective = exec_options.cap;\n          capabilities->effective_len = exec_options.cap_size;\n\n          capabilities->inheritable = dup_array (exec_options.cap, exec_options.cap_size);\n          capabilities->inheritable_len = exec_options.cap_size;\n\n          capabilities->bounding = dup_array (exec_options.cap, exec_options.cap_size);\n          capabilities->bounding_len = exec_options.cap_size;\n\n          capabilities->ambient = dup_array (exec_options.cap, exec_options.cap_size);\n          capabilities->ambient_len = exec_options.cap_size;\n\n          capabilities->permitted = dup_array (exec_options.cap, exec_options.cap_size);\n          capabilities->permitted_len = exec_options.cap_size;\n\n          process->capabilities = capabilities;\n        }\n\n      // noNewPriviledges will remain `false` if basespec has `false` unless specified\n      // Default is always `true` in generated basespec config\n      if (exec_options.no_new_privs)\n        process->no_new_privileges = 1;\n\n      exec_opts.process = process;\n    }\n\n  exec_opts.cgroup = exec_options.cgroup;\n\n  return libcrun_container_exec_with_options (&crun_context, argv[first_arg], &exec_opts, err);\n}",
        "func_hash": 202081994104919800529457023385761628896,
        "file_name": "exec.c",
        "file_hash": 10128723194506737000766570571290960247,
        "cwe": [
            "CWE-276"
        ],
        "cve": "CVE-2022-27650",
        "cve_desc": "A flaw was found in crun where containers were incorrectly started with non-empty default permissions. A vulnerability was found in Moby (Docker Engine) where containers were started incorrectly with non-empty inheritable Linux process capabilities. This flaw allows an attacker with access to programs with inheritable file capabilities to elevate those capabilities to the permitted set when execve(2) runs.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-27650",
        "func_name": "crun_command_exec",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 197998,
        "project": "tensorflow",
        "commit_id": "704866eabe03a9aeda044ec91a8d0c83fc1ebdbe",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/704866eabe03a9aeda044ec91a8d0c83fc1ebdbe",
        "commit_message": "Fix overflow CHECK issue with `tf.raw_ops.UnsortedSegmentJoin`.\n\nPiperOrigin-RevId: 370766155\nChange-Id: I33e7c6626224e1060a8a4ab51ad5d861c6d4c63e",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext* context) override {\n    const Tensor& input = context->input(0);\n    const TensorShape& input_shape = input.shape();\n    const int32 input_dims = input_shape.dims();\n\n    const Tensor& segment_id = context->input(1);\n    const TensorShape& segment_id_shape = segment_id.shape();\n    const int32 segment_dims = segment_id_shape.dims();\n\n    const Tensor& num_segments_tensor = context->input(2);\n    auto num_segments = num_segments_tensor.scalar<NUM_SEGMENTS_TYPE>()();\n\n    OP_REQUIRES(context, segment_dims != 0,\n                errors::InvalidArgument(\"Segment_id cannot have rank 0\"));\n\n    OP_REQUIRES(\n        context, segment_dims <= input_dims,\n        errors::OutOfRange(\"Invalid segment_id rank \", segment_dims,\n                           \" for input with \", input_dims, \" dimension(s)\"));\n    for (auto i = 0; i < segment_dims; i++) {\n      OP_REQUIRES(\n          context, segment_id_shape.dim_size(i) == input_shape.dim_size(i),\n          errors::InvalidArgument(\n              \"Segment dimension is \", segment_id_shape.dim_size(i),\n              \" while input dimension is \", input_dims, \" in rank \", i));\n    }\n\n    // Making output tensor.\n    Tensor* output_tensor = nullptr;\n    TensorShape output_shape =\n        GetOutputShape(input_shape, segment_id_shape, num_segments);\n    OP_REQUIRES_OK(context, context->allocate_output(\"output\", output_shape,\n                                                     &output_tensor));\n\n    // Preparating flat tensors.\n    auto output_flat = output_tensor->flat<tstring>();\n    auto flat_segment_id = segment_id.flat<INDICES_TYPE>();\n    auto flat_input = input.flat<tstring>();\n\n    for (int i = 0; i < flat_segment_id.size(); i++) {\n      OP_REQUIRES(\n          context,\n          ((flat_segment_id(i) < num_segments) && (flat_segment_id(i) >= 0)),\n          errors::InvalidArgument(\n              \"segment_ids are not allowed to exceed num_segments or\"\n              \" to have negative values.\"));\n    }\n\n    int64 big_stride;\n    int64 small_stride;\n    std::tie(big_stride, small_stride) =\n        GetStrides<INDICES_TYPE>(input_shape, segment_id_shape);\n    auto relative_offset_set =\n        GetFlattenedRelativeOffsets<INDICES_TYPE>(small_stride, big_stride);\n    for (auto start_offset = 0; start_offset < big_stride; start_offset++) {\n      for (auto i = 0; i < relative_offset_set.size(); i++) {\n        auto output_index = start_offset + flat_segment_id(i) * big_stride;\n        auto offset = start_offset + relative_offset_set[i];\n        if (output_flat(output_index).length() != 0)\n          output_flat(output_index).append(separator_.c_str());\n        output_flat(output_index).append(flat_input(offset));\n      }\n    }\n  }",
        "func_hash": 25791049116451232925309470165962173994,
        "file_name": "unsorted_segment_join_op.cc",
        "file_hash": 172265001795447375510451213673230640731,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2021-29552",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. An attacker can cause a denial of service by controlling the values of `num_segments` tensor argument for `UnsortedSegmentJoin`. This is because the implementation(https://github.com/tensorflow/tensorflow/blob/a2a607db15c7cd01d754d37e5448d72a13491bdb/tensorflow/core/kernels/unsorted_segment_join_op.cc#L92-L93) assumes that the `num_segments` tensor is a valid scalar. Since the tensor is empty the `CHECK` involved in `.scalar<T>()()` that checks that the number of elements is exactly 1 will be invalidated and this would result in process termination. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-29552",
        "func_name": "Compute",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 198003,
        "project": "tensorflow",
        "commit_id": "e86605c0a336c088b638da02135ea6f9f6753618",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/e86605c0a336c088b638da02135ea6f9f6753618",
        "commit_message": "Fix FPE in inpace update ops.\n\nPiperOrigin-RevId: 388303197\nChange-Id: Ib48309b6213ffe53eba81004b00e889d653e4b83",
        "target": 1,
        "irrelevant": 1,
        "func_before": "  void Compute(OpKernelContext* ctx) override {\n    auto x = ctx->input(0);\n    auto i = ctx->input(1);\n    auto v = ctx->input(2);\n\n    OP_REQUIRES(ctx, TensorShapeUtils::IsVector(i.shape()),\n                errors::InvalidArgument(\"i must be a vector. \",\n                                        i.shape().DebugString()));\n    OP_REQUIRES(ctx, x.dims() == v.dims(),\n                errors::InvalidArgument(\n                    \"x and v shape doesn't match (ranks differ): \",\n                    x.shape().DebugString(), \" vs. \", v.shape().DebugString()));\n    for (int i = 1; i < x.dims(); ++i) {\n      OP_REQUIRES(\n          ctx, x.dim_size(i) == v.dim_size(i),\n          errors::InvalidArgument(\"x and v shape doesn't match at index \", i,\n                                  \" : \", x.shape().DebugString(), \" vs. \",\n                                  v.shape().DebugString()));\n    }\n    OP_REQUIRES(ctx, i.dim_size(0) == v.dim_size(0),\n                errors::InvalidArgument(\n                    \"i and x shape doesn't match at index 0: \",\n                    i.shape().DebugString(), \" vs. \", v.shape().DebugString()));\n\n    Tensor y = x;  // This creates an alias intentionally.\n    // Skip processing if tensors are empty.\n    if (x.NumElements() > 0 || v.NumElements() > 0) {\n      OP_REQUIRES_OK(ctx, DoCompute(ctx, i, v, &y));\n    }\n    ctx->set_output(0, y);\n  }",
        "func_hash": 239122710109603573986035577656659080255,
        "file_name": "inplace_ops.cc",
        "file_hash": 227256482225018419801828296351506660662,
        "cwe": [
            "CWE-369"
        ],
        "cve": "CVE-2021-37660",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions an attacker can cause a floating point exception by calling inplace operations with crafted arguments that would result in a division by 0. The [implementation](https://github.com/tensorflow/tensorflow/blob/84d053187cb80d975ef2b9684d4b61981bca0c41/tensorflow/core/kernels/inplace_ops.cc#L283) has a logic error: it should skip processing if `x` and `v` are empty but the code uses `||` instead of `&&`. We have patched the issue in GitHub commit e86605c0a336c088b638da02135ea6f9f6753618. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37660",
        "func_name": "Compute",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 198004,
        "project": "tensorflow",
        "commit_id": "b5cdbf12ffcaaffecf98f22a6be5a64bb96e4f58",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/b5cdbf12ffcaaffecf98f22a6be5a64bb96e4f58",
        "commit_message": "Prevent overflow due to integer conversion to unsigned.\n\nPiperOrigin-RevId: 387738045\nChange-Id: Id7e95bc07e02df1c66b72bd09f389608c87bdebe",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext* context) override {\n    // boxes: [batch_size, num_anchors, q, 4]\n    const Tensor& boxes = context->input(0);\n    // scores: [batch_size, num_anchors, num_classes]\n    const Tensor& scores = context->input(1);\n    OP_REQUIRES(\n        context, (boxes.dim_size(0) == scores.dim_size(0)),\n        errors::InvalidArgument(\"boxes and scores must have same batch size\"));\n\n    // max_output_size: scalar\n    const Tensor& max_output_size = context->input(2);\n    OP_REQUIRES(\n        context, TensorShapeUtils::IsScalar(max_output_size.shape()),\n        errors::InvalidArgument(\"max_size_per_class must be 0-D, got shape \",\n                                max_output_size.shape().DebugString()));\n    const int max_size_per_class = max_output_size.scalar<int>()();\n    // max_total_size: scalar\n    const Tensor& max_total_size = context->input(3);\n    OP_REQUIRES(\n        context, TensorShapeUtils::IsScalar(max_total_size.shape()),\n        errors::InvalidArgument(\"max_total_size must be 0-D, got shape \",\n                                max_total_size.shape().DebugString()));\n    const int max_total_size_per_batch = max_total_size.scalar<int>()();\n    OP_REQUIRES(context, max_total_size_per_batch > 0,\n                errors::InvalidArgument(\"max_total_size must be > 0\"));\n    // Throw warning when `max_total_size` is too large as it may cause OOM.\n    if (max_total_size_per_batch > pow(10, 6)) {\n      LOG(WARNING) << \"Detected a large value for `max_total_size`. This may \"\n                   << \"cause OOM error. (max_total_size: \"\n                   << max_total_size.scalar<int>()() << \")\";\n    }\n    // iou_threshold: scalar\n    const Tensor& iou_threshold = context->input(4);\n    OP_REQUIRES(context, TensorShapeUtils::IsScalar(iou_threshold.shape()),\n                errors::InvalidArgument(\"iou_threshold must be 0-D, got shape \",\n                                        iou_threshold.shape().DebugString()));\n    const float iou_threshold_val = iou_threshold.scalar<float>()();\n\n    // score_threshold: scalar\n    const Tensor& score_threshold = context->input(5);\n    OP_REQUIRES(\n        context, TensorShapeUtils::IsScalar(score_threshold.shape()),\n        errors::InvalidArgument(\"score_threshold must be 0-D, got shape \",\n                                score_threshold.shape().DebugString()));\n    const float score_threshold_val = score_threshold.scalar<float>()();\n\n    OP_REQUIRES(context, iou_threshold_val >= 0 && iou_threshold_val <= 1,\n                errors::InvalidArgument(\"iou_threshold must be in [0, 1]\"));\n    int num_boxes = 0;\n    const int num_classes = scores.dim_size(2);\n    ParseAndCheckCombinedNMSBoxSizes(context, boxes, &num_boxes, num_classes);\n    CheckCombinedNMSScoreSizes(context, num_boxes, scores);\n\n    if (!context->status().ok()) {\n      return;\n    }\n    BatchedNonMaxSuppressionOp(context, boxes, scores, num_boxes,\n                               max_size_per_class, max_total_size_per_batch,\n                               score_threshold_val, iou_threshold_val,\n                               pad_per_class_, clip_boxes_);\n  }",
        "func_hash": 210673426581575547249707641301751491612,
        "file_name": "non_max_suppression_op.cc",
        "file_hash": 139290447269713266938093065325537015681,
        "cwe": [
            "CWE-369"
        ],
        "cve": "CVE-2021-37669",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions an attacker can cause denial of service in applications serving models using `tf.raw_ops.NonMaxSuppressionV5` by triggering a division by 0. The [implementation](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/core/kernels/image/non_max_suppression_op.cc#L170-L271) uses a user controlled argument to resize a `std::vector`. However, as `std::vector::resize` takes the size argument as a `size_t` and `output_size` is an `int`, there is an implicit conversion to unsigned. If the attacker supplies a negative value, this conversion results in a crash. A similar issue occurs in `CombinedNonMaxSuppression`. We have patched the issue in GitHub commit 3a7362750d5c372420aa8f0caf7bf5b5c3d0f52d and commit [b5cdbf12ffcaaffecf98f22a6be5a64bb96e4f58. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37669",
        "func_name": "Compute",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 198010,
        "project": "radare2",
        "commit_id": "193f4fe01d7f626e2ea937450f2e0c4604420e9d",
        "project_url": "https://github.com/radare/radare2",
        "commit_url": "https://github.com/radareorg/radare2/commit/193f4fe01d7f626e2ea937450f2e0c4604420e9d",
        "commit_message": "Fix integer overflow in string search causing oobread ##crash\n\n* Reported by @greatergoodest via huntrdev\n* BountyID: 8a3dc5cb-08b3-4807-82b2-77f08c137a04\n* Reproducer bfileovf",
        "target": 1,
        "irrelevant": 1,
        "func_before": "static int string_scan_range(RList *list, RBinFile *bf, int min,\n\t\t\t      const ut64 from, const ut64 to, int type, int raw, RBinSection *section) {\n\tRBin *bin = bf->rbin;\n\tut8 tmp[R_STRING_SCAN_BUFFER_SIZE];\n\tut64 str_start, needle = from;\n\tint count = 0, i, rc, runes;\n\tint str_type = R_STRING_TYPE_DETECT;\n\n\t// if list is null it means its gonna dump\n\tr_return_val_if_fail (bf, -1);\n\n\tif (type == -1) {\n\t\ttype = R_STRING_TYPE_DETECT;\n\t}\n\tif (from == to) {\n\t\treturn 0;\n\t}\n\tif (from > to) {\n\t\teprintf (\"Invalid range to find strings 0x%\"PFMT64x\" .. 0x%\"PFMT64x\"\\n\", from, to);\n\t\treturn -1;\n\t}\n\tst64 len = (st64)(to - from);\n\tif (len < 1 || len > ST32_MAX) {\n\t\teprintf (\"String scan range is invalid (%\"PFMT64d\" bytes)\\n\", len);\n\t\treturn -1;\n\t}\n\tut8 *buf = calloc (len, 1);\n\tif (!buf || !min) {\n\t\tfree (buf);\n\t\treturn -1;\n\t}\n\tst64 vdelta = 0, pdelta = 0;\n\tRBinSection *s = NULL;\n\tbool ascii_only = false;\n\tPJ *pj = NULL;\n\tif (bf->strmode == R_MODE_JSON && !list) {\n\t\tpj = pj_new ();\n\t\tif (pj) {\n\t\t\tpj_a (pj);\n\t\t}\n\t}\n\tr_buf_read_at (bf->buf, from, buf, len);\n\tchar *charset = r_sys_getenv (\"RABIN2_CHARSET\");\n\tif (!R_STR_ISEMPTY (charset)) {\n\t\tRCharset *ch = r_charset_new ();\n\t\tif (r_charset_use (ch, charset)) {\n\t\t\tint outlen = len * 4;\n\t\t\tut8 *out = calloc (len, 4);\n\t\t\tif (out) {\n\t\t\t\tint res = r_charset_encode_str (ch, out, outlen, buf, len);\n\t\t\t\tint i;\n\t\t\t\t// TODO unknown chars should be translated to null bytes\n\t\t\t\tfor (i = 0; i < res; i++) {\n\t\t\t\t\tif (out[i] == '?') {\n\t\t\t\t\t\tout[i] = 0;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tlen = res;\n\t\t\t\tfree (buf);\n\t\t\t\tbuf = out;\n\t\t\t} else {\n\t\t\t\teprintf (\"Cannot allocate\\n\");\n\t\t\t}\n\t\t} else {\n\t\t\teprintf (\"Invalid value for RABIN2_CHARSET.\\n\");\n\t\t}\n\t\tr_charset_free (ch);\n\t}\n\tfree (charset);\n\tRConsIsBreaked is_breaked = (bin && bin->consb.is_breaked)? bin->consb.is_breaked: NULL;\n\t// may oobread\n\twhile (needle < to) {\n\t\tif (is_breaked && is_breaked ()) {\n\t\t\tbreak;\n\t\t}\n\t\t// smol optimization\n\t\tif (needle + 4 < to) {\n\t\t\tut32 n1 = r_read_le32 (buf + needle - from);\n\t\t\tif (!n1) {\n\t\t\t\tneedle += 4;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t}\n\t\trc = r_utf8_decode (buf + needle - from, to - needle, NULL);\n\t\tif (!rc) {\n\t\t\tneedle++;\n\t\t\tcontinue;\n\t\t}\n\t\tbool addr_aligned = !(needle % 4);\n\n\t\tif (type == R_STRING_TYPE_DETECT) {\n\t\t\tchar *w = (char *)buf + needle + rc - from;\n\t\t\tif (((to - needle) > 8 + rc)) {\n\t\t\t\t// TODO: support le and be\n\t\t\t\tbool is_wide32le = (needle + rc + 2 < to) && (!w[0] && !w[1] && !w[2] && w[3] && !w[4]);\n\t\t\t\t// reduce false positives\n\t\t\t\tif (is_wide32le) {\n\t\t\t\t\tif (!w[5] && !w[6] && w[7] && w[8]) {\n\t\t\t\t\t\tis_wide32le = false;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (!addr_aligned) {\n\t\t\t\t\tis_wide32le = false;\n\t\t\t\t}\n\t\t\t\t///is_wide32be &= (n1 < 0xff && n11 < 0xff); // false; // n11 < 0xff;\n\t\t\t\tif (is_wide32le  && addr_aligned) {\n\t\t\t\t\tstr_type = R_STRING_TYPE_WIDE32; // asume big endian,is there little endian w32?\n\t\t\t\t} else {\n\t\t\t\t\t// bool is_wide = (n1 && n2 && n1 < 0xff && (!n2 || n2 < 0xff));\n\t\t\t\t\tbool is_wide = needle + rc + 4 < to && !w[0] && w[1] && !w[2] && w[3] && !w[4];\n\t\t\t\t\tstr_type = is_wide? R_STRING_TYPE_WIDE: R_STRING_TYPE_ASCII;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (rc > 1) {\n\t\t\t\t\tstr_type = R_STRING_TYPE_UTF8; // could be charset if set :?\n\t\t\t\t} else {\n\t\t\t\t\tstr_type = R_STRING_TYPE_ASCII;\n\t\t\t\t}\n\t\t\t}\n\t\t} else if (type == R_STRING_TYPE_UTF8) {\n\t\t\tstr_type = R_STRING_TYPE_ASCII; // initial assumption\n\t\t} else {\n\t\t\tstr_type = type;\n\t\t}\n\t\trunes = 0;\n\t\tstr_start = needle;\n\n\t\t/* Eat a whole C string */\n\t\tfor (i = 0; i < sizeof (tmp) - 4 && needle < to; i += rc) {\n\t\t\tRRune r = {0};\n\t\t\tif (str_type == R_STRING_TYPE_WIDE32) {\n\t\t\t\trc = r_utf32le_decode (buf + needle - from, to - needle, &r);\n\t\t\t\tif (rc) {\n\t\t\t\t\trc = 4;\n\t\t\t\t}\n\t\t\t} else if (str_type == R_STRING_TYPE_WIDE) {\n\t\t\t\trc = r_utf16le_decode (buf + needle - from, to - needle, &r);\n\t\t\t\tif (rc == 1) {\n\t\t\t\t\trc = 2;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\trc = r_utf8_decode (buf + needle - from, to - needle, &r);\n\t\t\t\tif (rc > 1) {\n\t\t\t\t\tstr_type = R_STRING_TYPE_UTF8;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t/* Invalid sequence detected */\n\t\t\tif (!rc || (ascii_only && r > 0x7f)) {\n\t\t\t\tneedle++;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tneedle += rc;\n\n\t\t\tif (r_isprint (r) && r != '\\\\') {\n\t\t\t\tif (str_type == R_STRING_TYPE_WIDE32) {\n\t\t\t\t\tif (r == 0xff) {\n\t\t\t\t\t\tr = 0;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\trc = r_utf8_encode (tmp + i, r);\n\t\t\t\trunes++;\n\t\t\t\t/* Print the escape code */\n\t\t\t} else if (r && r < 0x100 && strchr (\"\\b\\v\\f\\n\\r\\t\\a\\033\\\\\", (char)r)) {\n\t\t\t\tif ((i + 32) < sizeof (tmp) && r < 93) {\n\t\t\t\t\ttmp[i + 0] = '\\\\';\n\t\t\t\t\ttmp[i + 1] = \"       abtnvfr             e  \"\n\t\t\t\t\t             \"                              \"\n\t\t\t\t\t             \"                              \"\n\t\t\t\t\t             \"  \\\\\"[r];\n\t\t\t\t} else {\n\t\t\t\t\t// string too long\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\trc = 2;\n\t\t\t\trunes++;\n\t\t\t} else {\n\t\t\t\t/* \\0 marks the end of C-strings */\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\ttmp[i++] = '\\0';\n\n\t\tif (runes < min && runes >= 2 && str_type == R_STRING_TYPE_ASCII && needle < to) {\n\t\t\t// back up past the \\0 to the last char just in case it starts a wide string\n\t\t\tneedle -= 2;\n\t\t}\n\t\tif (runes >= min) {\n\t\t\t// reduce false positives\n\t\t\tint j, num_blocks, *block_list;\n\t\t\tint *freq_list = NULL, expected_ascii, actual_ascii, num_chars;\n\t\t\tif (str_type == R_STRING_TYPE_ASCII) {\n\t\t\t\tfor (j = 0; j < i; j++) {\n\t\t\t\t\tchar ch = tmp[j];\n\t\t\t\t\tif (ch != '\\n' && ch != '\\r' && ch != '\\t') {\n\t\t\t\t\t\tif (!IS_PRINTABLE (tmp[j])) {\n\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tswitch (str_type) {\n\t\t\tcase R_STRING_TYPE_UTF8:\n\t\t\tcase R_STRING_TYPE_WIDE:\n\t\t\tcase R_STRING_TYPE_WIDE32:\n\t\t\t\tnum_blocks = 0;\n\t\t\t\tblock_list = r_utf_block_list ((const ut8*)tmp, i - 1,\n\t\t\t\t\t\tstr_type == R_STRING_TYPE_WIDE? &freq_list: NULL);\n\t\t\t\tif (block_list) {\n\t\t\t\t\tfor (j = 0; block_list[j] != -1; j++) {\n\t\t\t\t\t\tnum_blocks++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (freq_list) {\n\t\t\t\t\tnum_chars = 0;\n\t\t\t\t\tactual_ascii = 0;\n\t\t\t\t\tfor (j = 0; freq_list[j] != -1; j++) {\n\t\t\t\t\t\tnum_chars += freq_list[j];\n\t\t\t\t\t\tif (!block_list[j]) { // ASCII\n\t\t\t\t\t\t\tactual_ascii = freq_list[j];\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tfree (freq_list);\n\t\t\t\t\texpected_ascii = num_blocks ? num_chars / num_blocks : 0;\n\t\t\t\t\tif (actual_ascii > expected_ascii) {\n\t\t\t\t\t\tascii_only = true;\n\t\t\t\t\t\tneedle = str_start;\n\t\t\t\t\t\tfree (block_list);\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfree (block_list);\n\t\t\t\tif (num_blocks > R_STRING_MAX_UNI_BLOCKS) {\n\t\t\t\t\tneedle++;\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t}\n\t\t\tRBinString *bs = R_NEW0 (RBinString);\n\t\t\tif (!bs) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbs->type = str_type;\n\t\t\tbs->length = runes;\n\t\t\tbs->size = needle - str_start;\n\t\t\tbs->ordinal = count++;\n\t\t\t// TODO: move into adjust_offset\n\t\t\tswitch (str_type) {\n\t\t\tcase R_STRING_TYPE_WIDE:\n\t\t\t\tif (str_start - from > 1) {\n\t\t\t\t\tconst ut8 *p = buf + str_start - 2 - from;\n\t\t\t\t\tif (p[0] == 0xff && p[1] == 0xfe) {\n\t\t\t\t\t\tstr_start -= 2; // \\xff\\xfe\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase R_STRING_TYPE_WIDE32:\n\t\t\t\tif (str_start - from > 3) {\n\t\t\t\t\tconst ut8 *p = buf + str_start - 4 - from;\n\t\t\t\t\tif (p[0] == 0xff && p[1] == 0xfe) {\n\t\t\t\t\t\tstr_start -= 4; // \\xff\\xfe\\x00\\x00\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (!s) {\n\t\t\t\tif (section) {\n\t\t\t\t\ts = section;\n\t\t\t\t} else if (bf->o) {\n\t\t\t\t\ts = r_bin_get_section_at (bf->o, str_start, false);\n\t\t\t\t}\n\t\t\t\tif (s) {\n\t\t\t\t\tvdelta = s->vaddr;\n\t\t\t\t\tpdelta = s->paddr;\n\t\t\t\t}\n\t\t\t}\n\t\t\tut64 baddr = bf->loadaddr && bf->o? bf->o->baddr: bf->loadaddr;\n\t\t\tbs->paddr = str_start + baddr;\n\t\t\tbs->vaddr = str_start - pdelta + vdelta + baddr;\n\t\t\tbs->string = r_str_ndup ((const char *)tmp, i);\n\t\t\tif (list) {\n\t\t\t\tr_list_append (list, bs);\n\t\t\t\tif (bf->o) {\n\t\t\t\t\tht_up_insert (bf->o->strings_db, bs->vaddr, bs);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tprint_string (bf, bs, raw, pj);\n\t\t\t\tr_bin_string_free (bs);\n\t\t\t}\n\t\t\tif (from == 0 && to == bf->size) {\n\t\t\t\t/* force lookup section at the next one */\n\t\t\t\ts = NULL;\n\t\t\t}\n\t\t}\n\t\tascii_only = false;\n\t}\n\tfree (buf);\n\tif (pj) {\n\t\tpj_end (pj);\n\t\tif (bin) {\n\t\t\tRIO *io = bin->iob.io;\n\t\t\tif (io) {\n\t\t\t\tio->cb_printf (\"%s\", pj_string (pj));\n\t\t\t}\n\t\t}\n\t\tpj_free (pj);\n\t}\n\treturn count;\n}",
        "func_hash": 327958810043229005935201535284879314576,
        "file_name": "bfile.c",
        "file_hash": 285505404053025817812791776020239027950,
        "cwe": [
            "CWE-125"
        ],
        "cve": "CVE-2022-1899",
        "cve_desc": "Out-of-bounds Read in GitHub repository radareorg/radare2 prior to 5.7.0.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-1899",
        "func_name": "string_scan_range",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 198013,
        "project": "tensorflow",
        "commit_id": "3150642acbbe254e3c3c5d2232143fa591855ac9",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/3150642acbbe254e3c3c5d2232143fa591855ac9",
        "commit_message": "Fix tf.raw_ops.LoadAndRemapMatrix vulnerability with invalid `row_remapping`.\n\nCheck that `row_remapping` has the correct dims().\n\nPiperOrigin-RevId: 445522800",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext* context) override {\n    // Checks what we're remapping and inverts the relevant remapping Tensors to\n    // be maps with key = old ID, value = new ID.\n    std::unordered_map<int64_t, int64_t> old_row_to_new_row_map;\n    std::vector<bool> row_id_present;\n    const Tensor* row_remapping_t;\n    OP_REQUIRES_OK(context, context->input(\"row_remapping\", &row_remapping_t));\n    const auto row_remapping = row_remapping_t->vec<int64_t>();\n    OP_REQUIRES(context, row_remapping.size() == num_rows_,\n                errors::InvalidArgument(strings::StrCat(\n                    \"Size of row_remapping is \", row_remapping.size(),\n                    \" instead of being equal to num_rows=\", num_rows_)));\n    OP_REQUIRES_OK(context, RemapVectorToMap(row_remapping, &row_id_present,\n                                             &old_row_to_new_row_map));\n\n    // Calculates the min/max old row ID that we need to read, to save us from\n    // reading some unnecessary slices of the old tensor.\n    int64_t min_old_row = -1;\n    int64_t max_old_row = -1;\n    for (int i = 0; i < row_remapping.size(); ++i) {\n      if (min_old_row < 0 ||\n          (row_remapping(i) >= 0 && row_remapping(i) < min_old_row)) {\n        min_old_row = row_remapping(i);\n      }\n      if (max_old_row < 0 ||\n          (row_remapping(i) >= 0 && row_remapping(i) > max_old_row)) {\n        max_old_row = row_remapping(i);\n      }\n    }\n\n    // Processes the remapping for columns.\n    std::unordered_map<int64_t, int64_t> old_col_to_new_col_map;\n    std::vector<bool> col_id_present;\n    const Tensor* col_remapping_t;\n    OP_REQUIRES_OK(context, context->input(\"col_remapping\", &col_remapping_t));\n    const auto col_remapping = col_remapping_t->vec<int64_t>();\n    // Note that we always \"remap rows\", even when the row vocabulary does\n    // not change, because partitioning requires a mapping from partitioned\n    // Variables to the full checkpoints we load.\n    const bool remap_cols = col_remapping.size() > 0;\n    if (remap_cols) {\n      OP_REQUIRES(\n          context, col_remapping.size() == num_cols_,\n          errors::InvalidArgument(strings::StrCat(\n              \"Provided col_remapping, but its size is \", col_remapping.size(),\n              \" instead of being equal to num_cols=\", num_cols_)));\n      OP_REQUIRES_OK(context, RemapVectorToMap(col_remapping, &col_id_present,\n                                               &old_col_to_new_col_map));\n    } else {\n      col_id_present.clear();\n      col_id_present.resize(num_cols_, true);\n    }\n\n    // Processes the checkpoint source and the provided Tensor name.\n    const Tensor* ckpt_path_t;\n    OP_REQUIRES_OK(context, context->input(\"ckpt_path\", &ckpt_path_t));\n    OP_REQUIRES(\n        context, ckpt_path_t->NumElements() == 1,\n        errors::InvalidArgument(\"The `ckpt_path` tensor must have exactly one \"\n                                \"element, got tensor of shape \",\n                                ckpt_path_t->shape().DebugString()));\n    const string& ckpt_path = ckpt_path_t->scalar<tstring>()();\n    const Tensor* old_tensor_name_t;\n    OP_REQUIRES_OK(context,\n                   context->input(\"old_tensor_name\", &old_tensor_name_t));\n    const string& old_tensor_name = old_tensor_name_t->scalar<tstring>()();\n\n    LOG(INFO) << \"Processing checkpoint : \" << ckpt_path;\n    BundleReader reader(context->env(), ckpt_path);\n    OP_REQUIRES_OK(context, reader.status());\n\n    DataType tensor_type;\n    TensorShape tensor_shape;\n    OP_REQUIRES_OK(context, reader.LookupDtypeAndShape(\n                                old_tensor_name, &tensor_type, &tensor_shape));\n    OP_REQUIRES(context, tensor_type == DT_FLOAT,\n                errors::InvalidArgument(strings::StrCat(\n                    \"Tensor \", old_tensor_name, \" has invalid type \",\n                    DataTypeString(tensor_type), \" instead of expected type \",\n                    DataTypeString(DT_FLOAT))));\n    // This op is limited to loading Tensors of rank 2 (matrices).\n    OP_REQUIRES(\n        context, tensor_shape.dims() == 2,\n        errors::InvalidArgument(strings::StrCat(\n            \"Tensor \", old_tensor_name, \" has shape \",\n            tensor_shape.DebugString(), \" of invalid rank \",\n            tensor_shape.dims(), \" instead of expected shape of rank 2.\")));\n\n    if (!remap_cols) {\n      // TODO(weiho): Consider relaxing this restriction to allow partial column\n      // loading (even when no column remapping is specified) if there turns out\n      // to be a use case for it.\n      OP_REQUIRES(context, num_cols_ == tensor_shape.dim_size(1),\n                  errors::InvalidArgument(strings::StrCat(\n                      \"Tensor \", old_tensor_name, \" has shape \",\n                      tensor_shape.DebugString(),\n                      \", where the size of its 2nd dimension is \",\n                      tensor_shape.dim_size(1),\n                      \" instead of being equal to num_cols=\", num_cols_)));\n    }\n\n    // Uses TensorSlice to potentially load the old tensor in chunks in case\n    // memory usage is a concern.\n    std::vector<TensorSlice> tensor_slices;\n    TensorSlice slice(tensor_shape.dims());\n    if (min_old_row >= 0 && max_old_row >= 0) {\n      int64_t row_start = min_old_row;\n      // TODO(weiho): Given the list of old row IDs of interest (the keys of\n      // old_row_to_new_row_map), we could also try something smarter to\n      // find some minimal set of covering ranges for the list of old row IDs\n      // such that the size of each range is less than max_rows_in_memory_.\n      while (row_start <= max_old_row) {\n        const int64_t slice_length =\n            max_rows_in_memory_ <= 0\n                // If max_rows_in_memory_ <= 0, we just load the entire chunk.\n                ? max_old_row - row_start + 1\n                : std::min(max_rows_in_memory_, max_old_row - row_start + 1);\n        slice.set_start(0, row_start);\n        slice.set_length(0, slice_length);\n        tensor_slices.push_back(slice);\n        row_start += slice_length;\n      }\n    }\n\n    // Allocates the output matrix.\n    Tensor* output_matrix_t = nullptr;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(\"output_matrix\",\n                                            TensorShape({num_rows_, num_cols_}),\n                                            &output_matrix_t));\n    auto output_matrix = output_matrix_t->matrix<float>();\n\n    // Iterates through tensor slices and copies over values from the old tensor\n    // to the output matrix.\n    int64_t row_index = min_old_row;\n    int64_t rows_copied = 0;\n    Tensor loaded_tensor_t;\n    for (const TensorSlice& tensor_slice : tensor_slices) {\n      LOG(INFO) << \"Loading slice \" << tensor_slice.DebugString();\n      TensorShape slice_shape;\n      OP_REQUIRES_OK(context,\n                     tensor_slice.SliceTensorShape(tensor_shape, &slice_shape));\n      // Potentially re-allocates the tensor buffer since the last slice may\n      // have fewer rows than the other slices.\n      if (loaded_tensor_t.shape() != slice_shape) {\n        loaded_tensor_t = Tensor(DT_FLOAT, slice_shape);\n      }\n      OP_REQUIRES_OK(context, reader.LookupSlice(old_tensor_name, tensor_slice,\n                                                 &loaded_tensor_t));\n\n      // Iterates through the old loaded tensor slice row-by-row.\n      for (int row = 0; row < loaded_tensor_t.dim_size(0); ++row, ++row_index) {\n        if (row_index % 500000 == min_old_row) {\n          LOG(INFO) << \"Processing old row \" << row_index;\n        }\n\n        // If the old row ID is not found in old_row_to_new_row_map, continue\n        // to the next row; otherwise, copy it to the output matrix.\n        const int64_t* new_row_ptr =\n            gtl::FindOrNull(old_row_to_new_row_map, row_index);\n        if (new_row_ptr == nullptr) {\n          continue;\n        }\n        ++rows_copied;\n        const int64_t new_row = *new_row_ptr;\n\n        // Copies over the row element-by-element, in case remapping is needed\n        // along the column axis.\n        const auto& loaded_tensor = loaded_tensor_t.matrix<float>();\n        for (int old_col = 0; old_col < loaded_tensor_t.dim_size(1);\n             ++old_col) {\n          int64_t new_col = old_col;\n          if (remap_cols) {\n            const int64_t* new_col_ptr =\n                gtl::FindOrNull(old_col_to_new_col_map, old_col);\n            if (new_col_ptr == nullptr) {\n              // Column remapping is specified, but this column is not found in\n              // old_col_to_new_col_map, so we leave it uninitialized, to be\n              // filled in with initializing_values later.\n              continue;\n            }\n            new_col = *new_col_ptr;\n          }\n\n          OP_REQUIRES(context,\n                      new_row < num_rows_ && new_col < num_cols_ &&\n                          new_row >= 0 && new_col >= 0,\n                      errors::Internal(strings::StrCat(\n                          \"new_row=\", new_row, \" and new_col=\", new_col,\n                          \" should have been less than num_rows_=\", num_rows_,\n                          \" and num_cols_=\", num_cols_,\n                          \" and non-negative. This should never have happened \"\n                          \"if the code were correct. Please file a bug.\")));\n          output_matrix(new_row, new_col) = loaded_tensor(row, old_col);\n        }\n      }\n    }\n    LOG(INFO) << \"Copied \" << rows_copied << \" rows from old matrix (with \"\n              << tensor_shape.dim_size(0) << \" rows) to new matrix (with \"\n              << num_rows_ << \" rows).\";\n\n    // At this point, there are potentially whole rows/columns uninitialized\n    // (corresponding to the indices where row_id_present/col_id_present are\n    // false). We fill this in cell-by-cell using row_id_present and\n    // col_id_present while dequeuing from the initializing_values vector.\n    const Tensor* initializing_values_t;\n    OP_REQUIRES_OK(\n        context, context->input(\"initializing_values\", &initializing_values_t));\n    const auto initializing_values = initializing_values_t->flat<float>();\n    int64_t initializing_values_index = 0;\n    for (int i = 0; i < num_rows_; ++i) {\n      for (int j = 0; j < num_cols_; ++j) {\n        if (row_id_present[i] && col_id_present[j]) continue;\n        OP_REQUIRES(\n            context, initializing_values_index < initializing_values.size(),\n            errors::InvalidArgument(\n                \"initializing_values contained \", initializing_values.size(),\n                \" elements, but more missing values remain.\"));\n        output_matrix(i, j) = initializing_values(initializing_values_index);\n        ++initializing_values_index;\n      }\n    }\n\n    // Checks that we used all the given initializing values.\n    OP_REQUIRES(\n        context, initializing_values_index == initializing_values.size(),\n        errors::InvalidArgument(\n            \"initializing_values contained \", initializing_values.size(),\n            \" elements, but only \", initializing_values_index,\n            \" elements were used to fill in missing values.\"));\n  }",
        "func_hash": 219722258688637064068607537553301810412,
        "file_name": "load_and_remap_matrix_op.cc",
        "file_hash": 213297145030896672862854801534820332645,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2022-29199",
        "cve_desc": "TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, the implementation of `tf.raw_ops.LoadAndRemapMatrix does not fully validate the input arguments. This results in a `CHECK`-failure which can be used to trigger a denial of service attack. The code assumes `initializing_values` is a vector but there is no validation for this before accessing its value. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-29199",
        "func_name": "Compute",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 198116,
        "project": "tensorflow",
        "commit_id": "87158f43f05f2720a374f3e6d22a7aaa3a33f750",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/87158f43f05f2720a374f3e6d22a7aaa3a33f750",
        "commit_message": "Prevent heap OOB in sparse reduction ops.\n\nPiperOrigin-RevId: 387934524\nChange-Id: I894aa30f1e454f09b471d565b4a325da49322c1a",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext *ctx) override {\n    const Tensor *indices_t, *values_t, *shape_t, *reduction_axes_t;\n    OP_REQUIRES_OK(ctx, ctx->input(\"input_indices\", &indices_t));\n    OP_REQUIRES_OK(ctx, ctx->input(\"input_values\", &values_t));\n    OP_REQUIRES_OK(ctx, ctx->input(\"input_shape\", &shape_t));\n    OP_REQUIRES_OK(ctx, ctx->input(\"reduction_axes\", &reduction_axes_t));\n\n    OP_REQUIRES_OK(ctx, ValidateInputs(shape_t, reduction_axes_t));\n\n    // TODO(zongheng): we will call Reorder() below, which will modify\n    // in-place the underlying indices and values buffers.  To avoid\n    // surprises of this kernel being stateful, we work around the above by\n    // making deep copies here.  Remove this if/when we change Reorder()'s\n    // semantics.\n    const auto shape_vec = shape_t->vec<int64>();\n    SparseTensor sp;\n    OP_REQUIRES_OK(ctx, SparseTensor::Create(\n        tensor::DeepCopy(*indices_t), tensor::DeepCopy(*values_t),\n                    TensorShape(shape_vec), &sp));\n    ReduceDetails reduction = SparseTensorReduceHelper(\n        sp, reduction_axes_t->flat<int32>(), keep_dims_);\n\n    Tensor *out_values;\n    OP_REQUIRES_OK(\n        ctx, ctx->allocate_output(0, reduction.reduced_shape, &out_values));\n    auto out_flat = out_values->flat<T>();\n    out_flat.setZero();\n\n    Tensor tmp_reduced_val;\n    OP_REQUIRES_OK(ctx, ctx->allocate_temp(DataTypeToEnum<T>::value,\n                                           TensorShape({}), &tmp_reduced_val));\n    auto reduced_val = tmp_reduced_val.scalar<T>();\n\n    // Compute strides, and use it to convert coords to flat index.  The\n    // coordinates returned by .group() have the same ndims as group_by_dims.\n    gtl::InlinedVector<int64, 8> output_strides(reduction.group_by_dims.size());\n    if (!output_strides.empty()) {  // Do this iff we don't reduce all.\n      output_strides.back() = 1;\n      for (int d = output_strides.size() - 2; d >= 0; --d) {\n        output_strides[d] =\n            output_strides[d + 1] * shape_vec(reduction.group_by_dims[d + 1]);\n      }\n    }\n\n    auto CoordinatesToFlatIndex = [](ArraySlice<int64> coords,\n                                     ArraySlice<int64> strides) -> int64 {\n      if (strides.empty()) {  // Reduce all.\n        return 0;\n      }\n      CHECK_EQ(coords.size(), strides.size());\n      int64_t idx = 0;\n      for (int i = 0; i < coords.size(); ++i) {\n        idx += coords[i] * strides[i];\n      }\n      return idx;\n    };\n\n    // Each group maps one-on-one onto a value in the reduced tensor.\n    // g.group() provides the coordinates of a particular reduced value.\n    sp.Reorder<T>(reduction.reorder_dims);\n    for (const auto &g : sp.group(reduction.group_by_dims)) {\n      Op::template Run<T>(ctx, reduced_val, g.template values<T>());\n      const int64_t idx = CoordinatesToFlatIndex(g.group(), output_strides);\n      out_flat(idx) = reduced_val();\n      VLOG(2) << \"coords: \" << absl::StrJoin(g.group(), \",\")\n              << \"; idx: \" << idx << \"; group \" << Op::Name() << \": \"\n              << reduced_val();\n    }\n  }",
        "func_hash": 226769425429975920381040402527052798393,
        "file_name": "sparse_reduce_op.cc",
        "file_hash": 21049285234129890276227338943103143863,
        "cwe": [
            "CWE-125"
        ],
        "cve": "CVE-2021-37635",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions the implementation of sparse reduction operations in TensorFlow can trigger accesses outside of bounds of heap allocated data. The [implementation](https://github.com/tensorflow/tensorflow/blob/a1bc56203f21a5a4995311825ffaba7a670d7747/tensorflow/core/kernels/sparse_reduce_op.cc#L217-L228) fails to validate that each reduction group does not overflow and that each corresponding index does not point to outside the bounds of the input tensor. We have patched the issue in GitHub commit 87158f43f05f2720a374f3e6d22a7aaa3a33f750. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37635",
        "func_name": "Compute",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 198117,
        "project": "tensorflow",
        "commit_id": "0f931751fb20f565c4e94aa6df58d54a003cdb30",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/0f931751fb20f565c4e94aa6df58d54a003cdb30",
        "commit_message": "Validate dimensions of input tensor in `FractionalAvgPoolGrad`\n\nPiperOrigin-RevId: 388286227\nChange-Id: Ieb7566155e92acc8993a2212c76deacadc0edc8a",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext* context) override {\n    // Here's the basic idea:\n    // Batch and depth dimension are independent from row and col dimension. And\n    // because FractionalAvgPool currently only support pooling along row and\n    // col, we can basically think of this 4D tensor backpropagation as\n    // operation of a series of 2D planes.\n    //\n    // For each element of a 'slice' (2D plane) of output_backprop, we need to\n    // figure out its contributors when doing FractionalAvgPool operation. This\n    // can be done based on row_pooling_sequence, col_pooling_seq and\n    // overlapping.\n    // Once we figure out the original contributors, we just need to evenly\n    // divide the value of this element among these contributors.\n    //\n    // Internally, we divide the out_backprop tensor and store it in a temporary\n    // tensor of double type. And cast it to the corresponding type.\n    typedef Eigen::Map<const Eigen::Matrix<T, Eigen::Dynamic, Eigen::Dynamic>>\n        ConstEigenMatrixMap;\n    typedef Eigen::Map<Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic>>\n        EigenDoubleMatrixMap;\n\n    // Grab the inputs.\n    const Tensor& orig_input_tensor_shape = context->input(0);\n    OP_REQUIRES(context,\n                orig_input_tensor_shape.dims() == 1 &&\n                    orig_input_tensor_shape.NumElements() == 4,\n                errors::InvalidArgument(\"original input tensor shape must be\"\n                                        \"1-dimensional and 4 elements\"));\n    const Tensor& out_backprop = context->input(1);\n    const Tensor& row_seq_tensor = context->input(2);\n    const Tensor& col_seq_tensor = context->input(3);\n\n    const int64_t out_batch = out_backprop.dim_size(0);\n    const int64_t out_rows = out_backprop.dim_size(1);\n    const int64_t out_cols = out_backprop.dim_size(2);\n    const int64_t out_depth = out_backprop.dim_size(3);\n\n    OP_REQUIRES(context, row_seq_tensor.NumElements() > out_rows,\n                errors::InvalidArgument(\"Given out_backprop shape \",\n                                        out_backprop.shape().DebugString(),\n                                        \", row_seq_tensor must have at least \",\n                                        out_rows + 1, \" elements, but got \",\n                                        row_seq_tensor.NumElements()));\n    OP_REQUIRES(context, col_seq_tensor.NumElements() > out_cols,\n                errors::InvalidArgument(\"Given out_backprop shape \",\n                                        out_backprop.shape().DebugString(),\n                                        \", col_seq_tensor must have at least \",\n                                        out_cols + 1, \" elements, but got \",\n                                        col_seq_tensor.NumElements()));\n\n    auto row_seq_tensor_flat = row_seq_tensor.flat<int64>();\n    auto col_seq_tensor_flat = col_seq_tensor.flat<int64>();\n    auto orig_input_tensor_shape_flat = orig_input_tensor_shape.flat<int64>();\n\n    const int64_t in_batch = orig_input_tensor_shape_flat(0);\n    const int64_t in_rows = orig_input_tensor_shape_flat(1);\n    const int64_t in_cols = orig_input_tensor_shape_flat(2);\n    const int64_t in_depth = orig_input_tensor_shape_flat(3);\n\n    constexpr int tensor_in_and_out_dims = 4;\n    // Transform orig_input_tensor_shape into TensorShape\n    TensorShape in_shape;\n    for (auto i = 0; i < tensor_in_and_out_dims; ++i) {\n      in_shape.AddDim(orig_input_tensor_shape_flat(i));\n    }\n\n    // Create intermediate in_backprop.\n    Tensor in_backprop_tensor_temp;\n    OP_REQUIRES_OK(context, context->forward_input_or_allocate_temp(\n                                {0}, DataTypeToEnum<double>::v(), in_shape,\n                                &in_backprop_tensor_temp));\n    in_backprop_tensor_temp.flat<double>().setZero();\n    // Transform 4D tensor to 2D matrix.\n    EigenDoubleMatrixMap in_backprop_tensor_temp_mat(\n        in_backprop_tensor_temp.flat<double>().data(), in_depth,\n        in_cols * in_rows * in_batch);\n    ConstEigenMatrixMap out_backprop_mat(out_backprop.flat<T>().data(),\n                                         out_depth,\n                                         out_cols * out_rows * out_batch);\n    // Loop through each element of out_backprop and evenly distribute the\n    // element to the corresponding pooling cell.\n    const int64_t in_max_row_index = in_rows - 1;\n    const int64_t in_max_col_index = in_cols - 1;\n    for (int64_t b = 0; b < out_batch; ++b) {\n      for (int64_t r = 0; r < out_rows; ++r) {\n        const int64_t in_row_start = row_seq_tensor_flat(r);\n        int64_t in_row_end = overlapping_ ? row_seq_tensor_flat(r + 1)\n                                          : row_seq_tensor_flat(r + 1) - 1;\n        in_row_end = std::min(in_row_end, in_max_row_index);\n        for (int64_t c = 0; c < out_cols; ++c) {\n          const int64_t in_col_start = col_seq_tensor_flat(c);\n          int64_t in_col_end = overlapping_ ? col_seq_tensor_flat(c + 1)\n                                            : col_seq_tensor_flat(c + 1) - 1;\n          in_col_end = std::min(in_col_end, in_max_col_index);\n\n          const int64_t num_elements_in_pooling_cell =\n              (in_row_end - in_row_start + 1) * (in_col_end - in_col_start + 1);\n          const int64_t out_index = (b * out_rows + r) * out_cols + c;\n          // Now we can evenly distribute out_backprop(b, h, w, *) to\n          // in_backprop(b, hs:he, ws:we, *).\n          for (int64_t in_r = in_row_start; in_r <= in_row_end; ++in_r) {\n            for (int64_t in_c = in_col_start; in_c <= in_col_end; ++in_c) {\n              const int64_t in_index = (b * in_rows + in_r) * in_cols + in_c;\n              // Walk through each channel (depth).\n              for (int64_t d = 0; d < out_depth; ++d) {\n                const double out_backprop_element = static_cast<double>(\n                    out_backprop_mat.coeffRef(d, out_index));\n                double& in_backprop_ref =\n                    in_backprop_tensor_temp_mat.coeffRef(d, in_index);\n                in_backprop_ref +=\n                    out_backprop_element / num_elements_in_pooling_cell;\n              }\n            }\n          }\n        }\n      }\n    }\n\n    // Depending on the type, cast double to type T.\n    Tensor* in_backprop_tensor = nullptr;\n    OP_REQUIRES_OK(context, context->forward_input_or_allocate_output(\n                                {0}, 0, in_shape, &in_backprop_tensor));\n    auto in_backprop_tensor_flat = in_backprop_tensor->flat<T>();\n    auto in_backprop_tensor_temp_flat = in_backprop_tensor_temp.flat<double>();\n    for (int64_t i = 0; i < in_backprop_tensor_flat.size(); ++i) {\n      in_backprop_tensor_flat(i) =\n          static_cast<T>(in_backprop_tensor_temp_flat(i));\n    }\n  }",
        "func_hash": 1946187127976060435937085266146503817,
        "file_name": "fractional_avg_pool_op.cc",
        "file_hash": 123284094403203358257933187084228510511,
        "cwe": [
            "CWE-476"
        ],
        "cve": "CVE-2021-37651",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions the implementation for `tf.raw_ops.FractionalAvgPoolGrad` can be tricked into accessing data outside of bounds of heap allocated buffers. The [implementation](https://github.com/tensorflow/tensorflow/blob/f24faa153ad31a4b51578f8181d3aaab77a1ddeb/tensorflow/core/kernels/fractional_avg_pool_op.cc#L205) does not validate that the input tensor is non-empty. Thus, code constructs an empty `EigenDoubleMatrixMap` and then accesses this buffer with indices that are outside of the empty area. We have patched the issue in GitHub commit 0f931751fb20f565c4e94aa6df58d54a003cdb30. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37651",
        "func_name": "Compute",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 198146,
        "project": "tensorflow",
        "commit_id": "429f009d2b2c09028647dd4bb7b3f6f414bbaad7",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/429f009d2b2c09028647dd4bb7b3f6f414bbaad7",
        "commit_message": "Add remaining missing validation to `BoostedTreesCalculateBestFeatureSplit`\n\nPiperOrigin-RevId: 387423006\nChange-Id: I8eaf30efb223011519e60707bfa751b275d3a443",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext* const context) override {\n    // node_id_range\n    const Tensor* node_id_range_t;\n    OP_REQUIRES_OK(context, context->input(\"node_id_range\", &node_id_range_t));\n    const auto node_id_range = node_id_range_t->vec<int32>();\n    const int32_t node_id_first = node_id_range(0);  // inclusive\n    const int32_t node_id_last = node_id_range(1);   // exclusive\n\n    const Tensor* stats_summary_t;\n    OP_REQUIRES_OK(context, context->input(\"stats_summary\", &stats_summary_t));\n    TTypes<float, 4>::ConstTensor stats_summary =\n        stats_summary_t->tensor<float, 4>();\n    const int32_t feature_dims = stats_summary_t->dim_size(1);\n    // The last bucket is for default/missing value.\n    const int32_t num_buckets = stats_summary_t->dim_size(2) - 1;\n    const int32_t logits_dim = logits_dim_;\n    const int32_t hessian_dim = stats_summary_t->dim_size(3) - logits_dim;\n    DCHECK_GT(hessian_dim, 0);\n    DCHECK_LE(hessian_dim, logits_dim * logits_dim);\n\n    const Tensor* l1_t;\n    OP_REQUIRES_OK(context, context->input(\"l1\", &l1_t));\n    const auto l1 = l1_t->scalar<float>()();\n    DCHECK_GE(l1, 0);\n    if (logits_dim_ > 1) {\n      // Multi-class L1 regularization not supported yet.\n      DCHECK_EQ(l1, 0);\n    }\n\n    const Tensor* l2_t;\n    OP_REQUIRES_OK(context, context->input(\"l2\", &l2_t));\n    const auto l2 = l2_t->scalar<float>()();\n    DCHECK_GE(l2, 0);\n\n    const Tensor* tree_complexity_t;\n    OP_REQUIRES_OK(context,\n                   context->input(\"tree_complexity\", &tree_complexity_t));\n    const auto tree_complexity = tree_complexity_t->scalar<float>()();\n\n    const Tensor* min_node_weight_t;\n    OP_REQUIRES_OK(context,\n                   context->input(\"min_node_weight\", &min_node_weight_t));\n    const auto min_node_weight = min_node_weight_t->scalar<float>()();\n\n    std::vector<int32> output_node_ids;\n    std::vector<float> output_gains;\n    std::vector<int32> output_feature_dimensions;\n    std::vector<int32> output_thresholds;\n    std::vector<Eigen::VectorXf> output_left_node_contribs;\n    std::vector<Eigen::VectorXf> output_right_node_contribs;\n    std::vector<string> output_split_types;\n\n    // TODO(tanzheny) parallelize the computation.\n    // Iterate each node and find the best gain per node.\n    for (int32_t node_id = node_id_first; node_id < node_id_last; ++node_id) {\n      float best_gain = std::numeric_limits<float>::lowest();\n      int32_t best_bucket = 0;\n      int32_t best_f_dim = 0;\n      string best_split_type;\n      Eigen::VectorXf best_contrib_for_left(logits_dim);\n      Eigen::VectorXf best_contrib_for_right(logits_dim);\n      float parent_gain;\n\n      // Including default bucket.\n      ConstMatrixMap stats_mat(&stats_summary(node_id, 0, 0, 0),\n                               num_buckets + 1, logits_dim + hessian_dim);\n      const Eigen::VectorXf total_grad =\n          stats_mat.leftCols(logits_dim).colwise().sum();\n      const Eigen::VectorXf total_hess =\n          stats_mat.rightCols(hessian_dim).colwise().sum();\n      if (total_hess.norm() < min_node_weight) {\n        continue;\n      }\n      Eigen::VectorXf parent_weight(logits_dim);\n      CalculateWeightsAndGains(total_grad, total_hess, l1, l2, &parent_weight,\n                               &parent_gain);\n\n      if (split_type_ == \"inequality\") {\n        CalculateBestInequalitySplit(\n            stats_summary, node_id, feature_dims, logits_dim, hessian_dim,\n            num_buckets, min_node_weight, l1, l2, &best_gain, &best_bucket,\n            &best_f_dim, &best_split_type, &best_contrib_for_left,\n            &best_contrib_for_right);\n      } else {\n        CalculateBestEqualitySplit(\n            stats_summary, total_grad, total_hess, node_id, feature_dims,\n            logits_dim, hessian_dim, num_buckets, l1, l2, &best_gain,\n            &best_bucket, &best_f_dim, &best_split_type, &best_contrib_for_left,\n            &best_contrib_for_right);\n      }\n\n      if (best_gain == std::numeric_limits<float>::lowest()) {\n        // Do not add the node if not split if found.\n        continue;\n      }\n      output_node_ids.push_back(node_id);\n      // Remove the parent gain for the parent node.\n      output_gains.push_back(best_gain - parent_gain);\n      output_feature_dimensions.push_back(best_f_dim);\n      // default direction is fixed for dense splits.\n      // TODO(tanzheny) account for default values.\n      output_split_types.push_back(best_split_type);\n      output_thresholds.push_back(best_bucket);\n      output_left_node_contribs.push_back(best_contrib_for_left);\n      output_right_node_contribs.push_back(best_contrib_for_right);\n    }  // for node id\n    const int num_nodes = output_node_ids.size();\n    // output_node_ids\n    Tensor* output_node_ids_t = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(\"node_ids\", {num_nodes},\n                                                     &output_node_ids_t));\n    auto output_node_ids_vec = output_node_ids_t->vec<int32>();\n\n    // output_gains\n    Tensor* output_gains_t;\n    OP_REQUIRES_OK(context, context->allocate_output(\"gains\", {num_nodes},\n                                                     &output_gains_t));\n    auto output_gains_vec = output_gains_t->vec<float>();\n\n    // output_feature_dimensions\n    Tensor* output_feature_dimension_t;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(\"feature_dimensions\", {num_nodes},\n                                            &output_feature_dimension_t));\n    auto output_feature_dimensions_vec =\n        output_feature_dimension_t->vec<int32>();\n\n    // output_thresholds\n    Tensor* output_thresholds_t;\n    OP_REQUIRES_OK(context, context->allocate_output(\"thresholds\", {num_nodes},\n                                                     &output_thresholds_t));\n    auto output_thresholds_vec = output_thresholds_t->vec<int32>();\n\n    // output_left_node_contribs\n    Tensor* output_left_node_contribs_t;\n    OP_REQUIRES_OK(context, context->allocate_output(\n                                \"left_node_contribs\", {num_nodes, logits_dim},\n                                &output_left_node_contribs_t));\n    auto output_left_node_contribs_matrix =\n        output_left_node_contribs_t->matrix<float>();\n\n    // output_right_node_contribs\n    Tensor* output_right_node_contribs_t;\n    OP_REQUIRES_OK(context, context->allocate_output(\n                                \"right_node_contribs\", {num_nodes, logits_dim},\n                                &output_right_node_contribs_t));\n    auto output_right_node_contribs_matrix =\n        output_right_node_contribs_t->matrix<float>();\n\n    // split type\n    Tensor* output_split_types_t;\n    OP_REQUIRES_OK(\n        context, context->allocate_output(\"split_with_default_directions\",\n                                          {num_nodes}, &output_split_types_t));\n    auto output_split_types_vec = output_split_types_t->vec<tstring>();\n\n    // Sets output tensors from vectors.\n    for (int i = 0; i < num_nodes; ++i) {\n      output_node_ids_vec(i) = output_node_ids[i];\n      // Adjust the gains to penalize by tree complexity.\n      output_gains_vec(i) = output_gains[i] - tree_complexity;\n      output_feature_dimensions_vec(i) = output_feature_dimensions[i];\n      output_thresholds_vec(i) = output_thresholds[i];\n      for (int j = 0; j < logits_dim; ++j) {\n        output_left_node_contribs_matrix(i, j) =\n            output_left_node_contribs[i][j];\n        output_right_node_contribs_matrix(i, j) =\n            output_right_node_contribs[i][j];\n      }\n      output_split_types_vec(i) = output_split_types[i];\n    }\n  }",
        "func_hash": 329288218153569846583726994870166814749,
        "file_name": "stats_ops.cc",
        "file_hash": 99816312750255630357955125041994485531,
        "cwe": [
            "CWE-824"
        ],
        "cve": "CVE-2021-37662",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions an attacker can generate undefined behavior via a reference binding to nullptr in `BoostedTreesCalculateBestGainsPerFeature` and similar attack can occur in `BoostedTreesCalculateBestFeatureSplitV2`. The [implementation](https://github.com/tensorflow/tensorflow/blob/84d053187cb80d975ef2b9684d4b61981bca0c41/tensorflow/core/kernels/boosted_trees/stats_ops.cc) does not validate the input values. We have patched the issue in GitHub commit 9c87c32c710d0b5b53dc6fd3bfde4046e1f7a5ad and in commit 429f009d2b2c09028647dd4bb7b3f6f414bbaad7. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37662",
        "func_name": "Compute",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 198161,
        "project": "ImageMagick",
        "commit_id": "a6240a163cb787909703d9fc649cf861f60ddd7c",
        "project_url": "https://github.com/ImageMagick/ImageMagick",
        "commit_url": "https://github.com/ImageMagick/ImageMagick/commit/a6240a163cb787909703d9fc649cf861f60ddd7c",
        "commit_message": "https://github.com/ImageMagick/ImageMagick/issues/131",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static Image *ReadMATImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n  Image *image, *image2=NULL,\n   *rotated_image;\n  register Quantum *q;\n\n  unsigned int status;\n  MATHeader MATLAB_HDR;\n  size_t size;  \n  size_t CellType;\n  QuantumInfo *quantum_info;\n  ImageInfo *clone_info;\n  int i;\n  ssize_t ldblk;\n  unsigned char *BImgBuff = NULL;\n  double MinVal, MaxVal;\n  unsigned z, z2;\n  unsigned Frames;\n  int logging;\n  int sample_size;\n  MagickOffsetType filepos=0x80;\n  BlobInfo *blob;\n  size_t one;\n  \n  unsigned int (*ReadBlobXXXLong)(Image *image);\n  unsigned short (*ReadBlobXXXShort)(Image *image);\n  void (*ReadBlobDoublesXXX)(Image * image, size_t len, double *data);\n  void (*ReadBlobFloatsXXX)(Image * image, size_t len, float *data);\n\n\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  logging = LogMagickEvent(CoderEvent,GetMagickModule(),\"enter\"); \n\n  /*\n     Open image file.\n   */\n  image = AcquireImage(image_info,exception);\n\n  status = OpenBlob(image_info, image, ReadBinaryBlobMode, exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n     Read MATLAB image.\n   */\n  clone_info=CloneImageInfo(image_info);\n  if(ReadBlob(image,124,(unsigned char *) &MATLAB_HDR.identific) != 124)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  MATLAB_HDR.Version = ReadBlobLSBShort(image);\n  if(ReadBlob(image,2,(unsigned char *) &MATLAB_HDR.EndianIndicator) != 2)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n\n  if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\"  Endian %c%c\",\n        MATLAB_HDR.EndianIndicator[0],MATLAB_HDR.EndianIndicator[1]);\n  if (!strncmp(MATLAB_HDR.EndianIndicator, \"IM\", 2))\n  {\n    ReadBlobXXXLong = ReadBlobLSBLong;\n    ReadBlobXXXShort = ReadBlobLSBShort;\n    ReadBlobDoublesXXX = ReadBlobDoublesLSB;\n    ReadBlobFloatsXXX = ReadBlobFloatsLSB;\n    image->endian = LSBEndian;\n  } \n  else if (!strncmp(MATLAB_HDR.EndianIndicator, \"MI\", 2))\n  {\n    ReadBlobXXXLong = ReadBlobMSBLong;\n    ReadBlobXXXShort = ReadBlobMSBShort;\n    ReadBlobDoublesXXX = ReadBlobDoublesMSB;\n    ReadBlobFloatsXXX = ReadBlobFloatsMSB;\n    image->endian = MSBEndian;\n  }\n  else \n    goto MATLAB_KO;    /* unsupported endian */\n\n  if (strncmp(MATLAB_HDR.identific, \"MATLAB\", 6))\nMATLAB_KO: ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n\n  filepos = TellBlob(image);\n  while(!EOFBlob(image)) /* object parser loop */\n  {\n    Frames = 1;\n    (void) SeekBlob(image,filepos,SEEK_SET);\n    /* printf(\"pos=%X\\n\",TellBlob(image)); */\n\n    MATLAB_HDR.DataType = ReadBlobXXXLong(image);\n    if(EOFBlob(image)) break;\n    MATLAB_HDR.ObjectSize = ReadBlobXXXLong(image);\n    if(EOFBlob(image)) break;\n    filepos += MATLAB_HDR.ObjectSize + 4 + 4;\n\n    image2 = image;\n#if defined(MAGICKCORE_ZLIB_DELEGATE)\n    if(MATLAB_HDR.DataType == miCOMPRESSED)\n    {\n      image2 = DecompressBlock(image,MATLAB_HDR.ObjectSize,clone_info,exception);\n      if(image2==NULL) continue;\n      MATLAB_HDR.DataType = ReadBlobXXXLong(image2); /* replace compressed object type. */\n    }\n#endif    \n\n    if(MATLAB_HDR.DataType!=miMATRIX) continue;  /* skip another objects. */\n \n    MATLAB_HDR.unknown1 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.unknown2 = ReadBlobXXXLong(image2);  \n\n    MATLAB_HDR.unknown5 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.StructureClass = MATLAB_HDR.unknown5 & 0xFF;\n    MATLAB_HDR.StructureFlag = (MATLAB_HDR.unknown5>>8) & 0xFF;  \n\n    MATLAB_HDR.unknown3 = ReadBlobXXXLong(image2);\n    if(image!=image2)\n      MATLAB_HDR.unknown4 = ReadBlobXXXLong(image2);  /* ??? don't understand why ?? */\n    MATLAB_HDR.unknown4 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.DimFlag = ReadBlobXXXLong(image2);\n    MATLAB_HDR.SizeX = ReadBlobXXXLong(image2);\n    MATLAB_HDR.SizeY = ReadBlobXXXLong(image2);  \n   \n\n    switch(MATLAB_HDR.DimFlag)\n    {     \n      case  8: z2=z=1; break;      /* 2D matrix*/\n      case 12: z2=z = ReadBlobXXXLong(image2);  /* 3D matrix RGB*/\n           (void) ReadBlobXXXLong(image2);\n         if(z!=3) ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n         break;\n      case 16: z2=z = ReadBlobXXXLong(image2);  /* 4D matrix animation */\n         if(z!=3 && z!=1)\n            ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n           Frames = ReadBlobXXXLong(image2);\n         break;\n      default: ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n    }  \n\n    MATLAB_HDR.Flag1 = ReadBlobXXXShort(image2);\n    MATLAB_HDR.NameFlag = ReadBlobXXXShort(image2);\n\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"MATLAB_HDR.StructureClass %d\",MATLAB_HDR.StructureClass);\n    if (MATLAB_HDR.StructureClass != mxCHAR_CLASS && \n        MATLAB_HDR.StructureClass != mxSINGLE_CLASS &&    /* float + complex float */\n        MATLAB_HDR.StructureClass != mxDOUBLE_CLASS &&    /* double + complex double */\n        MATLAB_HDR.StructureClass != mxINT8_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT8_CLASS &&    /* uint8 + uint8 3D */\n        MATLAB_HDR.StructureClass != mxINT16_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT16_CLASS &&    /* uint16 + uint16 3D */\n        MATLAB_HDR.StructureClass != mxINT32_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT32_CLASS &&    /* uint32 + uint32 3D */\n        MATLAB_HDR.StructureClass != mxINT64_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT64_CLASS)    /* uint64 + uint64 3D */\n      ThrowReaderException(CoderError,\"UnsupportedCellTypeInTheMatrix\");\n\n    switch (MATLAB_HDR.NameFlag)\n    {\n      case 0:\n        size = ReadBlobXXXLong(image2);  /* Object name string size */\n        size = 4 * (ssize_t) ((size + 3 + 1) / 4);\n        (void) SeekBlob(image2, size, SEEK_CUR);\n        break;\n      case 1:\n      case 2:\n      case 3:\n      case 4:\n        (void) ReadBlob(image2, 4, (unsigned char *) &size); /* Object name string */\n        break;\n      default:\n        goto MATLAB_KO;\n    }\n\n    CellType = ReadBlobXXXLong(image2);    /* Additional object type */\n    if (logging)\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"MATLAB_HDR.CellType: %.20g\",(double) CellType);\n  \n    (void) ReadBlob(image2, 4, (unsigned char *) &size);     /* data size */\n\n    NEXT_FRAME:\n    switch (CellType)\n    {\n      case miINT8:\n      case miUINT8:\n        sample_size = 8;\n        if(MATLAB_HDR.StructureFlag & FLAG_LOGICAL) \n          image->depth = 1;\n        else\n          image->depth = 8;         /* Byte type cell */\n        ldblk = (ssize_t) MATLAB_HDR.SizeX;      \n        break;\n      case miINT16:\n      case miUINT16:\n        sample_size = 16;\n        image->depth = 16;        /* Word type cell */\n        ldblk = (ssize_t) (2 * MATLAB_HDR.SizeX);\n        break;\n      case miINT32:\n      case miUINT32:\n        sample_size = 32;\n        image->depth = 32;        /* Dword type cell */\n        ldblk = (ssize_t) (4 * MATLAB_HDR.SizeX);      \n        break;\n      case miINT64:\n      case miUINT64:\n        sample_size = 64;\n        image->depth = 64;        /* Qword type cell */\n        ldblk = (ssize_t) (8 * MATLAB_HDR.SizeX);      \n        break;   \n      case miSINGLE:\n        sample_size = 32;\n        image->depth = 32;        /* double type cell */\n        (void) SetImageOption(clone_info,\"quantum:format\",\"floating-point\");\n        if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n  {              /* complex float type cell */\n  }\n        ldblk = (ssize_t) (4 * MATLAB_HDR.SizeX);\n        break;\n      case miDOUBLE:\n        sample_size = 64; \n        image->depth = 64;        /* double type cell */\n        (void) SetImageOption(clone_info,\"quantum:format\",\"floating-point\");\nDisableMSCWarning(4127)\n        if (sizeof(double) != 8)\nRestoreMSCWarning\n          ThrowReaderException(CoderError, \"IncompatibleSizeOfDouble\");\n        if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n  {                         /* complex double type cell */        \n  }\n        ldblk = (ssize_t) (8 * MATLAB_HDR.SizeX);\n        break;\n      default:\n        ThrowReaderException(CoderError, \"UnsupportedCellTypeInTheMatrix\");\n    }\n    (void) sample_size;\n    image->columns = MATLAB_HDR.SizeX;\n    image->rows = MATLAB_HDR.SizeY;    \n    quantum_info=AcquireQuantumInfo(clone_info,image);\n    if (quantum_info == (QuantumInfo *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    one=1;\n    image->colors = one << image->depth;\n    if (image->columns == 0 || image->rows == 0)\n      goto MATLAB_KO;\n    /* Image is gray when no complex flag is set and 2D Matrix */\n    if ((MATLAB_HDR.DimFlag == 8) &&\n        ((MATLAB_HDR.StructureFlag & FLAG_COMPLEX) == 0))\n      {\n        image->type=GrayscaleType;\n        SetImageColorspace(image,GRAYColorspace,exception);\n      }\n\n\n    /*\n      If ping is true, then only set image size and colors without\n      reading any image data.\n    */\n    if (image_info->ping)\n    {\n      size_t temp = image->columns;\n      image->columns = image->rows;\n      image->rows = temp;\n      goto done_reading; /* !!!!!! BAD  !!!! */\n    }  \n    status=SetImageExtent(image,image->columns,image->rows,exception);\n    if (status == MagickFalse)\n      return(DestroyImageList(image));\n\n  /* ----- Load raster data ----- */\n    BImgBuff = (unsigned char *) AcquireQuantumMemory((size_t) (ldblk),sizeof(double));    /* Ldblk was set in the check phase */\n    if (BImgBuff == NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n\n    MinVal = 0;\n    MaxVal = 0;\n    if (CellType==miDOUBLE || CellType==miSINGLE)        /* Find Min and Max Values for floats */\n    {\n      CalcMinMax(image2, image_info->endian,  MATLAB_HDR.SizeX, MATLAB_HDR.SizeY, CellType, ldblk, BImgBuff, &quantum_info->minimum, &quantum_info->maximum);\n    }\n\n    /* Main loop for reading all scanlines */\n    if(z==1) z=0; /* read grey scanlines */\n    /* else read color scanlines */\n    do\n    {\n      for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n      {\n        q=GetAuthenticPixels(image,0,MATLAB_HDR.SizeY-i-1,image->columns,1,exception);\n        if (q == (Quantum *) NULL)\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"  MAT set image pixels returns unexpected NULL on a row %u.\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto done_reading;    /* Skip image rotation, when cannot set image pixels    */\n  }\n        if(ReadBlob(image2,ldblk,(unsigned char *)BImgBuff) != (ssize_t) ldblk)\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n             \"  MAT cannot read scanrow %u from a file.\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto ExitLoop;\n  }\n        if((CellType==miINT8 || CellType==miUINT8) && (MATLAB_HDR.StructureFlag & FLAG_LOGICAL))\n        {\n          FixLogical((unsigned char *)BImgBuff,ldblk);\n          if(ImportQuantumPixels(image,(CacheView *) NULL,quantum_info,z2qtype[z],BImgBuff,exception) <= 0)\n    {\nImportQuantumPixelsFailed:\n      if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"  MAT failed to ImportQuantumPixels for a row %u\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n      break;\n    }\n        }\n        else\n        {\n          if(ImportQuantumPixels(image,(CacheView *) NULL,quantum_info,z2qtype[z],BImgBuff,exception) <= 0)\n      goto ImportQuantumPixelsFailed;\n\n\n          if (z<=1 &&       /* fix only during a last pass z==0 || z==1 */\n          (CellType==miINT8 || CellType==miINT16 || CellType==miINT32 || CellType==miINT64))\n      FixSignedValues(image,q,MATLAB_HDR.SizeX);\n        }\n\n        if (!SyncAuthenticPixels(image,exception))\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  MAT failed to sync image pixels for a row %u\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto ExitLoop;\n  }\n      }\n    } while(z-- >= 2);\nExitLoop:\n\n\n    /* Read complex part of numbers here */\n    if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n    {        /* Find Min and Max Values for complex parts of floats */\n      CellType = ReadBlobXXXLong(image2);    /* Additional object type */\n      i = ReadBlobXXXLong(image2);           /* size of a complex part - toss away*/\n\n      if (CellType==miDOUBLE || CellType==miSINGLE)\n      {\n        CalcMinMax(image2,  image_info->endian, MATLAB_HDR.SizeX, MATLAB_HDR.SizeY, CellType, ldblk, BImgBuff, &MinVal, &MaxVal);      \n      }\n\n      if (CellType==miDOUBLE)\n        for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n  {\n          ReadBlobDoublesXXX(image2, ldblk, (double *)BImgBuff);\n          InsertComplexDoubleRow(image, (double *)BImgBuff, i, MinVal, MaxVal,\n            exception);\n  }\n\n      if (CellType==miSINGLE)\n        for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n  {\n          ReadBlobFloatsXXX(image2, ldblk, (float *)BImgBuff);\n          InsertComplexFloatRow(image,(float *)BImgBuff,i,MinVal,MaxVal,\n            exception);\n  }    \n    }\n\n      /* Image is gray when no complex flag is set and 2D Matrix AGAIN!!! */\n    if ((MATLAB_HDR.DimFlag == 8) &&\n        ((MATLAB_HDR.StructureFlag & FLAG_COMPLEX) == 0))\n      image->type=GrayscaleType;\n    if (image->depth == 1)\n      image->type=BilevelType;\n\n    if(image2==image)\n        image2 = NULL;    /* Remove shadow copy to an image before rotation. */\n\n      /*  Rotate image. */\n    rotated_image = RotateImage(image, 90.0, exception);\n    if (rotated_image != (Image *) NULL)\n    {\n        /* Remove page offsets added by RotateImage */\n      rotated_image->page.x=0;\n      rotated_image->page.y=0;\n\n      blob = rotated_image->blob;\n      rotated_image->blob = image->blob;\n      rotated_image->colors = image->colors;\n      image->blob = blob;\n      AppendImageToList(&image,rotated_image);      \n      DeleteImageFromList(&image);      \n    }\n\ndone_reading:\n\n    if(image2!=NULL)\n      if(image2!=image)\n      {\n        DeleteImageFromList(&image2); \n  if(clone_info)\n  {\n          if(clone_info->file)\n    {\n            fclose(clone_info->file);\n            clone_info->file = NULL;\n            (void) remove_utf8(clone_info->filename);\n    }\n        }    \n      }\n\n      /* Allocate next image structure. */    \n    AcquireNextImage(image_info,image,exception);\n    if (image->next == (Image *) NULL) break;                \n    image=SyncNextImageInList(image);\n    image->columns=image->rows=0;\n    image->colors=0;    \n\n      /* row scan buffer is no longer needed */\n    RelinquishMagickMemory(BImgBuff);\n    BImgBuff = NULL;\n\n    if(--Frames>0)\n    {\n      z = z2;\n      if(image2==NULL) image2 = image;\n      goto NEXT_FRAME;\n    }\n    if ((image2!=NULL) && (image2!=image))   /* Does shadow temporary decompressed image exist? */\n      {\n/*  CloseBlob(image2); */\n        DeleteImageFromList(&image2);\n        if(clone_info)\n        {\n          if(clone_info->file)\n          {\n            fclose(clone_info->file);\n            clone_info->file = NULL;\n            (void) remove_utf8(clone_info->filename);\n          }\n        }\n        }\n  }\n\n  clone_info=DestroyImageInfo(clone_info);\n  RelinquishMagickMemory(BImgBuff);\n  CloseBlob(image);\n\n\n  {\n    Image *p;    \n    ssize_t scene=0;\n    \n    /*\n      Rewind list, removing any empty images while rewinding.\n    */\n    p=image;\n    image=NULL;\n    while (p != (Image *) NULL)\n      {\n        Image *tmp=p;\n        if ((p->rows == 0) || (p->columns == 0)) {\n          p=p->previous;\n          DeleteImageFromList(&tmp);\n        } else {\n          image=p;\n          p=p->previous;\n        }\n      }\n    \n    /*\n      Fix scene numbers\n    */\n    for (p=image; p != (Image *) NULL; p=p->next)\n      p->scene=scene++;\n  }\n\n  if(clone_info != NULL)  /* cleanup garbage file from compression */\n  {\n    if(clone_info->file)\n    {\n      fclose(clone_info->file);\n      clone_info->file = NULL;\n      (void) remove_utf8(clone_info->filename);\n    }\n    DestroyImageInfo(clone_info);\n    clone_info = NULL;\n  }\n  if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\"return\");\n  if(image==NULL)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  return (image);\n}",
        "func_hash": 123189732868835832469086799441508888909,
        "file_name": "mat.c",
        "file_hash": 184758751839368977736100938972533937602,
        "cwe": [
            "CWE-125"
        ],
        "cve": "CVE-2016-10070",
        "cve_desc": "Heap-based buffer overflow in the CalcMinMax function in coders/mat.c in ImageMagick before 6.9.4-0 allows remote attackers to cause a denial of service (out-of-bounds read and application crash) via a crafted mat file.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2016-10070",
        "func_name": "ReadMATImage",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 198169,
        "project": "tensorflow",
        "commit_id": "5b048e87e4e55990dae6b547add4dae59f4e1c76",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/5b048e87e4e55990dae6b547add4dae59f4e1c76",
        "commit_message": "Fix a null pointer exception in SVDF\n\nThis is due to not checking that `GetVariableInput` returns non-null tensor.\n\nAlso fix a potential null pointer exception in `GetVariableInput`.\n\nPiperOrigin-RevId: 385160147\nChange-Id: Iadf3f0705b036a9014d27caa5a8bbd91f4c4c401",
        "target": 1,
        "irrelevant": 0,
        "func_before": "TfLiteTensor* GetVariableInput(TfLiteContext* context, const TfLiteNode* node,\n                               int index) {\n  TfLiteTensor* tensor = GetMutableInput(context, node, index);\n  return tensor->is_variable ? tensor : nullptr;\n}",
        "func_hash": 10926286429278682792722078244037344195,
        "file_name": "kernel_util.cc",
        "file_hash": 18607953596861130302659896453881171161,
        "cwe": [
            "CWE-369"
        ],
        "cve": "CVE-2021-37681",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions the implementation of SVDF in TFLite is [vulnerable to a null pointer error](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/lite/kernels/svdf.cc#L300-L313). The [`GetVariableInput` function](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/lite/kernels/kernel_util.cc#L115-L119) can return a null pointer but `GetTensorData` assumes that the argument is always a valid tensor. Furthermore, because `GetVariableInput` calls [`GetMutableInput`](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/lite/kernels/kernel_util.cc#L82-L90) which might return `nullptr`, the `tensor->is_variable` expression can also trigger a null pointer exception. We have patched the issue in GitHub commit 5b048e87e4e55990dae6b547add4dae59f4e1c76. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37681",
        "func_name": "GetVariableInput",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 198170,
        "project": "tensorflow",
        "commit_id": "5b048e87e4e55990dae6b547add4dae59f4e1c76",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/5b048e87e4e55990dae6b547add4dae59f4e1c76",
        "commit_message": "Fix a null pointer exception in SVDF\n\nThis is due to not checking that `GetVariableInput` returns non-null tensor.\n\nAlso fix a potential null pointer exception in `GetVariableInput`.\n\nPiperOrigin-RevId: 385160147\nChange-Id: Iadf3f0705b036a9014d27caa5a8bbd91f4c4c401",
        "target": 1,
        "irrelevant": 0,
        "func_before": "TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n  auto* params = reinterpret_cast<TfLiteSVDFParams*>(node->builtin_data);\n  OpData* op_data = reinterpret_cast<OpData*>(node->user_data);\n\n  const TfLiteTensor* input;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n  const TfLiteTensor* weights_feature;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kWeightsFeatureTensor,\n                                          &weights_feature));\n  const TfLiteTensor* weights_time;\n  TF_LITE_ENSURE_OK(\n      context, GetInputSafe(context, node, kWeightsTimeTensor, &weights_time));\n  const TfLiteTensor* bias = GetOptionalInputTensor(context, node, kBiasTensor);\n\n  TfLiteTensor* scratch;\n  TF_LITE_ENSURE_OK(context,\n                    GetTemporarySafe(context, node, /*index=*/0, &scratch));\n\n  TfLiteTensor* state = GetVariableInput(context, node, kStateTensor);\n  TfLiteTensor* output;\n  TF_LITE_ENSURE_OK(context,\n                    GetOutputSafe(context, node, kOutputTensor, &output));\n\n  switch (weights_feature->type) {\n    case kTfLiteFloat32: {\n      reference_ops::EvalFloatSVDF(\n          params, GetTensorShape(input), GetTensorData<float>(input),\n          GetTensorShape(weights_feature),\n          GetTensorData<float>(weights_feature), GetTensorShape(weights_time),\n          GetTensorData<float>(weights_time), GetTensorShape(bias),\n          GetTensorData<float>(bias), GetTensorData<float>(scratch),\n          GetTensorData<float>(state), GetTensorShape(output),\n          GetTensorData<float>(output));\n      return kTfLiteOk;\n    }\n    case kTfLiteUInt8:\n    case kTfLiteInt8: {\n      if (input->type == kTfLiteFloat32) {\n        TfLiteTensor* input_quantized;\n        TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/1,\n                                                    &input_quantized));\n        TfLiteTensor* scaling_factors;\n        TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/2,\n                                                    &scaling_factors));\n        TfLiteTensor* float_weights_time;\n        TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/3,\n                                                    &float_weights_time));\n        TfLiteTensor* zero_points;\n        TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/4,\n                                                    &zero_points));\n        TfLiteTensor* row_sums;\n        TF_LITE_ENSURE_OK(\n            context, GetTemporarySafe(context, node, /*index=*/5, &row_sums));\n        // Dequantize weights time.\n        // TODO(alanchiao): this dequantization initialization only needs to\n        // happen once per model and should theoretically be placed in either\n        // Init or Prepare. However, TFLite doesn't allocate float_weights_time\n        // until the Eval function.\n        // TODO(alanchiao): refactor logic out into dequantize function.\n        if (!op_data->float_weights_time_initialized) {\n          const float dequantization_scale = weights_time->params.scale;\n          const int8_t* weights_time_ptr = GetTensorData<int8_t>(weights_time);\n          float* float_weights_time_ptr =\n              GetTensorData<float>(float_weights_time);\n          for (int i = 0; i < NumElements(float_weights_time); ++i) {\n            float_weights_time_ptr[i] =\n                weights_time_ptr[i] * dequantization_scale;\n          }\n          op_data->float_weights_time_initialized = true;\n        }\n\n        int32_t* zero_points_ptr = nullptr;\n        int32_t* row_sums_ptr = nullptr;\n        if (params->asymmetric_quantize_inputs && row_sums != nullptr) {\n          zero_points_ptr = GetTensorData<int32_t>(zero_points);\n          row_sums_ptr = GetTensorData<int32_t>(row_sums);\n        }\n\n        reference_ops::EvalHybridSVDF(\n            params, GetTensorShape(input), GetTensorData<float>(input),\n            GetTensorShape(weights_feature),\n            GetTensorData<int8_t>(weights_feature),\n            weights_feature->params.scale, GetTensorShape(float_weights_time),\n            GetTensorData<float>(float_weights_time), GetTensorShape(bias),\n            GetTensorData<float>(bias), GetTensorData<float>(scratch),\n            GetTensorData<float>(scaling_factors),\n            GetTensorData<int8_t>(input_quantized), GetTensorData<float>(state),\n            GetTensorShape(output), GetTensorData<float>(output),\n            zero_points_ptr, row_sums_ptr, &op_data->compute_row_sums);\n        return kTfLiteOk;\n      }\n      auto* input_params = reinterpret_cast<TfLiteAffineQuantization*>(\n          input->quantization.params);\n      auto* output_params = reinterpret_cast<TfLiteAffineQuantization*>(\n          output->quantization.params);\n      TfLiteTensor* output_temp;\n      TF_LITE_ENSURE_OK(\n          context, GetTemporarySafe(context, node, /*index=*/1, &output_temp));\n\n      // Currently supports only ReLU.\n      // TODO(jianlijianli): support other activations.\n      TF_LITE_ENSURE_EQ(context, params->activation, kTfLiteActRelu);\n\n      reference_ops::EvalIntegerSVDF(\n          params, GetTensorShape(input), GetTensorData<int8_t>(input),\n          GetTensorShape(weights_feature),\n          GetTensorData<int8_t>(weights_feature), GetTensorShape(weights_time),\n          GetTensorData<int16_t>(weights_time), GetTensorShape(bias),\n          GetTensorData<int32_t>(bias), GetTensorData<int16_t>(state),\n          GetTensorShape(output), GetTensorData<int8_t>(output),\n          GetTensorData<int32_t>(scratch), GetTensorData<int32_t>(output_temp),\n          op_data->effective_scale_1_a, op_data->effective_scale_1_b,\n          op_data->effective_scale_2_a, op_data->effective_scale_2_b,\n          input_params->zero_point->data[0],\n          output_params->zero_point->data[0]);\n      return kTfLiteOk;\n    }\n    default:\n      context->ReportError(context, \"Type %s not currently supported.\",\n                           TfLiteTypeGetName(weights_feature->type));\n      return kTfLiteError;\n  }\n}",
        "func_hash": 212919005141808616331409957930472583788,
        "file_name": "svdf.cc",
        "file_hash": 98626637255820911713355792561260448866,
        "cwe": [
            "CWE-369"
        ],
        "cve": "CVE-2021-37681",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions the implementation of SVDF in TFLite is [vulnerable to a null pointer error](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/lite/kernels/svdf.cc#L300-L313). The [`GetVariableInput` function](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/lite/kernels/kernel_util.cc#L115-L119) can return a null pointer but `GetTensorData` assumes that the argument is always a valid tensor. Furthermore, because `GetVariableInput` calls [`GetMutableInput`](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/lite/kernels/kernel_util.cc#L82-L90) which might return `nullptr`, the `tensor->is_variable` expression can also trigger a null pointer exception. We have patched the issue in GitHub commit 5b048e87e4e55990dae6b547add4dae59f4e1c76. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37681",
        "func_name": "Eval",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 198198,
        "project": "tensorflow",
        "commit_id": "01cff3f986259d661103412a20745928c727326f",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/01cff3f986259d661103412a20745928c727326f",
        "commit_message": "Fix heap OOB due to dimension mismatch in `ResourceScatterUpdate`\n\nPiperOrigin-RevId: 388292801\nChange-Id: Id9bd7244d98d41b1517d4771850b32782c0cc949",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void DoCompute(OpKernelContext* c) {\n    core::RefCountPtr<Var> v;\n    OP_REQUIRES_OK(c, LookupResource(c, HandleFromInput(c, 0), &v));\n    Tensor* params = v->tensor();\n    const Tensor& indices = c->input(1);\n    const Tensor& updates = c->input(2);\n\n    // Check that rank(updates.shape) = rank(indices.shape + params.shape[1:])\n    OP_REQUIRES(c,\n                updates.dims() == 0 ||\n                    updates.dims() == indices.dims() + params->dims() - 1,\n                errors::InvalidArgument(\n                    \"Must have updates.shape = indices.shape + \"\n                    \"params.shape[1:] or updates.shape = [], got \",\n                    \"updates.shape \", updates.shape().DebugString(),\n                    \", indices.shape \", indices.shape().DebugString(),\n                    \", params.shape \", params->shape().DebugString()));\n\n    // Check that we have enough index space\n    const int64_t N_big = indices.NumElements();\n    OP_REQUIRES(\n        c, N_big <= std::numeric_limits<Index>::max(),\n        errors::InvalidArgument(\"indices has too many elements for \",\n                                DataTypeString(DataTypeToEnum<Index>::v()),\n                                \" indexing: \", N_big, \" > \",\n                                std::numeric_limits<Index>::max()));\n    const Index N = static_cast<Index>(N_big);\n    OP_REQUIRES(\n        c, params->dim_size(0) <= std::numeric_limits<Index>::max(),\n        errors::InvalidArgument(\"params.shape[0] too large for \",\n                                DataTypeString(DataTypeToEnum<Index>::v()),\n                                \" indexing: \", params->dim_size(0), \" > \",\n                                std::numeric_limits<Index>::max()));\n\n    if (N > 0) {\n      auto indices_flat = indices.flat<Index>();\n      auto params_flat = params->flat_outer_dims<T>();\n      if (TensorShapeUtils::IsScalar(updates.shape())) {\n        const auto update = updates.scalar<T>();\n\n        functor::ScatterScalarFunctor<Device, T, Index, op> functor;\n        const Index bad_i = functor(c, c->template eigen_device<Device>(),\n                                    params_flat, update, indices_flat);\n        OP_REQUIRES(c, bad_i < 0,\n                    errors::InvalidArgument(\n                        \"indices\", SliceDebugString(indices.shape(), bad_i),\n                        \" = \", indices_flat(bad_i), \" is not in [0, \",\n                        params->dim_size(0), \")\"));\n      } else {\n        int64_t num_updates = updates.NumElements();\n        OP_REQUIRES(c, num_updates % N == 0,\n                    errors::InvalidArgument(\n                        \"shape of indices (\", indices.shape().DebugString(),\n                        \") is not compatible with the shape of updates (\",\n                        updates.shape().DebugString(), \")\"));\n        auto updates_flat = updates.shaped<T, 2>({N, num_updates / N});\n\n        functor::ScatterFunctor<Device, T, Index, op> functor;\n        const Index bad_i = functor(c, c->template eigen_device<Device>(),\n                                    params_flat, updates_flat, indices_flat);\n        OP_REQUIRES(c, bad_i < 0,\n                    errors::InvalidArgument(\n                        \"indices\", SliceDebugString(indices.shape(), bad_i),\n                        \" = \", indices_flat(bad_i), \" is not in [0, \",\n                        params->dim_size(0), \")\"));\n      }\n    }\n  }",
        "func_hash": 295685199526661026529481535318072250955,
        "file_name": "resource_variable_ops.cc",
        "file_hash": 45667374759135889125974448808093275693,
        "cwe": [
            "CWE-125"
        ],
        "cve": "CVE-2021-37655",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions an attacker can trigger a read from outside of bounds of heap allocated data by sending invalid arguments to `tf.raw_ops.ResourceScatterUpdate`. The [implementation](https://github.com/tensorflow/tensorflow/blob/f24faa153ad31a4b51578f8181d3aaab77a1ddeb/tensorflow/core/kernels/resource_variable_ops.cc#L919-L923) has an incomplete validation of the relationship between the shapes of `indices` and `updates`: instead of checking that the shape of `indices` is a prefix of the shape of `updates` (so that broadcasting can happen), code only checks that the number of elements in these two tensors are in a divisibility relationship. We have patched the issue in GitHub commit 01cff3f986259d661103412a20745928c727326f. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37655",
        "func_name": "DoCompute",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 198239,
        "project": "barebox",
        "commit_id": "a3337563c705bc8e0cf32f910b3e9e3c43d962ff",
        "project_url": "https://github.com/saschahauer/barebox",
        "commit_url": "https://github.com/saschahauer/barebox/commit/a3337563c705bc8e0cf32f910b3e9e3c43d962ff",
        "commit_message": "password: Use crypto_memneq() to compare hashes\n\nCryptographic verifications should be time-constant so that an attacker\ncannot get information about the secrets used by observing the system,\nso use crypto_memneq() rather than memcmp() to compare password hashes.\n\nSigned-off-by: Sascha Hauer <s.hauer@pengutronix.de>",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static int check_passwd(unsigned char *passwd, size_t length)\n{\n\tstruct digest *d = NULL;\n\tunsigned char *passwd1_sum;\n\tunsigned char *passwd2_sum;\n\tint ret = 0;\n\tint hash_len;\n\n\tif (IS_ENABLED(CONFIG_PASSWD_CRYPTO_PBKDF2)) {\n\t\thash_len = PBKDF2_LENGTH;\n\t} else {\n\t\td = digest_alloc(PASSWD_SUM);\n\t\tif (!d) {\n\t\t\tpr_err(\"No such digest: %s\\n\",\n\t\t\t       PASSWD_SUM ? PASSWD_SUM : \"NULL\");\n\t\t\treturn -ENOENT;\n\t\t}\n\n\t\thash_len = digest_length(d);\n\t}\n\n\tpasswd1_sum = calloc(hash_len * 2, sizeof(unsigned char));\n\tif (!passwd1_sum)\n\t\treturn -ENOMEM;\n\n\tpasswd2_sum = passwd1_sum + hash_len;\n\n\tif (is_passwd_env_enable())\n\t\tret = read_env_passwd(passwd2_sum, hash_len);\n\telse if (is_passwd_default_enable())\n\t\tret = read_default_passwd(passwd2_sum, hash_len);\n\telse\n\t\tret = -EINVAL;\n\n\tif (ret < 0)\n\t\tgoto err;\n\n\tif (IS_ENABLED(CONFIG_PASSWD_CRYPTO_PBKDF2)) {\n\t\tchar *key = passwd2_sum + PBKDF2_SALT_LEN;\n\t\tchar *salt = passwd2_sum;\n\t\tint keylen = PBKDF2_LENGTH - PBKDF2_SALT_LEN;\n\n\t\tret = pkcs5_pbkdf2_hmac_sha1(passwd, length, salt,\n\t\t\tPBKDF2_SALT_LEN, PBKDF2_COUNT, keylen, passwd1_sum);\n\t\tif (ret)\n\t\t\tgoto err;\n\n\t\tif (strncmp(passwd1_sum, key, keylen) == 0)\n\t\t\tret = 1;\n\t} else {\n\t\tret = digest_digest(d, passwd, length, passwd1_sum);\n\n\t\tif (ret)\n\t\t\tgoto err;\n\n\t\tif (strncmp(passwd1_sum, passwd2_sum, hash_len) == 0)\n\t\t\tret = 1;\n\t}\n\nerr:\n\tfree(passwd1_sum);\n\tdigest_free(d);\n\n\treturn ret;\n}",
        "func_hash": 69404159605803282192043232030112739673,
        "file_name": "password.c",
        "file_hash": 155548681482248654497093234101023237595,
        "cwe": [
            "CWE-200"
        ],
        "cve": "CVE-2021-37848",
        "cve_desc": "common/password.c in Pengutronix barebox through 2021.07.0 leaks timing information because strncmp is used during hash comparison.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37848",
        "func_name": "check_passwd",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 198259,
        "project": "tensorflow",
        "commit_id": "a2b743f6017d7b97af1fe49087ae15f0ac634373",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/a2b743f6017d7b97af1fe49087ae15f0ac634373",
        "commit_message": "Fix heap OOB in `tf.raw_ops.RaggedGather`\n\nPiperOrigin-RevId: 388355464\nChange-Id: If14d96231d1cd7aad7c4d1c22c1bab1576b75717",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext* context) override {\n    // Get the input Tensors.\n    OpInputList params_nested_splits_in;\n    OP_REQUIRES_OK(context, context->input_list(\"params_nested_splits\",\n                                                &params_nested_splits_in));\n    const Tensor& params_dense_values_in =\n        context->input(params_nested_splits_in.size());\n    const Tensor& indices_in =\n        context->input(params_nested_splits_in.size() + 1);\n\n    DCHECK_GT(params_nested_splits_in.size(), 0);  // Enforced by REGISTER_OP.\n    SPLITS_TYPE num_params = params_nested_splits_in[0].dim_size(0) - 1;\n    OP_REQUIRES_OK(context, ValidateIndices(indices_in, num_params));\n\n    OP_REQUIRES(context, params_dense_values_in.dims() > 0,\n                errors::InvalidArgument(\"params.rank must be nonzero\"));\n    SPLITS_TYPE num_params_dense_values = params_dense_values_in.dim_size(0);\n\n    // Calculate the `splits`, and store the value slices that we need to\n    // copy in `value_slices`.\n    std::vector<std::pair<SPLITS_TYPE, SPLITS_TYPE>> value_slices;\n    SPLITS_TYPE num_values = 0;\n    std::vector<std::vector<SPLITS_TYPE>> out_splits;\n    OP_REQUIRES_OK(context, MakeSplits(indices_in, params_nested_splits_in,\n                                       num_params_dense_values, &out_splits,\n                                       &value_slices, &num_values));\n\n    // Write the output tensors.\n    OP_REQUIRES_OK(context, WriteSplits(out_splits, context));\n    OP_REQUIRES_OK(context,\n                   WriteValues(params_dense_values_in, value_slices,\n                               out_splits.size(), num_values, context));\n  }",
        "func_hash": 307099744677498626698554862398752331906,
        "file_name": "ragged_gather_op.cc",
        "file_hash": 101959606941305621670893175769931334336,
        "cwe": [
            "CWE-369"
        ],
        "cve": "CVE-2021-37641",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions if the arguments to `tf.raw_ops.RaggedGather` don't determine a valid ragged tensor code can trigger a read from outside of bounds of heap allocated buffers. The [implementation](https://github.com/tensorflow/tensorflow/blob/8d72537c6abf5a44103b57b9c2e22c14f5f49698/tensorflow/core/kernels/ragged_gather_op.cc#L70) directly reads the first dimension of a tensor shape before checking that said tensor has rank of at least 1 (i.e., it is not a scalar). Furthermore, the implementation does not check that the list given by `params_nested_splits` is not an empty list of tensors. We have patched the issue in GitHub commit a2b743f6017d7b97af1fe49087ae15f0ac634373. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37641",
        "func_name": "Compute",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195385,
        "project": "flatpak",
        "commit_id": "65cbfac982cb1c83993a9e19aa424daee8e9f042",
        "project_url": "https://github.com/flatpak/flatpak",
        "commit_url": "https://github.com/flatpak/flatpak/commit/65cbfac982cb1c83993a9e19aa424daee8e9f042",
        "commit_message": "Ensure that bundles have metadata on install\n\nIf we have a bundle without metadata we wouldn't properly present\nthe permissions in the transaction.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "flatpak_dir_ensure_bundle_remote (FlatpakDir         *self,\n                                  GFile              *file,\n                                  GBytes             *extra_gpg_data,\n                                  FlatpakDecomposed **out_ref,\n                                  char              **out_checksum,\n                                  char              **out_metadata,\n                                  gboolean           *out_created_remote,\n                                  GCancellable       *cancellable,\n                                  GError            **error)\n{\n  g_autoptr(FlatpakDecomposed) ref = NULL;\n  gboolean created_remote = FALSE;\n  g_autoptr(GBytes) deploy_data = NULL;\n  g_autoptr(GVariant) metadata = NULL;\n  g_autofree char *origin = NULL;\n  g_autofree char *fp_metadata = NULL;\n  g_autofree char *basename = NULL;\n  g_autoptr(GBytes) included_gpg_data = NULL;\n  GBytes *gpg_data = NULL;\n  g_autofree char *to_checksum = NULL;\n  g_autofree char *remote = NULL;\n  g_autofree char *collection_id = NULL;\n\n  if (!flatpak_dir_ensure_repo (self, cancellable, error))\n    return NULL;\n\n  metadata = flatpak_bundle_load (file, &to_checksum,\n                                  &ref,\n                                  &origin,\n                                  NULL, &fp_metadata, NULL,\n                                  &included_gpg_data,\n                                  &collection_id,\n                                  error);\n  if (metadata == NULL)\n    return NULL;\n\n  gpg_data = extra_gpg_data ? extra_gpg_data : included_gpg_data;\n\n  deploy_data = flatpak_dir_get_deploy_data (self, ref, FLATPAK_DEPLOY_VERSION_ANY, cancellable, NULL);\n  if (deploy_data != NULL)\n    {\n      remote = g_strdup (flatpak_deploy_data_get_origin (deploy_data));\n\n      /* We need to import any gpg keys because otherwise the pull will fail */\n      if (gpg_data != NULL)\n        {\n          g_autoptr(GKeyFile) new_config = NULL;\n\n          new_config = ostree_repo_copy_config (flatpak_dir_get_repo (self));\n\n          if (!flatpak_dir_modify_remote (self, remote, new_config,\n                                          gpg_data, cancellable, error))\n            return NULL;\n        }\n    }\n  else\n    {\n      g_autofree char *id = flatpak_decomposed_dup_id (ref);\n      /* Add a remote for later updates */\n      basename = g_file_get_basename (file);\n      remote = flatpak_dir_create_origin_remote (self,\n                                                 origin,\n                                                 id,\n                                                 basename,\n                                                 flatpak_decomposed_get_ref (ref),\n                                                 gpg_data,\n                                                 collection_id,\n                                                 &created_remote,\n                                                 cancellable,\n                                                 error);\n      if (remote == NULL)\n        return NULL;\n    }\n\n  if (out_created_remote)\n    *out_created_remote = created_remote;\n\n  if (out_ref)\n    *out_ref = g_steal_pointer (&ref);\n\n  if (out_checksum)\n    *out_checksum = g_steal_pointer (&to_checksum);\n\n  if (out_metadata)\n    *out_metadata = g_steal_pointer (&fp_metadata);\n\n\n  return g_steal_pointer (&remote);\n}",
        "func_hash": 117751554146896350574194025697057651898,
        "file_name": "flatpak-dir.c",
        "file_hash": 41005800026546918810123079124181990480,
        "cwe": [
            "CWE-276"
        ],
        "cve": "CVE-2021-43860",
        "cve_desc": "Flatpak is a Linux application sandboxing and distribution framework. Prior to versions 1.12.3 and 1.10.6, Flatpak doesn't properly validate that the permissions displayed to the user for an app at install time match the actual permissions granted to the app at runtime, in the case that there's a null byte in the metadata file of an app. Therefore apps can grant themselves permissions without the consent of the user. Flatpak shows permissions to the user during install by reading them from the \"xa.metadata\" key in the commit metadata. This cannot contain a null terminator, because it is an untrusted GVariant. Flatpak compares these permissions to the *actual* metadata, from the \"metadata\" file to ensure it wasn't lied to. However, the actual metadata contents are loaded in several places where they are read as simple C-style strings. That means that, if the metadata file includes a null terminator, only the content of the file from *before* the terminator gets compared to xa.metadata. Thus, any permissions that appear in the metadata file after a null terminator are applied at runtime but not shown to the user. So maliciously crafted apps can give themselves hidden permissions. Users who have Flatpaks installed from untrusted sources are at risk in case the Flatpak has a maliciously crafted metadata file, either initially or in an update. This issue is patched in versions 1.12.3 and 1.10.6. As a workaround, users can manually check the permissions of installed apps by checking the metadata file or the xa.metadata key on the commit metadata.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-43860",
        "func_name": "flatpak_dir_ensure_bundle_remote",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195388,
        "project": "postgres",
        "commit_id": "160c0258802d10b0600d7671b1bbea55d8e17d45",
        "project_url": "https://github.com/postgres/postgres",
        "commit_url": "https://github.com/postgres/postgres/commit/160c0258802d10b0600d7671b1bbea55d8e17d45",
        "commit_message": "libpq: reject extraneous data after SSL or GSS encryption handshake.\n\nlibpq collects up to a bufferload of data whenever it reads data from\nthe socket.  When SSL or GSS encryption is requested during startup,\nany additional data received with the server's yes-or-no reply\nremained in the buffer, and would be treated as already-decrypted data\nonce the encryption handshake completed.  Thus, a man-in-the-middle\nwith the ability to inject data into the TCP connection could stuff\nsome cleartext data into the start of a supposedly encryption-protected\ndatabase session.\n\nThis could probably be abused to inject faked responses to the\nclient's first few queries, although other details of libpq's behavior\nmake that harder than it sounds.  A different line of attack is to\nexfiltrate the client's password, or other sensitive data that might\nbe sent early in the session.  That has been shown to be possible with\na server vulnerable to CVE-2021-23214.\n\nTo fix, throw a protocol-violation error if the internal buffer\nis not empty after the encryption handshake.\n\nOur thanks to Jacob Champion for reporting this problem.\n\nSecurity: CVE-2021-23222",
        "target": 1,
        "irrelevant": 0,
        "func_before": "PQconnectPoll(PGconn *conn)\n{\n\tbool\t\treset_connection_state_machine = false;\n\tbool\t\tneed_new_connection = false;\n\tPGresult   *res;\n\tchar\t\tsebuf[PG_STRERROR_R_BUFLEN];\n\tint\t\t\toptval;\n\n\tif (conn == NULL)\n\t\treturn PGRES_POLLING_FAILED;\n\n\t/* Get the new data */\n\tswitch (conn->status)\n\t{\n\t\t\t/*\n\t\t\t * We really shouldn't have been polled in these two cases, but we\n\t\t\t * can handle it.\n\t\t\t */\n\t\tcase CONNECTION_BAD:\n\t\t\treturn PGRES_POLLING_FAILED;\n\t\tcase CONNECTION_OK:\n\t\t\treturn PGRES_POLLING_OK;\n\n\t\t\t/* These are reading states */\n\t\tcase CONNECTION_AWAITING_RESPONSE:\n\t\tcase CONNECTION_AUTH_OK:\n\t\tcase CONNECTION_CHECK_WRITABLE:\n\t\tcase CONNECTION_CONSUME:\n\t\tcase CONNECTION_CHECK_STANDBY:\n\t\t\t{\n\t\t\t\t/* Load waiting data */\n\t\t\t\tint\t\t\tn = pqReadData(conn);\n\n\t\t\t\tif (n < 0)\n\t\t\t\t\tgoto error_return;\n\t\t\t\tif (n == 0)\n\t\t\t\t\treturn PGRES_POLLING_READING;\n\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t/* These are writing states, so we just proceed. */\n\t\tcase CONNECTION_STARTED:\n\t\tcase CONNECTION_MADE:\n\t\t\tbreak;\n\n\t\t\t/* Special cases: proceed without waiting. */\n\t\tcase CONNECTION_SSL_STARTUP:\n\t\tcase CONNECTION_NEEDED:\n\t\tcase CONNECTION_GSS_STARTUP:\n\t\tcase CONNECTION_CHECK_TARGET:\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tappendPQExpBufferStr(&conn->errorMessage,\n\t\t\t\t\t\t\t\t libpq_gettext(\"invalid connection state, probably indicative of memory corruption\\n\"));\n\t\t\tgoto error_return;\n\t}\n\n\nkeep_going:\t\t\t\t\t\t/* We will come back to here until there is\n\t\t\t\t\t\t\t\t * nothing left to do. */\n\n\t/* Time to advance to next address, or next host if no more addresses? */\n\tif (conn->try_next_addr)\n\t{\n\t\tif (conn->addr_cur && conn->addr_cur->ai_next)\n\t\t{\n\t\t\tconn->addr_cur = conn->addr_cur->ai_next;\n\t\t\treset_connection_state_machine = true;\n\t\t}\n\t\telse\n\t\t\tconn->try_next_host = true;\n\t\tconn->try_next_addr = false;\n\t}\n\n\t/* Time to advance to next connhost[] entry? */\n\tif (conn->try_next_host)\n\t{\n\t\tpg_conn_host *ch;\n\t\tstruct addrinfo hint;\n\t\tint\t\t\tthisport;\n\t\tint\t\t\tret;\n\t\tchar\t\tportstr[MAXPGPATH];\n\n\t\tif (conn->whichhost + 1 < conn->nconnhost)\n\t\t\tconn->whichhost++;\n\t\telse\n\t\t{\n\t\t\t/*\n\t\t\t * Oops, no more hosts.\n\t\t\t *\n\t\t\t * If we are trying to connect in \"prefer-standby\" mode, then drop\n\t\t\t * the standby requirement and start over.\n\t\t\t *\n\t\t\t * Otherwise, an appropriate error message is already set up, so\n\t\t\t * we just need to set the right status.\n\t\t\t */\n\t\t\tif (conn->target_server_type == SERVER_TYPE_PREFER_STANDBY &&\n\t\t\t\tconn->nconnhost > 0)\n\t\t\t{\n\t\t\t\tconn->target_server_type = SERVER_TYPE_PREFER_STANDBY_PASS2;\n\t\t\t\tconn->whichhost = 0;\n\t\t\t}\n\t\t\telse\n\t\t\t\tgoto error_return;\n\t\t}\n\n\t\t/* Drop any address info for previous host */\n\t\trelease_conn_addrinfo(conn);\n\n\t\t/*\n\t\t * Look up info for the new host.  On failure, log the problem in\n\t\t * conn->errorMessage, then loop around to try the next host.  (Note\n\t\t * we don't clear try_next_host until we've succeeded.)\n\t\t */\n\t\tch = &conn->connhost[conn->whichhost];\n\n\t\t/* Initialize hint structure */\n\t\tMemSet(&hint, 0, sizeof(hint));\n\t\thint.ai_socktype = SOCK_STREAM;\n\t\tconn->addrlist_family = hint.ai_family = AF_UNSPEC;\n\n\t\t/* Figure out the port number we're going to use. */\n\t\tif (ch->port == NULL || ch->port[0] == '\\0')\n\t\t\tthisport = DEF_PGPORT;\n\t\telse\n\t\t{\n\t\t\tif (!parse_int_param(ch->port, &thisport, conn, \"port\"))\n\t\t\t\tgoto error_return;\n\n\t\t\tif (thisport < 1 || thisport > 65535)\n\t\t\t{\n\t\t\t\tappendPQExpBuffer(&conn->errorMessage,\n\t\t\t\t\t\t\t\t  libpq_gettext(\"invalid port number: \\\"%s\\\"\\n\"),\n\t\t\t\t\t\t\t\t  ch->port);\n\t\t\t\tgoto keep_going;\n\t\t\t}\n\t\t}\n\t\tsnprintf(portstr, sizeof(portstr), \"%d\", thisport);\n\n\t\t/* Use pg_getaddrinfo_all() to resolve the address */\n\t\tswitch (ch->type)\n\t\t{\n\t\t\tcase CHT_HOST_NAME:\n\t\t\t\tret = pg_getaddrinfo_all(ch->host, portstr, &hint,\n\t\t\t\t\t\t\t\t\t\t &conn->addrlist);\n\t\t\t\tif (ret || !conn->addrlist)\n\t\t\t\t{\n\t\t\t\t\tappendPQExpBuffer(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t  libpq_gettext(\"could not translate host name \\\"%s\\\" to address: %s\\n\"),\n\t\t\t\t\t\t\t\t\t  ch->host, gai_strerror(ret));\n\t\t\t\t\tgoto keep_going;\n\t\t\t\t}\n\t\t\t\tbreak;\n\n\t\t\tcase CHT_HOST_ADDRESS:\n\t\t\t\thint.ai_flags = AI_NUMERICHOST;\n\t\t\t\tret = pg_getaddrinfo_all(ch->hostaddr, portstr, &hint,\n\t\t\t\t\t\t\t\t\t\t &conn->addrlist);\n\t\t\t\tif (ret || !conn->addrlist)\n\t\t\t\t{\n\t\t\t\t\tappendPQExpBuffer(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t  libpq_gettext(\"could not parse network address \\\"%s\\\": %s\\n\"),\n\t\t\t\t\t\t\t\t\t  ch->hostaddr, gai_strerror(ret));\n\t\t\t\t\tgoto keep_going;\n\t\t\t\t}\n\t\t\t\tbreak;\n\n\t\t\tcase CHT_UNIX_SOCKET:\n#ifdef HAVE_UNIX_SOCKETS\n\t\t\t\tconn->addrlist_family = hint.ai_family = AF_UNIX;\n\t\t\t\tUNIXSOCK_PATH(portstr, thisport, ch->host);\n\t\t\t\tif (strlen(portstr) >= UNIXSOCK_PATH_BUFLEN)\n\t\t\t\t{\n\t\t\t\t\tappendPQExpBuffer(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t  libpq_gettext(\"Unix-domain socket path \\\"%s\\\" is too long (maximum %d bytes)\\n\"),\n\t\t\t\t\t\t\t\t\t  portstr,\n\t\t\t\t\t\t\t\t\t  (int) (UNIXSOCK_PATH_BUFLEN - 1));\n\t\t\t\t\tgoto keep_going;\n\t\t\t\t}\n\n\t\t\t\t/*\n\t\t\t\t * NULL hostname tells pg_getaddrinfo_all to parse the service\n\t\t\t\t * name as a Unix-domain socket path.\n\t\t\t\t */\n\t\t\t\tret = pg_getaddrinfo_all(NULL, portstr, &hint,\n\t\t\t\t\t\t\t\t\t\t &conn->addrlist);\n\t\t\t\tif (ret || !conn->addrlist)\n\t\t\t\t{\n\t\t\t\t\tappendPQExpBuffer(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t  libpq_gettext(\"could not translate Unix-domain socket path \\\"%s\\\" to address: %s\\n\"),\n\t\t\t\t\t\t\t\t\t  portstr, gai_strerror(ret));\n\t\t\t\t\tgoto keep_going;\n\t\t\t\t}\n#else\n\t\t\t\tAssert(false);\n#endif\n\t\t\t\tbreak;\n\t\t}\n\n\t\t/* OK, scan this addrlist for a working server address */\n\t\tconn->addr_cur = conn->addrlist;\n\t\treset_connection_state_machine = true;\n\t\tconn->try_next_host = false;\n\t}\n\n\t/* Reset connection state machine? */\n\tif (reset_connection_state_machine)\n\t{\n\t\t/*\n\t\t * (Re) initialize our connection control variables for a set of\n\t\t * connection attempts to a single server address.  These variables\n\t\t * must persist across individual connection attempts, but we must\n\t\t * reset them when we start to consider a new server.\n\t\t */\n\t\tconn->pversion = PG_PROTOCOL(3, 0);\n\t\tconn->send_appname = true;\n#ifdef USE_SSL\n\t\t/* initialize these values based on SSL mode */\n\t\tconn->allow_ssl_try = (conn->sslmode[0] != 'd');\t/* \"disable\" */\n\t\tconn->wait_ssl_try = (conn->sslmode[0] == 'a'); /* \"allow\" */\n#endif\n#ifdef ENABLE_GSS\n\t\tconn->try_gss = (conn->gssencmode[0] != 'd');\t/* \"disable\" */\n#endif\n\n\t\treset_connection_state_machine = false;\n\t\tneed_new_connection = true;\n\t}\n\n\t/* Force a new connection (perhaps to the same server as before)? */\n\tif (need_new_connection)\n\t{\n\t\t/* Drop any existing connection */\n\t\tpqDropConnection(conn, true);\n\n\t\t/* Reset all state obtained from old server */\n\t\tpqDropServerData(conn);\n\n\t\t/* Drop any PGresult we might have, too */\n\t\tconn->asyncStatus = PGASYNC_IDLE;\n\t\tconn->xactStatus = PQTRANS_IDLE;\n\t\tconn->pipelineStatus = PQ_PIPELINE_OFF;\n\t\tpqClearAsyncResult(conn);\n\n\t\t/* Reset conn->status to put the state machine in the right state */\n\t\tconn->status = CONNECTION_NEEDED;\n\n\t\tneed_new_connection = false;\n\t}\n\n\t/* Now try to advance the state machine for this connection */\n\tswitch (conn->status)\n\t{\n\t\tcase CONNECTION_NEEDED:\n\t\t\t{\n\t\t\t\t/*\n\t\t\t\t * Try to initiate a connection to one of the addresses\n\t\t\t\t * returned by pg_getaddrinfo_all().  conn->addr_cur is the\n\t\t\t\t * next one to try.\n\t\t\t\t *\n\t\t\t\t * The extra level of braces here is historical.  It's not\n\t\t\t\t * worth reindenting this whole switch case to remove 'em.\n\t\t\t\t */\n\t\t\t\t{\n\t\t\t\t\tstruct addrinfo *addr_cur = conn->addr_cur;\n\t\t\t\t\tchar\t\thost_addr[NI_MAXHOST];\n\n\t\t\t\t\t/*\n\t\t\t\t\t * Advance to next possible host, if we've tried all of\n\t\t\t\t\t * the addresses for the current host.\n\t\t\t\t\t */\n\t\t\t\t\tif (addr_cur == NULL)\n\t\t\t\t\t{\n\t\t\t\t\t\tconn->try_next_host = true;\n\t\t\t\t\t\tgoto keep_going;\n\t\t\t\t\t}\n\n\t\t\t\t\t/* Remember current address for possible use later */\n\t\t\t\t\tmemcpy(&conn->raddr.addr, addr_cur->ai_addr,\n\t\t\t\t\t\t   addr_cur->ai_addrlen);\n\t\t\t\t\tconn->raddr.salen = addr_cur->ai_addrlen;\n\n\t\t\t\t\t/*\n\t\t\t\t\t * Set connip, too.  Note we purposely ignore strdup\n\t\t\t\t\t * failure; not a big problem if it fails.\n\t\t\t\t\t */\n\t\t\t\t\tif (conn->connip != NULL)\n\t\t\t\t\t{\n\t\t\t\t\t\tfree(conn->connip);\n\t\t\t\t\t\tconn->connip = NULL;\n\t\t\t\t\t}\n\t\t\t\t\tgetHostaddr(conn, host_addr, NI_MAXHOST);\n\t\t\t\t\tif (host_addr[0])\n\t\t\t\t\t\tconn->connip = strdup(host_addr);\n\n\t\t\t\t\t/* Try to create the socket */\n\t\t\t\t\tconn->sock = socket(addr_cur->ai_family, SOCK_STREAM, 0);\n\t\t\t\t\tif (conn->sock == PGINVALID_SOCKET)\n\t\t\t\t\t{\n\t\t\t\t\t\tint\t\t\terrorno = SOCK_ERRNO;\n\n\t\t\t\t\t\t/*\n\t\t\t\t\t\t * Silently ignore socket() failure if we have more\n\t\t\t\t\t\t * addresses to try; this reduces useless chatter in\n\t\t\t\t\t\t * cases where the address list includes both IPv4 and\n\t\t\t\t\t\t * IPv6 but kernel only accepts one family.\n\t\t\t\t\t\t */\n\t\t\t\t\t\tif (addr_cur->ai_next != NULL ||\n\t\t\t\t\t\t\tconn->whichhost + 1 < conn->nconnhost)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tconn->try_next_addr = true;\n\t\t\t\t\t\t\tgoto keep_going;\n\t\t\t\t\t\t}\n\t\t\t\t\t\temitHostIdentityInfo(conn, host_addr);\n\t\t\t\t\t\tappendPQExpBuffer(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t\t  libpq_gettext(\"could not create socket: %s\\n\"),\n\t\t\t\t\t\t\t\t\t\t  SOCK_STRERROR(errorno, sebuf, sizeof(sebuf)));\n\t\t\t\t\t\tgoto error_return;\n\t\t\t\t\t}\n\n\t\t\t\t\t/*\n\t\t\t\t\t * Once we've identified a target address, all errors\n\t\t\t\t\t * except the preceding socket()-failure case should be\n\t\t\t\t\t * prefixed with host-identity information.  (If the\n\t\t\t\t\t * connection succeeds, the contents of conn->errorMessage\n\t\t\t\t\t * won't matter, so this is harmless.)\n\t\t\t\t\t */\n\t\t\t\t\temitHostIdentityInfo(conn, host_addr);\n\n\t\t\t\t\t/*\n\t\t\t\t\t * Select socket options: no delay of outgoing data for\n\t\t\t\t\t * TCP sockets, nonblock mode, close-on-exec.  Try the\n\t\t\t\t\t * next address if any of this fails.\n\t\t\t\t\t */\n\t\t\t\t\tif (!IS_AF_UNIX(addr_cur->ai_family))\n\t\t\t\t\t{\n\t\t\t\t\t\tif (!connectNoDelay(conn))\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t/* error message already created */\n\t\t\t\t\t\t\tconn->try_next_addr = true;\n\t\t\t\t\t\t\tgoto keep_going;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif (!pg_set_noblock(conn->sock))\n\t\t\t\t\t{\n\t\t\t\t\t\tappendPQExpBuffer(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t\t  libpq_gettext(\"could not set socket to nonblocking mode: %s\\n\"),\n\t\t\t\t\t\t\t\t\t\t  SOCK_STRERROR(SOCK_ERRNO, sebuf, sizeof(sebuf)));\n\t\t\t\t\t\tconn->try_next_addr = true;\n\t\t\t\t\t\tgoto keep_going;\n\t\t\t\t\t}\n\n#ifdef F_SETFD\n\t\t\t\t\tif (fcntl(conn->sock, F_SETFD, FD_CLOEXEC) == -1)\n\t\t\t\t\t{\n\t\t\t\t\t\tappendPQExpBuffer(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t\t  libpq_gettext(\"could not set socket to close-on-exec mode: %s\\n\"),\n\t\t\t\t\t\t\t\t\t\t  SOCK_STRERROR(SOCK_ERRNO, sebuf, sizeof(sebuf)));\n\t\t\t\t\t\tconn->try_next_addr = true;\n\t\t\t\t\t\tgoto keep_going;\n\t\t\t\t\t}\n#endif\t\t\t\t\t\t\t/* F_SETFD */\n\n\t\t\t\t\tif (!IS_AF_UNIX(addr_cur->ai_family))\n\t\t\t\t\t{\n#ifndef WIN32\n\t\t\t\t\t\tint\t\t\ton = 1;\n#endif\n\t\t\t\t\t\tint\t\t\tusekeepalives = useKeepalives(conn);\n\t\t\t\t\t\tint\t\t\terr = 0;\n\n\t\t\t\t\t\tif (usekeepalives < 0)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tappendPQExpBufferStr(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t\t\t\t libpq_gettext(\"keepalives parameter must be an integer\\n\"));\n\t\t\t\t\t\t\terr = 1;\n\t\t\t\t\t\t}\n\t\t\t\t\t\telse if (usekeepalives == 0)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t/* Do nothing */\n\t\t\t\t\t\t}\n#ifndef WIN32\n\t\t\t\t\t\telse if (setsockopt(conn->sock,\n\t\t\t\t\t\t\t\t\t\t\tSOL_SOCKET, SO_KEEPALIVE,\n\t\t\t\t\t\t\t\t\t\t\t(char *) &on, sizeof(on)) < 0)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tappendPQExpBuffer(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t\t\t  libpq_gettext(\"%s(%s) failed: %s\\n\"),\n\t\t\t\t\t\t\t\t\t\t\t  \"setsockopt\",\n\t\t\t\t\t\t\t\t\t\t\t  \"SO_KEEPALIVE\",\n\t\t\t\t\t\t\t\t\t\t\t  SOCK_STRERROR(SOCK_ERRNO, sebuf, sizeof(sebuf)));\n\t\t\t\t\t\t\terr = 1;\n\t\t\t\t\t\t}\n\t\t\t\t\t\telse if (!setKeepalivesIdle(conn)\n\t\t\t\t\t\t\t\t || !setKeepalivesInterval(conn)\n\t\t\t\t\t\t\t\t || !setKeepalivesCount(conn))\n\t\t\t\t\t\t\terr = 1;\n#else\t\t\t\t\t\t\t/* WIN32 */\n#ifdef SIO_KEEPALIVE_VALS\n\t\t\t\t\t\telse if (!setKeepalivesWin32(conn))\n\t\t\t\t\t\t\terr = 1;\n#endif\t\t\t\t\t\t\t/* SIO_KEEPALIVE_VALS */\n#endif\t\t\t\t\t\t\t/* WIN32 */\n\t\t\t\t\t\telse if (!setTCPUserTimeout(conn))\n\t\t\t\t\t\t\terr = 1;\n\n\t\t\t\t\t\tif (err)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tconn->try_next_addr = true;\n\t\t\t\t\t\t\tgoto keep_going;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\t/*----------\n\t\t\t\t\t * We have three methods of blocking SIGPIPE during\n\t\t\t\t\t * send() calls to this socket:\n\t\t\t\t\t *\n\t\t\t\t\t *\t- setsockopt(sock, SO_NOSIGPIPE)\n\t\t\t\t\t *\t- send(sock, ..., MSG_NOSIGNAL)\n\t\t\t\t\t *\t- setting the signal mask to SIG_IGN during send()\n\t\t\t\t\t *\n\t\t\t\t\t * The third method requires three syscalls per send,\n\t\t\t\t\t * so we prefer either of the first two, but they are\n\t\t\t\t\t * less portable.  The state is tracked in the following\n\t\t\t\t\t * members of PGconn:\n\t\t\t\t\t *\n\t\t\t\t\t * conn->sigpipe_so\t\t- we have set up SO_NOSIGPIPE\n\t\t\t\t\t * conn->sigpipe_flag\t- we're specifying MSG_NOSIGNAL\n\t\t\t\t\t *\n\t\t\t\t\t * If we can use SO_NOSIGPIPE, then set sigpipe_so here\n\t\t\t\t\t * and we're done.  Otherwise, set sigpipe_flag so that\n\t\t\t\t\t * we will try MSG_NOSIGNAL on sends.  If we get an error\n\t\t\t\t\t * with MSG_NOSIGNAL, we'll clear that flag and revert to\n\t\t\t\t\t * signal masking.\n\t\t\t\t\t *----------\n\t\t\t\t\t */\n\t\t\t\t\tconn->sigpipe_so = false;\n#ifdef MSG_NOSIGNAL\n\t\t\t\t\tconn->sigpipe_flag = true;\n#else\n\t\t\t\t\tconn->sigpipe_flag = false;\n#endif\t\t\t\t\t\t\t/* MSG_NOSIGNAL */\n\n#ifdef SO_NOSIGPIPE\n\t\t\t\t\toptval = 1;\n\t\t\t\t\tif (setsockopt(conn->sock, SOL_SOCKET, SO_NOSIGPIPE,\n\t\t\t\t\t\t\t\t   (char *) &optval, sizeof(optval)) == 0)\n\t\t\t\t\t{\n\t\t\t\t\t\tconn->sigpipe_so = true;\n\t\t\t\t\t\tconn->sigpipe_flag = false;\n\t\t\t\t\t}\n#endif\t\t\t\t\t\t\t/* SO_NOSIGPIPE */\n\n\t\t\t\t\t/*\n\t\t\t\t\t * Start/make connection.  This should not block, since we\n\t\t\t\t\t * are in nonblock mode.  If it does, well, too bad.\n\t\t\t\t\t */\n\t\t\t\t\tif (connect(conn->sock, addr_cur->ai_addr,\n\t\t\t\t\t\t\t\taddr_cur->ai_addrlen) < 0)\n\t\t\t\t\t{\n\t\t\t\t\t\tif (SOCK_ERRNO == EINPROGRESS ||\n#ifdef WIN32\n\t\t\t\t\t\t\tSOCK_ERRNO == EWOULDBLOCK ||\n#endif\n\t\t\t\t\t\t\tSOCK_ERRNO == EINTR)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t/*\n\t\t\t\t\t\t\t * This is fine - we're in non-blocking mode, and\n\t\t\t\t\t\t\t * the connection is in progress.  Tell caller to\n\t\t\t\t\t\t\t * wait for write-ready on socket.\n\t\t\t\t\t\t\t */\n\t\t\t\t\t\t\tconn->status = CONNECTION_STARTED;\n\t\t\t\t\t\t\treturn PGRES_POLLING_WRITING;\n\t\t\t\t\t\t}\n\t\t\t\t\t\t/* otherwise, trouble */\n\t\t\t\t\t}\n\t\t\t\t\telse\n\t\t\t\t\t{\n\t\t\t\t\t\t/*\n\t\t\t\t\t\t * Hm, we're connected already --- seems the \"nonblock\n\t\t\t\t\t\t * connection\" wasn't.  Advance the state machine and\n\t\t\t\t\t\t * go do the next stuff.\n\t\t\t\t\t\t */\n\t\t\t\t\t\tconn->status = CONNECTION_STARTED;\n\t\t\t\t\t\tgoto keep_going;\n\t\t\t\t\t}\n\n\t\t\t\t\t/*\n\t\t\t\t\t * This connection failed.  Add the error report to\n\t\t\t\t\t * conn->errorMessage, then try the next address if any.\n\t\t\t\t\t */\n\t\t\t\t\tconnectFailureMessage(conn, SOCK_ERRNO);\n\t\t\t\t\tconn->try_next_addr = true;\n\t\t\t\t\tgoto keep_going;\n\t\t\t\t}\n\t\t\t}\n\n\t\tcase CONNECTION_STARTED:\n\t\t\t{\n\t\t\t\tACCEPT_TYPE_ARG3 optlen = sizeof(optval);\n\n\t\t\t\t/*\n\t\t\t\t * Write ready, since we've made it here, so the connection\n\t\t\t\t * has been made ... or has failed.\n\t\t\t\t */\n\n\t\t\t\t/*\n\t\t\t\t * Now check (using getsockopt) that there is not an error\n\t\t\t\t * state waiting for us on the socket.\n\t\t\t\t */\n\n\t\t\t\tif (getsockopt(conn->sock, SOL_SOCKET, SO_ERROR,\n\t\t\t\t\t\t\t   (char *) &optval, &optlen) == -1)\n\t\t\t\t{\n\t\t\t\t\tappendPQExpBuffer(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t  libpq_gettext(\"could not get socket error status: %s\\n\"),\n\t\t\t\t\t\t\t\t\t  SOCK_STRERROR(SOCK_ERRNO, sebuf, sizeof(sebuf)));\n\t\t\t\t\tgoto error_return;\n\t\t\t\t}\n\t\t\t\telse if (optval != 0)\n\t\t\t\t{\n\t\t\t\t\t/*\n\t\t\t\t\t * When using a nonblocking connect, we will typically see\n\t\t\t\t\t * connect failures at this point, so provide a friendly\n\t\t\t\t\t * error message.\n\t\t\t\t\t */\n\t\t\t\t\tconnectFailureMessage(conn, optval);\n\n\t\t\t\t\t/*\n\t\t\t\t\t * Try the next address if any, just as in the case where\n\t\t\t\t\t * connect() returned failure immediately.\n\t\t\t\t\t */\n\t\t\t\t\tconn->try_next_addr = true;\n\t\t\t\t\tgoto keep_going;\n\t\t\t\t}\n\n\t\t\t\t/* Fill in the client address */\n\t\t\t\tconn->laddr.salen = sizeof(conn->laddr.addr);\n\t\t\t\tif (getsockname(conn->sock,\n\t\t\t\t\t\t\t\t(struct sockaddr *) &conn->laddr.addr,\n\t\t\t\t\t\t\t\t&conn->laddr.salen) < 0)\n\t\t\t\t{\n\t\t\t\t\tappendPQExpBuffer(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t  libpq_gettext(\"could not get client address from socket: %s\\n\"),\n\t\t\t\t\t\t\t\t\t  SOCK_STRERROR(SOCK_ERRNO, sebuf, sizeof(sebuf)));\n\t\t\t\t\tgoto error_return;\n\t\t\t\t}\n\n\t\t\t\t/*\n\t\t\t\t * Make sure we can write before advancing to next step.\n\t\t\t\t */\n\t\t\t\tconn->status = CONNECTION_MADE;\n\t\t\t\treturn PGRES_POLLING_WRITING;\n\t\t\t}\n\n\t\tcase CONNECTION_MADE:\n\t\t\t{\n\t\t\t\tchar\t   *startpacket;\n\t\t\t\tint\t\t\tpacketlen;\n\n\t\t\t\t/*\n\t\t\t\t * Implement requirepeer check, if requested and it's a\n\t\t\t\t * Unix-domain socket.\n\t\t\t\t */\n\t\t\t\tif (conn->requirepeer && conn->requirepeer[0] &&\n\t\t\t\t\tIS_AF_UNIX(conn->raddr.addr.ss_family))\n\t\t\t\t{\n#ifndef WIN32\n\t\t\t\t\tchar\t\tpwdbuf[BUFSIZ];\n\t\t\t\t\tstruct passwd pass_buf;\n\t\t\t\t\tstruct passwd *pass;\n\t\t\t\t\tint\t\t\tpasserr;\n#endif\n\t\t\t\t\tuid_t\t\tuid;\n\t\t\t\t\tgid_t\t\tgid;\n\n\t\t\t\t\terrno = 0;\n\t\t\t\t\tif (getpeereid(conn->sock, &uid, &gid) != 0)\n\t\t\t\t\t{\n\t\t\t\t\t\t/*\n\t\t\t\t\t\t * Provide special error message if getpeereid is a\n\t\t\t\t\t\t * stub\n\t\t\t\t\t\t */\n\t\t\t\t\t\tif (errno == ENOSYS)\n\t\t\t\t\t\t\tappendPQExpBufferStr(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t\t\t\t libpq_gettext(\"requirepeer parameter is not supported on this platform\\n\"));\n\t\t\t\t\t\telse\n\t\t\t\t\t\t\tappendPQExpBuffer(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t\t\t  libpq_gettext(\"could not get peer credentials: %s\\n\"),\n\t\t\t\t\t\t\t\t\t\t\t  strerror_r(errno, sebuf, sizeof(sebuf)));\n\t\t\t\t\t\tgoto error_return;\n\t\t\t\t\t}\n\n#ifndef WIN32\n\t\t\t\t\tpasserr = pqGetpwuid(uid, &pass_buf, pwdbuf, sizeof(pwdbuf), &pass);\n\t\t\t\t\tif (pass == NULL)\n\t\t\t\t\t{\n\t\t\t\t\t\tif (passerr != 0)\n\t\t\t\t\t\t\tappendPQExpBuffer(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t\t\t  libpq_gettext(\"could not look up local user ID %d: %s\\n\"),\n\t\t\t\t\t\t\t\t\t\t\t  (int) uid,\n\t\t\t\t\t\t\t\t\t\t\t  strerror_r(passerr, sebuf, sizeof(sebuf)));\n\t\t\t\t\t\telse\n\t\t\t\t\t\t\tappendPQExpBuffer(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t\t\t  libpq_gettext(\"local user with ID %d does not exist\\n\"),\n\t\t\t\t\t\t\t\t\t\t\t  (int) uid);\n\t\t\t\t\t\tgoto error_return;\n\t\t\t\t\t}\n\n\t\t\t\t\tif (strcmp(pass->pw_name, conn->requirepeer) != 0)\n\t\t\t\t\t{\n\t\t\t\t\t\tappendPQExpBuffer(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t\t  libpq_gettext(\"requirepeer specifies \\\"%s\\\", but actual peer user name is \\\"%s\\\"\\n\"),\n\t\t\t\t\t\t\t\t\t\t  conn->requirepeer, pass->pw_name);\n\t\t\t\t\t\tgoto error_return;\n\t\t\t\t\t}\n#else\t\t\t\t\t\t\t/* WIN32 */\n\t\t\t\t\t/* should have failed with ENOSYS above */\n\t\t\t\t\tAssert(false);\n#endif\t\t\t\t\t\t\t/* WIN32 */\n\t\t\t\t}\n\n\t\t\t\tif (IS_AF_UNIX(conn->raddr.addr.ss_family))\n\t\t\t\t{\n\t\t\t\t\t/* Don't request SSL or GSSAPI over Unix sockets */\n#ifdef USE_SSL\n\t\t\t\t\tconn->allow_ssl_try = false;\n#endif\n#ifdef ENABLE_GSS\n\t\t\t\t\tconn->try_gss = false;\n#endif\n\t\t\t\t}\n\n#ifdef ENABLE_GSS\n\n\t\t\t\t/*\n\t\t\t\t * If GSSAPI encryption is enabled, then call\n\t\t\t\t * pg_GSS_have_cred_cache() which will return true if we can\n\t\t\t\t * acquire credentials (and give us a handle to use in\n\t\t\t\t * conn->gcred), and then send a packet to the server asking\n\t\t\t\t * for GSSAPI Encryption (and skip past SSL negotiation and\n\t\t\t\t * regular startup below).\n\t\t\t\t */\n\t\t\t\tif (conn->try_gss && !conn->gctx)\n\t\t\t\t\tconn->try_gss = pg_GSS_have_cred_cache(&conn->gcred);\n\t\t\t\tif (conn->try_gss && !conn->gctx)\n\t\t\t\t{\n\t\t\t\t\tProtocolVersion pv = pg_hton32(NEGOTIATE_GSS_CODE);\n\n\t\t\t\t\tif (pqPacketSend(conn, 0, &pv, sizeof(pv)) != STATUS_OK)\n\t\t\t\t\t{\n\t\t\t\t\t\tappendPQExpBuffer(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t\t  libpq_gettext(\"could not send GSSAPI negotiation packet: %s\\n\"),\n\t\t\t\t\t\t\t\t\t\t  SOCK_STRERROR(SOCK_ERRNO, sebuf, sizeof(sebuf)));\n\t\t\t\t\t\tgoto error_return;\n\t\t\t\t\t}\n\n\t\t\t\t\t/* Ok, wait for response */\n\t\t\t\t\tconn->status = CONNECTION_GSS_STARTUP;\n\t\t\t\t\treturn PGRES_POLLING_READING;\n\t\t\t\t}\n\t\t\t\telse if (!conn->gctx && conn->gssencmode[0] == 'r')\n\t\t\t\t{\n\t\t\t\t\tappendPQExpBufferStr(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t\t libpq_gettext(\"GSSAPI encryption required but was impossible (possibly no credential cache, no server support, or using a local socket)\\n\"));\n\t\t\t\t\tgoto error_return;\n\t\t\t\t}\n#endif\n\n#ifdef USE_SSL\n\n\t\t\t\t/*\n\t\t\t\t * Enable the libcrypto callbacks before checking if SSL needs\n\t\t\t\t * to be done.  This is done before sending the startup packet\n\t\t\t\t * as depending on the type of authentication done, like MD5\n\t\t\t\t * or SCRAM that use cryptohashes, the callbacks would be\n\t\t\t\t * required even without a SSL connection\n\t\t\t\t */\n\t\t\t\tif (pqsecure_initialize(conn, false, true) < 0)\n\t\t\t\t\tgoto error_return;\n\n\t\t\t\t/*\n\t\t\t\t * If SSL is enabled and we haven't already got encryption of\n\t\t\t\t * some sort running, request SSL instead of sending the\n\t\t\t\t * startup message.\n\t\t\t\t */\n\t\t\t\tif (conn->allow_ssl_try && !conn->wait_ssl_try &&\n\t\t\t\t\t!conn->ssl_in_use\n#ifdef ENABLE_GSS\n\t\t\t\t\t&& !conn->gssenc\n#endif\n\t\t\t\t\t)\n\t\t\t\t{\n\t\t\t\t\tProtocolVersion pv;\n\n\t\t\t\t\t/*\n\t\t\t\t\t * Send the SSL request packet.\n\t\t\t\t\t *\n\t\t\t\t\t * Theoretically, this could block, but it really\n\t\t\t\t\t * shouldn't since we only got here if the socket is\n\t\t\t\t\t * write-ready.\n\t\t\t\t\t */\n\t\t\t\t\tpv = pg_hton32(NEGOTIATE_SSL_CODE);\n\t\t\t\t\tif (pqPacketSend(conn, 0, &pv, sizeof(pv)) != STATUS_OK)\n\t\t\t\t\t{\n\t\t\t\t\t\tappendPQExpBuffer(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t\t  libpq_gettext(\"could not send SSL negotiation packet: %s\\n\"),\n\t\t\t\t\t\t\t\t\t\t  SOCK_STRERROR(SOCK_ERRNO, sebuf, sizeof(sebuf)));\n\t\t\t\t\t\tgoto error_return;\n\t\t\t\t\t}\n\t\t\t\t\t/* Ok, wait for response */\n\t\t\t\t\tconn->status = CONNECTION_SSL_STARTUP;\n\t\t\t\t\treturn PGRES_POLLING_READING;\n\t\t\t\t}\n#endif\t\t\t\t\t\t\t/* USE_SSL */\n\n\t\t\t\t/*\n\t\t\t\t * Build the startup packet.\n\t\t\t\t */\n\t\t\t\tstartpacket = pqBuildStartupPacket3(conn, &packetlen,\n\t\t\t\t\t\t\t\t\t\t\t\t\tEnvironmentOptions);\n\t\t\t\tif (!startpacket)\n\t\t\t\t{\n\t\t\t\t\tappendPQExpBufferStr(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t\t libpq_gettext(\"out of memory\\n\"));\n\t\t\t\t\tgoto error_return;\n\t\t\t\t}\n\n\t\t\t\t/*\n\t\t\t\t * Send the startup packet.\n\t\t\t\t *\n\t\t\t\t * Theoretically, this could block, but it really shouldn't\n\t\t\t\t * since we only got here if the socket is write-ready.\n\t\t\t\t */\n\t\t\t\tif (pqPacketSend(conn, 0, startpacket, packetlen) != STATUS_OK)\n\t\t\t\t{\n\t\t\t\t\tappendPQExpBuffer(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t  libpq_gettext(\"could not send startup packet: %s\\n\"),\n\t\t\t\t\t\t\t\t\t  SOCK_STRERROR(SOCK_ERRNO, sebuf, sizeof(sebuf)));\n\t\t\t\t\tfree(startpacket);\n\t\t\t\t\tgoto error_return;\n\t\t\t\t}\n\n\t\t\t\tfree(startpacket);\n\n\t\t\t\tconn->status = CONNECTION_AWAITING_RESPONSE;\n\t\t\t\treturn PGRES_POLLING_READING;\n\t\t\t}\n\n\t\t\t/*\n\t\t\t * Handle SSL negotiation: wait for postmaster messages and\n\t\t\t * respond as necessary.\n\t\t\t */\n\t\tcase CONNECTION_SSL_STARTUP:\n\t\t\t{\n#ifdef USE_SSL\n\t\t\t\tPostgresPollingStatusType pollres;\n\n\t\t\t\t/*\n\t\t\t\t * On first time through, get the postmaster's response to our\n\t\t\t\t * SSL negotiation packet.\n\t\t\t\t */\n\t\t\t\tif (!conn->ssl_in_use)\n\t\t\t\t{\n\t\t\t\t\t/*\n\t\t\t\t\t * We use pqReadData here since it has the logic to\n\t\t\t\t\t * distinguish no-data-yet from connection closure. Since\n\t\t\t\t\t * conn->ssl isn't set, a plain recv() will occur.\n\t\t\t\t\t */\n\t\t\t\t\tchar\t\tSSLok;\n\t\t\t\t\tint\t\t\trdresult;\n\n\t\t\t\t\trdresult = pqReadData(conn);\n\t\t\t\t\tif (rdresult < 0)\n\t\t\t\t\t{\n\t\t\t\t\t\t/* errorMessage is already filled in */\n\t\t\t\t\t\tgoto error_return;\n\t\t\t\t\t}\n\t\t\t\t\tif (rdresult == 0)\n\t\t\t\t\t{\n\t\t\t\t\t\t/* caller failed to wait for data */\n\t\t\t\t\t\treturn PGRES_POLLING_READING;\n\t\t\t\t\t}\n\t\t\t\t\tif (pqGetc(&SSLok, conn) < 0)\n\t\t\t\t\t{\n\t\t\t\t\t\t/* should not happen really */\n\t\t\t\t\t\treturn PGRES_POLLING_READING;\n\t\t\t\t\t}\n\t\t\t\t\tif (SSLok == 'S')\n\t\t\t\t\t{\n\t\t\t\t\t\t/* mark byte consumed */\n\t\t\t\t\t\tconn->inStart = conn->inCursor;\n\n\t\t\t\t\t\t/*\n\t\t\t\t\t\t * Set up global SSL state if required.  The crypto\n\t\t\t\t\t\t * state has already been set if libpq took care of\n\t\t\t\t\t\t * doing that, so there is no need to make that happen\n\t\t\t\t\t\t * again.\n\t\t\t\t\t\t */\n\t\t\t\t\t\tif (pqsecure_initialize(conn, true, false) != 0)\n\t\t\t\t\t\t\tgoto error_return;\n\t\t\t\t\t}\n\t\t\t\t\telse if (SSLok == 'N')\n\t\t\t\t\t{\n\t\t\t\t\t\t/* mark byte consumed */\n\t\t\t\t\t\tconn->inStart = conn->inCursor;\n\t\t\t\t\t\t/* OK to do without SSL? */\n\t\t\t\t\t\tif (conn->sslmode[0] == 'r' ||\t/* \"require\" */\n\t\t\t\t\t\t\tconn->sslmode[0] == 'v')\t/* \"verify-ca\" or\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t * \"verify-full\" */\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t/* Require SSL, but server does not want it */\n\t\t\t\t\t\t\tappendPQExpBufferStr(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t\t\t\t libpq_gettext(\"server does not support SSL, but SSL was required\\n\"));\n\t\t\t\t\t\t\tgoto error_return;\n\t\t\t\t\t\t}\n\t\t\t\t\t\t/* Otherwise, proceed with normal startup */\n\t\t\t\t\t\tconn->allow_ssl_try = false;\n\t\t\t\t\t\t/* We can proceed using this connection */\n\t\t\t\t\t\tconn->status = CONNECTION_MADE;\n\t\t\t\t\t\treturn PGRES_POLLING_WRITING;\n\t\t\t\t\t}\n\t\t\t\t\telse if (SSLok == 'E')\n\t\t\t\t\t{\n\t\t\t\t\t\t/*\n\t\t\t\t\t\t * Server failure of some sort, such as failure to\n\t\t\t\t\t\t * fork a backend process.  We need to process and\n\t\t\t\t\t\t * report the error message, which might be formatted\n\t\t\t\t\t\t * according to either protocol 2 or protocol 3.\n\t\t\t\t\t\t * Rather than duplicate the code for that, we flip\n\t\t\t\t\t\t * into AWAITING_RESPONSE state and let the code there\n\t\t\t\t\t\t * deal with it.  Note we have *not* consumed the \"E\"\n\t\t\t\t\t\t * byte here.\n\t\t\t\t\t\t */\n\t\t\t\t\t\tconn->status = CONNECTION_AWAITING_RESPONSE;\n\t\t\t\t\t\tgoto keep_going;\n\t\t\t\t\t}\n\t\t\t\t\telse\n\t\t\t\t\t{\n\t\t\t\t\t\tappendPQExpBuffer(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t\t  libpq_gettext(\"received invalid response to SSL negotiation: %c\\n\"),\n\t\t\t\t\t\t\t\t\t\t  SSLok);\n\t\t\t\t\t\tgoto error_return;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t/*\n\t\t\t\t * Begin or continue the SSL negotiation process.\n\t\t\t\t */\n\t\t\t\tpollres = pqsecure_open_client(conn);\n\t\t\t\tif (pollres == PGRES_POLLING_OK)\n\t\t\t\t{\n\t\t\t\t\t/* SSL handshake done, ready to send startup packet */\n\t\t\t\t\tconn->status = CONNECTION_MADE;\n\t\t\t\t\treturn PGRES_POLLING_WRITING;\n\t\t\t\t}\n\t\t\t\tif (pollres == PGRES_POLLING_FAILED)\n\t\t\t\t{\n\t\t\t\t\t/*\n\t\t\t\t\t * Failed ... if sslmode is \"prefer\" then do a non-SSL\n\t\t\t\t\t * retry\n\t\t\t\t\t */\n\t\t\t\t\tif (conn->sslmode[0] == 'p' /* \"prefer\" */\n\t\t\t\t\t\t&& conn->allow_ssl_try\t/* redundant? */\n\t\t\t\t\t\t&& !conn->wait_ssl_try) /* redundant? */\n\t\t\t\t\t{\n\t\t\t\t\t\t/* only retry once */\n\t\t\t\t\t\tconn->allow_ssl_try = false;\n\t\t\t\t\t\tneed_new_connection = true;\n\t\t\t\t\t\tgoto keep_going;\n\t\t\t\t\t}\n\t\t\t\t\t/* Else it's a hard failure */\n\t\t\t\t\tgoto error_return;\n\t\t\t\t}\n\t\t\t\t/* Else, return POLLING_READING or POLLING_WRITING status */\n\t\t\t\treturn pollres;\n#else\t\t\t\t\t\t\t/* !USE_SSL */\n\t\t\t\t/* can't get here */\n\t\t\t\tgoto error_return;\n#endif\t\t\t\t\t\t\t/* USE_SSL */\n\t\t\t}\n\n\t\tcase CONNECTION_GSS_STARTUP:\n\t\t\t{\n#ifdef ENABLE_GSS\n\t\t\t\tPostgresPollingStatusType pollres;\n\n\t\t\t\t/*\n\t\t\t\t * If we haven't yet, get the postmaster's response to our\n\t\t\t\t * negotiation packet\n\t\t\t\t */\n\t\t\t\tif (conn->try_gss && !conn->gctx)\n\t\t\t\t{\n\t\t\t\t\tchar\t\tgss_ok;\n\t\t\t\t\tint\t\t\trdresult = pqReadData(conn);\n\n\t\t\t\t\tif (rdresult < 0)\n\t\t\t\t\t\t/* pqReadData fills in error message */\n\t\t\t\t\t\tgoto error_return;\n\t\t\t\t\telse if (rdresult == 0)\n\t\t\t\t\t\t/* caller failed to wait for data */\n\t\t\t\t\t\treturn PGRES_POLLING_READING;\n\t\t\t\t\tif (pqGetc(&gss_ok, conn) < 0)\n\t\t\t\t\t\t/* shouldn't happen... */\n\t\t\t\t\t\treturn PGRES_POLLING_READING;\n\n\t\t\t\t\tif (gss_ok == 'E')\n\t\t\t\t\t{\n\t\t\t\t\t\t/*\n\t\t\t\t\t\t * Server failure of some sort.  Assume it's a\n\t\t\t\t\t\t * protocol version support failure, and let's see if\n\t\t\t\t\t\t * we can't recover (if it's not, we'll get a better\n\t\t\t\t\t\t * error message on retry).  Server gets fussy if we\n\t\t\t\t\t\t * don't hang up the socket, though.\n\t\t\t\t\t\t */\n\t\t\t\t\t\tconn->try_gss = false;\n\t\t\t\t\t\tneed_new_connection = true;\n\t\t\t\t\t\tgoto keep_going;\n\t\t\t\t\t}\n\n\t\t\t\t\t/* mark byte consumed */\n\t\t\t\t\tconn->inStart = conn->inCursor;\n\n\t\t\t\t\tif (gss_ok == 'N')\n\t\t\t\t\t{\n\t\t\t\t\t\t/* Server doesn't want GSSAPI; fall back if we can */\n\t\t\t\t\t\tif (conn->gssencmode[0] == 'r')\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tappendPQExpBufferStr(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t\t\t\t libpq_gettext(\"server doesn't support GSSAPI encryption, but it was required\\n\"));\n\t\t\t\t\t\t\tgoto error_return;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tconn->try_gss = false;\n\t\t\t\t\t\t/* We can proceed using this connection */\n\t\t\t\t\t\tconn->status = CONNECTION_MADE;\n\t\t\t\t\t\treturn PGRES_POLLING_WRITING;\n\t\t\t\t\t}\n\t\t\t\t\telse if (gss_ok != 'G')\n\t\t\t\t\t{\n\t\t\t\t\t\tappendPQExpBuffer(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t\t  libpq_gettext(\"received invalid response to GSSAPI negotiation: %c\\n\"),\n\t\t\t\t\t\t\t\t\t\t  gss_ok);\n\t\t\t\t\t\tgoto error_return;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t/* Begin or continue GSSAPI negotiation */\n\t\t\t\tpollres = pqsecure_open_gss(conn);\n\t\t\t\tif (pollres == PGRES_POLLING_OK)\n\t\t\t\t{\n\t\t\t\t\t/* All set for startup packet */\n\t\t\t\t\tconn->status = CONNECTION_MADE;\n\t\t\t\t\treturn PGRES_POLLING_WRITING;\n\t\t\t\t}\n\t\t\t\telse if (pollres == PGRES_POLLING_FAILED &&\n\t\t\t\t\t\t conn->gssencmode[0] == 'p')\n\t\t\t\t{\n\t\t\t\t\t/*\n\t\t\t\t\t * We failed, but we can retry on \"prefer\".  Have to drop\n\t\t\t\t\t * the current connection to do so, though.\n\t\t\t\t\t */\n\t\t\t\t\tconn->try_gss = false;\n\t\t\t\t\tneed_new_connection = true;\n\t\t\t\t\tgoto keep_going;\n\t\t\t\t}\n\t\t\t\treturn pollres;\n#else\t\t\t\t\t\t\t/* !ENABLE_GSS */\n\t\t\t\t/* unreachable */\n\t\t\t\tgoto error_return;\n#endif\t\t\t\t\t\t\t/* ENABLE_GSS */\n\t\t\t}\n\n\t\t\t/*\n\t\t\t * Handle authentication exchange: wait for postmaster messages\n\t\t\t * and respond as necessary.\n\t\t\t */\n\t\tcase CONNECTION_AWAITING_RESPONSE:\n\t\t\t{\n\t\t\t\tchar\t\tberesp;\n\t\t\t\tint\t\t\tmsgLength;\n\t\t\t\tint\t\t\tavail;\n\t\t\t\tAuthRequest areq;\n\t\t\t\tint\t\t\tres;\n\n\t\t\t\t/*\n\t\t\t\t * Scan the message from current point (note that if we find\n\t\t\t\t * the message is incomplete, we will return without advancing\n\t\t\t\t * inStart, and resume here next time).\n\t\t\t\t */\n\t\t\t\tconn->inCursor = conn->inStart;\n\n\t\t\t\t/* Read type byte */\n\t\t\t\tif (pqGetc(&beresp, conn))\n\t\t\t\t{\n\t\t\t\t\t/* We'll come back when there is more data */\n\t\t\t\t\treturn PGRES_POLLING_READING;\n\t\t\t\t}\n\n\t\t\t\t/*\n\t\t\t\t * Validate message type: we expect only an authentication\n\t\t\t\t * request or an error here.  Anything else probably means\n\t\t\t\t * it's not Postgres on the other end at all.\n\t\t\t\t */\n\t\t\t\tif (!(beresp == 'R' || beresp == 'E'))\n\t\t\t\t{\n\t\t\t\t\tappendPQExpBuffer(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t  libpq_gettext(\"expected authentication request from server, but received %c\\n\"),\n\t\t\t\t\t\t\t\t\t  beresp);\n\t\t\t\t\tgoto error_return;\n\t\t\t\t}\n\n\t\t\t\t/* Read message length word */\n\t\t\t\tif (pqGetInt(&msgLength, 4, conn))\n\t\t\t\t{\n\t\t\t\t\t/* We'll come back when there is more data */\n\t\t\t\t\treturn PGRES_POLLING_READING;\n\t\t\t\t}\n\n\t\t\t\t/*\n\t\t\t\t * Try to validate message length before using it.\n\t\t\t\t * Authentication requests can't be very large, although GSS\n\t\t\t\t * auth requests may not be that small.  Errors can be a\n\t\t\t\t * little larger, but not huge.  If we see a large apparent\n\t\t\t\t * length in an error, it means we're really talking to a\n\t\t\t\t * pre-3.0-protocol server; cope.  (Before version 14, the\n\t\t\t\t * server also used the old protocol for errors that happened\n\t\t\t\t * before processing the startup packet.)\n\t\t\t\t */\n\t\t\t\tif (beresp == 'R' && (msgLength < 8 || msgLength > 2000))\n\t\t\t\t{\n\t\t\t\t\tappendPQExpBuffer(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t  libpq_gettext(\"expected authentication request from server, but received %c\\n\"),\n\t\t\t\t\t\t\t\t\t  beresp);\n\t\t\t\t\tgoto error_return;\n\t\t\t\t}\n\n\t\t\t\tif (beresp == 'E' && (msgLength < 8 || msgLength > 30000))\n\t\t\t\t{\n\t\t\t\t\t/* Handle error from a pre-3.0 server */\n\t\t\t\t\tconn->inCursor = conn->inStart + 1; /* reread data */\n\t\t\t\t\tif (pqGets_append(&conn->errorMessage, conn))\n\t\t\t\t\t{\n\t\t\t\t\t\t/* We'll come back when there is more data */\n\t\t\t\t\t\treturn PGRES_POLLING_READING;\n\t\t\t\t\t}\n\t\t\t\t\t/* OK, we read the message; mark data consumed */\n\t\t\t\t\tconn->inStart = conn->inCursor;\n\n\t\t\t\t\t/*\n\t\t\t\t\t * Before 7.2, the postmaster didn't always end its\n\t\t\t\t\t * messages with a newline, so add one if needed to\n\t\t\t\t\t * conform to libpq conventions.\n\t\t\t\t\t */\n\t\t\t\t\tif (conn->errorMessage.len == 0 ||\n\t\t\t\t\t\tconn->errorMessage.data[conn->errorMessage.len - 1] != '\\n')\n\t\t\t\t\t{\n\t\t\t\t\t\tappendPQExpBufferChar(&conn->errorMessage, '\\n');\n\t\t\t\t\t}\n\n\t\t\t\t\tgoto error_return;\n\t\t\t\t}\n\n\t\t\t\t/*\n\t\t\t\t * Can't process if message body isn't all here yet.\n\t\t\t\t */\n\t\t\t\tmsgLength -= 4;\n\t\t\t\tavail = conn->inEnd - conn->inCursor;\n\t\t\t\tif (avail < msgLength)\n\t\t\t\t{\n\t\t\t\t\t/*\n\t\t\t\t\t * Before returning, try to enlarge the input buffer if\n\t\t\t\t\t * needed to hold the whole message; see notes in\n\t\t\t\t\t * pqParseInput3.\n\t\t\t\t\t */\n\t\t\t\t\tif (pqCheckInBufferSpace(conn->inCursor + (size_t) msgLength,\n\t\t\t\t\t\t\t\t\t\t\t conn))\n\t\t\t\t\t\tgoto error_return;\n\t\t\t\t\t/* We'll come back when there is more data */\n\t\t\t\t\treturn PGRES_POLLING_READING;\n\t\t\t\t}\n\n\t\t\t\t/* Handle errors. */\n\t\t\t\tif (beresp == 'E')\n\t\t\t\t{\n\t\t\t\t\tif (pqGetErrorNotice3(conn, true))\n\t\t\t\t\t{\n\t\t\t\t\t\t/* We'll come back when there is more data */\n\t\t\t\t\t\treturn PGRES_POLLING_READING;\n\t\t\t\t\t}\n\t\t\t\t\t/* OK, we read the message; mark data consumed */\n\t\t\t\t\tconn->inStart = conn->inCursor;\n\n\t\t\t\t\t/*\n\t\t\t\t\t * If error is \"cannot connect now\", try the next host if\n\t\t\t\t\t * any (but we don't want to consider additional addresses\n\t\t\t\t\t * for this host, nor is there much point in changing SSL\n\t\t\t\t\t * or GSS mode).  This is helpful when dealing with\n\t\t\t\t\t * standby servers that might not be in hot-standby state.\n\t\t\t\t\t */\n\t\t\t\t\tif (strcmp(conn->last_sqlstate,\n\t\t\t\t\t\t\t   ERRCODE_CANNOT_CONNECT_NOW) == 0)\n\t\t\t\t\t{\n\t\t\t\t\t\tconn->try_next_host = true;\n\t\t\t\t\t\tgoto keep_going;\n\t\t\t\t\t}\n\n\t\t\t\t\t/* Check to see if we should mention pgpassfile */\n\t\t\t\t\tpgpassfileWarning(conn);\n\n#ifdef ENABLE_GSS\n\n\t\t\t\t\t/*\n\t\t\t\t\t * If gssencmode is \"prefer\" and we're using GSSAPI, retry\n\t\t\t\t\t * without it.\n\t\t\t\t\t */\n\t\t\t\t\tif (conn->gssenc && conn->gssencmode[0] == 'p')\n\t\t\t\t\t{\n\t\t\t\t\t\t/* only retry once */\n\t\t\t\t\t\tconn->try_gss = false;\n\t\t\t\t\t\tneed_new_connection = true;\n\t\t\t\t\t\tgoto keep_going;\n\t\t\t\t\t}\n#endif\n\n#ifdef USE_SSL\n\n\t\t\t\t\t/*\n\t\t\t\t\t * if sslmode is \"allow\" and we haven't tried an SSL\n\t\t\t\t\t * connection already, then retry with an SSL connection\n\t\t\t\t\t */\n\t\t\t\t\tif (conn->sslmode[0] == 'a' /* \"allow\" */\n\t\t\t\t\t\t&& !conn->ssl_in_use\n\t\t\t\t\t\t&& conn->allow_ssl_try\n\t\t\t\t\t\t&& conn->wait_ssl_try)\n\t\t\t\t\t{\n\t\t\t\t\t\t/* only retry once */\n\t\t\t\t\t\tconn->wait_ssl_try = false;\n\t\t\t\t\t\tneed_new_connection = true;\n\t\t\t\t\t\tgoto keep_going;\n\t\t\t\t\t}\n\n\t\t\t\t\t/*\n\t\t\t\t\t * if sslmode is \"prefer\" and we're in an SSL connection,\n\t\t\t\t\t * then do a non-SSL retry\n\t\t\t\t\t */\n\t\t\t\t\tif (conn->sslmode[0] == 'p' /* \"prefer\" */\n\t\t\t\t\t\t&& conn->ssl_in_use\n\t\t\t\t\t\t&& conn->allow_ssl_try\t/* redundant? */\n\t\t\t\t\t\t&& !conn->wait_ssl_try) /* redundant? */\n\t\t\t\t\t{\n\t\t\t\t\t\t/* only retry once */\n\t\t\t\t\t\tconn->allow_ssl_try = false;\n\t\t\t\t\t\tneed_new_connection = true;\n\t\t\t\t\t\tgoto keep_going;\n\t\t\t\t\t}\n#endif\n\n\t\t\t\t\tgoto error_return;\n\t\t\t\t}\n\n\t\t\t\t/* It is an authentication request. */\n\t\t\t\tconn->auth_req_received = true;\n\n\t\t\t\t/* Get the type of request. */\n\t\t\t\tif (pqGetInt((int *) &areq, 4, conn))\n\t\t\t\t{\n\t\t\t\t\t/* We'll come back when there are more data */\n\t\t\t\t\treturn PGRES_POLLING_READING;\n\t\t\t\t}\n\t\t\t\tmsgLength -= 4;\n\n\t\t\t\t/*\n\t\t\t\t * Process the rest of the authentication request message, and\n\t\t\t\t * respond to it if necessary.\n\t\t\t\t *\n\t\t\t\t * Note that conn->pghost must be non-NULL if we are going to\n\t\t\t\t * avoid the Kerberos code doing a hostname look-up.\n\t\t\t\t */\n\t\t\t\tres = pg_fe_sendauth(areq, msgLength, conn);\n\n\t\t\t\t/* OK, we have processed the message; mark data consumed */\n\t\t\t\tconn->inStart = conn->inCursor;\n\n\t\t\t\tif (res != STATUS_OK)\n\t\t\t\t\tgoto error_return;\n\n\t\t\t\t/*\n\t\t\t\t * Just make sure that any data sent by pg_fe_sendauth is\n\t\t\t\t * flushed out.  Although this theoretically could block, it\n\t\t\t\t * really shouldn't since we don't send large auth responses.\n\t\t\t\t */\n\t\t\t\tif (pqFlush(conn))\n\t\t\t\t\tgoto error_return;\n\n\t\t\t\tif (areq == AUTH_REQ_OK)\n\t\t\t\t{\n\t\t\t\t\t/* We are done with authentication exchange */\n\t\t\t\t\tconn->status = CONNECTION_AUTH_OK;\n\n\t\t\t\t\t/*\n\t\t\t\t\t * Set asyncStatus so that PQgetResult will think that\n\t\t\t\t\t * what comes back next is the result of a query.  See\n\t\t\t\t\t * below.\n\t\t\t\t\t */\n\t\t\t\t\tconn->asyncStatus = PGASYNC_BUSY;\n\t\t\t\t}\n\n\t\t\t\t/* Look to see if we have more data yet. */\n\t\t\t\tgoto keep_going;\n\t\t\t}\n\n\t\tcase CONNECTION_AUTH_OK:\n\t\t\t{\n\t\t\t\t/*\n\t\t\t\t * Now we expect to hear from the backend. A ReadyForQuery\n\t\t\t\t * message indicates that startup is successful, but we might\n\t\t\t\t * also get an Error message indicating failure. (Notice\n\t\t\t\t * messages indicating nonfatal warnings are also allowed by\n\t\t\t\t * the protocol, as are ParameterStatus and BackendKeyData\n\t\t\t\t * messages.) Easiest way to handle this is to let\n\t\t\t\t * PQgetResult() read the messages. We just have to fake it\n\t\t\t\t * out about the state of the connection, by setting\n\t\t\t\t * asyncStatus = PGASYNC_BUSY (done above).\n\t\t\t\t */\n\n\t\t\t\tif (PQisBusy(conn))\n\t\t\t\t\treturn PGRES_POLLING_READING;\n\n\t\t\t\tres = PQgetResult(conn);\n\n\t\t\t\t/*\n\t\t\t\t * NULL return indicating we have gone to IDLE state is\n\t\t\t\t * expected\n\t\t\t\t */\n\t\t\t\tif (res)\n\t\t\t\t{\n\t\t\t\t\tif (res->resultStatus != PGRES_FATAL_ERROR)\n\t\t\t\t\t\tappendPQExpBufferStr(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t\t\t libpq_gettext(\"unexpected message from server during startup\\n\"));\n\t\t\t\t\telse if (conn->send_appname &&\n\t\t\t\t\t\t\t (conn->appname || conn->fbappname))\n\t\t\t\t\t{\n\t\t\t\t\t\t/*\n\t\t\t\t\t\t * If we tried to send application_name, check to see\n\t\t\t\t\t\t * if the error is about that --- pre-9.0 servers will\n\t\t\t\t\t\t * reject it at this stage of the process.  If so,\n\t\t\t\t\t\t * close the connection and retry without sending\n\t\t\t\t\t\t * application_name.  We could possibly get a false\n\t\t\t\t\t\t * SQLSTATE match here and retry uselessly, but there\n\t\t\t\t\t\t * seems no great harm in that; we'll just get the\n\t\t\t\t\t\t * same error again if it's unrelated.\n\t\t\t\t\t\t */\n\t\t\t\t\t\tconst char *sqlstate;\n\n\t\t\t\t\t\tsqlstate = PQresultErrorField(res, PG_DIAG_SQLSTATE);\n\t\t\t\t\t\tif (sqlstate &&\n\t\t\t\t\t\t\tstrcmp(sqlstate, ERRCODE_APPNAME_UNKNOWN) == 0)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tPQclear(res);\n\t\t\t\t\t\t\tconn->send_appname = false;\n\t\t\t\t\t\t\tneed_new_connection = true;\n\t\t\t\t\t\t\tgoto keep_going;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\t/*\n\t\t\t\t\t * if the resultStatus is FATAL, then conn->errorMessage\n\t\t\t\t\t * already has a copy of the error; needn't copy it back.\n\t\t\t\t\t * But add a newline if it's not there already, since\n\t\t\t\t\t * postmaster error messages may not have one.\n\t\t\t\t\t */\n\t\t\t\t\tif (conn->errorMessage.len <= 0 ||\n\t\t\t\t\t\tconn->errorMessage.data[conn->errorMessage.len - 1] != '\\n')\n\t\t\t\t\t\tappendPQExpBufferChar(&conn->errorMessage, '\\n');\n\t\t\t\t\tPQclear(res);\n\t\t\t\t\tgoto error_return;\n\t\t\t\t}\n\n\t\t\t\t/* Almost there now ... */\n\t\t\t\tconn->status = CONNECTION_CHECK_TARGET;\n\t\t\t\tgoto keep_going;\n\t\t\t}\n\n\t\tcase CONNECTION_CHECK_TARGET:\n\t\t\t{\n\t\t\t\t/*\n\t\t\t\t * If a read-write, read-only, primary, or standby connection\n\t\t\t\t * is required, see if we have one.\n\t\t\t\t */\n\t\t\t\tif (conn->target_server_type == SERVER_TYPE_READ_WRITE ||\n\t\t\t\t\tconn->target_server_type == SERVER_TYPE_READ_ONLY)\n\t\t\t\t{\n\t\t\t\t\tbool\t\tread_only_server;\n\n\t\t\t\t\t/*\n\t\t\t\t\t * If the server didn't report\n\t\t\t\t\t * \"default_transaction_read_only\" or \"in_hot_standby\" at\n\t\t\t\t\t * startup, we must determine its state by sending the\n\t\t\t\t\t * query \"SHOW transaction_read_only\".  This GUC exists in\n\t\t\t\t\t * all server versions that support 3.0 protocol.\n\t\t\t\t\t */\n\t\t\t\t\tif (conn->default_transaction_read_only == PG_BOOL_UNKNOWN ||\n\t\t\t\t\t\tconn->in_hot_standby == PG_BOOL_UNKNOWN)\n\t\t\t\t\t{\n\t\t\t\t\t\t/*\n\t\t\t\t\t\t * We use PQsendQueryContinue so that\n\t\t\t\t\t\t * conn->errorMessage does not get cleared.  We need\n\t\t\t\t\t\t * to preserve any error messages related to previous\n\t\t\t\t\t\t * hosts we have tried and failed to connect to.\n\t\t\t\t\t\t */\n\t\t\t\t\t\tconn->status = CONNECTION_OK;\n\t\t\t\t\t\tif (!PQsendQueryContinue(conn,\n\t\t\t\t\t\t\t\t\t\t\t\t \"SHOW transaction_read_only\"))\n\t\t\t\t\t\t\tgoto error_return;\n\t\t\t\t\t\t/* We'll return to this state when we have the answer */\n\t\t\t\t\t\tconn->status = CONNECTION_CHECK_WRITABLE;\n\t\t\t\t\t\treturn PGRES_POLLING_READING;\n\t\t\t\t\t}\n\n\t\t\t\t\t/* OK, we can make the test */\n\t\t\t\t\tread_only_server =\n\t\t\t\t\t\t(conn->default_transaction_read_only == PG_BOOL_YES ||\n\t\t\t\t\t\t conn->in_hot_standby == PG_BOOL_YES);\n\n\t\t\t\t\tif ((conn->target_server_type == SERVER_TYPE_READ_WRITE) ?\n\t\t\t\t\t\tread_only_server : !read_only_server)\n\t\t\t\t\t{\n\t\t\t\t\t\t/* Wrong server state, reject and try the next host */\n\t\t\t\t\t\tif (conn->target_server_type == SERVER_TYPE_READ_WRITE)\n\t\t\t\t\t\t\tappendPQExpBufferStr(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t\t\t\t libpq_gettext(\"session is read-only\\n\"));\n\t\t\t\t\t\telse\n\t\t\t\t\t\t\tappendPQExpBufferStr(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t\t\t\t libpq_gettext(\"session is not read-only\\n\"));\n\n\t\t\t\t\t\t/* Close connection politely. */\n\t\t\t\t\t\tconn->status = CONNECTION_OK;\n\t\t\t\t\t\tsendTerminateConn(conn);\n\n\t\t\t\t\t\t/*\n\t\t\t\t\t\t * Try next host if any, but we don't want to consider\n\t\t\t\t\t\t * additional addresses for this host.\n\t\t\t\t\t\t */\n\t\t\t\t\t\tconn->try_next_host = true;\n\t\t\t\t\t\tgoto keep_going;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telse if (conn->target_server_type == SERVER_TYPE_PRIMARY ||\n\t\t\t\t\t\t conn->target_server_type == SERVER_TYPE_STANDBY ||\n\t\t\t\t\t\t conn->target_server_type == SERVER_TYPE_PREFER_STANDBY)\n\t\t\t\t{\n\t\t\t\t\t/*\n\t\t\t\t\t * If the server didn't report \"in_hot_standby\" at\n\t\t\t\t\t * startup, we must determine its state by sending the\n\t\t\t\t\t * query \"SELECT pg_catalog.pg_is_in_recovery()\".  Servers\n\t\t\t\t\t * before 9.0 don't have that function, but by the same\n\t\t\t\t\t * token they don't have any standby mode, so we may just\n\t\t\t\t\t * assume the result.\n\t\t\t\t\t */\n\t\t\t\t\tif (conn->sversion < 90000)\n\t\t\t\t\t\tconn->in_hot_standby = PG_BOOL_NO;\n\n\t\t\t\t\tif (conn->in_hot_standby == PG_BOOL_UNKNOWN)\n\t\t\t\t\t{\n\t\t\t\t\t\t/*\n\t\t\t\t\t\t * We use PQsendQueryContinue so that\n\t\t\t\t\t\t * conn->errorMessage does not get cleared.  We need\n\t\t\t\t\t\t * to preserve any error messages related to previous\n\t\t\t\t\t\t * hosts we have tried and failed to connect to.\n\t\t\t\t\t\t */\n\t\t\t\t\t\tconn->status = CONNECTION_OK;\n\t\t\t\t\t\tif (!PQsendQueryContinue(conn,\n\t\t\t\t\t\t\t\t\t\t\t\t \"SELECT pg_catalog.pg_is_in_recovery()\"))\n\t\t\t\t\t\t\tgoto error_return;\n\t\t\t\t\t\t/* We'll return to this state when we have the answer */\n\t\t\t\t\t\tconn->status = CONNECTION_CHECK_STANDBY;\n\t\t\t\t\t\treturn PGRES_POLLING_READING;\n\t\t\t\t\t}\n\n\t\t\t\t\t/* OK, we can make the test */\n\t\t\t\t\tif ((conn->target_server_type == SERVER_TYPE_PRIMARY) ?\n\t\t\t\t\t\t(conn->in_hot_standby == PG_BOOL_YES) :\n\t\t\t\t\t\t(conn->in_hot_standby == PG_BOOL_NO))\n\t\t\t\t\t{\n\t\t\t\t\t\t/* Wrong server state, reject and try the next host */\n\t\t\t\t\t\tif (conn->target_server_type == SERVER_TYPE_PRIMARY)\n\t\t\t\t\t\t\tappendPQExpBufferStr(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t\t\t\t libpq_gettext(\"server is in hot standby mode\\n\"));\n\t\t\t\t\t\telse\n\t\t\t\t\t\t\tappendPQExpBufferStr(&conn->errorMessage,\n\t\t\t\t\t\t\t\t\t\t\t\t libpq_gettext(\"server is not in hot standby mode\\n\"));\n\n\t\t\t\t\t\t/* Close connection politely. */\n\t\t\t\t\t\tconn->status = CONNECTION_OK;\n\t\t\t\t\t\tsendTerminateConn(conn);\n\n\t\t\t\t\t\t/*\n\t\t\t\t\t\t * Try next host if any, but we don't want to consider\n\t\t\t\t\t\t * additional addresses for this host.\n\t\t\t\t\t\t */\n\t\t\t\t\t\tconn->try_next_host = true;\n\t\t\t\t\t\tgoto keep_going;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t/* We can release the address list now. */\n\t\t\t\trelease_conn_addrinfo(conn);\n\n\t\t\t\t/*\n\t\t\t\t * Contents of conn->errorMessage are no longer interesting\n\t\t\t\t * (and it seems some clients expect it to be empty after a\n\t\t\t\t * successful connection).\n\t\t\t\t */\n\t\t\t\tresetPQExpBuffer(&conn->errorMessage);\n\n\t\t\t\t/* We are open for business! */\n\t\t\t\tconn->status = CONNECTION_OK;\n\t\t\t\treturn PGRES_POLLING_OK;\n\t\t\t}\n\n\t\tcase CONNECTION_CONSUME:\n\t\t\t{\n\t\t\t\t/*\n\t\t\t\t * This state just makes sure the connection is idle after\n\t\t\t\t * we've obtained the result of a SHOW or SELECT query.  Once\n\t\t\t\t * we're clear, return to CONNECTION_CHECK_TARGET state to\n\t\t\t\t * decide what to do next.  We must transiently set status =\n\t\t\t\t * CONNECTION_OK in order to use the result-consuming\n\t\t\t\t * subroutines.\n\t\t\t\t */\n\t\t\t\tconn->status = CONNECTION_OK;\n\t\t\t\tif (!PQconsumeInput(conn))\n\t\t\t\t\tgoto error_return;\n\n\t\t\t\tif (PQisBusy(conn))\n\t\t\t\t{\n\t\t\t\t\tconn->status = CONNECTION_CONSUME;\n\t\t\t\t\treturn PGRES_POLLING_READING;\n\t\t\t\t}\n\n\t\t\t\t/* Call PQgetResult() again until we get a NULL result */\n\t\t\t\tres = PQgetResult(conn);\n\t\t\t\tif (res != NULL)\n\t\t\t\t{\n\t\t\t\t\tPQclear(res);\n\t\t\t\t\tconn->status = CONNECTION_CONSUME;\n\t\t\t\t\treturn PGRES_POLLING_READING;\n\t\t\t\t}\n\n\t\t\t\tconn->status = CONNECTION_CHECK_TARGET;\n\t\t\t\tgoto keep_going;\n\t\t\t}\n\n\t\tcase CONNECTION_CHECK_WRITABLE:\n\t\t\t{\n\t\t\t\t/*\n\t\t\t\t * Waiting for result of \"SHOW transaction_read_only\".  We\n\t\t\t\t * must transiently set status = CONNECTION_OK in order to use\n\t\t\t\t * the result-consuming subroutines.\n\t\t\t\t */\n\t\t\t\tconn->status = CONNECTION_OK;\n\t\t\t\tif (!PQconsumeInput(conn))\n\t\t\t\t\tgoto error_return;\n\n\t\t\t\tif (PQisBusy(conn))\n\t\t\t\t{\n\t\t\t\t\tconn->status = CONNECTION_CHECK_WRITABLE;\n\t\t\t\t\treturn PGRES_POLLING_READING;\n\t\t\t\t}\n\n\t\t\t\tres = PQgetResult(conn);\n\t\t\t\tif (res && PQresultStatus(res) == PGRES_TUPLES_OK &&\n\t\t\t\t\tPQntuples(res) == 1)\n\t\t\t\t{\n\t\t\t\t\tchar\t   *val = PQgetvalue(res, 0, 0);\n\n\t\t\t\t\t/*\n\t\t\t\t\t * \"transaction_read_only = on\" proves that at least one\n\t\t\t\t\t * of default_transaction_read_only and in_hot_standby is\n\t\t\t\t\t * on, but we don't actually know which.  We don't care\n\t\t\t\t\t * though for the purpose of identifying a read-only\n\t\t\t\t\t * session, so satisfy the CONNECTION_CHECK_TARGET code by\n\t\t\t\t\t * claiming they are both on.  On the other hand, if it's\n\t\t\t\t\t * a read-write session, they are certainly both off.\n\t\t\t\t\t */\n\t\t\t\t\tif (strncmp(val, \"on\", 2) == 0)\n\t\t\t\t\t{\n\t\t\t\t\t\tconn->default_transaction_read_only = PG_BOOL_YES;\n\t\t\t\t\t\tconn->in_hot_standby = PG_BOOL_YES;\n\t\t\t\t\t}\n\t\t\t\t\telse\n\t\t\t\t\t{\n\t\t\t\t\t\tconn->default_transaction_read_only = PG_BOOL_NO;\n\t\t\t\t\t\tconn->in_hot_standby = PG_BOOL_NO;\n\t\t\t\t\t}\n\t\t\t\t\tPQclear(res);\n\n\t\t\t\t\t/* Finish reading messages before continuing */\n\t\t\t\t\tconn->status = CONNECTION_CONSUME;\n\t\t\t\t\tgoto keep_going;\n\t\t\t\t}\n\n\t\t\t\t/* Something went wrong with \"SHOW transaction_read_only\". */\n\t\t\t\tif (res)\n\t\t\t\t\tPQclear(res);\n\n\t\t\t\t/* Append error report to conn->errorMessage. */\n\t\t\t\tappendPQExpBuffer(&conn->errorMessage,\n\t\t\t\t\t\t\t\t  libpq_gettext(\"\\\"%s\\\" failed\\n\"),\n\t\t\t\t\t\t\t\t  \"SHOW transaction_read_only\");\n\n\t\t\t\t/* Close connection politely. */\n\t\t\t\tconn->status = CONNECTION_OK;\n\t\t\t\tsendTerminateConn(conn);\n\n\t\t\t\t/* Try next host. */\n\t\t\t\tconn->try_next_host = true;\n\t\t\t\tgoto keep_going;\n\t\t\t}\n\n\t\tcase CONNECTION_CHECK_STANDBY:\n\t\t\t{\n\t\t\t\t/*\n\t\t\t\t * Waiting for result of \"SELECT pg_is_in_recovery()\".  We\n\t\t\t\t * must transiently set status = CONNECTION_OK in order to use\n\t\t\t\t * the result-consuming subroutines.\n\t\t\t\t */\n\t\t\t\tconn->status = CONNECTION_OK;\n\t\t\t\tif (!PQconsumeInput(conn))\n\t\t\t\t\tgoto error_return;\n\n\t\t\t\tif (PQisBusy(conn))\n\t\t\t\t{\n\t\t\t\t\tconn->status = CONNECTION_CHECK_STANDBY;\n\t\t\t\t\treturn PGRES_POLLING_READING;\n\t\t\t\t}\n\n\t\t\t\tres = PQgetResult(conn);\n\t\t\t\tif (res && PQresultStatus(res) == PGRES_TUPLES_OK &&\n\t\t\t\t\tPQntuples(res) == 1)\n\t\t\t\t{\n\t\t\t\t\tchar\t   *val = PQgetvalue(res, 0, 0);\n\n\t\t\t\t\tif (strncmp(val, \"t\", 1) == 0)\n\t\t\t\t\t\tconn->in_hot_standby = PG_BOOL_YES;\n\t\t\t\t\telse\n\t\t\t\t\t\tconn->in_hot_standby = PG_BOOL_NO;\n\t\t\t\t\tPQclear(res);\n\n\t\t\t\t\t/* Finish reading messages before continuing */\n\t\t\t\t\tconn->status = CONNECTION_CONSUME;\n\t\t\t\t\tgoto keep_going;\n\t\t\t\t}\n\n\t\t\t\t/* Something went wrong with \"SELECT pg_is_in_recovery()\". */\n\t\t\t\tif (res)\n\t\t\t\t\tPQclear(res);\n\n\t\t\t\t/* Append error report to conn->errorMessage. */\n\t\t\t\tappendPQExpBuffer(&conn->errorMessage,\n\t\t\t\t\t\t\t\t  libpq_gettext(\"\\\"%s\\\" failed\\n\"),\n\t\t\t\t\t\t\t\t  \"SELECT pg_is_in_recovery()\");\n\n\t\t\t\t/* Close connection politely. */\n\t\t\t\tconn->status = CONNECTION_OK;\n\t\t\t\tsendTerminateConn(conn);\n\n\t\t\t\t/* Try next host. */\n\t\t\t\tconn->try_next_host = true;\n\t\t\t\tgoto keep_going;\n\t\t\t}\n\n\t\tdefault:\n\t\t\tappendPQExpBuffer(&conn->errorMessage,\n\t\t\t\t\t\t\t  libpq_gettext(\"invalid connection state %d, \"\n\t\t\t\t\t\t\t\t\t\t\t\"probably indicative of memory corruption\\n\"),\n\t\t\t\t\t\t\t  conn->status);\n\t\t\tgoto error_return;\n\t}\n\n\t/* Unreachable */\n\nerror_return:\n\n\t/*\n\t * We used to close the socket at this point, but that makes it awkward\n\t * for those above us if they wish to remove this socket from their own\n\t * records (an fd_set for example).  We'll just have this socket closed\n\t * when PQfinish is called (which is compulsory even after an error, since\n\t * the connection structure must be freed).\n\t */\n\tconn->status = CONNECTION_BAD;\n\treturn PGRES_POLLING_FAILED;\n}",
        "func_hash": 145605680477709719969453491383463044279,
        "file_name": "fe-connect.c",
        "file_hash": 157537093140020562394962573075779914657,
        "cwe": [
            "CWE-522"
        ],
        "cve": "CVE-2021-23222",
        "cve_desc": "A man-in-the-middle attacker can inject false responses to the client's first few queries, despite the use of SSL certificate verification and encryption.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-23222",
        "func_name": "PQconnectPoll",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195389,
        "project": "tensorflow",
        "commit_id": "c2b31ff2d3151acb230edc3f5b1832d2c713a9e0",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/c2b31ff2d3151acb230edc3f5b1832d2c713a9e0",
        "commit_message": "Remove a `DCHECK`-fail, log an error instead.\n\n`DCHECK` in debug mode results in crashes. TensorFlow has had multiple vulnerabilities due to this.\n\nOutside of debug mode, `DCHECK` is a no-op.\n\nA better alternative is to report an error to the log buffer and continue. This should happen both in debug mode and in prod mode.\n\nPiperOrigin-RevId: 408375925\nChange-Id: Id5b3e19c73f3fbe0cc4bba26ca44ff9607bb6356",
        "target": 1,
        "irrelevant": 0,
        "func_before": "bool RepeatedAttrDefEqual(\n    const protobuf::RepeatedPtrField<OpDef::AttrDef>& a1,\n    const protobuf::RepeatedPtrField<OpDef::AttrDef>& a2) {\n  std::unordered_map<string, const OpDef::AttrDef*> a1_set;\n  for (const OpDef::AttrDef& def : a1) {\n    DCHECK(a1_set.find(def.name()) == a1_set.end())\n        << \"AttrDef names must be unique, but '\" << def.name()\n        << \"' appears more than once\";\n    a1_set[def.name()] = &def;\n  }\n  for (const OpDef::AttrDef& def : a2) {\n    auto iter = a1_set.find(def.name());\n    if (iter == a1_set.end()) return false;\n    if (!AttrDefEqual(*iter->second, def)) return false;\n    a1_set.erase(iter);\n  }\n  if (!a1_set.empty()) return false;\n  return true;\n}",
        "func_hash": 228350956694349821922378909162368693155,
        "file_name": "op_def_util.cc",
        "file_hash": 43202597261631718571985626227626810269,
        "cwe": [
            "CWE-617"
        ],
        "cve": "CVE-2022-23565",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. An attacker can trigger denial of service via assertion failure by altering a `SavedModel` on disk such that `AttrDef`s of some operation are duplicated. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23565",
        "func_name": "RepeatedAttrDefEqual",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195391,
        "project": "tensorflow",
        "commit_id": "f68fdab93fb7f4ddb4eb438c8fe052753c9413e8",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/f68fdab93fb7f4ddb4eb438c8fe052753c9413e8",
        "commit_message": "Add a check for pad width to be a positive value.\n\nPiperOrigin-RevId: 413275853\nChange-Id: I261a8db9dabf5ce48a806a9e58129080c9fac619",
        "target": 1,
        "irrelevant": 1,
        "func_before": "  void Compute(tensorflow::OpKernelContext* context) override {\n    for (int ngram_width : ngram_widths_) {\n      OP_REQUIRES(\n          context, ngram_width > 0,\n          errors::InvalidArgument(\"ngram_widths must contain positive values\"));\n    }\n\n    const tensorflow::Tensor* data;\n    OP_REQUIRES_OK(context, context->input(\"data\", &data));\n    const auto& input_data = data->flat<tstring>().data();\n\n    const tensorflow::Tensor* splits;\n    OP_REQUIRES_OK(context, context->input(\"data_splits\", &splits));\n    const auto& splits_vec = splits->flat<SPLITS_TYPE>();\n\n    // Validate that the splits are valid indices into data, only if there are\n    // splits specified.\n    const int input_data_size = data->flat<tstring>().size();\n    const int splits_vec_size = splits_vec.size();\n    if (splits_vec_size > 0) {\n      int prev_split = splits_vec(0);\n      OP_REQUIRES(context, prev_split == 0,\n                  errors::InvalidArgument(\"First split value must be 0, got \",\n                                          prev_split));\n      for (int i = 1; i < splits_vec_size; ++i) {\n        bool valid_splits = splits_vec(i) >= prev_split;\n        valid_splits = valid_splits && (splits_vec(i) <= input_data_size);\n        OP_REQUIRES(context, valid_splits,\n                    errors::InvalidArgument(\n                        \"Invalid split value \", splits_vec(i), \", must be in [\",\n                        prev_split, \", \", input_data_size, \"]\"));\n        prev_split = splits_vec(i);\n      }\n      OP_REQUIRES(context, prev_split == input_data_size,\n                  errors::InvalidArgument(\n                      \"Last split value must be data size. Expected \",\n                      input_data_size, \", got \", prev_split));\n    }\n\n    int num_batch_items = splits_vec.size() - 1;\n    tensorflow::Tensor* ngrams_splits;\n    OP_REQUIRES_OK(\n        context, context->allocate_output(1, splits->shape(), &ngrams_splits));\n    auto ngrams_splits_data = ngrams_splits->flat<SPLITS_TYPE>().data();\n\n    // If there is no data or size, return an empty RT.\n    if (data->flat<tstring>().size() == 0 || splits_vec.size() == 0) {\n      tensorflow::Tensor* empty;\n      OP_REQUIRES_OK(context,\n                     context->allocate_output(0, data->shape(), &empty));\n      for (int i = 0; i <= num_batch_items; ++i) {\n        ngrams_splits_data[i] = 0;\n      }\n      return;\n    }\n\n    ngrams_splits_data[0] = 0;\n    for (int i = 1; i <= num_batch_items; ++i) {\n      int length = splits_vec(i) - splits_vec(i - 1);\n      int num_ngrams = 0;\n      for (int ngram_width : ngram_widths_)\n        num_ngrams += get_num_ngrams(length, ngram_width);\n      if (preserve_short_ && length > 0 && num_ngrams == 0) {\n        num_ngrams = 1;\n      }\n      ngrams_splits_data[i] = ngrams_splits_data[i - 1] + num_ngrams;\n    }\n\n    tensorflow::Tensor* ngrams;\n    OP_REQUIRES_OK(\n        context,\n        context->allocate_output(\n            0, TensorShape({ngrams_splits_data[num_batch_items]}), &ngrams));\n    auto ngrams_data = ngrams->flat<tstring>().data();\n\n    for (int i = 0; i < num_batch_items; ++i) {\n      auto data_start = &input_data[splits_vec(i)];\n      int output_start_idx = ngrams_splits_data[i];\n      for (int ngram_width : ngram_widths_) {\n        auto output_start = &ngrams_data[output_start_idx];\n        int length = splits_vec(i + 1) - splits_vec(i);\n        int num_ngrams = get_num_ngrams(length, ngram_width);\n        CreateNgrams(data_start, output_start, num_ngrams, ngram_width);\n        output_start_idx += num_ngrams;\n      }\n      // If we're preserving short sequences, check to see if no sequence was\n      // generated by comparing the current output start idx to the original\n      // one (ngram_splits_data). If no ngrams were generated, then they will\n      // be equal (since we increment output_start_idx by num_ngrams every\n      // time we create a set of ngrams.)\n      if (preserve_short_ && output_start_idx == ngrams_splits_data[i]) {\n        int data_length = splits_vec(i + 1) - splits_vec(i);\n        // One legitimate reason to not have any ngrams when preserve_short_\n        // is true is if the sequence itself is empty. In that case, move on.\n        if (data_length == 0) {\n          continue;\n        }\n        // We don't have to worry about dynamic padding sizes here: if padding\n        // was dynamic, every sequence would have had sufficient padding to\n        // generate at least one ngram.\n        int ngram_width = data_length + 2 * pad_width_;\n        auto output_start = &ngrams_data[output_start_idx];\n        int num_ngrams = 1;\n        CreateNgrams(data_start, output_start, num_ngrams, ngram_width);\n      }\n    }\n  }",
        "func_hash": 93012019628610956612764593105283326156,
        "file_name": "string_ngrams_op.cc",
        "file_hash": 245905885483763938680185872776744444218,
        "cwe": [
            "CWE-190"
        ],
        "cve": "CVE-2022-21733",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The implementation of `StringNGrams` can be used to trigger a denial of service attack by causing an out of memory condition after an integer overflow. We are missing a validation on `pad_witdh` and that result in computing a negative value for `ngram_width` which is later used to allocate parts of the output. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-21733",
        "func_name": "Compute",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195398,
        "project": "v4l2loopback",
        "commit_id": "e4cd225557486c420f6a34411f98c575effd43dd",
        "project_url": "https://github.com/umlaeute/v4l2loopback",
        "commit_url": "https://github.com/umlaeute/v4l2loopback/commit/e4cd225557486c420f6a34411f98c575effd43dd",
        "commit_message": "add explicit format specifier to printf() invocations\n\nCWE-134",
        "target": 1,
        "irrelevant": 1,
        "func_before": "static int vidioc_querycap(struct file *file, void *priv,\n\t\t\t   struct v4l2_capability *cap)\n{\n\tstruct v4l2_loopback_device *dev = v4l2loopback_getdevice(file);\n\tint labellen = (sizeof(cap->card) < sizeof(dev->card_label)) ?\n\t\t\t       sizeof(cap->card) :\n\t\t\t\t     sizeof(dev->card_label);\n\tint device_nr =\n\t\t((struct v4l2loopback_private *)video_get_drvdata(dev->vdev))\n\t\t\t->device_nr;\n\t__u32 capabilities = V4L2_CAP_STREAMING | V4L2_CAP_READWRITE;\n\n\tstrlcpy(cap->driver, \"v4l2 loopback\", sizeof(cap->driver));\n\tsnprintf(cap->card, labellen, dev->card_label);\n\tsnprintf(cap->bus_info, sizeof(cap->bus_info),\n\t\t \"platform:v4l2loopback-%03d\", device_nr);\n\n#if LINUX_VERSION_CODE < KERNEL_VERSION(3, 1, 0)\n\t/* since 3.1.0, the v4l2-core system is supposed to set the version */\n\tcap->version = V4L2LOOPBACK_VERSION_CODE;\n#endif\n\n#ifdef V4L2_CAP_VIDEO_M2M\n\tcapabilities |= V4L2_CAP_VIDEO_M2M;\n#endif /* V4L2_CAP_VIDEO_M2M */\n\n\tif (dev->announce_all_caps) {\n\t\tcapabilities |= V4L2_CAP_VIDEO_CAPTURE | V4L2_CAP_VIDEO_OUTPUT;\n\t} else {\n\t\tif (dev->ready_for_capture) {\n\t\t\tcapabilities |= V4L2_CAP_VIDEO_CAPTURE;\n\t\t}\n\t\tif (dev->ready_for_output) {\n\t\t\tcapabilities |= V4L2_CAP_VIDEO_OUTPUT;\n\t\t}\n\t}\n\n#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 7, 0)\n\tdev->vdev->device_caps =\n#endif /* >=linux-4.7.0 */\n\t\tcap->device_caps = cap->capabilities = capabilities;\n\n#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 3, 0)\n\tcap->capabilities |= V4L2_CAP_DEVICE_CAPS;\n#endif\n\n\tmemset(cap->reserved, 0, sizeof(cap->reserved));\n\treturn 0;\n}",
        "func_hash": 275249025528691740507199336736969659771,
        "file_name": "v4l2loopback.c",
        "file_hash": 113113223463037707180278012059265756483,
        "cwe": [
            "CWE-134"
        ],
        "cve": "CVE-2022-2652",
        "cve_desc": "Depending on the way the format strings in the card label are crafted it's possible to leak kernel stack memory. There is also the possibility for DoS due to the v4l2loopback kernel module crashing when providing the card label on request (reproduce e.g. with many %s modifiers in a row).",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-2652",
        "func_name": "vidioc_querycap",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195399,
        "project": "tensorflow",
        "commit_id": "045deec1cbdebb27d817008ad5df94d96a08b1bf",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/045deec1cbdebb27d817008ad5df94d96a08b1bf",
        "commit_message": "Prevent null pointer dereference in `mutable_graph_view`\n\nPiperOrigin-RevId: 409684472\nChange-Id: I577eb9d9ac470fcec0501423171e739a4ec0cb5c",
        "target": 1,
        "irrelevant": 1,
        "func_before": "bool IsIdentityConsumingSwitch(const MutableGraphView& graph,\n                               const NodeDef& node) {\n  if ((IsIdentity(node) || IsIdentityNSingleInput(node)) &&\n      node.input_size() > 0) {\n    TensorId tensor_id = ParseTensorName(node.input(0));\n    if (IsTensorIdControlling(tensor_id)) {\n      return false;\n    }\n\n    NodeDef* input_node = graph.GetNode(tensor_id.node());\n    return IsSwitch(*input_node);\n  }\n  return false;\n}",
        "func_hash": 313619660222966312087557415210995637728,
        "file_name": "mutable_graph_view.cc",
        "file_hash": 11824580899895481141820753687530297202,
        "cwe": [
            "CWE-476"
        ],
        "cve": "CVE-2022-23589",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. Under certain scenarios, Grappler component of TensorFlow can trigger a null pointer dereference. There are 2 places where this can occur, for the same malicious alteration of a `SavedModel` file (fixing the first one would trigger the same dereference in the second place). First, during constant folding, the `GraphDef` might not have the required nodes for the binary operation. If a node is missing, the correposning `mul_*child` would be null, and the dereference in the subsequent line would be incorrect. We have a similar issue during `IsIdentityConsumingSwitch`. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23589",
        "func_name": "IsIdentityConsumingSwitch",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195402,
        "project": "tensorflow",
        "commit_id": "a1e1511dde36b3f8aa27a6ec630838e7ea40e091",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/a1e1511dde36b3f8aa27a6ec630838e7ea40e091",
        "commit_message": "[lite] Update TfLiteIntArrayCreate to return size_t\n\nPiperOrigin-RevId: 416439896\nChange-Id: I847f69b68d1ddaff4b1e925a09b8b69c1756653b",
        "target": 1,
        "irrelevant": 0,
        "func_before": "int TfLiteIntArrayGetSizeInBytes(int size) {\n  static TfLiteIntArray dummy;\n\n  int computed_size = sizeof(dummy) + sizeof(dummy.data[0]) * size;\n#if defined(_MSC_VER)\n  // Context for why this is needed is in http://b/189926408#comment21\n  computed_size -= sizeof(dummy.data[0]);\n#endif\n  return computed_size;\n}",
        "func_hash": 331591508579524081379498872268044006906,
        "file_name": "common.c",
        "file_hash": 227108095659128555473924245568634074234,
        "cwe": [
            "CWE-190"
        ],
        "cve": "CVE-2022-23558",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. An attacker can craft a TFLite model that would cause an integer overflow in `TfLiteIntArrayCreate`. The `TfLiteIntArrayGetSizeInBytes` returns an `int` instead of a `size_t. An attacker can control model inputs such that `computed_size` overflows the size of `int` datatype. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23558",
        "func_name": "TfLiteIntArrayGetSizeInBytes",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195403,
        "project": "tensorflow",
        "commit_id": "a1e1511dde36b3f8aa27a6ec630838e7ea40e091",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/a1e1511dde36b3f8aa27a6ec630838e7ea40e091",
        "commit_message": "[lite] Update TfLiteIntArrayCreate to return size_t\n\nPiperOrigin-RevId: 416439896\nChange-Id: I847f69b68d1ddaff4b1e925a09b8b69c1756653b",
        "target": 1,
        "irrelevant": 0,
        "func_before": "TfLiteIntArray* TfLiteIntArrayCreate(int size) {\n  int alloc_size = TfLiteIntArrayGetSizeInBytes(size);\n  if (alloc_size <= 0) return NULL;\n  TfLiteIntArray* ret = (TfLiteIntArray*)malloc(alloc_size);\n  if (!ret) return ret;\n  ret->size = size;\n  return ret;\n}",
        "func_hash": 64742066879088615123277599572040485093,
        "file_name": "common.c",
        "file_hash": 227108095659128555473924245568634074234,
        "cwe": [
            "CWE-190"
        ],
        "cve": "CVE-2022-23558",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. An attacker can craft a TFLite model that would cause an integer overflow in `TfLiteIntArrayCreate`. The `TfLiteIntArrayGetSizeInBytes` returns an `int` instead of a `size_t. An attacker can control model inputs such that `computed_size` overflows the size of `int` datatype. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23558",
        "func_name": "TfLiteIntArrayCreate",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195404,
        "project": "tensorflow",
        "commit_id": "ba4e8ac4dc2991e350d5cc407f8598c8d4ee70fb",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/ba4e8ac4dc2991e350d5cc407f8598c8d4ee70fb",
        "commit_message": "Fix potential divide by zero error when executing FractionalMaxPool, when pooling ratio is higher than input size for a particular dimension.\n\nPiperOrigin-RevId: 412151722\nChange-Id: I06e57cbb8eca43816eff79eac264fa7aae8f7163",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext* context) override {\n    typedef Eigen::Map<const Eigen::Matrix<T, Eigen::Dynamic, Eigen::Dynamic>>\n        ConstEigenMatrixMap;\n    typedef Eigen::Map<Eigen::Matrix<T, Eigen::Dynamic, Eigen::Dynamic>>\n        EigenMatrixMap;\n\n    constexpr int tensor_in_and_out_dims = 4;\n\n    const Tensor& tensor_in = context->input(0);\n    OP_REQUIRES(context, tensor_in.dims() == tensor_in_and_out_dims,\n                errors::InvalidArgument(\"tensor_in must be 4-dimensional\"));\n\n    std::vector<int> input_size(tensor_in_and_out_dims);\n    std::vector<int> output_size(tensor_in_and_out_dims);\n    for (int i = 0; i < tensor_in_and_out_dims; ++i) {\n      input_size[i] = tensor_in.dim_size(i);\n    }\n    // Output size.\n    for (int i = 0; i < tensor_in_and_out_dims; ++i) {\n      // This must match the same logic in the shape function in\n      // core/ops/nn_ops.cc.\n      output_size[i] =\n          static_cast<int>(std::floor(input_size[i] / pooling_ratio_[i]));\n      DCHECK_GT(output_size[i], 0);\n    }\n\n    // Generate pooling sequence.\n    std::vector<int64_t> height_cum_seq;\n    std::vector<int64_t> width_cum_seq;\n    GuardedPhiloxRandom generator;\n    generator.Init(seed_, seed2_);\n    height_cum_seq = GeneratePoolingSequence(input_size[1], output_size[1],\n                                             &generator, pseudo_random_);\n    width_cum_seq = GeneratePoolingSequence(input_size[2], output_size[2],\n                                            &generator, pseudo_random_);\n\n    // Prepare output.\n    Tensor* output_tensor = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(\n                                0,\n                                TensorShape({output_size[0], output_size[1],\n                                             output_size[2], output_size[3]}),\n                                &output_tensor));\n    Tensor* output_height_seq_tensor = nullptr;\n    OP_REQUIRES_OK(\n        context,\n        context->allocate_output(\n            1, TensorShape({static_cast<int64_t>(height_cum_seq.size())}),\n            &output_height_seq_tensor));\n    Tensor* output_width_seq_tensor = nullptr;\n    OP_REQUIRES_OK(\n        context,\n        context->allocate_output(\n            2, TensorShape({static_cast<int64_t>(width_cum_seq.size())}),\n            &output_width_seq_tensor));\n\n    ConstEigenMatrixMap in_mat(tensor_in.flat<T>().data(), input_size[3],\n                               input_size[2] * input_size[1] * input_size[0]);\n\n    EigenMatrixMap out_mat(output_tensor->flat<T>().data(), output_size[3],\n                           output_size[2] * output_size[1] * output_size[0]);\n\n    // Initializes the output tensor with MIN<T>.\n    output_tensor->flat<T>().setConstant(Eigen::NumTraits<T>::lowest());\n\n    auto output_height_seq_flat = output_height_seq_tensor->flat<int64_t>();\n    auto output_width_seq_flat = output_width_seq_tensor->flat<int64_t>();\n\n    // Set output tensors.\n    for (int i = 0; i < height_cum_seq.size(); ++i) {\n      output_height_seq_flat(i) = height_cum_seq[i];\n    }\n\n    for (int i = 0; i < width_cum_seq.size(); ++i) {\n      output_width_seq_flat(i) = width_cum_seq[i];\n    }\n\n    // For both input and output,\n    // 0: batch\n    // 1: height / row\n    // 2: width / col\n    // 3: depth / channel\n    const int64_t height_max = input_size[1] - 1;\n    const int64_t width_max = input_size[2] - 1;\n    for (int64_t b = 0; b < input_size[0]; ++b) {\n      // height sequence.\n      for (int64_t hs = 0; hs < height_cum_seq.size() - 1; ++hs) {\n        // height start and end.\n        const int64_t height_start = height_cum_seq[hs];\n        int64_t height_end =\n            overlapping_ ? height_cum_seq[hs + 1] : height_cum_seq[hs + 1] - 1;\n        height_end = std::min(height_end, height_max);\n\n        // width sequence.\n        for (int64_t ws = 0; ws < width_cum_seq.size() - 1; ++ws) {\n          const int64_t out_offset =\n              (b * output_size[1] + hs) * output_size[2] + ws;\n          // width start and end.\n          const int64_t width_start = width_cum_seq[ws];\n          int64_t width_end =\n              overlapping_ ? width_cum_seq[ws + 1] : width_cum_seq[ws + 1] - 1;\n          width_end = std::min(width_end, width_max);\n          for (int64_t h = height_start; h <= height_end; ++h) {\n            for (int64_t w = width_start; w <= width_end; ++w) {\n              const int64_t in_offset =\n                  (b * input_size[1] + h) * input_size[2] + w;\n              out_mat.col(out_offset) =\n                  out_mat.col(out_offset).cwiseMax(in_mat.col(in_offset));\n            }\n          }\n        }\n      }\n    }\n  }",
        "func_hash": 329653208386215793548956261636203970964,
        "file_name": "fractional_max_pool_op.cc",
        "file_hash": 38088244475067119710916669469162645605,
        "cwe": [
            "CWE-369"
        ],
        "cve": "CVE-2022-21735",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The implementation of `FractionalMaxPool` can be made to crash a TensorFlow process via a division by 0. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-21735",
        "func_name": "Compute",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195405,
        "project": "ImageMagick6",
        "commit_id": "29c8abce0da56b536542f76a9ddfebdaab5b2943",
        "project_url": "https://github.com/ImageMagick/ImageMagick6",
        "commit_url": "https://github.com/ImageMagick/ImageMagick6/commit/29c8abce0da56b536542f76a9ddfebdaab5b2943",
        "commit_message": "https://github.com/ImageMagick/ImageMagick/pull/4986",
        "target": 1,
        "irrelevant": 1,
        "func_before": "static Image *ReadPCLImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n#define CropBox  \"CropBox\"\n#define DeviceCMYK  \"DeviceCMYK\"\n#define MediaBox  \"MediaBox\"\n#define RenderPCLText  \"  Rendering PCL...  \"\n\n  char\n    command[MaxTextExtent],\n    *density,\n    filename[MaxTextExtent],\n    geometry[MaxTextExtent],\n    *options,\n    input_filename[MaxTextExtent];\n\n  const DelegateInfo\n    *delegate_info;\n\n  Image\n    *image,\n    *next_image;\n\n  ImageInfo\n    *read_info;\n\n  int\n    c;\n\n  MagickBooleanType\n    cmyk,\n    status;\n\n  PointInfo\n    delta;\n\n  RectangleInfo\n    bounding_box,\n    page;\n\n  char\n    *p;\n\n  SegmentInfo\n    bounds;\n\n  size_t\n    height,\n    width;\n\n  ssize_t\n    count;\n\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  /*\n    Open image file.\n  */\n  image=AcquireImage(image_info);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  status=AcquireUniqueSymbolicLink(image_info->filename,input_filename);\n  if (status == MagickFalse)\n    {\n      ThrowFileException(exception,FileOpenError,\"UnableToCreateTemporaryFile\",\n        image_info->filename);\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    Set the page density.\n  */\n  delta.x=DefaultResolution;\n  delta.y=DefaultResolution;\n  if ((image->x_resolution == 0.0) || (image->y_resolution == 0.0))\n    {\n      GeometryInfo\n        geometry_info;\n\n      MagickStatusType\n        flags;\n\n      flags=ParseGeometry(PSDensityGeometry,&geometry_info);\n      if ((flags & RhoValue) != 0)\n        image->x_resolution=geometry_info.rho;\n      image->y_resolution=image->x_resolution;\n      if ((flags & SigmaValue) != 0)\n        image->y_resolution=geometry_info.sigma;\n    }\n  /*\n    Determine page geometry from the PCL media box.\n  */\n  cmyk=image->colorspace == CMYKColorspace ? MagickTrue : MagickFalse;\n  count=0;\n  (void) memset(&bounding_box,0,sizeof(bounding_box));\n  (void) memset(&bounds,0,sizeof(bounds));\n  (void) memset(&page,0,sizeof(page));\n  (void) memset(command,0,sizeof(command));\n  p=command;\n  for (c=ReadBlobByte(image); c != EOF; c=ReadBlobByte(image))\n  {\n    if (image_info->page != (char *) NULL)\n      continue;\n    /*\n      Note PCL elements.\n    */\n    *p++=(char) c;\n    if ((c != (int) '/') && (c != '\\n') &&\n        ((size_t) (p-command) < (MaxTextExtent-1)))\n      continue;\n    *p='\\0';\n    p=command;\n    /*\n      Is this a CMYK document?\n    */\n    if (LocaleNCompare(DeviceCMYK,command,strlen(DeviceCMYK)) == 0)\n      cmyk=MagickTrue;\n    if (LocaleNCompare(CropBox,command,strlen(CropBox)) == 0)\n      {\n        /*\n          Note region defined by crop box.\n        */\n        count=(ssize_t) sscanf(command,\"CropBox [%lf %lf %lf %lf\",\n          &bounds.x1,&bounds.y1,&bounds.x2,&bounds.y2);\n        if (count != 4)\n          count=(ssize_t) sscanf(command,\"CropBox[%lf %lf %lf %lf\",\n            &bounds.x1,&bounds.y1,&bounds.x2,&bounds.y2);\n      }\n    if (LocaleNCompare(MediaBox,command,strlen(MediaBox)) == 0)\n      {\n        /*\n          Note region defined by media box.\n        */\n        count=(ssize_t) sscanf(command,\"MediaBox [%lf %lf %lf %lf\",\n          &bounds.x1,&bounds.y1,&bounds.x2,&bounds.y2);\n        if (count != 4)\n          count=(ssize_t) sscanf(command,\"MediaBox[%lf %lf %lf %lf\",\n            &bounds.x1,&bounds.y1,&bounds.x2,&bounds.y2);\n      }\n    if (count != 4)\n      continue;\n    /*\n      Set PCL render geometry.\n    */\n    width=(size_t) floor(bounds.x2-bounds.x1+0.5);\n    height=(size_t) floor(bounds.y2-bounds.y1+0.5);\n    if (width > page.width)\n      page.width=width;\n    if (height > page.height)\n      page.height=height;\n  }\n  (void) CloseBlob(image);\n  /*\n    Render PCL with the GhostPCL delegate.\n  */\n  if ((page.width == 0) || (page.height == 0))\n    (void) ParseAbsoluteGeometry(PSPageGeometry,&page);\n  if (image_info->page != (char *) NULL)\n    (void) ParseAbsoluteGeometry(image_info->page,&page);\n  (void) FormatLocaleString(geometry,MaxTextExtent,\"%.20gx%.20g\",(double)\n    page.width,(double) page.height);\n  if (image_info->monochrome != MagickFalse)\n    delegate_info=GetDelegateInfo(\"pcl:mono\",(char *) NULL,exception);\n  else\n     if (cmyk != MagickFalse)\n       delegate_info=GetDelegateInfo(\"pcl:cmyk\",(char *) NULL,exception);\n     else\n       delegate_info=GetDelegateInfo(\"pcl:color\",(char *) NULL,exception);\n  if (delegate_info == (const DelegateInfo *) NULL)\n    {\n      image=DestroyImage(image);\n      return((Image *) NULL);\n    }\n  if ((page.width == 0) || (page.height == 0))\n    (void) ParseAbsoluteGeometry(PSPageGeometry,&page);\n  if (image_info->page != (char *) NULL)\n    (void) ParseAbsoluteGeometry(image_info->page,&page);\n  density=AcquireString(\"\");\n  options=AcquireString(\"\");\n  (void) FormatLocaleString(density,MaxTextExtent,\"%gx%g\",\n    image->x_resolution,image->y_resolution);\n  if (image_info->ping != MagickFalse)\n    (void) FormatLocaleString(density,MagickPathExtent,\"2.0x2.0\");\n  page.width=(size_t) floor((double) page.width*image->x_resolution/delta.x+\n    0.5);\n  page.height=(size_t) floor((double) page.height*image->y_resolution/delta.y+\n    0.5);\n  (void) FormatLocaleString(options,MaxTextExtent,\"-g%.20gx%.20g \",(double)\n     page.width,(double) page.height);\n  image=DestroyImage(image);\n  read_info=CloneImageInfo(image_info);\n  *read_info->magick='\\0';\n  if (read_info->number_scenes != 0)\n    {\n      if (read_info->number_scenes != 1)\n        (void) FormatLocaleString(options,MaxTextExtent,\"-dLastPage=%.20g\",\n          (double) (read_info->scene+read_info->number_scenes));\n      else\n        (void) FormatLocaleString(options,MaxTextExtent,\n          \"-dFirstPage=%.20g -dLastPage=%.20g\",(double) read_info->scene+1,\n          (double) (read_info->scene+read_info->number_scenes));\n      read_info->number_scenes=0;\n      if (read_info->scenes != (char *) NULL)\n        *read_info->scenes='\\0';\n    }\n  (void) CopyMagickString(filename,read_info->filename,MaxTextExtent);\n  (void) AcquireUniqueFilename(read_info->filename);\n  (void) FormatLocaleString(command,MaxTextExtent,\n    GetDelegateCommands(delegate_info),\n    read_info->antialias != MagickFalse ? 4 : 1,\n    read_info->antialias != MagickFalse ? 4 : 1,density,options,\n    read_info->filename,input_filename);\n  options=DestroyString(options);\n  density=DestroyString(density);\n  status=ExternalDelegateCommand(MagickFalse,read_info->verbose,command,\n    (char *) NULL,exception) != 0 ? MagickTrue : MagickFalse;\n  image=ReadImage(read_info,exception);\n  (void) RelinquishUniqueFileResource(read_info->filename);\n  (void) RelinquishUniqueFileResource(input_filename);\n  read_info=DestroyImageInfo(read_info);\n  if (image == (Image *) NULL)\n    ThrowReaderException(DelegateError,\"PCLDelegateFailed\");\n  if (LocaleCompare(image->magick,\"BMP\") == 0)\n    {\n      Image\n        *cmyk_image;\n\n      cmyk_image=ConsolidateCMYKImages(image,&image->exception);\n      if (cmyk_image != (Image *) NULL)\n        {\n          image=DestroyImageList(image);\n          image=cmyk_image;\n        }\n    }\n  do\n  {\n    (void) CopyMagickString(image->filename,filename,MaxTextExtent);\n    image->page=page;\n    if (image_info->ping != MagickFalse)\n      {\n        image->magick_columns*=image->x_resolution/2.0;\n        image->magick_rows*=image->y_resolution/2.0;\n        image->columns*=image->x_resolution/2.0;\n        image->rows*=image->y_resolution/2.0;\n      }\n    next_image=SyncNextImageInList(image);\n    if (next_image != (Image *) NULL)\n      image=next_image;\n  } while (next_image != (Image *) NULL);\n  return(GetFirstImageInList(image));\n}",
        "func_hash": 285956846610376765198872183403915882061,
        "file_name": "pcl.c",
        "file_hash": 338547174937023730341471137685130471169,
        "cwe": [
            "CWE-190"
        ],
        "cve": "CVE-2022-32546",
        "cve_desc": "A vulnerability was found in ImageMagick, causing an outside the range of representable values of type 'unsigned long' at coders/pcl.c, when crafted or untrusted input is processed. This leads to a negative impact to application availability or other problems related to undefined behavior.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-32546",
        "func_name": "ReadPCLImage",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195409,
        "project": "gpac",
        "commit_id": "64a2e1b799352ac7d7aad1989bc06e7b0f2b01db",
        "project_url": "https://github.com/gpac/gpac",
        "commit_url": "https://github.com/gpac/gpac/commit/64a2e1b799352ac7d7aad1989bc06e7b0f2b01db",
        "commit_message": "fixed #2092",
        "target": 1,
        "irrelevant": 1,
        "func_before": "\nvoid gitn_box_del(GF_Box *s)\n{\n\tu32 i;\n\tGroupIdToNameBox *ptr = (GroupIdToNameBox *)s;\n\tif (ptr == NULL) return;\n\tfor (i=0; i<ptr->nb_entries; i++) {\n\t\tif (ptr->entries[i].name) gf_free(ptr->entries[i].name);\n\t}\n\tif (ptr->entries) gf_free(ptr->entries);\n\tgf_free(ptr);",
        "func_hash": 37642310110270321687625000100653046485,
        "file_name": "box_code_base.c",
        "file_hash": 212802147696207025803784466432150384318,
        "cwe": [
            "CWE-476"
        ],
        "cve": "CVE-2021-4043",
        "cve_desc": "NULL Pointer Dereference in GitHub repository gpac/gpac prior to 1.1.0.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-4043",
        "func_name": "gitn_box_del",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195410,
        "project": "tensorflow",
        "commit_id": "965b97e4a9650495cda5a8c210ef6684b4b9eceb",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/965b97e4a9650495cda5a8c210ef6684b4b9eceb",
        "commit_message": "Properly validate sparse tensor in `SparseTensorSliceDataset`\n\nExisting validation was incomplete.\n\nPiperOrigin-RevId: 415375048\nChange-Id: I14cd18f29ede73286f3ffac35171bd15828997e9",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void MakeDataset(OpKernelContext* ctx, DatasetBase** output) override {\n    // Create a new SparseTensorSliceDatasetOp::Dataset, insert it in\n    // the step container, and return it as the output.\n    const Tensor* indices;\n    OP_REQUIRES_OK(ctx, ctx->input(\"indices\", &indices));\n    const Tensor* values;\n    OP_REQUIRES_OK(ctx, ctx->input(\"values\", &values));\n    const Tensor* dense_shape;\n    OP_REQUIRES_OK(ctx, ctx->input(\"dense_shape\", &dense_shape));\n\n    OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(indices->shape()),\n                errors::InvalidArgument(\n                    \"Input indices should be a matrix but received shape \",\n                    indices->shape().DebugString()));\n\n    const auto num_indices = indices->NumElements();\n    const auto num_values = values->NumElements();\n    if (num_indices == 0 || num_values == 0) {\n      OP_REQUIRES(ctx, num_indices == num_values,\n                  errors::InvalidArgument(\n                      \"If indices or values are empty, the other one must also \"\n                      \"be. Got indices of shape \",\n                      indices->shape().DebugString(), \" and values of shape \",\n                      values->shape().DebugString()));\n    }\n    OP_REQUIRES(ctx, TensorShapeUtils::IsVector(values->shape()),\n                errors::InvalidArgument(\n                    \"Input values should be a vector but received shape \",\n                    indices->shape().DebugString()));\n    OP_REQUIRES(ctx, TensorShapeUtils::IsVector(dense_shape->shape()),\n                errors::InvalidArgument(\n                    \"Input shape should be a vector but received shape \",\n                    dense_shape->shape().DebugString()));\n\n    // We currently ensure that `sparse_tensor` is ordered in the\n    // batch dimension.\n    // TODO(mrry): Investigate ways to avoid this unconditional check\n    // if we can be sure that the sparse tensor was produced in an\n    // appropriate order (e.g. by `tf.parse_example()` or a Dataset\n    // that batches elements into rows of a SparseTensor).\n    int64_t previous_batch_index = -1;\n    for (int64_t i = 0; i < indices->dim_size(0); ++i) {\n      int64_t next_batch_index = indices->matrix<int64_t>()(i, 0);\n      OP_REQUIRES(\n          ctx, next_batch_index >= previous_batch_index,\n          errors::Unimplemented(\"The SparseTensor must be ordered in the batch \"\n                                \"dimension; handling arbitrarily ordered input \"\n                                \"is not currently supported.\"));\n      previous_batch_index = next_batch_index;\n    }\n    gtl::InlinedVector<int64_t, 8> std_order(dense_shape->NumElements(), 0);\n    sparse::SparseTensor tensor;\n    OP_REQUIRES_OK(\n        ctx, sparse::SparseTensor::Create(\n                 *indices, *values, TensorShape(dense_shape->vec<int64_t>()),\n                 std_order, &tensor));\n    *output = new Dataset<T>(ctx, std::move(tensor));\n  }",
        "func_hash": 232798786480644222523895580158118045723,
        "file_name": "sparse_tensor_slice_dataset_op.cc",
        "file_hash": 20179985196620256343354076777909821072,
        "cwe": [
            "CWE-476"
        ],
        "cve": "CVE-2022-21736",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The implementation of `SparseTensorSliceDataset` has an undefined behavior: under certain condition it can be made to dereference a `nullptr` value. The 3 input arguments to `SparseTensorSliceDataset` represent a sparse tensor. However, there are some preconditions that these arguments must satisfy but these are not validated in the implementation. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-21736",
        "func_name": "MakeDataset",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195471,
        "project": "weechat",
        "commit_id": "9904cb6d2eb40f679d8ff6557c22d53a3e3dc75a",
        "project_url": "https://github.com/weechat/weechat",
        "commit_url": "https://github.com/weechat/weechat/commit/9904cb6d2eb40f679d8ff6557c22d53a3e3dc75a",
        "commit_message": "irc: fix crash when receiving a malformed message 352 (who)\n\nThanks to Stuart Nevans Locke for reporting the issue.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "IRC_PROTOCOL_CALLBACK(352)\n{\n    char *pos_attr, *pos_hopcount, *pos_realname, *str_host;\n    int arg_start, length;\n    struct t_irc_channel *ptr_channel;\n    struct t_irc_nick *ptr_nick;\n\n    IRC_PROTOCOL_MIN_ARGS(5);\n\n    /* silently ignore malformed 352 message (missing infos) */\n    if (argc < 8)\n        return WEECHAT_RC_OK;\n\n    pos_attr = NULL;\n    pos_hopcount = NULL;\n    pos_realname = NULL;\n\n    if (argc > 8)\n    {\n        arg_start = (strcmp (argv[8], \"*\") == 0) ? 9 : 8;\n        if (argv[arg_start][0] == ':')\n        {\n            pos_attr = NULL;\n            pos_hopcount = (argc > arg_start) ? argv[arg_start] + 1 : NULL;\n            pos_realname = (argc > arg_start + 1) ? argv_eol[arg_start + 1] : NULL;\n        }\n        else\n        {\n            pos_attr = argv[arg_start];\n            pos_hopcount = (argc > arg_start + 1) ? argv[arg_start + 1] + 1 : NULL;\n            pos_realname = (argc > arg_start + 2) ? argv_eol[arg_start + 2] : NULL;\n        }\n    }\n\n    ptr_channel = irc_channel_search (server, argv[3]);\n    ptr_nick = (ptr_channel) ?\n        irc_nick_search (server, ptr_channel, argv[7]) : NULL;\n\n    /* update host in nick */\n    if (ptr_nick)\n    {\n        length = strlen (argv[4]) + 1 + strlen (argv[5]) + 1;\n        str_host = malloc (length);\n        if (str_host)\n        {\n            snprintf (str_host, length, \"%s@%s\", argv[4], argv[5]);\n            irc_nick_set_host (ptr_nick, str_host);\n            free (str_host);\n        }\n    }\n\n    /* update away flag in nick */\n    if (ptr_channel && ptr_nick && pos_attr)\n    {\n        irc_nick_set_away (server, ptr_channel, ptr_nick,\n                           (pos_attr[0] == 'G') ? 1 : 0);\n    }\n\n    /* update realname in nick */\n    if (ptr_channel && ptr_nick && pos_realname)\n    {\n        if (ptr_nick->realname)\n            free (ptr_nick->realname);\n        if (pos_realname &&\n            weechat_hashtable_has_key (server->cap_list, \"extended-join\"))\n        {\n            ptr_nick->realname = strdup (pos_realname);\n        }\n        else\n        {\n            ptr_nick->realname = NULL;\n        }\n    }\n\n    /* display output of who (manual who from user) */\n    if (!ptr_channel || (ptr_channel->checking_whox <= 0))\n    {\n        weechat_printf_date_tags (\n            irc_msgbuffer_get_target_buffer (\n                server, NULL, command, \"who\", NULL),\n            date,\n            irc_protocol_tags (command, \"irc_numeric\", NULL, NULL),\n            \"%s%s[%s%s%s] %s%s %s(%s%s@%s%s)%s %s%s%s%s(%s)\",\n            weechat_prefix (\"network\"),\n            IRC_COLOR_CHAT_DELIMITERS,\n            IRC_COLOR_CHAT_CHANNEL,\n            argv[3],\n            IRC_COLOR_CHAT_DELIMITERS,\n            irc_nick_color_for_msg (server, 1, NULL, argv[7]),\n            argv[7],\n            IRC_COLOR_CHAT_DELIMITERS,\n            IRC_COLOR_CHAT_HOST,\n            argv[4],\n            argv[5],\n            IRC_COLOR_CHAT_DELIMITERS,\n            IRC_COLOR_RESET,\n            (pos_attr) ? pos_attr : \"\",\n            (pos_attr) ? \" \" : \"\",\n            (pos_hopcount) ? pos_hopcount : \"\",\n            (pos_hopcount) ? \" \" : \"\",\n            (pos_realname) ? pos_realname : \"\");\n    }\n\n    return WEECHAT_RC_OK;\n}",
        "func_hash": 334241185700640959176375322270000746009,
        "file_name": "irc-protocol.c",
        "file_hash": 25326141648227228091841815556030791460,
        "cwe": [
            "CWE-476"
        ],
        "cve": "CVE-2020-9759",
        "cve_desc": "A Vulnerability of LG Electronic web OS TV Emulator could allow an attacker to escalate privileges and overwrite certain files. This vulnerability is due to wrong environment setting. An attacker could exploit this vulnerability through crafted configuration files and executable files.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2020-9759",
        "func_name": "IRC_PROTOCOL_CALLBACK",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195549,
        "project": "hhvm",
        "commit_id": "dabd48caf74995e605f1700344f1ff4a5d83441d",
        "project_url": "https://github.com/facebook/hhvm",
        "commit_url": "https://github.com/facebook/hhvm/commit/dabd48caf74995e605f1700344f1ff4a5d83441d",
        "commit_message": "Fix a json_decode crash when depth==0\n\nSummary:\nSetting depth=0 is an error, and should result in NULL, but we weren't\nchecking for it, so in the case of a single, top-level string, we\nwould reading the -1th element of the stack.\n\nDifferential Revision: D19609959\n\nfbshipit-source-id: 04ca1e0965e04b44df2d5c806a73c3da99ff66fb",
        "target": 1,
        "irrelevant": 0,
        "func_before": "bool JSON_parser(Variant &z, const char *p, int length, bool const assoc,\n                 int depth, int64_t options) {\n  // No GC safepoints during JSON parsing, please. Code is not re-entrant.\n  NoHandleSurpriseScope no_surprise(SafepointFlags);\n\n  json_parser *json = s_json_parser.get(); /* the parser state */\n  // Clear and reuse the thread-local string buffers. They are only freed if\n  // they exceed kMaxPersistentStringBufferCapacity at exit or if the thread\n  // is explicitly flushed (e.g., due to being idle).\n  json->initSb(length);\n  SCOPE_EXIT {\n    constexpr int kMaxPersistentStringBufferCapacity = 256 * 1024;\n    if (json->sb_cap > kMaxPersistentStringBufferCapacity) json->flushSb();\n  };\n  // SimpleParser only handles the most common set of options. Also, only use it\n  // if its array nesting depth check is *more* restrictive than what the user\n  // asks for, to ensure that the precise semantics of the general case is\n  // applied for all nesting overflows.\n  if (assoc &&\n      options == (options & (k_JSON_FB_LOOSE |\n                             k_JSON_FB_DARRAYS |\n                             k_JSON_FB_DARRAYS_AND_VARRAYS |\n                             k_JSON_FB_HACK_ARRAYS |\n                             k_JSON_FB_THRIFT_SIMPLE_JSON |\n                             k_JSON_FB_LEGACY_HACK_ARRAYS)) &&\n      depth >= SimpleParser::kMaxArrayDepth &&\n      length <= RuntimeOption::EvalSimpleJsonMaxLength &&\n      SimpleParser::TryParse(p, length, json->tl_buffer.tv, z,\n                             get_container_type_from_options(options),\n                             options & k_JSON_FB_THRIFT_SIMPLE_JSON)) {\n    return true;\n  }\n\n  int b;  /* the next character */\n  int c;  /* the next character class */\n  int s;  /* the next state */\n  int state = 0;\n\n  /*<fb>*/\n  bool const loose = options & k_JSON_FB_LOOSE;\n  JSONContainerType const container_type =\n    get_container_type_from_options(options);\n  int qchr = 0;\n  int8_t const *byte_class;\n  int8_t const (*next_state_table)[32];\n  if (loose) {\n    byte_class = loose_ascii_class;\n    next_state_table = loose_state_transition_table;\n  } else {\n    byte_class = ascii_class;\n    next_state_table = state_transition_table;\n  }\n  /*</fb>*/\n\n  UncheckedBuffer *buf = &json->sb_buf;\n  UncheckedBuffer *key = &json->sb_key;\n\n  DataType type = kInvalidDataType;\n  unsigned short escaped_bytes = 0;\n\n  auto reset_type = [&] { type = kInvalidDataType; };\n\n  json->depth = depth;\n  // Since the stack is maintainined on a per request basis, for performance\n  // reasons, it only makes sense to expand if necessary and cycles are wasted\n  // contracting. Calls with a depth other than default should be rare.\n  if (depth > json->stack.size()) {\n    json->stack.resize(depth);\n  }\n  SCOPE_EXIT {\n    if (json->stack.empty()) return;\n    for (int i = 0; i <= json->mark; i++) {\n      json->stack[i].key.reset();\n      json->stack[i].val.unset();\n    }\n    json->mark = -1;\n  };\n\n  json->mark = json->top = -1;\n  push(json, Mode::DONE);\n\n  UTF8To16Decoder decoder(p, length, loose);\n  for (;;) {\n    b = decoder.decode();\n    // Fast-case most common transition: append a simple string character.\n    if (state == 3 && type == KindOfString) {\n      while (b != '\\\"' &&  b != '\\\\' && b != '\\'' && b <= 127 && b >= ' ') {\n        buf->append((char)b);\n        b = decoder.decode();\n      }\n    }\n    if (b == UTF8_END) break; // UTF-8 decoding finishes successfully.\n    if (b == UTF8_ERROR) {\n      s_json_parser->error_code = JSON_ERROR_UTF8;\n      return false;\n    }\n    assertx(b >= 0);\n\n    if ((b & 127) == b) {\n      /*<fb>*/\n      c = byte_class[b];\n      /*</fb>*/\n      if (c <= S_ERR) {\n        s_json_parser->error_code = JSON_ERROR_CTRL_CHAR;\n        return false;\n      }\n    } else {\n      c = S_ETC;\n    }\n    /*\n      Get the next state from the transition table.\n    */\n\n    /*<fb>*/\n    s = next_state_table[state][c];\n\n    if (s == -4) {\n      if (b != qchr) {\n        s = 3;\n      } else {\n        qchr = 0;\n      }\n    }\n    /*</fb>*/\n\n    if (s < 0) {\n      /*\n        Perform one of the predefined actions.\n      */\n      switch (s) {\n        /*\n          empty }\n        */\n      case -9:\n        /*<fb>*/\n        if (json->top == 1) z = json->stack[json->top].val;\n        else {\n        /*</fb>*/\n          attach_zval(json, json->stack[json->top].key, assoc, container_type);\n        /*<fb>*/\n        }\n        /*</fb>*/\n        if (!pop(json, Mode::KEY)) {\n          return false;\n        }\n        state = 9;\n        break;\n        /*\n          {\n        */\n      case -8:\n        if (!push(json, Mode::KEY)) {\n          s_json_parser->error_code = JSON_ERROR_DEPTH;\n          return false;\n        }\n\n        state = 1;\n        if (json->top > 0) {\n          Variant &top = json->stack[json->top].val;\n          /*<fb>*/\n          if (container_type == JSONContainerType::COLLECTIONS) {\n            // stable_maps is meaningless\n            top = req::make<c_Map>();\n          } else {\n          /*</fb>*/\n            if (!assoc) {\n              top = SystemLib::AllocStdClassObject();\n            /* <fb> */\n            } else if (container_type == JSONContainerType::HACK_ARRAYS) {\n              top = Array::CreateDict();\n            } else if (container_type == JSONContainerType::DARRAYS ||\n                       container_type == JSONContainerType::DARRAYS_AND_VARRAYS)\n            {\n              top = Array::CreateDArray();\n            /* </fb> */\n            } else if (\n              container_type == JSONContainerType::LEGACY_HACK_ARRAYS) {\n              auto arr = staticEmptyDictArray()->copy();\n              arr->setLegacyArray(true);\n              top = arr;\n            } else {\n              top = Array::CreateDArray();\n            }\n          /*<fb>*/\n          }\n          /*</fb>*/\n          json->stack[json->top].key = copy_and_clear(*key);\n          reset_type();\n        }\n        break;\n        /*\n          }\n        */\n      case -7:\n        /*** BEGIN Facebook: json_utf8_loose ***/\n        /*\n          If this is a trailing comma in an object definition,\n          we're in Mode::KEY. In that case, throw that off the\n          stack and restore Mode::OBJECT so that we pretend the\n          trailing comma just didn't happen.\n        */\n        if (loose) {\n          if (pop(json, Mode::KEY)) {\n            push(json, Mode::OBJECT);\n          }\n        }\n        /*** END Facebook: json_utf8_loose ***/\n\n        if (type != kInvalidDataType &&\n            json->stack[json->top].mode == Mode::OBJECT) {\n          Variant mval;\n          json_create_zval(mval, *buf, type, options);\n          Variant &top = json->stack[json->top].val;\n          object_set(json, top, copy_and_clear(*key),\n                     mval, assoc, container_type);\n          buf->clear();\n          reset_type();\n        }\n\n        /*<fb>*/\n        if (json->top == 1) z = json->stack[json->top].val;\n        else {\n        /*</fb>*/\n          attach_zval(json, json->stack[json->top].key,\n            assoc, container_type);\n        /*<fb>*/\n        }\n        /*</fb>*/\n        if (!pop(json, Mode::OBJECT)) {\n          s_json_parser->error_code = JSON_ERROR_STATE_MISMATCH;\n          return false;\n        }\n        state = 9;\n        break;\n        /*\n          [\n        */\n      case -6:\n        if (!push(json, Mode::ARRAY)) {\n          s_json_parser->error_code = JSON_ERROR_DEPTH;\n          return false;\n        }\n        state = 2;\n\n        if (json->top > 0) {\n          Variant &top = json->stack[json->top].val;\n          /*<fb>*/\n          if (container_type == JSONContainerType::COLLECTIONS) {\n            top = req::make<c_Vector>();\n          } else if (container_type == JSONContainerType::HACK_ARRAYS) {\n            top = Array::CreateVec();\n          } else if (container_type == JSONContainerType::DARRAYS_AND_VARRAYS) {\n            top = Array::CreateVArray();\n          } else if (container_type == JSONContainerType::DARRAYS) {\n            top = Array::CreateDArray();\n          } else if (container_type == JSONContainerType::LEGACY_HACK_ARRAYS) {\n            auto arr = staticEmptyVecArray()->copy();\n            arr->setLegacyArray(true);\n            top = arr;\n          } else {\n            top = Array::CreateDArray();\n          }\n          /*</fb>*/\n          json->stack[json->top].key = copy_and_clear(*key);\n          reset_type();\n        }\n        break;\n        /*\n          ]\n        */\n      case -5:\n        {\n          if (type != kInvalidDataType &&\n               json->stack[json->top].mode == Mode::ARRAY) {\n            Variant mval;\n            json_create_zval(mval, *buf, type, options);\n            auto& top = json->stack[json->top].val;\n            if (container_type == JSONContainerType::COLLECTIONS) {\n              collections::append(top.getObjectData(), mval.asTypedValue());\n            } else {\n              top.asArrRef().append(mval);\n            }\n            buf->clear();\n            reset_type();\n          }\n\n          /*<fb>*/\n          if (json->top == 1) z = json->stack[json->top].val;\n          else {\n          /*</fb>*/\n            attach_zval(json, json->stack[json->top].key, assoc,\n              container_type);\n          /*<fb>*/\n          }\n          /*</fb>*/\n          if (!pop(json, Mode::ARRAY)) {\n            s_json_parser->error_code = JSON_ERROR_STATE_MISMATCH;\n            return false;\n          }\n          state = 9;\n        }\n        break;\n        /*\n          \"\n        */\n      case -4:\n        switch (json->stack[json->top].mode) {\n        case Mode::KEY:\n          state = 27;\n          std::swap(buf, key);\n          reset_type();\n          break;\n        case Mode::ARRAY:\n        case Mode::OBJECT:\n          state = 9;\n          break;\n        case Mode::DONE:\n          if (type == KindOfString) {\n            z = copy_and_clear(*buf);\n            state = 9;\n            break;\n          }\n          /* fall through if not KindOfString */\n        default:\n          s_json_parser->error_code = JSON_ERROR_SYNTAX;\n          return false;\n        }\n        break;\n        /*\n          ,\n        */\n      case -3:\n        {\n          Variant mval;\n          if (type != kInvalidDataType &&\n              (json->stack[json->top].mode == Mode::OBJECT ||\n               json->stack[json->top].mode == Mode::ARRAY)) {\n            json_create_zval(mval, *buf, type, options);\n          }\n\n          switch (json->stack[json->top].mode) {\n          case Mode::OBJECT:\n            if (pop(json, Mode::OBJECT) &&\n                push(json, Mode::KEY)) {\n              if (type != kInvalidDataType) {\n                Variant &top = json->stack[json->top].val;\n                object_set(\n                  json,\n                  top,\n                  copy_and_clear(*key),\n                  mval,\n                  assoc,\n                  container_type\n                );\n              }\n              state = 29;\n            }\n            break;\n          case Mode::ARRAY:\n            if (type != kInvalidDataType) {\n              auto& top = json->stack[json->top].val;\n              if (container_type == JSONContainerType::COLLECTIONS) {\n                collections::append(top.getObjectData(), mval.asTypedValue());\n              } else {\n                top.asArrRef().append(mval);\n              }\n            }\n            state = 28;\n            break;\n          default:\n            s_json_parser->error_code = JSON_ERROR_SYNTAX;\n            return false;\n          }\n          buf->clear();\n          reset_type();\n          check_non_safepoint_surprise();\n        }\n        break;\n\n        /*<fb>*/\n        /*\n          : (after unquoted string)\n        */\n      case -10:\n        if (json->stack[json->top].mode == Mode::KEY) {\n          state = 27;\n          std::swap(buf, key);\n          reset_type();\n          s = -2;\n        } else {\n          s = 3;\n          break;\n        }\n        /*</fb>*/\n\n        /*\n          :\n        */\n      case -2:\n        if (pop(json, Mode::KEY) && push(json, Mode::OBJECT)) {\n          state = 28;\n          break;\n        }\n        /*\n          syntax error\n        */\n      case -1:\n        s_json_parser->error_code = JSON_ERROR_SYNTAX;\n        return false;\n      }\n    } else {\n      /*\n        Change the state and iterate.\n      */\n      bool is_tsimplejson = options & k_JSON_FB_THRIFT_SIMPLE_JSON;\n      if (type == KindOfString) {\n        if (/*<fb>*/(/*</fb>*/s == 3/*<fb>*/ || s == 30)/*</fb>*/ &&\n            state != 8) {\n          if (state != 4) {\n            utf16_to_utf8(*buf, b);\n          } else {\n            switch (b) {\n            case 'b': buf->append('\\b'); break;\n            case 't': buf->append('\\t'); break;\n            case 'n': buf->append('\\n'); break;\n            case 'f': buf->append('\\f'); break;\n            case 'r': buf->append('\\r'); break;\n            default:\n              utf16_to_utf8(*buf, b);\n              break;\n            }\n          }\n        } else if (s == 6) {\n          if (UNLIKELY(is_tsimplejson)) {\n            if (UNLIKELY(b != '0'))  {\n              s_json_parser->error_code = JSON_ERROR_SYNTAX;\n              return false;\n            }\n            escaped_bytes = 0;\n          } else {\n            escaped_bytes = dehexchar(b) << 12;\n          }\n        } else if (s == 7) {\n          if (UNLIKELY(is_tsimplejson)) {\n            if (UNLIKELY(b != '0'))  {\n              s_json_parser->error_code = JSON_ERROR_SYNTAX;\n              return false;\n            }\n          } else {\n            escaped_bytes += dehexchar(b) << 8;\n          }\n        } else if (s == 8) {\n          escaped_bytes += dehexchar(b) << 4;\n        } else if (s == 3 && state == 8) {\n          escaped_bytes += dehexchar(b);\n          if (UNLIKELY(is_tsimplejson)) {\n            buf->append((char)escaped_bytes);\n          } else {\n            utf16_to_utf8(*buf, escaped_bytes);\n          }\n        }\n      } else if ((type == kInvalidDataType || type == KindOfNull) &&\n                 (c == S_DIG || c == S_ZER)) {\n        type = KindOfInt64;\n        buf->append((char)b);\n      } else if (type == KindOfInt64 && s == 24) {\n        type = KindOfDouble;\n        buf->append((char)b);\n      } else if ((type == kInvalidDataType || type == KindOfNull ||\n                  type == KindOfInt64) &&\n                 c == S_DOT) {\n        type = KindOfDouble;\n        buf->append((char)b);\n      } else if (type != KindOfString && c == S_QUO) {\n        type = KindOfString;\n        /*<fb>*/qchr = b;/*</fb>*/\n      } else if ((type == kInvalidDataType || type == KindOfNull ||\n                  type == KindOfInt64 || type == KindOfDouble) &&\n                 ((state == 12 && s == 9) ||\n                  (state == 16 && s == 9))) {\n        type = KindOfBoolean;\n      } else if (type == kInvalidDataType && state == 19 && s == 9) {\n        type = KindOfNull;\n      } else if (type != KindOfString && c > S_WSP) {\n        utf16_to_utf8(*buf, b);\n      }\n\n      state = s;\n    }\n  }\n\n  if (state == 9 && pop(json, Mode::DONE)) {\n    s_json_parser->error_code = JSON_ERROR_NONE;\n    return true;\n  }\n\n  s_json_parser->error_code = JSON_ERROR_SYNTAX;\n  return false;\n}",
        "func_hash": 279425347197289676453081001044103129987,
        "file_name": "JSON_parser.cpp",
        "file_hash": 153660966749897898132051442502557946400,
        "cwe": [
            "CWE-125"
        ],
        "cve": "CVE-2020-1892",
        "cve_desc": "Insufficient boundary checks when decoding JSON in JSON_parser allows read access to out of bounds memory, potentially leading to information leak and DOS. This issue affects HHVM 4.45.0, 4.44.0, 4.43.0, 4.42.0, 4.41.0, 4.40.0, 4.39.0, versions between 4.33.0 and 4.38.0 (inclusive), versions between 4.9.0 and 4.32.0 (inclusive), and versions prior to 4.8.7.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2020-1892",
        "func_name": "JSON_parser",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195565,
        "project": "hhvm",
        "commit_id": "dbeb9a56a638e3fdcef8b691c2a2967132dae692",
        "project_url": "https://github.com/facebook/hhvm",
        "commit_url": "https://github.com/facebook/hhvm/commit/dbeb9a56a638e3fdcef8b691c2a2967132dae692",
        "commit_message": "string_number_format: Correctly handles return value of snprintf\n\nSummary: `snprintf` can return a value greater than the number of bytes copied. In case the first byte of the string is not a digit (could be '-'), size of `tmpstr` was being updated without checking `tmplen`. This resulted in either an assertion error or a heap overflow depending on whether the assertion is compiled or not.\n\nReviewed By: mofarrell, qianxuweiren\n\nDifferential Revision: D17327899\n\nfbshipit-source-id: ee53875d21e02608c6d870388eecf1464de24ff1",
        "target": 1,
        "irrelevant": 1,
        "func_before": "String string_number_format(double d, int dec,\n                            const String& dec_point,\n                            const String& thousand_sep) {\n  char *tmpbuf = nullptr, *resbuf;\n  char *s, *t;  /* source, target */\n  char *dp;\n  int integral;\n  int tmplen, reslen=0;\n  int count=0;\n  int is_negative=0;\n\n  if (d < 0) {\n    is_negative = 1;\n    d = -d;\n  }\n\n  if (dec < 0) dec = 0;\n  d = php_math_round(d, dec);\n\n  // departure from PHP: we got rid of dependencies on spprintf() here.\n  String tmpstr(63, ReserveString);\n  tmpbuf = tmpstr.mutableData();\n  tmplen = snprintf(tmpbuf, 64, \"%.*F\", dec, d);\n  if (tmplen < 0) return empty_string();\n  if (tmpbuf == nullptr || !isdigit((int)tmpbuf[0])) {\n    tmpstr.setSize(tmplen);\n    return tmpstr;\n  }\n  if (tmplen >= 64) {\n    // Uncommon, asked for more than 64 chars worth of precision\n    tmpstr = String(tmplen, ReserveString);\n    tmpbuf = tmpstr.mutableData();\n    tmplen = snprintf(tmpbuf, tmplen + 1, \"%.*F\", dec, d);\n    if (tmplen < 0) return empty_string();\n    if (tmpbuf == nullptr || !isdigit((int)tmpbuf[0])) {\n      tmpstr.setSize(tmplen);\n      return tmpstr;\n    }\n  }\n\n  /* find decimal point, if expected */\n  if (dec) {\n    dp = strpbrk(tmpbuf, \".,\");\n  } else {\n    dp = nullptr;\n  }\n\n  /* calculate the length of the return buffer */\n  if (dp) {\n    integral = dp - tmpbuf;\n  } else {\n    /* no decimal point was found */\n    integral = tmplen;\n  }\n\n  /* allow for thousand separators */\n  if (!thousand_sep.empty()) {\n    if (integral + thousand_sep.size() * ((integral-1) / 3) < integral) {\n      /* overflow */\n      raise_error(\"String overflow\");\n    }\n\n    integral += ((integral-1) / 3) * thousand_sep.size();\n  }\n\n  reslen = integral;\n\n  if (dec) {\n    reslen += dec;\n\n    if (!dec_point.empty()) {\n      if (reslen + dec_point.size() < dec_point.size()) {\n        /* overflow */\n        raise_error(\"String overflow\");\n      }\n      reslen += dec_point.size();\n    }\n  }\n\n  /* add a byte for minus sign */\n  if (is_negative) {\n    reslen++;\n  }\n  String resstr(reslen, ReserveString);\n  resbuf = resstr.mutableData();\n\n  s = tmpbuf+tmplen-1;\n  t = resbuf+reslen-1;\n\n  /* copy the decimal places.\n   * Take care, as the sprintf implementation may return less places than\n   * we requested due to internal buffer limitations */\n  if (dec) {\n    int declen = dp ? s - dp : 0;\n    int topad = dec > declen ? dec - declen : 0;\n\n    /* pad with '0's */\n    while (topad--) {\n      *t-- = '0';\n    }\n\n    if (dp) {\n      s -= declen + 1; /* +1 to skip the point */\n      t -= declen;\n\n      /* now copy the chars after the point */\n      memcpy(t + 1, dp + 1, declen);\n    }\n\n    /* add decimal point */\n    if (!dec_point.empty()) {\n      memcpy(t + (1 - dec_point.size()), dec_point.data(), dec_point.size());\n      t -= dec_point.size();\n    }\n  }\n\n  /* copy the numbers before the decimal point, adding thousand\n   * separator every three digits */\n  while(s >= tmpbuf) {\n    *t-- = *s--;\n    if (thousand_sep && (++count%3)==0 && s>=tmpbuf) {\n      memcpy(t + (1 - thousand_sep.size()),\n             thousand_sep.data(),\n             thousand_sep.size());\n      t -= thousand_sep.size();\n    }\n  }\n\n  /* and a minus sign, if needed */\n  if (is_negative) {\n    *t-- = '-';\n  }\n\n  resstr.setSize(reslen);\n  return resstr;\n}",
        "func_hash": 125018652199743804521817207176944376682,
        "file_name": "zend-string.cpp",
        "file_hash": 157727558891612041764030573186624095506,
        "cwe": [
            "CWE-119"
        ],
        "cve": "CVE-2019-11929",
        "cve_desc": "Insufficient boundary checks when formatting numbers in number_format allows read/write access to out-of-bounds memory, potentially leading to remote code execution. This issue affects HHVM versions prior to 3.30.10, all versions between 4.0.0 and 4.8.5, all versions between 4.9.0 and 4.18.2, and versions 4.19.0, 4.19.1, 4.20.0, 4.20.1, 4.20.2, 4.21.0, 4.22.0, 4.23.0.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2019-11929",
        "func_name": "string_number_format",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195626,
        "project": "qemu",
        "commit_id": "7882080388be5088e72c425b02223c02e6cb4295",
        "project_url": "https://github.com/bonzini/qemu",
        "commit_url": "https://github.com/qemu/qemu/commit/7882080388be5088e72c425b02223c02e6cb4295",
        "commit_message": "virtio-serial: fix ANY_LAYOUT\n\nDon't assume a specific layout for control messages.\nRequired by virtio 1.\n\nSigned-off-by: Michael S. Tsirkin <mst@redhat.com>\nReviewed-by: Amit Shah <amit.shah@redhat.com>\nReviewed-by: Jason Wang <jasowang@redhat.com>",
        "target": 1,
        "irrelevant": 1,
        "func_before": "static size_t send_control_msg(VirtIOSerial *vser, void *buf, size_t len)\n{\n    VirtQueueElement elem;\n    VirtQueue *vq;\n\n    vq = vser->c_ivq;\n    if (!virtio_queue_ready(vq)) {\n        return 0;\n    }\n    if (!virtqueue_pop(vq, &elem)) {\n        return 0;\n    }\n\n    memcpy(elem.in_sg[0].iov_base, buf, len);\n\n    virtqueue_push(vq, &elem, len);\n    virtio_notify(VIRTIO_DEVICE(vser), vq);\n    return len;\n}",
        "func_hash": 301712778748262907171467771526276497164,
        "file_name": "virtio-serial-bus.c",
        "file_hash": 253157734411856913752064284433381457044,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2015-5745",
        "cve_desc": "Buffer overflow in the send_control_msg function in hw/char/virtio-serial-bus.c in QEMU before 2.4.0 allows guest users to cause a denial of service (QEMU process crash) via a crafted virtio control message.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2015-5745",
        "func_name": "send_control_msg",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195629,
        "project": "tensorflow",
        "commit_id": "a5b89cd68c02329d793356bda85d079e9e69b4e7",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/a5b89cd68c02329d793356bda85d079e9e69b4e7",
        "commit_message": "Fix empty resource handle vulnerability.\n\nSome ops that attempt to extract a resource handle from user input\ncan lead to nullptr dereferences.  This returns an error in such\na case.\n\nPiperOrigin-RevId: 445571938",
        "target": 1,
        "irrelevant": 1,
        "func_before": "Status GetDeviceForInput(const EagerOperation& op, const EagerContext& ctx,\n                         TensorHandle* tensor_handle, Device** result) {\n  Device* cpu_device = ctx.HostCPU();\n  string device_name;\n  if (tensor_handle->Type() != TensorHandle::LOCAL) {\n    Device* device = tensor_handle->device();\n    device_name = device != nullptr ? device->name() : cpu_device->name();\n    *result = (device == nullptr ? cpu_device : device);\n  } else if (tensor_handle->dtype == DT_RESOURCE) {\n    // Use the resource's actual device because it is the device that will\n    // influence partitioning the multi-device function.\n    const Tensor* tensor;\n    // TODO(fishx): Avoid blocking here.\n    TF_RETURN_IF_ERROR(tensor_handle->Tensor(&tensor));\n    const ResourceHandle& handle = tensor->flat<ResourceHandle>()(0);\n    device_name = handle.device();\n\n    Device* input_device;\n    TF_RETURN_IF_ERROR(\n        ctx.FindDeviceFromName(device_name.c_str(), &input_device));\n    *result = input_device;\n  } else {\n    Device* device = tensor_handle->device();\n    const bool is_tpu = device != nullptr && device->device_type() == \"TPU\";\n    // int32 return values can be placed on TPUs.\n    const bool use_host_memory =\n        is_tpu ? MTypeFromDTypeIntsOnDevice(tensor_handle->dtype)\n               : MTypeFromDType(tensor_handle->dtype);\n    if (use_host_memory) {\n      *result = cpu_device;\n    } else {\n      // Eager ops executing as functions should have their preferred inputs set\n      // to the op's device. This allows us to avoid expensive D2H copies if a\n      // mirror of the tensor already exists on the op's device.\n      if (!op.is_function() && device != nullptr && device != cpu_device) {\n        device = absl::get<Device*>(op.Device());\n      }\n      *result = (device == nullptr ? cpu_device : device);\n    }\n  }\n  return Status::OK();\n}",
        "func_hash": 227007805370541421392187811352073944672,
        "file_name": "execute.cc",
        "file_hash": 250138698264718373642663717664797527317,
        "cwe": [
            "CWE-476"
        ],
        "cve": "CVE-2022-29207",
        "cve_desc": "TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, multiple TensorFlow operations misbehave in eager mode when the resource handle provided to them is invalid. In graph mode, it would have been impossible to perform these API calls, but migration to TF 2.x eager mode opened up this vulnerability. If the resource handle is empty, then a reference is bound to a null pointer inside TensorFlow codebase (various codepaths). This is undefined behavior. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-29207",
        "func_name": "GetDeviceForInput",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195665,
        "project": "njs",
        "commit_id": "2e00e95473861846aa8538be87db07699d9f676d",
        "project_url": "https://github.com/nginx/njs",
        "commit_url": "https://github.com/nginx/njs/commit/2e00e95473861846aa8538be87db07699d9f676d",
        "commit_message": "Fixed Array.prototype.slice() with slow \"this\" argument.\n\nPreviously, when \"this\" argument was not a fast array, but the \"deleted\" array\nwas a fast array, the \"deleted\" array may be left in uninitialized state if\n\"this\" argument had gaps.\n\nThis fix is to ensure that \"deleted\" is properly initialized.\n\nThis fixes #485 issue on Github.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "njs_array_prototype_splice(njs_vm_t *vm, njs_value_t *args, njs_uint_t nargs,\n    njs_index_t unused)\n{\n    int64_t      i, n, start, length, items, delta, delete;\n    njs_int_t    ret;\n    njs_value_t  *this, value, del_object;\n    njs_array_t  *array, *deleted;\n\n    this = njs_argument(args, 0);\n\n    ret = njs_value_to_object(vm, this);\n    if (njs_slow_path(ret != NJS_OK)) {\n        return ret;\n    }\n\n    ret = njs_object_length(vm, this, &length);\n    if (njs_slow_path(ret == NJS_ERROR)) {\n        return ret;\n    }\n\n    ret = njs_value_to_integer(vm, njs_arg(args, nargs, 1), &start);\n    if (njs_slow_path(ret != NJS_OK)) {\n        return ret;\n    }\n\n    start = (start < 0) ? njs_max(length + start, 0) : njs_min(start, length);\n\n    items = 0;\n    delete = 0;\n\n    if (nargs == 2) {\n        delete = length - start;\n\n    } else if (nargs > 2) {\n        items = nargs - 3;\n\n        ret = njs_value_to_integer(vm, njs_arg(args, nargs, 2), &delete);\n        if (njs_slow_path(ret != NJS_OK)) {\n            return ret;\n        }\n\n        delete = njs_min(njs_max(delete, 0), length - start);\n    }\n\n    delta = items - delete;\n\n    if (njs_slow_path((length + delta) > NJS_MAX_LENGTH)) {\n        njs_type_error(vm, \"Invalid length\");\n        return NJS_ERROR;\n    }\n\n    /* TODO: ArraySpeciesCreate(). */\n\n    deleted = njs_array_alloc(vm, 0, delete, 0);\n    if (njs_slow_path(deleted == NULL)) {\n        return NJS_ERROR;\n    }\n\n    if (njs_fast_path(njs_is_fast_array(this) && deleted->object.fast_array)) {\n        array = njs_array(this);\n        for (i = 0, n = start; i < delete; i++, n++) {\n            deleted->start[i] = array->start[n];\n        }\n\n    } else {\n        njs_set_array(&del_object, deleted);\n\n        for (i = 0, n = start; i < delete; i++, n++) {\n            ret = njs_value_property_i64(vm, this, n, &value);\n            if (njs_slow_path(ret == NJS_ERROR)) {\n                return NJS_ERROR;\n            }\n\n            if (ret == NJS_OK) {\n                /* TODO:  CreateDataPropertyOrThrow(). */\n                ret = njs_value_property_i64_set(vm, &del_object, i, &value);\n                if (njs_slow_path(ret == NJS_ERROR)) {\n                    return ret;\n                }\n            }\n        }\n\n        ret = njs_object_length_set(vm, &del_object, delete);\n        if (njs_slow_path(ret != NJS_OK)) {\n            return NJS_ERROR;\n        }\n    }\n\n    if (njs_fast_path(njs_is_fast_array(this))) {\n        array = njs_array(this);\n\n        if (delta != 0) {\n            /*\n             * Relocate the rest of items.\n             * Index of the first item is in \"n\".\n             */\n            if (delta > 0) {\n                ret = njs_array_expand(vm, array, 0, delta);\n                if (njs_slow_path(ret != NJS_OK)) {\n                    return ret;\n                }\n            }\n\n            ret = njs_array_copy_within(vm, this, start + items, start + delete,\n                                        array->length - (start + delete), 0);\n            if (njs_slow_path(ret != NJS_OK)) {\n                return ret;\n            }\n\n            array->length += delta;\n        }\n\n        /* Copy new items. */\n\n        if (items > 0) {\n            memcpy(&array->start[start], &args[3],\n                   items * sizeof(njs_value_t));\n        }\n\n    } else {\n\n       if (delta != 0) {\n           ret = njs_array_copy_within(vm, this, start + items, start + delete,\n                                       length - (start + delete), delta < 0);\n            if (njs_slow_path(ret != NJS_OK)) {\n                return ret;\n            }\n\n            for (i = length - 1; i >= length + delta; i--) {\n                ret = njs_value_property_i64_delete(vm, this, i, NULL);\n                if (njs_slow_path(ret == NJS_ERROR)) {\n                    return NJS_ERROR;\n                }\n            }\n       }\n\n        /* Copy new items. */\n\n        for (i = 3, n = start; items-- > 0; i++, n++) {\n            ret = njs_value_property_i64_set(vm, this, n, &args[i]);\n            if (njs_slow_path(ret == NJS_ERROR)) {\n                return NJS_ERROR;\n            }\n        }\n\n        ret = njs_object_length_set(vm, this, length + delta);\n        if (njs_slow_path(ret != NJS_OK)) {\n            return NJS_ERROR;\n        }\n    }\n\n    njs_set_array(&vm->retval, deleted);\n\n    return NJS_OK;\n}",
        "func_hash": 41889957200154277256182614621042854713,
        "file_name": "njs_array.c",
        "file_hash": 27861953644579332654826088207600556930,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2022-29779",
        "cve_desc": "Nginx NJS v0.7.2 was discovered to contain a segmentation violation in the function njs_value_own_enumerate at src/njs_value.c.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-29779",
        "func_name": "njs_array_prototype_splice",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195668,
        "project": "mruby",
        "commit_id": "38b164ace7d6ae1c367883a3d67d7f559783faad",
        "project_url": "https://github.com/mruby/mruby",
        "commit_url": "https://github.com/mruby/mruby/commit/38b164ace7d6ae1c367883a3d67d7f559783faad",
        "commit_message": "codegen.c: fix a bug in `gen_values()`.\n\n- Fix limit handling that fails 15 arguments method calls.\n- Fix too early argument packing in arrays.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "gen_values(codegen_scope *s, node *t, int val, int limit)\n{\n  int n = 0;\n  int first = 1;\n  int slimit = GEN_VAL_STACK_MAX;\n\n  if (limit == 0) limit = GEN_LIT_ARY_MAX;\n  if (cursp() >= slimit) slimit = INT16_MAX;\n\n  if (!val) {\n    while (t) {\n      codegen(s, t->car, NOVAL);\n      n++;\n      t = t->cdr;\n    }\n    return n;\n  }\n\n  while (t) {\n    int is_splat = nint(t->car->car) == NODE_SPLAT;\n\n    if (is_splat || n > limit || cursp() >= slimit) { /* flush stack */\n      pop_n(n);\n      if (first) {\n        if (n == 0) {\n          genop_1(s, OP_LOADNIL, cursp());\n        }\n        else {\n          genop_2(s, OP_ARRAY, cursp(), n);\n        }\n        push();\n        first = 0;\n        limit = GEN_LIT_ARY_MAX;\n      }\n      else if (n > 0) {\n        pop();\n        genop_2(s, OP_ARYPUSH, cursp(), n);\n        push();\n      }\n      n = 0;\n    }\n    codegen(s, t->car, val);\n    if (is_splat) {\n      pop(); pop();\n      genop_1(s, OP_ARYCAT, cursp());\n      push();\n    }\n    else {\n      n++;\n    }\n    t = t->cdr;\n  }\n  if (!first) {\n    pop();\n    if (n > 0) {\n      pop_n(n);\n      genop_2(s, OP_ARYPUSH, cursp(), n);\n    }\n    return -1;                  /* variable length */\n  }\n  return n;\n}",
        "func_hash": 322425551847944018477435186419959863555,
        "file_name": "codegen.c",
        "file_hash": 88374800173229199956653339408236459963,
        "cwe": [
            "CWE-415"
        ],
        "cve": "CVE-2022-0570",
        "cve_desc": "Heap-based Buffer Overflow in Homebrew mruby prior to 3.2.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-0570",
        "func_name": "gen_values",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195670,
        "project": "pjproject",
        "commit_id": "856f87c2e97a27b256482dbe0d748b1194355a21",
        "project_url": "https://github.com/pjsip/pjproject",
        "commit_url": "https://github.com/pjsip/pjproject/commit/856f87c2e97a27b256482dbe0d748b1194355a21",
        "commit_message": "Merge pull request from GHSA-5x45-qp78-g4p4\n\n* Prevent infinite loop in scanning xml content\n\n* Simplify scanning method\n\n* Optimization",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static pj_xml_node *xml_parse_node( pj_pool_t *pool, pj_scanner *scanner)\n{\n    pj_xml_node *node;\n    pj_str_t end_name;\n\n    PJ_CHECK_STACK();\n\n    if (*scanner->curptr != '<')\n\ton_syntax_error(scanner);\n\n    /* Handle Processing Instructino (PI) construct (i.e. \"<?\") */\n    if (*scanner->curptr == '<' && *(scanner->curptr+1) == '?') {\n\tpj_scan_advance_n(scanner, 2, PJ_FALSE);\n\tfor (;;) {\n\t    pj_str_t dummy;\n\t    pj_scan_get_until_ch(scanner, '?', &dummy);\n\t    if (*scanner->curptr=='?' && *(scanner->curptr+1)=='>') {\n\t\tpj_scan_advance_n(scanner, 2, PJ_TRUE);\n\t\tbreak;\n\t    } else {\n\t\tpj_scan_advance_n(scanner, 1, PJ_FALSE);\n\t    }\n\t}\n\treturn xml_parse_node(pool, scanner);\n    }\n\n    /* Handle comments construct (i.e. \"<!\") */\n    if (pj_scan_strcmp(scanner, \"<!\", 2) == 0) {\n\tpj_scan_advance_n(scanner, 2, PJ_FALSE);\n\tfor (;;) {\n\t    pj_str_t dummy;\n\t    pj_scan_get_until_ch(scanner, '>', &dummy);\n\t    if (pj_scan_strcmp(scanner, \">\", 1) == 0) {\n\t\tpj_scan_advance_n(scanner, 1, PJ_TRUE);\n\t\tbreak;\n\t    } else {\n\t\tpj_scan_advance_n(scanner, 1, PJ_FALSE);\n\t    }\n\t}\n\treturn xml_parse_node(pool, scanner);\n    }\n\n    /* Alloc node. */\n    node = alloc_node(pool);\n\n    /* Get '<' */\n    pj_scan_get_char(scanner);\n\n    /* Get node name. */\n    pj_scan_get_until_chr( scanner, \" />\\t\\r\\n\", &node->name);\n\n    /* Get attributes. */\n    while (*scanner->curptr != '>' && *scanner->curptr != '/') {\n\tpj_xml_attr *attr = alloc_attr(pool);\n\t\n\tpj_scan_get_until_chr( scanner, \"=> \\t\\r\\n\", &attr->name);\n\tif (*scanner->curptr == '=') {\n\t    pj_scan_get_char( scanner );\n            pj_scan_get_quotes(scanner, \"\\\"'\", \"\\\"'\", 2, &attr->value);\n\t    /* remove quote characters */\n\t    ++attr->value.ptr;\n\t    attr->value.slen -= 2;\n\t}\n\t\n\tpj_list_push_back( &node->attr_head, attr );\n    }\n\n    if (*scanner->curptr == '/') {\n\tpj_scan_get_char(scanner);\n\tif (pj_scan_get_char(scanner) != '>')\n\t    on_syntax_error(scanner);\n\treturn node;\n    }\n\n    /* Enclosing bracket. */\n    if (pj_scan_get_char(scanner) != '>')\n\ton_syntax_error(scanner);\n\n    /* Sub nodes. */\n    while (*scanner->curptr == '<' && *(scanner->curptr+1) != '/'\n\t\t\t\t   && *(scanner->curptr+1) != '!')\n    {\n\tpj_xml_node *sub_node = xml_parse_node(pool, scanner);\n\tpj_list_push_back( &node->node_head, sub_node );\n    }\n\n    /* Content. */\n    if (!pj_scan_is_eof(scanner) && *scanner->curptr != '<') {\n\tpj_scan_get_until_ch(scanner, '<', &node->content);\n    }\n\n    /* CDATA content. */\n    if (*scanner->curptr == '<' && *(scanner->curptr+1) == '!' &&\n\tpj_scan_strcmp(scanner, \"<![CDATA[\", 9) == 0)\n    {\n\tpj_scan_advance_n(scanner, 9, PJ_FALSE);\n\tpj_scan_get_until_ch(scanner, ']', &node->content);\n\twhile (pj_scan_strcmp(scanner, \"]]>\", 3)) {\n\t    pj_str_t dummy;\n\t    pj_scan_get_until_ch(scanner, ']', &dummy);\n\t}\n\tnode->content.slen = scanner->curptr - node->content.ptr;\n\tpj_scan_advance_n(scanner, 3, PJ_TRUE);\n    }\n\n    /* Enclosing node. */\n    if (pj_scan_get_char(scanner) != '<' || pj_scan_get_char(scanner) != '/')\n\ton_syntax_error(scanner);\n\n    pj_scan_get_until_chr(scanner, \" \\t>\", &end_name);\n\n    /* Compare name. */\n    if (pj_stricmp(&node->name, &end_name) != 0)\n\ton_syntax_error(scanner);\n\n    /* Enclosing '>' */\n    if (pj_scan_get_char(scanner) != '>')\n\ton_syntax_error(scanner);\n\n    return node;\n}",
        "func_hash": 277240174945375908655928995975016589842,
        "file_name": "xml.c",
        "file_hash": 319030018310003515806173873266013713455,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2022-24763",
        "cve_desc": "PJSIP is a free and open source multimedia communication library written in the C language. Versions 2.12 and prior contain a denial-of-service vulnerability that affects PJSIP users that consume PJSIP's XML parsing in their apps. Users are advised to update. There are no known workarounds.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-24763",
        "func_name": "xml_parse_node",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 196889,
        "project": "rpm",
        "commit_id": "bd36c5dc9fb6d90c46fbfed8c2d67516fc571ec8",
        "project_url": "https://github.com/rpm-software-management/rpm",
        "commit_url": "https://github.com/rpm-software-management/rpm/commit/bd36c5dc9fb6d90c46fbfed8c2d67516fc571ec8",
        "commit_message": "Validate and require subkey binding signatures on PGP public keys\n\nAll subkeys must be followed by a binding signature by the primary key\nas per the OpenPGP RFC, enforce the presence and validity in the parser.\n\nThe implementation is as kludgey as they come to work around our\nsimple-minded parser structure without touching API, to maximise\nbackportability. Store all the raw packets internally as we decode them\nto be able to access previous elements at will, needed to validate ordering\nand access the actual data. Add testcases for manipulated keys whose\nimport previously would succeed.\n\nDepends on the two previous commits:\n7b399fcb8f52566e6f3b4327197a85facd08db91 and\n236b802a4aa48711823a191d1b7f753c82a89ec5\n\nFixes CVE-2021-3521.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "int pgpPrtParams(const uint8_t * pkts, size_t pktlen, unsigned int pkttype,\n\t\t pgpDigParams * ret)\n{\n    const uint8_t *p = pkts;\n    const uint8_t *pend = pkts + pktlen;\n    pgpDigParams digp = NULL;\n    struct pgpPkt pkt;\n    int rc = -1; /* assume failure */\n\n    while (p < pend) {\n\tif (decodePkt(p, (pend - p), &pkt))\n\t    break;\n\n\tif (digp == NULL) {\n\t    if (pkttype && pkt.tag != pkttype) {\n\t\tbreak;\n\t    } else {\n\t\tdigp = pgpDigParamsNew(pkt.tag);\n\t    }\n\t}\n\n\tif (pgpPrtPkt(&pkt, digp))\n\t    break;\n\n\tp += (pkt.body - pkt.head) + pkt.blen;\n\tif (pkttype == PGPTAG_SIGNATURE)\n\t    break;\n    }\n\n    rc = (digp && (p == pend)) ? 0 : -1;\n\n    if (ret && rc == 0) {\n\t*ret = digp;\n    } else {\n\tpgpDigParamsFree(digp);\n    }\n    return rc;\n}",
        "func_hash": 241902861702092358566393446057169117418,
        "file_name": "rpmpgp.c",
        "file_hash": 261680371397829724328332349939648686474,
        "cwe": [
            "CWE-284"
        ],
        "cve": "CVE-2021-3521",
        "cve_desc": "There is a flaw in RPM's signature functionality. OpenPGP subkeys are associated with a primary key via a \"binding signature.\" RPM does not check the binding signature of subkeys prior to importing them. If an attacker is able to add or socially engineer another party to add a malicious subkey to a legitimate public key, RPM could wrongly trust a malicious signature. The greatest impact of this flaw is to data integrity. To exploit this flaw, an attacker must either compromise an RPM repository or convince an administrator to install an untrusted RPM or public key. It is strongly recommended to only use RPMs and public keys from trusted sources.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-3521",
        "func_name": "pgpPrtParams",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 196893,
        "project": "envoy",
        "commit_id": "e9f936d85dc1edc34fabd0a1725ec180f2316353",
        "project_url": "https://github.com/istio/envoy",
        "commit_url": "https://github.com/envoyproxy/envoy/commit/e9f936d85dc1edc34fabd0a1725ec180f2316353",
        "commit_message": "CVE-2022-21654\n\ntls allows re-use when some cert validation settings have changed\n\nSigned-off-by: Yan Avlasov <yavlasov@google.com>",
        "target": 1,
        "irrelevant": 0,
        "func_before": "void DefaultCertValidator::updateDigestForSessionId(bssl::ScopedEVP_MD_CTX& md,\n                                                    uint8_t hash_buffer[EVP_MAX_MD_SIZE],\n                                                    unsigned hash_length) {\n  int rc;\n\n  // Hash all the settings that affect whether the server will allow/accept\n  // the client connection. This ensures that the client is always validated against\n  // the correct settings, even if session resumption across different listeners\n  // is enabled.\n  if (ca_cert_ != nullptr) {\n    rc = X509_digest(ca_cert_.get(), EVP_sha256(), hash_buffer, &hash_length);\n    RELEASE_ASSERT(rc == 1, Utility::getLastCryptoError().value_or(\"\"));\n    RELEASE_ASSERT(hash_length == SHA256_DIGEST_LENGTH,\n                   fmt::format(\"invalid SHA256 hash length {}\", hash_length));\n\n    rc = EVP_DigestUpdate(md.get(), hash_buffer, hash_length);\n    RELEASE_ASSERT(rc == 1, Utility::getLastCryptoError().value_or(\"\"));\n  }\n\n  for (const auto& hash : verify_certificate_hash_list_) {\n    rc = EVP_DigestUpdate(md.get(), hash.data(),\n                          hash.size() *\n                              sizeof(std::remove_reference<decltype(hash)>::type::value_type));\n    RELEASE_ASSERT(rc == 1, Utility::getLastCryptoError().value_or(\"\"));\n  }\n\n  for (const auto& hash : verify_certificate_spki_list_) {\n    rc = EVP_DigestUpdate(md.get(), hash.data(),\n                          hash.size() *\n                              sizeof(std::remove_reference<decltype(hash)>::type::value_type));\n    RELEASE_ASSERT(rc == 1, Utility::getLastCryptoError().value_or(\"\"));\n  }\n}",
        "func_hash": 140411723524972581248505271605198365196,
        "file_name": "default_validator.cc",
        "file_hash": 12469299547216327731154844869138538271,
        "cwe": [
            "CWE-362"
        ],
        "cve": "CVE-2022-21654",
        "cve_desc": "Envoy is an open source edge and service proxy, designed for cloud-native applications. Envoy's tls allows re-use when some cert validation settings have changed from their default configuration. The only workaround for this issue is to ensure that default tls settings are used. Users are advised to upgrade.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-21654",
        "func_name": "DefaultCertValidator::updateDigestForSessionId",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 196894,
        "project": "cryptopp",
        "commit_id": "9425e16437439e68c7d96abef922167d68fafaff",
        "project_url": "https://github.com/weidai11/cryptopp",
        "commit_url": "https://github.com/weidai11/cryptopp/commit/9425e16437439e68c7d96abef922167d68fafaff",
        "commit_message": "Fix for CVE-2015-2141. Thanks to Evgeny Sidorov for reporting. Squaring to satisfy Jacobi requirements suggested by JPM.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "Integer InvertibleRWFunction::CalculateInverse(RandomNumberGenerator &rng, const Integer &x) const\n{\n\tDoQuickSanityCheck();\n\tModularArithmetic modn(m_n);\n\tInteger r, rInv;\n\tdo {\t// do this in a loop for people using small numbers for testing\n\t\tr.Randomize(rng, Integer::One(), m_n - Integer::One());\n\t\trInv = modn.MultiplicativeInverse(r);\n\t} while (rInv.IsZero());\n\tInteger re = modn.Square(r);\n\tre = modn.Multiply(re, x);\t\t\t// blind\n\n\tInteger cp=re%m_p, cq=re%m_q;\n\tif (Jacobi(cp, m_p) * Jacobi(cq, m_q) != 1)\n\t{\n\t\tcp = cp.IsOdd() ? (cp+m_p) >> 1 : cp >> 1;\n\t\tcq = cq.IsOdd() ? (cq+m_q) >> 1 : cq >> 1;\n\t}\n\n\t#pragma omp parallel\n\t\t#pragma omp sections\n\t\t{\n\t\t\t#pragma omp section\n\t\t\t\tcp = ModularSquareRoot(cp, m_p);\n\t\t\t#pragma omp section\n\t\t\t\tcq = ModularSquareRoot(cq, m_q);\n\t\t}\n\n\tInteger y = CRT(cq, m_q, cp, m_p, m_u);\n\ty = modn.Multiply(y, rInv);\t\t\t\t// unblind\n\ty = STDMIN(y, m_n-y);\n\tif (ApplyFunction(y) != x)\t\t\t\t// check\n\t\tthrow Exception(Exception::OTHER_ERROR, \"InvertibleRWFunction: computational error during private key operation\");\n\treturn y;\n}",
        "func_hash": 290420030541756407514179370586675759104,
        "file_name": "rw.cpp",
        "file_hash": 28365074804944330860384058197646130181,
        "cwe": [
            "CWE-399"
        ],
        "cve": "CVE-2015-2141",
        "cve_desc": "The InvertibleRWFunction::CalculateInverse function in rw.cpp in libcrypt++ 5.6.2 does not properly blind private key operations for the Rabin-Williams digital signature algorithm, which allows remote attackers to obtain private keys via a timing attack.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2015-2141",
        "func_name": "InvertibleRWFunction::CalculateInverse",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 196993,
        "project": "libjxl",
        "commit_id": "7dfa400ded53919d986c5d3d23446a09e0cf481b",
        "project_url": "https://github.com/libjxl/libjxl",
        "commit_url": "https://github.com/libjxl/libjxl/commit/7dfa400ded53919d986c5d3d23446a09e0cf481b",
        "commit_message": "Fix handling of APNG with 0 delay_den (#313)",
        "target": 1,
        "irrelevant": 0,
        "func_before": "Status DecodeImageAPNG(Span<const uint8_t> bytes, ThreadPool* pool,\n                       CodecInOut* io) {\n  Reader r;\n  unsigned int id, i, j, w, h, w0, h0, x0, y0;\n  unsigned int delay_num, delay_den, dop, bop, rowbytes, imagesize;\n  unsigned char sig[8];\n  png_structp png_ptr;\n  png_infop info_ptr;\n  CHUNK chunk;\n  CHUNK chunkIHDR;\n  std::vector<CHUNK> chunksInfo;\n  bool isAnimated = false;\n  bool skipFirst = false;\n  bool hasInfo = false;\n  bool all_dispose_bg = true;\n  APNGFrame frameRaw = {};\n\n  r = {bytes.data(), bytes.data() + bytes.size()};\n  // Not an aPNG => not an error\n  unsigned char png_signature[8] = {137, 80, 78, 71, 13, 10, 26, 10};\n  if (r.Read(sig, 8) || memcmp(sig, png_signature, 8) != 0) {\n    return false;\n  }\n  id = read_chunk(&r, &chunkIHDR);\n\n  io->frames.clear();\n  io->dec_pixels = 0;\n  io->metadata.m.SetUintSamples(8);\n  io->metadata.m.SetAlphaBits(8);\n  io->metadata.m.color_encoding =\n      ColorEncoding::SRGB();  // todo: get data from png metadata\n  (void)io->dec_hints.Foreach(\n      [](const std::string& key, const std::string& /*value*/) {\n        JXL_WARNING(\"APNG decoder ignoring %s hint\", key.c_str());\n        return true;\n      });\n\n  bool errorstate = true;\n  if (id == kId_IHDR && chunkIHDR.size == 25) {\n    w0 = w = png_get_uint_32(chunkIHDR.p + 8);\n    h0 = h = png_get_uint_32(chunkIHDR.p + 12);\n\n    if (w > cMaxPNGSize || h > cMaxPNGSize) {\n      return false;\n    }\n\n    x0 = 0;\n    y0 = 0;\n    delay_num = 1;\n    delay_den = 10;\n    dop = 0;\n    bop = 0;\n    rowbytes = w * 4;\n    imagesize = h * rowbytes;\n\n    frameRaw.p = new unsigned char[imagesize];\n    frameRaw.rows = new png_bytep[h * sizeof(png_bytep)];\n    for (j = 0; j < h; j++) frameRaw.rows[j] = frameRaw.p + j * rowbytes;\n\n    if (!processing_start(png_ptr, info_ptr, (void*)&frameRaw, hasInfo,\n                          chunkIHDR, chunksInfo)) {\n      bool last_base_was_none = true;\n      while (!r.Eof()) {\n        id = read_chunk(&r, &chunk);\n        if (!id) break;\n        JXL_ASSERT(chunk.p != nullptr);\n\n        if (id == kId_acTL && !hasInfo && !isAnimated) {\n          isAnimated = true;\n          skipFirst = true;\n          io->metadata.m.have_animation = true;\n          io->metadata.m.animation.tps_numerator = 1000;\n        } else if (id == kId_IEND ||\n                   (id == kId_fcTL && (!hasInfo || isAnimated))) {\n          if (hasInfo) {\n            if (!processing_finish(png_ptr, info_ptr)) {\n              ImageBundle bundle(&io->metadata.m);\n              bundle.duration = delay_num * 1000 / delay_den;\n              bundle.origin.x0 = x0;\n              bundle.origin.y0 = y0;\n              // TODO(veluca): this could in principle be implemented.\n              if (last_base_was_none && !all_dispose_bg &&\n                  (x0 != 0 || y0 != 0 || w0 != w || h0 != h || bop != 0)) {\n                return JXL_FAILURE(\n                    \"APNG with dispose-to-0 is not supported for non-full or \"\n                    \"blended frames\");\n              }\n              switch (dop) {\n                case 0:\n                  bundle.use_for_next_frame = true;\n                  last_base_was_none = false;\n                  all_dispose_bg = false;\n                  break;\n                case 2:\n                  bundle.use_for_next_frame = false;\n                  all_dispose_bg = false;\n                  break;\n                default:\n                  bundle.use_for_next_frame = false;\n                  last_base_was_none = true;\n              }\n              bundle.blend = bop != 0;\n              io->dec_pixels += w0 * h0;\n\n              Image3F sub_frame(w0, h0);\n              ImageF sub_frame_alpha(w0, h0);\n              for (size_t y = 0; y < h0; ++y) {\n                float* const JXL_RESTRICT row_r = sub_frame.PlaneRow(0, y);\n                float* const JXL_RESTRICT row_g = sub_frame.PlaneRow(1, y);\n                float* const JXL_RESTRICT row_b = sub_frame.PlaneRow(2, y);\n                float* const JXL_RESTRICT row_alpha = sub_frame_alpha.Row(y);\n                uint8_t* const f = frameRaw.rows[y];\n                for (size_t x = 0; x < w0; ++x) {\n                  if (f[4 * x + 3] == 0) {\n                    row_alpha[x] = 0;\n                    row_r[x] = 0;\n                    row_g[x] = 0;\n                    row_b[x] = 0;\n                    continue;\n                  }\n                  row_r[x] = f[4 * x + 0] * (1.f / 255);\n                  row_g[x] = f[4 * x + 1] * (1.f / 255);\n                  row_b[x] = f[4 * x + 2] * (1.f / 255);\n                  row_alpha[x] = f[4 * x + 3] * (1.f / 255);\n                }\n              }\n              bundle.SetFromImage(std::move(sub_frame), ColorEncoding::SRGB());\n              bundle.SetAlpha(std::move(sub_frame_alpha),\n                              /*alpha_is_premultiplied=*/false);\n              io->frames.push_back(std::move(bundle));\n            } else {\n              delete[] chunk.p;\n              break;\n            }\n          }\n\n          if (id == kId_IEND) {\n            errorstate = false;\n            break;\n          }\n          // At this point the old frame is done. Let's start a new one.\n          w0 = png_get_uint_32(chunk.p + 12);\n          h0 = png_get_uint_32(chunk.p + 16);\n          x0 = png_get_uint_32(chunk.p + 20);\n          y0 = png_get_uint_32(chunk.p + 24);\n          delay_num = png_get_uint_16(chunk.p + 28);\n          delay_den = png_get_uint_16(chunk.p + 30);\n          dop = chunk.p[32];\n          bop = chunk.p[33];\n\n          if (w0 > cMaxPNGSize || h0 > cMaxPNGSize || x0 > cMaxPNGSize ||\n              y0 > cMaxPNGSize || x0 + w0 > w || y0 + h0 > h || dop > 2 ||\n              bop > 1) {\n            delete[] chunk.p;\n            break;\n          }\n\n          if (hasInfo) {\n            memcpy(chunkIHDR.p + 8, chunk.p + 12, 8);\n            if (processing_start(png_ptr, info_ptr, (void*)&frameRaw, hasInfo,\n                                 chunkIHDR, chunksInfo)) {\n              delete[] chunk.p;\n              break;\n            }\n          } else\n            skipFirst = false;\n\n          if (io->frames.size() == (skipFirst ? 1 : 0)) {\n            bop = 0;\n            if (dop == 2) dop = 1;\n          }\n        } else if (id == kId_IDAT) {\n          hasInfo = true;\n          if (processing_data(png_ptr, info_ptr, chunk.p, chunk.size)) {\n            delete[] chunk.p;\n            break;\n          }\n        } else if (id == kId_fdAT && isAnimated) {\n          png_save_uint_32(chunk.p + 4, chunk.size - 16);\n          memcpy(chunk.p + 8, \"IDAT\", 4);\n          if (processing_data(png_ptr, info_ptr, chunk.p + 4, chunk.size - 4)) {\n            delete[] chunk.p;\n            break;\n          }\n        } else if (!isAbc(chunk.p[4]) || !isAbc(chunk.p[5]) ||\n                   !isAbc(chunk.p[6]) || !isAbc(chunk.p[7])) {\n          delete[] chunk.p;\n          break;\n        } else if (!hasInfo) {\n          if (processing_data(png_ptr, info_ptr, chunk.p, chunk.size)) {\n            delete[] chunk.p;\n            break;\n          }\n          chunksInfo.push_back(chunk);\n          continue;\n        }\n        delete[] chunk.p;\n      }\n    }\n    delete[] frameRaw.rows;\n    delete[] frameRaw.p;\n  }\n\n  for (i = 0; i < chunksInfo.size(); i++) delete[] chunksInfo[i].p;\n\n  chunksInfo.clear();\n  delete[] chunkIHDR.p;\n\n  if (errorstate) return false;\n  SetIntensityTarget(io);\n  return true;\n}",
        "func_hash": 313851366023244520296960010326993371914,
        "file_name": "codec_apng.cc",
        "file_hash": 303923165706235443177070807550807665571,
        "cwe": [
            "CWE-369"
        ],
        "cve": "CVE-2021-36692",
        "cve_desc": "libjxl v0.3.7 is affected by a Divide By Zero in issue in lib/extras/codec_apng.cc jxl::DecodeImageAPNG(). When encoding a malicous APNG file using cjxl, an attacker can trigger a denial of service.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-36692",
        "func_name": "DecodeImageAPNG",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 197015,
        "project": "gpac",
        "commit_id": "dae9900580a8888969481cd72035408091edb11b",
        "project_url": "https://github.com/gpac/gpac",
        "commit_url": "https://github.com/gpac/gpac/commit/dae9900580a8888969481cd72035408091edb11b",
        "commit_message": "fixed #1659",
        "target": 1,
        "irrelevant": 1,
        "func_before": "GF_Err SetupWriters(MovieWriter *mw, GF_List *writers, u8 interleaving)\n{\n\tu32 i, trackCount;\n\tTrackWriter *writer;\n\tGF_TrackBox *trak;\n\tGF_ISOFile *movie = mw->movie;\n\n\tmw->total_samples = mw->nb_done = 0;\n\tif (!movie->moov) return GF_OK;\n\n\ttrackCount = gf_list_count(movie->moov->trackList);\n\tfor (i = 0; i < trackCount; i++) {\n\t\ttrak = gf_isom_get_track(movie->moov, i+1);\n\n\t\tGF_SAFEALLOC(writer, TrackWriter);\n\t\tif (!writer) goto exit;\n\t\twriter->sampleNumber = 1;\n\t\twriter->mdia = trak->Media;\n\t\twriter->stbl = trak->Media->information->sampleTable;\n\t\twriter->timeScale = trak->Media->mediaHeader->timeScale;\n\t\twriter->all_dref_mode = Media_SelfContainedType(writer->mdia);\n\n\t\tif (trak->sample_encryption)\n\t\t\twriter->prevent_dispatch = GF_TRUE;\n\n\t\twriter->isDone = 0;\n\t\twriter->DTSprev = 0;\n\t\twriter->chunkDur = 0;\n\t\twriter->chunkSize = 0;\n\t\twriter->constant_size = writer->constant_dur = 0;\n\t\tif (writer->stbl->SampleSize->sampleSize)\n\t\t\twriter->constant_size = writer->stbl->SampleSize->sampleSize;\n\t\tif (writer->stbl->TimeToSample->nb_entries==1) {\n\t\t\twriter->constant_dur = writer->stbl->TimeToSample->entries[0].sampleDelta;\n\t\t\tif (writer->constant_dur>1) writer->constant_dur = 0;\n\t\t}\n\t\tif (!writer->constant_dur || !writer->constant_size || (writer->constant_size>=10))\n\t\t\twriter->constant_size = writer->constant_dur = 0;\n\n\t\twriter->stsc = (GF_SampleToChunkBox *) gf_isom_box_new(GF_ISOM_BOX_TYPE_STSC);\n\t\tif (!writer->stsc) return GF_OUT_OF_MEM;\n\t\tif (writer->stbl->ChunkOffset->type == GF_ISOM_BOX_TYPE_STCO) {\n\t\t\twriter->stco = gf_isom_box_new(GF_ISOM_BOX_TYPE_STCO);\n\t\t} else {\n\t\t\twriter->stco = gf_isom_box_new(GF_ISOM_BOX_TYPE_CO64);\n\t\t}\n\t\tif (!writer->stco) return GF_OUT_OF_MEM;\n\t\t/*stops from chunk escape*/\n\t\tif (interleaving) writer->stbl->MaxSamplePerChunk = 0;\n\t\t/*for progress, assume only one descIndex*/\n\t\tif (Media_IsSelfContained(writer->mdia, 1))\n\t\t\tmw->total_samples += writer->stbl->SampleSize->sampleCount;\n\t\t/*optimization for interleaving: put audio last (this can be overridden by priorities)*/\n\t\tif (movie->storageMode != GF_ISOM_STORE_INTERLEAVED) {\n\t\t\tgf_list_add(writers, writer);\n\t\t} else {\n\t\t\tif (writer->mdia->information->InfoHeader && writer->mdia->information->InfoHeader->type == GF_ISOM_BOX_TYPE_SMHD) {\n\t\t\t\tgf_list_add(writers, writer);\n\t\t\t} else {\n\t\t\t\tgf_list_insert(writers, writer, 0);\n\t\t\t}\n\t\t}\n\t\tif (movie->sample_groups_in_traf && trak->Media->information->sampleTable) {\n\t\t\tgf_isom_box_array_del_parent(&trak->Media->information->sampleTable->child_boxes, trak->Media->information->sampleTable->sampleGroupsDescription);\n\t\t\ttrak->Media->information->sampleTable->sampleGroupsDescription = NULL;\n\t\t}\n\t}\n\treturn GF_OK;\n\nexit:\n\tCleanWriters(writers);\n\treturn GF_OUT_OF_MEM;\n}",
        "func_hash": 186223260006462489135452631752417424978,
        "file_name": "isom_store.c",
        "file_hash": 163429096111764821481093789064862178187,
        "cwe": [
            "CWE-476"
        ],
        "cve": "CVE-2020-35981",
        "cve_desc": "An issue was discovered in GPAC version 0.8.0 and 1.0.1. There is an invalid pointer dereference in the function SetupWriters() in isomedia/isom_store.c.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2020-35981",
        "func_name": "SetupWriters",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 197024,
        "project": "tensorflow",
        "commit_id": "93f428fd1768df147171ed674fee1fc5ab8309ec",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/93f428fd1768df147171ed674fee1fc5ab8309ec",
        "commit_message": "Fix nullptr deref and heap OOB access in binary cwise ops.\n\nPiperOrigin-RevId: 387936777\nChange-Id: I608b8074cec36a982cca622b7144cb2c43e6e19f",
        "target": 1,
        "irrelevant": 1,
        "func_before": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor& in0 = ctx->input(0);\n    const Tensor& in1 = ctx->input(1);\n    auto in0_flat = in0.flat<Tin>();\n    auto in1_flat = in1.flat<Tin>();\n    const Device& eigen_device = ctx->eigen_device<Device>();\n\n    Tensor* out = nullptr;\n    if (std::is_same<Tin, Tout>::value) {\n      OP_REQUIRES_OK(ctx, ctx->forward_input_or_allocate_output(\n                              {0, 1}, 0, in0.shape(), &out));\n    } else {\n      OP_REQUIRES_OK(ctx, ctx->allocate_output(0, in0.shape(), &out));\n    }\n    auto out_flat = out->flat<Tout>();\n    functor::SimpleBinaryFunctor<Device, Functor>()(eigen_device, out_flat,\n                                                    in0_flat, in1_flat);\n  }",
        "func_hash": 84336962255031391560456997711771904797,
        "file_name": "cwise_ops_common.h",
        "file_hash": 158457487648144003832850895201682084763,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2021-37659",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions an attacker can cause undefined behavior via binding a reference to null pointer in all binary cwise operations that don't require broadcasting (e.g., gradients of binary cwise operations). The [implementation](https://github.com/tensorflow/tensorflow/blob/84d053187cb80d975ef2b9684d4b61981bca0c41/tensorflow/core/kernels/cwise_ops_common.h#L264) assumes that the two inputs have exactly the same number of elements but does not check that. Hence, when the eigen functor executes it triggers heap OOB reads and undefined behavior due to binding to nullptr. We have patched the issue in GitHub commit 93f428fd1768df147171ed674fee1fc5ab8309ec. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37659",
        "func_name": "Compute",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 197057,
        "project": "drogon",
        "commit_id": "3c785326c63a34aa1799a639ae185bc9453cb447",
        "project_url": "https://github.com/drogonframework/drogon",
        "commit_url": "https://github.com/drogonframework/drogon/commit/3c785326c63a34aa1799a639ae185bc9453cb447",
        "commit_message": "Prevent malformed upload path causing arbitrary write (#1174)",
        "target": 1,
        "irrelevant": 0,
        "func_before": "int HttpFileImpl::save(const std::string &path) const\n{\n    assert(!path.empty());\n    if (fileName_.empty())\n        return -1;\n    filesystem::path fsPath(utils::toNativePath(path));\n    if (!fsPath.is_absolute() &&\n        (!fsPath.has_parent_path() ||\n         (fsPath.begin()->string() != \".\" && fsPath.begin()->string() != \"..\")))\n    {\n        filesystem::path fsUploadPath(utils::toNativePath(\n            HttpAppFrameworkImpl::instance().getUploadPath()));\n        fsPath = fsUploadPath / fsPath;\n    }\n    filesystem::path fsFileName(utils::toNativePath(fileName_));\n    if (!filesystem::exists(fsPath))\n    {\n        LOG_TRACE << \"create path:\" << fsPath;\n        drogon::error_code err;\n        filesystem::create_directories(fsPath, err);\n        if (err)\n        {\n            LOG_SYSERR;\n            return -1;\n        }\n    }\n    return saveTo(fsPath / fsFileName);\n}",
        "func_hash": 314463188138781431986696466899338798829,
        "file_name": "HttpFileImpl.cc",
        "file_hash": null,
        "cwe": [
            "CWE-552"
        ],
        "cve": "CVE-2022-25297",
        "cve_desc": "This affects the package drogonframework/drogon before 1.7.5. The unsafe handling of file names during upload using HttpFile::save() method may enable attackers to write files to arbitrary locations outside the designated target folder.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-25297",
        "func_name": "HttpFileImpl::save",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 197095,
        "project": "tensorflow",
        "commit_id": "15691e456c7dc9bd6be203b09765b063bf4a380c",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/15691e456c7dc9bd6be203b09765b063bf4a380c",
        "commit_message": "Prevent dereferencing of null pointers in TFLite's `add.cc`.\n\nPiperOrigin-RevId: 387244946\nChange-Id: I56094233327fbd8439b92e1dbb1262176e00eeb9",
        "target": 1,
        "irrelevant": 1,
        "func_before": "inline void BinaryBroadcastFiveFold(const ArithmeticParams& unswitched_params,\n                                    const RuntimeShape& unswitched_input1_shape,\n                                    const T* unswitched_input1_data,\n                                    const RuntimeShape& unswitched_input2_shape,\n                                    const T* unswitched_input2_data,\n                                    const RuntimeShape& output_shape,\n                                    T* output_data, ElementwiseF elementwise_f,\n                                    ScalarBroadcastF scalar_broadcast_f) {\n  ArithmeticParams switched_params = unswitched_params;\n  switched_params.input1_offset = unswitched_params.input2_offset;\n  switched_params.input1_multiplier = unswitched_params.input2_multiplier;\n  switched_params.input1_shift = unswitched_params.input2_shift;\n  switched_params.input2_offset = unswitched_params.input1_offset;\n  switched_params.input2_multiplier = unswitched_params.input1_multiplier;\n  switched_params.input2_shift = unswitched_params.input1_shift;\n\n  const bool use_unswitched =\n      unswitched_params.broadcast_category ==\n      tflite::BroadcastableOpCategory::kFirstInputBroadcastsFast;\n\n  const ArithmeticParams& params =\n      use_unswitched ? unswitched_params : switched_params;\n  const T* input1_data =\n      use_unswitched ? unswitched_input1_data : unswitched_input2_data;\n  const T* input2_data =\n      use_unswitched ? unswitched_input2_data : unswitched_input1_data;\n\n  // Fivefold nested loops. The second input resets its position for each\n  // iteration of the second loop. The first input resets its position at the\n  // beginning of the fourth loop. The innermost loop is an elementwise add of\n  // sections of the arrays.\n  T* output_data_ptr = output_data;\n  const T* input1_data_ptr = input1_data;\n  const T* input2_data_reset = input2_data;\n  // In the fivefold pattern, y0, y2 and y4 are not broadcast, and so shared\n  // between input shapes. y3 for input 1 is always broadcast, and so the\n  // dimension there is 1, whereas optionally y1 might be broadcast for\n  // input 2. Put another way, input1.shape.FlatSize = y0 * y1 * y2 * y4,\n  // input2.shape.FlatSize = y0 * y2 * y3 * y4.\n  int y0 = params.broadcast_shape[0];\n  int y1 = params.broadcast_shape[1];\n  int y2 = params.broadcast_shape[2];\n  int y3 = params.broadcast_shape[3];\n  int y4 = params.broadcast_shape[4];\n  if (y4 > 1) {\n    // General fivefold pattern, with y4 > 1 so there is a non-broadcast inner\n    // dimension.\n    for (int i0 = 0; i0 < y0; ++i0) {\n      const T* input2_data_ptr = nullptr;\n      for (int i1 = 0; i1 < y1; ++i1) {\n        input2_data_ptr = input2_data_reset;\n        for (int i2 = 0; i2 < y2; ++i2) {\n          for (int i3 = 0; i3 < y3; ++i3) {\n            elementwise_f(y4, params, input1_data_ptr, input2_data_ptr,\n                          output_data_ptr);\n            input2_data_ptr += y4;\n            output_data_ptr += y4;\n          }\n          // We have broadcast y4 of input1 data y3 times, and now move on.\n          input1_data_ptr += y4;\n        }\n      }\n      // We have broadcast y2*y3*y4 of input2 data y1 times, and now move on.\n      input2_data_reset = input2_data_ptr;\n    }\n  } else {\n    // Special case of y4 == 1, in which the innermost loop is a single\n    // element and can be combined with the next (y3) as an inner broadcast.\n    //\n    // Note that this handles the case of pure scalar broadcast when\n    // y0 == y1 == y2 == 1. With low overhead it handles cases such as scalar\n    // broadcast with batch (as y2 > 1).\n    //\n    // NOTE The process is the same as the above general case except\n    // simplified for y4 == 1 and the loop over y3 is contained within the\n    // AddScalarBroadcast function.\n    for (int i0 = 0; i0 < y0; ++i0) {\n      const T* input2_data_ptr = nullptr;\n      for (int i1 = 0; i1 < y1; ++i1) {\n        input2_data_ptr = input2_data_reset;\n        for (int i2 = 0; i2 < y2; ++i2) {\n          scalar_broadcast_f(y3, params, *input1_data_ptr, input2_data_ptr,\n                             output_data_ptr);\n          input2_data_ptr += y3;\n          output_data_ptr += y3;\n          input1_data_ptr += 1;\n        }\n      }\n      input2_data_reset = input2_data_ptr;\n    }\n  }\n}",
        "func_hash": 189506316609912057332068378278926028013,
        "file_name": "optimized_ops.h",
        "file_hash": 272937509923686290195986142976705267114,
        "cwe": [
            "CWE-369"
        ],
        "cve": "CVE-2021-37688",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions an attacker can craft a TFLite model that would trigger a null pointer dereference, which would result in a crash and denial of service. The [implementation](https://github.com/tensorflow/tensorflow/blob/149562d49faa709ea80df1d99fc41d005b81082a/tensorflow/lite/kernels/internal/optimized/optimized_ops.h#L268-L285) unconditionally dereferences a pointer. We have patched the issue in GitHub commit 15691e456c7dc9bd6be203b09765b063bf4a380c. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37688",
        "func_name": "BinaryBroadcastFiveFold",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 197110,
        "project": "tensorflow",
        "commit_id": "bc9c546ce7015c57c2f15c168b3d9201de679a1d",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/bc9c546ce7015c57c2f15c168b3d9201de679a1d",
        "commit_message": "Prevent heap oob access in `resource_variable_ops.cc`\n\nPiperOrigin-RevId: 387936433\nChange-Id: I9e71ddaa8dbd51ec6afbf163a6b3b591f193b4f6",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext* c) override {\n    core::RefCountPtr<Var> v;\n    OP_REQUIRES_OK(c, LookupResource(c, HandleFromInput(c, 0), &v));\n    OP_REQUIRES_OK(c, EnsureSparseVariableAccess<Device, T>(c, v.get()));\n    // NOTE: We hold the lock for the whole gather operation instead\n    // of increasing the reference count of v->tensor() to avoid a\n    // situation where a write to the same variable will see a\n    // reference count greater than one and make a copy of the\n    // (potentially very large) tensor buffer.\n    tf_shared_lock ml(*v->mu());\n    const Tensor& params = *v->tensor();\n    const Tensor& indices = c->input(1);\n    OP_REQUIRES(\n        c, TensorShapeUtils::IsVectorOrHigher(params.shape()),\n        errors::InvalidArgument(\"params must be at least 1 dimensional\"));\n\n    // Check that we have enough index space\n    const int64_t N = indices.NumElements();\n    OP_REQUIRES(\n        c, params.dim_size(0) <= std::numeric_limits<Index>::max(),\n        errors::InvalidArgument(\"params.shape[0] too large for \",\n                                DataTypeString(DataTypeToEnum<Index>::v()),\n                                \" indexing: \", params.dim_size(0), \" > \",\n                                std::numeric_limits<Index>::max()));\n\n    // The result shape is params.shape[:batch_dims] +\n    // indices.shape[batch_dims:] + params.shape[batch_dims+1:].\n    TensorShape result_shape;\n    for (int i = 0; i < batch_dims_; ++i) {\n      result_shape.AddDim(params.dim_size(i));\n    }\n    for (int i = batch_dims_; i < indices.dims(); ++i) {\n      result_shape.AddDim(indices.dim_size(i));\n    }\n    for (int i = batch_dims_ + 1; i < params.dims(); ++i) {\n      result_shape.AddDim(params.dim_size(i));\n    }\n\n    Tensor* out = nullptr;\n    Tensor tmp;\n    if (params.dtype() == DT_VARIANT) {\n      tmp = Tensor(DT_VARIANT, result_shape);\n      c->set_output(0, tmp);\n      out = &tmp;\n    } else {\n      OP_REQUIRES_OK(c, c->allocate_output(0, result_shape, &out));\n    }\n\n    if (N > 0) {\n      Tensor tmp_indices;\n\n      // Points to the original or updated (if batch_dims is set) indices.\n      const Tensor* op_indices = &indices;\n      if (batch_dims_ > 0) {\n        OP_REQUIRES_OK(c, c->allocate_temp(indices.dtype(), indices.shape(),\n                                           &tmp_indices));\n        functor::DenseUpdate<Device, Index, ASSIGN> copy_functor;\n        copy_functor(c->eigen_device<Device>(), tmp_indices.flat<Index>(),\n                     indices.flat<Index>());\n\n        AddBatchOffsets(&tmp_indices, params);\n        op_indices = &tmp_indices;\n      }\n\n      int64_t gather_dim_size = 1;\n      for (int idx = 0; idx <= batch_dims_; ++idx) {\n        gather_dim_size *= params.dim_size(idx);\n      }\n      int64_t inner_size = 1;\n      for (int i = batch_dims_ + 1; i < params.dims(); ++i) {\n        inner_size *= params.dim_size(i);\n      }\n      auto params_flat = params.shaped<T, 3>({1, gather_dim_size, inner_size});\n      const auto indices_flat = op_indices->flat<Index>();\n      auto out_flat = out->shaped<T, 3>({1, N, out->NumElements() / N});\n\n      functor::GatherFunctor<Device, T, Index> functor;\n      int64_t bad_i = functor(c, params_flat, indices_flat, out_flat);\n\n      OP_REQUIRES(\n          c, bad_i < 0,\n          errors::InvalidArgument(\n              \"indices\", SliceDebugString(indices.shape(), bad_i), \" = \",\n              indices_flat(bad_i), \" is not in [0, \", params.dim_size(0), \")\"));\n    }\n  }",
        "func_hash": 175944317482821883294168342214722979534,
        "file_name": "resource_variable_ops.cc",
        "file_hash": 82185528001770551132319474008789135292,
        "cwe": [
            "CWE-369"
        ],
        "cve": "CVE-2021-37654",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions an attacker can trigger a crash via a `CHECK`-fail in debug builds of TensorFlow using `tf.raw_ops.ResourceGather` or a read from outside the bounds of heap allocated data in the same API in a release build. The [implementation](https://github.com/tensorflow/tensorflow/blob/f24faa153ad31a4b51578f8181d3aaab77a1ddeb/tensorflow/core/kernels/resource_variable_ops.cc#L660-L668) does not check that the `batch_dims` value that the user supplies is less than the rank of the input tensor. Since the implementation uses several for loops over the dimensions of `tensor`, this results in reading data from outside the bounds of heap allocated buffer backing the tensor. We have patched the issue in GitHub commit bc9c546ce7015c57c2f15c168b3d9201de679a1d. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37654",
        "func_name": "Compute",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 197111,
        "project": "tinyexr",
        "commit_id": "a685e3332f61cd4e59324bf3f669d36973d64270",
        "project_url": "https://github.com/syoyo/tinyexr",
        "commit_url": "https://github.com/syoyo/tinyexr/commit/a685e3332f61cd4e59324bf3f669d36973d64270",
        "commit_message": "Make line_no with too large value(2**20) invalid. Fixes #124",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static int DecodeChunk(EXRImage *exr_image, const EXRHeader *exr_header,\n                       const std::vector<tinyexr::tinyexr_uint64> &offsets,\n                       const unsigned char *head, const size_t size,\n                       std::string *err) {\n  int num_channels = exr_header->num_channels;\n\n  int num_scanline_blocks = 1;\n  if (exr_header->compression_type == TINYEXR_COMPRESSIONTYPE_ZIP) {\n    num_scanline_blocks = 16;\n  } else if (exr_header->compression_type == TINYEXR_COMPRESSIONTYPE_PIZ) {\n    num_scanline_blocks = 32;\n  } else if (exr_header->compression_type == TINYEXR_COMPRESSIONTYPE_ZFP) {\n    num_scanline_blocks = 16;\n  }\n\n  int data_width = exr_header->data_window[2] - exr_header->data_window[0] + 1;\n  int data_height = exr_header->data_window[3] - exr_header->data_window[1] + 1;\n\n  if ((data_width < 0) || (data_height < 0)) {\n    if (err) {\n      std::stringstream ss;\n      ss << \"Invalid data width or data height: \" << data_width << \", \"\n         << data_height << std::endl;\n      (*err) += ss.str();\n    }\n    return TINYEXR_ERROR_INVALID_DATA;\n  }\n\n  // Do not allow too large data_width and data_height. header invalid?\n  {\n    const int threshold = 1024 * 8192;  // heuristics\n    if ((data_width > threshold) || (data_height > threshold)) {\n      if (err) {\n        std::stringstream ss;\n        ss << \"data_with or data_height too large. data_width: \" << data_width\n           << \", \"\n           << \"data_height = \" << data_height << std::endl;\n        (*err) += ss.str();\n      }\n      return TINYEXR_ERROR_INVALID_DATA;\n    }\n  }\n\n  size_t num_blocks = offsets.size();\n\n  std::vector<size_t> channel_offset_list;\n  int pixel_data_size = 0;\n  size_t channel_offset = 0;\n  if (!tinyexr::ComputeChannelLayout(&channel_offset_list, &pixel_data_size,\n                                     &channel_offset, num_channels,\n                                     exr_header->channels)) {\n    if (err) {\n      (*err) += \"Failed to compute channel layout.\\n\";\n    }\n    return TINYEXR_ERROR_INVALID_DATA;\n  }\n\n  bool invalid_data = false;  // TODO(LTE): Use atomic lock for MT safety.\n\n  if (exr_header->tiled) {\n    // value check\n    if (exr_header->tile_size_x < 0) {\n      if (err) {\n        std::stringstream ss;\n        ss << \"Invalid tile size x : \" << exr_header->tile_size_x << \"\\n\";\n        (*err) += ss.str();\n      }\n      return TINYEXR_ERROR_INVALID_HEADER;\n    }\n\n    if (exr_header->tile_size_y < 0) {\n      if (err) {\n        std::stringstream ss;\n        ss << \"Invalid tile size y : \" << exr_header->tile_size_y << \"\\n\";\n        (*err) += ss.str();\n      }\n      return TINYEXR_ERROR_INVALID_HEADER;\n    }\n\n    size_t num_tiles = offsets.size();  // = # of blocks\n\n    exr_image->tiles = static_cast<EXRTile *>(\n        calloc(sizeof(EXRTile), static_cast<size_t>(num_tiles)));\n\n    for (size_t tile_idx = 0; tile_idx < num_tiles; tile_idx++) {\n      // Allocate memory for each tile.\n      exr_image->tiles[tile_idx].images = tinyexr::AllocateImage(\n          num_channels, exr_header->channels, exr_header->requested_pixel_types,\n          exr_header->tile_size_x, exr_header->tile_size_y);\n\n      // 16 byte: tile coordinates\n      // 4 byte : data size\n      // ~      : data(uncompressed or compressed)\n      if (offsets[tile_idx] + sizeof(int) * 5 > size) {\n        if (err) {\n          (*err) += \"Insufficient data size.\\n\";\n        }\n        return TINYEXR_ERROR_INVALID_DATA;\n      }\n\n      size_t data_size = size_t(size - (offsets[tile_idx] + sizeof(int) * 5));\n      const unsigned char *data_ptr =\n          reinterpret_cast<const unsigned char *>(head + offsets[tile_idx]);\n\n      int tile_coordinates[4];\n      memcpy(tile_coordinates, data_ptr, sizeof(int) * 4);\n      tinyexr::swap4(reinterpret_cast<unsigned int *>(&tile_coordinates[0]));\n      tinyexr::swap4(reinterpret_cast<unsigned int *>(&tile_coordinates[1]));\n      tinyexr::swap4(reinterpret_cast<unsigned int *>(&tile_coordinates[2]));\n      tinyexr::swap4(reinterpret_cast<unsigned int *>(&tile_coordinates[3]));\n\n      // @todo{ LoD }\n      if (tile_coordinates[2] != 0) {\n        return TINYEXR_ERROR_UNSUPPORTED_FEATURE;\n      }\n      if (tile_coordinates[3] != 0) {\n        return TINYEXR_ERROR_UNSUPPORTED_FEATURE;\n      }\n\n      int data_len;\n      memcpy(&data_len, data_ptr + 16,\n             sizeof(int));  // 16 = sizeof(tile_coordinates)\n      tinyexr::swap4(reinterpret_cast<unsigned int *>(&data_len));\n\n      if (data_len < 4 || size_t(data_len) > data_size) {\n        if (err) {\n          (*err) += \"Insufficient data length.\\n\";\n        }\n        return TINYEXR_ERROR_INVALID_DATA;\n      }\n\n      // Move to data addr: 20 = 16 + 4;\n      data_ptr += 20;\n\n      tinyexr::DecodeTiledPixelData(\n          exr_image->tiles[tile_idx].images,\n          &(exr_image->tiles[tile_idx].width),\n          &(exr_image->tiles[tile_idx].height),\n          exr_header->requested_pixel_types, data_ptr,\n          static_cast<size_t>(data_len), exr_header->compression_type,\n          exr_header->line_order, data_width, data_height, tile_coordinates[0],\n          tile_coordinates[1], exr_header->tile_size_x, exr_header->tile_size_y,\n          static_cast<size_t>(pixel_data_size),\n          static_cast<size_t>(exr_header->num_custom_attributes),\n          exr_header->custom_attributes,\n          static_cast<size_t>(exr_header->num_channels), exr_header->channels,\n          channel_offset_list);\n\n      exr_image->tiles[tile_idx].offset_x = tile_coordinates[0];\n      exr_image->tiles[tile_idx].offset_y = tile_coordinates[1];\n      exr_image->tiles[tile_idx].level_x = tile_coordinates[2];\n      exr_image->tiles[tile_idx].level_y = tile_coordinates[3];\n\n      exr_image->num_tiles = static_cast<int>(num_tiles);\n    }\n  } else {  // scanline format\n\n    // Don't allow too large image(256GB * pixel_data_size or more). Workaround\n    // for #104.\n    size_t total_data_len =\n        size_t(data_width) * size_t(data_height) * size_t(num_channels);\n    const bool total_data_len_overflown = sizeof(void*) == 8 ? (total_data_len >= 0x4000000000) : false;\n    if ((total_data_len == 0) || total_data_len_overflown ) {\n      if (err) {\n        std::stringstream ss;\n        ss << \"Image data size is zero or too large: width = \" << data_width\n           << \", height = \" << data_height << \", channels = \" << num_channels\n           << std::endl;\n        (*err) += ss.str();\n      }\n      return TINYEXR_ERROR_INVALID_DATA;\n    }\n\n    exr_image->images = tinyexr::AllocateImage(\n        num_channels, exr_header->channels, exr_header->requested_pixel_types,\n        data_width, data_height);\n\n#ifdef _OPENMP\n#pragma omp parallel for\n#endif\n    for (int y = 0; y < static_cast<int>(num_blocks); y++) {\n      size_t y_idx = static_cast<size_t>(y);\n\n      if (offsets[y_idx] + sizeof(int) * 2 > size) {\n        invalid_data = true;\n      } else {\n        // 4 byte: scan line\n        // 4 byte: data size\n        // ~     : pixel data(uncompressed or compressed)\n        size_t data_size = size_t(size - (offsets[y_idx] + sizeof(int) * 2));\n        const unsigned char *data_ptr =\n            reinterpret_cast<const unsigned char *>(head + offsets[y_idx]);\n\n        int line_no;\n        memcpy(&line_no, data_ptr, sizeof(int));\n        int data_len;\n        memcpy(&data_len, data_ptr + 4, sizeof(int));\n        tinyexr::swap4(reinterpret_cast<unsigned int *>(&line_no));\n        tinyexr::swap4(reinterpret_cast<unsigned int *>(&data_len));\n\n        if (size_t(data_len) > data_size) {\n          invalid_data = true;\n        } else if (data_len == 0) {\n          // TODO(syoyo): May be ok to raise the threshold for example `data_len\n          // < 4`\n          invalid_data = true;\n        } else {\n          // line_no may be negative.\n          int end_line_no = (std::min)(line_no + num_scanline_blocks,\n                                       (exr_header->data_window[3] + 1));\n\n          int num_lines = end_line_no - line_no;\n\n          if (num_lines <= 0) {\n            invalid_data = true;\n          } else {\n            // Move to data addr: 8 = 4 + 4;\n            data_ptr += 8;\n\n            // Adjust line_no with data_window.bmin.y\n\n            // overflow check\n            tinyexr_int64 lno = static_cast<tinyexr_int64>(line_no) - static_cast<tinyexr_int64>(exr_header->data_window[1]);\n            if (lno > std::numeric_limits<int>::max()) {\n              line_no = -1; // invalid\n            } else if (lno < -std::numeric_limits<int>::max()) {\n              line_no = -1; // invalid\n            } else {\n              line_no -= exr_header->data_window[1];\n            }\n\n            if (line_no < 0) {\n              invalid_data = true;\n            } else {\n              if (!tinyexr::DecodePixelData(\n                      exr_image->images, exr_header->requested_pixel_types,\n                      data_ptr, static_cast<size_t>(data_len),\n                      exr_header->compression_type, exr_header->line_order,\n                      data_width, data_height, data_width, y, line_no,\n                      num_lines, static_cast<size_t>(pixel_data_size),\n                      static_cast<size_t>(exr_header->num_custom_attributes),\n                      exr_header->custom_attributes,\n                      static_cast<size_t>(exr_header->num_channels),\n                      exr_header->channels, channel_offset_list)) {\n                invalid_data = true;\n              }\n            }\n          }\n        }\n      }\n    }  // omp parallel\n  }\n\n  if (invalid_data) {\n    if (err) {\n      std::stringstream ss;\n      (*err) += \"Invalid data found when decoding pixels.\\n\";\n    }\n    return TINYEXR_ERROR_INVALID_DATA;\n  }\n\n  // Overwrite `pixel_type` with `requested_pixel_type`.\n  {\n    for (int c = 0; c < exr_header->num_channels; c++) {\n      exr_header->pixel_types[c] = exr_header->requested_pixel_types[c];\n    }\n  }\n\n  {\n    exr_image->num_channels = num_channels;\n\n    exr_image->width = data_width;\n    exr_image->height = data_height;\n  }\n\n  return TINYEXR_SUCCESS;\n}",
        "func_hash": 204576660378471471312302041175468111939,
        "file_name": "tinyexr.h",
        "file_hash": 28581937103314011160798682220091501322,
        "cwe": [
            "CWE-20"
        ],
        "cve": "CVE-2020-19490",
        "cve_desc": "tinyexr 0.9.5 has a integer overflow over-write in tinyexr::DecodePixelData in tinyexr.h, related to OpenEXR code.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2020-19490",
        "func_name": "DecodeChunk",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 197128,
        "project": "mruby",
        "commit_id": "f72315575f78a9a773adbce0ee7d3ec33434cb76",
        "project_url": "https://github.com/mruby/mruby",
        "commit_url": "https://github.com/mruby/mruby/commit/f72315575f78a9a773adbce0ee7d3ec33434cb76",
        "commit_message": "codegen.c: fix a argument generation bug in array assignment.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "gen_assignment(codegen_scope *s, node *tree, node *rhs, int sp, int val)\n{\n  int idx;\n  int type = nint(tree->car);\n\n  switch (type) {\n  case NODE_GVAR:\n  case NODE_ARG:\n  case NODE_LVAR:\n  case NODE_IVAR:\n  case NODE_CVAR:\n  case NODE_CONST:\n  case NODE_NIL:\n  case NODE_MASGN:\n    if (rhs) {\n      codegen(s, rhs, VAL);\n      pop();\n      sp = cursp();\n    }\n    break;\n\n  case NODE_COLON2:\n  case NODE_CALL:\n  case NODE_SCALL:\n    /* keep evaluation order */\n    break;\n\n  case NODE_NVAR:\n    codegen_error(s, \"Can't assign to numbered parameter\");\n    break;\n\n  default:\n    codegen_error(s, \"unknown lhs\");\n    break;\n  }\n\n  tree = tree->cdr;\n  switch (type) {\n  case NODE_GVAR:\n    gen_setxv(s, OP_SETGV, sp, nsym(tree), val);\n    break;\n  case NODE_ARG:\n  case NODE_LVAR:\n    idx = lv_idx(s, nsym(tree));\n    if (idx > 0) {\n      if (idx != sp) {\n        gen_move(s, idx, sp, val);\n      }\n      break;\n    }\n    else {                      /* upvar */\n      gen_setupvar(s, sp, nsym(tree));\n    }\n    break;\n  case NODE_IVAR:\n    gen_setxv(s, OP_SETIV, sp, nsym(tree), val);\n    break;\n  case NODE_CVAR:\n    gen_setxv(s, OP_SETCV, sp, nsym(tree), val);\n    break;\n  case NODE_CONST:\n    gen_setxv(s, OP_SETCONST, sp, nsym(tree), val);\n    break;\n  case NODE_COLON2:\n    if (sp) {\n      gen_move(s, cursp(), sp, 0);\n    }\n    sp = cursp();\n    push();\n    codegen(s, tree->car, VAL);\n    if (rhs) {\n      codegen(s, rhs, VAL); pop();\n      gen_move(s, sp, cursp(), 0);\n    }\n    pop_n(2);\n    idx = new_sym(s, nsym(tree->cdr));\n    genop_2(s, OP_SETMCNST, sp, idx);\n    break;\n\n  case NODE_CALL:\n  case NODE_SCALL:\n    {\n      int noself = 0, safe = (type == NODE_SCALL), skip = 0, top, call, n = 0;\n      mrb_sym mid = nsym(tree->cdr->car);\n\n      top = cursp();\n      if (val || sp == cursp()) {\n        push();                   /* room for retval */\n      }\n      call = cursp();\n      if (!tree->car) {\n        noself = 1;\n        push();\n      }\n      else {\n        codegen(s, tree->car, VAL); /* receiver */\n      }\n      if (safe) {\n        int recv = cursp()-1;\n        gen_move(s, cursp(), recv, 1);\n        skip = genjmp2_0(s, OP_JMPNIL, cursp(), val);\n      }\n      tree = tree->cdr->cdr->car;\n      if (tree) {\n        if (tree->car) {            /* positional arguments */\n          n = gen_values(s, tree->car, VAL, (tree->cdr->car)?13:14);\n          if (n < 0) {              /* variable length */\n            n = 15;\n            push();\n          }\n        }\n        if (tree->cdr->car) {       /* keyword arguments */\n          if (n == 14) {\n            pop_n(n);\n            genop_2(s, OP_ARRAY, cursp(), n);\n            push();\n            n = 15;\n          }\n          gen_hash(s, tree->cdr->car->cdr, VAL, 0);\n          if (n < 14) {\n            n++;\n          }\n          else {\n            pop_n(2);\n            genop_2(s, OP_ARYPUSH, cursp(), 1);\n          }\n          push();\n        }\n      }\n      if (rhs) {\n        codegen(s, rhs, VAL);\n        pop();\n      }\n      else {\n        gen_move(s, cursp(), sp, 0);\n      }\n      if (val) {\n        gen_move(s, top, cursp(), 1);\n      }\n      if (n < 14) {\n        n++;\n      }\n      else {\n        pop();\n        genop_2(s, OP_ARYPUSH, cursp(), 1);\n      }\n      s->sp = call;\n      if (mid == MRB_OPSYM_2(s->mrb, aref) && n == 2) {\n        genop_1(s, OP_SETIDX, cursp());\n      }\n      else {\n        genop_3(s, noself ? OP_SSEND : OP_SEND, cursp(), new_sym(s, attrsym(s, mid)), n);\n      }\n      if (safe) {\n        dispatch(s, skip);\n      }\n      s->sp = top;\n    }\n    break;\n\n  case NODE_MASGN:\n    gen_vmassignment(s, tree->car, sp, val);\n    break;\n\n  /* splat without assignment */\n  case NODE_NIL:\n    break;\n\n  default:\n    codegen_error(s, \"unknown lhs\");\n    break;\n  }\n  if (val) push();\n}",
        "func_hash": 236078569306136776334536654321578023921,
        "file_name": "codegen.c",
        "file_hash": 69656694646846748382204460208931803734,
        "cwe": [
            "CWE-125"
        ],
        "cve": "CVE-2022-0717",
        "cve_desc": "Out-of-bounds Read in GitHub repository mruby/mruby prior to 3.2.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-0717",
        "func_name": "gen_assignment",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 197135,
        "project": "linux",
        "commit_id": "505d9dcb0f7ddf9d075e729523a33d38642ae680",
        "project_url": "https://github.com/torvalds/linux",
        "commit_url": "https://github.com/torvalds/linux/commit/505d9dcb0f7ddf9d075e729523a33d38642ae680",
        "commit_message": "crypto: ccp - fix resource leaks in ccp_run_aes_gcm_cmd()\n\nThere are three bugs in this code:\n\n1) If we ccp_init_data() fails for &src then we need to free aad.\n   Use goto e_aad instead of goto e_ctx.\n2) The label to free the &final_wa was named incorrectly as \"e_tag\" but\n   it should have been \"e_final_wa\".  One error path leaked &final_wa.\n3) The &tag was leaked on one error path.  In that case, I added a free\n   before the goto because the resource was local to that block.\n\nFixes: 36cf515b9bbe (\"crypto: ccp - Enable support for AES GCM on v5 CCPs\")\nReported-by: \"minihanshen(\u6c88\u660e\u822a)\" <minihanshen@tencent.com>\nSigned-off-by: Dan Carpenter <dan.carpenter@oracle.com>\nReviewed-by: John Allen <john.allen@amd.com>\nTested-by: John Allen <john.allen@amd.com>\nSigned-off-by: Herbert Xu <herbert@gondor.apana.org.au>",
        "target": 1,
        "irrelevant": 0,
        "func_before": "ccp_run_aes_gcm_cmd(struct ccp_cmd_queue *cmd_q, struct ccp_cmd *cmd)\n{\n\tstruct ccp_aes_engine *aes = &cmd->u.aes;\n\tstruct ccp_dm_workarea key, ctx, final_wa, tag;\n\tstruct ccp_data src, dst;\n\tstruct ccp_data aad;\n\tstruct ccp_op op;\n\tunsigned int dm_offset;\n\tunsigned int authsize;\n\tunsigned int jobid;\n\tunsigned int ilen;\n\tbool in_place = true; /* Default value */\n\t__be64 *final;\n\tint ret;\n\n\tstruct scatterlist *p_inp, sg_inp[2];\n\tstruct scatterlist *p_tag, sg_tag[2];\n\tstruct scatterlist *p_outp, sg_outp[2];\n\tstruct scatterlist *p_aad;\n\n\tif (!aes->iv)\n\t\treturn -EINVAL;\n\n\tif (!((aes->key_len == AES_KEYSIZE_128) ||\n\t\t(aes->key_len == AES_KEYSIZE_192) ||\n\t\t(aes->key_len == AES_KEYSIZE_256)))\n\t\treturn -EINVAL;\n\n\tif (!aes->key) /* Gotta have a key SGL */\n\t\treturn -EINVAL;\n\n\t/* Zero defaults to 16 bytes, the maximum size */\n\tauthsize = aes->authsize ? aes->authsize : AES_BLOCK_SIZE;\n\tswitch (authsize) {\n\tcase 16:\n\tcase 15:\n\tcase 14:\n\tcase 13:\n\tcase 12:\n\tcase 8:\n\tcase 4:\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\t/* First, decompose the source buffer into AAD & PT,\n\t * and the destination buffer into AAD, CT & tag, or\n\t * the input into CT & tag.\n\t * It is expected that the input and output SGs will\n\t * be valid, even if the AAD and input lengths are 0.\n\t */\n\tp_aad = aes->src;\n\tp_inp = scatterwalk_ffwd(sg_inp, aes->src, aes->aad_len);\n\tp_outp = scatterwalk_ffwd(sg_outp, aes->dst, aes->aad_len);\n\tif (aes->action == CCP_AES_ACTION_ENCRYPT) {\n\t\tilen = aes->src_len;\n\t\tp_tag = scatterwalk_ffwd(sg_tag, p_outp, ilen);\n\t} else {\n\t\t/* Input length for decryption includes tag */\n\t\tilen = aes->src_len - authsize;\n\t\tp_tag = scatterwalk_ffwd(sg_tag, p_inp, ilen);\n\t}\n\n\tjobid = CCP_NEW_JOBID(cmd_q->ccp);\n\n\tmemset(&op, 0, sizeof(op));\n\top.cmd_q = cmd_q;\n\top.jobid = jobid;\n\top.sb_key = cmd_q->sb_key; /* Pre-allocated */\n\top.sb_ctx = cmd_q->sb_ctx; /* Pre-allocated */\n\top.init = 1;\n\top.u.aes.type = aes->type;\n\n\t/* Copy the key to the LSB */\n\tret = ccp_init_dm_workarea(&key, cmd_q,\n\t\t\t\t   CCP_AES_CTX_SB_COUNT * CCP_SB_BYTES,\n\t\t\t\t   DMA_TO_DEVICE);\n\tif (ret)\n\t\treturn ret;\n\n\tdm_offset = CCP_SB_BYTES - aes->key_len;\n\tret = ccp_set_dm_area(&key, dm_offset, aes->key, 0, aes->key_len);\n\tif (ret)\n\t\tgoto e_key;\n\tret = ccp_copy_to_sb(cmd_q, &key, op.jobid, op.sb_key,\n\t\t\t     CCP_PASSTHRU_BYTESWAP_256BIT);\n\tif (ret) {\n\t\tcmd->engine_error = cmd_q->cmd_error;\n\t\tgoto e_key;\n\t}\n\n\t/* Copy the context (IV) to the LSB.\n\t * There is an assumption here that the IV is 96 bits in length, plus\n\t * a nonce of 32 bits. If no IV is present, use a zeroed buffer.\n\t */\n\tret = ccp_init_dm_workarea(&ctx, cmd_q,\n\t\t\t\t   CCP_AES_CTX_SB_COUNT * CCP_SB_BYTES,\n\t\t\t\t   DMA_BIDIRECTIONAL);\n\tif (ret)\n\t\tgoto e_key;\n\n\tdm_offset = CCP_AES_CTX_SB_COUNT * CCP_SB_BYTES - aes->iv_len;\n\tret = ccp_set_dm_area(&ctx, dm_offset, aes->iv, 0, aes->iv_len);\n\tif (ret)\n\t\tgoto e_ctx;\n\n\tret = ccp_copy_to_sb(cmd_q, &ctx, op.jobid, op.sb_ctx,\n\t\t\t     CCP_PASSTHRU_BYTESWAP_256BIT);\n\tif (ret) {\n\t\tcmd->engine_error = cmd_q->cmd_error;\n\t\tgoto e_ctx;\n\t}\n\n\top.init = 1;\n\tif (aes->aad_len > 0) {\n\t\t/* Step 1: Run a GHASH over the Additional Authenticated Data */\n\t\tret = ccp_init_data(&aad, cmd_q, p_aad, aes->aad_len,\n\t\t\t\t    AES_BLOCK_SIZE,\n\t\t\t\t    DMA_TO_DEVICE);\n\t\tif (ret)\n\t\t\tgoto e_ctx;\n\n\t\top.u.aes.mode = CCP_AES_MODE_GHASH;\n\t\top.u.aes.action = CCP_AES_GHASHAAD;\n\n\t\twhile (aad.sg_wa.bytes_left) {\n\t\t\tccp_prepare_data(&aad, NULL, &op, AES_BLOCK_SIZE, true);\n\n\t\t\tret = cmd_q->ccp->vdata->perform->aes(&op);\n\t\t\tif (ret) {\n\t\t\t\tcmd->engine_error = cmd_q->cmd_error;\n\t\t\t\tgoto e_aad;\n\t\t\t}\n\n\t\t\tccp_process_data(&aad, NULL, &op);\n\t\t\top.init = 0;\n\t\t}\n\t}\n\n\top.u.aes.mode = CCP_AES_MODE_GCTR;\n\top.u.aes.action = aes->action;\n\n\tif (ilen > 0) {\n\t\t/* Step 2: Run a GCTR over the plaintext */\n\t\tin_place = (sg_virt(p_inp) == sg_virt(p_outp)) ? true : false;\n\n\t\tret = ccp_init_data(&src, cmd_q, p_inp, ilen,\n\t\t\t\t    AES_BLOCK_SIZE,\n\t\t\t\t    in_place ? DMA_BIDIRECTIONAL\n\t\t\t\t\t     : DMA_TO_DEVICE);\n\t\tif (ret)\n\t\t\tgoto e_ctx;\n\n\t\tif (in_place) {\n\t\t\tdst = src;\n\t\t} else {\n\t\t\tret = ccp_init_data(&dst, cmd_q, p_outp, ilen,\n\t\t\t\t\t    AES_BLOCK_SIZE, DMA_FROM_DEVICE);\n\t\t\tif (ret)\n\t\t\t\tgoto e_src;\n\t\t}\n\n\t\top.soc = 0;\n\t\top.eom = 0;\n\t\top.init = 1;\n\t\twhile (src.sg_wa.bytes_left) {\n\t\t\tccp_prepare_data(&src, &dst, &op, AES_BLOCK_SIZE, true);\n\t\t\tif (!src.sg_wa.bytes_left) {\n\t\t\t\tunsigned int nbytes = ilen % AES_BLOCK_SIZE;\n\n\t\t\t\tif (nbytes) {\n\t\t\t\t\top.eom = 1;\n\t\t\t\t\top.u.aes.size = (nbytes * 8) - 1;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tret = cmd_q->ccp->vdata->perform->aes(&op);\n\t\t\tif (ret) {\n\t\t\t\tcmd->engine_error = cmd_q->cmd_error;\n\t\t\t\tgoto e_dst;\n\t\t\t}\n\n\t\t\tccp_process_data(&src, &dst, &op);\n\t\t\top.init = 0;\n\t\t}\n\t}\n\n\t/* Step 3: Update the IV portion of the context with the original IV */\n\tret = ccp_copy_from_sb(cmd_q, &ctx, op.jobid, op.sb_ctx,\n\t\t\t       CCP_PASSTHRU_BYTESWAP_256BIT);\n\tif (ret) {\n\t\tcmd->engine_error = cmd_q->cmd_error;\n\t\tgoto e_dst;\n\t}\n\n\tret = ccp_set_dm_area(&ctx, dm_offset, aes->iv, 0, aes->iv_len);\n\tif (ret)\n\t\tgoto e_dst;\n\n\tret = ccp_copy_to_sb(cmd_q, &ctx, op.jobid, op.sb_ctx,\n\t\t\t     CCP_PASSTHRU_BYTESWAP_256BIT);\n\tif (ret) {\n\t\tcmd->engine_error = cmd_q->cmd_error;\n\t\tgoto e_dst;\n\t}\n\n\t/* Step 4: Concatenate the lengths of the AAD and source, and\n\t * hash that 16 byte buffer.\n\t */\n\tret = ccp_init_dm_workarea(&final_wa, cmd_q, AES_BLOCK_SIZE,\n\t\t\t\t   DMA_BIDIRECTIONAL);\n\tif (ret)\n\t\tgoto e_dst;\n\tfinal = (__be64 *)final_wa.address;\n\tfinal[0] = cpu_to_be64(aes->aad_len * 8);\n\tfinal[1] = cpu_to_be64(ilen * 8);\n\n\tmemset(&op, 0, sizeof(op));\n\top.cmd_q = cmd_q;\n\top.jobid = jobid;\n\top.sb_key = cmd_q->sb_key; /* Pre-allocated */\n\top.sb_ctx = cmd_q->sb_ctx; /* Pre-allocated */\n\top.init = 1;\n\top.u.aes.type = aes->type;\n\top.u.aes.mode = CCP_AES_MODE_GHASH;\n\top.u.aes.action = CCP_AES_GHASHFINAL;\n\top.src.type = CCP_MEMTYPE_SYSTEM;\n\top.src.u.dma.address = final_wa.dma.address;\n\top.src.u.dma.length = AES_BLOCK_SIZE;\n\top.dst.type = CCP_MEMTYPE_SYSTEM;\n\top.dst.u.dma.address = final_wa.dma.address;\n\top.dst.u.dma.length = AES_BLOCK_SIZE;\n\top.eom = 1;\n\top.u.aes.size = 0;\n\tret = cmd_q->ccp->vdata->perform->aes(&op);\n\tif (ret)\n\t\tgoto e_dst;\n\n\tif (aes->action == CCP_AES_ACTION_ENCRYPT) {\n\t\t/* Put the ciphered tag after the ciphertext. */\n\t\tccp_get_dm_area(&final_wa, 0, p_tag, 0, authsize);\n\t} else {\n\t\t/* Does this ciphered tag match the input? */\n\t\tret = ccp_init_dm_workarea(&tag, cmd_q, authsize,\n\t\t\t\t\t   DMA_BIDIRECTIONAL);\n\t\tif (ret)\n\t\t\tgoto e_tag;\n\t\tret = ccp_set_dm_area(&tag, 0, p_tag, 0, authsize);\n\t\tif (ret)\n\t\t\tgoto e_tag;\n\n\t\tret = crypto_memneq(tag.address, final_wa.address,\n\t\t\t\t    authsize) ? -EBADMSG : 0;\n\t\tccp_dm_free(&tag);\n\t}\n\ne_tag:\n\tccp_dm_free(&final_wa);\n\ne_dst:\n\tif (ilen > 0 && !in_place)\n\t\tccp_free_data(&dst, cmd_q);\n\ne_src:\n\tif (ilen > 0)\n\t\tccp_free_data(&src, cmd_q);\n\ne_aad:\n\tif (aes->aad_len)\n\t\tccp_free_data(&aad, cmd_q);\n\ne_ctx:\n\tccp_dm_free(&ctx);\n\ne_key:\n\tccp_dm_free(&key);\n\n\treturn ret;\n}",
        "func_hash": 164338035268758054525512134234222500237,
        "file_name": "ccp-ops.c",
        "file_hash": 220238669007539960746784666211129167889,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2021-3744",
        "cve_desc": "A memory leak flaw was found in the Linux kernel in the ccp_run_aes_gcm_cmd() function in drivers/crypto/ccp/ccp-ops.c, which allows attackers to cause a denial of service (memory consumption). This vulnerability is similar with the older CVE-2019-18808.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-3744",
        "func_name": "ccp_run_aes_gcm_cmd",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 197142,
        "project": "tensorflow",
        "commit_id": "6da6620efad397c85493b8f8667b821403516708",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/6da6620efad397c85493b8f8667b821403516708",
        "commit_message": "Secure tf.raw_ops.QuantizeV2\n\nValidate size and shape of min_range and max_range\nEnsure axis is within input dims limits\n\nPiperOrigin-RevId: 387232799\nChange-Id: I36975281f7b5758e9e31a8dcc73fe610ef456318",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor& input = ctx->input(0);\n    const Tensor& input_min_range = ctx->input(1);\n    const Tensor& input_max_range = ctx->input(2);\n\n    int num_slices = 1;\n    if (axis_ > -1) {\n      num_slices = input.dim_size(axis_);\n    }\n\n    const TensorShape& minmax_shape = ctx->input(1).shape();\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));\n\n    Tensor* output_min_tensor = nullptr;\n    Tensor* output_max_tensor = nullptr;\n\n    if (num_slices == 1) {\n      OP_REQUIRES_OK(ctx, ctx->allocate_output(1, {}, &output_min_tensor));\n      OP_REQUIRES_OK(ctx, ctx->allocate_output(2, {}, &output_max_tensor));\n      const float min_range = input_min_range.template flat<float>()(0);\n      const float max_range = input_max_range.template flat<float>()(0);\n      QuantizeTensor(ctx, input, min_range, max_range, output,\n                     output_min_tensor, output_max_tensor);\n      return;\n    }\n\n    OP_REQUIRES(ctx, mode_ != QUANTIZE_MODE_MIN_FIRST,\n                errors::Unimplemented(\"MIN_FIRST mode is not implemented for \"\n                                      \"Quantize with axis != -1.\"));\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_output(1, minmax_shape, &output_min_tensor));\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_output(2, minmax_shape, &output_max_tensor));\n\n    auto input_tensor =\n        input.template flat_inner_outer_dims<float, 3>(axis_ - 1);\n    int64_t pre_dim = 1, post_dim = 1;\n    for (int i = 0; i < axis_; ++i) {\n      pre_dim *= output->dim_size(i);\n    }\n    for (int i = axis_ + 1; i < output->dims(); ++i) {\n      post_dim *= output->dim_size(i);\n    }\n    auto output_tensor = output->template bit_casted_shaped<T, 3>(\n        {pre_dim, num_slices, post_dim});\n    auto min_ranges = input_min_range.template vec<float>();\n    auto max_ranges = input_max_range.template vec<float>();\n    for (int i = 0; i < num_slices; ++i) {\n      QuantizeSlice(ctx->eigen_device<Device>(), ctx,\n                    input_tensor.template chip<1>(i), min_ranges(i),\n                    max_ranges(i), output_tensor.template chip<1>(i),\n                    &output_min_tensor->flat<float>()(i),\n                    &output_max_tensor->flat<float>()(i));\n    }\n  }",
        "func_hash": 175054869100587978050053791864843631748,
        "file_name": "quantize_op.cc",
        "file_hash": 45910676002815731564213734124644481802,
        "cwe": [
            "CWE-476"
        ],
        "cve": "CVE-2021-37663",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions due to incomplete validation in `tf.raw_ops.QuantizeV2`, an attacker can trigger undefined behavior via binding a reference to a null pointer or can access data outside the bounds of heap allocated arrays. The [implementation](https://github.com/tensorflow/tensorflow/blob/84d053187cb80d975ef2b9684d4b61981bca0c41/tensorflow/core/kernels/quantize_op.cc#L59) has some validation but does not check that `min_range` and `max_range` both have the same non-zero number of elements. If `axis` is provided (i.e., not `-1`), then validation should check that it is a value in range for the rank of `input` tensor and then the lengths of `min_range` and `max_range` inputs match the `axis` dimension of the `input` tensor. We have patched the issue in GitHub commit 6da6620efad397c85493b8f8667b821403516708. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37663",
        "func_name": "Compute",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 197185,
        "project": "FFmpeg",
        "commit_id": "9ffa49496d1aae4cbbb387aac28a9e061a6ab0a6",
        "project_url": "https://github.com/FFmpeg/FFmpeg",
        "commit_url": "https://github.com/FFmpeg/FFmpeg/commit/9ffa49496d1aae4cbbb387aac28a9e061a6ab0a6",
        "commit_message": "avformat/adtsenc: return value check for init_get_bits in adts_decode_extradata\n\nAs the second argument for init_get_bits (buf) can be crafted, a return value check for this function call is necessary.\n'buf' is  part of  'AVPacket pkt'.\nreplace init_get_bits with init_get_bits8.\n\nSigned-off-by: Michael Niedermayer <michael@niedermayer.cc>",
        "target": 1,
        "irrelevant": 1,
        "func_before": "static int adts_decode_extradata(AVFormatContext *s, ADTSContext *adts, const uint8_t *buf, int size)\n{\n    GetBitContext gb;\n    PutBitContext pb;\n    MPEG4AudioConfig m4ac;\n    int off;\n\n    init_get_bits(&gb, buf, size * 8);\n    off = avpriv_mpeg4audio_get_config2(&m4ac, buf, size, 1, s);\n    if (off < 0)\n        return off;\n    skip_bits_long(&gb, off);\n    adts->objecttype        = m4ac.object_type - 1;\n    adts->sample_rate_index = m4ac.sampling_index;\n    adts->channel_conf      = m4ac.chan_config;\n\n    if (adts->objecttype > 3U) {\n        av_log(s, AV_LOG_ERROR, \"MPEG-4 AOT %d is not allowed in ADTS\\n\", adts->objecttype+1);\n        return AVERROR_INVALIDDATA;\n    }\n    if (adts->sample_rate_index == 15) {\n        av_log(s, AV_LOG_ERROR, \"Escape sample rate index illegal in ADTS\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n    if (get_bits(&gb, 1)) {\n        av_log(s, AV_LOG_ERROR, \"960/120 MDCT window is not allowed in ADTS\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n    if (get_bits(&gb, 1)) {\n        av_log(s, AV_LOG_ERROR, \"Scalable configurations are not allowed in ADTS\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n    if (get_bits(&gb, 1)) {\n        av_log(s, AV_LOG_ERROR, \"Extension flag is not allowed in ADTS\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n    if (!adts->channel_conf) {\n        init_put_bits(&pb, adts->pce_data, MAX_PCE_SIZE);\n\n        put_bits(&pb, 3, 5); //ID_PCE\n        adts->pce_size = (ff_copy_pce_data(&pb, &gb) + 3) / 8;\n        flush_put_bits(&pb);\n    }\n\n    adts->write_adts = 1;\n\n    return 0;\n}",
        "func_hash": 158925528540777233957652669648532881464,
        "file_name": "adtsenc.c",
        "file_hash": null,
        "cwe": [
            "CWE-252"
        ],
        "cve": "CVE-2021-38171",
        "cve_desc": "adts_decode_extradata in libavformat/adtsenc.c in FFmpeg 4.4 does not check the init_get_bits return value, which is a necessary step because the second argument to init_get_bits can be crafted.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-38171",
        "func_name": "adts_decode_extradata",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 197223,
        "project": "njs",
        "commit_id": "ab1702c7af9959366a5ddc4a75b4357d4e9ebdc1",
        "project_url": "https://github.com/nginx/njs",
        "commit_url": "https://github.com/nginx/njs/commit/ab1702c7af9959366a5ddc4a75b4357d4e9ebdc1",
        "commit_message": "Fixed typo while calculating module path length.\n\nThe issue was introduced in 77c398f26d7e (not released yet).",
        "target": 1,
        "irrelevant": 0,
        "func_before": "njs_module_path(njs_vm_t *vm, const njs_str_t *dir, njs_module_info_t *info)\n{\n    char        *p;\n    size_t      length;\n    njs_bool_t  trail;\n    char        src[NJS_MAX_PATH + 1];\n\n    trail = 0;\n    length = info->name.length;\n\n    if (dir != NULL) {\n        length = dir->length;\n\n        if (length == 0) {\n            return NJS_DECLINED;\n        }\n\n        trail = (dir->start[dir->length - 1] != '/');\n\n        if (trail) {\n            length++;\n        }\n    }\n\n    if (njs_slow_path(length > NJS_MAX_PATH)) {\n        return NJS_ERROR;\n    }\n\n    p = &src[0];\n\n    if (dir != NULL) {\n        p = (char *) njs_cpymem(p, dir->start, dir->length);\n\n        if (trail) {\n            *p++ = '/';\n        }\n    }\n\n    p = (char *) njs_cpymem(p, info->name.start, info->name.length);\n    *p = '\\0';\n\n    p = realpath(&src[0], &info->path[0]);\n    if (p == NULL) {\n        return NJS_DECLINED;\n    }\n\n    info->fd = open(&info->path[0], O_RDONLY);\n    if (info->fd < 0) {\n        return NJS_DECLINED;\n    }\n\n\n    info->file.start = (u_char *) &info->path[0];\n    info->file.length = njs_strlen(info->file.start);\n\n    return NJS_OK;\n}",
        "func_hash": 236847431367932249474325490160608146650,
        "file_name": "njs_module.c",
        "file_hash": 230069477074111336405443824718201036517,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2022-29379",
        "cve_desc": "Nginx NJS v0.7.3 was discovered to contain a stack overflow in the function njs_default_module_loader at /src/njs/src/njs_module.c. NOTE: multiple third parties dispute this report, e.g., the behavior is only found in unreleased development code that was not part of the 0.7.2, 0.7.3, or 0.7.4 release",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-29379",
        "func_name": "njs_module_path",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 197239,
        "project": "tensorflow",
        "commit_id": "203214568f5bc237603dbab6e1fd389f1572f5c9",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/203214568f5bc237603dbab6e1fd389f1572f5c9",
        "commit_message": "Reorganize and add more validation to MKL requantization\n\nPiperOrigin-RevId: 387901341\nChange-Id: I2515b9034c64e113db0bcec8337d30643ab0a0f1",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext* ctx) override {\n    try {\n      const Tensor& input = ctx->input(kInputTensorIndex);\n      const Tensor& input_min_vec = ctx->input(kInputMinVecIndex);\n      float* input_min_vec_data = (float*)const_cast<void*>(\n          static_cast<const void*>(input_min_vec.flat<float>().data()));\n      const Tensor& input_max_vec = ctx->input(kInputMaxVecIndex);\n      float* input_max_vec_data = (float*)const_cast<void*>(\n          static_cast<const void*>(input_max_vec.flat<float>().data()));\n\n      const Tensor& input_requested_min = ctx->input(this->kRequestMinIndex);\n      const float input_requested_min_float =\n          input_requested_min.flat<float>()(0);\n      const Tensor& input_requested_max = ctx->input(this->kRequestMaxIndex);\n      const float input_requested_max_float =\n          input_requested_max.flat<float>()(0);\n\n      size_t depth = input_min_vec.NumElements();\n      OP_REQUIRES(\n          ctx, input.dims() == 4,\n          errors::InvalidArgument(\"Current RequantizePerChannel operator\"\n                                  \"supports 4D tensors only.\"));\n      OP_REQUIRES(\n          ctx, input_min_vec.dim_size(0) == depth,\n          errors::InvalidArgument(\"input_min has incorrect size, expected \",\n                                  depth, \" was \", input_min_vec.dim_size(0)));\n      OP_REQUIRES(\n          ctx, input_max_vec.dim_size(0) == depth,\n          errors::InvalidArgument(\"input_max has incorrect size, expected \",\n                                  depth, \" was \", input_max_vec.dim_size(0)));\n\n      if (out_type_ == DT_QINT8) DCHECK(input_requested_min_float < 0.0f);\n\n      const float factor = (out_type_ == DT_QINT8) ? 127.0f : 255.0f;\n      const float requested_min_max =\n          std::max(std::abs(input_requested_min_float),\n                   std::abs(input_requested_max_float));\n      Tensor* output = nullptr;\n      OP_REQUIRES_OK(ctx, ctx->allocate_output(kOutputTensorIndex,\n                                               input.shape(), &output));\n\n      std::vector<float> scales(depth);\n      for (int i = 0; i < depth; ++i) {\n        float min_max_from_vec = std::max(std::abs(input_min_vec_data[i]),\n                                          std::abs(input_max_vec_data[i]));\n        scales[i] = factor * (min_max_from_vec / requested_min_max /\n                              static_cast<float>(1L << 31));\n      }\n\n      mkldnn::primitive_attr reorder_attr;\n      reorder_attr.set_output_scales(2, scales);\n\n      memory::dims dims_mkl_order =\n          TFShapeToMklDnnDimsInNCHW(input.shape(), FORMAT_NHWC);\n      memory::desc input_md = memory::desc(dims_mkl_order, MklDnnType<qint32>(),\n                                           memory::format_tag::nhwc);\n      memory::desc output_md =\n          (out_type_ == DT_QINT8)\n              ? memory::desc(dims_mkl_order, MklDnnType<qint8>(),\n                             memory::format_tag::nhwc)\n              : memory::desc(dims_mkl_order, MklDnnType<quint8>(),\n                             memory::format_tag::nhwc);\n\n      void* input_buf =\n          static_cast<void*>(const_cast<qint32*>(input.flat<qint32>().data()));\n      void* output_buf;\n      if (out_type_ == DT_QINT8) {\n        output_buf = static_cast<void*>(\n            const_cast<qint8*>(output->flat<qint8>().data()));\n      } else {\n        output_buf = static_cast<void*>(\n            const_cast<quint8*>(output->flat<quint8>().data()));\n      }\n\n      std::unique_ptr<memory> input_mem_prim(\n          new memory(input_md, cpu_engine_, input_buf));\n      std::unique_ptr<memory> output_mem_prim(\n          new memory(output_md, cpu_engine_, output_buf));\n\n      mkldnn::reorder::primitive_desc reorder_pd =\n          ReorderPd(cpu_engine_, input_mem_prim->get_desc(), cpu_engine_,\n                    output_mem_prim->get_desc(), reorder_attr);\n      std::shared_ptr<stream> reorder_stream;\n      MklDnnThreadPool eigen_tp(ctx);\n      reorder_stream.reset(CreateStream(&eigen_tp, cpu_engine_));\n      std::unordered_map<int, mkldnn::memory> reorder_args = {\n          {MKLDNN_ARG_FROM, *input_mem_prim},\n          {MKLDNN_ARG_TO, *output_mem_prim}};\n      std::unique_ptr<mkldnn::primitive> reorder_prim(\n          new mkldnn::reorder(reorder_pd));\n      reorder_prim->execute(*reorder_stream, reorder_args);\n\n      Tensor* output_min = nullptr;\n      Tensor* output_max = nullptr;\n      OP_REQUIRES_OK(ctx,\n                     ctx->allocate_output(kOutputMinIndex, {}, &output_min));\n      OP_REQUIRES_OK(ctx,\n                     ctx->allocate_output(kOutputMaxIndex, {}, &output_max));\n\n      output_min->flat<float>()(0) = input_requested_min_float;\n      output_max->flat<float>()(0) = input_requested_max_float;\n    } catch (mkldnn::error& e) {\n      string error_msg = \"Status: \" + std::to_string(e.status) +\n                         \", message: \" + std::string(e.message) + \", in file \" +\n                         std::string(__FILE__) + \":\" + std::to_string(__LINE__);\n      OP_REQUIRES_OK(\n          ctx, errors::Aborted(\"Operation received an exception:\", error_msg));\n    }\n  }",
        "func_hash": 324241400481110766657474950076141174434,
        "file_name": "mkl_requantize_per_channel_op.cc",
        "file_hash": 251676487738280920031977890166955496760,
        "cwe": [
            "CWE-20"
        ],
        "cve": "CVE-2021-37665",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions due to incomplete validation in MKL implementation of requantization, an attacker can trigger undefined behavior via binding a reference to a null pointer or can access data outside the bounds of heap allocated arrays. The [implementation](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/core/kernels/mkl/mkl_requantization_range_per_channel_op.cc) does not validate the dimensions of the `input` tensor. A similar issue occurs in `MklRequantizePerChannelOp`. The [implementation](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/core/kernels/mkl/mkl_requantize_per_channel_op.cc) does not perform full validation for all the input arguments. We have patched the issue in GitHub commit 9e62869465573cb2d9b5053f1fa02a81fce21d69 and in the Github commit 203214568f5bc237603dbab6e1fd389f1572f5c9. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37665",
        "func_name": "Compute",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 197242,
        "project": "tensorflow",
        "commit_id": "537bc7c723439b9194a358f64d871dd326c18887",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/537bc7c723439b9194a358f64d871dd326c18887",
        "commit_message": "Fix a null pointer exception caused by branching on uninitialized data.\n\nThis is due to not checking that the params for the quantization exists. If there is no quantization, we should not access the `.params` field.\n\nPiperOrigin-RevId: 385163909\nChange-Id: I2beb8d50649b6542db224c163033fbcbaa49314f",
        "target": 1,
        "irrelevant": 0,
        "func_before": "TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n  const auto* params = reinterpret_cast<TfLiteSVDFParams*>(node->builtin_data);\n  OpData* op_data = reinterpret_cast<OpData*>(node->user_data);\n  int scratch_tensor_index = op_data->scratch_tensor_index;\n\n  // Check we have all the inputs and outputs we need.\n  TF_LITE_ENSURE_EQ(context, node->outputs->size, 1);\n  TF_LITE_ENSURE_EQ(context, node->inputs->size, 5);\n\n  const TfLiteTensor* input;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n  const TfLiteTensor* weights_feature;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kWeightsFeatureTensor,\n                                          &weights_feature));\n  const TfLiteTensor* weights_time;\n  TF_LITE_ENSURE_OK(\n      context, GetInputSafe(context, node, kWeightsTimeTensor, &weights_time));\n\n  TF_LITE_ENSURE(context,\n                 input->type == kTfLiteFloat32 || input->type == kTfLiteInt8);\n\n  // Check all the parameters of tensor match within themselves and match the\n  // input configuration.\n  const int rank = params->rank;\n  const int batch_size = input->dims->data[0];\n  const int num_filters = weights_feature->dims->data[0];\n  TF_LITE_ENSURE(context, rank != 0);\n  TF_LITE_ENSURE_EQ(context, num_filters % rank, 0);\n  const int num_units = num_filters / rank;\n  const int memory_size = weights_time->dims->data[1];\n  TF_LITE_ENSURE_EQ(context, input->dims->data[1],\n                    weights_feature->dims->data[1]);\n  TF_LITE_ENSURE_EQ(context, weights_time->dims->data[0], num_filters);\n\n  const TfLiteTensor* bias = GetOptionalInputTensor(context, node, kBiasTensor);\n  if (bias) {\n    TF_LITE_ENSURE_EQ(context, bias->dims->data[0], num_units);\n  }\n\n  const TfLiteTensor* state;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kStateTensor, &state));\n  TfLiteTensor* output;\n  TF_LITE_ENSURE_OK(context,\n                    GetOutputSafe(context, node, kOutputTensor, &output));\n\n  // Check the shape of input state tensors.\n  TF_LITE_ENSURE_EQ(context, NumDimensions(state), 2);\n  TF_LITE_ENSURE_EQ(context, SizeOfDimension(state, 0), batch_size);\n  TF_LITE_ENSURE_EQ(context, SizeOfDimension(state, 1),\n                    memory_size * num_filters);\n\n  // Resize output.\n  TfLiteIntArray* output_size_array = TfLiteIntArrayCreate(2);\n  output_size_array->data[0] = batch_size;\n  output_size_array->data[1] = num_units;\n  TF_LITE_ENSURE_OK(context,\n                    context->ResizeTensor(context, output, output_size_array));\n\n  // The weights are of consistent type, so it suffices to check one.\n  const bool is_hybrid_op = IsHybridOp(input, weights_feature);\n  const bool is_full_integer = input->type == kTfLiteInt8;\n\n  // Resize scratch.\n  TfLiteIntArrayFree(node->temporaries);\n  if (is_hybrid_op) {\n    node->temporaries = TfLiteIntArrayCreate(6);\n  } else if (is_full_integer) {\n    node->temporaries = TfLiteIntArrayCreate(2);\n  } else {\n    node->temporaries = TfLiteIntArrayCreate(1);\n  }\n  node->temporaries->data[0] = scratch_tensor_index;\n\n  TfLiteIntArray* scratch_size_array = TfLiteIntArrayCreate(2);\n  scratch_size_array->data[0] = batch_size;\n  scratch_size_array->data[1] = num_filters;\n\n  TfLiteTensor* scratch_tensor;\n  TF_LITE_ENSURE_OK(\n      context, GetTemporarySafe(context, node, /*index=*/0, &scratch_tensor));\n\n  // The scratch buffer is of type int32 for full integer svdf and it's of type\n  // float32 for hybrid and float case.\n  if (is_full_integer) {\n    scratch_tensor->type = kTfLiteInt32;\n  } else {\n    scratch_tensor->type = kTfLiteFloat32;\n  }\n  scratch_tensor->allocation_type = kTfLiteArenaRw;\n  TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, scratch_tensor,\n                                                   scratch_size_array));\n\n  if (is_hybrid_op) {\n    op_data->compute_row_sums = true;\n    // Tell interpreter to allocate temporary tensors to store quantized values\n    // of input tensors.\n    node->temporaries->data[1] = scratch_tensor_index + 1;\n    TfLiteTensor* input_quantized;\n    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/1,\n                                                &input_quantized));\n    input_quantized->type = weights_feature->type;\n    input_quantized->allocation_type = kTfLiteArenaRw;\n    if (!TfLiteIntArrayEqual(input_quantized->dims, input->dims)) {\n      TfLiteIntArray* input_quantized_size = TfLiteIntArrayCopy(input->dims);\n      TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, input_quantized,\n                                                       input_quantized_size));\n    }\n\n    // Tell interpreter to allocate temporary tensors to store scaling factors.\n    node->temporaries->data[2] = scratch_tensor_index + 2;\n    TfLiteTensor* scaling_factors;\n    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/2,\n                                                &scaling_factors));\n    scaling_factors->type = kTfLiteFloat32;\n    scaling_factors->allocation_type = kTfLiteArenaRw;\n    int scaling_dims[1] = {batch_size};\n    if (!TfLiteIntArrayEqualsArray(scaling_factors->dims, 1, scaling_dims)) {\n      TfLiteIntArray* scaling_factors_size = TfLiteIntArrayCreate(1);\n      scaling_factors_size->data[0] = batch_size;\n      TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, scaling_factors,\n                                                       scaling_factors_size));\n    }\n\n    // Used to store dequantized weights_time matrix for hybrid computation of\n    // matmul(state, weights_time), which occurs in floating point.\n    node->temporaries->data[3] = scratch_tensor_index + 3;\n    TfLiteTensor* float_weights_time;\n    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/3,\n                                                &float_weights_time));\n    float_weights_time->type = kTfLiteFloat32;\n    // Persistent so that we can compute the dequantized weights only once.\n    float_weights_time->allocation_type = kTfLiteArenaRwPersistent;\n    if (!TfLiteIntArrayEqual(float_weights_time->dims, weights_time->dims)) {\n      TfLiteIntArray* float_weights_time_size =\n          TfLiteIntArrayCopy(weights_time->dims);\n      TF_LITE_ENSURE_OK(context,\n                        context->ResizeTensor(context, float_weights_time,\n                                              float_weights_time_size));\n    }\n\n    node->temporaries->data[4] = scratch_tensor_index + 4;\n    TfLiteTensor* zero_points;\n    TF_LITE_ENSURE_OK(\n        context, GetTemporarySafe(context, node, /*index=*/4, &zero_points));\n    zero_points->type = kTfLiteFloat32;\n    zero_points->allocation_type = kTfLiteArenaRw;\n    int zero_points_dims[1] = {batch_size};\n    if (!TfLiteIntArrayEqualsArray(zero_points->dims, 1, zero_points_dims)) {\n      TfLiteIntArray* zero_points_size = TfLiteIntArrayCreate(1);\n      zero_points_size->data[0] = zero_points_dims[0];\n      TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, zero_points,\n                                                       zero_points_size));\n    }\n\n    node->temporaries->data[5] = scratch_tensor_index + 5;\n    TfLiteTensor* row_sums;\n    TF_LITE_ENSURE_OK(context,\n                      GetTemporarySafe(context, node, /*index=*/5, &row_sums));\n    row_sums->type = kTfLiteFloat32;\n    row_sums->allocation_type = kTfLiteArenaRwPersistent;\n    int row_sums_dims[1] = {num_filters};\n    if (!TfLiteIntArrayEqualsArray(row_sums->dims, 1, row_sums_dims)) {\n      TfLiteIntArray* row_sums_size = TfLiteIntArrayCreate(1);\n      row_sums_size->data[0] = row_sums_dims[0];\n      TF_LITE_ENSURE_OK(\n          context, context->ResizeTensor(context, row_sums, row_sums_size));\n    }\n  }\n  if (is_full_integer) {\n    // Allocated one extra tensor.\n    TfLiteIntArray* output_temp_size_array = TfLiteIntArrayCreate(2);\n    output_temp_size_array->data[0] = num_units;\n    output_temp_size_array->data[1] = batch_size;\n    node->temporaries->data[1] = scratch_tensor_index + 1;\n    TfLiteTensor* output_temp;\n    TF_LITE_ENSURE_OK(\n        context, GetTemporarySafe(context, node, /*index=*/1, &output_temp));\n    output_temp->type = kTfLiteInt32;\n    output_temp->allocation_type = kTfLiteArenaRw;\n    TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, output_temp,\n                                                     output_temp_size_array));\n\n    // Calculate effective scales.\n    auto* input_params =\n        reinterpret_cast<TfLiteAffineQuantization*>(input->quantization.params);\n    auto* weights_feature_params = reinterpret_cast<TfLiteAffineQuantization*>(\n        weights_feature->quantization.params);\n    auto* state_params =\n        reinterpret_cast<TfLiteAffineQuantization*>(state->quantization.params);\n    auto* weight_time_params = reinterpret_cast<TfLiteAffineQuantization*>(\n        weights_time->quantization.params);\n    auto* output_params = reinterpret_cast<TfLiteAffineQuantization*>(\n        output->quantization.params);\n    const double effective_scale_1 = input_params->scale->data[0] *\n                                     weights_feature_params->scale->data[0] /\n                                     state_params->scale->data[0];\n    const double effective_scale_2 = state_params->scale->data[0] *\n                                     weight_time_params->scale->data[0] /\n                                     output_params->scale->data[0];\n    QuantizeMultiplier(effective_scale_1, &op_data->effective_scale_1_a,\n                       &op_data->effective_scale_1_b);\n    QuantizeMultiplier(effective_scale_2, &op_data->effective_scale_2_a,\n                       &op_data->effective_scale_2_b);\n  }\n  return kTfLiteOk;\n}",
        "func_hash": 233995710646174347190469029723118566827,
        "file_name": "svdf.cc",
        "file_hash": 151141611170941646620182312728274364600,
        "cwe": [
            "CWE-908"
        ],
        "cve": "CVE-2021-37682",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions all TFLite operations that use quantization can be made to use unitialized values. [For example](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/lite/kernels/depthwise_conv.cc#L198-L200). The issue stems from the fact that `quantization.params` is only valid if `quantization.type` is different that `kTfLiteNoQuantization`. However, these checks are missing in large parts of the code. We have patched the issue in GitHub commits 537bc7c723439b9194a358f64d871dd326c18887, 4a91f2069f7145aab6ba2d8cfe41be8a110c18a5 and 8933b8a21280696ab119b63263babdb54c298538. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37682",
        "func_name": "Prepare",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 197247,
        "project": "tensorflow",
        "commit_id": "ee119d4a498979525046fba1c3dd3f13a039fbb1",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/ee119d4a498979525046fba1c3dd3f13a039fbb1",
        "commit_message": "Fix segmentation fault in shape inference logic.\n\nWhen running shape functions, some functions (such as `MutableHashTableShape`)\nproduce extra output information in the form of a `ShapeAndType` struct.  The\nshapes embedded in this struct are owned by an inference context that is\ncleaned up almost immediately; if the upstream code attempts to access this\nshape information, it can trigger a segfault.\n\n`ShapeRefiner` is mitigating this for normal output shapes by cloning them\n(and thus putting the newly created shape under ownership of an inference\ncontext that will not die), but we were not doing the same for shapes and\ntypes.  This commit fixes that by doing similar logic on output shapes and\ntypes.\n\nPiperOrigin-RevId: 384761124\nChange-Id: I07c0c42d29dfbb55bfa13ec1f09ef825fb0a1a1d",
        "target": 1,
        "irrelevant": 1,
        "func_before": "Status ShapeRefiner::InferShapesForFunctionSubNode(\n    const Node* node, InferenceContext* outer_context) {\n  TF_RETURN_IF_ERROR(AddNodeInternal(node, outer_context));\n  InferenceContext* node_context = CHECK_NOTNULL(GetContext(node));\n\n  if (StringPiece(node->type_string()) == kArgOp) {\n    // Handle special node: function input.\n    // Shapes for these nodes are provided in the outer inference\n    // context.\n\n    int index;\n    TF_RETURN_IF_ERROR(GetNodeAttr(AttrSlice(node->def()), \"index\", &index));\n\n    if (index < 0 || outer_context->num_inputs() <= index) {\n      return errors::Internal(\n          \"Function instantiation included invalid input index: \", index,\n          \" not in [0, \", outer_context->num_inputs(), \").\");\n    }\n\n    // TODO(b/134547156): TEMPORARY WORKAROUND. If input shape handle is not set\n    // in outer context, set _Arg node output shape to unknown.\n    if (outer_context->input(index).SameHandle(ShapeHandle())) {\n      VLOG(1) << \"Function instantiation has undefined input shape at \"\n              << \"index: \" << index << \" in the outer inference context.\";\n      node_context->set_output(0, node_context->UnknownShape());\n    } else {\n      node_context->set_output(0, outer_context->input(index));\n    }\n\n    auto* resource = outer_context->input_handle_shapes_and_types(index);\n    if (resource) {\n      node_context->set_output_handle_shapes_and_types(0, *resource);\n    }\n  } else if (StringPiece(node->type_string()) == kRetvalOp) {\n    // Handle special node: function output.\n    // Shapes inferred for these nodes go into the outer inference\n    // context.\n\n    int index;\n    TF_RETURN_IF_ERROR(GetNodeAttr(AttrSlice(node->def()), \"index\", &index));\n\n    if (index < 0 || outer_context->num_outputs() <= index) {\n      return errors::Internal(\n          \"Function instantiation included invalid output index: \", index,\n          \" not in [0, \", outer_context->num_outputs(), \").\");\n    }\n\n    // outer_context outlives node_context, therefore we need to create\n    // a new shape handle owned by outer_context instead.\n    ShapeHandle handle;\n    TensorShapeProto proto;\n    node_context->ShapeHandleToProto(node_context->input(0), &proto);\n    TF_RETURN_IF_ERROR(outer_context->MakeShapeFromShapeProto(proto, &handle));\n    outer_context->set_output(index, handle);\n\n    auto* resource = node_context->input_handle_shapes_and_types(0);\n    if (resource) {\n      outer_context->set_output_handle_shapes_and_types(index, *resource);\n    }\n  }\n\n  return Status::OK();\n}",
        "func_hash": 296174489268649475183296977682065052967,
        "file_name": "shape_refiner.cc",
        "file_hash": null,
        "cwe": [
            "CWE-369"
        ],
        "cve": "CVE-2021-37690",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions when running shape functions, some functions (such as `MutableHashTableShape`) produce extra output information in the form of a `ShapeAndType` struct. The shapes embedded in this struct are owned by an inference context that is cleaned up almost immediately; if the upstream code attempts to access this shape information, it can trigger a segfault. `ShapeRefiner` is mitigating this for normal output shapes by cloning them (and thus putting the newly created shape under ownership of an inference context that will not die), but we were not doing the same for shapes and types. This commit fixes that by doing similar logic on output shapes and types. We have patched the issue in GitHub commit ee119d4a498979525046fba1c3dd3f13a039fbb1. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37690",
        "func_name": "ShapeRefiner::InferShapesForFunctionSubNode",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 197262,
        "project": "tensorflow",
        "commit_id": "e6cf28c72ba2eb949ca950d834dd6d66bb01cfae",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/e6cf28c72ba2eb949ca950d834dd6d66bb01cfae",
        "commit_message": "Validate that matrix dimension sizes in SparseMatMul are positive.\n\nPiperOrigin-RevId: 401149683\nChange-Id: Ib33eafc561a39c8741ece80b2edce6d4aae9a57d",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor& a = ctx->input(0);\n    const Tensor& b = ctx->input(1);\n    OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(a.shape()),\n                errors::InvalidArgument(\"a is not a matrix\"));\n    OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(b.shape()),\n                errors::InvalidArgument(\"b is not a matrix\"));\n\n    const int m = transpose_a_ ? a.dim_size(1) : a.dim_size(0);\n    const int k = transpose_a_ ? a.dim_size(0) : a.dim_size(1);\n    const int n = transpose_b_ ? b.dim_size(0) : b.dim_size(1);\n    const int k2 = transpose_b_ ? b.dim_size(1) : b.dim_size(0);\n\n    OP_REQUIRES(ctx, k == k2,\n                errors::InvalidArgument(\n                    \"Matrix size incompatible: a: \", a.shape().DebugString(),\n                    \", b: \", b.shape().DebugString()));\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, TensorShape({m, n}), &output));\n\n    if (k == 0) {\n      // If the inner dimension k in the matrix multiplication is zero, we fill\n      // the output with zeros.\n      functor::SetZeroFunctor<CPUDevice, float> f;\n      f(ctx->eigen_device<CPUDevice>(), output->flat<float>());\n      return;\n    }\n\n    auto out = output->matrix<float>();\n\n    std::unique_ptr<Tensor> a_float;\n    std::unique_ptr<Tensor> b_float;\n    if (!a_is_sparse_ && !b_is_sparse_) {\n      auto left = &a;\n      auto right = &b;\n      // TODO(agarwal): multi-thread the conversions from bfloat16 to float.\n      if (std::is_same<TL, bfloat16>::value) {\n        a_float.reset(new Tensor(DT_FLOAT, a.shape()));\n        BFloat16ToFloat(a.flat<bfloat16>().data(),\n                        a_float->flat<float>().data(), a.NumElements());\n        left = a_float.get();\n      }\n      if (std::is_same<TR, bfloat16>::value) {\n        b_float.reset(new Tensor(DT_FLOAT, b.shape()));\n        BFloat16ToFloat(b.flat<bfloat16>().data(),\n                        b_float->flat<float>().data(), b.NumElements());\n        right = b_float.get();\n      }\n      Eigen::array<Eigen::IndexPair<Eigen::DenseIndex>, 1> dim_pair;\n      dim_pair[0].first = transpose_a_ ? 0 : 1;\n      dim_pair[0].second = transpose_b_ ? 1 : 0;\n\n      out.device(ctx->template eigen_device<CPUDevice>()) =\n          left->matrix<float>().contract(right->matrix<float>(), dim_pair);\n      return;\n    }\n\n    auto left = &a;\n    auto right = &b;\n    bool transpose_output = false;\n    bool transpose_a = transpose_a_;\n    bool transpose_b = transpose_b_;\n    if (!a_is_sparse_) {\n      // Swap the order of multiplications using the identity:\n      // A * B = (B' *  A')'.\n      std::swap(left, right);\n      std::swap(transpose_a, transpose_b);\n      transpose_a = !transpose_a;\n      transpose_b = !transpose_b;\n      transpose_output = !transpose_output;\n    }\n\n    std::unique_ptr<Tensor> right_tr;\n    if (transpose_b) {\n      // TODO(agarwal): avoid transposing the matrix here and directly handle\n      // transpose in CreateDenseSlices.\n      OP_REQUIRES(ctx, right->dim_size(0) != 0,\n                  errors::InvalidArgument(\"b has an entry 0 in it's shape.\"));\n      OP_REQUIRES(ctx, right->dim_size(1) != 0,\n                  errors::InvalidArgument(\"b has an entry 0 in it's shape.\"));\n      right_tr.reset(\n          new Tensor(right->dtype(),\n                     TensorShape({right->dim_size(1), right->dim_size(0)})));\n\n      const auto perm = dsizes_10();\n      if (transpose_output) {\n        right_tr->matrix<TL>().device(ctx->template eigen_device<CPUDevice>()) =\n            right->matrix<TL>().shuffle(perm);\n      } else {\n        right_tr->matrix<TR>().device(ctx->template eigen_device<CPUDevice>()) =\n            right->matrix<TR>().shuffle(perm);\n      }\n      right = right_tr.get();\n    }\n\n    if (transpose_output) {\n      DoMatMul<TR, TL>::Compute(&this->cache_tr_, left->matrix<TR>(),\n                                right->matrix<TL>(), transpose_a,\n                                ctx->device()->tensorflow_cpu_worker_threads(),\n                                transpose_output, &out);\n    } else {\n      DoMatMul<TL, TR>::Compute(&this->cache_nt_, left->matrix<TL>(),\n                                right->matrix<TR>(), transpose_a,\n                                ctx->device()->tensorflow_cpu_worker_threads(),\n                                transpose_output, &out);\n    }\n  }",
        "func_hash": 281398484697111962957982643274603954439,
        "file_name": "sparse_matmul_op.cc",
        "file_hash": 108103579052154515117474451671828260520,
        "cwe": [
            "CWE-125"
        ],
        "cve": "CVE-2021-41219",
        "cve_desc": "TensorFlow is an open source platform for machine learning. In affected versions the code for sparse matrix multiplication is vulnerable to undefined behavior via binding a reference to `nullptr`. This occurs whenever the dimensions of `a` or `b` are 0 or less. In the case on one of these is 0, an empty output tensor should be allocated (to conserve the invariant that output tensors are always allocated when the operation is successful) but nothing should be written to it (that is, we should return early from the kernel implementation). Otherwise, attempts to write to this empty tensor would result in heap OOB access. The fix will be included in TensorFlow 2.7.0. We will also cherrypick this commit on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-41219",
        "func_name": "Compute",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 197305,
        "project": "pjproject",
        "commit_id": "11559e49e65bdf00922ad5ae28913ec6a198d508",
        "project_url": "https://github.com/pjsip/pjproject",
        "commit_url": "https://github.com/pjsip/pjproject/commit/11559e49e65bdf00922ad5ae28913ec6a198d508",
        "commit_message": "Merge pull request from GHSA-vhxv-phmx-g52q\n\n* Prevent OOB read/write when parsing RTCP FB RPSI\n\n* Add log information\n\n* Modification based on comments.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "PJ_DEF(pj_status_t) pjmedia_rtcp_fb_parse_rpsi(\n\t\t\t\t\tconst void *buf,\n\t\t\t\t\tpj_size_t length,\n\t\t\t\t\tpjmedia_rtcp_fb_rpsi *rpsi)\n{\n    pjmedia_rtcp_common *hdr = (pjmedia_rtcp_common*) buf;\n    pj_uint8_t *p;\n    pj_uint8_t padlen;\n    pj_size_t rpsi_len;\n\n    PJ_ASSERT_RETURN(buf && rpsi, PJ_EINVAL);\n    PJ_ASSERT_RETURN(length >= sizeof(pjmedia_rtcp_common), PJ_ETOOSMALL);\n\n    /* RPSI uses pt==RTCP_PSFB and FMT==3 */\n    if (hdr->pt != RTCP_PSFB || hdr->count != 3)\n\treturn PJ_ENOTFOUND;\n\n    rpsi_len = (pj_ntohs((pj_uint16_t)hdr->length)-2) * 4;\n    if (length < rpsi_len + 12)\n\treturn PJ_ETOOSMALL;\n\n    p = (pj_uint8_t*)hdr + sizeof(*hdr);\n    padlen = *p++;\n    rpsi->pt = (*p++ & 0x7F);\n    rpsi->rpsi_bit_len = rpsi_len*8 - 16 - padlen;\n    pj_strset(&rpsi->rpsi, (char*)p, (rpsi->rpsi_bit_len + 7)/8);\n\n    return PJ_SUCCESS;\n}",
        "func_hash": 36256848360171648205913357387602986017,
        "file_name": "rtcp_fb.c",
        "file_hash": 8904386284990700433551187598162654514,
        "cwe": [
            "CWE-200"
        ],
        "cve": "CVE-2022-24786",
        "cve_desc": "PJSIP is a free and open source multimedia communication library written in C. PJSIP versions 2.12 and prior do not parse incoming RTCP feedback RPSI (Reference Picture Selection Indication) packet, but any app that directly uses pjmedia_rtcp_fb_parse_rpsi() will be affected. A patch is available in the `master` branch of the `pjsip/pjproject` GitHub repository. There are currently no known workarounds.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-24786",
        "func_name": "PJ_DEF",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 200287,
        "project": "linux",
        "commit_id": "d6d86830705f173fca6087a3e67ceaf68db80523",
        "project_url": "https://github.com/torvalds/linux",
        "commit_url": "https://github.com/torvalds/linux/commit/d6d86830705f173fca6087a3e67ceaf68db80523",
        "commit_message": "net ticp:fix a kernel-infoleak in __tipc_sendmsg()\n\nstruct tipc_socket_addr.ref has a 4-byte hole,and __tipc_getname() currently\ncopying it to user space,causing kernel-infoleak.\n\nBUG: KMSAN: kernel-infoleak in instrument_copy_to_user include/linux/instrumented.h:121 [inline]\nBUG: KMSAN: kernel-infoleak in instrument_copy_to_user include/linux/instrumented.h:121 [inline] lib/usercopy.c:33\nBUG: KMSAN: kernel-infoleak in _copy_to_user+0x1c9/0x270 lib/usercopy.c:33 lib/usercopy.c:33\n instrument_copy_to_user include/linux/instrumented.h:121 [inline]\n instrument_copy_to_user include/linux/instrumented.h:121 [inline] lib/usercopy.c:33\n _copy_to_user+0x1c9/0x270 lib/usercopy.c:33 lib/usercopy.c:33\n copy_to_user include/linux/uaccess.h:209 [inline]\n copy_to_user include/linux/uaccess.h:209 [inline] net/socket.c:287\n move_addr_to_user+0x3f6/0x600 net/socket.c:287 net/socket.c:287\n __sys_getpeername+0x470/0x6b0 net/socket.c:1987 net/socket.c:1987\n __do_sys_getpeername net/socket.c:1997 [inline]\n __se_sys_getpeername net/socket.c:1994 [inline]\n __do_sys_getpeername net/socket.c:1997 [inline] net/socket.c:1994\n __se_sys_getpeername net/socket.c:1994 [inline] net/socket.c:1994\n __x64_sys_getpeername+0xda/0x120 net/socket.c:1994 net/socket.c:1994\n do_syscall_x64 arch/x86/entry/common.c:51 [inline]\n do_syscall_x64 arch/x86/entry/common.c:51 [inline] arch/x86/entry/common.c:82\n do_syscall_64+0x54/0xd0 arch/x86/entry/common.c:82 arch/x86/entry/common.c:82\n entry_SYSCALL_64_after_hwframe+0x44/0xae\n\nUninit was stored to memory at:\n tipc_getname+0x575/0x5e0 net/tipc/socket.c:757 net/tipc/socket.c:757\n __sys_getpeername+0x3b3/0x6b0 net/socket.c:1984 net/socket.c:1984\n __do_sys_getpeername net/socket.c:1997 [inline]\n __se_sys_getpeername net/socket.c:1994 [inline]\n __do_sys_getpeername net/socket.c:1997 [inline] net/socket.c:1994\n __se_sys_getpeername net/socket.c:1994 [inline] net/socket.c:1994\n __x64_sys_getpeername+0xda/0x120 net/socket.c:1994 net/socket.c:1994\n do_syscall_x64 arch/x86/entry/common.c:51 [inline]\n do_syscall_x64 arch/x86/entry/common.c:51 [inline] arch/x86/entry/common.c:82\n do_syscall_64+0x54/0xd0 arch/x86/entry/common.c:82 arch/x86/entry/common.c:82\n entry_SYSCALL_64_after_hwframe+0x44/0xae\n\nUninit was stored to memory at:\n msg_set_word net/tipc/msg.h:212 [inline]\n msg_set_destport net/tipc/msg.h:619 [inline]\n msg_set_word net/tipc/msg.h:212 [inline] net/tipc/socket.c:1486\n msg_set_destport net/tipc/msg.h:619 [inline] net/tipc/socket.c:1486\n __tipc_sendmsg+0x44fa/0x5890 net/tipc/socket.c:1486 net/tipc/socket.c:1486\n tipc_sendmsg+0xeb/0x140 net/tipc/socket.c:1402 net/tipc/socket.c:1402\n sock_sendmsg_nosec net/socket.c:704 [inline]\n sock_sendmsg net/socket.c:724 [inline]\n sock_sendmsg_nosec net/socket.c:704 [inline] net/socket.c:2409\n sock_sendmsg net/socket.c:724 [inline] net/socket.c:2409\n ____sys_sendmsg+0xe11/0x12c0 net/socket.c:2409 net/socket.c:2409\n ___sys_sendmsg net/socket.c:2463 [inline]\n ___sys_sendmsg net/socket.c:2463 [inline] net/socket.c:2492\n __sys_sendmsg+0x704/0x840 net/socket.c:2492 net/socket.c:2492\n __do_sys_sendmsg net/socket.c:2501 [inline]\n __se_sys_sendmsg net/socket.c:2499 [inline]\n __do_sys_sendmsg net/socket.c:2501 [inline] net/socket.c:2499\n __se_sys_sendmsg net/socket.c:2499 [inline] net/socket.c:2499\n __x64_sys_sendmsg+0xe2/0x120 net/socket.c:2499 net/socket.c:2499\n do_syscall_x64 arch/x86/entry/common.c:51 [inline]\n do_syscall_x64 arch/x86/entry/common.c:51 [inline] arch/x86/entry/common.c:82\n do_syscall_64+0x54/0xd0 arch/x86/entry/common.c:82 arch/x86/entry/common.c:82\n entry_SYSCALL_64_after_hwframe+0x44/0xae\n\nLocal variable skaddr created at:\n __tipc_sendmsg+0x2d0/0x5890 net/tipc/socket.c:1419 net/tipc/socket.c:1419\n tipc_sendmsg+0xeb/0x140 net/tipc/socket.c:1402 net/tipc/socket.c:1402\n\nBytes 4-7 of 16 are uninitialized\nMemory access of size 16 starts at ffff888113753e00\nData copied to user address 0000000020000280\n\nReported-by: syzbot+cdbd40e0c3ca02cae3b7@syzkaller.appspotmail.com\nSigned-off-by: Haimin Zhang <tcs_kernel@tencent.com>\nAcked-by: Jon Maloy <jmaloy@redhat.com>\nLink: https://lore.kernel.org/r/1640918123-14547-1-git-send-email-tcs.kernel@gmail.com\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static int __tipc_sendmsg(struct socket *sock, struct msghdr *m, size_t dlen)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct net *net = sock_net(sk);\n\tstruct tipc_sock *tsk = tipc_sk(sk);\n\tstruct tipc_uaddr *ua = (struct tipc_uaddr *)m->msg_name;\n\tlong timeout = sock_sndtimeo(sk, m->msg_flags & MSG_DONTWAIT);\n\tstruct list_head *clinks = &tsk->cong_links;\n\tbool syn = !tipc_sk_type_connectionless(sk);\n\tstruct tipc_group *grp = tsk->group;\n\tstruct tipc_msg *hdr = &tsk->phdr;\n\tstruct tipc_socket_addr skaddr;\n\tstruct sk_buff_head pkts;\n\tint atype, mtu, rc;\n\n\tif (unlikely(dlen > TIPC_MAX_USER_MSG_SIZE))\n\t\treturn -EMSGSIZE;\n\n\tif (ua) {\n\t\tif (!tipc_uaddr_valid(ua, m->msg_namelen))\n\t\t\treturn -EINVAL;\n\t\tatype = ua->addrtype;\n\t}\n\n\t/* If socket belongs to a communication group follow other paths */\n\tif (grp) {\n\t\tif (!ua)\n\t\t\treturn tipc_send_group_bcast(sock, m, dlen, timeout);\n\t\tif (atype == TIPC_SERVICE_ADDR)\n\t\t\treturn tipc_send_group_anycast(sock, m, dlen, timeout);\n\t\tif (atype == TIPC_SOCKET_ADDR)\n\t\t\treturn tipc_send_group_unicast(sock, m, dlen, timeout);\n\t\tif (atype == TIPC_SERVICE_RANGE)\n\t\t\treturn tipc_send_group_mcast(sock, m, dlen, timeout);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!ua) {\n\t\tua = (struct tipc_uaddr *)&tsk->peer;\n\t\tif (!syn && ua->family != AF_TIPC)\n\t\t\treturn -EDESTADDRREQ;\n\t\tatype = ua->addrtype;\n\t}\n\n\tif (unlikely(syn)) {\n\t\tif (sk->sk_state == TIPC_LISTEN)\n\t\t\treturn -EPIPE;\n\t\tif (sk->sk_state != TIPC_OPEN)\n\t\t\treturn -EISCONN;\n\t\tif (tsk->published)\n\t\t\treturn -EOPNOTSUPP;\n\t\tif (atype == TIPC_SERVICE_ADDR)\n\t\t\ttsk->conn_addrtype = atype;\n\t\tmsg_set_syn(hdr, 1);\n\t}\n\n\t/* Determine destination */\n\tif (atype == TIPC_SERVICE_RANGE) {\n\t\treturn tipc_sendmcast(sock, ua, m, dlen, timeout);\n\t} else if (atype == TIPC_SERVICE_ADDR) {\n\t\tskaddr.node = ua->lookup_node;\n\t\tua->scope = tipc_node2scope(skaddr.node);\n\t\tif (!tipc_nametbl_lookup_anycast(net, ua, &skaddr))\n\t\t\treturn -EHOSTUNREACH;\n\t} else if (atype == TIPC_SOCKET_ADDR) {\n\t\tskaddr = ua->sk;\n\t} else {\n\t\treturn -EINVAL;\n\t}\n\n\t/* Block or return if destination link is congested */\n\trc = tipc_wait_for_cond(sock, &timeout,\n\t\t\t\t!tipc_dest_find(clinks, skaddr.node, 0));\n\tif (unlikely(rc))\n\t\treturn rc;\n\n\t/* Finally build message header */\n\tmsg_set_destnode(hdr, skaddr.node);\n\tmsg_set_destport(hdr, skaddr.ref);\n\tif (atype == TIPC_SERVICE_ADDR) {\n\t\tmsg_set_type(hdr, TIPC_NAMED_MSG);\n\t\tmsg_set_hdr_sz(hdr, NAMED_H_SIZE);\n\t\tmsg_set_nametype(hdr, ua->sa.type);\n\t\tmsg_set_nameinst(hdr, ua->sa.instance);\n\t\tmsg_set_lookup_scope(hdr, ua->scope);\n\t} else { /* TIPC_SOCKET_ADDR */\n\t\tmsg_set_type(hdr, TIPC_DIRECT_MSG);\n\t\tmsg_set_lookup_scope(hdr, 0);\n\t\tmsg_set_hdr_sz(hdr, BASIC_H_SIZE);\n\t}\n\n\t/* Add message body */\n\t__skb_queue_head_init(&pkts);\n\tmtu = tipc_node_get_mtu(net, skaddr.node, tsk->portid, true);\n\trc = tipc_msg_build(hdr, m, 0, dlen, mtu, &pkts);\n\tif (unlikely(rc != dlen))\n\t\treturn rc;\n\tif (unlikely(syn && !tipc_msg_skb_clone(&pkts, &sk->sk_write_queue))) {\n\t\t__skb_queue_purge(&pkts);\n\t\treturn -ENOMEM;\n\t}\n\n\t/* Send message */\n\ttrace_tipc_sk_sendmsg(sk, skb_peek(&pkts), TIPC_DUMP_SK_SNDQ, \" \");\n\trc = tipc_node_xmit(net, &pkts, skaddr.node, tsk->portid);\n\tif (unlikely(rc == -ELINKCONG)) {\n\t\ttipc_dest_push(clinks, skaddr.node, 0);\n\t\ttsk->cong_link_cnt++;\n\t\trc = 0;\n\t}\n\n\tif (unlikely(syn && !rc)) {\n\t\ttipc_set_sk_state(sk, TIPC_CONNECTING);\n\t\tif (dlen && timeout) {\n\t\t\ttimeout = msecs_to_jiffies(timeout);\n\t\t\ttipc_wait_for_connect(sock, &timeout);\n\t\t}\n\t}\n\n\treturn rc ? rc : dlen;\n}",
        "func_hash": 187316583908925875095721276140565552990,
        "file_name": "socket.c",
        "file_hash": 211909288028562459580061336771266741769,
        "cwe": [
            "CWE-200"
        ],
        "cve": "CVE-2022-0382",
        "cve_desc": "An information leak flaw was found due to uninitialized memory in the Linux kernel's TIPC protocol subsystem, in the way a user sends a TIPC datagram to one or more destinations. This flaw allows a local user to read some kernel memory. This issue is limited to no more than 7 bytes, and the user cannot control what is read. This flaw affects the Linux kernel versions prior to 5.17-rc1.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-0382",
        "func_name": "__tipc_sendmsg",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 200305,
        "project": "ghostpdl",
        "commit_id": "2793769ff107d8d22dadd30c6e68cd781b569550",
        "project_url": "https://github.com/ArtifexSoftware/ghostpdl",
        "commit_url": "https://git.ghostscript.com/?p=ghostpdl.git;a=commitdiff;h=2793769ff107d8d22dadd30c6e68cd781b569550",
        "commit_message": "Bug 701819: fixed ordering in if expression to avoid out-of-bounds access.\n\nFixes:\n    ./sanbin/gs -dBATCH -dNOPAUSE -r965 -sOutputFile=tmp -sDEVICE=pcx16 ../bug-701819.pdf",
        "target": 1,
        "irrelevant": 0,
        "func_before": "pcx_write_rle(const byte * from, const byte * end, int step, gp_file * file)\n{\t\t\t\t/*\n                                 * The PCX format theoretically allows encoding runs of 63\n                                 * identical bytes, but some readers can't handle repetition\n                                 * counts greater than 15.\n                                 */\n#define MAX_RUN_COUNT 15\n    int max_run = step * MAX_RUN_COUNT;\n\n    while (from < end) {\n        byte data = *from;\n\n        from += step;\n        if (data != *from || from == end) {\n            if (data >= 0xc0)\n                gp_fputc(0xc1, file);\n        } else {\n            const byte *start = from;\n\n            while ((from < end) && (*from == data))\n                from += step;\n            /* Now (from - start) / step + 1 is the run length. */\n            while (from - start >= max_run) {\n                gp_fputc(0xc0 + MAX_RUN_COUNT, file);\n                gp_fputc(data, file);\n                start += max_run;\n            }\n            if (from > start || data >= 0xc0)\n                gp_fputc((from - start) / step + 0xc1, file);\n        }\n        gp_fputc(data, file);\n    }\n#undef MAX_RUN_COUNT\n}",
        "func_hash": 302156343438902913796919673468889397004,
        "file_name": "gdevpcx.c",
        "file_hash": 193192744323180393354892924891696445092,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2020-16305",
        "cve_desc": "A buffer overflow vulnerability in pcx_write_rle() in contrib/japanese/gdev10v.c of Artifex Software GhostScript v9.50 allows a remote attacker to cause a denial of service via a crafted PDF file. This is fixed in v9.51.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2020-16305",
        "func_name": "pcx_write_rle",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 200320,
        "project": "samba",
        "commit_id": "eb50fb8f3bf670bd7d1cf8fd4368ef4a73083696",
        "project_url": "https://github.com/samba-team/samba",
        "commit_url": "http://git.samba.org/?p=samba.git;a=commitdiff;h=eb50fb8f3bf670bd7d1cf8fd4368ef4a73083696",
        "commit_message": "FSCTL_GET_SHADOW_COPY_DATA: Don't return 4 extra bytes at end\n\nlabels_data_count already accounts for the unicode null character at the\nend of the array. There is no need in adding space for it again.\n\nSigned-off-by: Christof Schmitt <christof.schmitt@us.ibm.com>\nReviewed-by: Jeremy Allison <jra@samba.org>\nReviewed-by: Simo Sorce <idra@samba.org>\n\nAutobuild-User(master): Jeremy Allison <jra@samba.org>\nAutobuild-Date(master): Tue Aug  6 04:03:17 CEST 2013 on sn-devel-104",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static NTSTATUS vfswrap_fsctl(struct vfs_handle_struct *handle,\n\t\t\t      struct files_struct *fsp,\n\t\t\t      TALLOC_CTX *ctx,\n\t\t\t      uint32_t function,\n\t\t\t      uint16_t req_flags, /* Needed for UNICODE ... */\n\t\t\t      const uint8_t *_in_data,\n\t\t\t      uint32_t in_len,\n\t\t\t      uint8_t **_out_data,\n\t\t\t      uint32_t max_out_len,\n\t\t\t      uint32_t *out_len)\n{\n\tconst char *in_data = (const char *)_in_data;\n\tchar **out_data = (char **)_out_data;\n\n\tswitch (function) {\n\tcase FSCTL_SET_SPARSE:\n\t{\n\t\tbool set_sparse = true;\n\t\tNTSTATUS status;\n\n\t\tif (in_len >= 1 && in_data[0] == 0) {\n\t\t\tset_sparse = false;\n\t\t}\n\n\t\tstatus = file_set_sparse(handle->conn, fsp, set_sparse);\n\t\t\n\t\tDEBUG(NT_STATUS_IS_OK(status) ? 10 : 9,\n\t\t      (\"FSCTL_SET_SPARSE: fname[%s] set[%u] - %s\\n\",\n\t\t       smb_fname_str_dbg(fsp->fsp_name), set_sparse, \n\t\t       nt_errstr(status)));\n\n\t\treturn status;\n\t}\n\n\tcase FSCTL_CREATE_OR_GET_OBJECT_ID:\n\t{\n\t\tunsigned char objid[16];\n\t\tchar *return_data = NULL;\n\n\t\t/* This should return the object-id on this file.\n\t\t * I think I'll make this be the inode+dev. JRA.\n\t\t */\n\n\t\tDEBUG(10,(\"FSCTL_CREATE_OR_GET_OBJECT_ID: called on %s\\n\",\n\t\t\t  fsp_fnum_dbg(fsp)));\n\n\t\t*out_len = (max_out_len >= 64) ? 64 : max_out_len;\n\t\t/* Hmmm, will this cause problems if less data asked for? */\n\t\treturn_data = talloc_array(ctx, char, 64);\n\t\tif (return_data == NULL) {\n\t\t\treturn NT_STATUS_NO_MEMORY;\n\t\t}\n\n\t\t/* For backwards compatibility only store the dev/inode. */\n\t\tpush_file_id_16(return_data, &fsp->file_id);\n\t\tmemcpy(return_data+16,create_volume_objectid(fsp->conn,objid),16);\n\t\tpush_file_id_16(return_data+32, &fsp->file_id);\n\t\t*out_data = return_data;\n\t\treturn NT_STATUS_OK;\n\t}\n\n\tcase FSCTL_GET_REPARSE_POINT:\n\t{\n\t\t/* Fail it with STATUS_NOT_A_REPARSE_POINT */\n\t\tDEBUG(10, (\"FSCTL_GET_REPARSE_POINT: called on %s. \"\n\t\t\t   \"Status: NOT_IMPLEMENTED\\n\", fsp_fnum_dbg(fsp)));\n\t\treturn NT_STATUS_NOT_A_REPARSE_POINT;\n\t}\n\n\tcase FSCTL_SET_REPARSE_POINT:\n\t{\n\t\t/* Fail it with STATUS_NOT_A_REPARSE_POINT */\n\t\tDEBUG(10, (\"FSCTL_SET_REPARSE_POINT: called on %s. \"\n\t\t\t   \"Status: NOT_IMPLEMENTED\\n\", fsp_fnum_dbg(fsp)));\n\t\treturn NT_STATUS_NOT_A_REPARSE_POINT;\n\t}\n\n\tcase FSCTL_GET_SHADOW_COPY_DATA:\n\t{\n\t\t/*\n\t\t * This is called to retrieve the number of Shadow Copies (a.k.a. snapshots)\n\t\t * and return their volume names.  If max_data_count is 16, then it is just\n\t\t * asking for the number of volumes and length of the combined names.\n\t\t *\n\t\t * pdata is the data allocated by our caller, but that uses\n\t\t * total_data_count (which is 0 in our case) rather than max_data_count.\n\t\t * Allocate the correct amount and return the pointer to let\n\t\t * it be deallocated when we return.\n\t\t */\n\t\tstruct shadow_copy_data *shadow_data = NULL;\n\t\tbool labels = False;\n\t\tuint32 labels_data_count = 0;\n\t\tuint32 i;\n\t\tchar *cur_pdata = NULL;\n\n\t\tif (max_out_len < 16) {\n\t\t\tDEBUG(0,(\"FSCTL_GET_SHADOW_COPY_DATA: max_data_count(%u) < 16 is invalid!\\n\",\n\t\t\t\tmax_out_len));\n\t\t\treturn NT_STATUS_INVALID_PARAMETER;\n\t\t}\n\n\t\tif (max_out_len > 16) {\n\t\t\tlabels = True;\n\t\t}\n\n\t\tshadow_data = talloc_zero(ctx, struct shadow_copy_data);\n\t\tif (shadow_data == NULL) {\n\t\t\tDEBUG(0,(\"TALLOC_ZERO() failed!\\n\"));\n\t\t\treturn NT_STATUS_NO_MEMORY;\n\t\t}\n\n\t\t/*\n\t\t * Call the VFS routine to actually do the work.\n\t\t */\n\t\tif (SMB_VFS_GET_SHADOW_COPY_DATA(fsp, shadow_data, labels)!=0) {\n\t\t\tTALLOC_FREE(shadow_data);\n\t\t\tif (errno == ENOSYS) {\n\t\t\t\tDEBUG(5,(\"FSCTL_GET_SHADOW_COPY_DATA: connectpath %s, not supported.\\n\", \n\t\t\t\t\tfsp->conn->connectpath));\n\t\t\t\treturn NT_STATUS_NOT_SUPPORTED;\n\t\t\t} else {\n\t\t\t\tDEBUG(0,(\"FSCTL_GET_SHADOW_COPY_DATA: connectpath %s, failed.\\n\", \n\t\t\t\t\tfsp->conn->connectpath));\n\t\t\t\treturn NT_STATUS_UNSUCCESSFUL;\n\t\t\t}\n\t\t}\n\n\t\tlabels_data_count = (shadow_data->num_volumes * 2 * \n\t\t\t\t\tsizeof(SHADOW_COPY_LABEL)) + 2;\n\n\t\tif (!labels) {\n\t\t\t*out_len = 16;\n\t\t} else {\n\t\t\t*out_len = 12 + labels_data_count + 4;\n\t\t}\n\n\t\tif (max_out_len < *out_len) {\n\t\t\tDEBUG(0,(\"FSCTL_GET_SHADOW_COPY_DATA: max_data_count(%u) too small (%u) bytes needed!\\n\",\n\t\t\t\tmax_out_len, *out_len));\n\t\t\tTALLOC_FREE(shadow_data);\n\t\t\treturn NT_STATUS_BUFFER_TOO_SMALL;\n\t\t}\n\n\t\tcur_pdata = talloc_zero_array(ctx, char, *out_len);\n\t\tif (cur_pdata == NULL) {\n\t\t\tTALLOC_FREE(shadow_data);\n\t\t\treturn NT_STATUS_NO_MEMORY;\n\t\t}\n\n\t\t*out_data = cur_pdata;\n\n\t\t/* num_volumes 4 bytes */\n\t\tSIVAL(cur_pdata, 0, shadow_data->num_volumes);\n\n\t\tif (labels) {\n\t\t\t/* num_labels 4 bytes */\n\t\t\tSIVAL(cur_pdata, 4, shadow_data->num_volumes);\n\t\t}\n\n\t\t/* needed_data_count 4 bytes */\n\t\tSIVAL(cur_pdata, 8, labels_data_count + 4);\n\n\t\tcur_pdata += 12;\n\n\t\tDEBUG(10,(\"FSCTL_GET_SHADOW_COPY_DATA: %u volumes for path[%s].\\n\",\n\t\t\t  shadow_data->num_volumes, fsp_str_dbg(fsp)));\n\t\tif (labels && shadow_data->labels) {\n\t\t\tfor (i=0; i<shadow_data->num_volumes; i++) {\n\t\t\t\tsrvstr_push(cur_pdata, req_flags,\n\t\t\t\t\t    cur_pdata, shadow_data->labels[i],\n\t\t\t\t\t    2 * sizeof(SHADOW_COPY_LABEL),\n\t\t\t\t\t    STR_UNICODE|STR_TERMINATE);\n\t\t\t\tcur_pdata += 2 * sizeof(SHADOW_COPY_LABEL);\n\t\t\t\tDEBUGADD(10,(\"Label[%u]: '%s'\\n\",i,shadow_data->labels[i]));\n\t\t\t}\n\t\t}\n\n\t\tTALLOC_FREE(shadow_data);\n\n\t\treturn NT_STATUS_OK;\n\t}\n\n\tcase FSCTL_FIND_FILES_BY_SID:\n\t{\n\t\t/* pretend this succeeded -\n\t\t *\n\t\t * we have to send back a list with all files owned by this SID\n\t\t *\n\t\t * but I have to check that --metze\n\t\t */\n\t\tstruct dom_sid sid;\n\t\tuid_t uid;\n\t\tsize_t sid_len;\n\n\t\tDEBUG(10, (\"FSCTL_FIND_FILES_BY_SID: called on %s\\n\",\n\t\t\t   fsp_fnum_dbg(fsp)));\n\n\t\tif (in_len < 8) {\n\t\t\t/* NT_STATUS_BUFFER_TOO_SMALL maybe? */\n\t\t\treturn NT_STATUS_INVALID_PARAMETER;\n\t\t}\n\n\t\tsid_len = MIN(in_len - 4,SID_MAX_SIZE);\n\n\t\t/* unknown 4 bytes: this is not the length of the sid :-(  */\n\t\t/*unknown = IVAL(pdata,0);*/\n\n\t\tif (!sid_parse(in_data + 4, sid_len, &sid)) {\n\t\t\treturn NT_STATUS_INVALID_PARAMETER;\n\t\t}\n\t\tDEBUGADD(10, (\"for SID: %s\\n\", sid_string_dbg(&sid)));\n\n\t\tif (!sid_to_uid(&sid, &uid)) {\n\t\t\tDEBUG(0,(\"sid_to_uid: failed, sid[%s] sid_len[%lu]\\n\",\n\t\t\t\t sid_string_dbg(&sid),\n\t\t\t\t (unsigned long)sid_len));\n\t\t\tuid = (-1);\n\t\t}\n\n\t\t/* we can take a look at the find source :-)\n\t\t *\n\t\t * find ./ -uid $uid  -name '*'   is what we need here\n\t\t *\n\t\t *\n\t\t * and send 4bytes len and then NULL terminated unicode strings\n\t\t * for each file\n\t\t *\n\t\t * but I don't know how to deal with the paged results\n\t\t * (maybe we can hang the result anywhere in the fsp struct)\n\t\t *\n\t\t * but I don't know how to deal with the paged results\n\t\t * (maybe we can hang the result anywhere in the fsp struct)\n\t\t *\n\t\t * we don't send all files at once\n\t\t * and at the next we should *not* start from the beginning,\n\t\t * so we have to cache the result\n\t\t *\n\t\t * --metze\n\t\t */\n\n\t\t/* this works for now... */\n\t\treturn NT_STATUS_OK;\n\t}\n\n\tcase FSCTL_QUERY_ALLOCATED_RANGES:\n\t{\n\t\t/* FIXME: This is just a dummy reply, telling that all of the\n\t\t * file is allocated. MKS cp needs that.\n\t\t * Adding the real allocated ranges via FIEMAP on Linux\n\t\t * and SEEK_DATA/SEEK_HOLE on Solaris is needed to make\n\t\t * this FSCTL correct for sparse files.\n\t\t */\n\t\tNTSTATUS status;\n\t\tuint64_t offset, length;\n\t\tchar *out_data_tmp = NULL;\n\n\t\tif (in_len != 16) {\n\t\t\tDEBUG(0,(\"FSCTL_QUERY_ALLOCATED_RANGES: data_count(%u) != 16 is invalid!\\n\",\n\t\t\t\tin_len));\n\t\t\treturn NT_STATUS_INVALID_PARAMETER;\n\t\t}\n\n\t\tif (max_out_len < 16) {\n\t\t\tDEBUG(0,(\"FSCTL_QUERY_ALLOCATED_RANGES: max_out_len (%u) < 16 is invalid!\\n\",\n\t\t\t\tmax_out_len));\n\t\t\treturn NT_STATUS_INVALID_PARAMETER;\n\t\t}\n\n\t\toffset = BVAL(in_data,0);\n\t\tlength = BVAL(in_data,8);\n\n\t\tif (offset + length < offset) {\n\t\t\t/* No 64-bit integer wrap. */\n\t\t\treturn NT_STATUS_INVALID_PARAMETER;\n\t\t}\n\n\t\t/* Shouldn't this be SMB_VFS_STAT ... ? */\n\t\tstatus = vfs_stat_fsp(fsp);\n\t\tif (!NT_STATUS_IS_OK(status)) {\n\t\t\treturn status;\n\t\t}\n\n\t\t*out_len = 16;\n\t\tout_data_tmp = talloc_array(ctx, char, *out_len);\n\t\tif (out_data_tmp == NULL) {\n\t\t\tDEBUG(10, (\"unable to allocate memory for response\\n\"));\n\t\t\treturn NT_STATUS_NO_MEMORY;\n\t\t}\n\n\t\tif (offset > fsp->fsp_name->st.st_ex_size ||\n\t\t\t\tfsp->fsp_name->st.st_ex_size == 0 ||\n\t\t\t\tlength == 0) {\n\t\t\tmemset(out_data_tmp, 0, *out_len);\n\t\t} else {\n\t\t\tuint64_t end = offset + length;\n\t\t\tend = MIN(end, fsp->fsp_name->st.st_ex_size);\n\t\t\tSBVAL(out_data_tmp, 0, 0);\n\t\t\tSBVAL(out_data_tmp, 8, end);\n\t\t}\n\n\t\t*out_data = out_data_tmp;\n\n\t\treturn NT_STATUS_OK;\n\t}\n\n\tcase FSCTL_IS_VOLUME_DIRTY:\n\t{\n\t\tDEBUG(10,(\"FSCTL_IS_VOLUME_DIRTY: called on %s \"\n\t\t\t  \"(but remotely not supported)\\n\", fsp_fnum_dbg(fsp)));\n\t\t/*\n\t\t * http://msdn.microsoft.com/en-us/library/cc232128%28PROT.10%29.aspx\n\t\t * says we have to respond with NT_STATUS_INVALID_PARAMETER\n\t\t */\n\t\treturn NT_STATUS_INVALID_PARAMETER;\n\t}\n\n\tdefault:\n\t\t/* \n\t\t * Only print once ... unfortunately there could be lots of\n\t\t * different FSCTLs that are called.\n\t\t */\n\t\tif (!vfswrap_logged_ioctl_message) {\n\t\t\tvfswrap_logged_ioctl_message = true;\n\t\t\tDEBUG(2, (\"%s (0x%x): Currently not implemented.\\n\",\n\t\t\t__func__, function));\n\t\t}\n\t}\n\n\treturn NT_STATUS_NOT_SUPPORTED;\n}",
        "func_hash": 216855121268945563940656517843611340199,
        "file_name": "vfs_default.c",
        "file_hash": 120656139704674873497493645428059774528,
        "cwe": [
            "CWE-665"
        ],
        "cve": "CVE-2014-0178",
        "cve_desc": "Samba 3.6.6 through 3.6.23, 4.0.x before 4.0.18, and 4.1.x before 4.1.8, when a certain vfs shadow copy configuration is enabled, does not properly initialize the SRV_SNAPSHOT_ARRAY response field, which allows remote authenticated users to obtain potentially sensitive information from process memory via a (1) FSCTL_GET_SHADOW_COPY_DATA or (2) FSCTL_SRV_ENUMERATE_SNAPSHOTS request.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2014-0178",
        "func_name": "vfswrap_fsctl",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 200323,
        "project": "vim",
        "commit_id": "156d3911952d73b03d7420dc3540215247db0fe8",
        "project_url": "https://github.com/vim/vim",
        "commit_url": "https://github.com/vim/vim/commit/156d3911952d73b03d7420dc3540215247db0fe8",
        "commit_message": "patch 8.2.5123: using invalid index when looking for spell suggestions\n\nProblem:    Using invalid index when looking for spell suggestions.\nSolution:   Do not decrement the index when it is zero.",
        "target": 1,
        "irrelevant": 1,
        "func_before": "suggest_trie_walk(\n    suginfo_T\t*su,\n    langp_T\t*lp,\n    char_u\t*fword,\n    int\t\tsoundfold)\n{\n    char_u\ttword[MAXWLEN];\t    // good word collected so far\n    trystate_T\tstack[MAXWLEN];\n    char_u\tpreword[MAXWLEN * 3]; // word found with proper case;\n\t\t\t\t      // concatenation of prefix compound\n\t\t\t\t      // words and split word.  NUL terminated\n\t\t\t\t      // when going deeper but not when coming\n\t\t\t\t      // back.\n    char_u\tcompflags[MAXWLEN];\t// compound flags, one for each word\n    trystate_T\t*sp;\n    int\t\tnewscore;\n    int\t\tscore;\n    char_u\t*byts, *fbyts, *pbyts;\n    idx_T\t*idxs, *fidxs, *pidxs;\n    int\t\tdepth;\n    int\t\tc, c2, c3;\n    int\t\tn = 0;\n    int\t\tflags;\n    garray_T\t*gap;\n    idx_T\tarridx;\n    int\t\tlen;\n    char_u\t*p;\n    fromto_T\t*ftp;\n    int\t\tfl = 0, tl;\n    int\t\trepextra = 0;\t    // extra bytes in fword[] from REP item\n    slang_T\t*slang = lp->lp_slang;\n    int\t\tfword_ends;\n    int\t\tgoodword_ends;\n#ifdef DEBUG_TRIEWALK\n    // Stores the name of the change made at each level.\n    char_u\tchangename[MAXWLEN][80];\n#endif\n    int\t\tbreakcheckcount = 1000;\n#ifdef FEAT_RELTIME\n    proftime_T\ttime_limit;\n#endif\n    int\t\tcompound_ok;\n\n    // Go through the whole case-fold tree, try changes at each node.\n    // \"tword[]\" contains the word collected from nodes in the tree.\n    // \"fword[]\" the word we are trying to match with (initially the bad\n    // word).\n    depth = 0;\n    sp = &stack[0];\n    CLEAR_POINTER(sp);\n    sp->ts_curi = 1;\n\n    if (soundfold)\n    {\n\t// Going through the soundfold tree.\n\tbyts = fbyts = slang->sl_sbyts;\n\tidxs = fidxs = slang->sl_sidxs;\n\tpbyts = NULL;\n\tpidxs = NULL;\n\tsp->ts_prefixdepth = PFD_NOPREFIX;\n\tsp->ts_state = STATE_START;\n    }\n    else\n    {\n\t// When there are postponed prefixes we need to use these first.  At\n\t// the end of the prefix we continue in the case-fold tree.\n\tfbyts = slang->sl_fbyts;\n\tfidxs = slang->sl_fidxs;\n\tpbyts = slang->sl_pbyts;\n\tpidxs = slang->sl_pidxs;\n\tif (pbyts != NULL)\n\t{\n\t    byts = pbyts;\n\t    idxs = pidxs;\n\t    sp->ts_prefixdepth = PFD_PREFIXTREE;\n\t    sp->ts_state = STATE_NOPREFIX;\t// try without prefix first\n\t}\n\telse\n\t{\n\t    byts = fbyts;\n\t    idxs = fidxs;\n\t    sp->ts_prefixdepth = PFD_NOPREFIX;\n\t    sp->ts_state = STATE_START;\n\t}\n    }\n#ifdef FEAT_RELTIME\n    // The loop may take an indefinite amount of time. Break out after some\n    // time.\n    if (spell_suggest_timeout > 0)\n\tprofile_setlimit(spell_suggest_timeout, &time_limit);\n#endif\n\n    // Loop to find all suggestions.  At each round we either:\n    // - For the current state try one operation, advance \"ts_curi\",\n    //   increase \"depth\".\n    // - When a state is done go to the next, set \"ts_state\".\n    // - When all states are tried decrease \"depth\".\n    while (depth >= 0 && !got_int)\n    {\n\tsp = &stack[depth];\n\tswitch (sp->ts_state)\n\t{\n\tcase STATE_START:\n\tcase STATE_NOPREFIX:\n\t    // Start of node: Deal with NUL bytes, which means\n\t    // tword[] may end here.\n\t    arridx = sp->ts_arridx;\t    // current node in the tree\n\t    len = byts[arridx];\t\t    // bytes in this node\n\t    arridx += sp->ts_curi;\t    // index of current byte\n\n\t    if (sp->ts_prefixdepth == PFD_PREFIXTREE)\n\t    {\n\t\t// Skip over the NUL bytes, we use them later.\n\t\tfor (n = 0; n < len && byts[arridx + n] == 0; ++n)\n\t\t    ;\n\t\tsp->ts_curi += n;\n\n\t\t// Always past NUL bytes now.\n\t\tn = (int)sp->ts_state;\n\t\tPROF_STORE(sp->ts_state)\n\t\tsp->ts_state = STATE_ENDNUL;\n\t\tsp->ts_save_badflags = su->su_badflags;\n\n\t\t// At end of a prefix or at start of prefixtree: check for\n\t\t// following word.\n\t\tif (depth < MAXWLEN - 1\n\t\t\t    && (byts[arridx] == 0 || n == (int)STATE_NOPREFIX))\n\t\t{\n\t\t    // Set su->su_badflags to the caps type at this position.\n\t\t    // Use the caps type until here for the prefix itself.\n\t\t    if (has_mbyte)\n\t\t\tn = nofold_len(fword, sp->ts_fidx, su->su_badptr);\n\t\t    else\n\t\t\tn = sp->ts_fidx;\n\t\t    flags = badword_captype(su->su_badptr, su->su_badptr + n);\n\t\t    su->su_badflags = badword_captype(su->su_badptr + n,\n\t\t\t\t\t       su->su_badptr + su->su_badlen);\n#ifdef DEBUG_TRIEWALK\n\t\t    sprintf(changename[depth], \"prefix\");\n#endif\n\t\t    go_deeper(stack, depth, 0);\n\t\t    ++depth;\n\t\t    sp = &stack[depth];\n\t\t    sp->ts_prefixdepth = depth - 1;\n\t\t    byts = fbyts;\n\t\t    idxs = fidxs;\n\t\t    sp->ts_arridx = 0;\n\n\t\t    // Move the prefix to preword[] with the right case\n\t\t    // and make find_keepcap_word() works.\n\t\t    tword[sp->ts_twordlen] = NUL;\n\t\t    make_case_word(tword + sp->ts_splitoff,\n\t\t\t\t\t  preword + sp->ts_prewordlen, flags);\n\t\t    sp->ts_prewordlen = (char_u)STRLEN(preword);\n\t\t    sp->ts_splitoff = sp->ts_twordlen;\n\t\t}\n\t\tbreak;\n\t    }\n\n\t    if (sp->ts_curi > len || byts[arridx] != 0)\n\t    {\n\t\t// Past bytes in node and/or past NUL bytes.\n\t\tPROF_STORE(sp->ts_state)\n\t\tsp->ts_state = STATE_ENDNUL;\n\t\tsp->ts_save_badflags = su->su_badflags;\n\t\tbreak;\n\t    }\n\n\t    // End of word in tree.\n\t    ++sp->ts_curi;\t\t// eat one NUL byte\n\n\t    flags = (int)idxs[arridx];\n\n\t    // Skip words with the NOSUGGEST flag.\n\t    if (flags & WF_NOSUGGEST)\n\t\tbreak;\n\n\t    fword_ends = (fword[sp->ts_fidx] == NUL\n\t\t\t   || (soundfold\n\t\t\t       ? VIM_ISWHITE(fword[sp->ts_fidx])\n\t\t\t       : !spell_iswordp(fword + sp->ts_fidx, curwin)));\n\t    tword[sp->ts_twordlen] = NUL;\n\n\t    if (sp->ts_prefixdepth <= PFD_NOTSPECIAL\n\t\t\t\t\t&& (sp->ts_flags & TSF_PREFIXOK) == 0\n\t\t\t\t\t&& pbyts != NULL)\n\t    {\n\t\t// There was a prefix before the word.  Check that the prefix\n\t\t// can be used with this word.\n\t\t// Count the length of the NULs in the prefix.  If there are\n\t\t// none this must be the first try without a prefix.\n\t\tn = stack[sp->ts_prefixdepth].ts_arridx;\n\t\tlen = pbyts[n++];\n\t\tfor (c = 0; c < len && pbyts[n + c] == 0; ++c)\n\t\t    ;\n\t\tif (c > 0)\n\t\t{\n\t\t    c = valid_word_prefix(c, n, flags,\n\t\t\t\t       tword + sp->ts_splitoff, slang, FALSE);\n\t\t    if (c == 0)\n\t\t\tbreak;\n\n\t\t    // Use the WF_RARE flag for a rare prefix.\n\t\t    if (c & WF_RAREPFX)\n\t\t\tflags |= WF_RARE;\n\n\t\t    // Tricky: when checking for both prefix and compounding\n\t\t    // we run into the prefix flag first.\n\t\t    // Remember that it's OK, so that we accept the prefix\n\t\t    // when arriving at a compound flag.\n\t\t    sp->ts_flags |= TSF_PREFIXOK;\n\t\t}\n\t    }\n\n\t    // Check NEEDCOMPOUND: can't use word without compounding.  Do try\n\t    // appending another compound word below.\n\t    if (sp->ts_complen == sp->ts_compsplit && fword_ends\n\t\t\t\t\t\t     && (flags & WF_NEEDCOMP))\n\t\tgoodword_ends = FALSE;\n\t    else\n\t\tgoodword_ends = TRUE;\n\n\t    p = NULL;\n\t    compound_ok = TRUE;\n\t    if (sp->ts_complen > sp->ts_compsplit)\n\t    {\n\t\tif (slang->sl_nobreak)\n\t\t{\n\t\t    // There was a word before this word.  When there was no\n\t\t    // change in this word (it was correct) add the first word\n\t\t    // as a suggestion.  If this word was corrected too, we\n\t\t    // need to check if a correct word follows.\n\t\t    if (sp->ts_fidx - sp->ts_splitfidx\n\t\t\t\t\t  == sp->ts_twordlen - sp->ts_splitoff\n\t\t\t    && STRNCMP(fword + sp->ts_splitfidx,\n\t\t\t\t\ttword + sp->ts_splitoff,\n\t\t\t\t\t sp->ts_fidx - sp->ts_splitfidx) == 0)\n\t\t    {\n\t\t\tpreword[sp->ts_prewordlen] = NUL;\n\t\t\tnewscore = score_wordcount_adj(slang, sp->ts_score,\n\t\t\t\t\t\t preword + sp->ts_prewordlen,\n\t\t\t\t\t\t sp->ts_prewordlen > 0);\n\t\t\t// Add the suggestion if the score isn't too bad.\n\t\t\tif (newscore <= su->su_maxscore)\n\t\t\t    add_suggestion(su, &su->su_ga, preword,\n\t\t\t\t    sp->ts_splitfidx - repextra,\n\t\t\t\t    newscore, 0, FALSE,\n\t\t\t\t    lp->lp_sallang, FALSE);\n\t\t\tbreak;\n\t\t    }\n\t\t}\n\t\telse\n\t\t{\n\t\t    // There was a compound word before this word.  If this\n\t\t    // word does not support compounding then give up\n\t\t    // (splitting is tried for the word without compound\n\t\t    // flag).\n\t\t    if (((unsigned)flags >> 24) == 0\n\t\t\t    || sp->ts_twordlen - sp->ts_splitoff\n\t\t\t\t\t\t       < slang->sl_compminlen)\n\t\t\tbreak;\n\t\t    // For multi-byte chars check character length against\n\t\t    // COMPOUNDMIN.\n\t\t    if (has_mbyte\n\t\t\t    && slang->sl_compminlen > 0\n\t\t\t    && mb_charlen(tword + sp->ts_splitoff)\n\t\t\t\t\t\t       < slang->sl_compminlen)\n\t\t\tbreak;\n\n\t\t    compflags[sp->ts_complen] = ((unsigned)flags >> 24);\n\t\t    compflags[sp->ts_complen + 1] = NUL;\n\t\t    vim_strncpy(preword + sp->ts_prewordlen,\n\t\t\t    tword + sp->ts_splitoff,\n\t\t\t    sp->ts_twordlen - sp->ts_splitoff);\n\n\t\t    // Verify CHECKCOMPOUNDPATTERN  rules.\n\t\t    if (match_checkcompoundpattern(preword,  sp->ts_prewordlen,\n\t\t\t\t\t\t\t  &slang->sl_comppat))\n\t\t\tcompound_ok = FALSE;\n\n\t\t    if (compound_ok)\n\t\t    {\n\t\t\tp = preword;\n\t\t\twhile (*skiptowhite(p) != NUL)\n\t\t\t    p = skipwhite(skiptowhite(p));\n\t\t\tif (fword_ends && !can_compound(slang, p,\n\t\t\t\t\t\tcompflags + sp->ts_compsplit))\n\t\t\t    // Compound is not allowed.  But it may still be\n\t\t\t    // possible if we add another (short) word.\n\t\t\t    compound_ok = FALSE;\n\t\t    }\n\n\t\t    // Get pointer to last char of previous word.\n\t\t    p = preword + sp->ts_prewordlen;\n\t\t    MB_PTR_BACK(preword, p);\n\t\t}\n\t    }\n\n\t    // Form the word with proper case in preword.\n\t    // If there is a word from a previous split, append.\n\t    // For the soundfold tree don't change the case, simply append.\n\t    if (soundfold)\n\t\tSTRCPY(preword + sp->ts_prewordlen, tword + sp->ts_splitoff);\n\t    else if (flags & WF_KEEPCAP)\n\t\t// Must find the word in the keep-case tree.\n\t\tfind_keepcap_word(slang, tword + sp->ts_splitoff,\n\t\t\t\t\t\t preword + sp->ts_prewordlen);\n\t    else\n\t    {\n\t\t// Include badflags: If the badword is onecap or allcap\n\t\t// use that for the goodword too.  But if the badword is\n\t\t// allcap and it's only one char long use onecap.\n\t\tc = su->su_badflags;\n\t\tif ((c & WF_ALLCAP)\n\t\t\t&& su->su_badlen == (*mb_ptr2len)(su->su_badptr))\n\t\t    c = WF_ONECAP;\n\t\tc |= flags;\n\n\t\t// When appending a compound word after a word character don't\n\t\t// use Onecap.\n\t\tif (p != NULL && spell_iswordp_nmw(p, curwin))\n\t\t    c &= ~WF_ONECAP;\n\t\tmake_case_word(tword + sp->ts_splitoff,\n\t\t\t\t\t      preword + sp->ts_prewordlen, c);\n\t    }\n\n\t    if (!soundfold)\n\t    {\n\t\t// Don't use a banned word.  It may appear again as a good\n\t\t// word, thus remember it.\n\t\tif (flags & WF_BANNED)\n\t\t{\n\t\t    add_banned(su, preword + sp->ts_prewordlen);\n\t\t    break;\n\t\t}\n\t\tif ((sp->ts_complen == sp->ts_compsplit\n\t\t\t    && WAS_BANNED(su, preword + sp->ts_prewordlen))\n\t\t\t\t\t\t   || WAS_BANNED(su, preword))\n\t\t{\n\t\t    if (slang->sl_compprog == NULL)\n\t\t\tbreak;\n\t\t    // the word so far was banned but we may try compounding\n\t\t    goodword_ends = FALSE;\n\t\t}\n\t    }\n\n\t    newscore = 0;\n\t    if (!soundfold)\t// soundfold words don't have flags\n\t    {\n\t\tif ((flags & WF_REGION)\n\t\t\t    && (((unsigned)flags >> 16) & lp->lp_region) == 0)\n\t\t    newscore += SCORE_REGION;\n\t\tif (flags & WF_RARE)\n\t\t    newscore += SCORE_RARE;\n\n\t\tif (!spell_valid_case(su->su_badflags,\n\t\t\t\t  captype(preword + sp->ts_prewordlen, NULL)))\n\t\t    newscore += SCORE_ICASE;\n\t    }\n\n\t    // TODO: how about splitting in the soundfold tree?\n\t    if (fword_ends\n\t\t    && goodword_ends\n\t\t    && sp->ts_fidx >= sp->ts_fidxtry\n\t\t    && compound_ok)\n\t    {\n\t\t// The badword also ends: add suggestions.\n#ifdef DEBUG_TRIEWALK\n\t\tif (soundfold && STRCMP(preword, \"smwrd\") == 0)\n\t\t{\n\t\t    int\t    j;\n\n\t\t    // print the stack of changes that brought us here\n\t\t    smsg(\"------ %s -------\", fword);\n\t\t    for (j = 0; j < depth; ++j)\n\t\t\tsmsg(\"%s\", changename[j]);\n\t\t}\n#endif\n\t\tif (soundfold)\n\t\t{\n\t\t    // For soundfolded words we need to find the original\n\t\t    // words, the edit distance and then add them.\n\t\t    add_sound_suggest(su, preword, sp->ts_score, lp);\n\t\t}\n\t\telse if (sp->ts_fidx > 0)\n\t\t{\n\t\t    // Give a penalty when changing non-word char to word\n\t\t    // char, e.g., \"thes,\" -> \"these\".\n\t\t    p = fword + sp->ts_fidx;\n\t\t    MB_PTR_BACK(fword, p);\n\t\t    if (!spell_iswordp(p, curwin) && *preword != NUL)\n\t\t    {\n\t\t\tp = preword + STRLEN(preword);\n\t\t\tMB_PTR_BACK(preword, p);\n\t\t\tif (spell_iswordp(p, curwin))\n\t\t\t    newscore += SCORE_NONWORD;\n\t\t    }\n\n\t\t    // Give a bonus to words seen before.\n\t\t    score = score_wordcount_adj(slang,\n\t\t\t\t\t\tsp->ts_score + newscore,\n\t\t\t\t\t\tpreword + sp->ts_prewordlen,\n\t\t\t\t\t\tsp->ts_prewordlen > 0);\n\n\t\t    // Add the suggestion if the score isn't too bad.\n\t\t    if (score <= su->su_maxscore)\n\t\t    {\n\t\t\tadd_suggestion(su, &su->su_ga, preword,\n\t\t\t\t    sp->ts_fidx - repextra,\n\t\t\t\t    score, 0, FALSE, lp->lp_sallang, FALSE);\n\n\t\t\tif (su->su_badflags & WF_MIXCAP)\n\t\t\t{\n\t\t\t    // We really don't know if the word should be\n\t\t\t    // upper or lower case, add both.\n\t\t\t    c = captype(preword, NULL);\n\t\t\t    if (c == 0 || c == WF_ALLCAP)\n\t\t\t    {\n\t\t\t\tmake_case_word(tword + sp->ts_splitoff,\n\t\t\t\t\t      preword + sp->ts_prewordlen,\n\t\t\t\t\t\t      c == 0 ? WF_ALLCAP : 0);\n\n\t\t\t\tadd_suggestion(su, &su->su_ga, preword,\n\t\t\t\t\tsp->ts_fidx - repextra,\n\t\t\t\t\tscore + SCORE_ICASE, 0, FALSE,\n\t\t\t\t\tlp->lp_sallang, FALSE);\n\t\t\t    }\n\t\t\t}\n\t\t    }\n\t\t}\n\t    }\n\n\t    // Try word split and/or compounding.\n\t    if ((sp->ts_fidx >= sp->ts_fidxtry || fword_ends)\n\t\t    // Don't split halfway a character.\n\t\t    && (!has_mbyte || sp->ts_tcharlen == 0))\n\t    {\n\t\tint\ttry_compound;\n\t\tint\ttry_split;\n\n\t\t// If past the end of the bad word don't try a split.\n\t\t// Otherwise try changing the next word.  E.g., find\n\t\t// suggestions for \"the the\" where the second \"the\" is\n\t\t// different.  It's done like a split.\n\t\t// TODO: word split for soundfold words\n\t\ttry_split = (sp->ts_fidx - repextra < su->su_badlen)\n\t\t\t\t\t\t\t\t&& !soundfold;\n\n\t\t// Get here in several situations:\n\t\t// 1. The word in the tree ends:\n\t\t//    If the word allows compounding try that.  Otherwise try\n\t\t//    a split by inserting a space.  For both check that a\n\t\t//    valid words starts at fword[sp->ts_fidx].\n\t\t//    For NOBREAK do like compounding to be able to check if\n\t\t//    the next word is valid.\n\t\t// 2. The badword does end, but it was due to a change (e.g.,\n\t\t//    a swap).  No need to split, but do check that the\n\t\t//    following word is valid.\n\t\t// 3. The badword and the word in the tree end.  It may still\n\t\t//    be possible to compound another (short) word.\n\t\ttry_compound = FALSE;\n\t\tif (!soundfold\n\t\t\t&& !slang->sl_nocompoundsugs\n\t\t\t&& slang->sl_compprog != NULL\n\t\t\t&& ((unsigned)flags >> 24) != 0\n\t\t\t&& sp->ts_twordlen - sp->ts_splitoff\n\t\t\t\t\t\t       >= slang->sl_compminlen\n\t\t\t&& (!has_mbyte\n\t\t\t    || slang->sl_compminlen == 0\n\t\t\t    || mb_charlen(tword + sp->ts_splitoff)\n\t\t\t\t\t\t      >= slang->sl_compminlen)\n\t\t\t&& (slang->sl_compsylmax < MAXWLEN\n\t\t\t    || sp->ts_complen + 1 - sp->ts_compsplit\n\t\t\t\t\t\t\t  < slang->sl_compmax)\n\t\t\t&& (can_be_compound(sp, slang,\n\t\t\t\t\t compflags, ((unsigned)flags >> 24))))\n\n\t\t{\n\t\t    try_compound = TRUE;\n\t\t    compflags[sp->ts_complen] = ((unsigned)flags >> 24);\n\t\t    compflags[sp->ts_complen + 1] = NUL;\n\t\t}\n\n\t\t// For NOBREAK we never try splitting, it won't make any word\n\t\t// valid.\n\t\tif (slang->sl_nobreak && !slang->sl_nocompoundsugs)\n\t\t    try_compound = TRUE;\n\n\t\t// If we could add a compound word, and it's also possible to\n\t\t// split at this point, do the split first and set\n\t\t// TSF_DIDSPLIT to avoid doing it again.\n\t\telse if (!fword_ends\n\t\t\t&& try_compound\n\t\t\t&& (sp->ts_flags & TSF_DIDSPLIT) == 0)\n\t\t{\n\t\t    try_compound = FALSE;\n\t\t    sp->ts_flags |= TSF_DIDSPLIT;\n\t\t    --sp->ts_curi;\t    // do the same NUL again\n\t\t    compflags[sp->ts_complen] = NUL;\n\t\t}\n\t\telse\n\t\t    sp->ts_flags &= ~TSF_DIDSPLIT;\n\n\t\tif (try_split || try_compound)\n\t\t{\n\t\t    if (!try_compound && (!fword_ends || !goodword_ends))\n\t\t    {\n\t\t\t// If we're going to split need to check that the\n\t\t\t// words so far are valid for compounding.  If there\n\t\t\t// is only one word it must not have the NEEDCOMPOUND\n\t\t\t// flag.\n\t\t\tif (sp->ts_complen == sp->ts_compsplit\n\t\t\t\t\t\t     && (flags & WF_NEEDCOMP))\n\t\t\t    break;\n\t\t\tp = preword;\n\t\t\twhile (*skiptowhite(p) != NUL)\n\t\t\t    p = skipwhite(skiptowhite(p));\n\t\t\tif (sp->ts_complen > sp->ts_compsplit\n\t\t\t\t&& !can_compound(slang, p,\n\t\t\t\t\t\tcompflags + sp->ts_compsplit))\n\t\t\t    break;\n\n\t\t\tif (slang->sl_nosplitsugs)\n\t\t\t    newscore += SCORE_SPLIT_NO;\n\t\t\telse\n\t\t\t    newscore += SCORE_SPLIT;\n\n\t\t\t// Give a bonus to words seen before.\n\t\t\tnewscore = score_wordcount_adj(slang, newscore,\n\t\t\t\t\t   preword + sp->ts_prewordlen, TRUE);\n\t\t    }\n\n\t\t    if (TRY_DEEPER(su, stack, depth, newscore))\n\t\t    {\n\t\t\tgo_deeper(stack, depth, newscore);\n#ifdef DEBUG_TRIEWALK\n\t\t\tif (!try_compound && !fword_ends)\n\t\t\t    sprintf(changename[depth], \"%.*s-%s: split\",\n\t\t\t\t sp->ts_twordlen, tword, fword + sp->ts_fidx);\n\t\t\telse\n\t\t\t    sprintf(changename[depth], \"%.*s-%s: compound\",\n\t\t\t\t sp->ts_twordlen, tword, fword + sp->ts_fidx);\n#endif\n\t\t\t// Save things to be restored at STATE_SPLITUNDO.\n\t\t\tsp->ts_save_badflags = su->su_badflags;\n\t\t\tPROF_STORE(sp->ts_state)\n\t\t\tsp->ts_state = STATE_SPLITUNDO;\n\n\t\t\t++depth;\n\t\t\tsp = &stack[depth];\n\n\t\t\t// Append a space to preword when splitting.\n\t\t\tif (!try_compound && !fword_ends)\n\t\t\t    STRCAT(preword, \" \");\n\t\t\tsp->ts_prewordlen = (char_u)STRLEN(preword);\n\t\t\tsp->ts_splitoff = sp->ts_twordlen;\n\t\t\tsp->ts_splitfidx = sp->ts_fidx;\n\n\t\t\t// If the badword has a non-word character at this\n\t\t\t// position skip it.  That means replacing the\n\t\t\t// non-word character with a space.  Always skip a\n\t\t\t// character when the word ends.  But only when the\n\t\t\t// good word can end.\n\t\t\tif (((!try_compound && !spell_iswordp_nmw(fword\n\t\t\t\t\t\t\t       + sp->ts_fidx,\n\t\t\t\t\t\t\t       curwin))\n\t\t\t\t    || fword_ends)\n\t\t\t\t&& fword[sp->ts_fidx] != NUL\n\t\t\t\t&& goodword_ends)\n\t\t\t{\n\t\t\t    int\t    l;\n\n\t\t\t    l = mb_ptr2len(fword + sp->ts_fidx);\n\t\t\t    if (fword_ends)\n\t\t\t    {\n\t\t\t\t// Copy the skipped character to preword.\n\t\t\t\tmch_memmove(preword + sp->ts_prewordlen,\n\t\t\t\t\t\t      fword + sp->ts_fidx, l);\n\t\t\t\tsp->ts_prewordlen += l;\n\t\t\t\tpreword[sp->ts_prewordlen] = NUL;\n\t\t\t    }\n\t\t\t    else\n\t\t\t\tsp->ts_score -= SCORE_SPLIT - SCORE_SUBST;\n\t\t\t    sp->ts_fidx += l;\n\t\t\t}\n\n\t\t\t// When compounding include compound flag in\n\t\t\t// compflags[] (already set above).  When splitting we\n\t\t\t// may start compounding over again.\n\t\t\tif (try_compound)\n\t\t\t    ++sp->ts_complen;\n\t\t\telse\n\t\t\t    sp->ts_compsplit = sp->ts_complen;\n\t\t\tsp->ts_prefixdepth = PFD_NOPREFIX;\n\n\t\t\t// set su->su_badflags to the caps type at this\n\t\t\t// position\n\t\t\tif (has_mbyte)\n\t\t\t    n = nofold_len(fword, sp->ts_fidx, su->su_badptr);\n\t\t\telse\n\t\t\t    n = sp->ts_fidx;\n\t\t\tsu->su_badflags = badword_captype(su->su_badptr + n,\n\t\t\t\t\t       su->su_badptr + su->su_badlen);\n\n\t\t\t// Restart at top of the tree.\n\t\t\tsp->ts_arridx = 0;\n\n\t\t\t// If there are postponed prefixes, try these too.\n\t\t\tif (pbyts != NULL)\n\t\t\t{\n\t\t\t    byts = pbyts;\n\t\t\t    idxs = pidxs;\n\t\t\t    sp->ts_prefixdepth = PFD_PREFIXTREE;\n\t\t\t    PROF_STORE(sp->ts_state)\n\t\t\t    sp->ts_state = STATE_NOPREFIX;\n\t\t\t}\n\t\t    }\n\t\t}\n\t    }\n\t    break;\n\n\tcase STATE_SPLITUNDO:\n\t    // Undo the changes done for word split or compound word.\n\t    su->su_badflags = sp->ts_save_badflags;\n\n\t    // Continue looking for NUL bytes.\n\t    PROF_STORE(sp->ts_state)\n\t    sp->ts_state = STATE_START;\n\n\t    // In case we went into the prefix tree.\n\t    byts = fbyts;\n\t    idxs = fidxs;\n\t    break;\n\n\tcase STATE_ENDNUL:\n\t    // Past the NUL bytes in the node.\n\t    su->su_badflags = sp->ts_save_badflags;\n\t    if (fword[sp->ts_fidx] == NUL && sp->ts_tcharlen == 0)\n\t    {\n\t\t// The badword ends, can't use STATE_PLAIN.\n\t\tPROF_STORE(sp->ts_state)\n\t\tsp->ts_state = STATE_DEL;\n\t\tbreak;\n\t    }\n\t    PROF_STORE(sp->ts_state)\n\t    sp->ts_state = STATE_PLAIN;\n\t    // FALLTHROUGH\n\n\tcase STATE_PLAIN:\n\t    // Go over all possible bytes at this node, add each to tword[]\n\t    // and use child node.  \"ts_curi\" is the index.\n\t    arridx = sp->ts_arridx;\n\t    if (sp->ts_curi > byts[arridx])\n\t    {\n\t\t// Done all bytes at this node, do next state.  When still at\n\t\t// already changed bytes skip the other tricks.\n\t\tPROF_STORE(sp->ts_state)\n\t\tif (sp->ts_fidx >= sp->ts_fidxtry)\n\t\t    sp->ts_state = STATE_DEL;\n\t\telse\n\t\t    sp->ts_state = STATE_FINAL;\n\t    }\n\t    else\n\t    {\n\t\tarridx += sp->ts_curi++;\n\t\tc = byts[arridx];\n\n\t\t// Normal byte, go one level deeper.  If it's not equal to the\n\t\t// byte in the bad word adjust the score.  But don't even try\n\t\t// when the byte was already changed.  And don't try when we\n\t\t// just deleted this byte, accepting it is always cheaper than\n\t\t// delete + substitute.\n\t\tif (c == fword[sp->ts_fidx]\n\t\t\t|| (sp->ts_tcharlen > 0 && sp->ts_isdiff != DIFF_NONE))\n\t\t    newscore = 0;\n\t\telse\n\t\t    newscore = SCORE_SUBST;\n\t\tif ((newscore == 0\n\t\t\t    || (sp->ts_fidx >= sp->ts_fidxtry\n\t\t\t\t&& ((sp->ts_flags & TSF_DIDDEL) == 0\n\t\t\t\t    || c != fword[sp->ts_delidx])))\n\t\t\t&& TRY_DEEPER(su, stack, depth, newscore))\n\t\t{\n\t\t    go_deeper(stack, depth, newscore);\n#ifdef DEBUG_TRIEWALK\n\t\t    if (newscore > 0)\n\t\t\tsprintf(changename[depth], \"%.*s-%s: subst %c to %c\",\n\t\t\t\tsp->ts_twordlen, tword, fword + sp->ts_fidx,\n\t\t\t\tfword[sp->ts_fidx], c);\n\t\t    else\n\t\t\tsprintf(changename[depth], \"%.*s-%s: accept %c\",\n\t\t\t\tsp->ts_twordlen, tword, fword + sp->ts_fidx,\n\t\t\t\tfword[sp->ts_fidx]);\n#endif\n\t\t    ++depth;\n\t\t    sp = &stack[depth];\n\t\t    if (fword[sp->ts_fidx] != NUL)\n\t\t\t++sp->ts_fidx;\n\t\t    tword[sp->ts_twordlen++] = c;\n\t\t    sp->ts_arridx = idxs[arridx];\n\t\t    if (newscore == SCORE_SUBST)\n\t\t\tsp->ts_isdiff = DIFF_YES;\n\t\t    if (has_mbyte)\n\t\t    {\n\t\t\t// Multi-byte characters are a bit complicated to\n\t\t\t// handle: They differ when any of the bytes differ\n\t\t\t// and then their length may also differ.\n\t\t\tif (sp->ts_tcharlen == 0)\n\t\t\t{\n\t\t\t    // First byte.\n\t\t\t    sp->ts_tcharidx = 0;\n\t\t\t    sp->ts_tcharlen = MB_BYTE2LEN(c);\n\t\t\t    sp->ts_fcharstart = sp->ts_fidx - 1;\n\t\t\t    sp->ts_isdiff = (newscore != 0)\n\t\t\t\t\t\t       ? DIFF_YES : DIFF_NONE;\n\t\t\t}\n\t\t\telse if (sp->ts_isdiff == DIFF_INSERT)\n\t\t\t    // When inserting trail bytes don't advance in the\n\t\t\t    // bad word.\n\t\t\t    --sp->ts_fidx;\n\t\t\tif (++sp->ts_tcharidx == sp->ts_tcharlen)\n\t\t\t{\n\t\t\t    // Last byte of character.\n\t\t\t    if (sp->ts_isdiff == DIFF_YES)\n\t\t\t    {\n\t\t\t\t// Correct ts_fidx for the byte length of the\n\t\t\t\t// character (we didn't check that before).\n\t\t\t\tsp->ts_fidx = sp->ts_fcharstart\n\t\t\t\t\t    + mb_ptr2len(\n\t\t\t\t\t\t    fword + sp->ts_fcharstart);\n\t\t\t\t// For changing a composing character adjust\n\t\t\t\t// the score from SCORE_SUBST to\n\t\t\t\t// SCORE_SUBCOMP.\n\t\t\t\tif (enc_utf8\n\t\t\t\t\t&& utf_iscomposing(\n\t\t\t\t\t    utf_ptr2char(tword\n\t\t\t\t\t\t+ sp->ts_twordlen\n\t\t\t\t\t\t\t   - sp->ts_tcharlen))\n\t\t\t\t\t&& utf_iscomposing(\n\t\t\t\t\t    utf_ptr2char(fword\n\t\t\t\t\t\t\t+ sp->ts_fcharstart)))\n\t\t\t\t    sp->ts_score -=\n\t\t\t\t\t\t  SCORE_SUBST - SCORE_SUBCOMP;\n\n\t\t\t\t// For a similar character adjust score from\n\t\t\t\t// SCORE_SUBST to SCORE_SIMILAR.\n\t\t\t\telse if (!soundfold\n\t\t\t\t\t&& slang->sl_has_map\n\t\t\t\t\t&& similar_chars(slang,\n\t\t\t\t\t    mb_ptr2char(tword\n\t\t\t\t\t\t+ sp->ts_twordlen\n\t\t\t\t\t\t\t   - sp->ts_tcharlen),\n\t\t\t\t\t    mb_ptr2char(fword\n\t\t\t\t\t\t\t+ sp->ts_fcharstart)))\n\t\t\t\t    sp->ts_score -=\n\t\t\t\t\t\t  SCORE_SUBST - SCORE_SIMILAR;\n\t\t\t    }\n\t\t\t    else if (sp->ts_isdiff == DIFF_INSERT\n\t\t\t\t\t && sp->ts_twordlen > sp->ts_tcharlen)\n\t\t\t    {\n\t\t\t\tp = tword + sp->ts_twordlen - sp->ts_tcharlen;\n\t\t\t\tc = mb_ptr2char(p);\n\t\t\t\tif (enc_utf8 && utf_iscomposing(c))\n\t\t\t\t{\n\t\t\t\t    // Inserting a composing char doesn't\n\t\t\t\t    // count that much.\n\t\t\t\t    sp->ts_score -= SCORE_INS - SCORE_INSCOMP;\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t    // If the previous character was the same,\n\t\t\t\t    // thus doubling a character, give a bonus\n\t\t\t\t    // to the score.  Also for the soundfold\n\t\t\t\t    // tree (might seem illogical but does\n\t\t\t\t    // give better scores).\n\t\t\t\t    MB_PTR_BACK(tword, p);\n\t\t\t\t    if (c == mb_ptr2char(p))\n\t\t\t\t\tsp->ts_score -= SCORE_INS\n\t\t\t\t\t\t\t       - SCORE_INSDUP;\n\t\t\t\t}\n\t\t\t    }\n\n\t\t\t    // Starting a new char, reset the length.\n\t\t\t    sp->ts_tcharlen = 0;\n\t\t\t}\n\t\t    }\n\t\t    else\n\t\t    {\n\t\t\t// If we found a similar char adjust the score.\n\t\t\t// We do this after calling go_deeper() because\n\t\t\t// it's slow.\n\t\t\tif (newscore != 0\n\t\t\t\t&& !soundfold\n\t\t\t\t&& slang->sl_has_map\n\t\t\t\t&& similar_chars(slang,\n\t\t\t\t\t\t   c, fword[sp->ts_fidx - 1]))\n\t\t\t    sp->ts_score -= SCORE_SUBST - SCORE_SIMILAR;\n\t\t    }\n\t\t}\n\t    }\n\t    break;\n\n\tcase STATE_DEL:\n\t    // When past the first byte of a multi-byte char don't try\n\t    // delete/insert/swap a character.\n\t    if (has_mbyte && sp->ts_tcharlen > 0)\n\t    {\n\t\tPROF_STORE(sp->ts_state)\n\t\tsp->ts_state = STATE_FINAL;\n\t\tbreak;\n\t    }\n\t    // Try skipping one character in the bad word (delete it).\n\t    PROF_STORE(sp->ts_state)\n\t    sp->ts_state = STATE_INS_PREP;\n\t    sp->ts_curi = 1;\n\t    if (soundfold && sp->ts_fidx == 0 && fword[sp->ts_fidx] == '*')\n\t\t// Deleting a vowel at the start of a word counts less, see\n\t\t// soundalike_score().\n\t\tnewscore = 2 * SCORE_DEL / 3;\n\t    else\n\t\tnewscore = SCORE_DEL;\n\t    if (fword[sp->ts_fidx] != NUL\n\t\t\t\t    && TRY_DEEPER(su, stack, depth, newscore))\n\t    {\n\t\tgo_deeper(stack, depth, newscore);\n#ifdef DEBUG_TRIEWALK\n\t\tsprintf(changename[depth], \"%.*s-%s: delete %c\",\n\t\t\tsp->ts_twordlen, tword, fword + sp->ts_fidx,\n\t\t\tfword[sp->ts_fidx]);\n#endif\n\t\t++depth;\n\n\t\t// Remember what character we deleted, so that we can avoid\n\t\t// inserting it again.\n\t\tstack[depth].ts_flags |= TSF_DIDDEL;\n\t\tstack[depth].ts_delidx = sp->ts_fidx;\n\n\t\t// Advance over the character in fword[].  Give a bonus to the\n\t\t// score if the same character is following \"nn\" -> \"n\".  It's\n\t\t// a bit illogical for soundfold tree but it does give better\n\t\t// results.\n\t\tif (has_mbyte)\n\t\t{\n\t\t    c = mb_ptr2char(fword + sp->ts_fidx);\n\t\t    stack[depth].ts_fidx += mb_ptr2len(fword + sp->ts_fidx);\n\t\t    if (enc_utf8 && utf_iscomposing(c))\n\t\t\tstack[depth].ts_score -= SCORE_DEL - SCORE_DELCOMP;\n\t\t    else if (c == mb_ptr2char(fword + stack[depth].ts_fidx))\n\t\t\tstack[depth].ts_score -= SCORE_DEL - SCORE_DELDUP;\n\t\t}\n\t\telse\n\t\t{\n\t\t    ++stack[depth].ts_fidx;\n\t\t    if (fword[sp->ts_fidx] == fword[sp->ts_fidx + 1])\n\t\t\tstack[depth].ts_score -= SCORE_DEL - SCORE_DELDUP;\n\t\t}\n\t\tbreak;\n\t    }\n\t    // FALLTHROUGH\n\n\tcase STATE_INS_PREP:\n\t    if (sp->ts_flags & TSF_DIDDEL)\n\t    {\n\t\t// If we just deleted a byte then inserting won't make sense,\n\t\t// a substitute is always cheaper.\n\t\tPROF_STORE(sp->ts_state)\n\t\tsp->ts_state = STATE_SWAP;\n\t\tbreak;\n\t    }\n\n\t    // skip over NUL bytes\n\t    n = sp->ts_arridx;\n\t    for (;;)\n\t    {\n\t\tif (sp->ts_curi > byts[n])\n\t\t{\n\t\t    // Only NUL bytes at this node, go to next state.\n\t\t    PROF_STORE(sp->ts_state)\n\t\t    sp->ts_state = STATE_SWAP;\n\t\t    break;\n\t\t}\n\t\tif (byts[n + sp->ts_curi] != NUL)\n\t\t{\n\t\t    // Found a byte to insert.\n\t\t    PROF_STORE(sp->ts_state)\n\t\t    sp->ts_state = STATE_INS;\n\t\t    break;\n\t\t}\n\t\t++sp->ts_curi;\n\t    }\n\t    break;\n\n\t    // FALLTHROUGH\n\n\tcase STATE_INS:\n\t    // Insert one byte.  Repeat this for each possible byte at this\n\t    // node.\n\t    n = sp->ts_arridx;\n\t    if (sp->ts_curi > byts[n])\n\t    {\n\t\t// Done all bytes at this node, go to next state.\n\t\tPROF_STORE(sp->ts_state)\n\t\tsp->ts_state = STATE_SWAP;\n\t\tbreak;\n\t    }\n\n\t    // Do one more byte at this node, but:\n\t    // - Skip NUL bytes.\n\t    // - Skip the byte if it's equal to the byte in the word,\n\t    //   accepting that byte is always better.\n\t    n += sp->ts_curi++;\n\t    c = byts[n];\n\t    if (soundfold && sp->ts_twordlen == 0 && c == '*')\n\t\t// Inserting a vowel at the start of a word counts less,\n\t\t// see soundalike_score().\n\t\tnewscore = 2 * SCORE_INS / 3;\n\t    else\n\t\tnewscore = SCORE_INS;\n\t    if (c != fword[sp->ts_fidx]\n\t\t\t\t    && TRY_DEEPER(su, stack, depth, newscore))\n\t    {\n\t\tgo_deeper(stack, depth, newscore);\n#ifdef DEBUG_TRIEWALK\n\t\tsprintf(changename[depth], \"%.*s-%s: insert %c\",\n\t\t\tsp->ts_twordlen, tword, fword + sp->ts_fidx,\n\t\t\tc);\n#endif\n\t\t++depth;\n\t\tsp = &stack[depth];\n\t\ttword[sp->ts_twordlen++] = c;\n\t\tsp->ts_arridx = idxs[n];\n\t\tif (has_mbyte)\n\t\t{\n\t\t    fl = MB_BYTE2LEN(c);\n\t\t    if (fl > 1)\n\t\t    {\n\t\t\t// There are following bytes for the same character.\n\t\t\t// We must find all bytes before trying\n\t\t\t// delete/insert/swap/etc.\n\t\t\tsp->ts_tcharlen = fl;\n\t\t\tsp->ts_tcharidx = 1;\n\t\t\tsp->ts_isdiff = DIFF_INSERT;\n\t\t    }\n\t\t}\n\t\telse\n\t\t    fl = 1;\n\t\tif (fl == 1)\n\t\t{\n\t\t    // If the previous character was the same, thus doubling a\n\t\t    // character, give a bonus to the score.  Also for\n\t\t    // soundfold words (illogical but does give a better\n\t\t    // score).\n\t\t    if (sp->ts_twordlen >= 2\n\t\t\t\t\t   && tword[sp->ts_twordlen - 2] == c)\n\t\t\tsp->ts_score -= SCORE_INS - SCORE_INSDUP;\n\t\t}\n\t    }\n\t    break;\n\n\tcase STATE_SWAP:\n\t    // Swap two bytes in the bad word: \"12\" -> \"21\".\n\t    // We change \"fword\" here, it's changed back afterwards at\n\t    // STATE_UNSWAP.\n\t    p = fword + sp->ts_fidx;\n\t    c = *p;\n\t    if (c == NUL)\n\t    {\n\t\t// End of word, can't swap or replace.\n\t\tPROF_STORE(sp->ts_state)\n\t\tsp->ts_state = STATE_FINAL;\n\t\tbreak;\n\t    }\n\n\t    // Don't swap if the first character is not a word character.\n\t    // SWAP3 etc. also don't make sense then.\n\t    if (!soundfold && !spell_iswordp(p, curwin))\n\t    {\n\t\tPROF_STORE(sp->ts_state)\n\t\tsp->ts_state = STATE_REP_INI;\n\t\tbreak;\n\t    }\n\n\t    if (has_mbyte)\n\t    {\n\t\tn = MB_CPTR2LEN(p);\n\t\tc = mb_ptr2char(p);\n\t\tif (p[n] == NUL)\n\t\t    c2 = NUL;\n\t\telse if (!soundfold && !spell_iswordp(p + n, curwin))\n\t\t    c2 = c; // don't swap non-word char\n\t\telse\n\t\t    c2 = mb_ptr2char(p + n);\n\t    }\n\t    else\n\t    {\n\t\tif (p[1] == NUL)\n\t\t    c2 = NUL;\n\t\telse if (!soundfold && !spell_iswordp(p + 1, curwin))\n\t\t    c2 = c; // don't swap non-word char\n\t\telse\n\t\t    c2 = p[1];\n\t    }\n\n\t    // When the second character is NUL we can't swap.\n\t    if (c2 == NUL)\n\t    {\n\t\tPROF_STORE(sp->ts_state)\n\t\tsp->ts_state = STATE_REP_INI;\n\t\tbreak;\n\t    }\n\n\t    // When characters are identical, swap won't do anything.\n\t    // Also get here if the second char is not a word character.\n\t    if (c == c2)\n\t    {\n\t\tPROF_STORE(sp->ts_state)\n\t\tsp->ts_state = STATE_SWAP3;\n\t\tbreak;\n\t    }\n\t    if (c2 != NUL && TRY_DEEPER(su, stack, depth, SCORE_SWAP))\n\t    {\n\t\tgo_deeper(stack, depth, SCORE_SWAP);\n#ifdef DEBUG_TRIEWALK\n\t\tsprintf(changename[depth], \"%.*s-%s: swap %c and %c\",\n\t\t\tsp->ts_twordlen, tword, fword + sp->ts_fidx,\n\t\t\tc, c2);\n#endif\n\t\tPROF_STORE(sp->ts_state)\n\t\tsp->ts_state = STATE_UNSWAP;\n\t\t++depth;\n\t\tif (has_mbyte)\n\t\t{\n\t\t    fl = mb_char2len(c2);\n\t\t    mch_memmove(p, p + n, fl);\n\t\t    mb_char2bytes(c, p + fl);\n\t\t    stack[depth].ts_fidxtry = sp->ts_fidx + n + fl;\n\t\t}\n\t\telse\n\t\t{\n\t\t    p[0] = c2;\n\t\t    p[1] = c;\n\t\t    stack[depth].ts_fidxtry = sp->ts_fidx + 2;\n\t\t}\n\t    }\n\t    else\n\t    {\n\t\t// If this swap doesn't work then SWAP3 won't either.\n\t\tPROF_STORE(sp->ts_state)\n\t\tsp->ts_state = STATE_REP_INI;\n\t    }\n\t    break;\n\n\tcase STATE_UNSWAP:\n\t    // Undo the STATE_SWAP swap: \"21\" -> \"12\".\n\t    p = fword + sp->ts_fidx;\n\t    if (has_mbyte)\n\t    {\n\t\tn = mb_ptr2len(p);\n\t\tc = mb_ptr2char(p + n);\n\t\tmch_memmove(p + mb_ptr2len(p + n), p, n);\n\t\tmb_char2bytes(c, p);\n\t    }\n\t    else\n\t    {\n\t\tc = *p;\n\t\t*p = p[1];\n\t\tp[1] = c;\n\t    }\n\t    // FALLTHROUGH\n\n\tcase STATE_SWAP3:\n\t    // Swap two bytes, skipping one: \"123\" -> \"321\".  We change\n\t    // \"fword\" here, it's changed back afterwards at STATE_UNSWAP3.\n\t    p = fword + sp->ts_fidx;\n\t    if (has_mbyte)\n\t    {\n\t\tn = MB_CPTR2LEN(p);\n\t\tc = mb_ptr2char(p);\n\t\tfl = MB_CPTR2LEN(p + n);\n\t\tc2 = mb_ptr2char(p + n);\n\t\tif (!soundfold && !spell_iswordp(p + n + fl, curwin))\n\t\t    c3 = c;\t// don't swap non-word char\n\t\telse\n\t\t    c3 = mb_ptr2char(p + n + fl);\n\t    }\n\t    else\n\t    {\n\t\tc = *p;\n\t\tc2 = p[1];\n\t\tif (!soundfold && !spell_iswordp(p + 2, curwin))\n\t\t    c3 = c;\t// don't swap non-word char\n\t\telse\n\t\t    c3 = p[2];\n\t    }\n\n\t    // When characters are identical: \"121\" then SWAP3 result is\n\t    // identical, ROT3L result is same as SWAP: \"211\", ROT3L result is\n\t    // same as SWAP on next char: \"112\".  Thus skip all swapping.\n\t    // Also skip when c3 is NUL.\n\t    // Also get here when the third character is not a word character.\n\t    // Second character may any char: \"a.b\" -> \"b.a\"\n\t    if (c == c3 || c3 == NUL)\n\t    {\n\t\tPROF_STORE(sp->ts_state)\n\t\tsp->ts_state = STATE_REP_INI;\n\t\tbreak;\n\t    }\n\t    if (TRY_DEEPER(su, stack, depth, SCORE_SWAP3))\n\t    {\n\t\tgo_deeper(stack, depth, SCORE_SWAP3);\n#ifdef DEBUG_TRIEWALK\n\t\tsprintf(changename[depth], \"%.*s-%s: swap3 %c and %c\",\n\t\t\tsp->ts_twordlen, tword, fword + sp->ts_fidx,\n\t\t\tc, c3);\n#endif\n\t\tPROF_STORE(sp->ts_state)\n\t\tsp->ts_state = STATE_UNSWAP3;\n\t\t++depth;\n\t\tif (has_mbyte)\n\t\t{\n\t\t    tl = mb_char2len(c3);\n\t\t    mch_memmove(p, p + n + fl, tl);\n\t\t    mb_char2bytes(c2, p + tl);\n\t\t    mb_char2bytes(c, p + fl + tl);\n\t\t    stack[depth].ts_fidxtry = sp->ts_fidx + n + fl + tl;\n\t\t}\n\t\telse\n\t\t{\n\t\t    p[0] = p[2];\n\t\t    p[2] = c;\n\t\t    stack[depth].ts_fidxtry = sp->ts_fidx + 3;\n\t\t}\n\t    }\n\t    else\n\t    {\n\t\tPROF_STORE(sp->ts_state)\n\t\tsp->ts_state = STATE_REP_INI;\n\t    }\n\t    break;\n\n\tcase STATE_UNSWAP3:\n\t    // Undo STATE_SWAP3: \"321\" -> \"123\"\n\t    p = fword + sp->ts_fidx;\n\t    if (has_mbyte)\n\t    {\n\t\tn = mb_ptr2len(p);\n\t\tc2 = mb_ptr2char(p + n);\n\t\tfl = mb_ptr2len(p + n);\n\t\tc = mb_ptr2char(p + n + fl);\n\t\ttl = mb_ptr2len(p + n + fl);\n\t\tmch_memmove(p + fl + tl, p, n);\n\t\tmb_char2bytes(c, p);\n\t\tmb_char2bytes(c2, p + tl);\n\t\tp = p + tl;\n\t    }\n\t    else\n\t    {\n\t\tc = *p;\n\t\t*p = p[2];\n\t\tp[2] = c;\n\t\t++p;\n\t    }\n\n\t    if (!soundfold && !spell_iswordp(p, curwin))\n\t    {\n\t\t// Middle char is not a word char, skip the rotate.  First and\n\t\t// third char were already checked at swap and swap3.\n\t\tPROF_STORE(sp->ts_state)\n\t\tsp->ts_state = STATE_REP_INI;\n\t\tbreak;\n\t    }\n\n\t    // Rotate three characters left: \"123\" -> \"231\".  We change\n\t    // \"fword\" here, it's changed back afterwards at STATE_UNROT3L.\n\t    if (TRY_DEEPER(su, stack, depth, SCORE_SWAP3))\n\t    {\n\t\tgo_deeper(stack, depth, SCORE_SWAP3);\n#ifdef DEBUG_TRIEWALK\n\t\tp = fword + sp->ts_fidx;\n\t\tsprintf(changename[depth], \"%.*s-%s: rotate left %c%c%c\",\n\t\t\tsp->ts_twordlen, tword, fword + sp->ts_fidx,\n\t\t\tp[0], p[1], p[2]);\n#endif\n\t\tPROF_STORE(sp->ts_state)\n\t\tsp->ts_state = STATE_UNROT3L;\n\t\t++depth;\n\t\tp = fword + sp->ts_fidx;\n\t\tif (has_mbyte)\n\t\t{\n\t\t    n = MB_CPTR2LEN(p);\n\t\t    c = mb_ptr2char(p);\n\t\t    fl = MB_CPTR2LEN(p + n);\n\t\t    fl += MB_CPTR2LEN(p + n + fl);\n\t\t    mch_memmove(p, p + n, fl);\n\t\t    mb_char2bytes(c, p + fl);\n\t\t    stack[depth].ts_fidxtry = sp->ts_fidx + n + fl;\n\t\t}\n\t\telse\n\t\t{\n\t\t    c = *p;\n\t\t    *p = p[1];\n\t\t    p[1] = p[2];\n\t\t    p[2] = c;\n\t\t    stack[depth].ts_fidxtry = sp->ts_fidx + 3;\n\t\t}\n\t    }\n\t    else\n\t    {\n\t\tPROF_STORE(sp->ts_state)\n\t\tsp->ts_state = STATE_REP_INI;\n\t    }\n\t    break;\n\n\tcase STATE_UNROT3L:\n\t    // Undo ROT3L: \"231\" -> \"123\"\n\t    p = fword + sp->ts_fidx;\n\t    if (has_mbyte)\n\t    {\n\t\tn = mb_ptr2len(p);\n\t\tn += mb_ptr2len(p + n);\n\t\tc = mb_ptr2char(p + n);\n\t\ttl = mb_ptr2len(p + n);\n\t\tmch_memmove(p + tl, p, n);\n\t\tmb_char2bytes(c, p);\n\t    }\n\t    else\n\t    {\n\t\tc = p[2];\n\t\tp[2] = p[1];\n\t\tp[1] = *p;\n\t\t*p = c;\n\t    }\n\n\t    // Rotate three bytes right: \"123\" -> \"312\".  We change \"fword\"\n\t    // here, it's changed back afterwards at STATE_UNROT3R.\n\t    if (TRY_DEEPER(su, stack, depth, SCORE_SWAP3))\n\t    {\n\t\tgo_deeper(stack, depth, SCORE_SWAP3);\n#ifdef DEBUG_TRIEWALK\n\t\tp = fword + sp->ts_fidx;\n\t\tsprintf(changename[depth], \"%.*s-%s: rotate right %c%c%c\",\n\t\t\tsp->ts_twordlen, tword, fword + sp->ts_fidx,\n\t\t\tp[0], p[1], p[2]);\n#endif\n\t\tPROF_STORE(sp->ts_state)\n\t\tsp->ts_state = STATE_UNROT3R;\n\t\t++depth;\n\t\tp = fword + sp->ts_fidx;\n\t\tif (has_mbyte)\n\t\t{\n\t\t    n = MB_CPTR2LEN(p);\n\t\t    n += MB_CPTR2LEN(p + n);\n\t\t    c = mb_ptr2char(p + n);\n\t\t    tl = MB_CPTR2LEN(p + n);\n\t\t    mch_memmove(p + tl, p, n);\n\t\t    mb_char2bytes(c, p);\n\t\t    stack[depth].ts_fidxtry = sp->ts_fidx + n + tl;\n\t\t}\n\t\telse\n\t\t{\n\t\t    c = p[2];\n\t\t    p[2] = p[1];\n\t\t    p[1] = *p;\n\t\t    *p = c;\n\t\t    stack[depth].ts_fidxtry = sp->ts_fidx + 3;\n\t\t}\n\t    }\n\t    else\n\t    {\n\t\tPROF_STORE(sp->ts_state)\n\t\tsp->ts_state = STATE_REP_INI;\n\t    }\n\t    break;\n\n\tcase STATE_UNROT3R:\n\t    // Undo ROT3R: \"312\" -> \"123\"\n\t    p = fword + sp->ts_fidx;\n\t    if (has_mbyte)\n\t    {\n\t\tc = mb_ptr2char(p);\n\t\ttl = mb_ptr2len(p);\n\t\tn = mb_ptr2len(p + tl);\n\t\tn += mb_ptr2len(p + tl + n);\n\t\tmch_memmove(p, p + tl, n);\n\t\tmb_char2bytes(c, p + n);\n\t    }\n\t    else\n\t    {\n\t\tc = *p;\n\t\t*p = p[1];\n\t\tp[1] = p[2];\n\t\tp[2] = c;\n\t    }\n\t    // FALLTHROUGH\n\n\tcase STATE_REP_INI:\n\t    // Check if matching with REP items from the .aff file would work.\n\t    // Quickly skip if:\n\t    // - there are no REP items and we are not in the soundfold trie\n\t    // - the score is going to be too high anyway\n\t    // - already applied a REP item or swapped here\n\t    if ((lp->lp_replang == NULL && !soundfold)\n\t\t    || sp->ts_score + SCORE_REP >= su->su_maxscore\n\t\t    || sp->ts_fidx < sp->ts_fidxtry)\n\t    {\n\t\tPROF_STORE(sp->ts_state)\n\t\tsp->ts_state = STATE_FINAL;\n\t\tbreak;\n\t    }\n\n\t    // Use the first byte to quickly find the first entry that may\n\t    // match.  If the index is -1 there is none.\n\t    if (soundfold)\n\t\tsp->ts_curi = slang->sl_repsal_first[fword[sp->ts_fidx]];\n\t    else\n\t\tsp->ts_curi = lp->lp_replang->sl_rep_first[fword[sp->ts_fidx]];\n\n\t    if (sp->ts_curi < 0)\n\t    {\n\t\tPROF_STORE(sp->ts_state)\n\t\tsp->ts_state = STATE_FINAL;\n\t\tbreak;\n\t    }\n\n\t    PROF_STORE(sp->ts_state)\n\t    sp->ts_state = STATE_REP;\n\t    // FALLTHROUGH\n\n\tcase STATE_REP:\n\t    // Try matching with REP items from the .aff file.  For each match\n\t    // replace the characters and check if the resulting word is\n\t    // valid.\n\t    p = fword + sp->ts_fidx;\n\n\t    if (soundfold)\n\t\tgap = &slang->sl_repsal;\n\t    else\n\t\tgap = &lp->lp_replang->sl_rep;\n\t    while (sp->ts_curi < gap->ga_len)\n\t    {\n\t\tftp = (fromto_T *)gap->ga_data + sp->ts_curi++;\n\t\tif (*ftp->ft_from != *p)\n\t\t{\n\t\t    // past possible matching entries\n\t\t    sp->ts_curi = gap->ga_len;\n\t\t    break;\n\t\t}\n\t\tif (STRNCMP(ftp->ft_from, p, STRLEN(ftp->ft_from)) == 0\n\t\t\t&& TRY_DEEPER(su, stack, depth, SCORE_REP))\n\t\t{\n\t\t    go_deeper(stack, depth, SCORE_REP);\n#ifdef DEBUG_TRIEWALK\n\t\t    sprintf(changename[depth], \"%.*s-%s: replace %s with %s\",\n\t\t\t    sp->ts_twordlen, tword, fword + sp->ts_fidx,\n\t\t\t    ftp->ft_from, ftp->ft_to);\n#endif\n\t\t    // Need to undo this afterwards.\n\t\t    PROF_STORE(sp->ts_state)\n\t\t    sp->ts_state = STATE_REP_UNDO;\n\n\t\t    // Change the \"from\" to the \"to\" string.\n\t\t    ++depth;\n\t\t    fl = (int)STRLEN(ftp->ft_from);\n\t\t    tl = (int)STRLEN(ftp->ft_to);\n\t\t    if (fl != tl)\n\t\t    {\n\t\t\tSTRMOVE(p + tl, p + fl);\n\t\t\trepextra += tl - fl;\n\t\t    }\n\t\t    mch_memmove(p, ftp->ft_to, tl);\n\t\t    stack[depth].ts_fidxtry = sp->ts_fidx + tl;\n\t\t    stack[depth].ts_tcharlen = 0;\n\t\t    break;\n\t\t}\n\t    }\n\n\t    if (sp->ts_curi >= gap->ga_len && sp->ts_state == STATE_REP)\n\t    {\n\t\t// No (more) matches.\n\t\tPROF_STORE(sp->ts_state)\n\t\tsp->ts_state = STATE_FINAL;\n\t    }\n\n\t    break;\n\n\tcase STATE_REP_UNDO:\n\t    // Undo a REP replacement and continue with the next one.\n\t    if (soundfold)\n\t\tgap = &slang->sl_repsal;\n\t    else\n\t\tgap = &lp->lp_replang->sl_rep;\n\t    ftp = (fromto_T *)gap->ga_data + sp->ts_curi - 1;\n\t    fl = (int)STRLEN(ftp->ft_from);\n\t    tl = (int)STRLEN(ftp->ft_to);\n\t    p = fword + sp->ts_fidx;\n\t    if (fl != tl)\n\t    {\n\t\tSTRMOVE(p + fl, p + tl);\n\t\trepextra -= tl - fl;\n\t    }\n\t    mch_memmove(p, ftp->ft_from, fl);\n\t    PROF_STORE(sp->ts_state)\n\t    sp->ts_state = STATE_REP;\n\t    break;\n\n\tdefault:\n\t    // Did all possible states at this level, go up one level.\n\t    --depth;\n\n\t    if (depth >= 0 && stack[depth].ts_prefixdepth == PFD_PREFIXTREE)\n\t    {\n\t\t// Continue in or go back to the prefix tree.\n\t\tbyts = pbyts;\n\t\tidxs = pidxs;\n\t    }\n\n\t    // Don't check for CTRL-C too often, it takes time.\n\t    if (--breakcheckcount == 0)\n\t    {\n\t\tui_breakcheck();\n\t\tbreakcheckcount = 1000;\n#ifdef FEAT_RELTIME\n\t\tif (spell_suggest_timeout > 0\n\t\t\t\t\t  && profile_passed_limit(&time_limit))\n\t\t    got_int = TRUE;\n#endif\n\t    }\n\t}\n    }\n}",
        "func_hash": 86190004113264578506184029642372711349,
        "file_name": "spellsuggest.c",
        "file_hash": 224942464208559430024115846607965193151,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2022-2126",
        "cve_desc": "Out-of-bounds Read in GitHub repository vim/vim prior to 8.2.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-2126",
        "func_name": "suggest_trie_walk",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 200379,
        "project": "radare2",
        "commit_id": "48f0ea79f99174fb0a62cb2354e13496ce5b7c44",
        "project_url": "https://github.com/radare/radare2",
        "commit_url": "https://github.com/radareorg/radare2/commit/48f0ea79f99174fb0a62cb2354e13496ce5b7c44",
        "commit_message": "Fix null deref in ne parser ##crash\n\n* Reported by @cnitlrt via huntr.dev\n* BountyID: d8b6d239-6d7b-4783-b26b-5be848c01aa1/\n* Reproducer: nenull",
        "target": 1,
        "irrelevant": 1,
        "func_before": "RList *r_bin_ne_get_segments(r_bin_ne_obj_t *bin) {\n\tint i;\n\tif (!bin) {\n\t\treturn NULL;\n\t}\n\tRList *segments = r_list_newf (free);\n\tfor (i = 0; i < bin->ne_header->SegCount; i++) {\n\t\tRBinSection *bs = R_NEW0 (RBinSection);\n\t\tif (!bs) {\n\t\t\treturn segments;\n\t\t}\n\t\tNE_image_segment_entry *se = &bin->segment_entries[i];\n\t\tbs->size = se->length;\n\t\tbs->vsize = se->minAllocSz ? se->minAllocSz : 64000;\n\t\tbs->bits = R_SYS_BITS_16;\n\t\tbs->is_data = se->flags & IS_DATA;\n\t\tbs->perm = __translate_perms (se->flags);\n\t\tbs->paddr = (ut64)se->offset * bin->alignment;\n\t\tbs->name = r_str_newf (\"%s.%\" PFMT64d, se->flags & IS_MOVEABLE ? \"MOVEABLE\" : \"FIXED\", bs->paddr);\n\t\tbs->is_segment = true;\n\t\tr_list_append (segments, bs);\n\t}\n\tbin->segments = segments;\n\treturn segments;\n}",
        "func_hash": 32265811031369210493685487313253460681,
        "file_name": "ne.c",
        "file_hash": 158187364999589473605822811150926540610,
        "cwe": [
            "CWE-476"
        ],
        "cve": "CVE-2022-1382",
        "cve_desc": "NULL Pointer Dereference in GitHub repository radareorg/radare2 prior to 5.6.8. This vulnerability is capable of making the radare2 crash, thus affecting the availability of the system.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-1382",
        "func_name": "r_bin_ne_get_segments",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 200672,
        "project": "qemu",
        "commit_id": "bc6f28995ff88f5d82c38afcfd65406f0ae375aa",
        "project_url": "https://github.com/bonzini/qemu",
        "commit_url": "https://git.qemu.org/?p=qemu.git;a=commit;h=bc6f28995ff88f5d82c38afcfd65406f0ae375aa",
        "commit_message": "hw/sd: sdhci: Correctly set the controller status for ADMA\n\nWhen an ADMA transfer is started, the codes forget to set the\ncontroller status to indicate a transfer is in progress.\n\nWith this fix, the following 2 reproducers:\n\nhttps://paste.debian.net/plain/1185136\nhttps://paste.debian.net/plain/1185141\n\ncannot be reproduced with the following QEMU command line:\n\n$ qemu-system-x86_64 -nographic -machine accel=qtest -m 512M \\\n      -nodefaults -device sdhci-pci,sd-spec-version=3 \\\n      -drive if=sd,index=0,file=null-co://,format=raw,id=mydrive \\\n      -device sd-card,drive=mydrive -qtest stdio\n\nCc: qemu-stable@nongnu.org\nFixes: CVE-2020-17380\nFixes: CVE-2020-25085\nFixes: CVE-2021-3409\nFixes: d7dfca0807a0 (\"hw/sdhci: introduce standard SD host controller\")\nReported-by: Alexander Bulekov <alxndr@bu.edu>\nReported-by: Cornelius Aschermann (Ruhr-Universit\u00e4t Bochum)\nReported-by: Sergej Schumilo (Ruhr-Universit\u00e4t Bochum)\nReported-by: Simon W\u00f6rner (Ruhr-Universit\u00e4t Bochum)\nBuglink: https://bugs.launchpad.net/qemu/+bug/1892960\nBuglink: https://bugs.launchpad.net/qemu/+bug/1909418\nBuglink: https://bugzilla.redhat.com/show_bug.cgi?id=1928146\nTested-by: Alexander Bulekov <alxndr@bu.edu>\nReviewed-by: Philippe Mathieu-Daud\u00e9 <f4bug@amsat.org>\nSigned-off-by: Bin Meng <bmeng.cn@gmail.com>\nMessage-Id: <20210303122639.20004-4-bmeng.cn@gmail.com>\nSigned-off-by: Philippe Mathieu-Daud\u00e9 <f4bug@amsat.org>",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static void sdhci_do_adma(SDHCIState *s)\n{\n    unsigned int begin, length;\n    const uint16_t block_size = s->blksize & BLOCK_SIZE_MASK;\n    ADMADescr dscr = {};\n    int i;\n\n    if (s->trnmod & SDHC_TRNS_BLK_CNT_EN && !s->blkcnt) {\n        /* Stop Multiple Transfer */\n        sdhci_end_transfer(s);\n        return;\n    }\n\n    for (i = 0; i < SDHC_ADMA_DESCS_PER_DELAY; ++i) {\n        s->admaerr &= ~SDHC_ADMAERR_LENGTH_MISMATCH;\n\n        get_adma_description(s, &dscr);\n        trace_sdhci_adma_loop(dscr.addr, dscr.length, dscr.attr);\n\n        if ((dscr.attr & SDHC_ADMA_ATTR_VALID) == 0) {\n            /* Indicate that error occurred in ST_FDS state */\n            s->admaerr &= ~SDHC_ADMAERR_STATE_MASK;\n            s->admaerr |= SDHC_ADMAERR_STATE_ST_FDS;\n\n            /* Generate ADMA error interrupt */\n            if (s->errintstsen & SDHC_EISEN_ADMAERR) {\n                s->errintsts |= SDHC_EIS_ADMAERR;\n                s->norintsts |= SDHC_NIS_ERR;\n            }\n\n            sdhci_update_irq(s);\n            return;\n        }\n\n        length = dscr.length ? dscr.length : 64 * KiB;\n\n        switch (dscr.attr & SDHC_ADMA_ATTR_ACT_MASK) {\n        case SDHC_ADMA_ATTR_ACT_TRAN:  /* data transfer */\n            if (s->trnmod & SDHC_TRNS_READ) {\n                while (length) {\n                    if (s->data_count == 0) {\n                        sdbus_read_data(&s->sdbus, s->fifo_buffer, block_size);\n                    }\n                    begin = s->data_count;\n                    if ((length + begin) < block_size) {\n                        s->data_count = length + begin;\n                        length = 0;\n                     } else {\n                        s->data_count = block_size;\n                        length -= block_size - begin;\n                    }\n                    dma_memory_write(s->dma_as, dscr.addr,\n                                     &s->fifo_buffer[begin],\n                                     s->data_count - begin);\n                    dscr.addr += s->data_count - begin;\n                    if (s->data_count == block_size) {\n                        s->data_count = 0;\n                        if (s->trnmod & SDHC_TRNS_BLK_CNT_EN) {\n                            s->blkcnt--;\n                            if (s->blkcnt == 0) {\n                                break;\n                            }\n                        }\n                    }\n                }\n            } else {\n                while (length) {\n                    begin = s->data_count;\n                    if ((length + begin) < block_size) {\n                        s->data_count = length + begin;\n                        length = 0;\n                     } else {\n                        s->data_count = block_size;\n                        length -= block_size - begin;\n                    }\n                    dma_memory_read(s->dma_as, dscr.addr,\n                                    &s->fifo_buffer[begin],\n                                    s->data_count - begin);\n                    dscr.addr += s->data_count - begin;\n                    if (s->data_count == block_size) {\n                        sdbus_write_data(&s->sdbus, s->fifo_buffer, block_size);\n                        s->data_count = 0;\n                        if (s->trnmod & SDHC_TRNS_BLK_CNT_EN) {\n                            s->blkcnt--;\n                            if (s->blkcnt == 0) {\n                                break;\n                            }\n                        }\n                    }\n                }\n            }\n            s->admasysaddr += dscr.incr;\n            break;\n        case SDHC_ADMA_ATTR_ACT_LINK:   /* link to next descriptor table */\n            s->admasysaddr = dscr.addr;\n            trace_sdhci_adma(\"link\", s->admasysaddr);\n            break;\n        default:\n            s->admasysaddr += dscr.incr;\n            break;\n        }\n\n        if (dscr.attr & SDHC_ADMA_ATTR_INT) {\n            trace_sdhci_adma(\"interrupt\", s->admasysaddr);\n            if (s->norintstsen & SDHC_NISEN_DMA) {\n                s->norintsts |= SDHC_NIS_DMA;\n            }\n\n            if (sdhci_update_irq(s) && !(dscr.attr & SDHC_ADMA_ATTR_END)) {\n                /* IRQ delivered, reschedule current transfer */\n                break;\n            }\n        }\n\n        /* ADMA transfer terminates if blkcnt == 0 or by END attribute */\n        if (((s->trnmod & SDHC_TRNS_BLK_CNT_EN) &&\n                    (s->blkcnt == 0)) || (dscr.attr & SDHC_ADMA_ATTR_END)) {\n            trace_sdhci_adma_transfer_completed();\n            if (length || ((dscr.attr & SDHC_ADMA_ATTR_END) &&\n                (s->trnmod & SDHC_TRNS_BLK_CNT_EN) &&\n                s->blkcnt != 0)) {\n                trace_sdhci_error(\"SD/MMC host ADMA length mismatch\");\n                s->admaerr |= SDHC_ADMAERR_LENGTH_MISMATCH |\n                        SDHC_ADMAERR_STATE_ST_TFR;\n                if (s->errintstsen & SDHC_EISEN_ADMAERR) {\n                    trace_sdhci_error(\"Set ADMA error flag\");\n                    s->errintsts |= SDHC_EIS_ADMAERR;\n                    s->norintsts |= SDHC_NIS_ERR;\n                }\n\n                sdhci_update_irq(s);\n            }\n            sdhci_end_transfer(s);\n            return;\n        }\n\n    }\n\n    /* we have unfinished business - reschedule to continue ADMA */\n    timer_mod(s->transfer_timer,\n                   qemu_clock_get_ns(QEMU_CLOCK_VIRTUAL) + SDHC_TRANSFER_DELAY);\n}",
        "func_hash": 54427224725201055548567995202847143006,
        "file_name": "sdhci.c",
        "file_hash": 286742685023344467914463961907520076456,
        "cwe": [
            "CWE-119"
        ],
        "cve": "CVE-2021-3409",
        "cve_desc": "The patch for CVE-2020-17380/CVE-2020-25085 was found to be ineffective, thus making QEMU vulnerable to the out-of-bounds read/write access issues previously found in the SDHCI controller emulation code. This flaw allows a malicious privileged guest to crash the QEMU process on the host, resulting in a denial of service or potential code execution. QEMU up to (including) 5.2.0 is affected by this.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-3409",
        "func_name": "sdhci_do_adma",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 200695,
        "project": "linux",
        "commit_id": "fc739a058d99c9297ef6bfd923b809d85855b9a9",
        "project_url": "https://github.com/torvalds/linux",
        "commit_url": "https://github.com/torvalds/linux/commit/fc739a058d99c9297ef6bfd923b809d85855b9a9",
        "commit_message": "misc: fastrpc: prevent memory leak in fastrpc_dma_buf_attach\n\nIn fastrpc_dma_buf_attach if dma_get_sgtable fails the allocated memory\nfor a should be released.\n\nSigned-off-by: Navid Emamdoost <navid.emamdoost@gmail.com>\nLink: https://lore.kernel.org/r/20190925152742.16258-1-navid.emamdoost@gmail.com\nSigned-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static int fastrpc_dma_buf_attach(struct dma_buf *dmabuf,\n\t\t\t\t  struct dma_buf_attachment *attachment)\n{\n\tstruct fastrpc_dma_buf_attachment *a;\n\tstruct fastrpc_buf *buffer = dmabuf->priv;\n\tint ret;\n\n\ta = kzalloc(sizeof(*a), GFP_KERNEL);\n\tif (!a)\n\t\treturn -ENOMEM;\n\n\tret = dma_get_sgtable(buffer->dev, &a->sgt, buffer->virt,\n\t\t\t      FASTRPC_PHYS(buffer->phys), buffer->size);\n\tif (ret < 0) {\n\t\tdev_err(buffer->dev, \"failed to get scatterlist from DMA API\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\ta->dev = attachment->dev;\n\tINIT_LIST_HEAD(&a->node);\n\tattachment->priv = a;\n\n\tmutex_lock(&buffer->lock);\n\tlist_add(&a->node, &buffer->attachments);\n\tmutex_unlock(&buffer->lock);\n\n\treturn 0;\n}",
        "func_hash": 226882745088672382788622327400287132857,
        "file_name": "fastrpc.c",
        "file_hash": 22170772729445349597675548574301219151,
        "cwe": [
            "CWE-401"
        ],
        "cve": "CVE-2019-19069",
        "cve_desc": "A memory leak in the fastrpc_dma_buf_attach() function in drivers/misc/fastrpc.c in the Linux kernel before 5.3.9 allows attackers to cause a denial of service (memory consumption) by triggering dma_get_sgtable() failures, aka CID-fc739a058d99.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2019-19069",
        "func_name": "fastrpc_dma_buf_attach",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 200781,
        "project": "ncurses",
        "commit_id": "790a85dbd4a81d5f5d8dd02a44d84f01512ef443",
        "project_url": "https://github.com/mirror/ncurses",
        "commit_url": "https://github.com/mirror/ncurses/commit/790a85dbd4a81d5f5d8dd02a44d84f01512ef443#diff-7e95c7bc5f213e9be438e69a9d5d0f261a14952bcbd692f7b9014217b8047340",
        "commit_message": "ncurses 6.2 - patch 20200531\n\n+ correct configure version-check/warnng for g++ to allow for 10.x\n+ re-enable \"bel\" in konsole-base (report by Nia Huang)\n+ add linux-s entry (patch by Alexandre Montaron).\n+ drop long-obsolete convert_configure.pl\n+ add test/test_parm.c, for checking tparm changes.\n+ improve parameter-checking for tparm, adding function _nc_tiparm() to\n  handle the most-used case, which accepts only numeric parameters\n  (report/testcase by \"puppet-meteor\").\n+ use a more conservative estimate of the buffer-size in lib_tparm.c's\n  save_text() and save_number(), in case the sprintf() function\n  passes-through unexpected characters from a format specifier\n  (report/testcase by \"puppet-meteor\").\n+ add a check for end-of-string in cvtchar to handle a malformed\n  string in infotocap (report/testcase by \"puppet-meteor\").",
        "target": 1,
        "irrelevant": 0,
        "func_before": "cvtchar(register const char *sp)\n/* convert a character to a terminfo push */\n{\n    unsigned char c = 0;\n    int len;\n\n    switch (*sp) {\n    case '\\\\':\n\tswitch (*++sp) {\n\tcase '\\'':\n\tcase '$':\n\tcase '\\\\':\n\tcase '%':\n\t    c = UChar(*sp);\n\t    len = 2;\n\t    break;\n\tcase '\\0':\n\t    c = '\\\\';\n\t    len = 1;\n\t    break;\n\tcase '0':\n\tcase '1':\n\tcase '2':\n\tcase '3':\n\t    len = 1;\n\t    while (isdigit(UChar(*sp))) {\n\t\tc = UChar(8 * c + (*sp++ - '0'));\n\t\tlen++;\n\t    }\n\t    break;\n\tdefault:\n\t    c = UChar(*sp);\n\t    len = (c != '\\0') ? 2 : 1;\n\t    break;\n\t}\n\tbreak;\n    case '^':\n\tc = UChar(*++sp);\n\tif (c == '?')\n\t    c = 127;\n\telse\n\t    c &= 0x1f;\n\tlen = 2;\n\tbreak;\n    default:\n\tc = UChar(*sp);\n\tlen = (c != '\\0') ? 1 : 0;\n    }\n    if (isgraph(c) && c != ',' && c != '\\'' && c != '\\\\' && c != ':') {\n\tdp = save_string(dp, \"%\\'\");\n\tdp = save_char(dp, c);\n\tdp = save_char(dp, '\\'');\n    } else if (c != '\\0') {\n\tdp = save_string(dp, \"%{\");\n\tif (c > 99)\n\t    dp = save_char(dp, c / 100 + '0');\n\tif (c > 9)\n\t    dp = save_char(dp, ((int) (c / 10)) % 10 + '0');\n\tdp = save_char(dp, c % 10 + '0');\n\tdp = save_char(dp, '}');\n    }\n    return len;\n}",
        "func_hash": 56621931750240830327732003181202918311,
        "file_name": "captoinfo.c",
        "file_hash": null,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2021-39537",
        "cve_desc": "An issue was discovered in ncurses through v6.2-1. _nc_captoinfo in captoinfo.c has a heap-based buffer overflow.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-39537",
        "func_name": "cvtchar",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 200831,
        "project": "tor",
        "commit_id": "00fffbc1a15e2696a89c721d0c94dc333ff419ef",
        "project_url": "https://github.com/torproject/tor",
        "commit_url": "https://gitweb.torproject.org/tor.git/commitdiff/00fffbc1a15e2696a89c721d0c94dc333ff419ef",
        "commit_message": "Don't give the Guard flag to relays without the CVE-2011-2768 fix",
        "target": 1,
        "irrelevant": 0,
        "func_before": "set_routerstatus_from_routerinfo(routerstatus_t *rs,\n                                 routerinfo_t *ri, time_t now,\n                                 int naming, int listbadexits,\n                                 int listbaddirs, int vote_on_hsdirs)\n{\n  int unstable_version =\n    !tor_version_as_new_as(ri->platform,\"0.1.1.16-rc-cvs\");\n  memset(rs, 0, sizeof(routerstatus_t));\n\n  rs->is_authority =\n    router_digest_is_trusted_dir(ri->cache_info.identity_digest);\n\n  /* Already set by compute_performance_thresholds. */\n  rs->is_exit = ri->is_exit;\n  rs->is_stable = ri->is_stable =\n    router_is_active(ri, now) &&\n    !dirserv_thinks_router_is_unreliable(now, ri, 1, 0) &&\n    !unstable_version;\n  rs->is_fast = ri->is_fast =\n    router_is_active(ri, now) &&\n    !dirserv_thinks_router_is_unreliable(now, ri, 0, 1);\n  rs->is_running = ri->is_running; /* computed above */\n\n  if (naming) {\n    uint32_t name_status = dirserv_get_name_status(\n                         ri->cache_info.identity_digest, ri->nickname);\n    rs->is_named = (naming && (name_status & FP_NAMED)) ? 1 : 0;\n    rs->is_unnamed = (naming && (name_status & FP_UNNAMED)) ? 1 : 0;\n  }\n  rs->is_valid = ri->is_valid;\n\n  if (rs->is_fast &&\n      (router_get_advertised_bandwidth(ri) >= BANDWIDTH_TO_GUARANTEE_GUARD ||\n       router_get_advertised_bandwidth(ri) >=\n                              MIN(guard_bandwidth_including_exits,\n                                  guard_bandwidth_excluding_exits))) {\n    long tk = rep_hist_get_weighted_time_known(\n                                      ri->cache_info.identity_digest, now);\n    double wfu = rep_hist_get_weighted_fractional_uptime(\n                                      ri->cache_info.identity_digest, now);\n    rs->is_possible_guard = (wfu >= guard_wfu && tk >= guard_tk) ? 1 : 0;\n  } else {\n    rs->is_possible_guard = 0;\n  }\n  rs->is_bad_directory = listbaddirs && ri->is_bad_directory;\n  rs->is_bad_exit = listbadexits && ri->is_bad_exit;\n  ri->is_hs_dir = dirserv_thinks_router_is_hs_dir(ri, now);\n  rs->is_hs_dir = vote_on_hsdirs && ri->is_hs_dir;\n  rs->is_v2_dir = ri->dir_port != 0;\n\n  if (!strcasecmp(ri->nickname, UNNAMED_ROUTER_NICKNAME))\n    rs->is_named = rs->is_unnamed = 0;\n\n  rs->published_on = ri->cache_info.published_on;\n  memcpy(rs->identity_digest, ri->cache_info.identity_digest, DIGEST_LEN);\n  memcpy(rs->descriptor_digest, ri->cache_info.signed_descriptor_digest,\n         DIGEST_LEN);\n  rs->addr = ri->addr;\n  strlcpy(rs->nickname, ri->nickname, sizeof(rs->nickname));\n  rs->or_port = ri->or_port;\n  rs->dir_port = ri->dir_port;\n}",
        "func_hash": 318178419664162766552129781692369632852,
        "file_name": "dirserv.c",
        "file_hash": 144814081099750966253037063350589014941,
        "cwe": [
            "CWE-264"
        ],
        "cve": "CVE-2011-2768",
        "cve_desc": "Tor before 0.2.2.34, when configured as a client or bridge, sends a TLS certificate chain as part of an outgoing OR connection, which allows remote relays to bypass intended anonymity properties by reading this chain and then determining the set of entry guards that the client or bridge had selected.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2011-2768",
        "func_name": "set_routerstatus_from_routerinfo",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 200895,
        "project": "vim",
        "commit_id": "d6c67629ed05aae436164eec474832daf8ba7420",
        "project_url": "https://github.com/vim/vim",
        "commit_url": "https://github.com/vim/vim/commit/d6c67629ed05aae436164eec474832daf8ba7420",
        "commit_message": "patch 9.0.0260: using freed memory when using 'quickfixtextfunc' recursively\n\nProblem:    Using freed memory when using 'quickfixtextfunc' recursively.\nSolution:   Do not allow for recursion.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "call_qftf_func(qf_list_T *qfl, int qf_winid, long start_idx, long end_idx)\n{\n    callback_T\t*cb = &qftf_cb;\n    list_T\t*qftf_list = NULL;\n\n    // If 'quickfixtextfunc' is set, then use the user-supplied function to get\n    // the text to display. Use the local value of 'quickfixtextfunc' if it is\n    // set.\n    if (qfl->qf_qftf_cb.cb_name != NULL)\n\tcb = &qfl->qf_qftf_cb;\n    if (cb->cb_name != NULL)\n    {\n\ttypval_T\targs[1];\n\tdict_T\t\t*d;\n\ttypval_T\trettv;\n\n\t// create the dict argument\n\tif ((d = dict_alloc_lock(VAR_FIXED)) == NULL)\n\t    return NULL;\n\tdict_add_number(d, \"quickfix\", (long)IS_QF_LIST(qfl));\n\tdict_add_number(d, \"winid\", (long)qf_winid);\n\tdict_add_number(d, \"id\", (long)qfl->qf_id);\n\tdict_add_number(d, \"start_idx\", start_idx);\n\tdict_add_number(d, \"end_idx\", end_idx);\n\t++d->dv_refcount;\n\targs[0].v_type = VAR_DICT;\n\targs[0].vval.v_dict = d;\n\n\tqftf_list = NULL;\n\tif (call_callback(cb, 0, &rettv, 1, args) != FAIL)\n\t{\n\t    if (rettv.v_type == VAR_LIST)\n\t    {\n\t\tqftf_list = rettv.vval.v_list;\n\t\tqftf_list->lv_refcount++;\n\t    }\n\t    clear_tv(&rettv);\n\t}\n\tdict_unref(d);\n    }\n\n    return qftf_list;\n}",
        "func_hash": 339333086271181560510428879683096773754,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2022-2982",
        "cve_desc": "Use After Free in GitHub repository vim/vim prior to 9.0.0260.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-2982",
        "func_name": "call_qftf_func",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 200934,
        "project": "libvirt",
        "commit_id": "524de6cc35d3b222f0e940bb0fd027f5482572c5",
        "project_url": "https://github.com/libvirt/libvirt",
        "commit_url": "https://github.com/libvirt/libvirt/commit/524de6cc35d3b222f0e940bb0fd027f5482572c5",
        "commit_message": "virstoragetest: testBackingParse: Use VIR_DOMAIN_DEF_FORMAT_SECURE when formatting xml\n\nWe want to format even the secure information in tests.\n\nSigned-off-by: Peter Krempa <pkrempa@redhat.com>\nReviewed-by: Erik Skultety <eskultet@redhat.com>",
        "target": 1,
        "irrelevant": 0,
        "func_before": "testBackingParse(const void *args)\n{\n    const struct testBackingParseData *data = args;\n    g_auto(virBuffer) buf = VIR_BUFFER_INITIALIZER;\n    g_autofree char *xml = NULL;\n    g_autoptr(virStorageSource) src = NULL;\n    int rc;\n    int erc = data->rv;\n\n    /* expect failure return code with NULL expected data */\n    if (!data->expect)\n        erc = -1;\n\n    if ((rc = virStorageSourceNewFromBackingAbsolute(data->backing, &src)) != erc) {\n        fprintf(stderr, \"expected return value '%d' actual '%d'\\n\", erc, rc);\n        return -1;\n    }\n\n    if (!src)\n        return 0;\n\n    if (src && !data->expect) {\n        fprintf(stderr, \"parsing of backing store string '%s' should \"\n                        \"have failed\\n\", data->backing);\n        return -1;\n    }\n\n    if (virDomainDiskSourceFormat(&buf, src, \"source\", 0, false, 0, true, NULL) < 0 ||\n        !(xml = virBufferContentAndReset(&buf))) {\n        fprintf(stderr, \"failed to format disk source xml\\n\");\n        return -1;\n    }\n\n    if (STRNEQ(xml, data->expect)) {\n        fprintf(stderr, \"\\n backing store string '%s'\\n\"\n                        \"expected storage source xml:\\n%s\\n\"\n                        \"actual storage source xml:\\n%s\\n\",\n                        data->backing, data->expect, xml);\n        return -1;\n    }\n\n    return 0;\n}",
        "func_hash": 11097234962036893945341293376039418410,
        "file_name": "virstoragetest.c",
        "file_hash": 229136922246575533938843249875631381172,
        "cwe": [
            "CWE-212"
        ],
        "cve": "CVE-2020-14301",
        "cve_desc": "An information disclosure vulnerability was found in libvirt in versions before 6.3.0. HTTP cookies used to access network-based disks were saved in the XML dump of the guest domain. This flaw allows an attacker to access potentially sensitive information in the domain configuration via the `dumpxml` command.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2020-14301",
        "func_name": "testBackingParse",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 200976,
        "project": "vim",
        "commit_id": "395bd1f6d3edc9f7edb5d1f2d7deaf5a9e3ab93c",
        "project_url": "https://github.com/vim/vim",
        "commit_url": "https://github.com/vim/vim/commit/395bd1f6d3edc9f7edb5d1f2d7deaf5a9e3ab93c",
        "commit_message": "patch 8.2.4956: reading past end of line with \"gf\" in Visual block mode\n\nProblem:    Reading past end of line with \"gf\" in Visual block mode.\nSolution:   Do not include the NUL in the length.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "get_visual_text(\n    cmdarg_T\t*cap,\n    char_u\t**pp,\t    // return: start of selected text\n    int\t\t*lenp)\t    // return: length of selected text\n{\n    if (VIsual_mode != 'V')\n\tunadjust_for_sel();\n    if (VIsual.lnum != curwin->w_cursor.lnum)\n    {\n\tif (cap != NULL)\n\t    clearopbeep(cap->oap);\n\treturn FAIL;\n    }\n    if (VIsual_mode == 'V')\n    {\n\t*pp = ml_get_curline();\n\t*lenp = (int)STRLEN(*pp);\n    }\n    else\n    {\n\tif (LT_POS(curwin->w_cursor, VIsual))\n\t{\n\t    *pp = ml_get_pos(&curwin->w_cursor);\n\t    *lenp = VIsual.col - curwin->w_cursor.col + 1;\n\t}\n\telse\n\t{\n\t    *pp = ml_get_pos(&VIsual);\n\t    *lenp = curwin->w_cursor.col - VIsual.col + 1;\n\t}\n\tif (**pp == NUL)\n\t    *lenp = 0;\n\tif (has_mbyte && *lenp > 0)\n\t    // Correct the length to include all bytes of the last character.\n\t    *lenp += (*mb_ptr2len)(*pp + (*lenp - 1)) - 1;\n    }\n    reset_VIsual_and_resel();\n    return OK;\n}",
        "func_hash": 284497166738290361019440448049627151253,
        "file_name": "normal.c",
        "file_hash": null,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2022-1720",
        "cve_desc": "Buffer Over-read in function grab_file_name in GitHub repository vim/vim prior to 8.2.4956. This vulnerability is capable of crashing the software, memory modification, and possible remote execution.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-1720",
        "func_name": "get_visual_text",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 201006,
        "project": "linux",
        "commit_id": "2a8859f373b0a86f0ece8ec8312607eacf12485d",
        "project_url": "https://github.com/torvalds/linux",
        "commit_url": "https://github.com/torvalds/linux/commit/2a8859f373b0a86f0ece8ec8312607eacf12485d",
        "commit_message": "KVM: x86/mmu: do compare-and-exchange of gPTE via the user address\n\nFNAME(cmpxchg_gpte) is an inefficient mess.  It is at least decent if it\ncan go through get_user_pages_fast(), but if it cannot then it tries to\nuse memremap(); that is not just terribly slow, it is also wrong because\nit assumes that the VM_PFNMAP VMA is contiguous.\n\nThe right way to do it would be to do the same thing as\nhva_to_pfn_remapped() does since commit add6a0cd1c5b (\"KVM: MMU: try to\nfix up page faults before giving up\", 2016-07-05), using follow_pte()\nand fixup_user_fault() to determine the correct address to use for\nmemremap().  To do this, one could for example extract hva_to_pfn()\nfor use outside virt/kvm/kvm_main.c.  But really there is no reason to\ndo that either, because there is already a perfectly valid address to\ndo the cmpxchg() on, only it is a userspace address.  That means doing\nuser_access_begin()/user_access_end() and writing the code in assembly\nto handle exceptions correctly.  Worse, the guest PTE can be 8-byte\neven on i686 so there is the extra complication of using cmpxchg8b to\naccount for.  But at least it is an efficient mess.\n\n(Thanks to Linus for suggesting improvement on the inline assembly).\n\nReported-by: Qiuhao Li <qiuhao@sysec.org>\nReported-by: Gaoning Pan <pgn@zju.edu.cn>\nReported-by: Yongkang Jia <kangel@zju.edu.cn>\nReported-by: syzbot+6cde2282daa792c49ab8@syzkaller.appspotmail.com\nDebugged-by: Tadeusz Struk <tadeusz.struk@linaro.org>\nTested-by: Maxim Levitsky <mlevitsk@redhat.com>\nCc: stable@vger.kernel.org\nFixes: bd53cb35a3e9 (\"X86/KVM: Handle PFNs outside of kernel reach when touching GPTEs\")\nSigned-off-by: Paolo Bonzini <pbonzini@redhat.com>",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static int FNAME(cmpxchg_gpte)(struct kvm_vcpu *vcpu, struct kvm_mmu *mmu,\n\t\t\t       pt_element_t __user *ptep_user, unsigned index,\n\t\t\t       pt_element_t orig_pte, pt_element_t new_pte)\n{\n\tint npages;\n\tpt_element_t ret;\n\tpt_element_t *table;\n\tstruct page *page;\n\n\tnpages = get_user_pages_fast((unsigned long)ptep_user, 1, FOLL_WRITE, &page);\n\tif (likely(npages == 1)) {\n\t\ttable = kmap_atomic(page);\n\t\tret = CMPXCHG(&table[index], orig_pte, new_pte);\n\t\tkunmap_atomic(table);\n\n\t\tkvm_release_page_dirty(page);\n\t} else {\n\t\tstruct vm_area_struct *vma;\n\t\tunsigned long vaddr = (unsigned long)ptep_user & PAGE_MASK;\n\t\tunsigned long pfn;\n\t\tunsigned long paddr;\n\n\t\tmmap_read_lock(current->mm);\n\t\tvma = find_vma_intersection(current->mm, vaddr, vaddr + PAGE_SIZE);\n\t\tif (!vma || !(vma->vm_flags & VM_PFNMAP)) {\n\t\t\tmmap_read_unlock(current->mm);\n\t\t\treturn -EFAULT;\n\t\t}\n\t\tpfn = ((vaddr - vma->vm_start) >> PAGE_SHIFT) + vma->vm_pgoff;\n\t\tpaddr = pfn << PAGE_SHIFT;\n\t\ttable = memremap(paddr, PAGE_SIZE, MEMREMAP_WB);\n\t\tif (!table) {\n\t\t\tmmap_read_unlock(current->mm);\n\t\t\treturn -EFAULT;\n\t\t}\n\t\tret = CMPXCHG(&table[index], orig_pte, new_pte);\n\t\tmemunmap(table);\n\t\tmmap_read_unlock(current->mm);\n\t}\n\n\treturn (ret != orig_pte);\n}",
        "func_hash": 328878992778449870831639903805721619554,
        "file_name": "paging_tmpl.h",
        "file_hash": 99223665847947661027332128453448877347,
        "cwe": [
            "CWE-416"
        ],
        "cve": "CVE-2022-1158",
        "cve_desc": "A flaw was found in KVM. When updating a guest's page table entry, vm_pgoff was improperly used as the offset to get the page's pfn. As vaddr and vm_pgoff are controllable by user-mode processes, this flaw allows unprivileged local users on the host to write outside the userspace region and potentially corrupt the kernel, resulting in a denial of service condition.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-1158",
        "func_name": "FNAME",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 201007,
        "project": "pjproject",
        "commit_id": "560a1346f87aabe126509bb24930106dea292b00",
        "project_url": "https://github.com/pjsip/pjproject",
        "commit_url": "https://github.com/pjsip/pjproject/commit/560a1346f87aabe126509bb24930106dea292b00",
        "commit_message": "Merge pull request from GHSA-f5qg-pqcg-765m",
        "target": 1,
        "irrelevant": 1,
        "func_before": "static int print_media_desc(const pjmedia_sdp_media *m, char *buf, pj_size_t len)\n{\n    char *p = buf;\n    char *end = buf+len;\n    unsigned i;\n    int printed;\n\n    /* check length for the \"m=\" line. */\n    if (len < (pj_size_t)m->desc.media.slen+m->desc.transport.slen+12+24) {\n\treturn -1;\n    }\n    *p++ = 'm';\t    /* m= */\n    *p++ = '=';\n    pj_memcpy(p, m->desc.media.ptr, m->desc.media.slen);\n    p += m->desc.media.slen;\n    *p++ = ' ';\n    printed = pj_utoa(m->desc.port, p);\n    p += printed;\n    if (m->desc.port_count > 1) {\n\t*p++ = '/';\n\tprinted = pj_utoa(m->desc.port_count, p);\n\tp += printed;\n    }\n    *p++ = ' ';\n    pj_memcpy(p, m->desc.transport.ptr, m->desc.transport.slen);\n    p += m->desc.transport.slen;\n    for (i=0; i<m->desc.fmt_count; ++i) {\n\t*p++ = ' ';\n\tpj_memcpy(p, m->desc.fmt[i].ptr, m->desc.fmt[i].slen);\n\tp += m->desc.fmt[i].slen;\n    }\n    *p++ = '\\r';\n    *p++ = '\\n';\n\n    /* print connection info, if present. */\n    if (m->conn) {\n\tprinted = print_connection_info(m->conn, p, (int)(end-p));\n\tif (printed < 0) {\n\t    return -1;\n\t}\n\tp += printed;\n    }\n    \n    /* print optional bandwidth info. */\n    for (i=0; i<m->bandw_count; ++i) {\n\tprinted = (int)print_bandw(m->bandw[i], p, end-p);\n\tif (printed < 0) {\n\t    return -1;\n\t}\n\tp += printed;\n    }\n\n    /* print attributes. */\n    for (i=0; i<m->attr_count; ++i) {\n\tprinted = (int)print_attr(m->attr[i], p, end-p);\n\tif (printed < 0) {\n\t    return -1;\n\t}\n\tp += printed;\n    }\n\n    return (int)(p-buf);\n}",
        "func_hash": 243109353869436532488614405590479215364,
        "file_name": "sdp.c",
        "file_hash": 204440288713003047579803744169338279171,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2022-24764",
        "cve_desc": "PJSIP is a free and open source multimedia communication library written in C. Versions 2.12 and prior contain a stack buffer overflow vulnerability that affects PJSUA2 users or users that call the API `pjmedia_sdp_print(), pjmedia_sdp_media_print()`. Applications that do not use PJSUA2 and do not directly call `pjmedia_sdp_print()` or `pjmedia_sdp_media_print()` should not be affected. A patch is available on the `master` branch of the `pjsip/pjproject` GitHub repository. There are currently no known workarounds.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-24764",
        "func_name": "print_media_desc",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 201343,
        "project": "linux",
        "commit_id": "a3727a8bac0a9e77c70820655fd8715523ba3db7",
        "project_url": "https://github.com/torvalds/linux",
        "commit_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=a3727a8bac0a9e77c70820655fd8715523ba3db7",
        "commit_message": "selinux,smack: fix subjective/objective credential use mixups\n\nJann Horn reported a problem with commit eb1231f73c4d (\"selinux:\nclarify task subjective and objective credentials\") where some LSM\nhooks were attempting to access the subjective credentials of a task\nother than the current task.  Generally speaking, it is not safe to\naccess another task's subjective credentials and doing so can cause\na number of problems.\n\nFurther, while looking into the problem, I realized that Smack was\nsuffering from a similar problem brought about by a similar commit\n1fb057dcde11 (\"smack: differentiate between subjective and objective\ntask credentials\").\n\nThis patch addresses this problem by restoring the use of the task's\nobjective credentials in those cases where the task is other than the\ncurrent executing task.  Not only does this resolve the problem\nreported by Jann, it is arguably the correct thing to do in these\ncases.\n\nCc: stable@vger.kernel.org\nFixes: eb1231f73c4d (\"selinux: clarify task subjective and objective credentials\")\nFixes: 1fb057dcde11 (\"smack: differentiate between subjective and objective task credentials\")\nReported-by: Jann Horn <jannh@google.com>\nAcked-by: Eric W. Biederman <ebiederm@xmission.com>\nAcked-by: Casey Schaufler <casey@schaufler-ca.com>\nSigned-off-by: Paul Moore <paul@paul-moore.com>",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static int selinux_ptrace_traceme(struct task_struct *parent)\n{\n\treturn avc_has_perm(&selinux_state,\n\t\t\t    task_sid_subj(parent), task_sid_obj(current),\n\t\t\t    SECCLASS_PROCESS, PROCESS__PTRACE, NULL);\n}",
        "func_hash": 244235637020461368565337014513482216980,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-416"
        ],
        "cve": "CVE-2021-43057",
        "cve_desc": "An issue was discovered in the Linux kernel before 5.14.8. A use-after-free in selinux_ptrace_traceme (aka the SELinux handler for PTRACE_TRACEME) could be used by local attackers to cause memory corruption and escalate privileges, aka CID-a3727a8bac0a. This occurs because of an attempt to access the subjective credentials of another task.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-43057",
        "func_name": "selinux_ptrace_traceme",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 201353,
        "project": "wireless-drivers",
        "commit_id": "8b51dc7291473093c821195c4b6af85fadedbc2f",
        "project_url": "https://git.kernel.org/pub/scm/linux/kernel/git/kvalo/wireless-drivers",
        "commit_url": "https://git.kernel.org/pub/scm/linux/kernel/git/kvalo/wireless-drivers.git/commit/?id=8b51dc7291473093c821195c4b6af85fadedbc2f",
        "commit_message": "rsi: fix a double free bug in rsi_91x_deinit()\n\n`dev` (struct rsi_91x_usbdev *) field of adapter\n(struct rsi_91x_usbdev *) is allocated  and initialized in\n`rsi_init_usb_interface`. If any error is detected in information\nread from the device side,  `rsi_init_usb_interface` will be\nfreed. However, in the higher level error handling code in\n`rsi_probe`, if error is detected, `rsi_91x_deinit` is called\nagain, in which `dev` will be freed again, resulting double free.\n\nThis patch fixes the double free by removing the free operation on\n`dev` in `rsi_init_usb_interface`, because `rsi_91x_deinit` is also\nused in `rsi_disconnect`, in that code path, the `dev` field is not\n (and thus needs to be) freed.\n\nThis bug was found in v4.19, but is also present in the latest version\nof kernel. Fixes CVE-2019-15504.\n\nReported-by: Hui Peng <benquike@gmail.com>\nReported-by: Mathias Payer <mathias.payer@nebelwelt.net>\nSigned-off-by: Hui Peng <benquike@gmail.com>\nReviewed-by: Guenter Roeck <linux@roeck-us.net>\nSigned-off-by: Kalle Valo <kvalo@codeaurora.org>",
        "target": 1,
        "irrelevant": 1,
        "func_before": "static int rsi_init_usb_interface(struct rsi_hw *adapter,\n\t\t\t\t  struct usb_interface *pfunction)\n{\n\tstruct rsi_91x_usbdev *rsi_dev;\n\tint status;\n\n\trsi_dev = kzalloc(sizeof(*rsi_dev), GFP_KERNEL);\n\tif (!rsi_dev)\n\t\treturn -ENOMEM;\n\n\tadapter->rsi_dev = rsi_dev;\n\trsi_dev->usbdev = interface_to_usbdev(pfunction);\n\trsi_dev->priv = (void *)adapter;\n\n\tif (rsi_find_bulk_in_and_out_endpoints(pfunction, adapter)) {\n\t\tstatus = -EINVAL;\n\t\tgoto fail_eps;\n\t}\n\n\tadapter->device = &pfunction->dev;\n\tusb_set_intfdata(pfunction, adapter);\n\n\trsi_dev->tx_buffer = kmalloc(2048, GFP_KERNEL);\n\tif (!rsi_dev->tx_buffer) {\n\t\tstatus = -ENOMEM;\n\t\tgoto fail_eps;\n\t}\n\n\tif (rsi_usb_init_rx(adapter)) {\n\t\trsi_dbg(ERR_ZONE, \"Failed to init RX handle\\n\");\n\t\tstatus = -ENOMEM;\n\t\tgoto fail_rx;\n\t}\n\n\trsi_dev->tx_blk_size = 252;\n\tadapter->block_size = rsi_dev->tx_blk_size;\n\n\t/* Initializing function callbacks */\n\tadapter->check_hw_queue_status = rsi_usb_check_queue_status;\n\tadapter->determine_event_timeout = rsi_usb_event_timeout;\n\tadapter->rsi_host_intf = RSI_HOST_INTF_USB;\n\tadapter->host_intf_ops = &usb_host_intf_ops;\n\n#ifdef CONFIG_RSI_DEBUGFS\n\t/* In USB, one less than the MAX_DEBUGFS_ENTRIES entries is required */\n\tadapter->num_debugfs_entries = (MAX_DEBUGFS_ENTRIES - 1);\n#endif\n\n\trsi_dbg(INIT_ZONE, \"%s: Enabled the interface\\n\", __func__);\n\treturn 0;\n\nfail_rx:\n\tkfree(rsi_dev->tx_buffer);\n\nfail_eps:\n\tkfree(rsi_dev);\n\n\treturn status;\n}",
        "func_hash": 38914523915054214786919182237560230029,
        "file_name": "rsi_91x_usb.c",
        "file_hash": 337775591275050809530599688018008269692,
        "cwe": [
            "CWE-415"
        ],
        "cve": "CVE-2019-15504",
        "cve_desc": "drivers/net/wireless/rsi/rsi_91x_usb.c in the Linux kernel through 5.2.9 has a Double Free via crafted USB device traffic (which may be remote via usbip or usbredir).",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2019-15504",
        "func_name": "rsi_init_usb_interface",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 201382,
        "project": "gerbv",
        "commit_id": "672214abb47a802fc000125996e6e0a46c623a4e",
        "project_url": "https://github.com/gerbv/gerbv",
        "commit_url": "https://github.com/gerbv/gerbv/commit/672214abb47a802fc000125996e6e0a46c623a4e",
        "commit_message": "Add test to demonstrate buffer overrun",
        "target": 1,
        "irrelevant": 0,
        "func_before": "drill_parse_T_code(gerb_file_t *fd, drill_state_t *state,\n\t\t\tgerbv_image_t *image, ssize_t file_line)\n{\n    int tool_num;\n    gboolean done = FALSE;\n    int temp;\n    double size;\n    gerbv_drill_stats_t *stats = image->drill_stats;\n    gerbv_aperture_t *apert;\n    gchar *tmps;\n    gchar *string;\n\n    dprintf(\"---> entering %s()...\\n\", __FUNCTION__);\n\n    /* Sneak a peek at what's hiding after the 'T'. Ugly fix for\n       broken headers from Orcad, which is crap */\n    temp = gerb_fgetc(fd);\n    dprintf(\"  Found a char '%s' (0x%02x) after the T\\n\",\n\t    gerbv_escape_char(temp), temp);\n    \n    /* might be a tool tool change stop switch on/off*/\n    if((temp == 'C') && ((fd->ptr + 2) < fd->datalen)){\n    \tif(gerb_fgetc(fd) == 'S'){\n    \t    if (gerb_fgetc(fd) == 'T' ){\n    \t  \tfd->ptr -= 4;\n    \t  \ttmps = get_line(fd++);\n    \t  \tgerbv_stats_printf(stats->error_list, GERBV_MESSAGE_NOTE, -1,\n\t\t\t_(\"Tool change stop switch found \\\"%s\\\" \"\n\t\t\t    \"at line %ld in file \\\"%s\\\"\"),\n\t\t\ttmps, file_line, fd->filename);\n\t  \tg_free (tmps);\n\n\t  \treturn -1;\n\t    }\n\t    gerb_ungetc(fd);\n\t}\n\tgerb_ungetc(fd);\n    }\n\n    if( !(isdigit(temp) != 0 || temp == '+' || temp =='-') ) {\n\tif(temp != EOF) {\n\t    gerbv_stats_printf(stats->error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t   _(\"OrCAD bug: Junk text found in place of tool definition\"));\n\t    tmps = get_line(fd);\n\t    gerbv_stats_printf(stats->error_list, GERBV_MESSAGE_WARNING, -1,\n\t\t    _(\"Junk text \\\"%s\\\" \"\n\t\t\t\"at line %ld in file \\\"%s\\\"\"),\n\t\t    tmps, file_line, fd->filename);\n\t    g_free (tmps);\n\t    gerbv_stats_printf(stats->error_list, GERBV_MESSAGE_WARNING, -1,\n\t\t\t\t  _(\"Ignoring junk text\"));\n\t}\n\treturn -1;\n    }\n    gerb_ungetc(fd);\n\n    tool_num = (int) gerb_fgetint(fd, NULL);\n    dprintf (\"  Handling tool T%d at line %ld\\n\", tool_num, file_line);\n\n    if (tool_num == 0) \n\treturn tool_num; /* T00 is a command to unload the drill */\n\n    if (tool_num < TOOL_MIN || tool_num >= TOOL_MAX) {\n\tgerbv_stats_printf(stats->error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t_(\"Out of bounds drill number %d \"\n\t\t    \"at line %ld in file \\\"%s\\\"\"),\n\t\ttool_num, file_line, fd->filename);\n    }\n\n    /* Set the current tool to the correct one */\n    state->current_tool = tool_num;\n    apert = image->aperture[tool_num];\n\n    /* Check for a size definition */\n    temp = gerb_fgetc(fd);\n\n    /* This bit of code looks for a tool definition by scanning for strings\n     * of form TxxC, TxxF, TxxS.  */\n    while (!done) {\n\tswitch((char)temp) {\n\tcase 'C':\n\t    size = read_double(fd, state->header_number_format, GERBV_OMIT_ZEROS_TRAILING, state->decimals);\n\t    dprintf (\"  Read a size of %g\\n\", size);\n\n\t    if (state->unit == GERBV_UNIT_MM) {\n\t\tsize /= 25.4;\n\t    } else if(size >= 4.0) {\n\t\t/* If the drill size is >= 4 inches, assume that this\n\t\t   must be wrong and that the units are mils.\n\t\t   The limit being 4 inches is because the smallest drill\n\t\t   I've ever seen used is 0,3mm(about 12mil). Half of that\n\t\t   seemed a bit too small a margin, so a third it is */\n\n\t\tgerbv_stats_printf(stats->error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t\t_(\"Read a drill of diameter %g inches \"\n\t\t\t    \"at line %ld in file \\\"%s\\\"\"),\n\t\t\t    size, file_line, fd->filename);\n\t\tgerbv_stats_printf(stats->error_list, GERBV_MESSAGE_WARNING, -1,\n\t\t\t_(\"Assuming units are mils\"));\n\t\tsize /= 1000.0;\n\t    }\n\n\t    if (size <= 0. || size >= 10000.) {\n\t\tgerbv_stats_printf(stats->error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t\t_(\"Unreasonable drill size %g found for drill %d \"\n\t\t\t    \"at line %ld in file \\\"%s\\\"\"),\n\t\t\t    size, tool_num, file_line, fd->filename);\n\t    } else {\n\t\tif (apert != NULL) {\n\t\t    /* allow a redefine of a tool only if the new definition is exactly the same.\n\t\t     * This avoid lots of spurious complaints with the output of some cad\n\t\t     * tools while keeping complaints if there is a true problem\n\t\t     */\n\t\t    if (apert->parameter[0] != size\n\t\t    ||  apert->type != GERBV_APTYPE_CIRCLE\n\t\t    ||  apert->nuf_parameters != 1\n\t\t    ||  apert->unit != GERBV_UNIT_INCH) {\n\n\t\t\tgerbv_stats_printf(stats->error_list,\n\t\t\t\tGERBV_MESSAGE_ERROR, -1,\n\t\t\t\t_(\"Found redefinition of drill %d \"\n\t\t\t\t\"at line %ld in file \\\"%s\\\"\"),\n\t\t\t\ttool_num, file_line, fd->filename);\n\t\t    }\n\t\t} else {\n\t\t    apert = image->aperture[tool_num] =\n\t\t\t\t\t\tg_new0(gerbv_aperture_t, 1);\n\t\t    if (apert == NULL)\n\t\t\tGERB_FATAL_ERROR(\"malloc tool failed in %s()\",\n\t\t\t\t\t__FUNCTION__);\n\n\t\t    /* There's really no way of knowing what unit the tools\n\t\t       are defined in without sneaking a peek in the rest of\n\t\t       the file first. That's done in drill_guess_format() */\n\t\t    apert->parameter[0] = size;\n\t\t    apert->type = GERBV_APTYPE_CIRCLE;\n\t\t    apert->nuf_parameters = 1;\n\t\t    apert->unit = GERBV_UNIT_INCH;\n\t\t}\n\t    }\n\t    \n\t    /* Add the tool whose definition we just found into the list\n\t     * of tools for this layer used to generate statistics. */\n\t    stats = image->drill_stats;\n\t    string = g_strdup_printf(\"%s\", (state->unit == GERBV_UNIT_MM ? _(\"mm\") : _(\"inch\")));\n\t    drill_stats_add_to_drill_list(stats->drill_list, \n\t\t\t\t\t  tool_num, \n\t\t\t\t\t  state->unit == GERBV_UNIT_MM ? size*25.4 : size, \n\t\t\t\t\t  string);\n\t    g_free(string);\n\t    break;\n\n\tcase 'F':\n\tcase 'S' :\n\t    /* Silently ignored. They're not important. */\n\t    gerb_fgetint(fd, NULL);\n\t    break;\n\n\tdefault:\n\t    /* Stop when finding anything but what's expected\n\t       (and put it back) */\n\t    gerb_ungetc(fd);\n\t    done = TRUE;\n\t    break;\n\t}  /* switch((char)temp) */\n\n\ttemp = gerb_fgetc(fd);\n\tif (EOF == temp) {\n\t    gerbv_stats_printf(stats->error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t    _(\"Unexpected EOF encountered in header of \"\n\t\t\t\"drill file \\\"%s\\\"\"), fd->filename);\n\n\t/* Restore new line character for processing */\n\tif ('\\n' == temp || '\\r' == temp)\n\t    gerb_ungetc(fd);\n\t}\n    }   /* while(!done) */  /* Done looking at tool definitions */\n\n    /* Catch the tools that aren't defined.\n       This isn't strictly a good thing, but at least something is shown */\n    if (apert == NULL) {\n        double dia;\n\n\tapert = image->aperture[tool_num] = g_new0(gerbv_aperture_t, 1);\n\tif (apert == NULL)\n\t    GERB_FATAL_ERROR(\"malloc tool failed in %s()\", __FUNCTION__);\n\n        /* See if we have the tool table */\n        dia = gerbv_get_tool_diameter(tool_num);\n        if (dia <= 0) {\n            /*\n             * There is no tool. So go out and make some.\n             * This size calculation is, of course, totally bogus.\n             */\n            dia = (double)(16 + 8 * tool_num) / 1000;\n            /*\n             * Oooh, this is sooo ugly. But some CAD systems seem to always\n             * use T00 at the end of the file while others that don't have\n             * tool definitions inside the file never seem to use T00 at all.\n             */\n            if (tool_num != 0) {\n\t\tgerbv_stats_printf(stats->error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t\t_(\"Tool %02d used without being defined \"\n\t\t\t    \"at line %ld in file \\\"%s\\\"\"),\n\t\t\ttool_num, file_line, fd->filename);\n\t\tgerbv_stats_printf(stats->error_list, GERBV_MESSAGE_WARNING, -1,\n\t\t\t_(\"Setting a default size of %g\\\"\"), dia);\n            }\n\t}\n\n\tapert->type = GERBV_APTYPE_CIRCLE;\n\tapert->nuf_parameters = 1;\n\tapert->parameter[0] = dia;\n\n\t/* Add the tool whose definition we just found into the list\n\t * of tools for this layer used to generate statistics. */\n\tif (tool_num != 0) {  /* Only add non-zero tool nums.  \n\t\t\t       * Zero = unload command. */\n\t    stats = image->drill_stats;\n\t    string = g_strdup_printf(\"%s\", \n\t\t\t\t     (state->unit == GERBV_UNIT_MM ? _(\"mm\") : _(\"inch\")));\n\t    drill_stats_add_to_drill_list(stats->drill_list, \n\t\t\t\t\t  tool_num, \n\t\t\t\t\t  state->unit == GERBV_UNIT_MM ? dia*25.4 : dia,\n\t\t\t\t\t  string);\n\t    g_free(string);\n\t}\n    } /* if(image->aperture[tool_num] == NULL) */\t\n    \n    dprintf(\"<----  ...leaving %s()\\n\", __FUNCTION__);\n\n    return tool_num;\n} /* drill_parse_T_code() */",
        "func_hash": 185752158214328372341115505036759500651,
        "file_name": "drill.c",
        "file_hash": 62463866492734341751893387181625909179,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2021-40391",
        "cve_desc": "An out-of-bounds write vulnerability exists in the drill format T-code tool number functionality of Gerbv 2.7.0, dev (commit b5f1eacd), and the forked version of Gerbv (commit 71493260). A specially-crafted drill file can lead to code execution. An attacker can provide a malicious file to trigger this vulnerability.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-40391",
        "func_name": "drill_parse_T_code",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 201384,
        "project": "vim",
        "commit_id": "34f8117dec685ace52cd9e578e2729db278163fc",
        "project_url": "https://github.com/vim/vim",
        "commit_url": "https://github.com/vim/vim/commit/34f8117dec685ace52cd9e578e2729db278163fc",
        "commit_message": "patch 8.2.4397: crash when using many composing characters in error message\n\nProblem:    Crash when using many composing characters in error message.\nSolution:   Use mb_cptr2char_adv() instead of mb_ptr2char_adv().",
        "target": 1,
        "irrelevant": 0,
        "func_before": "ga_concat_shorten_esc(garray_T *gap, char_u *str)\n{\n    char_u  *p;\n    char_u  *s;\n    int\t    c;\n    int\t    clen;\n    char_u  buf[NUMBUFLEN];\n    int\t    same_len;\n\n    if (str == NULL)\n    {\n\tga_concat(gap, (char_u *)\"NULL\");\n\treturn;\n    }\n\n    for (p = str; *p != NUL; ++p)\n    {\n\tsame_len = 1;\n\ts = p;\n\tc = mb_ptr2char_adv(&s);\n\tclen = s - p;\n\twhile (*s != NUL && c == mb_ptr2char(s))\n\t{\n\t    ++same_len;\n\t    s += clen;\n\t}\n\tif (same_len > 20)\n\t{\n\t    ga_concat(gap, (char_u *)\"\\\\[\");\n\t    ga_concat_esc(gap, p, clen);\n\t    ga_concat(gap, (char_u *)\" occurs \");\n\t    vim_snprintf((char *)buf, NUMBUFLEN, \"%d\", same_len);\n\t    ga_concat(gap, buf);\n\t    ga_concat(gap, (char_u *)\" times]\");\n\t    p = s - 1;\n\t}\n\telse\n\t    ga_concat_esc(gap, p, clen);\n    }\n}",
        "func_hash": 50963215449221402235184881814854547880,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2022-0629",
        "cve_desc": "Stack-based Buffer Overflow in GitHub repository vim/vim prior to 8.2.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-0629",
        "func_name": "ga_concat_shorten_esc",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 201451,
        "project": "ImageMagick6",
        "commit_id": "e6ea5876e0228165ee3abc6e959aa174cee06680",
        "project_url": "https://github.com/ImageMagick/ImageMagick6",
        "commit_url": "https://github.com/ImageMagick/ImageMagick6/commit/e6ea5876e0228165ee3abc6e959aa174cee06680",
        "commit_message": "https://github.com/ImageMagick/ImageMagick/issues/4988",
        "target": 1,
        "irrelevant": 1,
        "func_before": "static Image *ReadCINImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n#define MonoColorType  1\n#define RGBColorType  3\n\n  char\n    property[MaxTextExtent];\n\n  CINInfo\n    cin;\n\n  Image\n    *image;\n\n  MagickBooleanType\n    status;\n\n  MagickOffsetType\n    offset;\n\n  QuantumInfo\n    *quantum_info;\n\n  QuantumType\n    quantum_type;\n\n  ssize_t\n    i;\n\n  PixelPacket\n    *q;\n\n  size_t\n    extent,\n    length;\n\n  ssize_t\n    count,\n    y;\n\n  unsigned char\n    magick[4],\n    *pixels;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  image=AcquireImage(image_info);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    File information.\n  */\n  offset=0;\n  count=ReadBlob(image,4,magick);\n  offset+=count;\n  if ((count != 4) ||\n      ((LocaleNCompare((char *) magick,\"\\200\\052\\137\\327\",4) != 0)))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  memset(&cin,0,sizeof(cin));\n  image->endian=(magick[0] == 0x80) && (magick[1] == 0x2a) &&\n    (magick[2] == 0x5f) && (magick[3] == 0xd7) ? MSBEndian : LSBEndian;\n  cin.file.image_offset=ReadBlobLong(image);\n  offset+=4;\n  cin.file.generic_length=ReadBlobLong(image);\n  offset+=4;\n  cin.file.industry_length=ReadBlobLong(image);\n  offset+=4;\n  cin.file.user_length=ReadBlobLong(image);\n  offset+=4;\n  cin.file.file_size=ReadBlobLong(image);\n  offset+=4;\n  offset+=ReadBlob(image,sizeof(cin.file.version),(unsigned char *)\n    cin.file.version);\n  (void) CopyMagickString(property,cin.file.version,sizeof(cin.file.version));\n  (void) SetImageProperty(image,\"dpx:file.version\",property);\n  offset+=ReadBlob(image,sizeof(cin.file.filename),(unsigned char *)\n    cin.file.filename);\n  (void) CopyMagickString(property,cin.file.filename,sizeof(cin.file.filename));\n  (void) SetImageProperty(image,\"dpx:file.filename\",property);\n  offset+=ReadBlob(image,sizeof(cin.file.create_date),(unsigned char *)\n    cin.file.create_date);\n  (void) CopyMagickString(property,cin.file.create_date,\n    sizeof(cin.file.create_date));\n  (void) SetImageProperty(image,\"dpx:file.create_date\",property);\n  offset+=ReadBlob(image,sizeof(cin.file.create_time),(unsigned char *)\n    cin.file.create_time);\n  (void) CopyMagickString(property,cin.file.create_time,\n     sizeof(cin.file.create_time));\n  (void) SetImageProperty(image,\"dpx:file.create_time\",property);\n  offset+=ReadBlob(image,sizeof(cin.file.reserve),(unsigned char *)\n    cin.file.reserve);\n  /*\n    Image information.\n  */\n  cin.image.orientation=(unsigned char) ReadBlobByte(image);\n  offset++;\n  if (cin.image.orientation != (unsigned char) (~0))\n    (void) FormatImageProperty(image,\"dpx:image.orientation\",\"%d\",\n      cin.image.orientation);\n  switch (cin.image.orientation)\n  {\n    default:\n    case 0: image->orientation=TopLeftOrientation; break;\n    case 1: image->orientation=TopRightOrientation; break;\n    case 2: image->orientation=BottomLeftOrientation; break;\n    case 3: image->orientation=BottomRightOrientation; break;\n    case 4: image->orientation=LeftTopOrientation; break;\n    case 5: image->orientation=RightTopOrientation; break;\n    case 6: image->orientation=LeftBottomOrientation; break;\n    case 7: image->orientation=RightBottomOrientation; break;\n  }\n  cin.image.number_channels=(unsigned char) ReadBlobByte(image);\n  offset++;\n  offset+=ReadBlob(image,sizeof(cin.image.reserve1),(unsigned char *)\n    cin.image.reserve1);\n  for (i=0; i < 8; i++)\n  {\n    cin.image.channel[i].designator[0]=(unsigned char) ReadBlobByte(image);\n    offset++;\n    cin.image.channel[i].designator[1]=(unsigned char) ReadBlobByte(image);\n    offset++;\n    cin.image.channel[i].bits_per_pixel=(unsigned char) ReadBlobByte(image);\n    offset++;\n    cin.image.channel[i].reserve=(unsigned char) ReadBlobByte(image);\n    offset++;\n    cin.image.channel[i].pixels_per_line=ReadBlobLong(image);\n    offset+=4;\n    cin.image.channel[i].lines_per_image=ReadBlobLong(image);\n    offset+=4;\n    cin.image.channel[i].min_data=ReadBlobFloat(image);\n    offset+=4;\n    cin.image.channel[i].min_quantity=ReadBlobFloat(image);\n    offset+=4;\n    cin.image.channel[i].max_data=ReadBlobFloat(image);\n    offset+=4;\n    cin.image.channel[i].max_quantity=ReadBlobFloat(image);\n    offset+=4;\n  }\n  cin.image.white_point[0]=ReadBlobFloat(image);\n  offset+=4;\n  if (IsFloatDefined(cin.image.white_point[0]) != MagickFalse)\n    image->chromaticity.white_point.x=cin.image.white_point[0];\n  cin.image.white_point[1]=ReadBlobFloat(image);\n  offset+=4;\n  if (IsFloatDefined(cin.image.white_point[1]) != MagickFalse)\n    image->chromaticity.white_point.y=cin.image.white_point[1];\n  cin.image.red_primary_chromaticity[0]=ReadBlobFloat(image);\n  offset+=4;\n  if (IsFloatDefined(cin.image.red_primary_chromaticity[0]) != MagickFalse)\n    image->chromaticity.red_primary.x=cin.image.red_primary_chromaticity[0];\n  cin.image.red_primary_chromaticity[1]=ReadBlobFloat(image);\n  offset+=4;\n  if (IsFloatDefined(cin.image.red_primary_chromaticity[1]) != MagickFalse)\n    image->chromaticity.red_primary.y=cin.image.red_primary_chromaticity[1];\n  cin.image.green_primary_chromaticity[0]=ReadBlobFloat(image);\n  offset+=4;\n  if (IsFloatDefined(cin.image.green_primary_chromaticity[0]) != MagickFalse)\n    image->chromaticity.red_primary.x=cin.image.green_primary_chromaticity[0];\n  cin.image.green_primary_chromaticity[1]=ReadBlobFloat(image);\n  offset+=4;\n  if (IsFloatDefined(cin.image.green_primary_chromaticity[1]) != MagickFalse)\n    image->chromaticity.green_primary.y=cin.image.green_primary_chromaticity[1];\n  cin.image.blue_primary_chromaticity[0]=ReadBlobFloat(image);\n  offset+=4;\n  if (IsFloatDefined(cin.image.blue_primary_chromaticity[0]) != MagickFalse)\n    image->chromaticity.blue_primary.x=cin.image.blue_primary_chromaticity[0];\n  cin.image.blue_primary_chromaticity[1]=ReadBlobFloat(image);\n  offset+=4;\n  if (IsFloatDefined(cin.image.blue_primary_chromaticity[1]) != MagickFalse)\n    image->chromaticity.blue_primary.y=cin.image.blue_primary_chromaticity[1];\n  offset+=ReadBlob(image,sizeof(cin.image.label),(unsigned char *)\n    cin.image.label);\n  (void) CopyMagickString(property,cin.image.label,sizeof(cin.image.label));\n  (void) SetImageProperty(image,\"dpx:image.label\",property);\n  offset+=ReadBlob(image,sizeof(cin.image.reserve),(unsigned char *)\n    cin.image.reserve);\n  /*\n    Image data format information.\n  */\n  cin.data_format.interleave=(unsigned char) ReadBlobByte(image);\n  offset++;\n  cin.data_format.packing=(unsigned char) ReadBlobByte(image);\n  offset++;\n  cin.data_format.sign=(unsigned char) ReadBlobByte(image);\n  offset++;\n  cin.data_format.sense=(unsigned char) ReadBlobByte(image);\n  offset++;\n  cin.data_format.line_pad=ReadBlobLong(image);\n  offset+=4;\n  cin.data_format.channel_pad=ReadBlobLong(image);\n  offset+=4;\n  offset+=ReadBlob(image,sizeof(cin.data_format.reserve),(unsigned char *)\n    cin.data_format.reserve);\n  /*\n    Image origination information.\n  */\n  cin.origination.x_offset=ReadBlobSignedLong(image);\n  offset+=4;\n  if ((size_t) cin.origination.x_offset != ~0UL)\n    (void) FormatImageProperty(image,\"dpx:origination.x_offset\",\"%.20g\",\n      (double) cin.origination.x_offset);\n  cin.origination.y_offset=(ssize_t) ReadBlobLong(image);\n  offset+=4;\n  if ((size_t) cin.origination.y_offset != ~0UL)\n    (void) FormatImageProperty(image,\"dpx:origination.y_offset\",\"%.20g\",\n      (double) cin.origination.y_offset);\n  offset+=ReadBlob(image,sizeof(cin.origination.filename),(unsigned char *)\n    cin.origination.filename);\n  (void) CopyMagickString(property,cin.origination.filename,\n    sizeof(cin.origination.filename));\n  (void) SetImageProperty(image,\"dpx:origination.filename\",property);\n  offset+=ReadBlob(image,sizeof(cin.origination.create_date),(unsigned char *)\n    cin.origination.create_date);\n  (void) CopyMagickString(property,cin.origination.create_date,\n    sizeof(cin.origination.create_date));\n  (void) SetImageProperty(image,\"dpx:origination.create_date\",property);\n  offset+=ReadBlob(image,sizeof(cin.origination.create_time),(unsigned char *)\n    cin.origination.create_time);\n  (void) CopyMagickString(property,cin.origination.create_time,\n    sizeof(cin.origination.create_time));\n  (void) SetImageProperty(image,\"dpx:origination.create_time\",property);\n  offset+=ReadBlob(image,sizeof(cin.origination.device),(unsigned char *)\n    cin.origination.device);\n  (void) CopyMagickString(property,cin.origination.device,\n    sizeof(cin.origination.device));\n  (void) SetImageProperty(image,\"dpx:origination.device\",property);\n  offset+=ReadBlob(image,sizeof(cin.origination.model),(unsigned char *)\n    cin.origination.model);\n  (void) CopyMagickString(property,cin.origination.model,\n    sizeof(cin.origination.model));\n  (void) SetImageProperty(image,\"dpx:origination.model\",property);\n  (void) memset(cin.origination.serial,0,\n    sizeof(cin.origination.serial));\n  offset+=ReadBlob(image,sizeof(cin.origination.serial),(unsigned char *)\n    cin.origination.serial);\n  (void) CopyMagickString(property,cin.origination.serial,\n    sizeof(cin.origination.serial));\n  (void) SetImageProperty(image,\"dpx:origination.serial\",property);\n  cin.origination.x_pitch=ReadBlobFloat(image);\n  offset+=4;\n  cin.origination.y_pitch=ReadBlobFloat(image);\n  offset+=4;\n  cin.origination.gamma=ReadBlobFloat(image);\n  offset+=4;\n  if (IsFloatDefined(cin.origination.gamma) != MagickFalse)\n    image->gamma=cin.origination.gamma;\n  offset+=ReadBlob(image,sizeof(cin.origination.reserve),(unsigned char *)\n    cin.origination.reserve);\n  if ((cin.file.image_offset > 2048) && (cin.file.user_length != 0))\n    {\n      int\n        c;\n\n      /*\n        Image film information.\n      */\n      cin.film.id=ReadBlobByte(image);\n      offset++;\n      c=cin.film.id;\n      if (c != ~0)\n        (void) FormatImageProperty(image,\"dpx:film.id\",\"%d\",cin.film.id);\n      cin.film.type=ReadBlobByte(image);\n      offset++;\n      c=cin.film.type;\n      if (c != ~0)\n        (void) FormatImageProperty(image,\"dpx:film.type\",\"%d\",cin.film.type);\n      cin.film.offset=ReadBlobByte(image);\n      offset++;\n      c=cin.film.offset;\n      if (c != ~0)\n        (void) FormatImageProperty(image,\"dpx:film.offset\",\"%d\",\n          cin.film.offset);\n      cin.film.reserve1=ReadBlobByte(image);\n      offset++;\n      cin.film.prefix=ReadBlobLong(image);\n      offset+=4;\n      if (cin.film.prefix != ~0UL)\n        (void) FormatImageProperty(image,\"dpx:film.prefix\",\"%.20g\",(double)\n          cin.film.prefix);\n      cin.film.count=ReadBlobLong(image);\n      offset+=4;\n      offset+=ReadBlob(image,sizeof(cin.film.format),(unsigned char *)\n        cin.film.format);\n      (void) CopyMagickString(property,cin.film.format,\n        sizeof(cin.film.format));\n      (void) SetImageProperty(image,\"dpx:film.format\",property);\n      cin.film.frame_position=ReadBlobLong(image);\n      offset+=4;\n      if (cin.film.frame_position != ~0UL)\n        (void) FormatImageProperty(image,\"dpx:film.frame_position\",\"%.20g\",\n          (double) cin.film.frame_position);\n      cin.film.frame_rate=ReadBlobFloat(image);\n      offset+=4;\n      if (IsFloatDefined(cin.film.frame_rate) != MagickFalse)\n        (void) FormatImageProperty(image,\"dpx:film.frame_rate\",\"%g\",\n          cin.film.frame_rate);\n      offset+=ReadBlob(image,sizeof(cin.film.frame_id),(unsigned char *)\n        cin.film.frame_id);\n      (void) CopyMagickString(property,cin.film.frame_id,\n        sizeof(cin.film.frame_id));\n      (void) SetImageProperty(image,\"dpx:film.frame_id\",property);\n      offset+=ReadBlob(image,sizeof(cin.film.slate_info),(unsigned char *)\n        cin.film.slate_info);\n      (void) CopyMagickString(property,cin.film.slate_info,\n        sizeof(cin.film.slate_info));\n      (void) SetImageProperty(image,\"dpx:film.slate_info\",property);\n      offset+=ReadBlob(image,sizeof(cin.film.reserve),(unsigned char *)\n        cin.film.reserve);\n    }\n  if ((cin.file.image_offset > 2048) && (cin.file.user_length != 0))\n    {\n      StringInfo\n        *profile;\n\n      /*\n        User defined data.\n      */\n      if (cin.file.user_length > GetBlobSize(image))\n        ThrowReaderException(CorruptImageError,\"InsufficientImageDataInFile\");\n      profile=BlobToStringInfo((const void *) NULL,cin.file.user_length);\n      if (profile == (StringInfo *) NULL)\n        ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n      offset+=ReadBlob(image,GetStringInfoLength(profile),\n        GetStringInfoDatum(profile));\n      (void) SetImageProfile(image,\"dpx:user.data\",profile);\n      profile=DestroyStringInfo(profile);\n    }\n  image->depth=cin.image.channel[0].bits_per_pixel;\n  image->columns=cin.image.channel[0].pixels_per_line;\n  image->rows=cin.image.channel[0].lines_per_image;\n  if (image_info->ping != MagickFalse)\n    {\n      (void) CloseBlob(image);\n      return(image);\n    }\n  if (((MagickSizeType) image->columns*image->rows/8) > GetBlobSize(image))\n    ThrowReaderException(CorruptImageError,\"InsufficientImageDataInFile\");\n  for ( ; offset < (MagickOffsetType) cin.file.image_offset; offset++)\n  {\n    int\n      c;\n\n    c=ReadBlobByte(image);\n    if (c == EOF)\n      break;\n  }\n  if (offset < (MagickOffsetType) cin.file.image_offset)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  status=SetImageExtent(image,image->columns,image->rows);\n  if (status == MagickFalse)\n    {\n      InheritException(exception,&image->exception);\n      return(DestroyImageList(image));\n    }\n  (void) SetImageBackgroundColor(image);\n  /*\n    Convert CIN raster image to pixel packets.\n  */\n  quantum_info=AcquireQuantumInfo(image_info,image);\n  if (quantum_info == (QuantumInfo *) NULL)\n    ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n  SetQuantumQuantum(quantum_info,32);\n  SetQuantumPack(quantum_info,MagickFalse);\n  quantum_type=RGBQuantum;\n  extent=GetQuantumExtent(image,quantum_info,quantum_type);\n  (void) extent;\n  length=GetBytesPerRow(image->columns,3,image->depth,MagickTrue);\n  if (cin.image.number_channels == 1)\n    {\n      quantum_type=GrayQuantum;\n      length=GetBytesPerRow(image->columns,1,image->depth,MagickTrue);\n    }\n  status=SetQuantumPad(image,quantum_info,0);\n  pixels=GetQuantumPixels(quantum_info);\n  for (y=0; y < (ssize_t) image->rows; y++)\n  {\n    const void\n      *stream;\n\n    q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n    if (q == (PixelPacket *) NULL)\n      break;\n    stream=ReadBlobStream(image,length,pixels,&count);\n    if (count != (ssize_t) length)\n      break;\n    (void) ImportQuantumPixels(image,(CacheView *) NULL,quantum_info,\n      quantum_type,(unsigned char *) stream,exception);\n    if (SyncAuthenticPixels(image,exception) == MagickFalse)\n      break;\n    if (image->previous == (Image *) NULL)\n      {\n        status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n          image->rows);\n        if (status == MagickFalse)\n          break;\n      }\n  }\n  SetQuantumImageType(image,quantum_type);\n  quantum_info=DestroyQuantumInfo(quantum_info);\n  if (EOFBlob(image) != MagickFalse)\n    ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n      image->filename);\n  SetImageColorspace(image,LogColorspace);\n  (void) CloseBlob(image);\n  return(GetFirstImageInList(image));\n}",
        "func_hash": 230911711267539175049972905344313345647,
        "file_name": "cin.c",
        "file_hash": 249228869233078232834553857521337694406,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2022-28463",
        "cve_desc": "ImageMagick 7.1.0-27 is vulnerable to Buffer Overflow.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-28463",
        "func_name": "ReadCINImage",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 201872,
        "project": "gnutls",
        "commit_id": "20a98e817713764b9df5306286091df1b61190d9",
        "project_url": "http://git.savannah.gnu.org/cgit/gnutls",
        "commit_url": "https://gitlab.com/gnutls/gnutls/commit/20a98e817713764b9df5306286091df1b61190d9",
        "commit_message": "handshake: check inappropriate fallback against the configured max version\n\nThat allows to operate on a server which is explicitly configured to\nutilize earlier than TLS 1.2 versions.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "_gnutls_server_select_suite(gnutls_session_t session, uint8_t * data,\n\t\t\t    unsigned int datalen)\n{\n\tint ret;\n\tunsigned int i, j, cipher_suites_size;\n\tsize_t pk_algos_size;\n\tuint8_t cipher_suites[MAX_CIPHERSUITE_SIZE];\n\tint retval;\n\tgnutls_pk_algorithm_t pk_algos[MAX_ALGOS];\t/* will hold the pk algorithms\n\t\t\t\t\t\t\t * supported by the peer.\n\t\t\t\t\t\t\t */\n\n\tfor (i = 0; i < datalen; i += 2) {\n\t\t/* TLS_RENEGO_PROTECTION_REQUEST = { 0x00, 0xff } */\n\t\tif (session->internals.priorities.sr != SR_DISABLED &&\n\t\t    data[i] == GNUTLS_RENEGO_PROTECTION_REQUEST_MAJOR &&\n\t\t    data[i + 1] == GNUTLS_RENEGO_PROTECTION_REQUEST_MINOR) {\n\t\t\t_gnutls_handshake_log\n\t\t\t    (\"HSK[%p]: Received safe renegotiation CS\\n\",\n\t\t\t     session);\n\t\t\tretval = _gnutls_ext_sr_recv_cs(session);\n\t\t\tif (retval < 0) {\n\t\t\t\tgnutls_assert();\n\t\t\t\treturn retval;\n\t\t\t}\n\t\t}\n\n\t\t/* TLS_FALLBACK_SCSV */\n\t\tif (data[i] == GNUTLS_FALLBACK_SCSV_MAJOR &&\n\t\t    data[i + 1] == GNUTLS_FALLBACK_SCSV_MINOR) {\n\t\t\t_gnutls_handshake_log\n\t\t\t    (\"HSK[%p]: Received fallback CS\\n\",\n\t\t\t     session);\n\n\t\t\tif (gnutls_protocol_get_version(session) !=\n\t\t\t    GNUTLS_TLS_VERSION_MAX)\n\t\t\t\treturn GNUTLS_E_INAPPROPRIATE_FALLBACK;\n\t\t}\n\t}\n\n\tpk_algos_size = MAX_ALGOS;\n\tret =\n\t    server_find_pk_algos_in_ciphersuites(data, datalen, pk_algos,\n\t\t\t\t\t\t &pk_algos_size);\n\tif (ret < 0)\n\t\treturn gnutls_assert_val(ret);\n\n\tret =\n\t    _gnutls_supported_ciphersuites(session, cipher_suites,\n\t\t\t\t\t   sizeof(cipher_suites));\n\tif (ret < 0)\n\t\treturn gnutls_assert_val(ret);\n\n\tcipher_suites_size = ret;\n\n\t/* Here we remove any ciphersuite that does not conform\n\t * the certificate requested, or to the\n\t * authentication requested (e.g. SRP).\n\t */\n\tret =\n\t    _gnutls_remove_unwanted_ciphersuites(session, cipher_suites,\n\t\t\t\t\t\t cipher_suites_size,\n\t\t\t\t\t\t pk_algos, pk_algos_size);\n\tif (ret <= 0) {\n\t\tgnutls_assert();\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t\telse\n\t\t\treturn GNUTLS_E_UNKNOWN_CIPHER_SUITE;\n\t}\n\n\tcipher_suites_size = ret;\n\n\t/* Data length should be zero mod 2 since\n\t * every ciphersuite is 2 bytes. (this check is needed\n\t * see below).\n\t */\n\tif (datalen % 2 != 0) {\n\t\tgnutls_assert();\n\t\treturn GNUTLS_E_UNEXPECTED_PACKET_LENGTH;\n\t}\n\n\tmemset(session->security_parameters.cipher_suite, 0, 2);\n\n\tretval = GNUTLS_E_UNKNOWN_CIPHER_SUITE;\n\n\t_gnutls_handshake_log\n\t    (\"HSK[%p]: Requested cipher suites[size: %d]: \\n\", session,\n\t     (int) datalen);\n\n\tif (session->internals.priorities.server_precedence == 0) {\n\t\tfor (j = 0; j < datalen; j += 2) {\n\t\t\t_gnutls_handshake_log(\"\\t0x%.2x, 0x%.2x %s\\n\",\n\t\t\t\t\t      data[j], data[j + 1],\n\t\t\t\t\t      _gnutls_cipher_suite_get_name\n\t\t\t\t\t      (&data[j]));\n\t\t\tfor (i = 0; i < cipher_suites_size; i += 2) {\n\t\t\t\tif (memcmp(&cipher_suites[i], &data[j], 2)\n\t\t\t\t    == 0) {\n\t\t\t\t\t_gnutls_handshake_log\n\t\t\t\t\t    (\"HSK[%p]: Selected cipher suite: %s\\n\",\n\t\t\t\t\t     session,\n\t\t\t\t\t     _gnutls_cipher_suite_get_name\n\t\t\t\t\t     (&data[j]));\n\t\t\t\t\tmemcpy(session->\n\t\t\t\t\t       security_parameters.\n\t\t\t\t\t       cipher_suite,\n\t\t\t\t\t       &cipher_suites[i], 2);\n\t\t\t\t\t_gnutls_epoch_set_cipher_suite\n\t\t\t\t\t    (session, EPOCH_NEXT,\n\t\t\t\t\t     session->security_parameters.\n\t\t\t\t\t     cipher_suite);\n\n\n\t\t\t\t\tretval = 0;\n\t\t\t\t\tgoto finish;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t} else {\t\t/* server selects */\n\n\t\tfor (i = 0; i < cipher_suites_size; i += 2) {\n\t\t\tfor (j = 0; j < datalen; j += 2) {\n\t\t\t\tif (memcmp(&cipher_suites[i], &data[j], 2)\n\t\t\t\t    == 0) {\n\t\t\t\t\t_gnutls_handshake_log\n\t\t\t\t\t    (\"HSK[%p]: Selected cipher suite: %s\\n\",\n\t\t\t\t\t     session,\n\t\t\t\t\t     _gnutls_cipher_suite_get_name\n\t\t\t\t\t     (&data[j]));\n\t\t\t\t\tmemcpy(session->\n\t\t\t\t\t       security_parameters.\n\t\t\t\t\t       cipher_suite,\n\t\t\t\t\t       &cipher_suites[i], 2);\n\t\t\t\t\t_gnutls_epoch_set_cipher_suite\n\t\t\t\t\t    (session, EPOCH_NEXT,\n\t\t\t\t\t     session->security_parameters.\n\t\t\t\t\t     cipher_suite);\n\n\n\t\t\t\t\tretval = 0;\n\t\t\t\t\tgoto finish;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n      finish:\n\n\tif (retval != 0) {\n\t\tgnutls_assert();\n\t\treturn retval;\n\t}\n\n\t/* check if the credentials (username, public key etc.) are ok\n\t */\n\tif (_gnutls_get_kx_cred\n\t    (session,\n\t     _gnutls_cipher_suite_get_kx_algo(session->security_parameters.\n\t\t\t\t\t      cipher_suite)) == NULL) {\n\t\tgnutls_assert();\n\t\treturn GNUTLS_E_INSUFFICIENT_CREDENTIALS;\n\t}\n\n\n\t/* set the mod_auth_st to the appropriate struct\n\t * according to the KX algorithm. This is needed since all the\n\t * handshake functions are read from there;\n\t */\n\tsession->internals.auth_struct =\n\t    _gnutls_kx_auth_struct(_gnutls_cipher_suite_get_kx_algo\n\t\t\t\t   (session->security_parameters.\n\t\t\t\t    cipher_suite));\n\tif (session->internals.auth_struct == NULL) {\n\n\t\t_gnutls_handshake_log\n\t\t    (\"HSK[%p]: Cannot find the appropriate handler for the KX algorithm\\n\",\n\t\t     session);\n\t\tgnutls_assert();\n\t\treturn GNUTLS_E_INTERNAL_ERROR;\n\t}\n\n\treturn 0;\n\n}",
        "func_hash": 43939075651028590089831343195417108850,
        "file_name": "gnutls_handshake.c",
        "file_hash": 33222600436004333309471609542396279978,
        "cwe": [
            "CWE-310"
        ],
        "cve": "CVE-2014-3566",
        "cve_desc": "The SSL protocol 3.0, as used in OpenSSL through 1.0.1i and other products, uses nondeterministic CBC padding, which makes it easier for man-in-the-middle attackers to obtain cleartext data via a padding-oracle attack, aka the \"POODLE\" issue.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2014-3566",
        "func_name": "_gnutls_server_select_suite",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 217254,
        "project": "ardour",
        "commit_id": "96daa4036a425ff3f23a7dfcba57bfb0f942bec6",
        "project_url": "https://github.com/Ardour/ardour",
        "commit_url": "https://github.com/Ardour/ardour/commit/96daa4036a425ff3f23a7dfcba57bfb0f942bec6",
        "commit_message": "fix apparent free-ordering issue reported in #7926",
        "target": 1,
        "irrelevant": 1,
        "func_before": "static XMLSharedNodeList* find_impl(xmlXPathContext* ctxt, const string& xpath)\n{\n\txmlXPathObject* result = xmlXPathEval((const xmlChar*)xpath.c_str(), ctxt);\n\n\tif (!result) {\n\t\txmlXPathFreeContext(ctxt);\n\t\txmlFreeDoc(ctxt->doc);\n\n\t\tthrow XMLException(\"Invalid XPath: \" + xpath);\n\t}\n\n\tif (result->type != XPATH_NODESET) {\n\t\txmlXPathFreeObject(result);\n\t\txmlXPathFreeContext(ctxt);\n\t\txmlFreeDoc(ctxt->doc);\n\n\t\tthrow XMLException(\"Only nodeset result types are supported.\");\n\t}\n\n\txmlNodeSet* nodeset = result->nodesetval;\n\tXMLSharedNodeList* nodes = new XMLSharedNodeList();\n\tif (nodeset) {\n\t\tfor (int i = 0; i < nodeset->nodeNr; ++i) {\n\t\t\tXMLNode* node = readnode(nodeset->nodeTab[i]);\n\t\t\tnodes->push_back(boost::shared_ptr<XMLNode>(node));\n\t\t}\n\t} else {\n\t\t// return empty set\n\t}\n\n\txmlXPathFreeObject(result);\n\n\treturn nodes;\n}",
        "func_hash": 302360056702262366271807964609080091494,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-416"
        ],
        "cve": "CVE-2020-22617",
        "cve_desc": "Ardour v5.12 contains a use-after-free vulnerability in the component ardour/libs/pbd/xml++.cc when using xmlFreeDoc and xmlXPathFreeContext.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2020-22617",
        "func_name": "find_impl",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 217321,
        "project": "jsish",
        "commit_id": "858da537bde4de9d8c92466d5a866505310bc328",
        "project_url": "https://github.com/pcmacdon/jsish",
        "commit_url": "https://github.com/pcmacdon/jsish/commit/858da537bde4de9d8c92466d5a866505310bc328",
        "commit_message": "Release \"3.0.8\": Address Array alloc sizing issues from issue \"integer overflow and buffer overflow #5\".\n\nFossilOrigin-Name: 8c46a1d465b358110dcfb271721d35fe843a1b52f2fa24ccc10094eb8aaf6fe4",
        "target": 1,
        "irrelevant": 1,
        "func_before": "int Jsi_ObjArraySizer(Jsi_Interp *interp, Jsi_Obj *obj, uint len)\n{\n    int nsiz = len + 1, mod = ALLOC_MOD_SIZE;\n    assert(obj->isarrlist);\n    if (mod>1)\n        nsiz = nsiz + ((mod-1) - (nsiz + mod - 1)%mod);\n    if (nsiz > MAX_ARRAY_LIST) {\n        Jsi_LogError(\"array size too large\");\n        return 0;\n    }\n    if (len >= obj->arrMaxSize) {\n        int oldsz = (nsiz-obj->arrMaxSize);\n        obj->arr = (Jsi_Value**)Jsi_Realloc(obj->arr, nsiz*sizeof(Jsi_Value*));\n        memset(obj->arr+obj->arrMaxSize, 0, oldsz*sizeof(Jsi_Value*));\n        obj->arrMaxSize = nsiz;\n    }\n    if (len>obj->arrCnt)\n        obj->arrCnt = len;\n    return nsiz;\n}",
        "func_hash": 158587304886223234141585164472175789365,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-190"
        ],
        "cve": "CVE-2020-22874",
        "cve_desc": "Integer overflow vulnerability in function Jsi_ObjArraySizer in jsish before 3.0.8, allows remote attackers to execute arbitrary code.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2020-22874",
        "func_name": "Jsi_ObjArraySizer",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 217457,
        "project": "spnego-http-auth-nginx-module",
        "commit_id": "a06f9efca373e25328b1c53639a48decd0854570",
        "project_url": "https://github.com/stnoonan/spnego-http-auth-nginx-module",
        "commit_url": "https://github.com/stnoonan/spnego-http-auth-nginx-module/commit/a06f9efca373e25328b1c53639a48decd0854570",
        "commit_message": "Check basic auth result against != NGX_OK rather than == NGX_DECLINED\n\nThis corrects the error handling case when ngx_http_auth_spnego_basic is called with a bad configuration or bad username. These cases return NGX_ERROR, which allowed basic auth to proceed.\n\nThanks to Prakapovich Pavel aka Flyguy.by for pointing this out.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "ngx_http_auth_spnego_handler(\n        ngx_http_request_t * r)\n{\n    ngx_int_t ret = NGX_DECLINED;\n    ngx_http_auth_spnego_ctx_t *ctx;\n    ngx_http_auth_spnego_loc_conf_t *alcf;\n\n    alcf = ngx_http_get_module_loc_conf(r, ngx_http_auth_spnego_module);\n\n    if (alcf->protect == 0) {\n        return NGX_DECLINED;\n    }\n\n    ctx = ngx_http_get_module_ctx(r, ngx_http_auth_spnego_module);\n    if (NULL == ctx) {\n        ctx = ngx_palloc(r->pool, sizeof(ngx_http_auth_spnego_ctx_t));\n        if (NULL == ctx) {\n            return NGX_HTTP_INTERNAL_SERVER_ERROR;\n        }\n        ctx->token.len = 0;\n        ctx->token.data = NULL;\n        ctx->head = 0;\n        ctx->ret = NGX_HTTP_UNAUTHORIZED;\n        ngx_http_set_ctx(r, ctx, ngx_http_auth_spnego_module);\n    }\n\n    spnego_debug3(\"SSO auth handling IN: token.len=%d, head=%d, ret=%d\",\n            ctx->token.len, ctx->head, ctx->ret);\n\n    if (ctx->token.len && ctx->head) {\n        spnego_debug1(\"Found token and head, returning %d\", ctx->ret);\n        return ctx->ret;\n    }\n\n    if (NULL != r->headers_in.user.data) {\n        spnego_debug0(\"User header set\");\n        return NGX_OK;\n    }\n\n    spnego_debug0(\"Begin auth\");\n\n    if (alcf->allow_basic) {\n        spnego_debug0(\"Detect basic auth\");\n        ret = ngx_http_auth_basic_user(r);\n        if (NGX_OK == ret) {\n            spnego_debug0(\"Basic auth credentials supplied by client\");\n            /* If basic auth is enabled and basic creds are supplied\n             * attempt basic auth.  If we attempt basic auth, we do\n             * not fall through to real SPNEGO */\n            if (NGX_DECLINED == ngx_http_auth_spnego_basic(r, ctx, alcf)) {\n                spnego_debug0(\"Basic auth failed\");\n                if (NGX_ERROR == ngx_http_auth_spnego_headers_basic_only(r, ctx, alcf)) {\n                    spnego_debug0(\"Error setting headers\");\n                    return (ctx->ret = NGX_HTTP_INTERNAL_SERVER_ERROR);\n                }\n                return (ctx->ret = NGX_HTTP_UNAUTHORIZED);\n            }\n\n            if (!ngx_spnego_authorized_principal(r, &r->headers_in.user, alcf)) {\n                spnego_debug0(\"User not authorized\");\n                return (ctx->ret = NGX_HTTP_FORBIDDEN);\n            }\n\n            spnego_debug0(\"Basic auth succeeded\");\n            return (ctx->ret = NGX_OK);\n        }\n    }\n\n    /* Basic auth either disabled or not supplied by client */\n    spnego_debug0(\"Detect SPNEGO token\");\n    ret = ngx_http_auth_spnego_token(r, ctx);\n    if (NGX_OK == ret) {\n        spnego_debug0(\"Client sent a reasonable Negotiate header\");\n        ret = ngx_http_auth_spnego_auth_user_gss(r, ctx, alcf);\n        if (NGX_ERROR == ret) {\n            spnego_debug0(\"GSSAPI failed\");\n            return (ctx->ret = NGX_HTTP_INTERNAL_SERVER_ERROR);\n        }\n        /* There are chances that client knows about Negotiate\n         * but doesn't support GSSAPI. We could attempt to fall\n         * back to basic here... */\n        if (NGX_DECLINED == ret) {\n            spnego_debug0(\"GSSAPI failed\");\n            if(!alcf->allow_basic) {\n                return (ctx->ret = NGX_HTTP_FORBIDDEN);\n            }\n            if (NGX_ERROR == ngx_http_auth_spnego_headers_basic_only(r, ctx, alcf)) {\n                spnego_debug0(\"Error setting headers\");\n                return (ctx->ret = NGX_HTTP_INTERNAL_SERVER_ERROR);\n            }\n            return (ctx->ret = NGX_HTTP_UNAUTHORIZED);\n        }\n\n        if (!ngx_spnego_authorized_principal(r, &r->headers_in.user, alcf)) {\n            spnego_debug0(\"User not authorized\");\n            return (ctx->ret = NGX_HTTP_FORBIDDEN);\n        }\n\n        spnego_debug0(\"GSSAPI auth succeeded\");\n    }\n\n    ngx_str_t *token_out_b64 = NULL;\n    switch(ret) {\n        case NGX_DECLINED: /* DECLINED, but not yet FORBIDDEN */\n            ctx->ret = NGX_HTTP_UNAUTHORIZED;\n            break;\n        case NGX_OK:\n            ctx->ret = NGX_OK;\n            token_out_b64 = &ctx->token_out_b64;\n            break;\n        case NGX_ERROR:\n        default:\n            ctx->ret = NGX_HTTP_INTERNAL_SERVER_ERROR;\n            break;\n    }\n\n    if (NGX_ERROR == ngx_http_auth_spnego_headers(r, ctx, token_out_b64, alcf)) {\n        spnego_debug0(\"Error setting headers\");\n        ctx->ret = NGX_HTTP_INTERNAL_SERVER_ERROR;\n    }\n\n    spnego_debug3(\"SSO auth handling OUT: token.len=%d, head=%d, ret=%d\",\n            ctx->token.len, ctx->head, ctx->ret);\n    return ctx->ret;\n}",
        "func_hash": 315404812195750248230966628792775317523,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-287"
        ],
        "cve": "CVE-2021-21335",
        "cve_desc": "In the SPNEGO HTTP Authentication Module for nginx (spnego-http-auth-nginx-module) before version 1.1.1 basic Authentication can be bypassed using a malformed username. This affects users of spnego-http-auth-nginx-module that have enabled basic authentication. This is fixed in version 1.1.1 of spnego-http-auth-nginx-module. As a workaround, one may disable basic authentication.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-21335",
        "func_name": "ngx_http_auth_spnego_handler",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 217514,
        "project": "skiboot",
        "commit_id": "5be38b672c1410e2f10acd3ad2eecfdc81d5daf7",
        "project_url": "https://github.com/open-power/skiboot",
        "commit_url": "https://github.com/open-power/skiboot/commit/5be38b672c1410e2f10acd3ad2eecfdc81d5daf7",
        "commit_message": "secvar: fix endian conversion\n\nunpack_timestamp() calls le32_to_cpu() for endian conversion of\nuint16_t \"year\" value. This patch fixes the code to use le16_to_cpu().\n\nSigned-off-by: Nayna Jain <nayna@linux.ibm.com>\nReviewed-by: Daniel Axtens <dja@axtens.net>\nSigned-off-by: Vasant Hegde <hegdevasant@linux.vnet.ibm.com>",
        "target": 1,
        "irrelevant": 1,
        "func_before": "static uint64_t unpack_timestamp(const struct efi_time *timestamp)\n{\n\tuint64_t val = 0;\n\tuint16_t year = le32_to_cpu(timestamp->year);\n\n\t/* pad1, nanosecond, timezone, daylight and pad2 are meant to be zero */\n\tval |= ((uint64_t) timestamp->pad1 & 0xFF) << 0;\n\tval |= ((uint64_t) timestamp->second & 0xFF) << (1*8);\n\tval |= ((uint64_t) timestamp->minute & 0xFF) << (2*8);\n\tval |= ((uint64_t) timestamp->hour & 0xFF) << (3*8);\n\tval |= ((uint64_t) timestamp->day & 0xFF) << (4*8);\n\tval |= ((uint64_t) timestamp->month & 0xFF) << (5*8);\n\tval |= ((uint64_t) year) << (6*8);\n\n\treturn val;\n}",
        "func_hash": 311038473946488653732481318478780397503,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-681"
        ],
        "cve": "CVE-2021-36357",
        "cve_desc": "An issue was discovered in OpenPOWER 2.6 firmware. unpack_timestamp() calls le32_to_cpu() for endian conversion of a uint16_t \"year\" value, resulting in a type mismatch that can truncate a higher integer value to a smaller one, and bypass a timestamp check. The fix is to use the right endian conversion function.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-36357",
        "func_name": "unpack_timestamp",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 194963,
        "project": "ImageMagick6",
        "commit_id": "dc070da861a015d3c97488fdcca6063b44d47a7b",
        "project_url": "https://github.com/ImageMagick/ImageMagick6",
        "commit_url": "https://github.com/ImageMagick/ImageMagick6/commit/dc070da861a015d3c97488fdcca6063b44d47a7b",
        "commit_message": "https://github.com/ImageMagick/ImageMagick/pull/5034",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static MagickBooleanType GetEXIFProperty(const Image *image,\n  const char *property)\n{\n#define MaxDirectoryStack  16\n#define EXIF_DELIMITER  \"\\n\"\n#define EXIF_NUM_FORMATS  12\n#define EXIF_FMT_BYTE  1\n#define EXIF_FMT_STRING  2\n#define EXIF_FMT_USHORT  3\n#define EXIF_FMT_ULONG  4\n#define EXIF_FMT_URATIONAL  5\n#define EXIF_FMT_SBYTE  6\n#define EXIF_FMT_UNDEFINED  7\n#define EXIF_FMT_SSHORT  8\n#define EXIF_FMT_SLONG  9\n#define EXIF_FMT_SRATIONAL  10\n#define EXIF_FMT_SINGLE  11\n#define EXIF_FMT_DOUBLE  12\n#define TAG_EXIF_OFFSET  0x8769\n#define TAG_GPS_OFFSET  0x8825\n#define TAG_INTEROP_OFFSET  0xa005\n\n#define EXIFMultipleValues(size,format,arg) \\\n{ \\\n   ssize_t \\\n     component; \\\n \\\n   size_t \\\n     length; \\\n \\\n   unsigned char \\\n     *p1; \\\n \\\n   length=0; \\\n   p1=p; \\\n   for (component=0; component < components; component++) \\\n   { \\\n     length+=FormatLocaleString(buffer+length,MaxTextExtent-length, \\\n       format\", \",arg); \\\n     if (length >= (MaxTextExtent-1)) \\\n       length=MaxTextExtent-1; \\\n     p1+=size; \\\n   } \\\n   if (length > 1) \\\n     buffer[length-2]='\\0'; \\\n   value=AcquireString(buffer); \\\n}\n\n#define EXIFMultipleFractions(size,format,arg1,arg2) \\\n{ \\\n   ssize_t \\\n     component; \\\n \\\n   size_t \\\n     length; \\\n \\\n   unsigned char \\\n     *p1; \\\n \\\n   length=0; \\\n   p1=p; \\\n   for (component=0; component < components; component++) \\\n   { \\\n     length+=FormatLocaleString(buffer+length,MaxTextExtent-length, \\\n       format\", \",(arg1),(arg2)); \\\n     if (length >= (MaxTextExtent-1)) \\\n       length=MaxTextExtent-1; \\\n     p1+=size; \\\n   } \\\n   if (length > 1) \\\n     buffer[length-2]='\\0'; \\\n   value=AcquireString(buffer); \\\n}\n\n  typedef struct _DirectoryInfo\n  {\n    const unsigned char\n      *directory;\n\n    size_t\n      entry;\n\n    ssize_t\n      offset;\n  } DirectoryInfo;\n\n  typedef struct _TagInfo\n  {\n    size_t\n      tag;\n\n    const char\n      description[36];\n  } TagInfo;\n\n  static const TagInfo\n    EXIFTag[] =\n    {\n      {  0x001, \"exif:InteroperabilityIndex\" },\n      {  0x002, \"exif:InteroperabilityVersion\" },\n      {  0x100, \"exif:ImageWidth\" },\n      {  0x101, \"exif:ImageLength\" },\n      {  0x102, \"exif:BitsPerSample\" },\n      {  0x103, \"exif:Compression\" },\n      {  0x106, \"exif:PhotometricInterpretation\" },\n      {  0x10a, \"exif:FillOrder\" },\n      {  0x10d, \"exif:DocumentName\" },\n      {  0x10e, \"exif:ImageDescription\" },\n      {  0x10f, \"exif:Make\" },\n      {  0x110, \"exif:Model\" },\n      {  0x111, \"exif:StripOffsets\" },\n      {  0x112, \"exif:Orientation\" },\n      {  0x115, \"exif:SamplesPerPixel\" },\n      {  0x116, \"exif:RowsPerStrip\" },\n      {  0x117, \"exif:StripByteCounts\" },\n      {  0x11a, \"exif:XResolution\" },\n      {  0x11b, \"exif:YResolution\" },\n      {  0x11c, \"exif:PlanarConfiguration\" },\n      {  0x11d, \"exif:PageName\" },\n      {  0x11e, \"exif:XPosition\" },\n      {  0x11f, \"exif:YPosition\" },\n      {  0x118, \"exif:MinSampleValue\" },\n      {  0x119, \"exif:MaxSampleValue\" },\n      {  0x120, \"exif:FreeOffsets\" },\n      {  0x121, \"exif:FreeByteCounts\" },\n      {  0x122, \"exif:GrayResponseUnit\" },\n      {  0x123, \"exif:GrayResponseCurve\" },\n      {  0x124, \"exif:T4Options\" },\n      {  0x125, \"exif:T6Options\" },\n      {  0x128, \"exif:ResolutionUnit\" },\n      {  0x12d, \"exif:TransferFunction\" },\n      {  0x131, \"exif:Software\" },\n      {  0x132, \"exif:DateTime\" },\n      {  0x13b, \"exif:Artist\" },\n      {  0x13e, \"exif:WhitePoint\" },\n      {  0x13f, \"exif:PrimaryChromaticities\" },\n      {  0x140, \"exif:ColorMap\" },\n      {  0x141, \"exif:HalfToneHints\" },\n      {  0x142, \"exif:TileWidth\" },\n      {  0x143, \"exif:TileLength\" },\n      {  0x144, \"exif:TileOffsets\" },\n      {  0x145, \"exif:TileByteCounts\" },\n      {  0x14a, \"exif:SubIFD\" },\n      {  0x14c, \"exif:InkSet\" },\n      {  0x14d, \"exif:InkNames\" },\n      {  0x14e, \"exif:NumberOfInks\" },\n      {  0x150, \"exif:DotRange\" },\n      {  0x151, \"exif:TargetPrinter\" },\n      {  0x152, \"exif:ExtraSample\" },\n      {  0x153, \"exif:SampleFormat\" },\n      {  0x154, \"exif:SMinSampleValue\" },\n      {  0x155, \"exif:SMaxSampleValue\" },\n      {  0x156, \"exif:TransferRange\" },\n      {  0x157, \"exif:ClipPath\" },\n      {  0x158, \"exif:XClipPathUnits\" },\n      {  0x159, \"exif:YClipPathUnits\" },\n      {  0x15a, \"exif:Indexed\" },\n      {  0x15b, \"exif:JPEGTables\" },\n      {  0x15f, \"exif:OPIProxy\" },\n      {  0x200, \"exif:JPEGProc\" },\n      {  0x201, \"exif:JPEGInterchangeFormat\" },\n      {  0x202, \"exif:JPEGInterchangeFormatLength\" },\n      {  0x203, \"exif:JPEGRestartInterval\" },\n      {  0x205, \"exif:JPEGLosslessPredictors\" },\n      {  0x206, \"exif:JPEGPointTransforms\" },\n      {  0x207, \"exif:JPEGQTables\" },\n      {  0x208, \"exif:JPEGDCTables\" },\n      {  0x209, \"exif:JPEGACTables\" },\n      {  0x211, \"exif:YCbCrCoefficients\" },\n      {  0x212, \"exif:YCbCrSubSampling\" },\n      {  0x213, \"exif:YCbCrPositioning\" },\n      {  0x214, \"exif:ReferenceBlackWhite\" },\n      {  0x2bc, \"exif:ExtensibleMetadataPlatform\" },\n      {  0x301, \"exif:Gamma\" },\n      {  0x302, \"exif:ICCProfileDescriptor\" },\n      {  0x303, \"exif:SRGBRenderingIntent\" },\n      {  0x320, \"exif:ImageTitle\" },\n      {  0x5001, \"exif:ResolutionXUnit\" },\n      {  0x5002, \"exif:ResolutionYUnit\" },\n      {  0x5003, \"exif:ResolutionXLengthUnit\" },\n      {  0x5004, \"exif:ResolutionYLengthUnit\" },\n      {  0x5005, \"exif:PrintFlags\" },\n      {  0x5006, \"exif:PrintFlagsVersion\" },\n      {  0x5007, \"exif:PrintFlagsCrop\" },\n      {  0x5008, \"exif:PrintFlagsBleedWidth\" },\n      {  0x5009, \"exif:PrintFlagsBleedWidthScale\" },\n      {  0x500A, \"exif:HalftoneLPI\" },\n      {  0x500B, \"exif:HalftoneLPIUnit\" },\n      {  0x500C, \"exif:HalftoneDegree\" },\n      {  0x500D, \"exif:HalftoneShape\" },\n      {  0x500E, \"exif:HalftoneMisc\" },\n      {  0x500F, \"exif:HalftoneScreen\" },\n      {  0x5010, \"exif:JPEGQuality\" },\n      {  0x5011, \"exif:GridSize\" },\n      {  0x5012, \"exif:ThumbnailFormat\" },\n      {  0x5013, \"exif:ThumbnailWidth\" },\n      {  0x5014, \"exif:ThumbnailHeight\" },\n      {  0x5015, \"exif:ThumbnailColorDepth\" },\n      {  0x5016, \"exif:ThumbnailPlanes\" },\n      {  0x5017, \"exif:ThumbnailRawBytes\" },\n      {  0x5018, \"exif:ThumbnailSize\" },\n      {  0x5019, \"exif:ThumbnailCompressedSize\" },\n      {  0x501a, \"exif:ColorTransferFunction\" },\n      {  0x501b, \"exif:ThumbnailData\" },\n      {  0x5020, \"exif:ThumbnailImageWidth\" },\n      {  0x5021, \"exif:ThumbnailImageHeight\" },\n      {  0x5022, \"exif:ThumbnailBitsPerSample\" },\n      {  0x5023, \"exif:ThumbnailCompression\" },\n      {  0x5024, \"exif:ThumbnailPhotometricInterp\" },\n      {  0x5025, \"exif:ThumbnailImageDescription\" },\n      {  0x5026, \"exif:ThumbnailEquipMake\" },\n      {  0x5027, \"exif:ThumbnailEquipModel\" },\n      {  0x5028, \"exif:ThumbnailStripOffsets\" },\n      {  0x5029, \"exif:ThumbnailOrientation\" },\n      {  0x502a, \"exif:ThumbnailSamplesPerPixel\" },\n      {  0x502b, \"exif:ThumbnailRowsPerStrip\" },\n      {  0x502c, \"exif:ThumbnailStripBytesCount\" },\n      {  0x502d, \"exif:ThumbnailResolutionX\" },\n      {  0x502e, \"exif:ThumbnailResolutionY\" },\n      {  0x502f, \"exif:ThumbnailPlanarConfig\" },\n      {  0x5030, \"exif:ThumbnailResolutionUnit\" },\n      {  0x5031, \"exif:ThumbnailTransferFunction\" },\n      {  0x5032, \"exif:ThumbnailSoftwareUsed\" },\n      {  0x5033, \"exif:ThumbnailDateTime\" },\n      {  0x5034, \"exif:ThumbnailArtist\" },\n      {  0x5035, \"exif:ThumbnailWhitePoint\" },\n      {  0x5036, \"exif:ThumbnailPrimaryChromaticities\" },\n      {  0x5037, \"exif:ThumbnailYCbCrCoefficients\" },\n      {  0x5038, \"exif:ThumbnailYCbCrSubsampling\" },\n      {  0x5039, \"exif:ThumbnailYCbCrPositioning\" },\n      {  0x503A, \"exif:ThumbnailRefBlackWhite\" },\n      {  0x503B, \"exif:ThumbnailCopyRight\" },\n      {  0x5090, \"exif:LuminanceTable\" },\n      {  0x5091, \"exif:ChrominanceTable\" },\n      {  0x5100, \"exif:FrameDelay\" },\n      {  0x5101, \"exif:LoopCount\" },\n      {  0x5110, \"exif:PixelUnit\" },\n      {  0x5111, \"exif:PixelPerUnitX\" },\n      {  0x5112, \"exif:PixelPerUnitY\" },\n      {  0x5113, \"exif:PaletteHistogram\" },\n      {  0x1000, \"exif:RelatedImageFileFormat\" },\n      {  0x1001, \"exif:RelatedImageLength\" },\n      {  0x1002, \"exif:RelatedImageWidth\" },\n      {  0x800d, \"exif:ImageID\" },\n      {  0x80e3, \"exif:Matteing\" },\n      {  0x80e4, \"exif:DataType\" },\n      {  0x80e5, \"exif:ImageDepth\" },\n      {  0x80e6, \"exif:TileDepth\" },\n      {  0x828d, \"exif:CFARepeatPatternDim\" },\n      {  0x828e, \"exif:CFAPattern2\" },\n      {  0x828f, \"exif:BatteryLevel\" },\n      {  0x8298, \"exif:Copyright\" },\n      {  0x829a, \"exif:ExposureTime\" },\n      {  0x829d, \"exif:FNumber\" },\n      {  0x83bb, \"exif:IPTC/NAA\" },\n      {  0x84e3, \"exif:IT8RasterPadding\" },\n      {  0x84e5, \"exif:IT8ColorTable\" },\n      {  0x8649, \"exif:ImageResourceInformation\" },\n      {  0x8769, \"exif:ExifOffset\" },  /* specs as \"Exif IFD Pointer\"? */\n      {  0x8773, \"exif:InterColorProfile\" },\n      {  0x8822, \"exif:ExposureProgram\" },\n      {  0x8824, \"exif:SpectralSensitivity\" },\n      {  0x8825, \"exif:GPSInfo\" }, /* specs as \"GPSInfo IFD Pointer\"? */\n      {  0x8827, \"exif:PhotographicSensitivity\" },\n      {  0x8828, \"exif:OECF\" },\n      {  0x8829, \"exif:Interlace\" },      \n      {  0x882a, \"exif:TimeZoneOffset\" },\n      {  0x882b, \"exif:SelfTimerMode\" },\n      {  0x8830, \"exif:SensitivityType\" },\n      {  0x8831, \"exif:StandardOutputSensitivity\" },\n      {  0x8832, \"exif:RecommendedExposureIndex\" },\n      {  0x8833, \"exif:ISOSpeed\" },\n      {  0x8834, \"exif:ISOSpeedLatitudeyyy\" },\n      {  0x8835, \"exif:ISOSpeedLatitudezzz\" },\n      {  0x9000, \"exif:ExifVersion\" },\n      {  0x9003, \"exif:DateTimeOriginal\" },\n      {  0x9004, \"exif:DateTimeDigitized\" },\n      {  0x9010, \"exif:OffsetTime\" },\n      {  0x9011, \"exif:OffsetTimeOriginal\" },\n      {  0x9012, \"exif:OffsetTimeDigitized\" },\n      {  0x9101, \"exif:ComponentsConfiguration\" },\n      {  0x9102, \"exif:CompressedBitsPerPixel\" },\n      {  0x9201, \"exif:ShutterSpeedValue\" },\n      {  0x9202, \"exif:ApertureValue\" },\n      {  0x9203, \"exif:BrightnessValue\" },\n      {  0x9204, \"exif:ExposureBiasValue\" },\n      {  0x9205, \"exif:MaxApertureValue\" },\n      {  0x9206, \"exif:SubjectDistance\" },\n      {  0x9207, \"exif:MeteringMode\" },\n      {  0x9208, \"exif:LightSource\" },\n      {  0x9209, \"exif:Flash\" },\n      {  0x920a, \"exif:FocalLength\" },\n      {  0x920b, \"exif:FlashEnergy\" },\n      {  0x920c, \"exif:SpatialFrequencyResponse\" },\n      {  0x920d, \"exif:Noise\" },\n      {  0x9214, \"exif:SubjectArea\" },\n      {  0x9290, \"exif:SubSecTime\" },\n      {  0x9291, \"exif:SubSecTimeOriginal\" },\n      {  0x9292, \"exif:SubSecTimeDigitized\" },    \n      {  0x9211, \"exif:ImageNumber\" },\n      {  0x9212, \"exif:SecurityClassification\" },\n      {  0x9213, \"exif:ImageHistory\" },\n      {  0x9214, \"exif:SubjectArea\" },\n      {  0x9215, \"exif:ExposureIndex\" },\n      {  0x9216, \"exif:TIFF-EPStandardID\" },\n      {  0x927c, \"exif:MakerNote\" },\n      {  0x9286, \"exif:UserComment\" },\n      {  0x9290, \"exif:SubSecTime\" },\n      {  0x9291, \"exif:SubSecTimeOriginal\" },\n      {  0x9292, \"exif:SubSecTimeDigitized\" },    \n      {  0x9400, \"exif:Temperature\" },\n      {  0x9401, \"exif:Humidity\" },\n      {  0x9402, \"exif:Pressure\" },\n      {  0x9403, \"exif:WaterDepth\" },\n      {  0x9404, \"exif:Acceleration\" },\n      {  0x9405, \"exif:CameraElevationAngle\" },    \n      {  0x9C9b, \"exif:WinXP-Title\" },\n      {  0x9C9c, \"exif:WinXP-Comments\" },\n      {  0x9C9d, \"exif:WinXP-Author\" },\n      {  0x9C9e, \"exif:WinXP-Keywords\" },\n      {  0x9C9f, \"exif:WinXP-Subject\" },      \n      {  0xa000, \"exif:FlashPixVersion\" },\n      {  0xa001, \"exif:ColorSpace\" },\n      {  0xa002, \"exif:PixelXDimension\" },\n      {  0xa003, \"exif:PixelYDimension\" },\n      {  0xa004, \"exif:RelatedSoundFile\" },\n      {  0xa005, \"exif:InteroperabilityOffset\" },\n      {  0xa20b, \"exif:FlashEnergy\" },\n      {  0xa20c, \"exif:SpatialFrequencyResponse\" },\n      {  0xa20d, \"exif:Noise\" },\n      {  0xa20e, \"exif:FocalPlaneXResolution\" },\n      {  0xa20f, \"exif:FocalPlaneYResolution\" },\n      {  0xa210, \"exif:FocalPlaneResolutionUnit\" },\n      {  0xa214, \"exif:SubjectLocation\" },\n      {  0xa215, \"exif:ExposureIndex\" },\n      {  0xa216, \"exif:TIFF/EPStandardID\" },\n      {  0xa217, \"exif:SensingMethod\" },\n      {  0xa300, \"exif:FileSource\" },\n      {  0xa301, \"exif:SceneType\" },\n      {  0xa302, \"exif:CFAPattern\" },\n      {  0xa401, \"exif:CustomRendered\" },\n      {  0xa402, \"exif:ExposureMode\" },\n      {  0xa403, \"exif:WhiteBalance\" },\n      {  0xa404, \"exif:DigitalZoomRatio\" },\n      {  0xa405, \"exif:FocalLengthIn35mmFilm\" },\n      {  0xa406, \"exif:SceneCaptureType\" },\n      {  0xa407, \"exif:GainControl\" },\n      {  0xa408, \"exif:Contrast\" },\n      {  0xa409, \"exif:Saturation\" },\n      {  0xa40a, \"exif:Sharpness\" },\n      {  0xa40b, \"exif:DeviceSettingDescription\" },\n      {  0xa40c, \"exif:SubjectDistanceRange\" },\n      {  0xa420, \"exif:ImageUniqueID\" },\n      {  0xa430, \"exif:CameraOwnerName\" },\n      {  0xa431, \"exif:BodySerialNumber\" },\n      {  0xa432, \"exif:LensSpecification\" },\n      {  0xa433, \"exif:LensMake\" },\n      {  0xa434, \"exif:LensModel\" },\n      {  0xa435, \"exif:LensSerialNumber\" },\n      {  0xc4a5, \"exif:PrintImageMatching\" },\n      {  0xa500, \"exif:Gamma\" },\n      {  0xc640, \"exif:CR2Slice\" },\n      { 0x10000, \"exif:GPSVersionID\" },\n      { 0x10001, \"exif:GPSLatitudeRef\" },\n      { 0x10002, \"exif:GPSLatitude\" },\n      { 0x10003, \"exif:GPSLongitudeRef\" },\n      { 0x10004, \"exif:GPSLongitude\" },\n      { 0x10005, \"exif:GPSAltitudeRef\" },\n      { 0x10006, \"exif:GPSAltitude\" },\n      { 0x10007, \"exif:GPSTimeStamp\" },\n      { 0x10008, \"exif:GPSSatellites\" },\n      { 0x10009, \"exif:GPSStatus\" },\n      { 0x1000a, \"exif:GPSMeasureMode\" },\n      { 0x1000b, \"exif:GPSDop\" },\n      { 0x1000c, \"exif:GPSSpeedRef\" },\n      { 0x1000d, \"exif:GPSSpeed\" },\n      { 0x1000e, \"exif:GPSTrackRef\" },\n      { 0x1000f, \"exif:GPSTrack\" },\n      { 0x10010, \"exif:GPSImgDirectionRef\" },\n      { 0x10011, \"exif:GPSImgDirection\" },\n      { 0x10012, \"exif:GPSMapDatum\" },\n      { 0x10013, \"exif:GPSDestLatitudeRef\" },\n      { 0x10014, \"exif:GPSDestLatitude\" },\n      { 0x10015, \"exif:GPSDestLongitudeRef\" },\n      { 0x10016, \"exif:GPSDestLongitude\" },\n      { 0x10017, \"exif:GPSDestBearingRef\" },\n      { 0x10018, \"exif:GPSDestBearing\" },\n      { 0x10019, \"exif:GPSDestDistanceRef\" },\n      { 0x1001a, \"exif:GPSDestDistance\" },\n      { 0x1001b, \"exif:GPSProcessingMethod\" },\n      { 0x1001c, \"exif:GPSAreaInformation\" },\n      { 0x1001d, \"exif:GPSDateStamp\" },\n      { 0x1001e, \"exif:GPSDifferential\" },\n      { 0x1001f, \"exif:GPSHPositioningError\" },\n      { 0x00000, \"\" }\n    };  /* http://www.cipa.jp/std/documents/e/DC-008-Translation-2016-E.pdf */\n\n  const StringInfo\n    *profile;\n\n  const unsigned char\n    *directory,\n    *exif;\n\n  DirectoryInfo\n    directory_stack[MaxDirectoryStack];\n\n  EndianType\n    endian;\n\n  MagickBooleanType\n    status;\n\n  ssize_t\n    i;\n\n  size_t\n    entry,\n    length,\n    number_entries,\n    tag,\n    tag_value;\n\n  SplayTreeInfo\n    *exif_resources;\n\n  ssize_t\n    all,\n    id,\n    level,\n    offset,\n    tag_offset;\n\n  static int\n    tag_bytes[] = {0, 1, 1, 2, 4, 8, 1, 1, 2, 4, 8, 4, 8};\n\n  /*\n    If EXIF data exists, then try to parse the request for a tag.\n  */\n  profile=GetImageProfile(image,\"exif\");\n  if (profile == (const StringInfo *) NULL)\n    return(MagickFalse);\n  if ((property == (const char *) NULL) || (*property == '\\0'))\n    return(MagickFalse);\n  while (isspace((int) ((unsigned char) *property)) != 0)\n    property++;\n  if (strlen(property) <= 5)\n    return(MagickFalse);\n  all=0;\n  tag=(~0UL);\n  switch (*(property+5))\n  {\n    case '*':\n    {\n      /*\n        Caller has asked for all the tags in the EXIF data.\n      */\n      tag=0;\n      all=1; /* return the data in description=value format */\n      break;\n    }\n    case '!':\n    {\n      tag=0;\n      all=2; /* return the data in tagid=value format */\n      break;\n    }\n    case '#':\n    case '@':\n    {\n      int\n        c;\n\n      size_t\n        n;\n\n      /*\n        Check for a hex based tag specification first.\n      */\n      tag=(*(property+5) == '@') ? 1UL : 0UL;\n      property+=6;\n      n=strlen(property);\n      if (n != 4)\n        return(MagickFalse);\n      /*\n        Parse tag specification as a hex number.\n      */\n      n/=4;\n      do\n      {\n        for (i=(ssize_t) n-1L; i >= 0; i--)\n        {\n          c=(*property++);\n          tag<<=4;\n          if ((c >= '0') && (c <= '9'))\n            tag|=(c-'0');\n          else\n            if ((c >= 'A') && (c <= 'F'))\n              tag|=(c-('A'-10));\n            else\n              if ((c >= 'a') && (c <= 'f'))\n                tag|=(c-('a'-10));\n              else\n                return(MagickFalse);\n        }\n      } while (*property != '\\0');\n      break;\n    }\n    default:\n    {\n      /*\n        Try to match the text with a tag name instead.\n      */\n      for (i=0; ; i++)\n      {\n        if (EXIFTag[i].tag == 0)\n          break;\n        if (LocaleCompare(EXIFTag[i].description,property) == 0)\n          {\n            tag=(size_t) EXIFTag[i].tag;\n            break;\n          }\n      }\n      break;\n    }\n  }\n  if (tag == (~0UL))\n    return(MagickFalse);\n  length=GetStringInfoLength(profile);\n  if (length < 6)\n    return(MagickFalse);\n  exif=GetStringInfoDatum(profile);\n  while (length != 0)\n  {\n    if (ReadPropertyByte(&exif,&length) != 0x45)\n      continue;\n    if (ReadPropertyByte(&exif,&length) != 0x78)\n      continue;\n    if (ReadPropertyByte(&exif,&length) != 0x69)\n      continue;\n    if (ReadPropertyByte(&exif,&length) != 0x66)\n      continue;\n    if (ReadPropertyByte(&exif,&length) != 0x00)\n      continue;\n    if (ReadPropertyByte(&exif,&length) != 0x00)\n      continue;\n    break;\n  }\n  if (length < 16)\n    return(MagickFalse);\n  id=(ssize_t) ReadPropertySignedShort(LSBEndian,exif);\n  endian=LSBEndian;\n  if (id == 0x4949)\n    endian=LSBEndian;\n  else\n    if (id == 0x4D4D)\n      endian=MSBEndian;\n    else\n      return(MagickFalse);\n  if (ReadPropertyUnsignedShort(endian,exif+2) != 0x002a)\n    return(MagickFalse);\n  /*\n    This the offset to the first IFD.\n  */\n  offset=(ssize_t) ReadPropertySignedLong(endian,exif+4);\n  if ((offset < 0) || (size_t) offset >= length)\n    return(MagickFalse);\n  /*\n    Set the pointer to the first IFD and follow it were it leads.\n  */\n  status=MagickFalse;\n  directory=exif+offset;\n  level=0;\n  entry=0;\n  tag_offset=0;\n  exif_resources=NewSplayTree((int (*)(const void *,const void *)) NULL,\n    (void *(*)(void *)) NULL,(void *(*)(void *)) NULL);\n  do\n  {\n    /*\n      If there is anything on the stack then pop it off.\n    */\n    if (level > 0)\n      {\n        level--;\n        directory=directory_stack[level].directory;\n        entry=directory_stack[level].entry;\n        tag_offset=directory_stack[level].offset;\n      }\n    if ((directory < exif) || (directory > (exif+length-2)))\n      break;\n    /*\n      Determine how many entries there are in the current IFD.\n    */\n    number_entries=(size_t) ReadPropertyUnsignedShort(endian,directory);\n    for ( ; entry < number_entries; entry++)\n    {\n      unsigned char\n        *p,\n        *q;\n\n      size_t\n        format;\n\n      ssize_t\n        number_bytes,\n        components;\n\n      q=(unsigned char *) (directory+(12*entry)+2);\n      if (q > (exif+length-12))\n        break;  /* corrupt EXIF */\n      if (GetValueFromSplayTree(exif_resources,q) == q)\n        break;\n      (void) AddValueToSplayTree(exif_resources,q,q);\n      tag_value=(size_t) ReadPropertyUnsignedShort(endian,q)+tag_offset;\n      format=(size_t) ReadPropertyUnsignedShort(endian,q+2);\n      if (format >= (sizeof(tag_bytes)/sizeof(*tag_bytes)))\n        break;\n      if (format == 0)\n        break;  /* corrupt EXIF */\n      components=(ssize_t) ReadPropertySignedLong(endian,q+4);\n      if (components < 0)\n        break;  /* corrupt EXIF */\n      number_bytes=(size_t) components*tag_bytes[format];\n      if (number_bytes < components)\n        break;  /* prevent overflow */\n      if (number_bytes <= 4)\n        p=q+8;\n      else\n        {\n          ssize_t\n            dir_offset;\n\n          /*\n            The directory entry contains an offset.\n          */\n          dir_offset=(ssize_t) ReadPropertySignedLong(endian,q+8);\n          if ((dir_offset < 0) || (size_t) dir_offset >= length)\n            continue;\n          if (((size_t) dir_offset+number_bytes) < (size_t) dir_offset)\n            continue;  /* prevent overflow */\n          if (((size_t) dir_offset+number_bytes) > length)\n            continue;\n          p=(unsigned char *) (exif+dir_offset);\n        }\n      if ((all != 0) || (tag == (size_t) tag_value))\n        {\n          char\n            buffer[MaxTextExtent],\n            *value;\n\n          if ((p < exif) || (p > (exif+length-tag_bytes[format])))\n            break;\n          value=(char *) NULL;\n          *buffer='\\0';\n          switch (format)\n          {\n            case EXIF_FMT_BYTE:\n            case EXIF_FMT_UNDEFINED:\n            {\n              value=(char *) NULL;\n              if (~((size_t) number_bytes) >= 1)\n                value=(char *) AcquireQuantumMemory((size_t) number_bytes+1UL,\n                  sizeof(*value));\n              if (value != (char *) NULL)\n                {\n                  for (i=0; i < (ssize_t) number_bytes; i++)\n                  {\n                    value[i]='.';\n                    if (isprint((int) p[i]) != 0) \n                      value[i]=(char) p[i];\n                  }\n                  value[i]='\\0';\n                }\n              break;\n            }\n            case EXIF_FMT_SBYTE:\n            {\n              EXIFMultipleValues(1,\"%.20g\",(double) (*(signed char *) p1));\n              break;\n            }\n            case EXIF_FMT_SSHORT:\n            {\n              EXIFMultipleValues(2,\"%hd\",ReadPropertySignedShort(endian,p1));\n              break;\n            }\n            case EXIF_FMT_USHORT:\n            {\n              EXIFMultipleValues(2,\"%hu\",ReadPropertyUnsignedShort(endian,p1));\n              break;\n            }\n            case EXIF_FMT_ULONG:\n            {\n              EXIFMultipleValues(4,\"%.20g\",(double)\n                ReadPropertyUnsignedLong(endian,p1));\n              break;\n            }\n            case EXIF_FMT_SLONG:\n            {\n              EXIFMultipleValues(4,\"%.20g\",(double)\n                ReadPropertySignedLong(endian,p1));\n              break;\n            }\n            case EXIF_FMT_URATIONAL:\n            {\n              EXIFMultipleFractions(8,\"%.20g/%.20g\",(double)\n                ReadPropertyUnsignedLong(endian,p1),(double)\n                ReadPropertyUnsignedLong(endian,p1+4));\n              break;\n            }\n            case EXIF_FMT_SRATIONAL:\n            {\n              EXIFMultipleFractions(8,\"%.20g/%.20g\",(double)\n                ReadPropertySignedLong(endian,p1),(double)\n                ReadPropertySignedLong(endian,p1+4));\n              break;\n            }\n            case EXIF_FMT_SINGLE:\n            {\n              EXIFMultipleValues(4,\"%f\",(double) *(float *) p1);\n              break;\n            }\n            case EXIF_FMT_DOUBLE:\n            {\n              EXIFMultipleValues(8,\"%f\",*(double *) p1);\n              break;\n            }\n            case EXIF_FMT_STRING:\n            default:\n            {\n              if ((p < exif) || (p > (exif+length-number_bytes)))\n                break;\n              value=(char *) NULL;\n              if (~((size_t) number_bytes) >= 1)\n                value=(char *) AcquireQuantumMemory((size_t) number_bytes+1UL,\n                  sizeof(*value));\n              if (value != (char *) NULL)\n                {\n                  ssize_t\n                    i;\n\n                  for (i=0; i < (ssize_t) number_bytes; i++)\n                  {\n                    value[i]='.';\n                    if ((isprint((int) p[i]) != 0) || (p[i] == '\\0'))\n                      value[i]=(char) p[i];\n                  }\n                  value[i]='\\0';\n                }\n              break;\n            }\n          }\n          if (value != (char *) NULL)\n            {\n              char\n                *key;\n\n              const char\n                *p;\n\n              key=AcquireString(property);\n              switch (all)\n              {\n                case 1:\n                {\n                  const char\n                    *description;\n\n                  ssize_t\n                    i;\n\n                  description=\"unknown\";\n                  for (i=0; ; i++)\n                  {\n                    if (EXIFTag[i].tag == 0)\n                      break;\n                    if (EXIFTag[i].tag == tag_value)\n                      {\n                        description=EXIFTag[i].description;\n                        break;\n                      }\n                  }\n                  (void) FormatLocaleString(key,MaxTextExtent,\"%s\",\n                    description);\n                  if (level == 2)\n                    (void) SubstituteString(&key,\"exif:\",\"exif:thumbnail:\");\n                  break;\n                }\n                case 2:\n                {\n                  if (tag_value < 0x10000)\n                    (void) FormatLocaleString(key,MaxTextExtent,\"#%04lx\",\n                      (unsigned long) tag_value);\n                  else\n                    if (tag_value < 0x20000)\n                      (void) FormatLocaleString(key,MaxTextExtent,\"@%04lx\",\n                        (unsigned long) (tag_value & 0xffff));\n                    else\n                      (void) FormatLocaleString(key,MaxTextExtent,\"unknown\");\n                  break;\n                }\n                default:\n                {\n                  if (level == 2)\n                    (void) SubstituteString(&key,\"exif:\",\"exif:thumbnail:\");\n                }\n              }\n              p=(const char *) NULL;\n              if (image->properties != (void *) NULL)\n                p=(const char *) GetValueFromSplayTree((SplayTreeInfo *)\n                  image->properties,key);\n              if (p == (const char *) NULL)\n                (void) SetImageProperty((Image *) image,key,value);\n              value=DestroyString(value);\n              key=DestroyString(key);\n              status=MagickTrue;\n            }\n        }\n        if ((tag_value == TAG_EXIF_OFFSET) ||\n            (tag_value == TAG_INTEROP_OFFSET) || (tag_value == TAG_GPS_OFFSET))\n          {\n            ssize_t\n              offset;\n\n            offset=(ssize_t) ReadPropertySignedLong(endian,p);\n            if (((size_t) offset < length) && (level < (MaxDirectoryStack-2)))\n              {\n                ssize_t\n                  tag_offset1;\n\n                tag_offset1=(ssize_t) ((tag_value == TAG_GPS_OFFSET) ? 0x10000 :\n                  0);\n                directory_stack[level].directory=directory;\n                entry++;\n                directory_stack[level].entry=entry;\n                directory_stack[level].offset=tag_offset;\n                level++;\n                /*\n                  Check for duplicate tag.\n                */\n                for (i=0; i < level; i++)\n                  if (directory_stack[i].directory == (exif+tag_offset1))\n                    break;\n                if (i < level)\n                  break;  /* duplicate tag */\n                directory_stack[level].directory=exif+offset;\n                directory_stack[level].offset=tag_offset1;\n                directory_stack[level].entry=0;\n                level++;\n                if ((directory+2+(12*number_entries)+4) > (exif+length))\n                  break;\n                offset=(ssize_t) ReadPropertySignedLong(endian,directory+2+(12*\n                  number_entries));\n                if ((offset != 0) && ((size_t) offset < length) &&\n                    (level < (MaxDirectoryStack-2)))\n                  {\n                    directory_stack[level].directory=exif+offset;\n                    directory_stack[level].entry=0;\n                    directory_stack[level].offset=tag_offset1;\n                    level++;\n                  }\n              }\n            break;\n          }\n    }\n  } while (level > 0);\n  exif_resources=DestroySplayTree(exif_resources);\n  return(status);\n}",
        "func_hash": 292096308156704952246887123009503225331,
        "file_name": "property.c",
        "file_hash": 122751008107964047346147343124174074065,
        "cwe": [
            "CWE-704"
        ],
        "cve": "CVE-2022-32547",
        "cve_desc": "In ImageMagick, there is load of misaligned address for type 'double', which requires 8 byte alignment and for type 'float', which requires 4 byte alignment at MagickCore/property.c. Whenever crafted or untrusted input is processed by ImageMagick, this causes a negative impact to application availability or other problems related to undefined behavior.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-32547",
        "func_name": "GetEXIFProperty",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 194989,
        "project": "ImageMagick6",
        "commit_id": "450949ed017f009b399c937cf362f0058eacc5fa",
        "project_url": "https://github.com/ImageMagick/ImageMagick6",
        "commit_url": "https://github.com/ImageMagick/ImageMagick6/commit/450949ed017f009b399c937cf362f0058eacc5fa",
        "commit_message": "Pull request: https://github.com/ImageMagick/ImageMagick/pull/4963",
        "target": 1,
        "irrelevant": 1,
        "func_before": "static MagickBooleanType ReadPSDChannelPixels(Image *image,\n  const size_t channels,const ssize_t row,const ssize_t type,\n  const unsigned char *pixels,ExceptionInfo *exception)\n{\n  Quantum\n    pixel;\n\n  const unsigned char\n    *p;\n\n  IndexPacket\n    *indexes;\n\n  PixelPacket\n    *q;\n\n  ssize_t\n    x;\n\n  size_t\n    packet_size;\n\n  unsigned short\n    nibble;\n\n  p=pixels;\n  q=GetAuthenticPixels(image,0,row,image->columns,1,exception);\n  if (q == (PixelPacket *) NULL)\n    return MagickFalse;\n  indexes=GetAuthenticIndexQueue(image);\n  packet_size=GetPSDPacketSize(image);\n  for (x=0; x < (ssize_t) image->columns; x++)\n  {\n    if (packet_size == 1)\n      pixel=ScaleCharToQuantum(*p++);\n    else\n      if (packet_size == 2)\n        {\n          p=PushShortPixel(MSBEndian,p,&nibble);\n          pixel=ScaleShortToQuantum(nibble);\n        }\n      else\n        {\n          MagickFloatType\n            nibble;\n\n          p=PushFloatPixel(MSBEndian,p,&nibble);\n          pixel=ClampToQuantum((MagickRealType)QuantumRange*nibble);\n        }\n    if (image->depth > 1)\n      {\n        SetPSDPixel(image,channels,type,packet_size,pixel,q,indexes,x);\n        q++;\n      }\n    else\n      {\n        ssize_t\n          bit,\n          number_bits;\n\n        number_bits=(ssize_t) image->columns-x;\n        if (number_bits > 8)\n          number_bits=8;\n        for (bit=0; bit < number_bits; bit++)\n        {\n          SetPSDPixel(image,channels,type,packet_size,(((unsigned char) pixel)\n            & (0x01 << (7-bit))) != 0 ? 0 : QuantumRange,q++,indexes,x++);\n        }\n        if (x != (ssize_t) image->columns)\n          x--;\n        continue;\n      }\n  }\n  return(SyncAuthenticPixels(image,exception));\n}",
        "func_hash": 50584299779312396054491404176852470969,
        "file_name": "psd.c",
        "file_hash": 159316916509494023086155162326374999236,
        "cwe": [
            "CWE-190"
        ],
        "cve": "CVE-2022-32545",
        "cve_desc": "A vulnerability was found in ImageMagick, causing an outside the range of representable values of type 'unsigned char' at coders/psd.c, when crafted or untrusted input is processed. This leads to a negative impact to application availability or other problems related to undefined behavior.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-32545",
        "func_name": "ReadPSDChannelPixels",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 194994,
        "project": "tensorflow",
        "commit_id": "c79ccba517dbb1a0ccb9b01ee3bd2a63748b60dd",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/c79ccba517dbb1a0ccb9b01ee3bd2a63748b60dd",
        "commit_message": "Fix memory leak when a graph node is invalid.\n\nIf a graph node is invalid but a kernel is created then we set the kernel back to `nullptr` but we forget to delete it. Hence, we get a memory leak.\n\nPiperOrigin-RevId: 408968108\nChange-Id: I1d8a9d0d8988ed5e08be8b9f2004ce1b4cd11b7c",
        "target": 1,
        "irrelevant": 0,
        "func_before": "Status ImmutableExecutorState::Initialize(const Graph& graph) {\n  TF_RETURN_IF_ERROR(gview_.Initialize(&graph));\n\n  // Build the information about frames in this subgraph.\n  ControlFlowInfo cf_info;\n  TF_RETURN_IF_ERROR(BuildControlFlowInfo(&graph, &cf_info));\n\n  for (auto& it : cf_info.unique_frame_names) {\n    EnsureFrameInfo(it)->nodes =\n        absl::make_unique<std::vector<const NodeItem*>>();\n  }\n  root_frame_info_ = frame_info_[\"\"].get();\n\n  pending_ids_.resize(gview_.num_nodes());\n\n  // Preprocess every node in the graph to create an instance of op\n  // kernel for each node.\n  requires_control_flow_ = false;\n  for (const Node* n : graph.nodes()) {\n    if (IsSink(n)) continue;\n    if (IsSwitch(n) || IsMerge(n) || IsEnter(n) || IsExit(n)) {\n      requires_control_flow_ = true;\n    } else if (IsRecv(n)) {\n      // A Recv node from a different device may produce dead tensors from\n      // non-local control-flow nodes.\n      //\n      // TODO(mrry): Track whether control flow was present in the\n      // pre-partitioned graph, and enable the caller (e.g.\n      // `DirectSession`) to relax this constraint.\n      string send_device;\n      string recv_device;\n      TF_RETURN_IF_ERROR(GetNodeAttr(n->attrs(), \"send_device\", &send_device));\n      TF_RETURN_IF_ERROR(GetNodeAttr(n->attrs(), \"recv_device\", &recv_device));\n      if (send_device != recv_device) {\n        requires_control_flow_ = true;\n      }\n    }\n\n    const int id = n->id();\n    const string& frame_name = cf_info.frame_names[id];\n    FrameInfo* frame_info = EnsureFrameInfo(frame_name);\n\n    NodeItem* item = gview_.node(id);\n    item->node_id = id;\n\n    item->input_start = frame_info->total_inputs;\n    frame_info->total_inputs += n->num_inputs();\n\n    Status s = params_.create_kernel(n->properties(), &item->kernel);\n    if (!s.ok()) {\n      item->kernel = nullptr;\n      s = AttachDef(s, *n);\n      return s;\n    }\n    CHECK(item->kernel);\n    item->kernel_is_async = (item->kernel->AsAsync() != nullptr);\n    item->is_merge = IsMerge(n);\n    item->is_any_consumer_merge_or_control_trigger = false;\n    for (const Node* consumer : n->out_nodes()) {\n      if (IsMerge(consumer) || IsControlTrigger(consumer)) {\n        item->is_any_consumer_merge_or_control_trigger = true;\n        break;\n      }\n    }\n    const Tensor* const_tensor = item->kernel->const_tensor();\n    if (const_tensor) {\n      // Hold onto a shallow copy of the constant tensor in `*this` so that the\n      // reference count does not drop to 1. This prevents the constant tensor\n      // from being forwarded, and its buffer reused.\n      const_tensors_.emplace_back(*const_tensor);\n    }\n    item->const_tensor = const_tensor;\n    item->is_noop = (item->kernel->type_string_view() == \"NoOp\");\n    item->is_enter = IsEnter(n);\n    if (item->is_enter) {\n      bool is_constant_enter;\n      TF_RETURN_IF_ERROR(\n          GetNodeAttr(n->attrs(), \"is_constant\", &is_constant_enter));\n      item->is_constant_enter = is_constant_enter;\n\n      string frame_name;\n      TF_RETURN_IF_ERROR(GetNodeAttr(n->attrs(), \"frame_name\", &frame_name));\n      FrameInfo* frame_info = frame_info_[frame_name].get();\n\n      int parallel_iterations;\n      TF_RETURN_IF_ERROR(\n          GetNodeAttr(n->attrs(), \"parallel_iterations\", &parallel_iterations));\n\n      if (frame_info->parallel_iterations == -1) {\n        frame_info->parallel_iterations = parallel_iterations;\n      } else if (frame_info->parallel_iterations != parallel_iterations) {\n        LOG(WARNING) << \"Loop frame \\\"\" << frame_name\n                     << \"\\\" had two different values for parallel_iterations: \"\n                     << frame_info->parallel_iterations << \" vs. \"\n                     << parallel_iterations << \".\";\n      }\n\n      if (enter_frame_info_.size() <= id) {\n        enter_frame_info_.resize(id + 1);\n      }\n      enter_frame_info_[id] = frame_info;\n    } else {\n      item->is_constant_enter = false;\n    }\n    item->is_exit = IsExit(n);\n    item->is_control_trigger = IsControlTrigger(n);\n    item->is_source = IsSource(n);\n    item->is_enter_exit_or_next_iter =\n        (IsEnter(n) || IsExit(n) || IsNextIteration(n));\n    item->is_transfer_node = IsTransferNode(n);\n    item->is_initialization_op = IsInitializationOp(n);\n    item->is_recv_or_switch = IsRecv(n) || IsSwitch(n);\n    item->is_next_iteration = IsNextIteration(n);\n    item->is_distributed_communication = IsDistributedCommunication(n);\n\n    // Compute the maximum values we'll store for this node in the\n    // pending counts data structure, and allocate a handle in\n    // that frame's pending counts data structure that has enough\n    // space to store these maximal count values.\n    size_t max_pending, max_dead;\n    GetMaxPendingCounts(n, &max_pending, &max_dead);\n    pending_ids_[id] =\n        frame_info->pending_counts_layout.CreateHandle(max_pending, max_dead);\n\n    // See if this node is a root node, and if so, add item to root_nodes_.\n    if (n->in_edges().empty()) {\n      root_nodes_.push_back(item);\n    }\n\n    // Initialize static information about the frames in the graph.\n    frame_info->nodes->push_back(item);\n    if (item->is_enter) {\n      string enter_name;\n      TF_RETURN_IF_ERROR(GetNodeAttr(n->attrs(), \"frame_name\", &enter_name));\n      EnsureFrameInfo(enter_name)->input_count++;\n    }\n\n    // Record information about whether each output of the op is used.\n    std::unique_ptr<bool[]> outputs_required(new bool[n->num_outputs()]);\n    std::fill(&outputs_required[0], &outputs_required[n->num_outputs()], false);\n    int32_t unused_outputs = n->num_outputs();\n    for (const Edge* e : n->out_edges()) {\n      if (IsSink(e->dst())) continue;\n      if (e->src_output() >= 0) {\n        if (!outputs_required[e->src_output()]) {\n          --unused_outputs;\n          outputs_required[e->src_output()] = true;\n        }\n      }\n    }\n    if (unused_outputs > 0) {\n      for (int i = 0; i < n->num_outputs(); ++i) {\n        if (!outputs_required[i]) {\n          metrics::RecordUnusedOutput(n->type_string());\n        }\n      }\n      item->outputs_required = std::move(outputs_required);\n    }\n  }\n\n  // Rewrite each `EdgeInfo::input_slot` member to refer directly to the input\n  // location.\n  for (const Node* n : graph.nodes()) {\n    if (IsSink(n)) continue;\n    const int id = n->id();\n    NodeItem* item = gview_.node(id);\n\n    for (EdgeInfo& e : item->mutable_output_edges()) {\n      const int dst_id = e.dst_id;\n      NodeItem* dst_item = gview_.node(dst_id);\n      e.input_slot += dst_item->input_start;\n    }\n  }\n\n  // Initialize PendingCounts only after pending_ids_[node.id] is initialized\n  // for all nodes.\n  InitializePending(&graph, cf_info);\n  return gview_.SetAllocAttrs(&graph, params_.device);\n}",
        "func_hash": 105248557138287586060572648585871722551,
        "file_name": "immutable_executor_state.cc",
        "file_hash": 234046012522402227954780787024760975669,
        "cwe": [
            "CWE-401"
        ],
        "cve": "CVE-2022-23578",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. If a graph node is invalid, TensorFlow can leak memory in the implementation of `ImmutableExecutorState::Initialize`. Here, we set `item->kernel` to `nullptr` but it is a simple `OpKernel*` pointer so the memory that was previously allocated to it would leak. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23578",
        "func_name": "ImmutableExecutorState::Initialize",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 194996,
        "project": "tensorflow",
        "commit_id": "4f38b1ac8e42727e18a2f0bde06d3bee8e77b250",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/4f38b1ac8e42727e18a2f0bde06d3bee8e77b250",
        "commit_message": "Prevent null dereference read in `GetInitOp`.\n\nWe have a map of maps. We test that the key exists in the first map but then we don't have any validation that this also means the second map has the needed key. In the scenarios where this is not the case, we'll dereference a nullptr, if we don't have this check\n\nPiperOrigin-RevId: 408739325\nChange-Id: If9bb7ed759aba1f3b56a34913f209508dbaf65ce",
        "target": 1,
        "irrelevant": 1,
        "func_before": "Status GetInitOp(const string& export_dir, const MetaGraphDef& meta_graph_def,\n                 string* init_op_name) {\n  const auto& sig_def_map = meta_graph_def.signature_def();\n  const auto& init_op_sig_it =\n      meta_graph_def.signature_def().find(kSavedModelInitOpSignatureKey);\n  if (init_op_sig_it != sig_def_map.end()) {\n    *init_op_name = init_op_sig_it->second.outputs()\n                        .find(kSavedModelInitOpSignatureKey)\n                        ->second.name();\n    return Status::OK();\n  }\n\n  const auto& collection_def_map = meta_graph_def.collection_def();\n  string init_op_collection_key;\n  if (collection_def_map.find(kSavedModelMainOpKey) !=\n      collection_def_map.end()) {\n    init_op_collection_key = kSavedModelMainOpKey;\n  } else {\n    init_op_collection_key = kSavedModelLegacyInitOpKey;\n  }\n\n  const auto init_op_it = collection_def_map.find(init_op_collection_key);\n  if (init_op_it != collection_def_map.end()) {\n    if (init_op_it->second.node_list().value_size() != 1) {\n      return errors::FailedPrecondition(\n          strings::StrCat(\"Expected exactly one main op in : \", export_dir));\n    }\n    *init_op_name = init_op_it->second.node_list().value(0);\n  }\n  return Status::OK();\n}",
        "func_hash": 90320046309155279319769139363770698236,
        "file_name": "loader_util.cc",
        "file_hash": 223638670651747648145854147173893848422,
        "cwe": [
            "CWE-476"
        ],
        "cve": "CVE-2022-23577",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The implementation of `GetInitOp` is vulnerable to a crash caused by dereferencing a null pointer. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23577",
        "func_name": "GetInitOp",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 194998,
        "project": "tensorflow",
        "commit_id": "240655511cd3e701155f944a972db71b6c0b1bb6",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/240655511cd3e701155f944a972db71b6c0b1bb6",
        "commit_message": "Eliminate `CHECK`-fails from `IsSimplifiableReshape` via `MakeShape(<invalid shape>)`\n\nPiperOrigin-RevId: 409166738\nChange-Id: I7f0a3590b8acae3f3e3e2fe636e1f5ef285693cf",
        "target": 1,
        "irrelevant": 0,
        "func_before": "Status ConstantFolding::IsSimplifiableReshape(\n    const NodeDef& node, const GraphProperties& properties) const {\n  if (!IsReshape(node)) {\n    return errors::Internal(\"Node \", node.name(), \" is not a Reshape node\");\n  }\n  if (2 > node.input_size()) {\n    return errors::Internal(\"Node \", node.name(),\n                            \" must have at most 2 inputs but has \",\n                            node.input_size());\n  }\n  const NodeDef* new_shape = node_map_->GetNode(node.input(1));\n  if (!IsReallyConstant(*new_shape)) {\n    return errors::Internal(\"Node \", node.name(), \" has shape \",\n                            new_shape->DebugString(),\n                            \" which is not a constant\");\n  }\n  TensorVector outputs;\n  auto outputs_cleanup = gtl::MakeCleanup([&outputs] {\n    for (const auto& output : outputs) {\n      delete output.tensor;\n    }\n  });\n\n  Status s = EvaluateNode(*new_shape, TensorVector(), &outputs);\n  if (!s.ok()) {\n    return errors::Internal(\"Could not evaluate node \", node.name());\n  }\n  if (outputs.size() != 1) {\n    return errors::Internal(\"Node \", node.name(),\n                            \" must have exactly 1 output but has \",\n                            outputs.size());\n  }\n\n  const std::vector<OpInfo::TensorProperties>& props =\n      properties.GetInputProperties(node.name());\n  if (props.empty()) {\n    return errors::Internal(\"Node \", node.name(), \" has no properties\");\n  }\n  const OpInfo::TensorProperties& prop = props[0];\n  if (prop.dtype() == DT_INVALID) {\n    return errors::Internal(\"Node \", node.name(), \" has property \",\n                            prop.DebugString(), \" with invalid dtype\");\n  }\n  const PartialTensorShape shape(prop.shape());\n  if (!shape.IsFullyDefined()) {\n    return errors::Internal(\"Node \", node.name(), \" has property \",\n                            prop.DebugString(), \" with shape \",\n                            shape.DebugString(), \" which is not fully defined\");\n  }\n\n  PartialTensorShape new_dims;\n  if (outputs[0]->dtype() == DT_INT32) {\n    std::vector<int32> shp;\n    for (int i = 0; i < outputs[0]->NumElements(); ++i) {\n      int32_t dim = outputs[0]->flat<int32>()(i);\n      shp.push_back(dim);\n    }\n    TF_CHECK_OK(TensorShapeUtils::MakeShape(shp, &new_dims));\n  } else {\n    std::vector<int64_t> shp;\n    for (int i = 0; i < outputs[0]->NumElements(); ++i) {\n      int64_t dim = outputs[0]->flat<int64_t>()(i);\n      shp.push_back(dim);\n    }\n    TF_CHECK_OK(TensorShapeUtils::MakeShape(shp, &new_dims));\n  }\n\n  if (!shape.IsCompatibleWith(new_dims)) {\n    return errors::Internal(\"Expected shape \", shape.DebugString(),\n                            \"to be compatible with \", new_dims.DebugString());\n  }\n\n  return Status::OK();\n}",
        "func_hash": 122664089420988233915419567191040959656,
        "file_name": "constant_folding.cc",
        "file_hash": 35061507297230918846503076104140700863,
        "cwe": [
            "CWE-617"
        ],
        "cve": "CVE-2022-23581",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The Grappler optimizer in TensorFlow can be used to cause a denial of service by altering a `SavedModel` such that `IsSimplifiableReshape` would trigger `CHECK` failures. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23581",
        "func_name": "ConstantFolding::IsSimplifiableReshape",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195017,
        "project": "gpac",
        "commit_id": "ad18ece95fa064efc0995c4ab2c985f77fb166ec",
        "project_url": "https://github.com/gpac/gpac",
        "commit_url": "https://github.com/gpac/gpac/commit/ad18ece95fa064efc0995c4ab2c985f77fb166ec",
        "commit_message": "fixed #1904",
        "target": 1,
        "irrelevant": 1,
        "func_before": "u32 GetHintFormat(GF_TrackBox *trak)\n{\n\tGF_HintMediaHeaderBox *hmhd = (GF_HintMediaHeaderBox *)trak->Media->information->InfoHeader;\n\tif (hmhd->type != GF_ISOM_BOX_TYPE_HMHD)\n\t\treturn 0;\n\t\t\n\tif (!hmhd || !hmhd->subType) {\n\t\tGF_Box *a = (GF_Box *)gf_list_get(trak->Media->information->sampleTable->SampleDescription->child_boxes, 0);\n\t\tif (!hmhd) return a ? a->type : 0;\n\t\tif (a) hmhd->subType = a->type;\n\t\treturn hmhd->subType;\n\t}\n\treturn hmhd->subType;\n}",
        "func_hash": 91218268849686441388880855658517990203,
        "file_name": "hint_track.c",
        "file_hash": 60176895274654779679144452624639678766,
        "cwe": [
            "CWE-476"
        ],
        "cve": "CVE-2021-40576",
        "cve_desc": "The binary MP4Box in Gpac 1.0.1 has a null pointer dereference vulnerability in the gf_isom_get_payt_count function in hint_track.c, which allows attackers to cause a denial of service.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-40576",
        "func_name": "GetHintFormat",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195019,
        "project": "tensorflow",
        "commit_id": "6b5adc0877de832b2a7c189532dbbbc64622eeb6",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/6b5adc0877de832b2a7c189532dbbbc64622eeb6",
        "commit_message": "Prevent `CHECK`-fail when building reference tensor.\n\nThe tensor constructor does not allow reference dtypes, as these should not show up explicitly. However, when passed these invalid types instead of building an invalid object the constructor crashes via a `CHECK`-fail. We have a static builder that properly handles this case but is not applicable given current usage.\n\nInstead, before calling the constructor, we can check that the dtype is not a reference type and return an error otherwise, given that the dtype is user controlled so malicious users can trigger denial of service.\n\nPiperOrigin-RevId: 409662503\nChange-Id: I5892f831fde7f276cd7ab34519cf6b8061c71a59",
        "target": 1,
        "irrelevant": 0,
        "func_before": "Status ConstantFolding::EvaluateOneFoldable(const NodeDef& node,\n                                            std::vector<NodeDef>* outputs,\n                                            bool* result_too_large) {\n  TensorVector inputs;\n  TensorVector output_tensors;\n  auto inputs_cleanup = gtl::MakeCleanup([&inputs, &output_tensors] {\n    for (const auto& input : inputs) {\n      delete input.tensor;\n    }\n    for (const auto& output : output_tensors) {\n      if (output.tensor) {\n        delete output.tensor;\n      }\n    }\n  });\n\n  size_t total_inputs_size = 0;\n  for (const auto& input : node.input()) {\n    const TensorId input_tensor = ParseTensorName(input);\n    if (input_tensor.index() < 0) {\n      // Control dependency\n      break;\n    }\n    const NodeDef* input_node = node_map_->GetNode(input);\n    if (!IsReallyConstant(*input_node)) {\n      return Status(error::INVALID_ARGUMENT,\n                    strings::StrCat(\"Can't fold \", node.name(), \", its \", input,\n                                    \" isn't constant\"));\n    }\n    TF_RETURN_IF_ERROR(CheckAttrExists(*input_node, \"value\"));\n    const TensorProto& raw_val = input_node->attr().at(\"value\").tensor();\n    if (raw_val.dtype() == DT_INVALID) {\n      return Status(\n          error::INVALID_ARGUMENT,\n          strings::StrCat(\"A tensor in the input node, with TensorId of \",\n                          input_tensor.ToString(),\n                          \" has a dtype of DT_INVALID.\"));\n    }\n    Tensor* value = new Tensor(raw_val.dtype(), raw_val.tensor_shape());\n    if (!value->FromProto(raw_val)) {\n      delete (value);\n      return errors::InvalidArgument(\"Unable to make Tensor from proto for \",\n                                     node.name(), \" with shape \",\n                                     raw_val.tensor_shape().DebugString());\n    }\n    inputs.emplace_back(value);\n    total_inputs_size += value->TotalBytes();\n  }\n\n  TF_RETURN_IF_ERROR(EvaluateNode(node, inputs, &output_tensors));\n  if (output_tensors.empty()) {\n    return Status(error::INVALID_ARGUMENT, \"Expected at least one output.\");\n  }\n\n  outputs->resize(output_tensors.size());\n  for (size_t i = 0; i < output_tensors.size(); i++) {\n    string node_name = OptimizedNodeName(node, \"-folded\");\n    if (output_tensors.size() > 1) {\n      node_name = strings::StrCat(node_name, \"-\", i);\n    }\n    if (output_tensors[i].tensor) {\n      Status s = CreateNodeDef(node_name, output_tensors[i], &outputs->at(i),\n                               total_inputs_size);\n      if (!s.ok()) {\n        *result_too_large = true;\n        return s;\n      }\n    } else {\n      // Create an empty NodeDef to identify dead outputs (e.g. the output of a\n      // switch that's not selected by the switch predicate).\n      outputs->at(i) = NodeDef();\n    }\n  }\n  return Status::OK();\n}",
        "func_hash": 33937240667530924395323323412961833143,
        "file_name": "constant_folding.cc",
        "file_hash": 221573695858123615640237954647315751120,
        "cwe": [
            "CWE-617"
        ],
        "cve": "CVE-2022-23588",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. A malicious user can cause a denial of service by altering a `SavedModel` such that Grappler optimizer would attempt to build a tensor using a reference `dtype`. This would result in a crash due to a `CHECK`-fail in the `Tensor` constructor as reference types are not allowed. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23588",
        "func_name": "ConstantFolding::EvaluateOneFoldable",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195022,
        "project": "glewlwyd",
        "commit_id": "125281f1c0d4b6a8b49f7e55a757205a2ef01fbe",
        "project_url": "https://github.com/babelouest/glewlwyd",
        "commit_url": "https://github.com/babelouest/glewlwyd/commit/125281f1c0d4b6a8b49f7e55a757205a2ef01fbe",
        "commit_message": "Fix update session when auth fail",
        "target": 1,
        "irrelevant": 0,
        "func_before": "int callback_glewlwyd_user_auth (const struct _u_request * request, struct _u_response * response, void * user_data) {\n  struct config_elements * config = (struct config_elements *)user_data;\n  json_t * j_param = ulfius_get_json_body_request(request, NULL), * j_result = NULL;\n  const char * ip_source = get_ip_source(request);\n  char * issued_for = get_client_hostname(request);\n  char * session_uid, expires[129];\n  time_t now;\n  struct tm ts;\n  \n  time(&now);\n  now += GLEWLWYD_DEFAULT_SESSION_EXPIRATION_COOKIE;\n  gmtime_r(&now, &ts);\n  strftime(expires, 128, \"%a, %d %b %Y %T %Z\", &ts);\n  if (j_param != NULL) {\n    if (json_string_length(json_object_get(j_param, \"username\"))) {\n      if (json_object_get(j_param, \"scheme_type\") == NULL || 0 == o_strcmp(json_string_value(json_object_get(j_param, \"scheme_type\")), \"password\")) {\n        if (json_string_length(json_object_get(j_param, \"password\"))) {\n          j_result = auth_check_user_credentials(config, json_string_value(json_object_get(j_param, \"username\")), json_string_value(json_object_get(j_param, \"password\")));\n          if (check_result_value(j_result, G_OK)) {\n            if ((session_uid = get_session_id(config, request)) == NULL) {\n              session_uid = generate_session_id();\n            }\n            if (user_session_update(config, session_uid, u_map_get_case(request->map_header, \"user-agent\"), issued_for, json_string_value(json_object_get(j_param, \"username\")), NULL, 1) != G_OK) {\n              y_log_message(Y_LOG_LEVEL_ERROR, \"callback_glewlwyd_user_auth - Error user_session_update (1)\");\n              response->status = 500;\n            } else {\n              ulfius_add_cookie_to_response(response, config->session_key, session_uid, expires, 0, config->cookie_domain, \"/\", config->cookie_secure, 0);\n              y_log_message(Y_LOG_LEVEL_INFO, \"Event - User '%s' authenticated with password\", json_string_value(json_object_get(j_param, \"username\")));\n            }\n            o_free(session_uid);\n            glewlwyd_metrics_increment_counter_va(config, GLWD_METRICS_AUTH_USER_VALID, 1, NULL);\n            glewlwyd_metrics_increment_counter_va(config, GLWD_METRICS_AUTH_USER_VALID_SCHEME, 1, \"scheme_type\", \"password\", NULL);\n          } else {\n            if (check_result_value(j_result, G_ERROR_UNAUTHORIZED)) {\n              y_log_message(Y_LOG_LEVEL_WARNING, \"Security - Authorization invalid for username %s at IP Address %s\", json_string_value(json_object_get(j_param, \"username\")), ip_source);\n            }\n            if ((session_uid = get_session_id(config, request)) != NULL && user_session_update(config, session_uid, u_map_get_case(request->map_header, \"user-agent\"), issued_for, json_string_value(json_object_get(j_param, \"username\")), NULL, 1) != G_OK) {\n              y_log_message(Y_LOG_LEVEL_ERROR, \"callback_glewlwyd_user_auth - Error user_session_update (2)\");\n            }\n            o_free(session_uid);\n            response->status = 401;\n            glewlwyd_metrics_increment_counter_va(config, GLWD_METRICS_AUTH_USER_INVALID, 1, NULL);\n            glewlwyd_metrics_increment_counter_va(config, GLWD_METRICS_AUTH_USER_INVALID_SCHEME, 1, \"scheme_type\", \"password\", NULL);\n          }\n          json_decref(j_result);\n        } else if (json_object_get(j_param, \"password\") != NULL && !json_is_string(json_object_get(j_param, \"password\"))) {\n          ulfius_set_string_body_response(response, 400, \"password must be a string\");\n        } else {\n          session_uid = get_session_id(config, request);\n          j_result = get_users_for_session(config, session_uid);\n          if (check_result_value(j_result, G_OK)) {\n            // Refresh username to set as default\n            if (user_session_update(config, u_map_get(request->map_cookie, config->session_key), u_map_get_case(request->map_header, \"user-agent\"), issued_for, json_string_value(json_object_get(j_param, \"username\")), NULL, 0) != G_OK) {\n              y_log_message(Y_LOG_LEVEL_ERROR, \"callback_glewlwyd_user_auth - Error user_session_update (3)\");\n              response->status = 500;\n            } else {\n              ulfius_add_cookie_to_response(response, config->session_key, session_uid, expires, 0, config->cookie_domain, \"/\", config->cookie_secure, 0);\n            }\n          } else if (check_result_value(j_result, G_ERROR_NOT_FOUND)) {\n            response->status = 401;\n          } else {\n            y_log_message(Y_LOG_LEVEL_ERROR, \"callback_glewlwyd_user_auth - Error get_users_for_session\");\n            response->status = 500;\n          }\n          o_free(session_uid);\n          json_decref(j_result);\n        }\n      } else {\n        if (json_string_length(json_object_get(j_param, \"scheme_type\")) && json_string_length(json_object_get(j_param, \"scheme_name\")) && json_is_object(json_object_get(j_param, \"value\"))) {\n          j_result = auth_check_user_scheme(config, json_string_value(json_object_get(j_param, \"scheme_type\")), json_string_value(json_object_get(j_param, \"scheme_name\")), json_string_value(json_object_get(j_param, \"username\")), json_object_get(j_param, \"value\"), request);\n          if (check_result_value(j_result, G_ERROR_PARAM)) {\n            ulfius_set_string_body_response(response, 400, \"bad scheme response\");\n          } else if (check_result_value(j_result, G_ERROR_UNAUTHORIZED)) {\n            y_log_message(Y_LOG_LEVEL_WARNING, \"Security - Authorization invalid for username %s at IP Address %s\", json_string_value(json_object_get(j_param, \"username\")), ip_source);\n            response->status = 401;\n            glewlwyd_metrics_increment_counter_va(config, GLWD_METRICS_AUTH_USER_INVALID, 1, NULL);\n            glewlwyd_metrics_increment_counter_va(config, GLWD_METRICS_AUTH_USER_INVALID_SCHEME, 1, \"scheme_type\", json_string_value(json_object_get(j_param, \"scheme_type\")), \"scheme_name\", json_string_value(json_object_get(j_param, \"scheme_name\")), NULL);\n          } else if (check_result_value(j_result, G_ERROR_NOT_FOUND)) {\n            response->status = 404;\n          } else if (check_result_value(j_result, G_OK)) {\n            if ((session_uid = get_session_id(config, request)) == NULL) {\n              session_uid = generate_session_id();\n            }\n            if (user_session_update(config, session_uid, u_map_get_case(request->map_header, \"user-agent\"), issued_for, json_string_value(json_object_get(j_param, \"username\")), json_string_value(json_object_get(j_param, \"scheme_name\")), 1) != G_OK) {\n              y_log_message(Y_LOG_LEVEL_ERROR, \"callback_glewlwyd_user_auth - Error user_session_update (4)\");\n              response->status = 500;\n            } else {\n              ulfius_add_cookie_to_response(response, config->session_key, session_uid, expires, 0, config->cookie_domain, \"/\", config->cookie_secure, 0);\n              y_log_message(Y_LOG_LEVEL_INFO, \"Event - User '%s' authenticated with scheme '%s/%s'\", json_string_value(json_object_get(j_param, \"username\")), json_string_value(json_object_get(j_param, \"scheme_type\")), json_string_value(json_object_get(j_param, \"scheme_name\")));\n            }\n            o_free(session_uid);\n            glewlwyd_metrics_increment_counter_va(config, GLWD_METRICS_AUTH_USER_VALID, 1, NULL);\n            glewlwyd_metrics_increment_counter_va(config, GLWD_METRICS_AUTH_USER_VALID_SCHEME, 1, \"scheme_type\", json_string_value(json_object_get(j_param, \"scheme_type\")), \"scheme_name\", json_string_value(json_object_get(j_param, \"scheme_name\")), NULL);\n          } else {\n            y_log_message(Y_LOG_LEVEL_ERROR, \"callback_glewlwyd_user_auth - Error auth_check_user_scheme\");\n            response->status = 500;\n          }\n          json_decref(j_result);\n        } else {\n          ulfius_set_string_body_response(response, 400, \"scheme_type, scheme_name and value are mandatory\");\n        }\n      }\n    } else {\n      if (json_string_length(json_object_get(j_param, \"scheme_type\")) && json_string_length(json_object_get(j_param, \"scheme_name\")) && json_is_object(json_object_get(j_param, \"value\"))) {\n        j_result = auth_check_identify_scheme(config, json_string_value(json_object_get(j_param, \"scheme_type\")), json_string_value(json_object_get(j_param, \"scheme_name\")), json_object_get(j_param, \"value\"), request);\n        if (check_result_value(j_result, G_ERROR_PARAM)) {\n          ulfius_set_string_body_response(response, 400, \"bad scheme response\");\n        } else if (check_result_value(j_result, G_ERROR_UNAUTHORIZED)) {\n          y_log_message(Y_LOG_LEVEL_WARNING, \"Security - Authorization invalid for username <UNKNOWN> at IP Address %s\", ip_source);\n          response->status = 401;\n        } else if (check_result_value(j_result, G_ERROR_NOT_FOUND)) {\n          response->status = 404;\n        } else if (check_result_value(j_result, G_OK)) {\n          if ((session_uid = get_session_id(config, request)) == NULL) {\n            session_uid = generate_session_id();\n          }\n          if (user_session_update(config, session_uid, u_map_get_case(request->map_header, \"user-agent\"), issued_for, json_string_value(json_object_get(j_result, \"username\")), json_string_value(json_object_get(j_param, \"scheme_name\")), 1) != G_OK) {\n            y_log_message(Y_LOG_LEVEL_ERROR, \"callback_glewlwyd_user_auth - Error user_session_update (4)\");\n            response->status = 500;\n          } else {\n            ulfius_add_cookie_to_response(response, config->session_key, session_uid, expires, 0, config->cookie_domain, \"/\", config->cookie_secure, 0);\n            y_log_message(Y_LOG_LEVEL_INFO, \"Event - User '%s' authenticated with scheme '%s/%s'\", json_string_value(json_object_get(j_result, \"username\")), json_string_value(json_object_get(j_param, \"scheme_type\")), json_string_value(json_object_get(j_param, \"scheme_name\")));\n          }\n          o_free(session_uid);\n        } else {\n          y_log_message(Y_LOG_LEVEL_ERROR, \"callback_glewlwyd_user_auth - Error auth_check_user_scheme\");\n          response->status = 500;\n        }\n        json_decref(j_result);\n      } else {\n        ulfius_set_string_body_response(response, 400, \"username is mandatory\");\n      }\n    }\n  } else {\n    ulfius_set_string_body_response(response, 400, \"Input parameters must be in JSON format\");\n  }\n  json_decref(j_param);\n  o_free(issued_for);\n\n  return U_CALLBACK_CONTINUE;\n}",
        "func_hash": 236114269060053642565806917047085397848,
        "file_name": "webservice.c",
        "file_hash": 249878395356016662912854745569339968395,
        "cwe": [
            "CWE-287"
        ],
        "cve": "CVE-2021-45379",
        "cve_desc": "Glewlwyd 2.0.0, fixed in 2.6.1 is affected by an incorrect access control vulnerability. One user can attempt to log in as another user without its password.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-45379",
        "func_name": "callback_glewlwyd_user_auth",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195023,
        "project": "tensorflow",
        "commit_id": "a68f68061e263a88321c104a6c911fe5598050a8",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/a68f68061e263a88321c104a6c911fe5598050a8",
        "commit_message": "Replace faulty overflow check with a builder for `TensorShape`.\n\nPrevents an integer overflow that was not caught before.\n\nPiperOrigin-RevId: 415381595\nChange-Id: I76585ddedc912bd9f4a390aeafa8e2ced1a28863",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext* context) override {\n    const Tensor* input_indices;\n    const Tensor* input_values;\n    const Tensor* input_shape;\n    SparseTensorsMap* map;\n\n    OP_REQUIRES_OK(context, context->input(\"sparse_indices\", &input_indices));\n    OP_REQUIRES_OK(context, context->input(\"sparse_values\", &input_values));\n    OP_REQUIRES_OK(context, context->input(\"sparse_shape\", &input_shape));\n    OP_REQUIRES_OK(context, GetMap(context, true /* is_writing */, &map));\n\n    OP_REQUIRES(context, TensorShapeUtils::IsMatrix(input_indices->shape()),\n                errors::InvalidArgument(\n                    \"Input indices should be a matrix but received shape \",\n                    input_indices->shape().DebugString()));\n    OP_REQUIRES(context, TensorShapeUtils::IsVector(input_values->shape()),\n                errors::InvalidArgument(\n                    \"Input values should be a vector but received shape \",\n                    input_values->shape().DebugString()));\n    OP_REQUIRES(context, TensorShapeUtils::IsVector(input_shape->shape()),\n                errors::InvalidArgument(\n                    \"Input shape should be a vector but received shape \",\n                    input_shape->shape().DebugString()));\n    OP_REQUIRES(\n        context,\n        input_values->shape().dim_size(0) == input_indices->shape().dim_size(0),\n        errors::InvalidArgument(\n            \"Number of values must match first dimension of indices. \", \"Got \",\n            input_values->shape().dim_size(0),\n            \" values, indices shape: \", input_indices->shape().DebugString()));\n    OP_REQUIRES(\n        context,\n        input_shape->shape().dim_size(0) == input_indices->shape().dim_size(1),\n        errors::InvalidArgument(\n            \"Number of dimensions must match second dimension of indices. \",\n            \"Got \", input_shape->shape().dim_size(0),\n            \" dimensions, indices shape: \",\n            input_indices->shape().DebugString()));\n\n    int rank = input_shape->NumElements();\n\n    OP_REQUIRES(\n        context, rank > 1,\n        errors::InvalidArgument(\n            \"Rank of input SparseTensor should be > 1, but saw rank: \", rank));\n\n    auto input_shape_vec = input_shape->vec<int64_t>();\n    int new_num_elements = 1;\n    bool overflow_ocurred = false;\n    for (int i = 0; i < input_shape_vec.size(); i++) {\n      new_num_elements =\n          MultiplyWithoutOverflow(new_num_elements, input_shape_vec(i));\n      if (new_num_elements < 0) {\n        overflow_ocurred = true;\n        break;\n      }\n    }\n\n    OP_REQUIRES(\n        context, !overflow_ocurred,\n        errors::Internal(\"Encountered overflow from large input shape.\"));\n\n    TensorShape tensor_input_shape(input_shape_vec);\n    gtl::InlinedVector<int64_t, 8> std_order(rank);\n    std::iota(std_order.begin(), std_order.end(), 0);\n    SparseTensor input_st;\n    OP_REQUIRES_OK(context, SparseTensor::Create(*input_indices, *input_values,\n                                                 tensor_input_shape, std_order,\n                                                 &input_st));\n\n    const int64_t N = input_shape_vec(0);\n\n    Tensor sparse_handles(DT_INT64, TensorShape({N}));\n    auto sparse_handles_t = sparse_handles.vec<int64_t>();\n\n    OP_REQUIRES_OK(context, input_st.IndicesValid());\n\n    // We can generate the output shape proto string now, for all\n    // minibatch entries.\n    TensorShape output_shape;\n    OP_REQUIRES_OK(context, TensorShapeUtils::MakeShape(\n                                input_shape_vec.data() + 1,\n                                input_shape->NumElements() - 1, &output_shape));\n\n    // Get groups by minibatch dimension\n    std::unordered_set<int64_t> visited;\n    sparse::GroupIterable minibatch = input_st.group({0});\n    for (const auto& subset : minibatch) {\n      const int64_t b = subset.group()[0];\n      visited.insert(b);\n      OP_REQUIRES(\n          context, b > -1 && b < N,\n          errors::InvalidArgument(\n              \"Received unexpected column 0 value in input SparseTensor: \", b,\n              \" < 0 or >= N (= \", N, \")\"));\n\n      const auto indices = subset.indices();\n      const auto values = subset.values<T>();\n      const int64_t num_entries = values.size();\n\n      Tensor output_indices = Tensor(DT_INT64, {num_entries, rank - 1});\n      Tensor output_values = Tensor(DataTypeToEnum<T>::value, {num_entries});\n\n      auto output_indices_t = output_indices.matrix<int64_t>();\n      auto output_values_t = output_values.vec<T>();\n\n      for (int i = 0; i < num_entries; ++i) {\n        for (int d = 1; d < rank; ++d) {\n          output_indices_t(i, d - 1) = indices(i, d);\n        }\n        output_values_t(i) = values(i);\n      }\n\n      SparseTensor st_i;\n      OP_REQUIRES_OK(context,\n                     SparseTensor::Create(output_indices, output_values,\n                                          output_shape, &st_i));\n      int64_t handle;\n      OP_REQUIRES_OK(context, map->AddSparseTensor(context, st_i, &handle));\n      sparse_handles_t(b) = handle;\n    }\n\n    // Fill in any gaps; we must provide an empty ST for batch entries\n    // the grouper didn't find.\n    if (visited.size() < N) {\n      Tensor empty_indices(DT_INT64, {0, rank - 1});\n      Tensor empty_values(DataTypeToEnum<T>::value, {0});\n      SparseTensor empty_st;\n      OP_REQUIRES_OK(context, SparseTensor::Create(empty_indices, empty_values,\n                                                   output_shape, &empty_st));\n\n      for (int64_t b = 0; b < N; ++b) {\n        // We skipped this batch entry.\n        if (visited.find(b) == visited.end()) {\n          int64_t handle;\n          OP_REQUIRES_OK(context,\n                         map->AddSparseTensor(context, empty_st, &handle));\n          sparse_handles_t(b) = handle;\n        }\n      }\n    }\n\n    context->set_output(0, sparse_handles);\n  }",
        "func_hash": 160387063214720131730960354923232758630,
        "file_name": "sparse_tensors_map_ops.cc",
        "file_hash": 224775123349374780251651202891389866533,
        "cwe": [
            "CWE-190"
        ],
        "cve": "CVE-2022-23568",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The implementation of `AddManySparseToTensorsMap` is vulnerable to an integer overflow which results in a `CHECK`-fail when building new `TensorShape` objects (so, an assert failure based denial of service). We are missing some validation on the shapes of the input tensors as well as directly constructing a large `TensorShape` with user-provided dimensions. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23568",
        "func_name": "Compute",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195026,
        "project": "linux",
        "commit_id": "ab0fc21bc7105b54bafd85bd8b82742f9e68898a",
        "project_url": "https://github.com/torvalds/linux",
        "commit_url": "https://github.com/torvalds/linux/commit/ab0fc21bc7105b54bafd85bd8b82742f9e68898a",
        "commit_message": "Revert \"NFSv4: Handle the special Linux file open access mode\"\n\nThis reverts commit 44942b4e457beda00981f616402a1a791e8c616e.\n\nAfter secondly opening a file with O_ACCMODE|O_DIRECT flags,\nnfs4_valid_open_stateid() will dereference NULL nfs4_state when lseek().\n\nReproducer:\n  1. mount -t nfs -o vers=4.2 $server_ip:/ /mnt/\n  2. fd = open(\"/mnt/file\", O_ACCMODE|O_DIRECT|O_CREAT)\n  3. close(fd)\n  4. fd = open(\"/mnt/file\", O_ACCMODE|O_DIRECT)\n  5. lseek(fd)\n\nReported-by: Lyu Tao <tao.lyu@epfl.ch>\nSigned-off-by: ChenXiaoSong <chenxiaosong2@huawei.com>\nSigned-off-by: Trond Myklebust <trond.myklebust@hammerspace.com>",
        "target": 1,
        "irrelevant": 0,
        "func_before": "nfs4_file_open(struct inode *inode, struct file *filp)\n{\n\tstruct nfs_open_context *ctx;\n\tstruct dentry *dentry = file_dentry(filp);\n\tstruct dentry *parent = NULL;\n\tstruct inode *dir;\n\tunsigned openflags = filp->f_flags;\n\tstruct iattr attr;\n\tint err;\n\n\t/*\n\t * If no cached dentry exists or if it's negative, NFSv4 handled the\n\t * opens in ->lookup() or ->create().\n\t *\n\t * We only get this far for a cached positive dentry.  We skipped\n\t * revalidation, so handle it here by dropping the dentry and returning\n\t * -EOPENSTALE.  The VFS will retry the lookup/create/open.\n\t */\n\n\tdprintk(\"NFS: open file(%pd2)\\n\", dentry);\n\n\terr = nfs_check_flags(openflags);\n\tif (err)\n\t\treturn err;\n\n\tif ((openflags & O_ACCMODE) == 3)\n\t\treturn nfs_open(inode, filp);\n\n\t/* We can't create new files here */\n\topenflags &= ~(O_CREAT|O_EXCL);\n\n\tparent = dget_parent(dentry);\n\tdir = d_inode(parent);\n\n\tctx = alloc_nfs_open_context(file_dentry(filp), filp->f_mode, filp);\n\terr = PTR_ERR(ctx);\n\tif (IS_ERR(ctx))\n\t\tgoto out;\n\n\tattr.ia_valid = ATTR_OPEN;\n\tif (openflags & O_TRUNC) {\n\t\tattr.ia_valid |= ATTR_SIZE;\n\t\tattr.ia_size = 0;\n\t\tfilemap_write_and_wait(inode->i_mapping);\n\t}\n\n\tinode = NFS_PROTO(dir)->open_context(dir, ctx, openflags, &attr, NULL);\n\tif (IS_ERR(inode)) {\n\t\terr = PTR_ERR(inode);\n\t\tswitch (err) {\n\t\tdefault:\n\t\t\tgoto out_put_ctx;\n\t\tcase -ENOENT:\n\t\tcase -ESTALE:\n\t\tcase -EISDIR:\n\t\tcase -ENOTDIR:\n\t\tcase -ELOOP:\n\t\t\tgoto out_drop;\n\t\t}\n\t}\n\tif (inode != d_inode(dentry))\n\t\tgoto out_drop;\n\n\tnfs_file_set_open_context(filp, ctx);\n\tnfs_fscache_open_file(inode, filp);\n\terr = 0;\n\nout_put_ctx:\n\tput_nfs_open_context(ctx);\nout:\n\tdput(parent);\n\treturn err;\n\nout_drop:\n\td_drop(dentry);\n\terr = -EOPENSTALE;\n\tgoto out_put_ctx;\n}",
        "func_hash": 67846125552854891508125900978071958871,
        "file_name": "nfs4file.c",
        "file_hash": 109456154040292488452120321326967957719,
        "cwe": [
            "CWE-909"
        ],
        "cve": "CVE-2022-24448",
        "cve_desc": "An issue was discovered in fs/nfs/dir.c in the Linux kernel before 5.16.5. If an application sets the O_DIRECTORY flag, and tries to open a regular file, nfs_atomic_open() performs a regular lookup. If a regular file is found, ENOTDIR should occur, but the server instead returns uninitialized data in the file descriptor.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-24448",
        "func_name": "nfs4_file_open",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195028,
        "project": "tensorflow",
        "commit_id": "ab51e5b813573dc9f51efa335aebcf2994125ee9",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/ab51e5b813573dc9f51efa335aebcf2994125ee9",
        "commit_message": "Prevent memory leak in decoding PNG images.\n\nPiperOrigin-RevId: 409300653\nChange-Id: I6182124c545989cef80cefd439b659095920763b",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void DecodePngV2(OpKernelContext* context, StringPiece input) {\n    int channel_bits = (data_type_ == DataType::DT_UINT8) ? 8 : 16;\n    png::DecodeContext decode;\n    OP_REQUIRES(\n        context, png::CommonInitDecode(input, channels_, channel_bits, &decode),\n        errors::InvalidArgument(\"Invalid PNG. Failed to initialize decoder.\"));\n\n    // Verify that width and height are not too large:\n    // - verify width and height don't overflow int.\n    // - width can later be multiplied by channels_ and sizeof(uint16), so\n    //   verify single dimension is not too large.\n    // - verify when width and height are multiplied together, there are a few\n    //   bits to spare as well.\n    const int width = static_cast<int>(decode.width);\n    const int height = static_cast<int>(decode.height);\n    const int64_t total_size =\n        static_cast<int64_t>(width) * static_cast<int64_t>(height);\n    if (width != static_cast<int64_t>(decode.width) || width <= 0 ||\n        width >= (1LL << 27) || height != static_cast<int64_t>(decode.height) ||\n        height <= 0 || height >= (1LL << 27) || total_size >= (1LL << 29)) {\n      OP_REQUIRES(context, false,\n                  errors::InvalidArgument(\"PNG size too large for int: \",\n                                          decode.width, \" by \", decode.height));\n    }\n\n    Tensor* output = nullptr;\n    // By the existing API, we support decoding PNG with `DecodeGif` op.\n    // We need to make sure to return 4-D shapes when using `DecodeGif`.\n    if (op_type_ == \"DecodeGif\") {\n      OP_REQUIRES_OK(\n          context,\n          context->allocate_output(\n              0, TensorShape({1, height, width, decode.channels}), &output));\n    } else {\n      OP_REQUIRES_OK(\n          context,\n          context->allocate_output(\n              0, TensorShape({height, width, decode.channels}), &output));\n    }\n\n    if (op_type_ == \"DecodeBmp\") {\n      // TODO(b/171060723): Only DecodeBmp as op_type_ is not acceptable here\n      // because currently `decode_(jpeg|png|gif)` ops can decode any one of\n      // jpeg, png or gif but not bmp. Similarly, `decode_bmp` cannot decode\n      // anything but bmp formats. This behavior needs to be revisited. For more\n      // details, please refer to the bug.\n      OP_REQUIRES(context, false,\n                  errors::InvalidArgument(\n                      \"Trying to decode PNG format using DecodeBmp op. Use \"\n                      \"`decode_png` or `decode_image` instead.\"));\n    } else if (op_type_ == \"DecodeAndCropJpeg\") {\n      OP_REQUIRES(context, false,\n                  errors::InvalidArgument(\n                      \"DecodeAndCropJpeg operation can run on JPEG only, but \"\n                      \"detected PNG.\"));\n    }\n\n    if (data_type_ == DataType::DT_UINT8) {\n      OP_REQUIRES(\n          context,\n          png::CommonFinishDecode(\n              reinterpret_cast<png_bytep>(output->flat<uint8>().data()),\n              decode.channels * width * sizeof(uint8), &decode),\n          errors::InvalidArgument(\"Invalid PNG data, size \", input.size()));\n    } else if (data_type_ == DataType::DT_UINT16) {\n      OP_REQUIRES(\n          context,\n          png::CommonFinishDecode(\n              reinterpret_cast<png_bytep>(output->flat<uint16>().data()),\n              decode.channels * width * sizeof(uint16), &decode),\n          errors::InvalidArgument(\"Invalid PNG data, size \", input.size()));\n    } else if (data_type_ == DataType::DT_FLOAT) {\n      // `png::CommonFinishDecode` does not support `float`. First allocate\n      // uint16 buffer for the image and decode in uint16 (lossless). Wrap the\n      // buffer in `unique_ptr` so that we don't forget to delete the buffer.\n      std::unique_ptr<uint16[]> buffer(\n          new uint16[height * width * decode.channels]);\n      OP_REQUIRES(\n          context,\n          png::CommonFinishDecode(reinterpret_cast<png_bytep>(buffer.get()),\n                                  decode.channels * width * sizeof(uint16),\n                                  &decode),\n          errors::InvalidArgument(\"Invalid PNG data, size \", input.size()));\n\n      // Convert uint16 image data to desired data type.\n      // Use eigen threadpooling to speed up the copy operation.\n      const auto& device = context->eigen_device<Eigen::ThreadPoolDevice>();\n      TTypes<uint16, 3>::UnalignedConstTensor buf(buffer.get(), height, width,\n                                                  decode.channels);\n      float scale = 1. / std::numeric_limits<uint16>::max();\n      // Fill output tensor with desired dtype.\n      output->tensor<float, 3>().device(device) = buf.cast<float>() * scale;\n    }\n  }",
        "func_hash": 67814436772398534036630434647873886403,
        "file_name": "decode_image_op.cc",
        "file_hash": 283519422605879710361255065504339887165,
        "cwe": [
            "CWE-401"
        ],
        "cve": "CVE-2022-23585",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. When decoding PNG images TensorFlow can produce a memory leak if the image is invalid. After calling `png::CommonInitDecode(..., &decode)`, the `decode` value contains allocated buffers which can only be freed by calling `png::CommonFreeDecode(&decode)`. However, several error case in the function implementation invoke the `OP_REQUIRES` macro which immediately terminates the execution of the function, without allowing for the memory free to occur. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23585",
        "func_name": "DecodePngV2",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195029,
        "project": "tensorflow",
        "commit_id": "c99d98cd189839dcf51aee94e7437b54b31f8abd",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/c99d98cd189839dcf51aee94e7437b54b31f8abd",
        "commit_message": "Handle invalid inputs instead of crashing.\n\nPiperOrigin-RevId: 409549744\nChange-Id: I7f5935b34b53f7e426a5462fcc027bdbf5dcda24",
        "target": 1,
        "irrelevant": 0,
        "func_before": "void Node::RunForwardTypeInference() {\n  VLOG(4) << \"Forward type inference: \" << props_->node_def.DebugString();\n\n  if (props_->fwd_type_fn == nullptr) {\n    return;\n  }\n\n  std::vector<Node*> input_nodes(props_->input_types.size(), nullptr);\n  std::vector<int> input_idx(props_->input_types.size(), 0);\n  for (const auto& edge : in_edges_) {\n    if (edge->IsControlEdge()) {\n      continue;\n    }\n    DCHECK(edge->dst_input() < input_nodes.size()) << DebugString();\n    int i = edge->dst_input();\n    input_nodes.at(i) = edge->src();\n    input_idx.at(i) = edge->src_output();\n  }\n\n  // Note: technically, we could use a very generic type when some of the inputs\n  // are unknown. But there is an expectation that a node will have complete\n  // inputs soon, so updating intermediate types is largely unnecessary.\n\n  for (const auto* node : input_nodes) {\n    if (node == nullptr) {\n      // Incomplete inputs, bail.\n      ClearTypeInfo();\n      return;\n    }\n  }\n\n  static FullTypeDef* no_type = new FullTypeDef();\n\n  std::vector<std::reference_wrapper<const FullTypeDef>> input_types;\n  for (int i = 0; i < input_nodes.size(); i++) {\n    const auto* node = input_nodes[i];\n    if (node->def().has_experimental_type()) {\n      const auto& node_t = node->def().experimental_type();\n      if (node_t.type_id() != TFT_UNSET) {\n        int ix = input_idx[i];\n        DCHECK(ix < node_t.args_size())\n            << \"input \" << i << \" should have an output \" << ix\n            << \" but instead only has \" << node_t.args_size()\n            << \" outputs: \" << node_t.DebugString();\n        input_types.emplace_back(node_t.args(ix));\n      } else {\n        input_types.emplace_back(*no_type);\n      }\n    } else {\n      // Incomplete inputs, bail.\n      ClearTypeInfo();\n      return;\n    }\n  }\n\n  const auto infer_type = props_->fwd_type_fn(input_types);\n  const FullTypeDef infer_typedef = infer_type.ValueOrDie();\n  if (infer_typedef.type_id() != TFT_UNSET) {\n    MaybeCopyOnWrite();\n    *(props_->node_def.mutable_experimental_type()) = infer_typedef;\n  }\n}",
        "func_hash": 285691869172413131662679092330979772991,
        "file_name": "graph.cc",
        "file_hash": 172099243927919341591512227523808328051,
        "cwe": [
            "CWE-125"
        ],
        "cve": "CVE-2022-23592",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. TensorFlow's type inference can cause a heap out of bounds read as the bounds checking is done in a `DCHECK` (which is a no-op during production). An attacker can control the `input_idx` variable such that `ix` would be larger than the number of values in `node_t.args`. The fix will be included in TensorFlow 2.8.0. This is the only affected version.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23592",
        "func_name": "Node::RunForwardTypeInference",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195037,
        "project": "tensorflow",
        "commit_id": "b51b82fe65ebace4475e3c54eb089c18a4403f1c",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/b51b82fe65ebace4475e3c54eb089c18a4403f1c",
        "commit_message": "Add missing validation to `AddManySparseToTensorsMap`.\n\nSparse tensors have a set of requirements for the 3 components and not all of them were checked.\n\nPiperOrigin-RevId: 415358027\nChange-Id: I96cbb672999cd1da772c22fabbd15507e32e12dc",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext* context) override {\n    const Tensor* input_indices;\n    const Tensor* input_values;\n    const Tensor* input_shape;\n    SparseTensorsMap* map;\n\n    OP_REQUIRES_OK(context, context->input(\"sparse_indices\", &input_indices));\n    OP_REQUIRES_OK(context, context->input(\"sparse_values\", &input_values));\n    OP_REQUIRES_OK(context, context->input(\"sparse_shape\", &input_shape));\n    OP_REQUIRES_OK(context, GetMap(context, true /* is_writing */, &map));\n\n    OP_REQUIRES(context, TensorShapeUtils::IsMatrix(input_indices->shape()),\n                errors::InvalidArgument(\n                    \"Input indices should be a matrix but received shape \",\n                    input_indices->shape().DebugString()));\n\n    OP_REQUIRES(context, TensorShapeUtils::IsVector(input_values->shape()),\n                errors::InvalidArgument(\n                    \"Input values should be a vector but received shape \",\n                    input_values->shape().DebugString()));\n\n    OP_REQUIRES(context, TensorShapeUtils::IsVector(input_shape->shape()),\n                errors::InvalidArgument(\n                    \"Input shape should be a vector but received shape \",\n                    input_shape->shape().DebugString()));\n\n    int rank = input_shape->NumElements();\n\n    OP_REQUIRES(\n        context, rank > 1,\n        errors::InvalidArgument(\n            \"Rank of input SparseTensor should be > 1, but saw rank: \", rank));\n\n    auto input_shape_vec = input_shape->vec<int64_t>();\n    int new_num_elements = 1;\n    bool overflow_ocurred = false;\n    for (int i = 0; i < input_shape_vec.size(); i++) {\n      new_num_elements =\n          MultiplyWithoutOverflow(new_num_elements, input_shape_vec(i));\n      if (new_num_elements < 0) {\n        overflow_ocurred = true;\n        break;\n      }\n    }\n\n    OP_REQUIRES(\n        context, !overflow_ocurred,\n        errors::Internal(\"Encountered overflow from large input shape.\"));\n\n    TensorShape tensor_input_shape(input_shape_vec);\n    gtl::InlinedVector<int64_t, 8> std_order(rank);\n    std::iota(std_order.begin(), std_order.end(), 0);\n    SparseTensor input_st;\n    OP_REQUIRES_OK(context, SparseTensor::Create(*input_indices, *input_values,\n                                                 tensor_input_shape, std_order,\n                                                 &input_st));\n\n    const int64_t N = input_shape_vec(0);\n\n    Tensor sparse_handles(DT_INT64, TensorShape({N}));\n    auto sparse_handles_t = sparse_handles.vec<int64_t>();\n\n    OP_REQUIRES_OK(context, input_st.IndicesValid());\n\n    // We can generate the output shape proto string now, for all\n    // minibatch entries.\n    TensorShape output_shape;\n    OP_REQUIRES_OK(context, TensorShapeUtils::MakeShape(\n                                input_shape_vec.data() + 1,\n                                input_shape->NumElements() - 1, &output_shape));\n\n    // Get groups by minibatch dimension\n    std::unordered_set<int64_t> visited;\n    sparse::GroupIterable minibatch = input_st.group({0});\n    for (const auto& subset : minibatch) {\n      const int64_t b = subset.group()[0];\n      visited.insert(b);\n      OP_REQUIRES(\n          context, b > -1 && b < N,\n          errors::InvalidArgument(\n              \"Received unexpected column 0 value in input SparseTensor: \", b,\n              \" < 0 or >= N (= \", N, \")\"));\n\n      const auto indices = subset.indices();\n      const auto values = subset.values<T>();\n      const int64_t num_entries = values.size();\n\n      Tensor output_indices = Tensor(DT_INT64, {num_entries, rank - 1});\n      Tensor output_values = Tensor(DataTypeToEnum<T>::value, {num_entries});\n\n      auto output_indices_t = output_indices.matrix<int64_t>();\n      auto output_values_t = output_values.vec<T>();\n\n      for (int i = 0; i < num_entries; ++i) {\n        for (int d = 1; d < rank; ++d) {\n          output_indices_t(i, d - 1) = indices(i, d);\n        }\n        output_values_t(i) = values(i);\n      }\n\n      SparseTensor st_i;\n      OP_REQUIRES_OK(context,\n                     SparseTensor::Create(output_indices, output_values,\n                                          output_shape, &st_i));\n      int64_t handle;\n      OP_REQUIRES_OK(context, map->AddSparseTensor(context, st_i, &handle));\n      sparse_handles_t(b) = handle;\n    }\n\n    // Fill in any gaps; we must provide an empty ST for batch entries\n    // the grouper didn't find.\n    if (visited.size() < N) {\n      Tensor empty_indices(DT_INT64, {0, rank - 1});\n      Tensor empty_values(DataTypeToEnum<T>::value, {0});\n      SparseTensor empty_st;\n      OP_REQUIRES_OK(context, SparseTensor::Create(empty_indices, empty_values,\n                                                   output_shape, &empty_st));\n\n      for (int64_t b = 0; b < N; ++b) {\n        // We skipped this batch entry.\n        if (visited.find(b) == visited.end()) {\n          int64_t handle;\n          OP_REQUIRES_OK(context,\n                         map->AddSparseTensor(context, empty_st, &handle));\n          sparse_handles_t(b) = handle;\n        }\n      }\n    }\n\n    context->set_output(0, sparse_handles);\n  }",
        "func_hash": 171961580694281680039206916179435077047,
        "file_name": "sparse_tensors_map_ops.cc",
        "file_hash": 190320072369250411027996685136568189736,
        "cwe": [
            "CWE-190"
        ],
        "cve": "CVE-2022-23568",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The implementation of `AddManySparseToTensorsMap` is vulnerable to an integer overflow which results in a `CHECK`-fail when building new `TensorShape` objects (so, an assert failure based denial of service). We are missing some validation on the shapes of the input tensors as well as directly constructing a large `TensorShape` with user-provided dimensions. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23568",
        "func_name": "Compute",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195038,
        "project": "mruby",
        "commit_id": "27d1e0132a0804581dca28df042e7047fd27eaa8",
        "project_url": "https://github.com/mruby/mruby",
        "commit_url": "https://github.com/mruby/mruby/commit/27d1e0132a0804581dca28df042e7047fd27eaa8",
        "commit_message": "array.c: fix `mrb_ary_shift_m` initialization bug.\n\nThe `ARY_PTR` and `ARY_LEN` may be modified in `mrb_get_args`.",
        "target": 1,
        "irrelevant": 1,
        "func_before": "mrb_ary_shift_m(mrb_state *mrb, mrb_value self)\n{\n  struct RArray *a = mrb_ary_ptr(self);\n  mrb_int len = ARY_LEN(a);\n  mrb_int n;\n  mrb_value val;\n\n  if (mrb_get_args(mrb, \"|i\", &n) == 0) {\n    return mrb_ary_shift(mrb, self);\n  };\n  ary_modify_check(mrb, a);\n  if (len == 0 || n == 0) return mrb_ary_new(mrb);\n  if (n < 0) mrb_raise(mrb, E_ARGUMENT_ERROR, \"negative array shift\");\n  if (n > len) n = len;\n  val = mrb_ary_new_from_values(mrb, n, ARY_PTR(a));\n  if (ARY_SHARED_P(a)) {\n  L_SHIFT:\n    a->as.heap.ptr+=n;\n    a->as.heap.len-=n;\n    return val;\n  }\n  if (len > ARY_SHIFT_SHARED_MIN) {\n    ary_make_shared(mrb, a);\n    goto L_SHIFT;\n  }\n  else if (len == n) {\n    ARY_SET_LEN(a, 0);\n  }\n  else {\n    mrb_value *ptr = ARY_PTR(a);\n    mrb_int size = len-n;\n\n    while (size--) {\n      *ptr = *(ptr+n);\n      ++ptr;\n    }\n    ARY_SET_LEN(a, len-n);\n  }\n  return val;\n}",
        "func_hash": 88987793594626442814152795226896894437,
        "file_name": "array.c",
        "file_hash": 131985777969528154957566525214352537878,
        "cwe": [
            "CWE-476"
        ],
        "cve": "CVE-2021-4188",
        "cve_desc": "mruby is vulnerable to NULL Pointer Dereference",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-4188",
        "func_name": "mrb_ary_shift_m",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195039,
        "project": "tensorflow",
        "commit_id": "e7f497570abb6b4ae5af4970620cd880e4c0c904",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/e7f497570abb6b4ae5af4970620cd880e4c0c904",
        "commit_message": "Fix segfault on OOM in Conv2D.\n\nPiperOrigin-RevId: 404655317\nChange-Id: I33588dbd3f5d0fef980e3c908bf5515a9ee09ce7",
        "target": 1,
        "irrelevant": 1,
        "func_before": "  void operator()(OpKernelContext* ctx, const Tensor& input,\n                  const Tensor& filter, int row_stride, int col_stride,\n                  int row_dilation, int col_dilation, const Padding& padding,\n                  const std::vector<int64_t>& explicit_paddings, Tensor* output,\n                  TensorFormat data_format) {\n    DCHECK(data_format == FORMAT_NHWC)\n        << \"Grouped conv implementation only \"\n           \"supports NHWC tensor format for now.\";\n\n    const int64_t in_depth = input.dim_size(3);\n    const int64_t patch_depth = filter.dim_size(2);\n    const int64_t num_groups = in_depth / patch_depth;\n\n    // Shuffle input/filter tensors to have group as a leading dimension.\n    std::array<int64_t, 5> shuffle({3, 0, 1, 2, 4});\n\n    // Compute pre shuffle dimemnsions.\n    auto pre_shuffle = [&](const Tensor& tensor) -> std::array<int64, 5> {\n      return {tensor.dim_size(0), tensor.dim_size(1), tensor.dim_size(2),\n              num_groups, tensor.dim_size(3) / num_groups};\n    };\n\n    // Compute post shuffle dimemnsions.\n    auto post_shuffle = [&](const Tensor& tensor) -> std::array<int64, 5> {\n      return {num_groups, tensor.dim_size(0), tensor.dim_size(1),\n              tensor.dim_size(2), tensor.dim_size(3) / num_groups};\n    };\n\n    auto& device = ctx->eigen_device<CPUDevice>();\n\n    absl::BlockingCounter shuffles_completed(2);\n    auto on_shuffled = [&]() { shuffles_completed.DecrementCount(); };\n\n    // Shuffle input into temporary tensor.\n    Tensor input_shuffled(input.dtype(), TensorShape(post_shuffle(input)));\n    input_shuffled.tensor<T, 5>().device(device, on_shuffled) =\n        input.shaped<T, 5>(pre_shuffle(input)).shuffle(shuffle);\n\n    // Shuffle filter into temporary tensor.\n    Tensor filter_shuffled(filter.dtype(), TensorShape(post_shuffle(filter)));\n    filter_shuffled.tensor<T, 5>().device(device, on_shuffled) =\n        filter.shaped<T, 5>(pre_shuffle(filter)).shuffle(shuffle);\n\n    // Wait for the completion of input/filter shuffles.\n    shuffles_completed.Wait();\n\n    // Write group convolution results into temporary output tensor.\n    Tensor output_shuffled(output->dtype(), TensorShape(post_shuffle(*output)));\n\n    for (int64_t i = 0; i < num_groups; ++i) {\n      // TODO(ezhulenev): Run this loop using `parallelFor` (regular parallelFor\n      // will lead to deadlock, SpatialConvolution has to use async Eigen\n      // assignment). This requires small changes to Eigen to support async\n      // exeuction for tensor chipping operation.\n\n      // TODO(ezhulenev): Grouped convolution should also support 1x1 filter\n      // optimization.\n\n      auto input_slice = input_shuffled.tensor<T, 5>().template chip<0>(i);\n      auto filter_slice = filter_shuffled.tensor<T, 5>().template chip<0>(i);\n      auto output_slice = output_shuffled.tensor<T, 5>().template chip<0>(i);\n\n      if (padding == EXPLICIT) {\n        functor::SpatialConvolution<CPUDevice, T>()(\n            ctx->eigen_device<CPUDevice>(), output_slice, input_slice,\n            filter_slice, row_stride, col_stride, row_dilation, col_dilation,\n            static_cast<int>(explicit_paddings[2]),\n            static_cast<int>(explicit_paddings[3]),\n            static_cast<int>(explicit_paddings[4]),\n            static_cast<int>(explicit_paddings[5]));\n      } else {\n        functor::SpatialConvolution<CPUDevice, T>()(\n            ctx->eigen_device<CPUDevice>(), output_slice, input_slice,\n            filter_slice, row_stride, col_stride, row_dilation, col_dilation,\n            BrainPadding2EigenPadding(padding));\n      }\n    }\n\n    // Shuffle temporary output back into pre-shuffled shape.\n    std::array<int64_t, 5> rev_shuffle({1, 2, 3, 0, 4});\n    output->shaped<T, 5>(pre_shuffle(*output)).device(device) =\n        output_shuffled.tensor<T, 5>().shuffle(rev_shuffle);\n  }",
        "func_hash": 257618220779157714024325768166416151732,
        "file_name": "conv_ops.cc",
        "file_hash": 252300068611383622428481854806618645318,
        "cwe": [
            "CWE-354"
        ],
        "cve": "CVE-2021-41206",
        "cve_desc": "TensorFlow is an open source platform for machine learning. In affected versions several TensorFlow operations are missing validation for the shapes of the tensor arguments involved in the call. Depending on the API, this can result in undefined behavior and segfault or `CHECK`-fail related crashes but in some scenarios writes and reads from heap populated arrays are also possible. We have discovered these issues internally via tooling while working on improving/testing GPU op determinism. As such, we don't have reproducers and there will be multiple fixes for these issues. These fixes will be included in TensorFlow 2.7.0. We will also cherrypick these commits on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-41206",
        "func_name": "operator",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195040,
        "project": "tensorflow",
        "commit_id": "e21af685e1828f7ca65038307df5cc06de4479e8",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/e21af685e1828f7ca65038307df5cc06de4479e8",
        "commit_message": "Fix Null-pointer dereference in BuildXlaCompilationCache\n\nIf ConfigProto is not used, then use the default settings which is to allow all devices.\n\nPiperOrigin-RevId: 420391800\nChange-Id: I88161ad7042990aef678e77b597a2fb2c8f815be",
        "target": 1,
        "irrelevant": 1,
        "func_before": "Status BuildXlaCompilationCache(DeviceBase* device, FunctionLibraryRuntime* flr,\n                                const XlaPlatformInfo& platform_info,\n                                XlaCompilationCache** cache) {\n  if (platform_info.xla_device_metadata()) {\n    *cache = new XlaCompilationCache(\n        platform_info.xla_device_metadata()->client(),\n        platform_info.xla_device_metadata()->jit_device_type());\n    return Status::OK();\n  }\n\n  auto platform =\n      se::MultiPlatformManager::PlatformWithId(platform_info.platform_id());\n  if (!platform.ok()) {\n    return platform.status();\n  }\n\n  StatusOr<xla::Compiler*> compiler_for_platform =\n      xla::Compiler::GetForPlatform(platform.ValueOrDie());\n  if (!compiler_for_platform.ok()) {\n    // In some rare cases (usually in unit tests with very small clusters) we\n    // may end up transforming an XLA cluster with at least one GPU operation\n    // (which would normally force the cluster to be compiled using XLA:GPU)\n    // into an XLA cluster with no GPU operations (i.e. containing only CPU\n    // operations).  Such a cluster can fail compilation (in way that\n    // MarkForCompilation could not have detected) if the CPU JIT is not linked\n    // in.\n    //\n    // So bail out of _XlaCompile in this case, and let the executor handle the\n    // situation for us.\n    const Status& status = compiler_for_platform.status();\n    if (status.code() == error::NOT_FOUND) {\n      return errors::Unimplemented(\"Could not find compiler for platform \",\n                                   platform.ValueOrDie()->Name(), \": \",\n                                   status.ToString());\n    }\n  }\n\n  xla::LocalClientOptions client_options;\n  client_options.set_platform(platform.ValueOrDie());\n  client_options.set_intra_op_parallelism_threads(\n      device->tensorflow_cpu_worker_threads()->num_threads);\n\n  string allowed_gpus =\n      flr->config_proto()->gpu_options().visible_device_list();\n  TF_ASSIGN_OR_RETURN(absl::optional<std::set<int>> gpu_ids,\n                      ParseVisibleDeviceList(allowed_gpus));\n  client_options.set_allowed_devices(gpu_ids);\n\n  auto client = xla::ClientLibrary::GetOrCreateLocalClient(client_options);\n  if (!client.ok()) {\n    return client.status();\n  }\n  const XlaOpRegistry::DeviceRegistration* registration;\n  if (!XlaOpRegistry::GetCompilationDevice(platform_info.device_type().type(),\n                                           &registration)) {\n    return errors::InvalidArgument(\"No JIT device registered for \",\n                                   platform_info.device_type().type());\n  }\n  *cache = new XlaCompilationCache(\n      client.ValueOrDie(), DeviceType(registration->compilation_device_name));\n  return Status::OK();\n}",
        "func_hash": 179065639871904945359341382009364285020,
        "file_name": "xla_platform_info.cc",
        "file_hash": 171804916137745205288117058026592469555,
        "cwe": [
            "CWE-476"
        ],
        "cve": "CVE-2022-23595",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. When building an XLA compilation cache, if default settings are used, TensorFlow triggers a null pointer dereference. In the default scenario, all devices are allowed, so `flr->config_proto` is `nullptr`. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23595",
        "func_name": "BuildXlaCompilationCache",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195055,
        "project": "tensorflow",
        "commit_id": "2b7100d6cdff36aa21010a82269bc05a6d1cc74a",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/2b7100d6cdff36aa21010a82269bc05a6d1cc74a",
        "commit_message": "Cleanup and remove duplicate validation in `SparseCount`.\n\nWe have valdiation that is duplicated, checking different conditions, in different formats and failing to capture all cases. This should fix all the previous bugs.\n\nPiperOrigin-RevId: 414886981\nChange-Id: Ibf0bba0beb057b76d505324bb9487565daf95f01",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext* context) override {\n    const Tensor& indices = context->input(0);\n    const Tensor& values = context->input(1);\n    const Tensor& shape = context->input(2);\n    const Tensor& weights = context->input(3);\n    bool use_weights = weights.NumElements() > 0;\n\n    OP_REQUIRES(context, TensorShapeUtils::IsMatrix(indices.shape()),\n                errors::InvalidArgument(\n                    \"Input indices must be a 2-dimensional tensor. Got: \",\n                    indices.shape().DebugString()));\n\n    if (use_weights) {\n      OP_REQUIRES(\n          context, weights.shape() == values.shape(),\n          errors::InvalidArgument(\n              \"Weights and values must have the same shape. Weight shape: \",\n              weights.shape().DebugString(),\n              \"; values shape: \", values.shape().DebugString()));\n    }\n\n    OP_REQUIRES(context, shape.NumElements() != 0,\n                errors::InvalidArgument(\n                    \"The shape argument requires at least one element.\"));\n\n    bool is_1d = shape.NumElements() == 1;\n    auto shape_vector = shape.flat<int64_t>();\n    int num_batches = is_1d ? 1 : shape_vector(0);\n    int num_values = values.NumElements();\n\n    for (int b = 0; b < shape_vector.size(); b++) {\n      OP_REQUIRES(context, shape_vector(b) >= 0,\n                  errors::InvalidArgument(\n                      \"Elements in dense_shape must be >= 0. Instead got:\",\n                      shape.DebugString()));\n    }\n\n    OP_REQUIRES(context, num_values == indices.shape().dim_size(0),\n                errors::InvalidArgument(\n                    \"Number of values must match first dimension of indices.\",\n                    \"Got \", num_values,\n                    \" values, indices shape: \", indices.shape().DebugString()));\n\n    const auto indices_values = indices.matrix<int64_t>();\n    const auto values_values = values.flat<T>();\n    const auto weight_values = weights.flat<W>();\n\n    auto per_batch_counts = BatchedMap<W>(num_batches);\n\n    T max_value = 0;\n\n    OP_REQUIRES(context, num_values <= indices.shape().dim_size(0),\n                errors::InvalidArgument(\n                    \"The first dimension of indices must be equal to or \"\n                    \"greather than number of values. ( \",\n                    indices.shape().dim_size(0), \" vs. \", num_values, \" )\"));\n    OP_REQUIRES(context, indices.shape().dim_size(1) > 0,\n                errors::InvalidArgument(\"The second dimension of indices must \"\n                                        \"be greater than 0. Received: \",\n                                        indices.shape().dim_size(1)));\n\n    for (int idx = 0; idx < num_values; ++idx) {\n      int batch = is_1d ? 0 : indices_values(idx, 0);\n      if (batch >= num_batches) {\n        OP_REQUIRES(context, batch < num_batches,\n                    errors::InvalidArgument(\n                        \"Indices value along the first dimension must be \",\n                        \"lower than the first index of the shape.\", \"Got \",\n                        batch, \" as batch and \", num_batches,\n                        \" as the first dimension of the shape.\"));\n      }\n      const auto& value = values_values(idx);\n      if (value >= 0 && (maxlength_ <= 0 || value < maxlength_)) {\n        if (binary_output_) {\n          per_batch_counts[batch][value] = 1;\n        } else if (use_weights) {\n          per_batch_counts[batch][value] += weight_values(idx);\n        } else {\n          per_batch_counts[batch][value]++;\n        }\n        if (value > max_value) {\n          max_value = value;\n        }\n      }\n    }\n\n    int num_output_values = GetOutputSize(max_value, maxlength_, minlength_);\n    OP_REQUIRES_OK(context, OutputSparse<W>(per_batch_counts, num_output_values,\n                                            is_1d, context));\n  }",
        "func_hash": 115744370413617881150207979427400512016,
        "file_name": "count_ops.cc",
        "file_hash": 290832582717285970119064032382621433475,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2022-21740",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The implementation of `SparseCountSparseOutput` is vulnerable to a heap overflow. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-21740",
        "func_name": "Compute",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195056,
        "project": "tensorflow",
        "commit_id": "8c6f391a2282684a25cbfec7687bd5d35261a209",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/8c6f391a2282684a25cbfec7687bd5d35261a209",
        "commit_message": "[lite] Add check for bias_size is zero to avoid division by zero. This shouldn't happen for properly converted models. Just safety check\n\nPiperOrigin-RevId: 416383645\nChange-Id: If8e508bf696ae8ecfb927e69c139a8ccf7fe60cb",
        "target": 1,
        "irrelevant": 0,
        "func_before": "inline void BiasAndClamp(float clamp_min, float clamp_max, int bias_size,\n                         const float* bias_data, int array_size,\n                         float* array_data) {\n  // Note: see b/132215220: in May 2019 we thought it would be OK to replace\n  // this with the Eigen one-liner:\n  //   return (array.colwise() + bias).cwiseMin(clamp_max).cwiseMin(clamp_max).\n  // This turned out to severely regress performance: +4ms (i.e. 8%) on\n  // MobileNet v2 / 1.0 / 224. So we keep custom NEON code for now.\n  TFLITE_DCHECK_EQ((array_size % bias_size), 0);\n#ifdef USE_NEON\n  float* array_ptr = array_data;\n  float* array_end_ptr = array_ptr + array_size;\n  const auto clamp_min_vec = vdupq_n_f32(clamp_min);\n  const auto clamp_max_vec = vdupq_n_f32(clamp_max);\n  for (; array_ptr != array_end_ptr; array_ptr += bias_size) {\n    int i = 0;\n    for (; i <= bias_size - 16; i += 16) {\n      auto b0 = vld1q_f32(bias_data + i);\n      auto b1 = vld1q_f32(bias_data + i + 4);\n      auto b2 = vld1q_f32(bias_data + i + 8);\n      auto b3 = vld1q_f32(bias_data + i + 12);\n      auto a0 = vld1q_f32(array_ptr + i);\n      auto a1 = vld1q_f32(array_ptr + i + 4);\n      auto a2 = vld1q_f32(array_ptr + i + 8);\n      auto a3 = vld1q_f32(array_ptr + i + 12);\n      auto x0 = vaddq_f32(a0, b0);\n      auto x1 = vaddq_f32(a1, b1);\n      auto x2 = vaddq_f32(a2, b2);\n      auto x3 = vaddq_f32(a3, b3);\n      x0 = vmaxq_f32(clamp_min_vec, x0);\n      x1 = vmaxq_f32(clamp_min_vec, x1);\n      x2 = vmaxq_f32(clamp_min_vec, x2);\n      x3 = vmaxq_f32(clamp_min_vec, x3);\n      x0 = vminq_f32(clamp_max_vec, x0);\n      x1 = vminq_f32(clamp_max_vec, x1);\n      x2 = vminq_f32(clamp_max_vec, x2);\n      x3 = vminq_f32(clamp_max_vec, x3);\n      vst1q_f32(array_ptr + i, x0);\n      vst1q_f32(array_ptr + i + 4, x1);\n      vst1q_f32(array_ptr + i + 8, x2);\n      vst1q_f32(array_ptr + i + 12, x3);\n    }\n    for (; i <= bias_size - 4; i += 4) {\n      auto b = vld1q_f32(bias_data + i);\n      auto a = vld1q_f32(array_ptr + i);\n      auto x = vaddq_f32(a, b);\n      x = vmaxq_f32(clamp_min_vec, x);\n      x = vminq_f32(clamp_max_vec, x);\n      vst1q_f32(array_ptr + i, x);\n    }\n    for (; i < bias_size; i++) {\n      array_ptr[i] = ActivationFunctionWithMinMax(array_ptr[i] + bias_data[i],\n                                                  clamp_min, clamp_max);\n    }\n  }\n#else  // not NEON\n  for (int array_offset = 0; array_offset < array_size;\n       array_offset += bias_size) {\n    for (int i = 0; i < bias_size; i++) {\n      array_data[array_offset + i] = ActivationFunctionWithMinMax(\n          array_data[array_offset + i] + bias_data[i], clamp_min, clamp_max);\n    }\n  }\n#endif\n}",
        "func_hash": 154263320578941255259441922880599149557,
        "file_name": "common.h",
        "file_hash": 11373796702176609664888229687660280569,
        "cwe": [
            "CWE-369"
        ],
        "cve": "CVE-2022-23557",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. An attacker can craft a TFLite model that would trigger a division by zero in `BiasAndClamp` implementation. There is no check that the `bias_size` is non zero. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23557",
        "func_name": "BiasAndClamp",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195059,
        "project": "tensorflow",
        "commit_id": "92dba16749fae36c246bec3f9ba474d9ddeb7662",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/92dba16749fae36c246bec3f9ba474d9ddeb7662",
        "commit_message": "Prevent a null-pointer dereference / `CHECK`-fail in grappler.\n\nPiperOrigin-RevId: 409187354\nChange-Id: I369c249cca32e6c56ec193f0ebbf2f2768fc7d43",
        "target": 1,
        "irrelevant": 0,
        "func_before": "bool DependencyOptimizer::SafeToRemoveIdentity(const NodeDef& node) const {\n  if (!IsIdentity(node) && !IsIdentityN(node)) {\n    return true;\n  }\n\n  if (nodes_to_preserve_.find(node.name()) != nodes_to_preserve_.end()) {\n    return false;\n  }\n  if (!fetch_nodes_known_) {\n    // The output values of this node may be needed.\n    return false;\n  }\n\n  if (node.input_size() < 1) {\n    // Node lacks input, is invalid\n    return false;\n  }\n\n  const NodeDef* input = node_map_->GetNode(NodeName(node.input(0)));\n  CHECK(input != nullptr) << \"node = \" << node.name()\n                          << \" input = \" << node.input(0);\n  // Don't remove Identity nodes corresponding to Variable reads or following\n  // Recv.\n  if (IsVariable(*input) || IsRecv(*input)) {\n    return false;\n  }\n  for (const auto& consumer : node_map_->GetOutputs(node.name())) {\n    if (node.input_size() > 1 && (IsRetval(*consumer) || IsMerge(*consumer))) {\n      return false;\n    }\n    if (IsSwitch(*input)) {\n      for (const string& consumer_input : consumer->input()) {\n        if (consumer_input == AsControlDependency(node.name())) {\n          return false;\n        }\n      }\n    }\n  }\n  return true;\n}",
        "func_hash": 61147310262209694276783937154772465535,
        "file_name": "dependency_optimizer.cc",
        "file_hash": 98916752340112642333125918775752240620,
        "cwe": [
            "CWE-617"
        ],
        "cve": "CVE-2022-23579",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The Grappler optimizer in TensorFlow can be used to cause a denial of service by altering a `SavedModel` such that `SafeToRemoveIdentity` would trigger `CHECK` failures. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23579",
        "func_name": "DependencyOptimizer::SafeToRemoveIdentity",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195063,
        "project": "gpac",
        "commit_id": "5f2c2a16d30229b6241f02fa28e3d6b810d64858",
        "project_url": "https://github.com/gpac/gpac",
        "commit_url": "https://github.com/gpac/gpac/commit/5f2c2a16d30229b6241f02fa28e3d6b810d64858",
        "commit_message": "fixed #1905",
        "target": 1,
        "irrelevant": 0,
        "func_before": "GF_Err mpgviddmx_process(GF_Filter *filter)\n{\n\tGF_MPGVidDmxCtx *ctx = gf_filter_get_udta(filter);\n\tGF_FilterPacket *pck, *dst_pck;\n\tu64 byte_offset;\n\ts64 vosh_start = -1;\n\ts64 vosh_end = -1;\n\tGF_Err e;\n\tchar *data;\n\tu8 *start;\n\tu32 pck_size;\n\ts32 remain;\n\n\t//always reparse duration\n\tif (!ctx->duration.num)\n\t\tmpgviddmx_check_dur(filter, ctx);\n\n\tpck = gf_filter_pid_get_packet(ctx->ipid);\n\tif (!pck) {\n\t\tif (gf_filter_pid_is_eos(ctx->ipid)) {\n\t\t\tmpgviddmx_enqueue_or_dispatch(ctx, NULL, GF_TRUE, GF_TRUE);\n\t\t\tif (ctx->opid)\n\t\t\t\tgf_filter_pid_set_eos(ctx->opid);\n\t\t\tif (ctx->src_pck) gf_filter_pck_unref(ctx->src_pck);\n\t\t\tctx->src_pck = NULL;\n\t\t\treturn GF_EOS;\n\t\t}\n\t\treturn GF_OK;\n\t}\n\n\tdata = (char *) gf_filter_pck_get_data(pck, &pck_size);\n\tbyte_offset = gf_filter_pck_get_byte_offset(pck);\n\n\tstart = data;\n\tremain = pck_size;\n\n\t//input pid sets some timescale - we flushed pending data , update cts\n\tif (!ctx->resume_from && ctx->timescale) {\n\t\tu64 ts = gf_filter_pck_get_cts(pck);\n\t\tif (ts != GF_FILTER_NO_TS) {\n\t\t\tif (!ctx->cts || !ctx->recompute_cts)\n\t\t\t\tctx->cts = ts;\n\t\t}\n\t\tts = gf_filter_pck_get_dts(pck);\n\t\tif (ts != GF_FILTER_NO_TS) {\n\t\t\tif (!ctx->dts || !ctx->recompute_cts)\n\t\t\t\tctx->dts = ts;\n\n\t\t\tif (!ctx->prev_dts) ctx->prev_dts = ts;\n\t\t\telse if (ctx->prev_dts != ts) {\n\t\t\t\tu64 diff = ts;\n\t\t\t\tdiff -= ctx->prev_dts;\n\t\t\t\tif (!ctx->cur_fps.den) ctx->cur_fps.den = (u32) diff;\n\t\t\t\telse if (ctx->cur_fps.den > diff)\n\t\t\t\t\tctx->cur_fps.den = (u32) diff;\n\t\t\t}\n\t\t}\n\t\tgf_filter_pck_get_framing(pck, &ctx->input_is_au_start, &ctx->input_is_au_end);\n\t\t//this will force CTS recomput of each frame\n\t\tif (ctx->recompute_cts) ctx->input_is_au_start = GF_FALSE;\n\t\tif (ctx->src_pck) gf_filter_pck_unref(ctx->src_pck);\n\t\tctx->src_pck = pck;\n\t\tgf_filter_pck_ref_props(&ctx->src_pck);\n\t}\n\n\t//we stored some data to find the complete vosh, aggregate this packet with current one\n\tif (!ctx->resume_from && ctx->hdr_store_size) {\n\t\tif (ctx->hdr_store_alloc < ctx->hdr_store_size + pck_size) {\n\t\t\tctx->hdr_store_alloc = ctx->hdr_store_size + pck_size;\n\t\t\tctx->hdr_store = gf_realloc(ctx->hdr_store, sizeof(char)*ctx->hdr_store_alloc);\n\t\t}\n\t\tmemcpy(ctx->hdr_store + ctx->hdr_store_size, data, sizeof(char)*pck_size);\n\t\tif (byte_offset != GF_FILTER_NO_BO) {\n\t\t\tif (byte_offset >= ctx->hdr_store_size)\n\t\t\t\tbyte_offset -= ctx->hdr_store_size;\n\t\t\telse\n\t\t\t\tbyte_offset = GF_FILTER_NO_BO;\n\t\t}\n\t\tctx->hdr_store_size += pck_size;\n\t\tstart = data = ctx->hdr_store;\n\t\tremain = pck_size = ctx->hdr_store_size;\n\t}\n\n\tif (ctx->resume_from) {\n\t\tif (gf_filter_pid_would_block(ctx->opid))\n\t\t\treturn GF_OK;\n\n\t\t//resume from data copied internally\n\t\tif (ctx->hdr_store_size) {\n\t\t\tassert(ctx->resume_from <= ctx->hdr_store_size);\n\t\t\tstart = data = ctx->hdr_store + ctx->resume_from;\n\t\t\tremain = pck_size = ctx->hdr_store_size - ctx->resume_from;\n\t\t} else {\n\t\t\tassert(remain >= (s32) ctx->resume_from);\n\t\t\tstart += ctx->resume_from;\n\t\t\tremain -= ctx->resume_from;\n\t\t}\n\t\tctx->resume_from = 0;\n\t}\n\n\tif (!ctx->bs) {\n\t\tctx->bs = gf_bs_new(start, remain, GF_BITSTREAM_READ);\n\t} else {\n\t\tgf_bs_reassign_buffer(ctx->bs, start, remain);\n\t}\n\tif (!ctx->vparser) {\n\t\tctx->vparser = gf_m4v_parser_bs_new(ctx->bs, ctx->is_mpg12);\n\t}\n\n\n\twhile (remain) {\n\t\tBool full_frame;\n\t\tu8 *pck_data;\n\t\ts32 current;\n\t\tu8 sc_type, forced_sc_type=0;\n\t\tBool sc_type_forced = GF_FALSE;\n\t\tBool skip_pck = GF_FALSE;\n\t\tu8 ftype;\n\t\tu32 tinc;\n\t\tu64 size=0;\n\t\tu64 fstart;\n\t\tBool is_coded;\n\t\tu32 bytes_from_store = 0;\n\t\tu32 hdr_offset = 0;\n\t\tBool copy_last_bytes = GF_FALSE;\n\n\t\t//not enough bytes to parse start code\n\t\tif (remain<5) {\n\t\t\tmemcpy(ctx->hdr_store, start, remain);\n\t\t\tctx->bytes_in_header = remain;\n\t\t\tbreak;\n\t\t}\n\t\tcurrent = -1;\n\n\t\t//we have some potential bytes of a start code in the store, copy some more bytes and check if valid start code.\n\t\t//if not, dispatch these bytes as continuation of the data\n\t\tif (ctx->bytes_in_header) {\n\n\t\t\tmemcpy(ctx->hdr_store + ctx->bytes_in_header, start, 8 - ctx->bytes_in_header);\n\t\t\tcurrent = mpgviddmx_next_start_code(ctx->hdr_store, 8);\n\n\t\t\t//no start code in stored buffer\n\t\t\tif ((current<0) || (current >= (s32) ctx->bytes_in_header) )  {\n\t\t\t\tif (ctx->opid) {\n\t\t\t\t\tdst_pck = gf_filter_pck_new_alloc(ctx->opid, ctx->bytes_in_header, &pck_data);\n\t\t\t\t\tif (!dst_pck) return GF_OUT_OF_MEM;\n\n\t\t\t\t\tif (ctx->src_pck) gf_filter_pck_merge_properties(ctx->src_pck, dst_pck);\n\t\t\t\t\tgf_filter_pck_set_cts(dst_pck, GF_FILTER_NO_TS);\n\t\t\t\t\tgf_filter_pck_set_dts(dst_pck, GF_FILTER_NO_TS);\n\t\t\t\t\tmemcpy(pck_data, ctx->hdr_store, ctx->bytes_in_header);\n\t\t\t\t\tgf_filter_pck_set_framing(dst_pck, GF_FALSE, GF_FALSE);\n\n\t\t\t\t\tif (byte_offset != GF_FILTER_NO_BO) {\n\t\t\t\t\t\tgf_filter_pck_set_byte_offset(dst_pck, byte_offset - ctx->bytes_in_header);\n\t\t\t\t\t}\n\n\t\t\t\t\tmpgviddmx_enqueue_or_dispatch(ctx, dst_pck, GF_FALSE, GF_FALSE);\n\t\t\t\t}\n\n\t\t\t\tif (current<0) current = -1;\n\t\t\t\telse current -= ctx->bytes_in_header;\n\t\t\t\tctx->bytes_in_header = 0;\n\t\t\t} else {\n\t\t\t\t//we have a valid start code, check which byte in our store or in the packet payload is the start code type\n\t\t\t\t//and remember its location to reinit the parser from there\n\t\t\t\thdr_offset = 4 - ctx->bytes_in_header + current;\n\t\t\t\t//bytes still to dispatch\n\t\t\t\tbytes_from_store = ctx->bytes_in_header;\n\t\t\t\tctx->bytes_in_header = 0;\n\t\t\t\tif (!hdr_offset) {\n\t\t\t\t\tforced_sc_type = ctx->hdr_store[current+3];\n\t\t\t\t} else {\n\t\t\t\t\tforced_sc_type = start[hdr_offset-1];\n\t\t\t\t}\n\t\t\t\tsc_type_forced = GF_TRUE;\n\t\t\t}\n\t\t}\n\t\t//no starcode in store, look for startcode in packet\n\t\tif (current == -1) {\n\t\t\t//locate next start code\n\t\t\tcurrent = mpgviddmx_next_start_code(start, remain);\n\t\t\t//no start code, dispatch the block\n\t\t\tif (current<0) {\n\t\t\t\tu8 b3, b2, b1;\n\t\t\t\tif (! ctx->frame_started) {\n\t\t\t\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_MEDIA, (\"[MPGVid] no start code in block and no frame started, discarding data\\n\" ));\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tsize = remain;\n\t\t\t\tb3 = start[remain-3];\n\t\t\t\tb2 = start[remain-2];\n\t\t\t\tb1 = start[remain-1];\n\t\t\t\t//we may have a startcode at the end of the packet, store it and don't dispatch the last 3 bytes !\n\t\t\t\tif (!b1 || !b2 || !b3) {\n\t\t\t\t\tcopy_last_bytes = GF_TRUE;\n\t\t\t\t\tassert(size >= 3);\n\t\t\t\t\tsize -= 3;\n\t\t\t\t\tctx->bytes_in_header = 3;\n\t\t\t\t}\n\n\t\t\t\tdst_pck = gf_filter_pck_new_alloc(ctx->opid, (u32) size, &pck_data);\n\t\t\t\tif (!dst_pck) return GF_OUT_OF_MEM;\n\n\t\t\t\tif (ctx->src_pck) gf_filter_pck_merge_properties(ctx->src_pck, dst_pck);\n\t\t\t\tmemcpy(pck_data, start, (size_t) size);\n\t\t\t\tgf_filter_pck_set_framing(dst_pck, GF_FALSE, GF_FALSE);\n\t\t\t\tgf_filter_pck_set_cts(dst_pck, GF_FILTER_NO_TS);\n\t\t\t\tgf_filter_pck_set_dts(dst_pck, GF_FILTER_NO_TS);\n\n\t\t\t\tif (byte_offset != GF_FILTER_NO_BO) {\n\t\t\t\t\tgf_filter_pck_set_byte_offset(dst_pck, byte_offset);\n\t\t\t\t}\n\n\t\t\t\tmpgviddmx_enqueue_or_dispatch(ctx, dst_pck, GF_FALSE, GF_FALSE);\n\t\t\t\tif (copy_last_bytes) {\n\t\t\t\t\tmemcpy(ctx->hdr_store, start+remain-3, 3);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tassert(current>=0);\n\n\t\t//if we are in the middle of parsing the vosh, skip over bytes remaining from previous obj not parsed\n\t\tif ((vosh_start>=0) && current) {\n\t\t\tassert(remain>=current);\n\t\t\tstart += current;\n\t\t\tremain -= current;\n\t\t\tcurrent = 0;\n\t\t}\n\t\t//also skip if no output pid\n\t\tif (!ctx->opid && current) {\n\t\t\tassert(remain>=current);\n\t\t\tstart += current;\n\t\t\tremain -= current;\n\t\t\tcurrent = 0;\n\t\t}\n\t\t//dispatch remaining bytes\n\t\tif (current>0) {\n\t\t\t//flush remaining\n\t\t\tdst_pck = gf_filter_pck_new_alloc(ctx->opid, current, &pck_data);\n\t\t\tif (!dst_pck) return GF_OUT_OF_MEM;\n\n\t\t\tif (ctx->src_pck) gf_filter_pck_merge_properties(ctx->src_pck, dst_pck);\n\t\t\tgf_filter_pck_set_cts(dst_pck, GF_FILTER_NO_TS);\n\t\t\tgf_filter_pck_set_dts(dst_pck, GF_FILTER_NO_TS);\n\t\t\tgf_filter_pck_set_framing(dst_pck, GF_FALSE, GF_TRUE);\n\t\t\t//bytes were partly in store, partly in packet\n\t\t\tif (bytes_from_store) {\n\t\t\t\tif (byte_offset != GF_FILTER_NO_BO) {\n\t\t\t\t\tgf_filter_pck_set_byte_offset(dst_pck, byte_offset - bytes_from_store);\n\t\t\t\t}\n\t\t\t\tassert(bytes_from_store>=(u32) current);\n\t\t\t\tbytes_from_store -= current;\n\t\t\t\tmemcpy(pck_data, ctx->hdr_store, current);\n\t\t\t} else {\n\t\t\t\t//bytes were only in packet\n\t\t\t\tif (byte_offset != GF_FILTER_NO_BO) {\n\t\t\t\t\tgf_filter_pck_set_byte_offset(dst_pck, byte_offset);\n\t\t\t\t}\n\t\t\t\tmemcpy(pck_data, start, current);\n\t\t\t\tassert(remain>=current);\n\t\t\t\tstart += current;\n\t\t\t\tremain -= current;\n\t\t\t\tcurrent = 0;\n\t\t\t}\n\t\t\tgf_filter_pck_set_carousel_version(dst_pck, 1);\n\n\t\t\tmpgviddmx_enqueue_or_dispatch(ctx, dst_pck, GF_FALSE, GF_FALSE);\n\t\t}\n\n\t\t//parse headers\n\n\t\t//we have a start code loaded, eg the data packet does not have a full start code at the beginning\n\t\tif (sc_type_forced) {\n\t\t\tgf_bs_reassign_buffer(ctx->bs, start + hdr_offset, remain - hdr_offset);\n\t\t\tsc_type = forced_sc_type;\n\t\t} else {\n\t\t\tgf_bs_reassign_buffer(ctx->bs, start, remain);\n\t\t\tgf_bs_read_int(ctx->bs, 24);\n\t\t\tsc_type = gf_bs_read_int(ctx->bs, 8);\n\t\t}\n\n\t\tif (ctx->is_mpg12) {\n\t\t\tswitch (sc_type) {\n\t\t\tcase M2V_SEQ_START_CODE:\n\t\t\tcase M2V_EXT_START_CODE:\n\t\t\t\tgf_bs_reassign_buffer(ctx->bs, start, remain);\n\t\t\t\te = gf_m4v_parse_config(ctx->vparser, &ctx->dsi);\n\t\t\t\t//not enough data, accumulate until we can parse the full header\n\t\t\t\tif (e==GF_EOS) {\n\t\t\t\t\tif (vosh_start<0) vosh_start = 0;\n\t\t\t\t\tif (data == ctx->hdr_store) {\n\t\t\t\t\t\tmemmove(ctx->hdr_store, start, remain);\n\t\t\t\t\t\tctx->hdr_store_size = remain;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tif (ctx->hdr_store_alloc < ctx->hdr_store_size + pck_size - vosh_start) {\n\t\t\t\t\t\t\tctx->hdr_store_alloc = (u32) (ctx->hdr_store_size + pck_size - vosh_start);\n\t\t\t\t\t\t\tctx->hdr_store = gf_realloc(ctx->hdr_store, sizeof(char)*ctx->hdr_store_alloc);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tmemcpy(ctx->hdr_store + ctx->hdr_store_size, data + vosh_start, (size_t) (pck_size - vosh_start) );\n\t\t\t\t\t\tctx->hdr_store_size += pck_size - (u32) vosh_start;\n\t\t\t\t\t}\n\t\t\t\t\tgf_filter_pid_drop_packet(ctx->ipid);\n\t\t\t\t\treturn GF_OK;\n\t\t\t\t} else if (e != GF_OK) {\n\t\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_MEDIA, (\"[MPGVid] Failed to parse VOS header: %s\\n\", gf_error_to_string(e) ));\n\t\t\t\t} else {\n\t\t\t\t\tmpgviddmx_check_pid(filter, ctx, 0, NULL);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase M2V_PIC_START_CODE:\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t} else {\n\t\t\tu8 PL;\n\t\t\tswitch (sc_type) {\n\t\t\tcase M4V_VOS_START_CODE:\n\t\t\t\tctx->dsi.VideoPL = (u8) gf_bs_read_u8(ctx->bs);\n\t\t\t\tvosh_start = start - (u8 *)data;\n\t\t\t\tskip_pck = GF_TRUE;\n\t\t\t\tassert(remain>=5);\n\t\t\t\tstart += 5;\n\t\t\t\tremain -= 5;\n\t\t\t\tbreak;\n\t\t\tcase M4V_VOL_START_CODE:\n\t\t\t\tgf_bs_reassign_buffer(ctx->bs, start, remain);\n\t\t\t\tPL = ctx->dsi.VideoPL;\n\t\t\t\te = gf_m4v_parse_config(ctx->vparser, &ctx->dsi);\n\t\t\t\tctx->dsi.VideoPL = PL;\n\t\t\t\t//not enough data, accumulate until we can parse the full header\n\t\t\t\tif (e==GF_EOS) {\n\t\t\t\t\tif (vosh_start<0) vosh_start = 0;\n\t\t\t\t\tif (data == ctx->hdr_store) {\n\t\t\t\t\t\tmemmove(ctx->hdr_store, start, remain);\n\t\t\t\t\t\tctx->hdr_store_size = remain;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tif (ctx->hdr_store_alloc < ctx->hdr_store_size + pck_size - vosh_start) {\n\t\t\t\t\t\t\tctx->hdr_store_alloc = (u32) (ctx->hdr_store_size + pck_size - (u32) vosh_start);\n\t\t\t\t\t\t\tctx->hdr_store = gf_realloc(ctx->hdr_store, sizeof(char)*ctx->hdr_store_alloc);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tmemcpy(ctx->hdr_store + ctx->hdr_store_size, data + vosh_start, (size_t) (pck_size - vosh_start) );\n\t\t\t\t\t\tctx->hdr_store_size += pck_size - (u32) vosh_start;\n\t\t\t\t\t}\n\t\t\t\t\tgf_filter_pid_drop_packet(ctx->ipid);\n\t\t\t\t\treturn GF_OK;\n\t\t\t\t} else if (e != GF_OK) {\n\t\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_MEDIA, (\"[MPGVid] Failed to parse VOS header: %s\\n\", gf_error_to_string(e) ));\n\t\t\t\t} else {\n\t\t\t\t\tu32 obj_size = (u32) gf_m4v_get_object_start(ctx->vparser);\n\t\t\t\t\tif (vosh_start<0) vosh_start = 0;\n\t\t\t\t\tvosh_end = start - (u8 *)data + obj_size;\n\t\t\t\t\tvosh_end -= vosh_start;\n\t\t\t\t\tmpgviddmx_check_pid(filter, ctx,(u32)  vosh_end, data+vosh_start);\n\t\t\t\t\tskip_pck = GF_TRUE;\n\t\t\t\t\tassert(remain>=(s32) obj_size);\n\t\t\t\t\tstart += obj_size;\n\t\t\t\t\tremain -= obj_size;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase M4V_VOP_START_CODE:\n\t\t\tcase M4V_GOV_START_CODE:\n\t\t\t\tbreak;\n\n\t\t\tcase M4V_VO_START_CODE:\n\t\t\tcase M4V_VISOBJ_START_CODE:\n\t\t\tdefault:\n\t\t\t\tif (vosh_start>=0) {\n\t\t\t\t\tskip_pck = GF_TRUE;\n\t\t\t\t\tassert(remain>=4);\n\t\t\t\t\tstart += 4;\n\t\t\t\t\tremain -= 4;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif (skip_pck) {\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (!ctx->opid) {\n\t\t\tassert(remain>=4);\n\t\t\tstart += 4;\n\t\t\tremain -= 4;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (!ctx->is_playing) {\n\t\t\tctx->resume_from = (u32) ((char *)start -  (char *)data);\n\t\t\treturn GF_OK;\n\t\t}\n\t\t//at this point, we no longer reaggregate packets\n\t\tctx->hdr_store_size = 0;\n\n\t\tif (ctx->in_seek) {\n\t\t\tu64 nb_frames_at_seek = (u64) (ctx->start_range * ctx->cur_fps.num);\n\t\t\tif (ctx->cts + ctx->cur_fps.den >= nb_frames_at_seek) {\n\t\t\t\t//u32 samples_to_discard = (ctx->cts + ctx->dts_inc) - nb_samples_at_seek;\n\t\t\t\tctx->in_seek = GF_FALSE;\n\t\t\t}\n\t\t}\n\t\t//may happen that after all our checks, only 4 bytes are left, continue to store these 4 bytes\n\t\tif (remain<5)\n\t\t\tcontinue;\n\n\t\t//good to go\n\t\tgf_m4v_parser_reset(ctx->vparser, sc_type_forced ? forced_sc_type + 1 : 0);\n\t\tsize = 0;\n\t\te = gf_m4v_parse_frame(ctx->vparser, &ctx->dsi, &ftype, &tinc, &size, &fstart, &is_coded);\n\t\t//true if we strip VO and VISOBJ assert(!fstart);\n\n\t\t//we skipped bytes already in store + end of start code present in packet, so the size of the first object\n\t\t//needs adjustement\n\t\tif (bytes_from_store) {\n\t\t\tsize += bytes_from_store + hdr_offset;\n\t\t}\n\n\t\tif ((e == GF_EOS) && !ctx->input_is_au_end) {\n\t\t\tu8 b3 = start[remain-3];\n\t\t\tu8 b2 = start[remain-2];\n\t\t\tu8 b1 = start[remain-1];\n\n\t\t\t//we may have a startcode at the end of the packet, store it and don't dispatch the last 3 bytes !\n\t\t\tif (!b1 || !b2 || !b3) {\n\t\t\t\tcopy_last_bytes = GF_TRUE;\n\t\t\t\tassert(size >= 3);\n\t\t\t\tsize -= 3;\n\t\t\t\tctx->bytes_in_header = 3;\n\t\t\t}\n\t\t\tfull_frame = GF_FALSE;\n\t\t} else {\n\t\t\tfull_frame = GF_TRUE;\n\t\t}\n\n\t\tif (!is_coded) {\n\t\t\t/*if prev is B and we're parsing a packed bitstream discard n-vop*/\n\t\t\tif (ctx->forced_packed && ctx->b_frames) {\n\t\t\t\tctx->is_packed = GF_TRUE;\n\t\t\t\tassert(remain>=size);\n\t\t\t\tstart += size;\n\t\t\t\tremain -= (s32) size;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\t/*policy is to import at variable frame rate, skip*/\n\t\t\tif (ctx->vfr) {\n\t\t\t\tctx->is_vfr = GF_TRUE;\n\t\t\t\tmpgviddmx_update_time(ctx);\n\t\t\t\tassert(remain>=size);\n\t\t\t\tstart += size;\n\t\t\t\tremain -= (s32) size;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\t/*policy is to keep non coded frame (constant frame rate), add*/\n\t\t}\n\n\t\tif (ftype==2) {\n\t\t\t//count number of B-frames since last ref\n\t\t\tctx->b_frames++;\n\t\t\tctx->nb_b++;\n\t\t} else {\n\t\t\t//flush all pending packets\n\t\t\tmpgviddmx_enqueue_or_dispatch(ctx, NULL, GF_TRUE, GF_FALSE);\n\t\t\t//remeber the CTS of the last ref\n\t\t\tctx->last_ref_cts = ctx->cts;\n\t\t\tif (ctx->max_b < ctx->b_frames) ctx->max_b = ctx->b_frames;\n\t\t\t\n\t\t\tctx->b_frames = 0;\n\t\t\tif (ftype)\n\t\t\t\tctx->nb_p++;\n\t\t\telse\n\t\t\t\tctx->nb_i++;\n\t\t}\n\t\tctx->nb_frames++;\n\n\t\tdst_pck = gf_filter_pck_new_alloc(ctx->opid, (u32) size, &pck_data);\n\t\tif (!dst_pck) return GF_OUT_OF_MEM;\n\n\t\tif (ctx->src_pck) gf_filter_pck_merge_properties(ctx->src_pck, dst_pck);\n\t\t//bytes come from both our store and the data packet\n\t\tif (bytes_from_store) {\n\t\t\tmemcpy(pck_data, ctx->hdr_store+current, bytes_from_store);\n\t\t\tassert(size >= bytes_from_store);\n\t\t\tsize -= bytes_from_store;\n\t\t\tif (byte_offset != GF_FILTER_NO_BO) {\n\t\t\t\tgf_filter_pck_set_byte_offset(dst_pck, byte_offset - bytes_from_store);\n\t\t\t}\n\t\t\tmemcpy(pck_data + bytes_from_store, start, (size_t) size);\n\t\t} else {\n\t\t\t//bytes only come the data packet\n\t\t\tmemcpy(pck_data, start, (size_t) size);\n\t\t\tif (byte_offset != GF_FILTER_NO_BO) {\n\t\t\t\tgf_filter_pck_set_byte_offset(dst_pck, byte_offset + start - (u8 *) data);\n\t\t\t}\n\t\t}\n\t\tassert(pck_data[0] == 0);\n\t\tassert(pck_data[1] == 0);\n\t\tassert(pck_data[2] == 0x01);\n\n\t\tgf_filter_pck_set_framing(dst_pck, GF_TRUE, (full_frame || ctx->input_is_au_end) ? GF_TRUE : GF_FALSE);\n\t\tgf_filter_pck_set_cts(dst_pck, ctx->cts);\n\t\tgf_filter_pck_set_dts(dst_pck, ctx->dts);\n\t\tif (ctx->input_is_au_start) {\n\t\t\tctx->input_is_au_start = GF_FALSE;\n\t\t} else {\n\t\t\t//we use the carousel flag temporarly to indicate the cts must be recomputed\n\t\t\tgf_filter_pck_set_carousel_version(dst_pck, 1);\n\t\t}\n\t\tgf_filter_pck_set_sap(dst_pck, ftype ? GF_FILTER_SAP_NONE : GF_FILTER_SAP_1);\n\t\tgf_filter_pck_set_duration(dst_pck, ctx->cur_fps.den);\n\t\tif (ctx->in_seek) gf_filter_pck_set_seek_flag(dst_pck, GF_TRUE);\n\t\tctx->frame_started = GF_TRUE;\n\n\t\tmpgviddmx_enqueue_or_dispatch(ctx, dst_pck, GF_FALSE, GF_FALSE);\n\n\t\tmpgviddmx_update_time(ctx);\n\n\t\tif (!full_frame) {\n\t\t\tif (copy_last_bytes) {\n\t\t\t\tmemcpy(ctx->hdr_store, start+remain-3, 3);\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\tassert(remain>=size);\n\t\tstart += size;\n\t\tremain -= (s32) size;\n\t}\n\tgf_filter_pid_drop_packet(ctx->ipid);\n\n\treturn GF_OK;\n}",
        "func_hash": 49630978088913986571244550780083545600,
        "file_name": "reframe_mpgvid.c",
        "file_hash": 148306570807841160156662867455353144265,
        "cwe": [
            "CWE-476"
        ],
        "cve": "CVE-2021-40575",
        "cve_desc": "The binary MP4Box in Gpac 1.0.1 has a null pointer dereference vulnerability in the mpgviddmx_process function in reframe_mpgvid.c, which allows attackers to cause a denial of service. This vulnerability is possibly due to an incomplete fix for CVE-2021-40566.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-40575",
        "func_name": "mpgviddmx_process",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 216728,
        "project": "graphviz",
        "commit_id": "839085f8026afd6f6920a0c31ad2a9d880d97932",
        "project_url": "https://gitlab.com/graphviz/graphviz",
        "commit_url": "https://gitlab.com/graphviz/graphviz/commit/839085f8026afd6f6920a0c31ad2a9d880d97932",
        "commit_message": "attempted fix for null pointer deference on malformed input",
        "target": 1,
        "irrelevant": 1,
        "func_before": "Agraph_t *agroot(void* obj)\n{\n    switch (AGTYPE(obj)) {\n    case AGINEDGE:\n    case AGOUTEDGE:\n\treturn ((Agedge_t *) obj)->node->root;\n    case AGNODE:\n\treturn ((Agnode_t *) obj)->root;\n    case AGRAPH:\n\treturn ((Agraph_t *) obj)->root;\n    default:\t\t\t/* actually can't occur if only 2 bit tags */\n\tagerr(AGERR, \"agroot of a bad object\");\n\treturn NILgraph;\n    }\n}",
        "func_hash": 275284791948548661260832026527731938206,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-476"
        ],
        "cve": "CVE-2019-11023",
        "cve_desc": "The agroot() function in cgraph\\obj.c in libcgraph.a in Graphviz 2.39.20160612.1140 has a NULL pointer dereference, as demonstrated by graphml2gv.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2019-11023",
        "func_name": "agroot",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 216799,
        "project": "core",
        "commit_id": "fb246611e62ad8c5a95b0ca180a63f17aa34b0d8",
        "project_url": "https://github.com/LibreOffice/core",
        "commit_url": "https://github.com/dovecot/core/commit/fb246611e62ad8c5a95b0ca180a63f17aa34b0d8",
        "commit_message": "lib-ntlm: Check buffer length on responses\n\nAdd missing check for buffer length.\n\nIf this is not checked, it is possible to send message which\ncauses read past buffer bug.\n\nBroken in c7480644202e5451fbed448508ea29a25cffc99c",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static bool ntlmssp_check_buffer(const struct ntlmssp_buffer *buffer,\n\t\t\t\t size_t data_size, const char **error)\n{\n\tuint32_t offset = read_le32(&buffer->offset);\n\tuint16_t length = read_le16(&buffer->length);\n\tuint16_t space = read_le16(&buffer->space);\n\n\t/* Empty buffer is ok */\n\tif (length == 0 && space == 0)\n\t\treturn TRUE;\n\n\tif (offset >= data_size) {\n\t\t*error = \"buffer offset out of bounds\";\n\t\treturn FALSE;\n\t}\n\n\tif (offset + space > data_size) {\n\t\t*error = \"buffer end out of bounds\";\n\t\treturn FALSE;\n\t}\n\n\treturn TRUE;\n}",
        "func_hash": 209828353012389088506060342960975963748,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-125"
        ],
        "cve": "CVE-2020-12673",
        "cve_desc": "In Dovecot before 2.3.11.3, sending a specially formatted NTLM request will crash the auth service because of an out-of-bounds read.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2020-12673",
        "func_name": "ntlmssp_check_buffer",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 216803,
        "project": "gnuplot",
        "commit_id": "052cbd17c3cbbc602ee080b2617d32a8417d7563",
        "project_url": "https://github.com/gnuplot/gnuplot",
        "commit_url": "https://github.com/gnuplot/gnuplot/commit/052cbd17c3cbbc602ee080b2617d32a8417d7563",
        "commit_message": "successive failures of \"set print <foo>\" could cause double-free\nBug #2312",
        "target": 1,
        "irrelevant": 1,
        "func_before": "print_set_output(char *name, TBOOLEAN datablock, TBOOLEAN append_p)\n{\n    if (print_out && print_out != stderr && print_out != stdout) {\n#ifdef PIPES\n\tif (print_out_name[0] == '|') {\n\t    if (0 > pclose(print_out))\n\t\tperror(print_out_name);\n\t} else\n#endif\n\t    if (0 > fclose(print_out))\n\t\tperror(print_out_name);\n    }\n\n    free(print_out_name);\n    print_out_name = NULL;\n    print_out_var = NULL;\n\n    if (! name) {\n\tprint_out = stderr;\n\treturn;\n    }\n\n    if (strcmp(name, \"-\") == 0) {\n\tprint_out = stdout;\n\treturn;\n    }\n\n#ifdef PIPES\n    if (name[0] == '|') {\n\trestrict_popen();\n\tprint_out = popen(name + 1, \"w\");\n\tif (!print_out)\n\t    perror(name);\n\telse\n\t    print_out_name = name;\n\treturn;\n    }\n#endif\n\n    if (!datablock) {\n\tprint_out = fopen(name, append_p ? \"a\" : \"w\");\n\tif (!print_out) {\n\t    perror(name);\n\t    return;\n\t}\n    } else {\n\tprint_out_var = add_udv_by_name(name);\n\tif (!append_p)\n\t    gpfree_datablock(&print_out_var->udv_value);\n\t/* If this is not an existing datablock to be appended */\n\t/* then make it a new empty datablock */\n\tif (print_out_var->udv_value.type != DATABLOCK) {\n\t    free_value(&print_out_var->udv_value);\n\t    print_out_var->udv_value.type = DATABLOCK;\n\t    print_out_var->udv_value.v.data_array = NULL;\n\t}\n    }\n\n    print_out_name = name;\n}",
        "func_hash": 328916832716321363528711493757918252280,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-415"
        ],
        "cve": "CVE-2020-25559",
        "cve_desc": "gnuplot 5.5 is affected by double free when executing print_set_output. This may result in context-dependent arbitrary code execution.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2020-25559",
        "func_name": "print_set_output",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 216804,
        "project": "gnuplot",
        "commit_id": "963c7df3e0c5266efff260d0dff757dfe03d3632",
        "project_url": "https://github.com/gnuplot/gnuplot",
        "commit_url": "https://github.com/gnuplot/gnuplot/commit/963c7df3e0c5266efff260d0dff757dfe03d3632",
        "commit_message": "Better error handling for faulty font syntax\n\nA missing close-quote in an enhanced text font specification could\ncause a segfault.\nBug #2303",
        "target": 1,
        "irrelevant": 0,
        "func_before": "enhanced_recursion(\n    const char *p,\n    TBOOLEAN brace,\n    char *fontname,\n    double fontsize,\n    double base,\n    TBOOLEAN widthflag,\n    TBOOLEAN showflag,\n    int overprint)\n{\n    TBOOLEAN wasitalic, wasbold;\n\n    /* Keep track of the style of the font passed in at this recursion level */\n    wasitalic = (strstr(fontname, \":Italic\") != NULL);\n    wasbold = (strstr(fontname, \":Bold\") != NULL);\n\n    FPRINTF((stderr, \"RECURSE WITH \\\"%s\\\", %d %s %.1f %.1f %d %d %d\",\n\t\tp, brace, fontname, fontsize, base, widthflag, showflag, overprint));\n\n    /* Start each recursion with a clean string */\n    (term->enhanced_flush)();\n\n    if (base + fontsize > enhanced_max_height) {\n\tenhanced_max_height = base + fontsize;\n\tENH_DEBUG((\"Setting max height to %.1f\\n\", enhanced_max_height));\n    }\n\n    if (base < enhanced_min_height) {\n\tenhanced_min_height = base;\n\tENH_DEBUG((\"Setting min height to %.1f\\n\", enhanced_min_height));\n    }\n\n    while (*p) {\n\tdouble shift;\n\n\t/*\n\t * EAM Jun 2009 - treating bytes one at a time does not work for multibyte\n\t * encodings, including utf-8. If we hit a byte with the high bit set, test\n\t * whether it starts a legal UTF-8 sequence and if so copy the whole thing.\n\t * Other multibyte encodings are still a problem.\n\t * Gnuplot's other defined encodings are all single-byte; for those we\n\t * really do want to treat one byte at a time.\n\t */\n\tif ((*p & 0x80) && (encoding == S_ENC_DEFAULT || encoding == S_ENC_UTF8)) {\n\t    unsigned long utf8char;\n\t    const char *nextchar = p;\n\n\t    (term->enhanced_open)(fontname, fontsize, base, widthflag, showflag, overprint);\n\t    if (utf8toulong(&utf8char, &nextchar)) {\t/* Legal UTF8 sequence */\n\t\twhile (p < nextchar)\n\t\t    (term->enhanced_writec)(*p++);\n\t\tp--;\n\t    } else {\t\t\t\t\t/* Some other multibyte encoding? */\n\t\t(term->enhanced_writec)(*p);\n\t    }\n/* shige : for Shift_JIS */\n\t} else if ((*p & 0x80) && (encoding == S_ENC_SJIS)) {\n\t    (term->enhanced_open)(fontname, fontsize, base, widthflag, showflag, overprint);\n\t    (term->enhanced_writec)(*(p++));\n\t    (term->enhanced_writec)(*p);\n\t} else\n\n\tswitch (*p) {\n\tcase '}'  :\n\t    /*{{{  deal with it*/\n\t    if (brace)\n\t\treturn (p);\n\n\t    int_warn(NO_CARET, \"enhanced text parser - spurious }\");\n\t    break;\n\t    /*}}}*/\n\n\tcase '_'  :\n\tcase '^'  :\n\t    /*{{{  deal with super/sub script*/\n\t    shift = (*p == '^') ? 0.5 : -0.3;\n\t    (term->enhanced_flush)();\n\t    p = enhanced_recursion(p + 1, FALSE, fontname, fontsize * 0.8,\n\t\t\t      base + shift * fontsize, widthflag,\n\t\t\t      showflag, overprint);\n\t    break;\n\t    /*}}}*/\n\tcase '{'  :\n\t    {\n\t\tTBOOLEAN isitalic = FALSE, isbold = FALSE, isnormal = FALSE;\n\t\tconst char *start_of_fontname = NULL;\n\t\tconst char *end_of_fontname = NULL;\n\t\tchar *localfontname = NULL;\n\t\tchar ch;\n\t\tdouble f = fontsize, ovp;\n\n\t\t/* Mar 2014 - this will hold \"fontfamily{:Italic}{:Bold}\" */\n\t\tchar *styledfontname = NULL;\n\n\t\t/*{{{  recurse (possibly with a new font) */\n\n\t\tENH_DEBUG((\"Dealing with {\\n\"));\n\n\t\t/* 30 Sep 2016:  Remove incorrect whitespace-eating loop going */\n\t\t/* waaay back to 31-May-2000 */        /* while (*++p == ' '); */\n\t\t++p;\n\t\t/* get vertical offset (if present) for overprinted text */\n\t\tif (overprint == 2) {\n\t\t    char *end;\n\t\t    ovp = strtod(p,&end);\n\t\t    p = end;\n\t\t    if (term->flags & TERM_IS_POSTSCRIPT)\n\t\t\tbase = ovp*f;\n\t\t    else\n\t\t\tbase += ovp*f;\n\t\t}\n\t\t--p;\n\n\t\tif (*++p == '/') {\n\t\t    /* then parse a fontname, optional fontsize */\n\t\t    while (*++p == ' ')\n\t\t\t;       /* do nothing */\n\t\t    if (*p=='-') {\n\t\t\twhile (*++p == ' ')\n\t\t\t    ;   /* do nothing */\n\t\t    }\n\t\t    start_of_fontname = p;\n\n\t\t    /* Allow font name to be in quotes.\n\t\t     * This makes it possible to handle font names containing spaces.\n\t\t     */\n\t\t    if (*p == '\\'' || *p == '\"') {\n\t\t\t++p;\n\t\t\twhile (*p != '\\0' && *p != '}' && *p != *start_of_fontname)\n\t\t\t    ++p;\n\t\t\tif (*p != *start_of_fontname) {\n\t\t\t    int_warn(NO_CARET, \"cannot interpret font name %s\", start_of_fontname);\n\t\t\t    p = start_of_fontname;\n\t\t\t}\n\t\t\tstart_of_fontname++;\n\t\t\tend_of_fontname = p++;\n\t\t\tch = *p;\n\t\t    } else {\n\n\t\t    /* Normal unquoted font name */\n\t\t\twhile ((ch = *p) > ' ' && ch != '=' && ch != '*' && ch != '}' && ch != ':')\n\t\t\t    ++p;\n\t\t\tend_of_fontname = p;\n\t\t    }\n\n\t\t    do {\n\t\t\tif (ch == '=') {\n\t\t\t    /* get optional font size */\n\t\t\t    char *end;\n\t\t\t    p++;\n\t\t\t    ENH_DEBUG((\"Calling strtod(\\\"%s\\\") ...\", p));\n\t\t\t    f = strtod(p, &end);\n\t\t\t    p = end;\n\t\t\t    ENH_DEBUG((\"Returned %.1f and \\\"%s\\\"\\n\", f, p));\n\n\t\t\t    if (f == 0)\n\t\t\t\tf = fontsize;\n\t\t\t    else\n\t\t\t\tf *= enhanced_fontscale;  /* remember the scaling */\n\n\t\t\t    ENH_DEBUG((\"Font size %.1f\\n\", f));\n\t\t\t} else if (ch == '*') {\n\t\t\t    /* get optional font size scale factor */\n\t\t\t    char *end;\n\t\t\t    p++;\n\t\t\t    ENH_DEBUG((\"Calling strtod(\\\"%s\\\") ...\", p));\n\t\t\t    f = strtod(p, &end);\n\t\t\t    p = end;\n\t\t\t    ENH_DEBUG((\"Returned %.1f and \\\"%s\\\"\\n\", f, p));\n\n\t\t\t    if (f)\n\t\t\t\tf *= fontsize;  /* apply the scale factor */\n\t\t\t    else\n\t\t\t\tf = fontsize;\n\n\t\t\t    ENH_DEBUG((\"Font size %.1f\\n\", f));\n\t\t\t} else if (ch == ':') {\n\t\t\t    /* get optional style markup attributes */\n\t\t\t    p++;\n\t\t\t    if (!strncmp(p,\"Bold\",4))\n\t\t\t\tisbold = TRUE;\n\t\t\t    if (!strncmp(p,\"Italic\",6))\n\t\t\t\tisitalic = TRUE;\n\t\t\t    if (!strncmp(p,\"Normal\",6))\n\t\t\t\tisnormal = TRUE;\n\t\t\t    while (isalpha((unsigned char)*p)) {p++;}\n\t\t\t}\n\t\t    } while (((ch = *p) == '=') || (ch == ':') || (ch == '*'));\n\n\t\t    if (ch == '}')\n\t\t\tint_warn(NO_CARET,\"bad syntax in enhanced text string\");\n\n\t\t    if (*p == ' ')\t/* Eat up a single space following a font spec */\n\t\t\t++p;\n\t\t    if (!start_of_fontname || (start_of_fontname == end_of_fontname)) {\n\t\t\t/* Use the font name passed in to us */\n\t\t\tlocalfontname = gp_strdup(fontname);\n\t\t    } else {\n\t\t\t/* We found a new font name {/Font ...} */\n\t\t\tint len = end_of_fontname - start_of_fontname;\n\t\t\tlocalfontname = gp_alloc(len+1,\"localfontname\");\n\t\t\tstrncpy(localfontname, start_of_fontname, len);\n\t\t\tlocalfontname[len] = '\\0';\n\t\t    }\n\t\t}\n\t\t/*}}}*/\n\n\t\t/* Collect cumulative style markup before passing it in the font name */\n\t\tisitalic = (wasitalic || isitalic) && !isnormal;\n\t\tisbold = (wasbold || isbold) && !isnormal;\n\n\t\tstyledfontname = stylefont(localfontname ? localfontname : fontname,\n\t\t\t\t\t    isbold, isitalic);\n\n\t\tp = enhanced_recursion(p, TRUE, styledfontname, f, base,\n\t\t\t\t  widthflag, showflag, overprint);\n\n\t\t(term->enhanced_flush)();\n\n\t\tfree(styledfontname);\n\t\tfree(localfontname);\n\n\t\tbreak;\n\t    } /* case '{' */\n\tcase '@' :\n\t    /*{{{  phantom box - prints next 'char', then restores currentpoint */\n\t    (term->enhanced_flush)();\n\t    (term->enhanced_open)(fontname, fontsize, base, widthflag, showflag, 3);\n\t    p = enhanced_recursion(++p, FALSE, fontname, fontsize, base,\n\t\t\t      widthflag, showflag, overprint);\n\t    (term->enhanced_open)(fontname, fontsize, base, widthflag, showflag, 4);\n\t    break;\n\t    /*}}}*/\n\n\tcase '&' :\n\t    /*{{{  character skip - skips space equal to length of character(s) */\n\t    (term->enhanced_flush)();\n\n\t    p = enhanced_recursion(++p, FALSE, fontname, fontsize, base,\n\t\t\t      widthflag, FALSE, overprint);\n\t    break;\n\t    /*}}}*/\n\n\tcase '~' :\n\t    /*{{{ overprinted text */\n\t    /* the second string is overwritten on the first, centered\n\t     * horizontally on the first and (optionally) vertically\n\t     * shifted by an amount specified (as a fraction of the\n\t     * current fontsize) at the beginning of the second string\n\n\t     * Note that in this implementation neither the under- nor\n\t     * overprinted string can contain syntax that would result\n\t     * in additional recursions -- no subscripts,\n\t     * superscripts, or anything else, with the exception of a\n\t     * font definition at the beginning of the text */\n\n\t    (term->enhanced_flush)();\n\t    p = enhanced_recursion(++p, FALSE, fontname, fontsize, base,\n\t\t\t      widthflag, showflag, 1);\n\t    (term->enhanced_flush)();\n\t    if (!*p)\n\t        break;\n\t    p = enhanced_recursion(++p, FALSE, fontname, fontsize, base,\n\t\t\t      FALSE, showflag, 2);\n\n\t    overprint = 0;   /* may not be necessary, but just in case . . . */\n\t    break;\n\t    /*}}}*/\n\n\tcase '('  :\n\tcase ')'  :\n\t    /*{{{  an escape and print it */\n\t    /* special cases */\n\t    (term->enhanced_open)(fontname, fontsize, base, widthflag, showflag, overprint);\n\t    if (term->flags & TERM_IS_POSTSCRIPT)\n\t\t(term->enhanced_writec)('\\\\');\n\t    (term->enhanced_writec)(*p);\n\t    break;\n\t    /*}}}*/\n\n\tcase '\\\\'  :\n\t    /*{{{  various types of escape sequences, some context-dependent */\n\t    (term->enhanced_open)(fontname, fontsize, base, widthflag, showflag, overprint);\n\n\t    /*     Unicode represented as \\U+hhhhh where hhhhh is hexadecimal code point.\n\t     *     For UTF-8 encoding we translate hhhhh to a UTF-8 byte sequence and\n\t     *     output the bytes one by one.\n\t     */\n\t    if (p[1] == 'U' && p[2] == '+') {\n\t\tif (encoding == S_ENC_UTF8) {\n\t\t    uint32_t codepoint;\n\t\t    unsigned char utf8char[8];\n\t\t    int i, length;\n\n\t\t    sscanf(&(p[3]), \"%5x\", &codepoint);\n\t\t    length = ucs4toutf8(codepoint, utf8char);\n\t\t    p += (codepoint > 0xFFFF) ? 7 : 6;\n\t\t    for (i=0; i<length; i++)\n\t\t\t(term->enhanced_writec)(utf8char[i]);\n\t\t    break;\n\t\t}\n\n\t    /*     FIXME: non-utf8 environments not yet supported.\n\t     *     Note that some terminals may have an alternative way to handle unicode\n\t     *     escape sequences that is not dependent on encoding.\n\t     *     E.g. svg and html output could convert to xml sequences &#xhhhh;\n\t     *     For these cases we must retain the leading backslash so that the\n\t     *     unicode escape sequence can be recognized by the terminal driver.\n\t     */\n\t\t(term->enhanced_writec)(p[0]);\n\t\tbreak;\n\t    }\n\n\t    /* Enhanced mode always uses \\xyz as an octal character representation\n\t     * but each terminal type must give us the actual output format wanted.\n\t     * pdf.trm wants the raw character code, which is why we use strtol();\n\t     * most other terminal types want some variant of \"\\\\%o\".\n\t     */\n\t    if (p[1] >= '0' && p[1] <= '7') {\n\t\tchar *e, escape[16], octal[4] = {'\\0','\\0','\\0','\\0'};\n\n\t\toctal[0] = *(++p);\n\t\tif (p[1] >= '0' && p[1] <= '7') {\n\t\t    octal[1] = *(++p);\n\t\t    if (p[1] >= '0' && p[1] <= '7')\n\t\t\toctal[2] = *(++p);\n\t\t}\n\t\tsprintf(escape, enhanced_escape_format, strtol(octal,NULL,8));\n\t\tfor (e=escape; *e; e++) {\n\t\t    (term->enhanced_writec)(*e);\n\t\t}\n\t\tbreak;\n\t    }\n\n\t    /* This was the original (prior to version 4) enhanced text code specific\n\t     * to the reserved characters of PostScript.\n\t     */\n\t    if (term->flags & TERM_IS_POSTSCRIPT) {\n\t\tif (p[1]=='\\\\' || p[1]=='(' || p[1]==')') {\n\t\t    (term->enhanced_writec)('\\\\');\n\t\t} else if (strchr(\"^_@&~{}\",p[1]) == NULL) {\n\t\t    (term->enhanced_writec)('\\\\');\n\t\t    (term->enhanced_writec)('\\\\');\n\t\t    break;\n\t\t}\n\t    }\n\n\t    /* Step past the backslash character in the input stream */\n\t    ++p;\n\n\t    /* HBB: Avoid broken output if there's a \\ exactly at the end of the line */\n\t    if (*p == '\\0') {\n\t\tint_warn(NO_CARET, \"enhanced text parser -- spurious backslash\");\n\t\tbreak;\n\t    }\n\n\t    /* SVG requires an escaped '&' to be passed as something else */\n\t    /* FIXME: terminal-dependent code does not belong here */\n\t    if (*p == '&' && encoding == S_ENC_DEFAULT && !strcmp(term->name, \"svg\")) {\n\t\t(term->enhanced_writec)('\\376');\n\t\tbreak;\n\t    }\n\n\t    /* print the character following the backslash */\n\t    (term->enhanced_writec)(*p);\n\t    break;\n\t    /*}}}*/\n\n\tdefault:\n\t    /*{{{  print it */\n\t    (term->enhanced_open)(fontname, fontsize, base, widthflag, showflag, overprint);\n\t    (term->enhanced_writec)(*p);\n\t    /*}}}*/\n\t} /* switch (*p) */\n\n\t/* like TeX, we only do one character in a recursion, unless it's\n\t * in braces\n\t */\n\n\tif (!brace) {\n\t    (term->enhanced_flush)();\n\t    return(p);  /* the ++p in the outer copy will increment us */\n\t}\n\n\tif (*p) /* only not true if { not terminated, I think */\n\t    ++p;\n    } /* while (*p) */\n\n    (term->enhanced_flush)();\n    return p;\n}",
        "func_hash": 220071254976249587289701639503776454504,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2020-25412",
        "cve_desc": "com_line() in command.c in gnuplot 5.4 leads to an out-of-bounds-write from strncpy() that may lead to arbitrary code execution.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2020-25412",
        "func_name": "enhanced_recursion",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 216904,
        "project": "server",
        "commit_id": "2e7891080667c59ac80f788eef4d59d447595772",
        "project_url": "https://github.com/MariaDB/server",
        "commit_url": "https://github.com/MariaDB/server/commit/2e7891080667c59ac80f788eef4d59d447595772",
        "commit_message": "MDEV-25635 Assertion failure when pushing from HAVING into WHERE of view\n\nThis bug could manifest itself after pushing a where condition over a\nmergeable derived table / view / CTE DT into a grouping view / derived\ntable / CTE V whose item list contained set functions with constant\narguments such as MIN(2), SUM(1) etc. In such cases the field references\nused in the condition pushed into the view V that correspond set functions\nare wrapped into Item_direct_view_ref wrappers. Due to a wrong implementation\nof the virtual method const_item() for the class Item_direct_view_ref the\nwrapped set functions with constant arguments could be erroneously taken\nfor constant items. This could lead to a wrong result set returned by the\nmain select query in 10.2. In 10.4 where a possibility of pushing condition\nfrom HAVING into WHERE had been added this could cause a crash.\n\nApproved by Sergey Petrunya <sergey.petrunya@mariadb.com>",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  bool const_item() const { return used_tables() == 0; }",
        "func_hash": 52700246065121489756672133081907986383,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-617"
        ],
        "cve": "CVE-2021-46666",
        "cve_desc": "MariaDB before 10.6.2 allows an application crash because of mishandling of a pushdown from a HAVING clause to a WHERE clause.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-46666",
        "func_name": "const_item",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 216967,
        "project": "server",
        "commit_id": "0beed9b5e933f0ff79b3bb346524f7a451d14e38",
        "project_url": "https://github.com/MariaDB/server",
        "commit_url": "https://github.com/MariaDB/server/commit/0beed9b5e933f0ff79b3bb346524f7a451d14e38",
        "commit_message": "MDEV-28097 use-after-free when WHERE has subquery with an outer reference in HAVING\n\nwhen resolving WHERE and ON clauses, do not look in\nSELECT list/aliases.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "int setup_conds(THD *thd, TABLE_LIST *tables, List<TABLE_LIST> &leaves,\n                COND **conds)\n{\n  SELECT_LEX *select_lex= thd->lex->current_select;\n  TABLE_LIST *table= NULL;\t// For HP compilers\n  /*\n    it_is_update set to TRUE when tables of primary SELECT_LEX (SELECT_LEX\n    which belong to LEX, i.e. most up SELECT) will be updated by\n    INSERT/UPDATE/LOAD\n    NOTE: using this condition helps to prevent call of prepare_check_option()\n    from subquery of VIEW, because tables of subquery belongs to VIEW\n    (see condition before prepare_check_option() call)\n  */\n  bool it_is_update= (select_lex == thd->lex->first_select_lex()) &&\n    thd->lex->which_check_option_applicable();\n  bool save_is_item_list_lookup= select_lex->is_item_list_lookup;\n  TABLE_LIST *derived= select_lex->master_unit()->derived;\n  DBUG_ENTER(\"setup_conds\");\n\n  select_lex->is_item_list_lookup= 0;\n\n  thd->column_usage= MARK_COLUMNS_READ;\n  DBUG_PRINT(\"info\", (\"thd->column_usage: %d\", thd->column_usage));\n  select_lex->cond_count= 0;\n  select_lex->between_count= 0;\n  select_lex->max_equal_elems= 0;\n\n  for (table= tables; table; table= table->next_local)\n  {\n    if (select_lex == thd->lex->first_select_lex() &&\n        select_lex->first_cond_optimization &&\n        table->merged_for_insert &&\n        table->prepare_where(thd, conds, FALSE))\n      goto err_no_arena;\n  }\n\n  if (*conds)\n  {\n    thd->where=\"where clause\";\n    DBUG_EXECUTE(\"where\",\n                 print_where(*conds,\n                             \"WHERE in setup_conds\",\n                             QT_ORDINARY););\n    /*\n      Wrap alone field in WHERE clause in case it will be outer field of subquery\n      which need persistent pointer on it, but conds could be changed by optimizer\n    */\n    if ((*conds)->type() == Item::FIELD_ITEM && !derived)\n      wrap_ident(thd, conds);\n    (*conds)->mark_as_condition_AND_part(NO_JOIN_NEST);\n    if ((*conds)->fix_fields_if_needed_for_bool(thd, conds))\n      goto err_no_arena;\n  }\n\n  /*\n    Apply fix_fields() to all ON clauses at all levels of nesting,\n    including the ones inside view definitions.\n  */\n  if (setup_on_expr(thd, tables, it_is_update))\n    goto err_no_arena;\n\n  if (!thd->stmt_arena->is_conventional())\n  {\n    /*\n      We are in prepared statement preparation code => we should store\n      WHERE clause changing for next executions.\n\n      We do this ON -> WHERE transformation only once per PS/SP statement.\n    */\n    select_lex->where= *conds;\n  }\n  thd->lex->current_select->is_item_list_lookup= save_is_item_list_lookup;\n  DBUG_RETURN(thd->is_error());\n\nerr_no_arena:\n  select_lex->is_item_list_lookup= save_is_item_list_lookup;\n  DBUG_RETURN(1);\n}",
        "func_hash": 244305677857068716399838865539882516778,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-416"
        ],
        "cve": "CVE-2022-27455",
        "cve_desc": "MariaDB Server v10.6.3 and below was discovered to contain an use-after-free in the component my_wildcmp_8bit_impl at /strings/ctype-simple.c.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-27455",
        "func_name": "setup_conds",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 216983,
        "project": "qemu",
        "commit_id": "418ade7849ce7641c0f7333718caf5091a02fd4c",
        "project_url": "https://github.com/bonzini/qemu",
        "commit_url": "https://github.com/qemu/qemu/commit/418ade7849ce7641c0f7333718caf5091a02fd4c",
        "commit_message": "softmmu: Always initialize xlat in address_space_translate_for_iotlb\n\nThe bug is an uninitialized memory read, along the translate_fail\npath, which results in garbage being read from iotlb_to_section,\nwhich can lead to a crash in io_readx/io_writex.\n\nThe bug may be fixed by writing any value with zero\nin ~TARGET_PAGE_MASK, so that the call to iotlb_to_section using\nthe xlat'ed address returns io_mem_unassigned, as desired by the\ntranslate_fail path.\n\nIt is most useful to record the original physical page address,\nwhich will eventually be logged by memory_region_access_valid\nwhen the access is rejected by unassigned_mem_accepts.\n\nResolves: https://gitlab.com/qemu-project/qemu/-/issues/1065\nSigned-off-by: Richard Henderson <richard.henderson@linaro.org>\nReviewed-by: Peter Maydell <peter.maydell@linaro.org>\nMessage-Id: <20220621153829.366423-1-richard.henderson@linaro.org>",
        "target": 1,
        "irrelevant": 0,
        "func_before": "address_space_translate_for_iotlb(CPUState *cpu, int asidx, hwaddr addr,\n                                  hwaddr *xlat, hwaddr *plen,\n                                  MemTxAttrs attrs, int *prot)\n{\n    MemoryRegionSection *section;\n    IOMMUMemoryRegion *iommu_mr;\n    IOMMUMemoryRegionClass *imrc;\n    IOMMUTLBEntry iotlb;\n    int iommu_idx;\n    AddressSpaceDispatch *d =\n        qatomic_rcu_read(&cpu->cpu_ases[asidx].memory_dispatch);\n\n    for (;;) {\n        section = address_space_translate_internal(d, addr, &addr, plen, false);\n\n        iommu_mr = memory_region_get_iommu(section->mr);\n        if (!iommu_mr) {\n            break;\n        }\n\n        imrc = memory_region_get_iommu_class_nocheck(iommu_mr);\n\n        iommu_idx = imrc->attrs_to_index(iommu_mr, attrs);\n        tcg_register_iommu_notifier(cpu, iommu_mr, iommu_idx);\n        /* We need all the permissions, so pass IOMMU_NONE so the IOMMU\n         * doesn't short-cut its translation table walk.\n         */\n        iotlb = imrc->translate(iommu_mr, addr, IOMMU_NONE, iommu_idx);\n        addr = ((iotlb.translated_addr & ~iotlb.addr_mask)\n                | (addr & iotlb.addr_mask));\n        /* Update the caller's prot bits to remove permissions the IOMMU\n         * is giving us a failure response for. If we get down to no\n         * permissions left at all we can give up now.\n         */\n        if (!(iotlb.perm & IOMMU_RO)) {\n            *prot &= ~(PAGE_READ | PAGE_EXEC);\n        }\n        if (!(iotlb.perm & IOMMU_WO)) {\n            *prot &= ~PAGE_WRITE;\n        }\n\n        if (!*prot) {\n            goto translate_fail;\n        }\n\n        d = flatview_to_dispatch(address_space_to_flatview(iotlb.target_as));\n    }\n\n    assert(!memory_region_is_iommu(section->mr));\n    *xlat = addr;\n    return section;\n\ntranslate_fail:\n    return &d->map.sections[PHYS_SECTION_UNASSIGNED];\n}",
        "func_hash": 119842489623736981380410642519747422328,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-908"
        ],
        "cve": "CVE-2022-35414",
        "cve_desc": "softmmu/physmem.c in QEMU through 7.0.0 can perform an uninitialized read on the translate_fail path, leading to an io_readx or io_writex crash. NOTE: a third party states that the Non-virtualization Use Case in the qemu.org reference applies here, i.e., \"Bugs affecting the non-virtualization use case are not considered security bugs at this time.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-35414",
        "func_name": "address_space_translate_for_iotlb",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 217129,
        "project": "bootstrap-dht",
        "commit_id": "e809ea80e3527e32c40756eddd8b2ae44bc3af1a",
        "project_url": "https://github.com/bittorrent/bootstrap-dht",
        "commit_url": "https://github.com/bittorrent/bootstrap-dht/commit/e809ea80e3527e32c40756eddd8b2ae44bc3af1a",
        "commit_message": "Check for out-of-bounds bencoded lengths before advancing buffer pointer",
        "target": 1,
        "irrelevant": 0,
        "func_before": "\tint lazy_bdecode(char const* start, char const* end, lazy_entry& ret\n\t\t, error_code& ec, int* error_pos, int depth_limit, int item_limit)\n\t{\n\t\tchar const* const orig_start = start;\n\t\tret.clear();\n\t\tif (start == end) return 0;\n\n\t\tstd::vector<lazy_entry*> stack;\n\n\t\tstack.push_back(&ret);\n\t\twhile (start <= end)\n\t\t{\n\t\t\tif (stack.empty()) break; // done!\n\n\t\t\tlazy_entry* top = stack.back();\n\n\t\t\tif (int(stack.size()) > depth_limit) TORRENT_FAIL_BDECODE(bdecode_errors::depth_exceeded);\n\t\t\tif (start >= end) TORRENT_FAIL_BDECODE(bdecode_errors::unexpected_eof);\n\t\t\tchar t = *start;\n\t\t\t++start;\n\t\t\tif (start >= end && t != 'e') TORRENT_FAIL_BDECODE(bdecode_errors::unexpected_eof);\n\n\t\t\tswitch (top->type())\n\t\t\t{\n\t\t\t\tcase lazy_entry::dict_t:\n\t\t\t\t{\n\t\t\t\t\tif (t == 'e')\n\t\t\t\t\t{\n\t\t\t\t\t\ttop->set_end(start);\n\t\t\t\t\t\tstack.pop_back();\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t\tif (!numeric(t)) TORRENT_FAIL_BDECODE(bdecode_errors::expected_string);\n\t\t\t\t\tboost::int64_t len = t - '0';\n\t\t\t\t\tbdecode_errors::error_code_enum e = bdecode_errors::no_error;\n\t\t\t\t\tstart = parse_int(start, end, ':', len, e);\n\t\t\t\t\tif (e)\n\t\t\t\t\t\tTORRENT_FAIL_BDECODE(e);\n\n\t\t\t\t\tif (start + len + 1 > end)\n\t\t\t\t\t\tTORRENT_FAIL_BDECODE(bdecode_errors::unexpected_eof);\n\n\t\t\t\t\tif (len < 0)\n\t\t\t\t\t\tTORRENT_FAIL_BDECODE(bdecode_errors::overflow);\n\n\t\t\t\t\t++start;\n\t\t\t\t\tif (start == end) TORRENT_FAIL_BDECODE(bdecode_errors::unexpected_eof);\n\t\t\t\t\tlazy_entry* ent = top->dict_append(start);\n\t\t\t\t\tif (ent == 0) TORRENT_FAIL_BDECODE(boost::system::errc::not_enough_memory);\n\t\t\t\t\tstart += len;\n\t\t\t\t\tif (start >= end) TORRENT_FAIL_BDECODE(bdecode_errors::unexpected_eof);\n\t\t\t\t\tstack.push_back(ent);\n\t\t\t\t\tt = *start;\n\t\t\t\t\t++start;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tcase lazy_entry::list_t:\n\t\t\t\t{\n\t\t\t\t\tif (t == 'e')\n\t\t\t\t\t{\n\t\t\t\t\t\ttop->set_end(start);\n\t\t\t\t\t\tstack.pop_back();\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t\tlazy_entry* ent = top->list_append();\n\t\t\t\t\tif (ent == 0) TORRENT_FAIL_BDECODE(boost::system::errc::not_enough_memory);\n\t\t\t\t\tstack.push_back(ent);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tdefault: break;\n\t\t\t}\n\n\t\t\t--item_limit;\n\t\t\tif (item_limit <= 0) TORRENT_FAIL_BDECODE(bdecode_errors::limit_exceeded);\n\n\t\t\ttop = stack.back();\n\t\t\tswitch (t)\n\t\t\t{\n\t\t\t\tcase 'd':\n\t\t\t\t\ttop->construct_dict(start - 1);\n\t\t\t\t\tcontinue;\n\t\t\t\tcase 'l':\n\t\t\t\t\ttop->construct_list(start - 1);\n\t\t\t\t\tcontinue;\n\t\t\t\tcase 'i':\n\t\t\t\t{\n\t\t\t\t\tchar const* int_start = start;\n\t\t\t\t\tstart = find_char(start, end, 'e');\n\t\t\t\t\ttop->construct_int(int_start, start - int_start);\n\t\t\t\t\tif (start == end) TORRENT_FAIL_BDECODE(bdecode_errors::unexpected_eof);\n\t\t\t\t\tTORRENT_ASSERT(*start == 'e');\n\t\t\t\t\t++start;\n\t\t\t\t\tstack.pop_back();\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tdefault:\n\t\t\t\t{\n\t\t\t\t\tif (!numeric(t))\n\t\t\t\t\t\tTORRENT_FAIL_BDECODE(bdecode_errors::expected_value);\n\n\t\t\t\t\tboost::int64_t len = t - '0';\n\t\t\t\t\tbdecode_errors::error_code_enum e = bdecode_errors::no_error;\n\t\t\t\t\tstart = parse_int(start, end, ':', len, e);\n\t\t\t\t\tif (e)\n\t\t\t\t\t\tTORRENT_FAIL_BDECODE(e);\n\t\t\t\t\tif (start + len + 1 > end)\n\t\t\t\t\t\tTORRENT_FAIL_BDECODE(bdecode_errors::unexpected_eof);\n\t\t\t\t\tif (len < 0)\n\t\t\t\t\t\tTORRENT_FAIL_BDECODE(bdecode_errors::overflow);\n\n\t\t\t\t\t++start;\n\t\t\t\t\ttop->construct_string(start, int(len));\n\t\t\t\t\tstack.pop_back();\n\t\t\t\t\tstart += len;\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn 0;\n\t\t}\n\t\treturn 0;\n\t}",
        "func_hash": 26854422676906062381139387440560031690,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-20"
        ],
        "cve": "CVE-2015-5685",
        "cve_desc": "The lazy_bdecode function in BitTorrent DHT bootstrap server (bootstrap-dht ) allows remote attackers to execute arbitrary code via a crafted packet, related to \"improper indexing.\"",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2015-5685",
        "func_name": "lazy_bdecode",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 217131,
        "project": "gd-libgd",
        "commit_id": "47eb44b2e90ca88a08dca9f9a1aa9041e9587f43",
        "project_url": "https://bitbucket.org/libgd/gd-libgd",
        "commit_url": "https://bitbucket.org/libgd/gd-libgd/commits/47eb44b2e90ca88a08dca9f9a1aa9041e9587f43",
        "commit_message": "Fix possible buffer read overflow\ndetected by -fsanitize=address, thanks to Jan Bee",
        "target": 1,
        "irrelevant": 1,
        "func_before": "GetCode_(gdIOCtx *fd, CODE_STATIC_DATA *scd, int code_size, int flag, int *ZeroDataBlockP)\n{\n\tint i, j, ret;\n\tunsigned char count;\n\n\tif(flag) {\n\t\tscd->curbit = 0;\n\t\tscd->lastbit = 0;\n\t\tscd->last_byte = 0;\n\t\tscd->done = FALSE;\n\t\treturn 0;\n\t}\n\n\tif((scd->curbit + code_size) >= scd->lastbit) {\n\t\tif(scd->done) {\n\t\t\tif(scd->curbit >= scd->lastbit) {\n\t\t\t\t/* Oh well */\n\t\t\t}\n\t\t\treturn -1;\n\t\t}\n\n\t\tscd->buf[0] = scd->buf[scd->last_byte - 2];\n\t\tscd->buf[1] = scd->buf[scd->last_byte - 1];\n\n\t\tif((count = GetDataBlock(fd, &scd->buf[2], ZeroDataBlockP)) <= 0) {\n\t\t\tscd->done = TRUE;\n\t\t}\n\n\t\tscd->last_byte = 2 + count;\n\t\tscd->curbit = (scd->curbit - scd->lastbit) + 16;\n\t\tscd->lastbit = (2 + count) * 8;\n\t}\n\n\tret = 0;\n\tfor (i = scd->curbit, j = 0; j < code_size; ++i, ++j) {\n\t\tret |= ((scd->buf[i / 8] & (1 << (i % 8))) != 0) << j;\n\t}\n\n\tscd->curbit += code_size;\n\n\treturn ret;\n}",
        "func_hash": 193987119857378962206988893625754622033,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-119"
        ],
        "cve": "CVE-2014-9709",
        "cve_desc": "The GetCode_ function in gd_gif_in.c in GD 2.1.1 and earlier, as used in PHP before 5.5.21 and 5.6.x before 5.6.5, allows remote attackers to cause a denial of service (buffer over-read and application crash) via a crafted GIF image that is improperly handled by the gdImageCreateFromGif function.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2014-9709",
        "func_name": "GetCode_",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 217231,
        "project": "opaque",
        "commit_id": "5ddda15d89f5ac82f4416208c5319ace4aecdc36",
        "project_url": "https://github.com/ucbrise/opaque",
        "commit_url": "https://github.com/ucbrise/opaque/commit/5ddda15d89f5ac82f4416208c5319ace4aecdc36",
        "commit_message": "Check that ecall [user_check] pointers and ocall_malloc result pointer are outside enclave (#67)\n\nThis should reduce the enclave's attack surface by preventing an attacker from invoking ecalls on or triggering unexpected writes to arbitrary enclave memory, which could potentially leak information about that memory or lead to incorrect results.\n\nFixes #36. Fixes #66.",
        "target": 1,
        "irrelevant": 1,
        "func_before": "void ocall_malloc(size_t size, uint8_t **ret) {\n  *ret = static_cast<uint8_t *>(malloc(size));\n}",
        "func_hash": 206657736615012684702820705282863743646,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2018-20742",
        "cve_desc": "An issue was discovered in UC Berkeley RISE Opaque before 2018-12-01. There is no boundary check on ocall_malloc. The return value could be a pointer to enclave memory. It could cause an arbitrary enclave memory write.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2018-20742",
        "func_name": "ocall_malloc",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 217234,
        "project": "univention-corporate-server",
        "commit_id": "a28053045bd2e778c50ed1acaf4e52e1e34f6e34",
        "project_url": "https://github.com/univention/univention-corporate-server",
        "commit_url": "https://github.com/univention/univention-corporate-server/commit/a28053045bd2e778c50ed1acaf4e52e1e34f6e34",
        "commit_message": "Bug #48427 UDN: Forbid vulnerable GET_DN for VERSION >= 3\n\nUDL using PROTOCOL_3 must no longer use GET_DN but WAIT_DN - if it is\nstill used this is a protocol violation. UDL simply will not get an\nanswer.\n\nWhen UCRV 'notifier/protocol/version is set to 3, any old client still\nusing PROTOCOL_2 will get rejected while negotiating the protocol\nversion, so it is asserted that \"version >= network_procotol_version\".",
        "target": 1,
        "irrelevant": 0,
        "func_before": "int data_on_connection(int fd, callback_remove_handler remove)\n{\n\tint nread;\n\tchar *network_packet;\n\tchar network_line[8192];\n\tchar *p;\n\tunsigned long id;\n\n\tchar string[1024];\n\tunsigned long msg_id = UINT32_MAX;\n\tenum network_protocol version = network_client_get_version(fd);\n\n\tioctl(fd, FIONREAD, &nread);\n\n\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_ALL, \"new connection data = %d\\n\",nread);\n\n\tif(nread == 0)\n\t{\n\t\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_PROCESS, \"%d failed, got 0 close connection to listener \", fd);\n\t\tclose(fd);\n\t\tFD_CLR(fd, &readfds);\n\t\tremove(fd);\n\t\tnetwork_client_dump ();\n\t\treturn 0;\n\t}\n\n\n\tif ( nread >= 8192 ) {\n\n\t\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_ERROR, \"%d failed, more than 8192 close connection to listener \", fd);\n\t\tclose(fd);\n\t\tFD_CLR(fd, &readfds);\n\t\tremove(fd);\n\n\t\treturn 0;\n\t}\n\n\t/* read the whole package */\n\tnetwork_packet=malloc((nread+1) * sizeof(char));\n\tread(fd, network_packet, nread);\n\tnetwork_packet[nread]='\\0';\n\n\tmemset(network_line, 0, 8192);\n\tp=network_packet;\n\tp_sem(sem_id);\n\n\twhile ( get_network_line(p, network_line) ) {\n\n\t\tif ( strlen(network_line) > 0 ) {\n\t\t\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_ALL, \"line = [%s]\",network_line);\n\t\t}\n\n\t\t\n\t\tif ( !strncmp(network_line, \"MSGID: \", strlen(\"MSGID: \")) ) {\n\t\t\t/* read message id  */\n\n\t\t\tmsg_id=strtoul(&(network_line[strlen(\"MSGID: \")]), NULL, 10);\n\n\t\t\tp+=strlen(network_line);\n\n\n\t\t} else if ( !strncmp(network_line, \"Version: \", strlen(\"Version: \")) ) {\n\t\t\tchar *head = network_line, *end;\n\n\t\t\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_ALL, \"RECV: VERSION\");\n\n\t\t\tversion = strtoul(head + 9, &end, 10);\n\t\t\tif (!head[9] || *end)\n\t\t\t\tgoto failed;\n\n\t\t\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_ALL, \"VERSION=%d\", version);\n\n\t\t\tif (version < network_procotol_version) {\n\t\t\t\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_PROCESS, \"Forbidden VERSION=%d < %d, close connection to listener\", version, network_procotol_version);\n\t\t\t\tgoto close;\n\t\t\t} else if (version >= PROTOCOL_LAST) {\n\t\t\t\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_PROCESS, \"Future VERSION=%d\", version);\n\t\t\t\tversion = PROTOCOL_LAST - 1;\n\t\t\t}\n\t\t\tnetwork_client_set_version(fd, version);\n\t\t\t\n\t\t\t/* reset message id */\n\t\t\tmsg_id = UINT32_MAX;\n\n\t\t\tp+=strlen(network_line);\n\n\n\t\t} else if ( !strncmp(network_line, \"Capabilities: \", strlen(\"Capabilities: \")) ) {\n\n\t\t\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_ALL, \"RECV: Capabilities\");\n\n\t\t\tif ( version > PROTOCOL_UNKNOWN ) {\n\n\t\t\t\tmemset(string, 0, sizeof(string));\n\t\t\t\t\n\t\t\t\tsnprintf(string, sizeof(string), \"Version: %d\\nCapabilities: \\n\\n\", version);\n\n\t\t\t\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_ALL, \"SEND: %s\", string);\n\n\t\t\t\twrite(fd, string, strlen(string));\n\n\t\t\t} else {\n\t\t\t\t\n\t\t\t\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_ALL, \"Capabilities recv, but no version line\");\n\t\t\t\t\n\t\t\t}\n\n\t\t\tp+=strlen(network_line);\n\n\n\t\t} else if ( !strncmp(network_line, \"GET_DN \", strlen(\"GET_DN \")) && msg_id != UINT32_MAX && network_client_get_version(fd) > 0) {\n\n\t\t\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_ALL, \"RECV: GET_DN\");\n\n\t\t\tid=strtoul(&(network_line[strlen(\"GET_DN \")]), NULL, 10);\n\n\t\t\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_ALL, \"id: %ld\",id);\n\n\t\t\tif ( id <= notify_last_id.id) {\n\n\t\t\t\tchar *dn_string = NULL;\n\n\t\t\t\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_ALL, \"try to read %ld from cache\", id);\n\n\t\t\t\t/* try to read from cache */\n\t\t\t\tif ( (dn_string = notifier_cache_get(id)) == NULL ) {\n\n\t\t\t\t\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_ALL, \"%ld not found in cache\", id);\n\n\t\t\t\t\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_ALL, \"%ld get one dn\", id);\n\n\t\t\t\t\t/* read from transaction file, because not in cache */\n\t\t\t\t\tif( (dn_string=notify_transcation_get_one_dn ( id )) == NULL ) {\n\n\t\t\t\t\t\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_ALL, \"%ld failed \", id);\n\t\t\t\t\t\t/* TODO: maybe close connection? */\n\n\t\t\t\t\t\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_ERROR, \"%d failed, close connection to listener \", fd);\n\t\t\t\t\t\tclose(fd);\n\t\t\t\t\t\tFD_CLR(fd, &readfds);\n\t\t\t\t\t\tremove(fd);\n\n\t\t\t\t\t\treturn 0;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif ( dn_string != NULL ) {\n\n\t\t\t\t\tsnprintf(string, sizeof(string), \"MSGID: %ld\\n%s\\n\\n\",msg_id,dn_string);\n\n\t\t\t\t\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_ALL, \"--> %d: [%s]\",fd, string);\n\n\t\t\t\t\twrite(fd, string, strlen(string));\n\n\t\t\t\t\tfree(dn_string);\n\n\t\t\t\t}\n\n\n\t\t\t} else {\n\t\t\t\t/* set wanted id */\n\n\t\t\t\tnetwork_client_set_next_id(fd, id);\n\t\t\t\tnetwork_client_set_msg_id(fd, msg_id);\n\n\t\t\t}\n\n\t\t\tp+=strlen(network_line)+1;\n\t\t\tmsg_id = UINT32_MAX;\n\n\t\t} else if (!strncmp(p, \"WAIT_ID \", 8) && msg_id != UINT32_MAX && version >= PROTOCOL_3) {\n\t\t\tchar *head = network_line, *end;\n\t\t\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_ALL, \"RECV: WAIT_ID\");\n\t\t\tid = strtoul(head + 8, &end, 10);\n\t\t\tif (!head[8] || *end)\n\t\t\t\tgoto failed;\n\t\t\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_ALL, \"id: %ld\", id);\n\n\t\t\tif (id <= notify_last_id.id) {\n\t\t\t\tsnprintf(string, sizeof(string), \"MSGID: %ld\\n%ld\\n\\n\", msg_id, notify_last_id.id);\n\t\t\t\twrite(fd, string, strlen(string));\n\t\t\t} else {\n\t\t\t\t/* set wanted id */\n\t\t\t\tnetwork_client_set_next_id(fd, id);\n\t\t\t\tnetwork_client_set_msg_id(fd, msg_id);\n\t\t\t}\n\n\t\t\tp += strlen(network_line) + 1;\n\t\t\tmsg_id = UINT32_MAX;\n\n\t\t} else if ( !strncmp(network_line, \"GET_ID\", strlen(\"GET_ID\")) && msg_id != UINT32_MAX  && network_client_get_version(fd) > 0) {\n\n\t\t\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_ALL, \"RECV: GET_ID\");\n\n\t\t\tmemset(string, 0, sizeof(string));\n\n\t\t\tsnprintf(string, sizeof(string), \"MSGID: %ld\\n%ld\\n\\n\",msg_id,notify_last_id.id);\n\n\t\t\twrite(fd, string, strlen(string));\n\n\t\t\tp+=strlen(network_line)+1;\n\t\t\tmsg_id = UINT32_MAX;\n\n\n\t\t} else if ( !strncmp(network_line, \"GET_SCHEMA_ID\", strlen(\"GET_SCHEMA_ID\")) && msg_id != UINT32_MAX  && network_client_get_version(fd) > 0) {\n\n\t\t\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_ALL, \"RECV: GET_SCHEMA_ID\");\n\n\t\t\tmemset(string, 0, sizeof(string));\n\n\t\t\tsnprintf(string, sizeof(string), \"MSGID: %ld\\n%ld\\n\\n\",msg_id,SCHEMA_ID);\n\n\t\t\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_ALL, \"--> %d: [%s]\",fd, string);\n\n\t\t\twrite(fd, string, strlen(string));\n\n\t\t\tp+=strlen(network_line)+1;\n\t\t\tmsg_id = UINT32_MAX;\n\n\n\t\t} else if ( !strncmp(network_line, \"ALIVE\", strlen(\"ALIVE\")) && msg_id != UINT32_MAX  && network_client_get_version(fd) > 0) {\n\n\t\t\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_ALL, \"RECV: ALIVE\");\n\n\t\t\tsnprintf(string, sizeof(string), \"MSGID: %ld\\nOKAY\\n\\n\",msg_id);\n\n\t\t\twrite(fd, string, strlen(string));\n\n\t\t\tp+=strlen(network_line)+1;\n\t\t\tmsg_id = UINT32_MAX;\n\n\t\t} else {\n\n\t\t\tp+=strlen(network_line);\n\n\t\t\tif (strlen(network_line) == 0 ) {\n\t\t\t\tp+=1;\n \t\t\t} else {\n\t\t\t\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_ERROR, \"Drop package [%s]\", network_line);\n\t\t\t}\n\n\t\t}\n\t}\n\tv_sem(sem_id);\n\n\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_ALL, \"END Package\");\n\t\n\n\tnetwork_client_dump ();\n\n\treturn 0;\n\nfailed:\n\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_PROCESS, \"Failed parsing [%s]\", p);\nclose:\n\tclose(fd);\n\tFD_CLR(fd, &readfds);\n\tremove(fd);\n\treturn 0;\n}",
        "func_hash": 26417302945123183266379996857046132142,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-200"
        ],
        "cve": "CVE-2019-1010283",
        "cve_desc": "Univention Corporate Server univention-directory-notifier 12.0.1-3 and earlier is affected by: CWE-213: Intentional Information Exposure. The impact is: Loss of Confidentiality. The component is: function data_on_connection() in src/callback.c. The attack vector is: network connectivity. The fixed version is: 12.0.1-4 and later.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2019-1010283",
        "func_name": "data_on_connection",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 217238,
        "project": "serenity",
        "commit_id": "48fbf6a88d4822a1e5470cf08f29464511bd72c1",
        "project_url": "https://github.com/SerenityOS/serenity",
        "commit_url": "https://github.com/SerenityOS/serenity/commit/48fbf6a88d4822a1e5470cf08f29464511bd72c1",
        "commit_message": "LibCrypto: Don't copy the prime test candidates\n\nThis was copying a bunch of bigints for no reason.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static bool MR_primality_test(UnsignedBigInteger n, const Vector<UnsignedBigInteger, 256>& tests)\n{\n    // Written using Wikipedia:\n    // https://en.wikipedia.org/wiki/Miller%E2%80%93Rabin_primality_test#Miller%E2%80%93Rabin_test\n    ASSERT(!(n < 4));\n    auto predecessor = n.minus({ 1 });\n    auto d = predecessor;\n    size_t r = 0;\n\n    {\n        auto div_result = d.divided_by(2);\n        while (div_result.remainder == 0) {\n            d = div_result.quotient;\n            div_result = d.divided_by(2);\n            ++r;\n        }\n    }\n    if (r == 0) {\n        // n - 1 is odd, so n was even. But there is only one even prime:\n        return n == 2;\n    }\n\n    for (auto a : tests) {\n        // Technically: ASSERT(2 <= a && a <= n - 2)\n        ASSERT(a < n);\n        auto x = ModularPower(a, d, n);\n        if (x == 1 || x == predecessor)\n            continue;\n        bool skip_this_witness = false;\n        // r \u2212 1 iterations.\n        for (size_t i = 0; i < r - 1; ++i) {\n            x = ModularPower(x, 2, n);\n            if (x == predecessor) {\n                skip_this_witness = true;\n                break;\n            }\n        }\n        if (skip_this_witness)\n            continue;\n        return false; // \"composite\"\n    }\n\n    return true; // \"probably prime\"\n}",
        "func_hash": 209495948576285830185728169492009901118,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-120"
        ],
        "cve": "CVE-2021-27343",
        "cve_desc": "SerenityOS Unspecified is affected by: Buffer Overflow. The impact is: obtain sensitive information (context-dependent). The component is: /Userland/Libraries/LibCrypto/ASN1/DER.h Crypto::der_decode_sequence() function. The attack vector is: Parsing RSA Key ASN.1.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-27343",
        "func_name": "MR_primality_test",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 217239,
        "project": "serenity",
        "commit_id": "c9f25bca048443e317f1994ba9b106f2386688c3",
        "project_url": "https://github.com/SerenityOS/serenity",
        "commit_url": "https://github.com/SerenityOS/serenity/commit/c9f25bca048443e317f1994ba9b106f2386688c3",
        "commit_message": "LibTextCodec: Make UTF16BEDecoder read only up to an even offset\n\nReading up to the end of the input string of odd length results in\nan out-of-bounds read",
        "target": 1,
        "irrelevant": 1,
        "func_before": "String UTF16BEDecoder::to_utf8(const StringView& input)\n{\n    StringBuilder builder(input.length() / 2);\n    for (size_t i = 0; i < input.length(); i += 2) {\n        u16 code_point = (input[i] << 8) | input[i + 1];\n        builder.append_code_point(code_point);\n    }\n    return builder.to_string();\n}",
        "func_hash": 185746559055129378339300492275239703317,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-120"
        ],
        "cve": "CVE-2021-28874",
        "cve_desc": "SerenityOS fixed as of c9f25bca048443e317f1994ba9b106f2386688c3 contains a buffer overflow vulnerability in LibTextCode through opening a crafted file.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-28874",
        "func_name": "UTF16BEDecoder::to_utf8",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 217240,
        "project": "serenity",
        "commit_id": "4317db7498eaa5a37068052bb0310fbc6a5f78e4",
        "project_url": "https://github.com/SerenityOS/serenity",
        "commit_url": "https://github.com/SerenityOS/serenity/commit/4317db7498eaa5a37068052bb0310fbc6a5f78e4",
        "commit_message": "LibArchive: Make bounds checks stricter in the Zip parser\n\nWe now also check we have enough space in the incoming buffer for the\nvarious signatures and optional (length specified) fields. This helps\nprevents a possible heap overflow read.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "    bool read(ReadonlyBytes buffer)\n    {\n        auto fields_size = sizeof(CentralDirectoryRecord) - (sizeof(u8*) * 3);\n        if (buffer.size() < fields_size)\n            return false;\n        if (memcmp(buffer.data(), central_directory_record_signature, sizeof(central_directory_record_signature)) != 0)\n            return false;\n        memcpy(reinterpret_cast<void*>(&made_by_version), buffer.data() + sizeof(central_directory_record_signature), fields_size);\n        name = buffer.data() + sizeof(central_directory_record_signature) + fields_size;\n        extra_data = name + name_length;\n        comment = extra_data + extra_data_length;\n        return true;\n    }",
        "func_hash": 338559769760382772800704932805932220486,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-120"
        ],
        "cve": "CVE-2021-30045",
        "cve_desc": "SerenityOS 2021-03-27 contains a buffer overflow vulnerability in the EndOfCentralDirectory::read() function.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-30045",
        "func_name": "read",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 217241,
        "project": "serenity",
        "commit_id": "4317db7498eaa5a37068052bb0310fbc6a5f78e4",
        "project_url": "https://github.com/SerenityOS/serenity",
        "commit_url": "https://github.com/SerenityOS/serenity/commit/4317db7498eaa5a37068052bb0310fbc6a5f78e4",
        "commit_message": "LibArchive: Make bounds checks stricter in the Zip parser\n\nWe now also check we have enough space in the incoming buffer for the\nvarious signatures and optional (length specified) fields. This helps\nprevents a possible heap overflow read.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "    bool read(ReadonlyBytes buffer)\n    {\n        auto fields_size = sizeof(LocalFileHeader) - (sizeof(u8*) * 3);\n        if (buffer.size() < fields_size)\n            return false;\n        if (memcmp(buffer.data(), local_file_header_signature, sizeof(local_file_header_signature)) != 0)\n            return false;\n        memcpy(reinterpret_cast<void*>(&minimum_version), buffer.data() + sizeof(local_file_header_signature), fields_size);\n        name = buffer.data() + sizeof(local_file_header_signature) + fields_size;\n        extra_data = name + name_length;\n        compressed_data = extra_data + extra_data_length;\n        return true;\n    }",
        "func_hash": 189502346137609023414840536827945179408,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-120"
        ],
        "cve": "CVE-2021-30045",
        "cve_desc": "SerenityOS 2021-03-27 contains a buffer overflow vulnerability in the EndOfCentralDirectory::read() function.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-30045",
        "func_name": "read",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 217242,
        "project": "serenity",
        "commit_id": "4317db7498eaa5a37068052bb0310fbc6a5f78e4",
        "project_url": "https://github.com/SerenityOS/serenity",
        "commit_url": "https://github.com/SerenityOS/serenity/commit/4317db7498eaa5a37068052bb0310fbc6a5f78e4",
        "commit_message": "LibArchive: Make bounds checks stricter in the Zip parser\n\nWe now also check we have enough space in the incoming buffer for the\nvarious signatures and optional (length specified) fields. This helps\nprevents a possible heap overflow read.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "    bool read(ReadonlyBytes buffer)\n    {\n        auto fields_size = sizeof(EndOfCentralDirectory) - sizeof(u8*);\n        if (buffer.size() < fields_size)\n            return false;\n        if (memcmp(buffer.data(), end_of_central_directory_signature, sizeof(end_of_central_directory_signature)) != 0)\n            return false;\n        memcpy(reinterpret_cast<void*>(&disk_number), buffer.data() + sizeof(end_of_central_directory_signature), fields_size);\n        comment = buffer.data() + sizeof(end_of_central_directory_signature) + fields_size;\n        return true;\n    }",
        "func_hash": 68370273513077950337347122851874612690,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-120"
        ],
        "cve": "CVE-2021-30045",
        "cve_desc": "SerenityOS 2021-03-27 contains a buffer overflow vulnerability in the EndOfCentralDirectory::read() function.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-30045",
        "func_name": "read",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 217244,
        "project": "mbed-coap",
        "commit_id": "4647a68e364401e81dbd370728127d844f221d93",
        "project_url": "https://github.com/mjurczak/mbed-coap",
        "commit_url": "https://github.com/mjurczak/mbed-coap/commit/4647a68e364401e81dbd370728127d844f221d93",
        "commit_message": "Implemented measures to prevent memory leaks in sn_coap_parser_options_parse().\n\nAdded a helper uint16_t addition function with overflow detection. The function is used when calculating the extended length and option delta. The overlow detection is needed to avoid wrap-around of option number or length.\nAdditional checks in options using sn_coap_parser_options_parse_multiple_options() have been implemented to avoid overwriting of pointers pointing to previously allocated memory.",
        "target": 1,
        "irrelevant": 1,
        "func_before": "static int8_t sn_coap_parser_options_parse(struct coap_s *handle, uint8_t **packet_data_pptr, sn_coap_hdr_s *dst_coap_msg_ptr, uint8_t *packet_data_start_ptr, uint16_t packet_len)\n{\n    uint8_t previous_option_number = 0;\n    int8_t  ret_status             = 0;\n    uint16_t message_left          = sn_coap_parser_move_packet_ptr(packet_data_pptr,\n                                                                    packet_data_start_ptr,\n                                                                    packet_len,\n                                                                    0);\n\n    /*  Parse token, if exists  */\n    dst_coap_msg_ptr->token_len = *packet_data_start_ptr & COAP_HEADER_TOKEN_LENGTH_MASK;\n\n    if (dst_coap_msg_ptr->token_len) {\n        int8_t ptr_check_result;\n        if ((dst_coap_msg_ptr->token_len > 8) || dst_coap_msg_ptr->token_ptr) {\n            tr_error(\"sn_coap_parser_options_parse - token not valid!\");\n            return -1;\n        }\n\n        ptr_check_result = sn_coap_parser_check_packet_ptr(*packet_data_pptr, packet_data_start_ptr, packet_len, dst_coap_msg_ptr->token_len);\n        if (0 != ptr_check_result) {\n            tr_error(\"sn_coap_parser_options_parse - **packet_data_pptr overflow !\");\n            return -1;\n        }\n\n        dst_coap_msg_ptr->token_ptr = sn_coap_protocol_malloc_copy(handle, *packet_data_pptr, dst_coap_msg_ptr->token_len);\n\n        if (dst_coap_msg_ptr->token_ptr == NULL) {\n            tr_error(\"sn_coap_parser_options_parse - failed to allocate token!\");\n            return -1;\n        }\n\n        message_left = sn_coap_parser_move_packet_ptr(packet_data_pptr,\n                                                      packet_data_start_ptr,\n                                                      packet_len,\n                                                      dst_coap_msg_ptr->token_len);\n    }\n\n    /* Loop all Options */\n    while (message_left && (**packet_data_pptr != 0xff)) {\n        /* Get option length WITHOUT extensions */\n        uint16_t option_len = (**packet_data_pptr & 0x0F);\n        /* Get option number WITHOUT extensions */\n        uint16_t  option_number = (**packet_data_pptr >> COAP_OPTIONS_OPTION_NUMBER_SHIFT);\n\n        message_left = sn_coap_parser_move_packet_ptr(packet_data_pptr, packet_data_start_ptr, packet_len, 1);\n\n        int8_t    option_parse_result;\n        /* Add possible option delta extension */\n        option_parse_result = parse_ext_option(&option_number,\n                                                packet_data_pptr,\n                                                packet_data_start_ptr,\n                                                packet_len,\n                                                &message_left);\n        if (option_parse_result != 0) {\n            return -1;\n        }\n        /* Add previous option to option delta and get option number */\n        option_number += previous_option_number;\n\n        /* Add possible option length extension to resolve full length of the option */\n        option_parse_result = parse_ext_option(&option_len,\n                                                packet_data_pptr,\n                                                packet_data_start_ptr,\n                                                packet_len,\n                                                &message_left);\n        if (option_parse_result != 0) {\n            return -1;\n        }\n\n        /* * * Parse option itself * * */\n        /* Some options are handled independently in own functions */\n        previous_option_number = option_number;\n        /* Allocate options_list_ptr if needed */\n        switch (option_number) {\n            case COAP_OPTION_MAX_AGE:\n            case COAP_OPTION_PROXY_URI:\n            case COAP_OPTION_ETAG:\n            case COAP_OPTION_URI_HOST:\n            case COAP_OPTION_LOCATION_PATH:\n            case COAP_OPTION_URI_PORT:\n            case COAP_OPTION_LOCATION_QUERY:\n            case COAP_OPTION_OBSERVE:\n            case COAP_OPTION_URI_QUERY:\n            case COAP_OPTION_BLOCK2:\n            case COAP_OPTION_BLOCK1:\n            case COAP_OPTION_ACCEPT:\n            case COAP_OPTION_SIZE1:\n            case COAP_OPTION_SIZE2:\n                if (sn_coap_parser_alloc_options(handle, dst_coap_msg_ptr) == NULL) {\n                    tr_error(\"sn_coap_parser_options_parse - failed to allocate options!\");\n                    return -1;\n                }\n                break;\n        }\n\n        if (message_left < option_len){\n            /* packet_data_pptr would overflow! */\n            tr_error(\"sn_coap_parser_options_parse - **packet_data_pptr would overflow when parsing options!\");\n            return -1;\n        }\n\n        /* Parse option */\n        switch (option_number) {\n            case COAP_OPTION_CONTENT_FORMAT:\n                if ((option_len > 2) || (dst_coap_msg_ptr->content_format != COAP_CT_NONE)) {\n                    tr_error(\"sn_coap_parser_options_parse - COAP_OPTION_CONTENT_FORMAT not valid!\");\n                    return -1;\n                }\n                dst_coap_msg_ptr->content_format = (sn_coap_content_format_e) sn_coap_parser_options_parse_uint(packet_data_pptr, option_len);\n                break;\n\n            case COAP_OPTION_MAX_AGE:\n                if (option_len > 4) {\n                    tr_error(\"sn_coap_parser_options_parse - COAP_OPTION_MAX_AGE not valid!\");\n                    return -1;\n                }\n                dst_coap_msg_ptr->options_list_ptr->max_age = sn_coap_parser_options_parse_uint(packet_data_pptr, option_len);\n                break;\n\n            case COAP_OPTION_PROXY_URI:\n                if ((option_len > 1034) || (option_len < 1) || dst_coap_msg_ptr->options_list_ptr->proxy_uri_ptr) {\n                    tr_error(\"sn_coap_parser_options_parse - COAP_OPTION_PROXY_URI not valid!\");\n                    return -1;\n                }\n                dst_coap_msg_ptr->options_list_ptr->proxy_uri_len = option_len;\n                dst_coap_msg_ptr->options_list_ptr->proxy_uri_ptr = sn_coap_protocol_malloc_copy(handle, *packet_data_pptr, option_len);\n\n                if (dst_coap_msg_ptr->options_list_ptr->proxy_uri_ptr == NULL) {\n                    tr_error(\"sn_coap_parser_options_parse - COAP_OPTION_PROXY_URI allocation failed!\");\n                    return -1;\n                }\n                message_left = sn_coap_parser_move_packet_ptr(packet_data_pptr, packet_data_start_ptr, packet_len, option_len);\n                break;\n\n            case COAP_OPTION_ETAG:\n                /* This is managed independently because User gives this option in one character table */\n                ret_status = sn_coap_parser_options_parse_multiple_options(handle, packet_data_pptr,\n                             message_left,\n                             &dst_coap_msg_ptr->options_list_ptr->etag_ptr,\n                             (uint16_t *)&dst_coap_msg_ptr->options_list_ptr->etag_len,\n                             COAP_OPTION_ETAG, option_len);\n                if (ret_status < 0) {\n                    tr_error(\"sn_coap_parser_options_parse - COAP_OPTION_ETAG not valid!\");\n                    return -1;\n                }\n                break;\n\n            case COAP_OPTION_URI_HOST:\n                if ((option_len > 255) || (option_len < 1) || dst_coap_msg_ptr->options_list_ptr->uri_host_ptr) {\n                    tr_error(\"sn_coap_parser_options_parse - COAP_OPTION_URI_HOST not valid!\");\n                    return -1;\n                }\n                dst_coap_msg_ptr->options_list_ptr->uri_host_len = option_len;\n                dst_coap_msg_ptr->options_list_ptr->uri_host_ptr = sn_coap_protocol_malloc_copy(handle, *packet_data_pptr, option_len);\n\n                if (dst_coap_msg_ptr->options_list_ptr->uri_host_ptr == NULL) {\n                    tr_error(\"sn_coap_parser_options_parse - COAP_OPTION_URI_HOST allocation failed!\");\n                    return -1;\n                }\n                message_left = sn_coap_parser_move_packet_ptr(packet_data_pptr, packet_data_start_ptr, packet_len, option_len);\n                break;\n\n            case COAP_OPTION_LOCATION_PATH:\n                if (dst_coap_msg_ptr->options_list_ptr->location_path_ptr) {\n                    tr_error(\"sn_coap_parser_options_parse - COAP_OPTION_LOCATION_PATH exists!\");\n                    return -1;\n                }\n                /* This is managed independently because User gives this option in one character table */\n                ret_status = sn_coap_parser_options_parse_multiple_options(handle, packet_data_pptr, message_left,\n                             &dst_coap_msg_ptr->options_list_ptr->location_path_ptr, &dst_coap_msg_ptr->options_list_ptr->location_path_len,\n                             COAP_OPTION_LOCATION_PATH, option_len);\n                if (ret_status <0) {\n                    tr_error(\"sn_coap_parser_options_parse - COAP_OPTION_LOCATION_PATH not valid!\");\n                    return -1;\n                }\n                break;\n\n            case COAP_OPTION_URI_PORT:\n                if ((option_len > 2) || dst_coap_msg_ptr->options_list_ptr->uri_port != COAP_OPTION_URI_PORT_NONE) {\n                    tr_error(\"sn_coap_parser_options_parse - COAP_OPTION_URI_PORT not valid!\");\n                    return -1;\n                }\n                dst_coap_msg_ptr->options_list_ptr->uri_port = sn_coap_parser_options_parse_uint(packet_data_pptr, option_len);\n                break;\n\n            case COAP_OPTION_LOCATION_QUERY:\n                ret_status = sn_coap_parser_options_parse_multiple_options(handle, packet_data_pptr, message_left,\n                             &dst_coap_msg_ptr->options_list_ptr->location_query_ptr, &dst_coap_msg_ptr->options_list_ptr->location_query_len,\n                             COAP_OPTION_LOCATION_QUERY, option_len);\n                if (ret_status < 0) {\n                    tr_error(\"sn_coap_parser_options_parse - COAP_OPTION_LOCATION_QUERY not valid!\");\n                    return -1;\n                }\n\n                break;\n\n            case COAP_OPTION_URI_PATH:\n                ret_status = sn_coap_parser_options_parse_multiple_options(handle, packet_data_pptr, message_left,\n                             &dst_coap_msg_ptr->uri_path_ptr, &dst_coap_msg_ptr->uri_path_len,\n                             COAP_OPTION_URI_PATH, option_len);\n                if (ret_status < 0) {\n                    tr_error(\"sn_coap_parser_options_parse - COAP_OPTION_URI_PATH not valid!\");\n                    return -1;\n                }\n                break;\n\n            case COAP_OPTION_OBSERVE:\n                if ((option_len > 2) || dst_coap_msg_ptr->options_list_ptr->observe != COAP_OBSERVE_NONE) {\n                    tr_error(\"sn_coap_parser_options_parse - COAP_OPTION_OBSERVE not valid!\");\n                    return -1;\n                }\n                dst_coap_msg_ptr->options_list_ptr->observe = sn_coap_parser_options_parse_uint(packet_data_pptr, option_len);\n                break;\n\n            case COAP_OPTION_URI_QUERY:\n                ret_status = sn_coap_parser_options_parse_multiple_options(handle, packet_data_pptr, message_left,\n                             &dst_coap_msg_ptr->options_list_ptr->uri_query_ptr, &dst_coap_msg_ptr->options_list_ptr->uri_query_len,\n                             COAP_OPTION_URI_QUERY, option_len);\n                if (ret_status < 0) {\n                    tr_error(\"sn_coap_parser_options_parse - COAP_OPTION_URI_QUERY not valid!\");\n                    return -1;\n                }\n                break;\n\n            case COAP_OPTION_BLOCK2:\n                if ((option_len > 3) || dst_coap_msg_ptr->options_list_ptr->block2 != COAP_OPTION_BLOCK_NONE) {\n                    tr_error(\"sn_coap_parser_options_parse - COAP_OPTION_BLOCK2 not valid!\");\n                    return -1;\n                }\n                dst_coap_msg_ptr->options_list_ptr->block2 = sn_coap_parser_options_parse_uint(packet_data_pptr, option_len);\n                break;\n\n            case COAP_OPTION_BLOCK1:\n                if ((option_len > 3) || dst_coap_msg_ptr->options_list_ptr->block1 != COAP_OPTION_BLOCK_NONE) {\n                    tr_error(\"sn_coap_parser_options_parse - COAP_OPTION_BLOCK1 not valid!\");\n                    return -1;\n                }\n                dst_coap_msg_ptr->options_list_ptr->block1 = sn_coap_parser_options_parse_uint(packet_data_pptr, option_len);\n                break;\n\n            case COAP_OPTION_ACCEPT:\n                if ((option_len > 2) || (dst_coap_msg_ptr->options_list_ptr->accept != COAP_CT_NONE)) {\n                    tr_error(\"sn_coap_parser_options_parse - COAP_OPTION_ACCEPT not valid!\");\n                    return -1;\n                }\n                dst_coap_msg_ptr->options_list_ptr->accept = (sn_coap_content_format_e) sn_coap_parser_options_parse_uint(packet_data_pptr, option_len);\n                break;\n\n            case COAP_OPTION_SIZE1:\n                if ((option_len > 4) || dst_coap_msg_ptr->options_list_ptr->use_size1) {\n                    tr_error(\"sn_coap_parser_options_parse - COAP_OPTION_SIZE1 not valid!\");\n                    return -1;\n                }\n                dst_coap_msg_ptr->options_list_ptr->use_size1 = true;\n                dst_coap_msg_ptr->options_list_ptr->size1 = sn_coap_parser_options_parse_uint(packet_data_pptr, option_len);\n                break;\n\n            case COAP_OPTION_SIZE2:\n                if ((option_len > 4) || dst_coap_msg_ptr->options_list_ptr->use_size2) {\n                    tr_error(\"sn_coap_parser_options_parse - COAP_OPTION_SIZE2 not valid!\");\n                    return -1;\n                }\n                dst_coap_msg_ptr->options_list_ptr->use_size2 = true;\n                dst_coap_msg_ptr->options_list_ptr->size2 = sn_coap_parser_options_parse_uint(packet_data_pptr, option_len);\n                break;\n\n            default:\n                tr_error(\"sn_coap_parser_options_parse - unknown option!\");\n                return -1;\n        }\n\n        /* Check for overflow */\n        if ((*packet_data_pptr - packet_data_start_ptr) > packet_len) {\n            return -1;\n        }\n        message_left = sn_coap_parser_move_packet_ptr(packet_data_pptr,\n                                                      packet_data_start_ptr,\n                                                      packet_len,\n                                                      0);\n    }\n    return 0;\n}",
        "func_hash": 118765562002679695778933862391394313057,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-401"
        ],
        "cve": "CVE-2020-12887",
        "cve_desc": "Memory leaks were discovered in the CoAP library in Arm Mbed OS 5.15.3 when using the Arm mbed-coap library 5.1.5. The CoAP parser is responsible for parsing received CoAP packets. The function sn_coap_parser_options_parse() parses the CoAP option number field of all options present in the input packet. Each option number is calculated as a sum of the previous option number and a delta of the current option. The delta and the previous option number are expressed as unsigned 16-bit integers. Due to lack of overflow detection, it is possible to craft a packet that wraps the option number around and results in the same option number being processed again in a single packet. Certain options allocate memory by calling a memory allocation function. In the cases of COAP_OPTION_URI_QUERY, COAP_OPTION_URI_PATH, COAP_OPTION_LOCATION_QUERY, and COAP_OPTION_ETAG, there is no check on whether memory has already been allocated, which in conjunction with the option number integer overflow may lead to multiple assignments of allocated memory to a single pointer. This has been demonstrated to lead to memory leak by buffer orphaning. As a result, the memory is never freed.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2020-12887",
        "func_name": "sn_coap_parser_options_parse",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 217248,
        "project": "phosphor-host-ipmid",
        "commit_id": "b265455a2518ece7c004b43c144199ec980fc620",
        "project_url": "https://github.com/openbmc/phosphor-host-ipmid",
        "commit_url": "https://github.com/openbmc/phosphor-host-ipmid/commit/b265455a2518ece7c004b43c144199ec980fc620",
        "commit_message": "Use more restrictive permissions on /etc/ipmi-pass\n\nThis forces the permissions on /etc/ipmi-pass to be 0600 or RW only by\nowner. This is to prevent non-owners from reading the file, even though\nit is obfuscated to make it harder for ipmi passwords to leak.\n\nTested: change ipmi passwords and see that the /etc/ipmi-pass file has\n        0600 permissions.\n\nChange-Id: I4be0b8a65f98ced031493f7767879eb054e1ee84\nSigned-off-by: Vernon Mauery <vernon.mauery@linux.intel.com>",
        "target": 1,
        "irrelevant": 0,
        "func_before": "int PasswdMgr::updatePasswdSpecialFile(const std::string& userName,\n                                       const std::string& newUserName)\n{\n    phosphor::user::shadow::Lock lock();\n\n    size_t bytesWritten = 0;\n    size_t inBytesLen = 0;\n    size_t isUsrFound = false;\n    const EVP_CIPHER* cipher = EVP_aes_128_cbc();\n    std::vector<uint8_t> dataBuf;\n\n    // Read the encrypted file and get the file data\n    // Check user existance and return if not exist.\n    if (readPasswdFileData(dataBuf) != 0)\n    {\n        log<level::DEBUG>(\"Error in reading the encrypted pass file\");\n        return -EIO;\n    }\n\n    if (dataBuf.size() != 0)\n    {\n        inBytesLen =\n            dataBuf.size() + newUserName.size() + EVP_CIPHER_block_size(cipher);\n    }\n\n    std::vector<uint8_t> inBytes(inBytesLen);\n    if (inBytesLen != 0)\n    {\n        char* outPtr = reinterpret_cast<char*>(dataBuf.data());\n        char* nToken = NULL;\n        char* linePtr = strtok_r(outPtr, \"\\n\", &nToken);\n        while (linePtr != NULL)\n        {\n            size_t userEPos = 0;\n\n            std::string lineStr(linePtr);\n            if ((userEPos = lineStr.find(\":\")) != std::string::npos)\n            {\n                if (userName.compare(lineStr.substr(0, userEPos)) == 0)\n                {\n                    isUsrFound = true;\n                    if (!newUserName.empty())\n                    {\n                        bytesWritten += std::snprintf(\n                            reinterpret_cast<char*>(&inBytes[0]) + bytesWritten,\n                            (inBytesLen - bytesWritten), \"%s%s\\n\",\n                            newUserName.c_str(),\n                            lineStr.substr(userEPos, lineStr.size()).data());\n                    }\n                }\n                else\n                {\n                    bytesWritten += std::snprintf(\n                        reinterpret_cast<char*>(&inBytes[0]) + bytesWritten,\n                        (inBytesLen - bytesWritten), \"%s\\n\", lineStr.data());\n                }\n            }\n            linePtr = strtok_r(NULL, \"\\n\", &nToken);\n        }\n        inBytesLen = bytesWritten;\n    }\n    if (!isUsrFound)\n    {\n        log<level::DEBUG>(\"User doesn't exist\");\n        return 0;\n    }\n\n    // Read the key buff from key file\n    std::array<uint8_t, maxKeySize> keyBuff;\n    std::ifstream keyFile(encryptKeyFileName, std::ios::in | std::ios::binary);\n    if (!keyFile.good())\n    {\n        log<level::DEBUG>(\"Error in opening encryption key file\");\n        return -EIO;\n    }\n    keyFile.read(reinterpret_cast<char*>(keyBuff.data()), keyBuff.size());\n    if (keyFile.fail())\n    {\n        log<level::DEBUG>(\"Error in reading encryption key file\");\n        return -EIO;\n    }\n    keyFile.close();\n\n    // Read the original passwd file mode\n    struct stat st = {};\n    if (stat(passwdFileName, &st) != 0)\n    {\n        log<level::DEBUG>(\"Error in getting password file fstat()\");\n        return -EIO;\n    }\n\n    // Create temporary file for write\n    std::string pwdFile(passwdFileName);\n    std::vector<char> tempFileName(pwdFile.begin(), pwdFile.end());\n    std::vector<char> fileTemplate = {'_', '_', 'X', 'X', 'X',\n                                      'X', 'X', 'X', '\\0'};\n    tempFileName.insert(tempFileName.end(), fileTemplate.begin(),\n                        fileTemplate.end());\n    int fd = mkstemp((char*)tempFileName.data());\n    if (fd == -1)\n    {\n        log<level::DEBUG>(\"Error creating temp file\");\n        return -EIO;\n    }\n\n    std::string strTempFileName(tempFileName.data());\n    // Open the temp file for writing from provided fd\n    // By \"true\", remove it at exit if still there.\n    // This is needed to cleanup the temp file at exception\n    phosphor::user::File temp(fd, strTempFileName, \"w\", true);\n    if ((temp)() == NULL)\n    {\n        close(fd);\n        log<level::DEBUG>(\"Error creating temp file\");\n        return -EIO;\n    }\n\n    // Set the file mode as of actual ipmi-pass file.\n    if (fchmod(fileno((temp)()), st.st_mode) < 0)\n    {\n        log<level::DEBUG>(\"Error setting fchmod for temp file\");\n        return -EIO;\n    }\n\n    const EVP_MD* digest = EVP_sha256();\n    size_t hashLen = EVP_MD_block_size(digest);\n    std::vector<uint8_t> hash(hashLen);\n    size_t ivLen = EVP_CIPHER_iv_length(cipher);\n    std::vector<uint8_t> iv(ivLen);\n    std::array<uint8_t, EVP_MAX_KEY_LENGTH> key;\n    size_t keyLen = key.size();\n    std::array<uint8_t, EVP_MAX_MD_SIZE> mac;\n    size_t macLen = mac.size();\n\n    // Create random hash and generate hash key which will be used for\n    // encryption.\n    if (RAND_bytes(hash.data(), hashLen) != 1)\n    {\n        log<level::DEBUG>(\"Hash genertion failed, bailing out\");\n        return -EIO;\n    }\n    if (NULL == HMAC(digest, keyBuff.data(), keyBuff.size(), hash.data(),\n                     hashLen, key.data(),\n                     reinterpret_cast<unsigned int*>(&keyLen)))\n    {\n        log<level::DEBUG>(\"Failed to create MAC for authentication\");\n        return -EIO;\n    }\n\n    // Generate IV values\n    if (RAND_bytes(iv.data(), ivLen) != 1)\n    {\n        log<level::DEBUG>(\"UV genertion failed, bailing out\");\n        return -EIO;\n    }\n\n    // Encrypt the input data\n    std::vector<uint8_t> outBytes(inBytesLen + EVP_MAX_BLOCK_LENGTH);\n    size_t outBytesLen = 0;\n    if (inBytesLen != 0)\n    {\n        if (encryptDecryptData(true, EVP_aes_128_cbc(), key.data(), keyLen,\n                               iv.data(), ivLen, inBytes.data(), inBytesLen,\n                               mac.data(), &macLen, outBytes.data(),\n                               &outBytesLen) != 0)\n        {\n            log<level::DEBUG>(\"Error while encrypting the data\");\n            return -EIO;\n        }\n        outBytes[outBytesLen] = 0;\n    }\n    OPENSSL_cleanse(key.data(), keyLen);\n\n    // Update the meta password structure.\n    MetaPassStruct metaData = {META_PASSWD_SIG, {0, 0}, 0, 0, 0, 0, 0};\n    metaData.hashSize = hashLen;\n    metaData.ivSize = ivLen;\n    metaData.dataSize = bytesWritten;\n    metaData.padSize = outBytesLen - bytesWritten;\n    metaData.macSize = macLen;\n\n    if (fwrite(&metaData, 1, sizeof(metaData), (temp)()) != sizeof(metaData))\n    {\n        log<level::DEBUG>(\"Error in writing meta data\");\n        return -EIO;\n    }\n\n    if (fwrite(&hash[0], 1, hashLen, (temp)()) != hashLen)\n    {\n        log<level::DEBUG>(\"Error in writing hash data\");\n        return -EIO;\n    }\n\n    if (fwrite(&iv[0], 1, ivLen, (temp)()) != ivLen)\n    {\n        log<level::DEBUG>(\"Error in writing IV data\");\n        return -EIO;\n    }\n\n    if (fwrite(&outBytes[0], 1, outBytesLen, (temp)()) != outBytesLen)\n    {\n        log<level::DEBUG>(\"Error in writing encrypted data\");\n        return -EIO;\n    }\n\n    if (fwrite(&mac[0], 1, macLen, (temp)()) != macLen)\n    {\n        log<level::DEBUG>(\"Error in writing MAC data\");\n        return -EIO;\n    }\n\n    if (fflush((temp)()))\n    {\n        log<level::DEBUG>(\n            \"File fflush error while writing entries to special file\");\n        return -EIO;\n    }\n\n    OPENSSL_cleanse(iv.data(), ivLen);\n\n    // Rename the tmp  file to actual file\n    if (std::rename(strTempFileName.data(), passwdFileName) != 0)\n    {\n        log<level::DEBUG>(\"Failed to rename tmp file to ipmi-pass\");\n        return -EIO;\n    }\n\n    return 0;\n}",
        "func_hash": 308411431480407804964577791887753101427,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-276"
        ],
        "cve": "CVE-2020-14156",
        "cve_desc": "user_channel/passwd_mgr.cpp in OpenBMC phosphor-host-ipmid before 2020-04-03 does not ensure that /etc/ipmi-pass has strong file permissions.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2020-14156",
        "func_name": "PasswdMgr::updatePasswdSpecialFile",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 217249,
        "project": "bsdiff4",
        "commit_id": "49a4cee2feef7deaf9d89e5e793a8824930284d7",
        "project_url": "https://github.com/ilanschnell/bsdiff4",
        "commit_url": "https://github.com/ilanschnell/bsdiff4/commit/49a4cee2feef7deaf9d89e5e793a8824930284d7",
        "commit_message": "apply patch from Robert Scott to fix - shifting some bounds checking",
        "target": 1,
        "irrelevant": 1,
        "func_before": "static PyObject* patch(PyObject* self, PyObject* args)\n{\n    char *origData, *newData, *diffBlock, *extraBlock, *diffPtr, *extraPtr;\n    Py_ssize_t origDataLength, newDataLength, diffBlockLength, extraBlockLength;\n    PyObject *controlTuples, *tuple, *results;\n    off_t oldpos, newpos, x, y, z;\n    int i, j, numTuples;\n\n    if (!PyArg_ParseTuple(args, \"s#nO!s#s#\",\n                          &origData, &origDataLength, &newDataLength,\n                          &PyList_Type, &controlTuples,\n                          &diffBlock, &diffBlockLength,\n                          &extraBlock, &extraBlockLength))\n        return NULL;\n\n    /* allocate the memory for the new data */\n    newData = PyMem_Malloc(newDataLength + 1);\n    if (!newData)\n        return PyErr_NoMemory();\n\n    oldpos = 0;\n    newpos = 0;\n    diffPtr = diffBlock;\n    extraPtr = extraBlock;\n    numTuples = PyList_GET_SIZE(controlTuples);\n    for (i = 0; i < numTuples; i++) {\n        tuple = PyList_GET_ITEM(controlTuples, i);\n        if (!PyTuple_Check(tuple)) {\n            PyMem_Free(newData);\n            PyErr_SetString(PyExc_TypeError, \"expecting tuple\");\n            return NULL;\n        }\n        if (PyTuple_GET_SIZE(tuple) != 3) {\n            PyMem_Free(newData);\n            PyErr_SetString(PyExc_TypeError, \"expecting tuple of size 3\");\n            return NULL;\n        }\n        x = PyLong_AsLong(PyTuple_GET_ITEM(tuple, 0));\n        y = PyLong_AsLong(PyTuple_GET_ITEM(tuple, 1));\n        z = PyLong_AsLong(PyTuple_GET_ITEM(tuple, 2));\n        if (newpos + x > newDataLength ||\n                diffPtr + x > diffBlock + diffBlockLength ||\n                extraPtr + y > extraBlock + extraBlockLength) {\n            PyMem_Free(newData);\n            PyErr_SetString(PyExc_ValueError, \"corrupt patch (overflow)\");\n            return NULL;\n        }\n        memcpy(newData + newpos, diffPtr, x);\n        diffPtr += x;\n        for (j = 0; j < x; j++)\n            if ((oldpos + j >= 0) && (oldpos + j < origDataLength))\n                newData[newpos + j] += origData[oldpos + j];\n        newpos += x;\n        oldpos += x;\n        memcpy(newData + newpos, extraPtr, y);\n        extraPtr += y;\n        newpos += y;\n        oldpos += z;\n    }\n\n    /* confirm that a valid patch was applied */\n    if (newpos != newDataLength ||\n            diffPtr != diffBlock + diffBlockLength ||\n            extraPtr != extraBlock + extraBlockLength) {\n        PyMem_Free(newData);\n        PyErr_SetString(PyExc_ValueError, \"corrupt patch (underflow)\");\n        return NULL;\n    }\n\n    results = PyBytes_FromStringAndSize(newData, newDataLength);\n    PyMem_Free(newData);\n    return results;\n}",
        "func_hash": 35777879312070160535442824993398419892,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2020-15904",
        "cve_desc": "A buffer overflow in the patching routine of bsdiff4 before 1.2.0 allows an attacker to write to heap memory (beyond allocated bounds) via a crafted patch file.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2020-15904",
        "func_name": "patch",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 217253,
        "project": "gilcc",
        "commit_id": "803969389ca9c06237075a7f8eeb1a19e6651759",
        "project_url": "https://github.com/trgil/gilcc",
        "commit_url": "https://github.com/trgil/gilcc/commit/803969389ca9c06237075a7f8eeb1a19e6651759",
        "commit_message": "Fix parser tmp-buffer overflow issue",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static int src_parser_trans_stage_1_2_3(const int tmp_fd, const char *src, const struct trans_config cfg)\n{\n    struct parser_buf pbuf = {\n        .f_indx = 0,\n        .tmp_indx = 0,\n        .f_read_size = 0\n    };\n\n    int write_count = 0;\n    int src_fd;\n    int p_state = P_STATE_CODE;\n\n    src_fd = open(src, O_RDONLY);\n    if (src_fd == -1) {\n        fprintf(stderr, \"**Error: Could not open source file: %s.\\n\", src);\n        return -1;\n    }\n\n    while (p_buf_refill(&pbuf, src_fd) > 0) {\n\n        while (PBUF_F_REMD(pbuf)) {\n\n            switch (p_state) {\n            case P_STATE_COMMENT_C:\n\n                switch (PBUF_F_CHAR(pbuf)) {\n                case '*':\n                    p_buf_push_tmp_char(&pbuf, '*');\n                    continue;\n\n                case '/':\n                    if (pbuf.tmp_indx && (PBUF_TMP_PREV_CHAR(pbuf) == '*')) {\n                        pbuf.tmp_indx--;\n                        p_state = P_STATE_CODE;\n                    }\n                    break;\n\n                default:\n                    if (pbuf.tmp_indx && (PBUF_TMP_PREV_CHAR(pbuf) == '*'))\n                        pbuf.tmp_indx--;\n                    break;\n                }\n\n                pbuf.f_indx++;\n\n            case P_STATE_CODE:\n            default:\n\n                /* TODO: add trigraph support */\n\n                switch (PBUF_F_CHAR(pbuf)) {\n                case ' ':\n                case '\\t':\n                    if (pbuf.tmp_indx &&\n                            (PBUF_TMP_PREV_CHAR(pbuf) == ' ' || PBUF_TMP_PREV_CHAR(pbuf) == '\\t' ||\n                             PBUF_TMP_PREV_CHAR(pbuf) == '\\n'))\n                        pbuf.f_indx++;\n                    else\n                        p_buf_push_tmp_char(&pbuf, ' ');\n\n                    continue;\n\n                case '\\r':\n                case '\\n':\n                    if (pbuf.tmp_indx &&\n                            (PBUF_TMP_PREV_CHAR(pbuf) == ' ' || PBUF_TMP_PREV_CHAR(pbuf) == '\\t' ||\n                             PBUF_TMP_PREV_CHAR(pbuf) == '\\n')) {\n                        pbuf.f_indx++;\n                    } else if (pbuf.tmp_indx && \n                            (PBUF_TMP_PREV_CHAR(pbuf) == '\\\\')) {\n                        pbuf.tmp_indx--;\n                        pbuf.f_indx++;\n                    } else {\n                        p_buf_push_tmp_char(&pbuf, '\\n');\n                    }\n\n                    continue;\n\n                case '\\\\':\n                    p_buf_push_tmp_char(&pbuf, '\\\\');\n                    continue;\n\n                case '/':\n                    p_buf_push_tmp_char(&pbuf, '/');\n                    continue;\n\n                case '*':\n                    if (pbuf.tmp_indx &&\n                            (PBUF_TMP_PREV_CHAR(pbuf) == '/')) {\n                        pbuf.tmp_indx--;\n                        pbuf.f_indx++;\n                        p_state = P_STATE_COMMENT_C;\n                        continue;\n                    }\n\n                default:\n                    break;\n                }\n\n                /* TODO: check return values */\n                p_buf_write_tmp(&pbuf, tmp_fd);\n                p_buf_write_f_char(&pbuf, tmp_fd);\n            }\n        }\n    }\n\n    p_buf_write_tmp(&pbuf, tmp_fd);\n    return 0;\n}",
        "func_hash": 143425032595184974590291153741115718450,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-120"
        ],
        "cve": "CVE-2020-21572",
        "cve_desc": "Buffer overflow vulnerability in function src_parser_trans_stage_1_2_3 trgil gilcc before commit 803969389ca9c06237075a7f8eeb1a19e6651759, allows attackers to cause a denial of service.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2020-21572",
        "func_name": "src_parser_trans_stage_1_2_3",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195067,
        "project": "tensorflow",
        "commit_id": "8a513cec4bec15961fbfdedcaa5376522980455c",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/8a513cec4bec15961fbfdedcaa5376522980455c",
        "commit_message": "Prevent null dereference read in `SpecializeType()`\n\nFor some adversarial protos, the attribute for a key might not exist.\n\nPiperOrigin-RevId: 408382090\nChange-Id: Ie7eabe532c9ff280fce5dce1f6cdb93c76c2e040",
        "target": 1,
        "irrelevant": 0,
        "func_before": "StatusOr<FullTypeDef> SpecializeType(const AttrSlice& attrs,\n                                     const OpDef& op_def) {\n  FullTypeDef ft;\n  ft.set_type_id(TFT_PRODUCT);\n\n  for (int i = 0; i < op_def.output_arg_size(); i++) {\n    auto* t = ft.add_args();\n\n    *t = op_def.output_arg(i).experimental_full_type();\n\n    // Resolve dependent types. The convention for op registrations is to use\n    // attributes as type variables.\n    // See https://www.tensorflow.org/guide/create_op#type_polymorphism.\n    // Once the op signature can be defined entirely in FullType, this\n    // convention can be deprecated.\n    //\n    // Note: While this code performs some basic verifications, it generally\n    // assumes consistent op defs and attributes. If more complete\n    // verifications are needed, they should be done by separately, and in a\n    // way that can be reused for type inference.\n    for (int j = 0; j < t->args_size(); j++) {\n      auto* arg = t->mutable_args(i);\n      if (arg->type_id() == TFT_VAR) {\n        const auto* attr = attrs.Find(arg->s());\n        DCHECK(attr != nullptr);\n        if (attr->value_case() == AttrValue::kList) {\n          const auto& attr_list = attr->list();\n          arg->set_type_id(TFT_PRODUCT);\n          for (int i = 0; i < attr_list.type_size(); i++) {\n            map_dtype_to_tensor(attr_list.type(i), arg->add_args());\n          }\n\n        } else if (attr->value_case() == AttrValue::kType) {\n          map_dtype_to_tensor(attr->type(), arg);\n\n        } else {\n          return Status(error::UNIMPLEMENTED,\n                        absl::StrCat(\"unknown attribute type\",\n                                     attrs.DebugString(), \" key=\", arg->s()));\n        }\n\n        arg->clear_s();\n      }\n    }\n  }\n\n  return ft;\n}",
        "func_hash": 61628354902568849889482519012959401120,
        "file_name": "full_type_util.cc",
        "file_hash": 62085073442308348539645082851768736733,
        "cwe": [
            "CWE-617"
        ],
        "cve": "CVE-2022-23570",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. When decoding a tensor from protobuf, TensorFlow might do a null-dereference if attributes of some mutable arguments to some operations are missing from the proto. This is guarded by a `DCHECK`. However, `DCHECK` is a no-op in production builds and an assertion failure in debug builds. In the first case execution proceeds to the dereferencing of the null pointer, whereas in the second case it results in a crash due to the assertion failure. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, and TensorFlow 2.6.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23570",
        "func_name": "SpecializeType",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195069,
        "project": "gpac",
        "commit_id": "f1ae01d745200a258cdf62622f71754c37cb6c30",
        "project_url": "https://github.com/gpac/gpac",
        "commit_url": "https://github.com/gpac/gpac/commit/f1ae01d745200a258cdf62622f71754c37cb6c30",
        "commit_message": "fixed #1900",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static s32 svc_parse_slice(GF_BitStream *bs, AVCState *avc, AVCSliceInfo *si)\n{\n\ts32 pps_id;\n\n\t/*s->current_picture.reference= h->nal_ref_idc != 0;*/\n\tgf_bs_read_ue_log(bs, \"first_mb_in_slice\");\n\tsi->slice_type = gf_bs_read_ue_log(bs, \"slice_type\");\n\tif (si->slice_type > 9) return -1;\n\n\tpps_id = gf_bs_read_ue_log(bs, \"pps_id\");\n\tif (pps_id > 255)\n\t\treturn -1;\n\tsi->pps = &avc->pps[pps_id];\n\tsi->pps->id = pps_id;\n\tif (!si->pps->slice_group_count)\n\t\treturn -2;\n\tsi->sps = &avc->sps[si->pps->sps_id + GF_SVC_SSPS_ID_SHIFT];\n\tif (!si->sps->log2_max_frame_num)\n\t\treturn -2;\n\n\tsi->frame_num = gf_bs_read_int_log(bs, si->sps->log2_max_frame_num, \"frame_num\");\n\n\tsi->field_pic_flag = 0;\n\tif (si->sps->frame_mbs_only_flag) {\n\t\t/*s->picture_structure= PICT_FRAME;*/\n\t}\n\telse {\n\t\tsi->field_pic_flag = gf_bs_read_int_log(bs, 1, \"field_pic_flag\");\n\t\tif (si->field_pic_flag) si->bottom_field_flag = gf_bs_read_int_log(bs, 1, \"bottom_field_flag\");\n\t}\n\tif (si->nal_unit_type == GF_AVC_NALU_IDR_SLICE || si->NalHeader.idr_pic_flag)\n\t\tsi->idr_pic_id = gf_bs_read_ue_log(bs, \"idr_pic_id\");\n\n\tif (si->sps->poc_type == 0) {\n\t\tsi->poc_lsb = gf_bs_read_int_log(bs, si->sps->log2_max_poc_lsb, \"poc_lsb\");\n\t\tif (si->pps->pic_order_present && !si->field_pic_flag) {\n\t\t\tsi->delta_poc_bottom = gf_bs_read_se_log(bs, \"delta_poc_bottom\");\n\t\t}\n\t}\n\telse if ((si->sps->poc_type == 1) && !si->sps->delta_pic_order_always_zero_flag) {\n\t\tsi->delta_poc[0] = gf_bs_read_se_log(bs, \"delta_poc0\");\n\t\tif ((si->pps->pic_order_present == 1) && !si->field_pic_flag)\n\t\t\tsi->delta_poc[1] = gf_bs_read_se_log(bs, \"delta_poc1\");\n\t}\n\tif (si->pps->redundant_pic_cnt_present) {\n\t\tsi->redundant_pic_cnt = gf_bs_read_ue_log(bs, \"redundant_pic_cnt\");\n\t}\n\treturn 0;\n}",
        "func_hash": 32918828304584753556059241288811637938,
        "file_name": "av_parsers.c",
        "file_hash": 168517587328341017594269375399465893964,
        "cwe": [
            "CWE-120"
        ],
        "cve": "CVE-2021-40568",
        "cve_desc": "A buffer overflow vulnerability exists in Gpac through 1.0.1 via a malformed MP4 file in the svc_parse_slice function in av_parsers.c, which allows attackers to cause a denial of service, even code execution and escalation of privileges.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-40568",
        "func_name": "svc_parse_slice",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195073,
        "project": "tensorflow",
        "commit_id": "e746adbfcfee15e9cfdb391ff746c765b99bdf9b",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/e746adbfcfee15e9cfdb391ff746c765b99bdf9b",
        "commit_message": "Prevent use after free in `DecodePng` kernel.\n\nWe are cleaning up the memory in `decode` and then we are using an `OP_REQUIRES` to check an invariant on the `decode` data.\n\nPiperOrigin-RevId: 409299145\nChange-Id: I4eb93aaca52483eb202e89b78df07fbb2f6cb254",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void DecodePngV2(OpKernelContext* context, StringPiece input) {\n    int channel_bits = (data_type_ == DataType::DT_UINT8) ? 8 : 16;\n    png::DecodeContext decode;\n    OP_REQUIRES(\n        context, png::CommonInitDecode(input, channels_, channel_bits, &decode),\n        errors::InvalidArgument(\"Invalid PNG. Failed to initialize decoder.\"));\n\n    // Verify that width and height are not too large:\n    // - verify width and height don't overflow int.\n    // - width can later be multiplied by channels_ and sizeof(uint16), so\n    //   verify single dimension is not too large.\n    // - verify when width and height are multiplied together, there are a few\n    //   bits to spare as well.\n    const int width = static_cast<int>(decode.width);\n    const int height = static_cast<int>(decode.height);\n    const int64_t total_size =\n        static_cast<int64_t>(width) * static_cast<int64_t>(height);\n    if (width != static_cast<int64_t>(decode.width) || width <= 0 ||\n        width >= (1LL << 27) || height != static_cast<int64_t>(decode.height) ||\n        height <= 0 || height >= (1LL << 27) || total_size >= (1LL << 29)) {\n      png::CommonFreeDecode(&decode);\n      OP_REQUIRES(context, false,\n                  errors::InvalidArgument(\"PNG size too large for int: \",\n                                          decode.width, \" by \", decode.height));\n    }\n\n    Tensor* output = nullptr;\n    Status status;\n    // By the existing API, we support decoding PNG with `DecodeGif` op.\n    // We need to make sure to return 4-D shapes when using `DecodeGif`.\n    if (op_type_ == \"DecodeGif\") {\n      status = context->allocate_output(\n          0, TensorShape({1, height, width, decode.channels}), &output);\n    } else {\n      status = context->allocate_output(\n          0, TensorShape({height, width, decode.channels}), &output);\n    }\n\n    if (op_type_ == \"DecodeBmp\") {\n      // TODO(b/171060723): Only DecodeBmp as op_type_ is not acceptable here\n      // because currently `decode_(jpeg|png|gif)` ops can decode any one of\n      // jpeg, png or gif but not bmp. Similarly, `decode_bmp` cannot decode\n      // anything but bmp formats. This behavior needs to be revisited. For more\n      // details, please refer to the bug.\n      OP_REQUIRES(context, false,\n                  errors::InvalidArgument(\n                      \"Trying to decode PNG format using DecodeBmp op. Use \"\n                      \"`decode_png` or `decode_image` instead.\"));\n    } else if (op_type_ == \"DecodeAndCropJpeg\") {\n      OP_REQUIRES(context, false,\n                  errors::InvalidArgument(\n                      \"DecodeAndCropJpeg operation can run on JPEG only, but \"\n                      \"detected PNG.\"));\n    }\n\n    if (!status.ok()) png::CommonFreeDecode(&decode);\n    OP_REQUIRES_OK(context, status);\n\n    if (data_type_ == DataType::DT_UINT8) {\n      OP_REQUIRES(\n          context,\n          png::CommonFinishDecode(\n              reinterpret_cast<png_bytep>(output->flat<uint8>().data()),\n              decode.channels * width * sizeof(uint8), &decode),\n          errors::InvalidArgument(\"Invalid PNG data, size \", input.size()));\n    } else if (data_type_ == DataType::DT_UINT16) {\n      OP_REQUIRES(\n          context,\n          png::CommonFinishDecode(\n              reinterpret_cast<png_bytep>(output->flat<uint16>().data()),\n              decode.channels * width * sizeof(uint16), &decode),\n          errors::InvalidArgument(\"Invalid PNG data, size \", input.size()));\n    } else if (data_type_ == DataType::DT_FLOAT) {\n      // `png::CommonFinishDecode` does not support `float`. First allocate\n      // uint16 buffer for the image and decode in uint16 (lossless). Wrap the\n      // buffer in `unique_ptr` so that we don't forget to delete the buffer.\n      std::unique_ptr<uint16[]> buffer(\n          new uint16[height * width * decode.channels]);\n      OP_REQUIRES(\n          context,\n          png::CommonFinishDecode(reinterpret_cast<png_bytep>(buffer.get()),\n                                  decode.channels * width * sizeof(uint16),\n                                  &decode),\n          errors::InvalidArgument(\"Invalid PNG data, size \", input.size()));\n\n      // Convert uint16 image data to desired data type.\n      // Use eigen threadpooling to speed up the copy operation.\n      const auto& device = context->eigen_device<Eigen::ThreadPoolDevice>();\n      TTypes<uint16, 3>::UnalignedConstTensor buf(buffer.get(), height, width,\n                                                  decode.channels);\n      float scale = 1. / std::numeric_limits<uint16>::max();\n      // Fill output tensor with desired dtype.\n      output->tensor<float, 3>().device(device) = buf.cast<float>() * scale;\n    }\n  }",
        "func_hash": 20785520030401878119367159260444796492,
        "file_name": "decode_image_op.cc",
        "file_hash": 250237771010213788823348212493793467085,
        "cwe": [
            "CWE-416"
        ],
        "cve": "CVE-2022-23584",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. A malicious user can cause a use after free behavior when decoding PNG images. After `png::CommonFreeDecode(&decode)` gets called, the values of `decode.width` and `decode.height` are in an unspecified state. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23584",
        "func_name": "DecodePngV2",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195074,
        "project": "gpac",
        "commit_id": "a69b567b8c95c72f9560c873c5ab348be058f340",
        "project_url": "https://github.com/gpac/gpac",
        "commit_url": "https://github.com/gpac/gpac/commit/a69b567b8c95c72f9560c873c5ab348be058f340",
        "commit_message": "fixed #1895",
        "target": 1,
        "irrelevant": 0,
        "func_before": "GF_AV1Config *gf_odf_av1_cfg_read_bs_size(GF_BitStream *bs, u32 size)\n{\n#ifndef GPAC_DISABLE_AV_PARSERS\n\tAV1State state;\n\tu8 reserved;\n\tGF_AV1Config *cfg;\n\n\tif (!size) size = (u32) gf_bs_available(bs);\n\tif (!size) return NULL;\n\n\tcfg = gf_odf_av1_cfg_new();\n\tgf_av1_init_state(&state);\n\tstate.config = cfg;\n\n\tcfg->marker = gf_bs_read_int(bs, 1);\n\tcfg->version = gf_bs_read_int(bs, 7);\n\tcfg->seq_profile = gf_bs_read_int(bs, 3);\n\tcfg->seq_level_idx_0 = gf_bs_read_int(bs, 5);\n\tcfg->seq_tier_0 = gf_bs_read_int(bs, 1);\n\tcfg->high_bitdepth = gf_bs_read_int(bs, 1);\n\tcfg->twelve_bit = gf_bs_read_int(bs, 1);\n\tcfg->monochrome = gf_bs_read_int(bs, 1);\n\tcfg->chroma_subsampling_x = gf_bs_read_int(bs, 1);\n\tcfg->chroma_subsampling_y = gf_bs_read_int(bs, 1);\n\tcfg->chroma_sample_position = gf_bs_read_int(bs, 2);\n\n\treserved = gf_bs_read_int(bs, 3);\n\tif (reserved != 0 || cfg->marker != 1 || cfg->version != 1) {\n\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_CONTAINER, (\"[AV1] wrong avcC reserved %d / marker %d / version %d expecting 0 1 1\\n\", reserved, cfg->marker, cfg->version));\n\t\tgf_odf_av1_cfg_del(cfg);\n\t\treturn NULL;\n\t}\n\tcfg->initial_presentation_delay_present = gf_bs_read_int(bs, 1);\n\tif (cfg->initial_presentation_delay_present) {\n\t\tcfg->initial_presentation_delay_minus_one = gf_bs_read_int(bs, 4);\n\t} else {\n\t\t/*reserved = */gf_bs_read_int(bs, 4);\n\t\tcfg->initial_presentation_delay_minus_one = 0;\n\t}\n\tsize -= 4;\n\n\twhile (size) {\n\t\tu64 pos, obu_size;\n\t\tObuType obu_type;\n\t\tGF_AV1_OBUArrayEntry *a;\n\n\t\tpos = gf_bs_get_position(bs);\n\t\tobu_size = 0;\n\t\tif (gf_av1_parse_obu(bs, &obu_type, &obu_size, NULL, &state) != GF_OK) {\n\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[AV1] could not parse AV1 OBU at position \"LLU\". Leaving parsing.\\n\", pos));\n\t\t\tbreak;\n\t\t}\n\t\tassert(obu_size == gf_bs_get_position(bs) - pos);\n\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_CONTAINER, (\"[AV1] parsed AV1 OBU type=%u size=\"LLU\" at position \"LLU\".\\n\", obu_type, obu_size, pos));\n\n\t\tif (!av1_is_obu_header(obu_type)) {\n\t\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_CONTAINER, (\"[AV1] AV1 unexpected OBU type=%u size=\"LLU\" found at position \"LLU\". Forwarding.\\n\", pos));\n\t\t}\n\t\tGF_SAFEALLOC(a, GF_AV1_OBUArrayEntry);\n\t\tif (!a) break;\n\t\ta->obu = gf_malloc((size_t)obu_size);\n\t\tif (!a->obu) {\n\t\t\tgf_free(a);\n\t\t\tbreak;\n\t\t}\n\t\tgf_bs_seek(bs, pos);\n\t\tgf_bs_read_data(bs, (char *) a->obu, (u32)obu_size);\n\t\ta->obu_length = obu_size;\n\t\ta->obu_type = obu_type;\n\t\tgf_list_add(cfg->obu_array, a);\n\n\t\tif (size<obu_size) {\n\t\t\tGF_LOG(GF_LOG_WARNING, GF_LOG_CONTAINER, (\"[AV1] AV1 config misses %d bytes to fit the entire OBU\\n\", obu_size - size));\n\t\t\tbreak;\n\t\t}\n\t\tsize -= (u32) obu_size;\n\t}\n\tgf_av1_reset_state(& state, GF_TRUE);\n\treturn cfg;\n#else\n\treturn NULL;\n#endif\n}",
        "func_hash": 270972574846681061752900592460657064315,
        "file_name": "descriptors.c",
        "file_hash": 100253523943266503998746709370742625478,
        "cwe": [
            "CWE-415"
        ],
        "cve": "CVE-2021-40571",
        "cve_desc": "The binary MP4Box in Gpac 1.0.1 has a double-free vulnerability in the ilst_box_read function in box_code_apple.c, which allows attackers to cause a denial of service, even code execution and escalation of privileges.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-40571",
        "func_name": "gf_odf_av1_cfg_read_bs_size",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195082,
        "project": "linux",
        "commit_id": "c7dfa4009965a9b2d7b329ee970eb8da0d32f0bc",
        "project_url": "https://github.com/torvalds/linux",
        "commit_url": "https://github.com/torvalds/linux/commit/c7dfa4009965a9b2d7b329ee970eb8da0d32f0bc",
        "commit_message": "KVM: nSVM: always intercept VMLOAD/VMSAVE when nested (CVE-2021-3656)\n\nIf L1 disables VMLOAD/VMSAVE intercepts, and doesn't enable\nVirtual VMLOAD/VMSAVE (currently not supported for the nested hypervisor),\nthen VMLOAD/VMSAVE must operate on the L1 physical memory, which is only\npossible by making L0 intercept these instructions.\n\nFailure to do so allowed the nested guest to run VMLOAD/VMSAVE unintercepted,\nand thus read/write portions of the host physical memory.\n\nFixes: 89c8a4984fc9 (\"KVM: SVM: Enable Virtual VMLOAD VMSAVE feature\")\n\nSuggested-by: Paolo Bonzini <pbonzini@redhat.com>\nSigned-off-by: Maxim Levitsky <mlevitsk@redhat.com>\nSigned-off-by: Paolo Bonzini <pbonzini@redhat.com>",
        "target": 1,
        "irrelevant": 0,
        "func_before": "void recalc_intercepts(struct vcpu_svm *svm)\n{\n\tstruct vmcb_control_area *c, *h, *g;\n\tunsigned int i;\n\n\tvmcb_mark_dirty(svm->vmcb, VMCB_INTERCEPTS);\n\n\tif (!is_guest_mode(&svm->vcpu))\n\t\treturn;\n\n\tc = &svm->vmcb->control;\n\th = &svm->vmcb01.ptr->control;\n\tg = &svm->nested.ctl;\n\n\tfor (i = 0; i < MAX_INTERCEPT; i++)\n\t\tc->intercepts[i] = h->intercepts[i];\n\n\tif (g->int_ctl & V_INTR_MASKING_MASK) {\n\t\t/* We only want the cr8 intercept bits of L1 */\n\t\tvmcb_clr_intercept(c, INTERCEPT_CR8_READ);\n\t\tvmcb_clr_intercept(c, INTERCEPT_CR8_WRITE);\n\n\t\t/*\n\t\t * Once running L2 with HF_VINTR_MASK, EFLAGS.IF does not\n\t\t * affect any interrupt we may want to inject; therefore,\n\t\t * interrupt window vmexits are irrelevant to L0.\n\t\t */\n\t\tvmcb_clr_intercept(c, INTERCEPT_VINTR);\n\t}\n\n\t/* We don't want to see VMMCALLs from a nested guest */\n\tvmcb_clr_intercept(c, INTERCEPT_VMMCALL);\n\n\tfor (i = 0; i < MAX_INTERCEPT; i++)\n\t\tc->intercepts[i] |= g->intercepts[i];\n\n\t/* If SMI is not intercepted, ignore guest SMI intercept as well  */\n\tif (!intercept_smi)\n\t\tvmcb_clr_intercept(c, INTERCEPT_SMI);\n}",
        "func_hash": 308018010909685377463219146239861290533,
        "file_name": "None",
        "file_hash": null,
        "cwe": [
            "CWE-862"
        ],
        "cve": "CVE-2021-3656",
        "cve_desc": "A flaw was found in the KVM's AMD code for supporting SVM nested virtualization. The flaw occurs when processing the VMCB (virtual machine control block) provided by the L1 guest to spawn/handle a nested guest (L2). Due to improper validation of the \"virt_ext\" field, this issue could allow a malicious L1 to disable both VMLOAD/VMSAVE intercepts and VLS (Virtual VMLOAD/VMSAVE) for the L2 guest. As a result, the L2 guest would be allowed to read/write physical pages of the host, resulting in a crash of the entire system, leak of sensitive data or potential guest-to-host escape.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-3656",
        "func_name": "recalc_intercepts",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195083,
        "project": "tensorflow",
        "commit_id": "5b491cd5e41ad63735161cec9c2a568172c8b6a3",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/5b491cd5e41ad63735161cec9c2a568172c8b6a3",
        "commit_message": "Validate `proto.dtype()` before calling `set_dtype()`.\n\nThis prevents a `DCHECK`-fail when the proto contains an invalid dtype for a tensor shape with 0 elements or for an incomplete tensor shape.\n\nPiperOrigin-RevId: 408369083\nChange-Id: Ia21a3e3d62a90d642a4561f08f3b543e5ad00c46",
        "target": 1,
        "irrelevant": 0,
        "func_before": "bool Tensor::FromProto(Allocator* a, const TensorProto& proto) {\n  CHECK_NOTNULL(a);\n  TensorBuffer* p = nullptr;\n  if (!TensorShape::IsValid(proto.tensor_shape())) return false;\n  if (proto.dtype() == DT_INVALID) return false;\n  TensorShape shape(proto.tensor_shape());\n  const int64_t N = shape.num_elements();\n  if (N > 0 && proto.dtype()) {\n    bool dtype_error = false;\n    if (!proto.tensor_content().empty()) {\n      const auto& content = proto.tensor_content();\n      CASES_WITH_DEFAULT(proto.dtype(), p = Helper<T>::Decode(a, content, N),\n                         dtype_error = true, dtype_error = true);\n    } else {\n      CASES_WITH_DEFAULT(proto.dtype(), p = FromProtoField<T>(a, proto, N),\n                         dtype_error = true, dtype_error = true);\n    }\n    if (dtype_error || p == nullptr) return false;\n  }\n  shape_ = shape;\n  set_dtype(proto.dtype());\n  UnrefIfNonNull(buf_);\n  buf_ = p;\n  // TODO(misard) add tracking of which kernels and steps are calling\n  // FromProto.\n  if (MemoryLoggingEnabled() && buf_ != nullptr && buf_->data() != nullptr) {\n    LogMemory::RecordTensorAllocation(\"Unknown (from Proto)\",\n                                      LogMemory::UNKNOWN_STEP_ID, *this);\n  }\n  return true;\n}",
        "func_hash": 112719252128622113589892906952570683457,
        "file_name": "tensor.cc",
        "file_hash": 289613009517546867193769314060658742037,
        "cwe": [
            "CWE-617"
        ],
        "cve": "CVE-2022-23571",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. When decoding a tensor from protobuf, a TensorFlow process can encounter cases where a `CHECK` assertion is invalidated based on user controlled arguments, if the tensors have an invalid `dtype` and 0 elements or an invalid shape. This allows attackers to cause denial of services in TensorFlow processes. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23571",
        "func_name": "Tensor::FromProto",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195085,
        "project": "flatpak",
        "commit_id": "89ae9fe74c6d445bb1b3a40e568d77cf5de47e48",
        "project_url": "https://github.com/flatpak/flatpak",
        "commit_url": "https://github.com/flatpak/flatpak/commit/89ae9fe74c6d445bb1b3a40e568d77cf5de47e48",
        "commit_message": "run: Add cross-references for some other seccomp syscall filters\n\nSigned-off-by: Simon McVittie <smcv@collabora.com>",
        "target": 1,
        "irrelevant": 0,
        "func_before": "setup_seccomp (FlatpakBwrap   *bwrap,\n               const char     *arch,\n               gulong          allowed_personality,\n               FlatpakRunFlags run_flags,\n               GError        **error)\n{\n  gboolean multiarch = (run_flags & FLATPAK_RUN_FLAG_MULTIARCH) != 0;\n  gboolean devel = (run_flags & FLATPAK_RUN_FLAG_DEVEL) != 0;\n\n  __attribute__((cleanup (cleanup_seccomp))) scmp_filter_ctx seccomp = NULL;\n\n  /**** BEGIN NOTE ON CODE SHARING\n   *\n   * There are today a number of different Linux container\n   * implementations.  That will likely continue for long into the\n   * future.  But we can still try to share code, and it's important\n   * to do so because it affects what library and application writers\n   * can do, and we should support code portability between different\n   * container tools.\n   *\n   * This syscall blocklist is copied from linux-user-chroot, which was in turn\n   * clearly influenced by the Sandstorm.io blocklist.\n   *\n   * If you make any changes here, I suggest sending the changes along\n   * to other sandbox maintainers.  Using the libseccomp list is also\n   * an appropriate venue:\n   * https://groups.google.com/forum/#!forum/libseccomp\n   *\n   * A non-exhaustive list of links to container tooling that might\n   * want to share this blocklist:\n   *\n   *  https://github.com/sandstorm-io/sandstorm\n   *    in src/sandstorm/supervisor.c++\n   *  https://github.com/flatpak/flatpak.git\n   *    in common/flatpak-run.c\n   *  https://git.gnome.org/browse/linux-user-chroot\n   *    in src/setup-seccomp.c\n   *\n   **** END NOTE ON CODE SHARING\n   */\n  struct\n  {\n    int                  scall;\n    int                  errnum;\n    struct scmp_arg_cmp *arg;\n  } syscall_blocklist[] = {\n    /* Block dmesg */\n    {SCMP_SYS (syslog), EPERM},\n    /* Useless old syscall */\n    {SCMP_SYS (uselib), EPERM},\n    /* Don't allow disabling accounting */\n    {SCMP_SYS (acct), EPERM},\n    /* 16-bit code is unnecessary in the sandbox, and modify_ldt is a\n       historic source of interesting information leaks. */\n    {SCMP_SYS (modify_ldt), EPERM},\n    /* Don't allow reading current quota use */\n    {SCMP_SYS (quotactl), EPERM},\n\n    /* Don't allow access to the kernel keyring */\n    {SCMP_SYS (add_key), EPERM},\n    {SCMP_SYS (keyctl), EPERM},\n    {SCMP_SYS (request_key), EPERM},\n\n    /* Scary VM/NUMA ops */\n    {SCMP_SYS (move_pages), EPERM},\n    {SCMP_SYS (mbind), EPERM},\n    {SCMP_SYS (get_mempolicy), EPERM},\n    {SCMP_SYS (set_mempolicy), EPERM},\n    {SCMP_SYS (migrate_pages), EPERM},\n\n    /* Don't allow subnamespace setups: */\n    {SCMP_SYS (unshare), EPERM},\n    {SCMP_SYS (mount), EPERM},\n    {SCMP_SYS (pivot_root), EPERM},\n#if defined(__s390__) || defined(__s390x__) || defined(__CRIS__)\n    /* Architectures with CONFIG_CLONE_BACKWARDS2: the child stack\n     * and flags arguments are reversed so the flags come second */\n    {SCMP_SYS (clone), EPERM, &SCMP_A1 (SCMP_CMP_MASKED_EQ, CLONE_NEWUSER, CLONE_NEWUSER)},\n#else\n    /* Normally the flags come first */\n    {SCMP_SYS (clone), EPERM, &SCMP_A0 (SCMP_CMP_MASKED_EQ, CLONE_NEWUSER, CLONE_NEWUSER)},\n#endif\n\n    /* Don't allow faking input to the controlling tty (CVE-2017-5226) */\n    {SCMP_SYS (ioctl), EPERM, &SCMP_A1 (SCMP_CMP_MASKED_EQ, 0xFFFFFFFFu, (int) TIOCSTI)},\n  };\n\n  struct\n  {\n    int                  scall;\n    int                  errnum;\n    struct scmp_arg_cmp *arg;\n  } syscall_nondevel_blocklist[] = {\n    /* Profiling operations; we expect these to be done by tools from outside\n     * the sandbox.  In particular perf has been the source of many CVEs.\n     */\n    {SCMP_SYS (perf_event_open), EPERM},\n    /* Don't allow you to switch to bsd emulation or whatnot */\n    {SCMP_SYS (personality), EPERM, &SCMP_A0 (SCMP_CMP_NE, allowed_personality)},\n    {SCMP_SYS (ptrace), EPERM}\n  };\n  /* Blocklist all but unix, inet, inet6 and netlink */\n  struct\n  {\n    int             family;\n    FlatpakRunFlags flags_mask;\n  } socket_family_allowlist[] = {\n    /* NOTE: Keep in numerical order */\n    { AF_UNSPEC, 0 },\n    { AF_LOCAL, 0 },\n    { AF_INET, 0 },\n    { AF_INET6, 0 },\n    { AF_NETLINK, 0 },\n    { AF_CAN, FLATPAK_RUN_FLAG_CANBUS },\n    { AF_BLUETOOTH, FLATPAK_RUN_FLAG_BLUETOOTH },\n  };\n  int last_allowed_family;\n  int i, r;\n  g_auto(GLnxTmpfile) seccomp_tmpf  = { 0, };\n\n  seccomp = seccomp_init (SCMP_ACT_ALLOW);\n  if (!seccomp)\n    return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Initialize seccomp failed\"));\n\n  if (arch != NULL)\n    {\n      uint32_t arch_id = 0;\n      const uint32_t *extra_arches = NULL;\n\n      if (strcmp (arch, \"i386\") == 0)\n        {\n          arch_id = SCMP_ARCH_X86;\n        }\n      else if (strcmp (arch, \"x86_64\") == 0)\n        {\n          arch_id = SCMP_ARCH_X86_64;\n          extra_arches = seccomp_x86_64_extra_arches;\n        }\n      else if (strcmp (arch, \"arm\") == 0)\n        {\n          arch_id = SCMP_ARCH_ARM;\n        }\n#ifdef SCMP_ARCH_AARCH64\n      else if (strcmp (arch, \"aarch64\") == 0)\n        {\n          arch_id = SCMP_ARCH_AARCH64;\n          extra_arches = seccomp_aarch64_extra_arches;\n        }\n#endif\n\n      /* We only really need to handle arches on multiarch systems.\n       * If only one arch is supported the default is fine */\n      if (arch_id != 0)\n        {\n          /* This *adds* the target arch, instead of replacing the\n             native one. This is not ideal, because we'd like to only\n             allow the target arch, but we can't really disallow the\n             native arch at this point, because then bubblewrap\n             couldn't continue running. */\n          r = seccomp_arch_add (seccomp, arch_id);\n          if (r < 0 && r != -EEXIST)\n            return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to add architecture to seccomp filter\"));\n\n          if (multiarch && extra_arches != NULL)\n            {\n              for (i = 0; extra_arches[i] != 0; i++)\n                {\n                  r = seccomp_arch_add (seccomp, extra_arches[i]);\n                  if (r < 0 && r != -EEXIST)\n                    return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to add multiarch architecture to seccomp filter\"));\n                }\n            }\n        }\n    }\n\n  /* TODO: Should we filter the kernel keyring syscalls in some way?\n   * We do want them to be used by desktop apps, but they could also perhaps\n   * leak system stuff or secrets from other apps.\n   */\n\n  for (i = 0; i < G_N_ELEMENTS (syscall_blocklist); i++)\n    {\n      int scall = syscall_blocklist[i].scall;\n      int errnum = syscall_blocklist[i].errnum;\n\n      g_return_val_if_fail (errnum == EPERM || errnum == ENOSYS, FALSE);\n\n      if (syscall_blocklist[i].arg)\n        r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (errnum), scall, 1, *syscall_blocklist[i].arg);\n      else\n        r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (errnum), scall, 0);\n      if (r < 0 && r == -EFAULT /* unknown syscall */)\n        return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to block syscall %d\"), scall);\n    }\n\n  if (!devel)\n    {\n      for (i = 0; i < G_N_ELEMENTS (syscall_nondevel_blocklist); i++)\n        {\n          int scall = syscall_nondevel_blocklist[i].scall;\n          int errnum = syscall_nondevel_blocklist[i].errnum;\n\n          g_return_val_if_fail (errnum == EPERM || errnum == ENOSYS, FALSE);\n\n          if (syscall_nondevel_blocklist[i].arg)\n            r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (errnum), scall, 1, *syscall_nondevel_blocklist[i].arg);\n          else\n            r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (errnum), scall, 0);\n\n          if (r < 0 && r == -EFAULT /* unknown syscall */)\n            return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to block syscall %d\"), scall);\n        }\n    }\n\n  /* Socket filtering doesn't work on e.g. i386, so ignore failures here\n   * However, we need to user seccomp_rule_add_exact to avoid libseccomp doing\n   * something else: https://github.com/seccomp/libseccomp/issues/8 */\n  last_allowed_family = -1;\n  for (i = 0; i < G_N_ELEMENTS (socket_family_allowlist); i++)\n    {\n      int family = socket_family_allowlist[i].family;\n      int disallowed;\n\n      if (socket_family_allowlist[i].flags_mask != 0 &&\n          (socket_family_allowlist[i].flags_mask & run_flags) != socket_family_allowlist[i].flags_mask)\n        continue;\n\n      for (disallowed = last_allowed_family + 1; disallowed < family; disallowed++)\n        {\n          /* Blocklist the in-between valid families */\n          seccomp_rule_add_exact (seccomp, SCMP_ACT_ERRNO (EAFNOSUPPORT), SCMP_SYS (socket), 1, SCMP_A0 (SCMP_CMP_EQ, disallowed));\n        }\n      last_allowed_family = family;\n    }\n  /* Blocklist the rest */\n  seccomp_rule_add_exact (seccomp, SCMP_ACT_ERRNO (EAFNOSUPPORT), SCMP_SYS (socket), 1, SCMP_A0 (SCMP_CMP_GE, last_allowed_family + 1));\n\n  if (!glnx_open_anonymous_tmpfile_full (O_RDWR | O_CLOEXEC, \"/tmp\", &seccomp_tmpf, error))\n    return FALSE;\n\n  if (seccomp_export_bpf (seccomp, seccomp_tmpf.fd) != 0)\n    return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to export bpf\"));\n\n  lseek (seccomp_tmpf.fd, 0, SEEK_SET);\n\n  flatpak_bwrap_add_args_data_fd (bwrap,\n                                  \"--seccomp\", glnx_steal_fd (&seccomp_tmpf.fd), NULL);\n\n  return TRUE;\n}",
        "func_hash": 317270177478890809263706599611102789156,
        "file_name": "flatpak-run.c",
        "file_hash": 181541557775990000611012968168262998381,
        "cwe": [
            "CWE-20"
        ],
        "cve": "CVE-2021-41133",
        "cve_desc": "Flatpak is a system for building, distributing, and running sandboxed desktop applications on Linux. In versions prior to 1.10.4 and 1.12.0, Flatpak apps with direct access to AF_UNIX sockets such as those used by Wayland, Pipewire or pipewire-pulse can trick portals and other host-OS services into treating the Flatpak app as though it was an ordinary, non-sandboxed host-OS process. They can do this by manipulating the VFS using recent mount-related syscalls that are not blocked by Flatpak's denylist seccomp filter, in order to substitute a crafted `/.flatpak-info` or make that file disappear entirely. Flatpak apps that act as clients for AF_UNIX sockets such as those used by Wayland, Pipewire or pipewire-pulse can escalate the privileges that the corresponding services will believe the Flatpak app has. Note that protocols that operate entirely over the D-Bus session bus (user bus), system bus or accessibility bus are not affected by this. This is due to the use of a proxy process `xdg-dbus-proxy`, whose VFS cannot be manipulated by the Flatpak app, when interacting with these buses. Patches exist for versions 1.10.4 and 1.12.0, and as of time of publication, a patch for version 1.8.2 is being planned. There are no workarounds aside from upgrading to a patched version.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-41133",
        "func_name": "setup_seccomp",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195091,
        "project": "tensorflow",
        "commit_id": "35f0fabb4c178253a964d7aabdbb15c6a398b69a",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/35f0fabb4c178253a964d7aabdbb15c6a398b69a",
        "commit_message": "Avoid Segfault for scalar shapes.\n\nCalling tensor::FromElementsOp with an empty vector of elements and no type\ncauses a segfault. We need to let the FromElementsOp know which scalar type it\nshould have.\nAlso add back the DynamicBroadcastInDimOp canonicalization patterns, which\npreviously prevented this bug from happening.\nAdd a regression test that demonstrates the bug.\n\nPiperOrigin-RevId: 417561444\nChange-Id: I6d1d6cfb71aabbad6102422625a00bbe253ac95a",
        "target": 1,
        "irrelevant": 0,
        "func_before": "llvm::Optional<Value> simplifyBroadcast(ShapeComponentAnalysis& analysis,\n                                        ValueRange shapes, Location loc,\n                                        OpBuilder* builder) {\n  // First find the input shape with the largest rank.\n  SmallVector<ArrayRef<ShapeComponentAnalysis::SymbolicExpr>> shapes_found;\n  size_t maxRank = 0;\n  for (const auto &shape : llvm::enumerate(shapes)) {\n    auto found_shape = analysis.GetValueInfo(shape.value());\n    if (!found_shape) return {};\n    shapes_found.push_back(*found_shape);\n    maxRank = std::max(maxRank, found_shape->size());\n  }\n\n  SmallVector<const ShapeComponentAnalysis::SymbolicExpr*> joined_dimensions(\n      maxRank);\n  SmallVector<std::pair<Value, int64_t>> shape_and_rank_for_dim(maxRank);\n  for (const auto &shape : llvm::enumerate(shapes_found)) {\n    for (const auto &dim : llvm::enumerate(llvm::reverse(shape.value()))) {\n      // 1 dimensions don't contribute to the final result.\n      if (dim.value().isConstant(1)) continue;\n      // If it's not a 1 dimension it will be present in the result. Remember\n      // where it came from.\n      auto index = maxRank - dim.index() - 1;\n      if (!joined_dimensions[index]) {\n        joined_dimensions[index] = &dim.value();\n        shape_and_rank_for_dim[index] =\n            std::make_pair(shapes[shape.index()], shape.value().size());\n        continue;\n      }\n      // Bail if the dimensions are neither equal nor 1.\n      if (*joined_dimensions[index] != dim.value()) return {};\n    }\n  }\n  // If the output is the same as one of the inputs just return that.\n  if (llvm::is_splat(shape_and_rank_for_dim) &&\n      shape_and_rank_for_dim[0].first) {\n    return shape_and_rank_for_dim[0].first;\n  }\n  // Otherwise rematerialize the shape from the pieces we have.\n  SmallVector<Value> elements;\n  for (int i = 0; i != maxRank; ++i) {\n    // 1 dimensions are filtered above, recreate the constant.\n    if (!shape_and_rank_for_dim[i].first) {\n      auto one = builder->getIntegerAttr(\n          shapes[0].getType().cast<RankedTensorType>().getElementType(), 1);\n      elements.push_back(builder->create<ConstantOp>(loc, one));\n      continue;\n    }\n    // Extract from one of the shapes, accounting for the reverse indexing\n    // performed by broadcast.\n    Value index = builder->create<ConstantIndexOp>(\n        loc, i - maxRank + shape_and_rank_for_dim[i].second);\n    elements.push_back(builder->create<tensor::ExtractOp>(\n        loc, shape_and_rank_for_dim[i].first, index));\n  }\n  return Value(builder->create<tensor::FromElementsOp>(loc, elements));\n}",
        "func_hash": 84683486121098934971147990908524528886,
        "file_name": "tf_cpurt_symbolic_shape_optimization.cc",
        "file_hash": 183860206963562900623001205261417288221,
        "cwe": [
            "CWE-754"
        ],
        "cve": "CVE-2022-23593",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The `simplifyBroadcast` function in the MLIR-TFRT infrastructure in TensorFlow is vulnerable to a segfault (hence, denial of service), if called with scalar shapes. If all shapes are scalar, then `maxRank` is 0, so we build an empty `SmallVector`. The fix will be included in TensorFlow 2.8.0. This is the only affected version.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23593",
        "func_name": "simplifyBroadcast",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195092,
        "project": "hermes",
        "commit_id": "55e1b2343f4deb1a1b5726cfe1e23b2068217ff2",
        "project_url": "https://github.com/facebook/hermes",
        "commit_url": "https://github.com/facebook/hermes/commit/55e1b2343f4deb1a1b5726cfe1e23b2068217ff2",
        "commit_message": "Handle typeof applied to empty in InstSimplify\n\nSummary:\nDo not simplify `typeof` if it is applied to an invalid type. This\nhandles a case like the one in the added test, where `typeof` is called\non a literal empty in unreachable code.\n\nReviewed By: kodafb\n\nDifferential Revision: D31000173\n\nfbshipit-source-id: 2d7f69cbcc9c1bb0a916585c07171089444c85dc",
        "target": 1,
        "irrelevant": 0,
        "func_before": "Literal *hermes::evalUnaryOperator(\n    UnaryOperatorInst::OpKind kind,\n    IRBuilder &builder,\n    Literal *operand) {\n  switch (kind) {\n    case UnaryOperatorInst::OpKind::MinusKind:\n      // Negate constant integers.\n      switch (operand->getKind()) {\n        case ValueKind::LiteralNumberKind:\n          if (auto *literalNum = llvh::dyn_cast<LiteralNumber>(operand)) {\n            auto V = -literalNum->getValue();\n            return builder.getLiteralNumber(V);\n          }\n          break;\n        case ValueKind::LiteralUndefinedKind:\n          return builder.getLiteralNaN();\n        case ValueKind::LiteralBoolKind:\n          if (evalIsTrue(builder, operand)) {\n            return builder.getLiteralNumber(-1);\n          } else { // evalIsFalse(operand)\n            return builder.getLiteralNegativeZero();\n          }\n        case ValueKind::LiteralNullKind:\n          return builder.getLiteralNegativeZero();\n        default:\n          break;\n      }\n      break;\n    case UnaryOperatorInst::OpKind::TypeofKind:\n      switch (operand->getKind()) {\n        case ValueKind::GlobalObjectKind:\n        case ValueKind::LiteralNullKind:\n          return builder.getLiteralString(\"object\");\n        case ValueKind::LiteralUndefinedKind:\n          return builder.getLiteralString(\"undefined\");\n        case ValueKind::LiteralBoolKind:\n          return builder.getLiteralString(\"boolean\");\n        case ValueKind::LiteralNumberKind:\n          return builder.getLiteralString(\"number\");\n        case ValueKind::LiteralStringKind:\n          return builder.getLiteralString(\"string\");\n        default:\n          llvm_unreachable(\"Invalid literal kind.\");\n      }\n      break;\n\n    case UnaryOperatorInst::OpKind::BangKind:\n      if (evalIsTrue(builder, operand)) {\n        return builder.getLiteralBool(false);\n      }\n      if (evalIsFalse(builder, operand)) {\n        return builder.getLiteralBool(true);\n      }\n      break;\n\n    case UnaryOperatorInst::OpKind::VoidKind:\n      return builder.getLiteralUndefined();\n\n    default:\n      break;\n  }\n\n  return nullptr;\n}",
        "func_hash": 318397569222892175642900890058916302083,
        "file_name": "IREval.cpp",
        "file_hash": 25640608993938735880507555687030796129,
        "cwe": [
            "CWE-843"
        ],
        "cve": "CVE-2021-24045",
        "cve_desc": "A type confusion vulnerability could be triggered when resolving the \"typeof\" unary operator in Facebook Hermes prior to v0.10.0. Note that this is only exploitable if the application using Hermes permits evaluation of untrusted JavaScript. Hence, most React Native applications are not affected.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-24045",
        "func_name": "hermes::evalUnaryOperator",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195095,
        "project": "e2guardian",
        "commit_id": "eae46a7e2a57103aadca903c4a24cca94dc502a2",
        "project_url": "https://github.com/e2guardian/e2guardian",
        "commit_url": "https://github.com/e2guardian/e2guardian/commit/eae46a7e2a57103aadca903c4a24cca94dc502a2",
        "commit_message": "Fix bug #707 cert hostnames not being checked\n- only happened when openssl v1.1 is used",
        "target": 1,
        "irrelevant": 1,
        "func_before": "int Socket::startSslClient(const std::string &certificate_path, String hostname)\n{\n    if (isssl) {\n        stopSsl();\n    }\n\n    ERR_clear_error();\n#if OPENSSL_VERSION_NUMBER < 0x10100000L\n    ctx = SSL_CTX_new(SSLv23_client_method());\n#else\n    ctx = SSL_CTX_new(TLS_client_method());\n#endif\n\n    if (ctx == NULL) {\n#ifdef NETDEBUG\n        std::cout << thread_id << \"Error ssl context is null (check that openssl has been inited)\" << std::endl;\n#endif\n        log_ssl_errors(\"Error ssl context is null for %s\", hostname.c_str());\n        return -1;\n    }\n\n    //set the timeout for the ssl session\n    if (SSL_CTX_set_timeout(ctx, 130l) < 1) {\n            SSL_CTX_free(ctx);\n            ctx = NULL;\n        return -1;\n    }\n\n    //load certs\n    ERR_clear_error();\n    if (certificate_path.length()) {\n        if (!SSL_CTX_load_verify_locations(ctx, NULL, certificate_path.c_str())) {\n#ifdef NETDEBUG\n            std::cout << thread_id << \"couldnt load certificates\" << std::endl;\n#endif\n            log_ssl_errors(\"couldnt load certificates from %s\", certificate_path.c_str());\n            //tidy up\n            SSL_CTX_free(ctx);\n            ctx = NULL;\n            return -2;\n        }\n    } else if (!SSL_CTX_set_default_verify_paths(ctx)) //use default if no certPpath given\n    {\n#ifdef NETDEBUG\n        std::cout << thread_id << \"couldnt load certificates\" << std::endl;\n#endif\n            log_ssl_errors(\"couldnt load default certificates for %s\", hostname.c_str());\n        //tidy up\n        SSL_CTX_free(ctx);\n        ctx = NULL;\n        return -2;\n    }\n\n    // add validation params\n    ERR_clear_error();\n    X509_VERIFY_PARAM *x509_param = X509_VERIFY_PARAM_new();\n    if (!x509_param) {\n        log_ssl_errors(\"couldnt add validation params for %s\", hostname.c_str());\n        //X509_VERIFY_PARAM_free(x509_param);\n            SSL_CTX_free(ctx);\n            ctx = NULL;\n        return -2;\n    }\n\n    ERR_clear_error();\n    if (!X509_VERIFY_PARAM_set_flags(x509_param, X509_V_FLAG_TRUSTED_FIRST)) {\n        log_ssl_errors(\"couldnt add validation params for %s\", hostname.c_str());\n        X509_VERIFY_PARAM_free(x509_param);\n            SSL_CTX_free(ctx);\n            ctx = NULL;\n        return -2;\n    }\n\n    ERR_clear_error();\n    if (!SSL_CTX_set1_param(ctx, x509_param)) {\n        log_ssl_errors(\"couldnt add validation params for %s\", hostname.c_str());\n        X509_VERIFY_PARAM_free(x509_param);\n            SSL_CTX_free(ctx);\n            ctx = NULL;\n        return -2;\n    }\n\n    X509_VERIFY_PARAM_free(x509_param);     // try not freeing this as SSL_CTX_free seems to be ring to free it\n\n    //hand socket over to ssl lib\n    ERR_clear_error();\n    ssl = SSL_new(ctx);\n    SSL_set_options(ssl, SSL_OP_ALL);\n    SSL_set_mode(ssl, SSL_MODE_AUTO_RETRY);\n    SSL_set_connect_state(ssl);\n\n    //fcntl(this->getFD() ,F_SETFL, O_NONBLOCK); // blocking mode used currently\n    SSL_set_fd(ssl, this->getFD());\n    SSL_set_tlsext_host_name(ssl, hostname.c_str());\n\n    //make io non blocking as select wont tell us if we can do a read without blocking\n    //BIO_set_nbio(SSL_get_rbio(ssl),1l);  // blocking mode used currently\n    //BIO_set_nbio(SSL_get_wbio(ssl),1l); // blocking mode used currently\n    ERR_clear_error();\n    int rc = SSL_connect(ssl);\n    if (rc < 0) {\n        log_ssl_errors(\"ssl_connect failed to %s\", hostname.c_str());\n#ifdef NETDEBUG\n        std::cout << thread_id << \"ssl_connect failed with error \" << SSL_get_error(ssl, rc) << std::endl;\n#endif\n        // tidy up\n        SSL_free(ssl);\n        ssl = NULL;\n        SSL_CTX_free(ctx);\n        ctx = NULL;\n        return -3;\n    }\n\n    //should be safer to do this last as nothing will ever try to use a ssl socket that isnt fully setup\n    isssl = true;\n    issslserver = false;\n    return 0;\n}",
        "func_hash": 285364534121786496260977042144971081331,
        "file_name": "Socket.cpp",
        "file_hash": 283084154597152068392957992825637904487,
        "cwe": [
            "CWE-295"
        ],
        "cve": "CVE-2021-44273",
        "cve_desc": "e2guardian v5.4.x <= v5.4.3r is affected by missing SSL certificate validation in the SSL MITM engine. In standalone mode (i.e., acting as a proxy or a transparent proxy), with SSL MITM enabled, e2guardian, if built with OpenSSL v1.1.x, did not validate hostnames in certificates of the web servers that it connected to, and thus was itself vulnerable to MITM attacks.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-44273",
        "func_name": "Socket::startSslClient",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195216,
        "project": "tensorflow",
        "commit_id": "3d89911481ba6ebe8c88c1c0b595412121e6c645",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/3d89911481ba6ebe8c88c1c0b595412121e6c645",
        "commit_message": "Eliminate `CHECK`-fail from `function.cc`.\n\nPiperOrigin-RevId: 409414744\nChange-Id: Ic854e12ab2edb88b165d32e2d632c4ee654d71ad",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  Status BuildInputArgIndex(const OpDef::ArgDef& arg_def, AttrSlice attr_values,\n                            const FunctionDef::ArgAttrs* arg_attrs,\n                            bool ints_on_device,\n                            int64_t resource_arg_unique_id) {\n    bool is_type_list;\n    DataTypeVector dtypes;\n    TF_RETURN_IF_ERROR(\n        ArgNumType(attr_values, arg_def, &is_type_list, &dtypes));\n    CHECK_GE(dtypes.size(), size_t{1});\n    int arg_index = result_.nodes.size();\n    TF_RETURN_IF_ERROR(\n        AddItem(arg_def.name(), {true, arg_index, 0, is_type_list, dtypes}));\n    // Creates dtypes.size() nodes in the graph.\n    for (size_t i = 0; i < dtypes.size(); ++i) {\n      TF_RETURN_IF_ERROR(AddItem(strings::StrCat(arg_def.name(), \":\", i),\n                                 {true, arg_index, 0, false, {dtypes[i]}}));\n      DCHECK_EQ(arg_index, result_.nodes.size());\n      string name = arg_def.name();\n      if (dtypes.size() > 1) {\n        strings::StrAppend(&name, \"_\", i);\n      }\n      NodeDef* gnode = AddNode(name);\n      if (ints_on_device && dtypes[i] == DataType::DT_INT32) {\n        gnode->set_op(FunctionLibraryDefinition::kDeviceArgOp);\n      } else {\n        gnode->set_op(FunctionLibraryDefinition::kArgOp);\n      }\n      DataType dtype = arg_def.is_ref() ? MakeRefType(dtypes[i]) : dtypes[i];\n      AddAttr(\"T\", dtype, gnode);\n      AddAttr(\"index\", arg_index, gnode);\n      if (resource_arg_unique_id >= 0) {\n        AddAttr(\"_resource_arg_unique_id\", resource_arg_unique_id, gnode);\n      }\n      if (arg_attrs) {\n        for (const auto& arg_attr : arg_attrs->attr()) {\n          AddAttr(arg_attr.first, arg_attr.second, gnode->mutable_attr());\n        }\n      }\n      result_.arg_types.push_back(dtypes[i]);\n      ++arg_index;\n    }\n    return Status::OK();\n  }",
        "func_hash": 195029536653628646842978253954389653589,
        "file_name": "function.cc",
        "file_hash": 203653418997522182482043276556638340074,
        "cwe": [
            "CWE-617"
        ],
        "cve": "CVE-2022-23586",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. A malicious user can cause a denial of service by altering a `SavedModel` such that assertions in `function.cc` would be falsified and crash the Python interpreter. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23586",
        "func_name": "BuildInputArgIndex",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195218,
        "project": "mruby",
        "commit_id": "0849a2885f81cfd82134992c06df3ccd59052ac7",
        "project_url": "https://github.com/mruby/mruby",
        "commit_url": "https://github.com/mruby/mruby/commit/0849a2885f81cfd82134992c06df3ccd59052ac7",
        "commit_message": "codegen.c: stack position may be wrong on assignments.\n\nWhen `[]=` access includes keyword arguments.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "gen_assignment(codegen_scope *s, node *tree, node *rhs, int sp, int val)\n{\n  int idx;\n  int type = nint(tree->car);\n\n  switch (type) {\n  case NODE_GVAR:\n  case NODE_ARG:\n  case NODE_LVAR:\n  case NODE_IVAR:\n  case NODE_CVAR:\n  case NODE_CONST:\n  case NODE_NIL:\n  case NODE_MASGN:\n    if (rhs) {\n      codegen(s, rhs, VAL);\n      pop();\n      sp = cursp();\n    }\n    break;\n\n  case NODE_COLON2:\n  case NODE_CALL:\n  case NODE_SCALL:\n    /* keep evaluation order */\n    break;\n\n  case NODE_NVAR:\n    codegen_error(s, \"Can't assign to numbered parameter\");\n    break;\n\n  default:\n    codegen_error(s, \"unknown lhs\");\n    break;\n  }\n\n  tree = tree->cdr;\n  switch (type) {\n  case NODE_GVAR:\n    gen_setxv(s, OP_SETGV, sp, nsym(tree), val);\n    break;\n  case NODE_ARG:\n  case NODE_LVAR:\n    idx = lv_idx(s, nsym(tree));\n    if (idx > 0) {\n      if (idx != sp) {\n        gen_move(s, idx, sp, val);\n      }\n      break;\n    }\n    else {                      /* upvar */\n      gen_setupvar(s, sp, nsym(tree));\n    }\n    break;\n  case NODE_IVAR:\n    gen_setxv(s, OP_SETIV, sp, nsym(tree), val);\n    break;\n  case NODE_CVAR:\n    gen_setxv(s, OP_SETCV, sp, nsym(tree), val);\n    break;\n  case NODE_CONST:\n    gen_setxv(s, OP_SETCONST, sp, nsym(tree), val);\n    break;\n  case NODE_COLON2:\n    if (sp) {\n      gen_move(s, cursp(), sp, 0);\n    }\n    sp = cursp();\n    push();\n    codegen(s, tree->car, VAL);\n    if (rhs) {\n      codegen(s, rhs, VAL); pop();\n      gen_move(s, sp, cursp(), 0);\n    }\n    pop_n(2);\n    idx = new_sym(s, nsym(tree->cdr));\n    genop_2(s, OP_SETMCNST, sp, idx);\n    break;\n\n  case NODE_CALL:\n  case NODE_SCALL:\n    {\n      int noself = 0, safe = (type == NODE_SCALL), skip = 0, top, call, n = 0;\n      mrb_sym mid = nsym(tree->cdr->car);\n\n      top = cursp();\n      if (val || sp == cursp()) {\n        push();                   /* room for retval */\n      }\n      call = cursp();\n      if (!tree->car) {\n        noself = 1;\n        push();\n      }\n      else {\n        codegen(s, tree->car, VAL); /* receiver */\n      }\n      if (safe) {\n        int recv = cursp()-1;\n        gen_move(s, cursp(), recv, 1);\n        skip = genjmp2_0(s, OP_JMPNIL, cursp(), val);\n      }\n      tree = tree->cdr->cdr->car;\n      if (tree) {\n        if (tree->car) {            /* positional arguments */\n          n = gen_values(s, tree->car, VAL, (tree->cdr->car)?13:14);\n          if (n < 0) {              /* variable length */\n            n = 15;\n            push();\n          }\n        }\n        if (tree->cdr->car) {       /* keyword arguments */\n          gen_hash(s, tree->cdr->car->cdr, VAL, 0);\n          if (n < 14) {\n            n++;\n            push();\n          }\n          else {\n            pop();\n            genop_2(s, OP_ARYPUSH, cursp(), 1);\n          }\n        }\n      }\n      if (rhs) {\n        codegen(s, rhs, VAL);\n        pop();\n      }\n      else {\n        gen_move(s, cursp(), sp, 0);\n      }\n      if (val) {\n        gen_move(s, top, cursp(), 1);\n      }\n      if (n < 14) {\n        n++;\n      }\n      else {\n        pop();\n        genop_2(s, OP_ARYPUSH, cursp(), 1);\n      }\n      s->sp = call;\n      if (mid == MRB_OPSYM_2(s->mrb, aref) && n == 2) {\n        genop_1(s, OP_SETIDX, cursp());\n      }\n      else {\n        genop_3(s, noself ? OP_SSEND : OP_SEND, cursp(), new_sym(s, attrsym(s, mid)), n);\n      }\n      if (safe) {\n        dispatch(s, skip);\n      }\n      s->sp = top;\n    }\n    break;\n\n  case NODE_MASGN:\n    gen_vmassignment(s, tree->car, sp, val);\n    break;\n\n  /* splat without assignment */\n  case NODE_NIL:\n    break;\n\n  default:\n    codegen_error(s, \"unknown lhs\");\n    break;\n  }\n  if (val) push();\n}",
        "func_hash": 12667856709713500812869636396145269639,
        "file_name": "codegen.c",
        "file_hash": 19439930809958148904555588093451410064,
        "cwe": [
            "CWE-125"
        ],
        "cve": "CVE-2022-0525",
        "cve_desc": "Out-of-bounds Read in Homebrew mruby prior to 3.2.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-0525",
        "func_name": "gen_assignment",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195220,
        "project": "tmate-ssh-server",
        "commit_id": "1c020d1f5ca462f5b150b46a027aaa1bbe3c9596",
        "project_url": "https://github.com/tmate-io/tmate-ssh-server",
        "commit_url": "https://github.com/tmate-io/tmate-ssh-server/commit/1c020d1f5ca462f5b150b46a027aaa1bbe3c9596",
        "commit_message": "Harden /tmp/tmate directory\n\nSuggested by Matthias Gerstner",
        "target": 1,
        "irrelevant": 0,
        "func_before": "int main(int argc, char **argv, char **envp)\n{\n\tint opt;\n\n\twhile ((opt = getopt(argc, argv, \"b:h:k:p:q:w:z:xv\")) != -1) {\n\t\tswitch (opt) {\n\t\tcase 'b':\n\t\t\ttmate_settings->bind_addr = xstrdup(optarg);\n\t\t\tbreak;\n\t\tcase 'h':\n\t\t\ttmate_settings->tmate_host = xstrdup(optarg);\n\t\t\tbreak;\n\t\tcase 'k':\n\t\t\ttmate_settings->keys_dir = xstrdup(optarg);\n\t\t\tbreak;\n\t\tcase 'p':\n\t\t\ttmate_settings->ssh_port = atoi(optarg);\n\t\t\tbreak;\n\t\tcase 'q':\n\t\t\ttmate_settings->ssh_port_advertized = atoi(optarg);\n\t\t\tbreak;\n\t\tcase 'w':\n\t\t\ttmate_settings->websocket_hostname = xstrdup(optarg);\n\t\t\tbreak;\n\t\tcase 'z':\n\t\t\ttmate_settings->websocket_port = atoi(optarg);\n\t\t\tbreak;\n\t\tcase 'x':\n\t\t\ttmate_settings->use_proxy_protocol = true;\n\t\t\tbreak;\n\t\tcase 'v':\n\t\t\ttmate_settings->log_level++;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tusage();\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\tinit_logging(tmate_settings->log_level);\n\n\tsetup_locale();\n\n\tif (!tmate_settings->tmate_host)\n\t\ttmate_settings->tmate_host = get_full_hostname();\n\n\tcmdline = *argv;\n\tcmdline_end = *envp;\n\n\ttmate_preload_trace_lib();\n\ttmate_catch_sigsegv();\n\ttmate_init_rand();\n\n\tif ((mkdir(TMATE_WORKDIR, 0701)             < 0 && errno != EEXIST) ||\n\t    (mkdir(TMATE_WORKDIR \"/sessions\", 0703) < 0 && errno != EEXIST) ||\n\t    (mkdir(TMATE_WORKDIR \"/jail\", 0700)     < 0 && errno != EEXIST))\n\t\ttmate_fatal(\"Cannot prepare session in \" TMATE_WORKDIR);\n\n\t/* The websocket server needs to access the /session dir to rename sockets */\n\tif ((chmod(TMATE_WORKDIR, 0701)             < 0) ||\n\t    (chmod(TMATE_WORKDIR \"/sessions\", 0703) < 0) ||\n\t    (chmod(TMATE_WORKDIR \"/jail\", 0700)     < 0))\n\t\ttmate_fatal(\"Cannot prepare session in \" TMATE_WORKDIR);\n\n\ttmate_ssh_server_main(tmate_session,\n\t\t\t      tmate_settings->keys_dir, tmate_settings->bind_addr, tmate_settings->ssh_port);\n\treturn 0;\n}",
        "func_hash": 154027151645284385944526585123822701001,
        "file_name": "tmate-main.c",
        "file_hash": 280350825550794138629823084137678566150,
        "cwe": [
            "CWE-362"
        ],
        "cve": "CVE-2021-44512",
        "cve_desc": "World-writable permissions on the /tmp/tmate/sessions directory in tmate-ssh-server 2.3.0 allow a local attacker to compromise the integrity of session handling, or obtain the read-write session ID from a read-only session symlink in this directory.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-44512",
        "func_name": "main",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195230,
        "project": "pjproject",
        "commit_id": "f74c1fc22b760d2a24369aa72c74c4a9ab985859",
        "project_url": "https://github.com/pjsip/pjproject",
        "commit_url": "https://github.com/pjsip/pjproject/commit/f74c1fc22b760d2a24369aa72c74c4a9ab985859",
        "commit_message": "Merge pull request from GHSA-r374-qrwv-86hh",
        "target": 1,
        "irrelevant": 1,
        "func_before": "void pjmedia_rtcp_xr_rx_rtcp_xr( pjmedia_rtcp_xr_session *sess,\n\t\t\t\t const void *pkt,\n\t\t\t\t pj_size_t size)\n{\n    const pjmedia_rtcp_xr_pkt\t      *rtcp_xr = (pjmedia_rtcp_xr_pkt*) pkt;\n    const pjmedia_rtcp_xr_rb_rr_time  *rb_rr_time = NULL;\n    const pjmedia_rtcp_xr_rb_dlrr     *rb_dlrr = NULL;\n    const pjmedia_rtcp_xr_rb_stats    *rb_stats = NULL;\n    const pjmedia_rtcp_xr_rb_voip_mtc *rb_voip_mtc = NULL;\n    const pjmedia_rtcp_xr_rb_header   *rb_hdr = (pjmedia_rtcp_xr_rb_header*) \n\t\t\t\t\t\trtcp_xr->buf;\n    unsigned pkt_len, rb_len;\n\n    if (rtcp_xr->common.pt != RTCP_XR)\n\treturn;\n\n    pkt_len = pj_ntohs((pj_uint16_t)rtcp_xr->common.length);\n\n    if ((pkt_len + 1) > (size / 4))\n\treturn;\n\n    /* Parse report rpt_types */\n    while ((pj_int32_t*)rb_hdr < (pj_int32_t*)pkt + pkt_len)\n    {\t\n\trb_len = pj_ntohs((pj_uint16_t)rb_hdr->length);\n\n\t/* Just skip any block with length == 0 (no report content) */\n\tif (rb_len) {\n\t    switch (rb_hdr->bt) {\n\t\tcase BT_RR_TIME:\n\t\t    rb_rr_time = (pjmedia_rtcp_xr_rb_rr_time*) rb_hdr;\n\t\t    break;\n\t\tcase BT_DLRR:\n\t\t    rb_dlrr = (pjmedia_rtcp_xr_rb_dlrr*) rb_hdr;\n\t\t    break;\n\t\tcase BT_STATS:\n\t\t    rb_stats = (pjmedia_rtcp_xr_rb_stats*) rb_hdr;\n\t\t    break;\n\t\tcase BT_VOIP_METRICS:\n\t\t    rb_voip_mtc = (pjmedia_rtcp_xr_rb_voip_mtc*) rb_hdr;\n\t\t    break;\n\t\tdefault:\n\t\t    break;\n\t    }\n\t}\n\trb_hdr = (pjmedia_rtcp_xr_rb_header*)\n\t\t ((pj_int32_t*)rb_hdr + rb_len + 1);\n    }\n\n    /* Receiving RR Time */\n    if (rb_rr_time) {\n\t/* Save LRR from NTP timestamp of the RR time block report */\n\tsess->rx_lrr = ((pj_ntohl(rb_rr_time->ntp_sec) & 0x0000FFFF) << 16) | \n\t\t       ((pj_ntohl(rb_rr_time->ntp_frac) >> 16) & 0xFFFF);\n\n\t/* Calculate RR arrival time for DLRR */\n\tpj_get_timestamp(&sess->rx_lrr_time);\n\n\tTRACE_((sess->name, \"Rx RTCP SR: ntp_ts=%p\", sess->rx_lrr,\n\t       (pj_uint32_t)(sess->rx_lrr_time.u64*65536/\n\t\t\t     sess->rtcp_session->ts_freq.u64)));\n    }\n\n    /* Receiving DLRR */\n    if (rb_dlrr) {\n\tpj_uint32_t lrr, now, dlrr;\n\tpj_uint64_t eedelay;\n\tpjmedia_rtcp_ntp_rec ntp;\n\n\t/* LRR is the middle 32bit of NTP. It has 1/65536 second \n\t * resolution \n\t */\n\tlrr = pj_ntohl(rb_dlrr->item.lrr);\n\n\t/* DLRR is delay since LRR, also in 1/65536 resolution */\n\tdlrr = pj_ntohl(rb_dlrr->item.dlrr);\n\n\t/* Get current time, and convert to 1/65536 resolution */\n\tpjmedia_rtcp_get_ntp_time(sess->rtcp_session, &ntp);\n\tnow = ((ntp.hi & 0xFFFF) << 16) + (ntp.lo >> 16);\n\n\t/* End-to-end delay is (now-lrr-dlrr) */\n\teedelay = now - lrr - dlrr;\n\n\t/* Convert end to end delay to usec (keeping the calculation in\n         * 64bit space)::\n\t *   sess->ee_delay = (eedelay * 1000) / 65536;\n\t */\n\tif (eedelay < 4294) {\n\t    eedelay = (eedelay * 1000000) >> 16;\n\t} else {\n\t    eedelay = (eedelay * 1000) >> 16;\n\t    eedelay *= 1000;\n\t}\n\n\tTRACE_((sess->name, \"Rx RTCP XR DLRR: lrr=%p, dlrr=%p (%d:%03dms), \"\n\t\t\t   \"now=%p, rtt=%p\",\n\t\tlrr, dlrr, dlrr/65536, (dlrr%65536)*1000/65536,\n\t\tnow, (pj_uint32_t)eedelay));\n\t\n\t/* Only save calculation if \"now\" is greater than lrr, or\n\t * otherwise rtt will be invalid \n\t */\n\tif (now-dlrr >= lrr) {\n\t    unsigned rtt = (pj_uint32_t)eedelay;\n\t    \n\t    /* Check that eedelay value really makes sense. \n\t     * We allow up to 30 seconds RTT!\n\t     */\n\t    if (eedelay <= 30 * 1000 * 1000UL) {\n\t\t/* \"Normalize\" rtt value that is exceptionally high.\n\t\t * For such values, \"normalize\" the rtt to be three times\n\t\t * the average value.\n\t\t */\n\t\tif (rtt>((unsigned)sess->stat.rtt.mean*3) && sess->stat.rtt.n!=0)\n\t\t{\n\t\t    unsigned orig_rtt = rtt;\n\t\t    rtt = (unsigned)sess->stat.rtt.mean*3;\n\t\t    PJ_LOG(5,(sess->name, \n\t\t\t      \"RTT value %d usec is normalized to %d usec\",\n\t\t\t      orig_rtt, rtt));\n\t\t}\n    \t\n\t\tTRACE_((sess->name, \"RTCP RTT is set to %d usec\", rtt));\n\t\tpj_math_stat_update(&sess->stat.rtt, rtt);\n\t    }\n\t} else {\n\t    PJ_LOG(5, (sess->name, \"Internal RTCP NTP clock skew detected: \"\n\t\t\t\t   \"lrr=%p, now=%p, dlrr=%p (%d:%03dms), \"\n\t\t\t\t   \"diff=%d\",\n\t\t\t\t   lrr, now, dlrr, dlrr/65536,\n\t\t\t\t   (dlrr%65536)*1000/65536,\n\t\t\t\t   dlrr-(now-lrr)));\n\t}\n    }\n\n    /* Receiving Statistics Summary */\n    if (rb_stats) {\n\tpj_uint8_t flags = rb_stats->header.specific;\n\n\tpj_bzero(&sess->stat.tx.stat_sum, sizeof(sess->stat.tx.stat_sum));\n\n\t/* Range of packets sequence reported in this blocks */\n\tsess->stat.tx.stat_sum.begin_seq = pj_ntohs(rb_stats->begin_seq);\n\tsess->stat.tx.stat_sum.end_seq   = pj_ntohs(rb_stats->end_seq);\n\n\t/* Get flags of valid fields */\n\tsess->stat.tx.stat_sum.l = (flags & (1 << 7)) != 0;\n\tsess->stat.tx.stat_sum.d = (flags & (1 << 6)) != 0;\n\tsess->stat.tx.stat_sum.j = (flags & (1 << 5)) != 0;\n\tsess->stat.tx.stat_sum.t = (flags & (3 << 3)) != 0;\n\n\t/* Fetch the reports info */\n\tif (sess->stat.tx.stat_sum.l) {\n\t    sess->stat.tx.stat_sum.lost = pj_ntohl(rb_stats->lost);\n\t}\n\n\tif (sess->stat.tx.stat_sum.d) {\n\t    sess->stat.tx.stat_sum.dup = pj_ntohl(rb_stats->dup);\n\t}\n\n\tif (sess->stat.tx.stat_sum.j) {\n\t    sess->stat.tx.stat_sum.jitter.min = pj_ntohl(rb_stats->jitter_min);\n\t    sess->stat.tx.stat_sum.jitter.max = pj_ntohl(rb_stats->jitter_max);\n\t    sess->stat.tx.stat_sum.jitter.mean= pj_ntohl(rb_stats->jitter_mean);\n\t    pj_math_stat_set_stddev(&sess->stat.tx.stat_sum.jitter, \n\t\t\t\t    pj_ntohl(rb_stats->jitter_dev));\n\t}\n\n\tif (sess->stat.tx.stat_sum.t) {\n\t    sess->stat.tx.stat_sum.toh.min = rb_stats->toh_min;\n\t    sess->stat.tx.stat_sum.toh.max = rb_stats->toh_max;\n\t    sess->stat.tx.stat_sum.toh.mean= rb_stats->toh_mean;\n\t    pj_math_stat_set_stddev(&sess->stat.tx.stat_sum.toh, \n\t\t\t\t    pj_ntohl(rb_stats->toh_dev));\n\t}\n\n\tpj_gettimeofday(&sess->stat.tx.stat_sum.update);\n    }\n\n    /* Receiving VoIP Metrics */\n    if (rb_voip_mtc) {\n\tsess->stat.tx.voip_mtc.loss_rate = rb_voip_mtc->loss_rate;\n\tsess->stat.tx.voip_mtc.discard_rate = rb_voip_mtc->discard_rate;\n\tsess->stat.tx.voip_mtc.burst_den = rb_voip_mtc->burst_den;\n\tsess->stat.tx.voip_mtc.gap_den = rb_voip_mtc->gap_den;\n\tsess->stat.tx.voip_mtc.burst_dur = pj_ntohs(rb_voip_mtc->burst_dur);\n\tsess->stat.tx.voip_mtc.gap_dur = pj_ntohs(rb_voip_mtc->gap_dur);\n\tsess->stat.tx.voip_mtc.rnd_trip_delay = \n\t\t\t\t\tpj_ntohs(rb_voip_mtc->rnd_trip_delay);\n\tsess->stat.tx.voip_mtc.end_sys_delay = \n\t\t\t\t\tpj_ntohs(rb_voip_mtc->end_sys_delay);\n\t/* signal & noise level encoded in two's complement form */\n\tsess->stat.tx.voip_mtc.signal_lvl = (pj_int8_t)\n\t\t\t\t    ((rb_voip_mtc->signal_lvl > 127)?\n\t\t\t\t     ((int)rb_voip_mtc->signal_lvl - 256) : \n\t\t\t\t     rb_voip_mtc->signal_lvl);\n\tsess->stat.tx.voip_mtc.noise_lvl  = (pj_int8_t)\n\t\t\t\t    ((rb_voip_mtc->noise_lvl > 127)?\n\t\t\t\t     ((int)rb_voip_mtc->noise_lvl - 256) : \n\t\t\t\t     rb_voip_mtc->noise_lvl);\n\tsess->stat.tx.voip_mtc.rerl = rb_voip_mtc->rerl;\n\tsess->stat.tx.voip_mtc.gmin = rb_voip_mtc->gmin;\n\tsess->stat.tx.voip_mtc.r_factor = rb_voip_mtc->r_factor;\n\tsess->stat.tx.voip_mtc.ext_r_factor = rb_voip_mtc->ext_r_factor;\n\tsess->stat.tx.voip_mtc.mos_lq = rb_voip_mtc->mos_lq;\n\tsess->stat.tx.voip_mtc.mos_cq = rb_voip_mtc->mos_cq;\n\tsess->stat.tx.voip_mtc.rx_config = rb_voip_mtc->rx_config;\n\tsess->stat.tx.voip_mtc.jb_nom = pj_ntohs(rb_voip_mtc->jb_nom);\n\tsess->stat.tx.voip_mtc.jb_max = pj_ntohs(rb_voip_mtc->jb_max);\n\tsess->stat.tx.voip_mtc.jb_abs_max = pj_ntohs(rb_voip_mtc->jb_abs_max);\n\n\tpj_gettimeofday(&sess->stat.tx.voip_mtc.update);\n    }\n}",
        "func_hash": 128531615202269817130665554219664776865,
        "file_name": "rtcp_xr.c",
        "file_hash": 114410540091951766279707779044798368853,
        "cwe": [
            "CWE-125"
        ],
        "cve": "CVE-2021-43845",
        "cve_desc": "PJSIP is a free and open source multimedia communication library. In version 2.11.1 and prior, if incoming RTCP XR message contain block, the data field is not checked against the received packet size, potentially resulting in an out-of-bound read access. This affects all users that use PJMEDIA and RTCP XR. A malicious actor can send a RTCP XR message with an invalid packet size.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-43845",
        "func_name": "pjmedia_rtcp_xr_rx_rtcp_xr",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195231,
        "project": "gpac",
        "commit_id": "893fb99b606eebfae46cde151846a980e689039b",
        "project_url": "https://github.com/gpac/gpac",
        "commit_url": "https://github.com/gpac/gpac/commit/893fb99b606eebfae46cde151846a980e689039b",
        "commit_message": "fixed #1902",
        "target": 1,
        "irrelevant": 1,
        "func_before": "s32 gf_avc_parse_nalu(GF_BitStream *bs, AVCState *avc)\n{\n\tu8 idr_flag;\n\ts32 slice, ret;\n\tu32 nal_hdr;\n\tAVCSliceInfo n_state;\n\n\tgf_bs_enable_emulation_byte_removal(bs, GF_TRUE);\n\n\tnal_hdr = gf_bs_read_u8(bs);\n\n\tslice = 0;\n\tmemcpy(&n_state, &avc->s_info, sizeof(AVCSliceInfo));\n\tavc->last_nal_type_parsed = n_state.nal_unit_type = nal_hdr & 0x1F;\n\tn_state.nal_ref_idc = (nal_hdr >> 5) & 0x3;\n\n\tidr_flag = 0;\n\n\tswitch (n_state.nal_unit_type) {\n\tcase GF_AVC_NALU_ACCESS_UNIT:\n\tcase GF_AVC_NALU_END_OF_SEQ:\n\tcase GF_AVC_NALU_END_OF_STREAM:\n\t\tret = 1;\n\t\tbreak;\n\n\tcase GF_AVC_NALU_SVC_SLICE:\n\t\tSVC_ReadNal_header_extension(bs, &n_state.NalHeader);\n\t\t// slice buffer - read the info and compare.\n\t\t/*ret = */svc_parse_slice(bs, avc, &n_state);\n\t\tif (avc->s_info.nal_ref_idc) {\n\t\t\tn_state.poc_lsb_prev = avc->s_info.poc_lsb;\n\t\t\tn_state.poc_msb_prev = avc->s_info.poc_msb;\n\t\t}\n\t\tavc_compute_poc(&n_state);\n\n\t\tif (avc->s_info.poc != n_state.poc) {\n\t\t\tmemcpy(&avc->s_info, &n_state, sizeof(AVCSliceInfo));\n\t\t\treturn 1;\n\t\t}\n\t\tmemcpy(&avc->s_info, &n_state, sizeof(AVCSliceInfo));\n\t\treturn 0;\n\n\tcase GF_AVC_NALU_SVC_PREFIX_NALU:\n\t\tSVC_ReadNal_header_extension(bs, &n_state.NalHeader);\n\t\treturn 0;\n\n\tcase GF_AVC_NALU_IDR_SLICE:\n\tcase GF_AVC_NALU_NON_IDR_SLICE:\n\tcase GF_AVC_NALU_DP_A_SLICE:\n\tcase GF_AVC_NALU_DP_B_SLICE:\n\tcase GF_AVC_NALU_DP_C_SLICE:\n\t\tslice = 1;\n\t\t/* slice buffer - read the info and compare.*/\n\t\tret = avc_parse_slice(bs, avc, idr_flag, &n_state);\n\t\tif (ret < 0) return ret;\n\t\tret = 0;\n\t\tif (\n\t\t\t((avc->s_info.nal_unit_type > GF_AVC_NALU_IDR_SLICE) || (avc->s_info.nal_unit_type < GF_AVC_NALU_NON_IDR_SLICE))\n\t\t\t&& (avc->s_info.nal_unit_type != GF_AVC_NALU_SVC_SLICE)\n\t\t\t) {\n\t\t\tbreak;\n\t\t}\n\t\tif (avc->s_info.frame_num != n_state.frame_num) {\n\t\t\tret = 1;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (avc->s_info.field_pic_flag != n_state.field_pic_flag) {\n\t\t\tret = 1;\n\t\t\tbreak;\n\t\t}\n\t\tif ((avc->s_info.nal_ref_idc != n_state.nal_ref_idc) &&\n\t\t\t(!avc->s_info.nal_ref_idc || !n_state.nal_ref_idc)) {\n\t\t\tret = 1;\n\t\t\tbreak;\n\t\t}\n\t\tassert(avc->s_info.sps);\n\n\t\tif (avc->s_info.sps->poc_type == n_state.sps->poc_type) {\n\t\t\tif (!avc->s_info.sps->poc_type) {\n\t\t\t\tif (!n_state.bottom_field_flag && (avc->s_info.poc_lsb != n_state.poc_lsb)) {\n\t\t\t\t\tret = 1;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tif (avc->s_info.delta_poc_bottom != n_state.delta_poc_bottom) {\n\t\t\t\t\tret = 1;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\telse if (avc->s_info.sps->poc_type == 1) {\n\t\t\t\tif (avc->s_info.delta_poc[0] != n_state.delta_poc[0]) {\n\t\t\t\t\tret = 1;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tif (avc->s_info.delta_poc[1] != n_state.delta_poc[1]) {\n\t\t\t\t\tret = 1;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif (n_state.nal_unit_type == GF_AVC_NALU_IDR_SLICE) {\n\t\t\tif (avc->s_info.nal_unit_type != GF_AVC_NALU_IDR_SLICE) { /*IdrPicFlag differs in value*/\n\t\t\t\tret = 1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\telse if (avc->s_info.idr_pic_id != n_state.idr_pic_id) { /*both IDR and idr_pic_id differs*/\n\t\t\t\tret = 1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tbreak;\n\tcase GF_AVC_NALU_SEQ_PARAM:\n\t\tavc->last_ps_idx = gf_avc_read_sps_bs_internal(bs, avc, 0, NULL, nal_hdr);\n\t\tif (avc->last_ps_idx < 0) return -1;\n\t\treturn 0;\n\n\tcase GF_AVC_NALU_PIC_PARAM:\n\t\tavc->last_ps_idx = gf_avc_read_pps_bs_internal(bs, avc, nal_hdr);\n\t\tif (avc->last_ps_idx < 0) return -1;\n\t\treturn 0;\n\tcase GF_AVC_NALU_SVC_SUBSEQ_PARAM:\n\t\tavc->last_ps_idx = gf_avc_read_sps_bs_internal(bs, avc, 1, NULL, nal_hdr);\n\t\tif (avc->last_ps_idx < 0) return -1;\n\t\treturn 0;\n\tcase GF_AVC_NALU_SEQ_PARAM_EXT:\n\t\tavc->last_ps_idx = (s32) gf_bs_read_ue(bs);\n\t\tif (avc->last_ps_idx < 0) return -1;\n\t\treturn 0;\n\n\tcase GF_AVC_NALU_SEI:\n\tcase GF_AVC_NALU_FILLER_DATA:\n\t\treturn 0;\n\n\tdefault:\n\t\tif (avc->s_info.nal_unit_type <= GF_AVC_NALU_IDR_SLICE) ret = 1;\n\t\t//To detect change of AU when multiple sps and pps in stream\n\t\telse if ((nal_hdr & 0x1F) == GF_AVC_NALU_SEI && avc->s_info.nal_unit_type == GF_AVC_NALU_SVC_SLICE)\n\t\t\tret = 1;\n\t\telse if ((nal_hdr & 0x1F) == GF_AVC_NALU_SEQ_PARAM && avc->s_info.nal_unit_type == GF_AVC_NALU_SVC_SLICE)\n\t\t\tret = 1;\n\t\telse\n\t\t\tret = 0;\n\t\tbreak;\n\t}\n\n\t/* save _prev values */\n\tif (ret && avc->s_info.sps) {\n\t\tn_state.frame_num_offset_prev = avc->s_info.frame_num_offset;\n\t\tif ((avc->s_info.sps->poc_type != 2) || (avc->s_info.nal_ref_idc != 0))\n\t\t\tn_state.frame_num_prev = avc->s_info.frame_num;\n\t\tif (avc->s_info.nal_ref_idc) {\n\t\t\tn_state.poc_lsb_prev = avc->s_info.poc_lsb;\n\t\t\tn_state.poc_msb_prev = avc->s_info.poc_msb;\n\t\t}\n\t}\n\tif (slice)\n\t\tavc_compute_poc(&n_state);\n\tmemcpy(&avc->s_info, &n_state, sizeof(AVCSliceInfo));\n\treturn ret;\n}",
        "func_hash": 99100226875075764129164909998725433232,
        "file_name": "av_parsers.c",
        "file_hash": 168517587328341017594269375399465893964,
        "cwe": [
            "CWE-476"
        ],
        "cve": "CVE-2021-40565",
        "cve_desc": "A Segmentation fault caused by a null pointer dereference vulnerability exists in Gpac through 1.0.1 via the gf_avc_parse_nalu function in av_parsers.c when using mp4box, which causes a denial of service.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-40565",
        "func_name": "gf_avc_parse_nalu",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195233,
        "project": "tensorflow",
        "commit_id": "97282c6d0d34476b6ba033f961590b783fa184cd",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/97282c6d0d34476b6ba033f961590b783fa184cd",
        "commit_message": "Prevent a crash due to heap OOB write in grappler.\n\nPiperOrigin-RevId: 408318417\nChange-Id: If095feb8c001e3a8ac4a85b7387b81e8309df47d",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  Status SetUnknownShape(const NodeDef* node, int output_port) {\n    shape_inference::ShapeHandle shape =\n        GetUnknownOutputShape(node, output_port);\n    InferenceContext* ctx = GetContext(node);\n    if (ctx == nullptr) {\n      return errors::InvalidArgument(\"Missing context\");\n    }\n    ctx->set_output(output_port, shape);\n    return Status::OK();\n  }",
        "func_hash": 128649942367020682781968122888762734954,
        "file_name": "graph_properties.cc",
        "file_hash": 2473148557397819170260688514824580473,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2022-23566",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. TensorFlow is vulnerable to a heap OOB write in `Grappler`. The `set_output` function writes to an array at the specified index. Hence, this gives a malicious user a write primitive. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23566",
        "func_name": "SetUnknownShape",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195234,
        "project": "tensorflow",
        "commit_id": "dcc21c7bc972b10b6fb95c2fb0f4ab5a59680ec2",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/dcc21c7bc972b10b6fb95c2fb0f4ab5a59680ec2",
        "commit_message": "Eliminate debug `CHECK`-fail from `function.cc`\n\nPiperOrigin-RevId: 409416119\nChange-Id: I8376ee464d434e9b970ff0ad49edfdaa2a273cfe",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  Status BuildInputArgIndex(const OpDef::ArgDef& arg_def, AttrSlice attr_values,\n                            const FunctionDef::ArgAttrs* arg_attrs,\n                            bool ints_on_device,\n                            int64_t resource_arg_unique_id) {\n    bool is_type_list;\n    DataTypeVector dtypes;\n    TF_RETURN_IF_ERROR(\n        ArgNumType(attr_values, arg_def, &is_type_list, &dtypes));\n    if (dtypes.size() < size_t{1}) {\n      return errors::Internal(\"Expected a list of at least one dtype\");\n    }\n    int arg_index = result_.nodes.size();\n    TF_RETURN_IF_ERROR(\n        AddItem(arg_def.name(), {true, arg_index, 0, is_type_list, dtypes}));\n    // Creates dtypes.size() nodes in the graph.\n    for (size_t i = 0; i < dtypes.size(); ++i) {\n      TF_RETURN_IF_ERROR(AddItem(strings::StrCat(arg_def.name(), \":\", i),\n                                 {true, arg_index, 0, false, {dtypes[i]}}));\n      DCHECK_EQ(arg_index, result_.nodes.size());\n      string name = arg_def.name();\n      if (dtypes.size() > 1) {\n        strings::StrAppend(&name, \"_\", i);\n      }\n      NodeDef* gnode = AddNode(name);\n      if (ints_on_device && dtypes[i] == DataType::DT_INT32) {\n        gnode->set_op(FunctionLibraryDefinition::kDeviceArgOp);\n      } else {\n        gnode->set_op(FunctionLibraryDefinition::kArgOp);\n      }\n      DataType dtype = arg_def.is_ref() ? MakeRefType(dtypes[i]) : dtypes[i];\n      AddAttr(\"T\", dtype, gnode);\n      AddAttr(\"index\", arg_index, gnode);\n      if (resource_arg_unique_id >= 0) {\n        AddAttr(\"_resource_arg_unique_id\", resource_arg_unique_id, gnode);\n      }\n      if (arg_attrs) {\n        for (const auto& arg_attr : arg_attrs->attr()) {\n          AddAttr(arg_attr.first, arg_attr.second, gnode->mutable_attr());\n        }\n      }\n      result_.arg_types.push_back(dtypes[i]);\n      ++arg_index;\n    }\n    return Status::OK();\n  }",
        "func_hash": 149416980820983113024454385523610384435,
        "file_name": "function.cc",
        "file_hash": 275755455359751936167516531130081059449,
        "cwe": [
            "CWE-617"
        ],
        "cve": "CVE-2022-23586",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. A malicious user can cause a denial of service by altering a `SavedModel` such that assertions in `function.cc` would be falsified and crash the Python interpreter. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23586",
        "func_name": "BuildInputArgIndex",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195237,
        "project": "ImageMagick",
        "commit_id": "f221ea0fa3171f0f4fdf74ac9d81b203b9534c23",
        "project_url": "https://github.com/ImageMagick/ImageMagick",
        "commit_url": "https://github.com/ImageMagick/ImageMagick/commit/f221ea0fa3171f0f4fdf74ac9d81b203b9534c23",
        "commit_message": "Fixes #4985: 4e+26 is outside the range of representable values of type 'unsigned long' at coders/pcl.c:299 (#4986)\n\n* fix Division by zero in XMenuWidget() of MagickCore/widget.c\n\n* Fix memory leak in AnimateImageCommand() of MagickWand/animate.c and DisplayImageCommand() of MagickWand/display.c\n\n* fix Division by zero in ReadEnhMetaFile() of coders/emf.c\n\n* Resolve conflicts\n\n* fix issue: outside the range of representable values of type 'unsigned char' at coders/psd.c:1025\n\n* fix error: 4e+26 is outside the range of representable values of type 'unsigned long' at coders/pcl.c:299\n\nCo-authored-by: zhailiangliang <zhailiangliang@loongson.cn>",
        "target": 1,
        "irrelevant": 1,
        "func_before": "static Image *ReadPCLImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n#define CropBox  \"CropBox\"\n#define DeviceCMYK  \"DeviceCMYK\"\n#define MediaBox  \"MediaBox\"\n#define RenderPCLText  \"  Rendering PCL...  \"\n\n  char\n    command[MagickPathExtent],\n    *density,\n    filename[MagickPathExtent],\n    geometry[MagickPathExtent],\n    *options,\n    input_filename[MagickPathExtent];\n\n  const DelegateInfo\n    *delegate_info;\n\n  Image\n    *image,\n    *next_image;\n\n  ImageInfo\n    *read_info;\n\n  MagickBooleanType\n    cmyk,\n    status;\n\n  PointInfo\n    delta;\n\n  RectangleInfo\n    bounding_box,\n    page;\n\n  char\n    *p;\n\n  ssize_t\n    c;\n\n  SegmentInfo\n    bounds;\n\n  size_t\n    height,\n    width;\n\n  ssize_t\n    count;\n\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  /*\n    Open image file.\n  */\n  image=AcquireImage(image_info,exception);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  status=AcquireUniqueSymbolicLink(image_info->filename,input_filename);\n  if (status == MagickFalse)\n    {\n      ThrowFileException(exception,FileOpenError,\"UnableToCreateTemporaryFile\",\n        image_info->filename);\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    Set the page density.\n  */\n  delta.x=DefaultResolution;\n  delta.y=DefaultResolution;\n  if ((image->resolution.x == 0.0) || (image->resolution.y == 0.0))\n    {\n      GeometryInfo\n        geometry_info;\n\n      MagickStatusType\n        flags;\n\n      flags=ParseGeometry(PSDensityGeometry,&geometry_info);\n      if ((flags & RhoValue) != 0)\n        image->resolution.x=geometry_info.rho;\n      image->resolution.y=image->resolution.x;\n      if ((flags & SigmaValue) != 0)\n        image->resolution.y=geometry_info.sigma;\n    }\n  /*\n    Determine page geometry from the PCL media box.\n  */\n  cmyk=image->colorspace == CMYKColorspace ? MagickTrue : MagickFalse;\n  count=0;\n  (void) memset(&bounding_box,0,sizeof(bounding_box));\n  (void) memset(&bounds,0,sizeof(bounds));\n  (void) memset(&page,0,sizeof(page));\n  (void) memset(command,0,sizeof(command));\n  p=command;\n  for (c=ReadBlobByte(image); c != EOF; c=ReadBlobByte(image))\n  {\n    if (image_info->page != (char *) NULL)\n      continue;\n    /*\n      Note PCL elements.\n    */\n    *p++=(char) c;\n    if ((c != (int) '/') && (c != '\\n') &&\n        ((size_t) (p-command) < (MagickPathExtent-1)))\n      continue;\n    *p='\\0';\n    p=command;\n    /*\n      Is this a CMYK document?\n    */\n    if (LocaleNCompare(DeviceCMYK,command,strlen(DeviceCMYK)) == 0)\n      cmyk=MagickTrue;\n    if (LocaleNCompare(CropBox,command,strlen(CropBox)) == 0)\n      {\n        /*\n          Note region defined by crop box.\n        */\n        count=(ssize_t) sscanf(command,\"CropBox [%lf %lf %lf %lf\",\n          &bounds.x1,&bounds.y1,&bounds.x2,&bounds.y2);\n        if (count != 4)\n          count=(ssize_t) sscanf(command,\"CropBox[%lf %lf %lf %lf\",\n            &bounds.x1,&bounds.y1,&bounds.x2,&bounds.y2);\n      }\n    if (LocaleNCompare(MediaBox,command,strlen(MediaBox)) == 0)\n      {\n        /*\n          Note region defined by media box.\n        */\n        count=(ssize_t) sscanf(command,\"MediaBox [%lf %lf %lf %lf\",\n          &bounds.x1,&bounds.y1,&bounds.x2,&bounds.y2);\n        if (count != 4)\n          count=(ssize_t) sscanf(command,\"MediaBox[%lf %lf %lf %lf\",\n            &bounds.x1,&bounds.y1,&bounds.x2,&bounds.y2);\n      }\n    if (count != 4)\n      continue;\n    /*\n      Set PCL render geometry.\n    */\n    width=(size_t) floor(bounds.x2-bounds.x1+0.5);\n    height=(size_t) floor(bounds.y2-bounds.y1+0.5);\n    if (width > page.width)\n      page.width=width;\n    if (height > page.height)\n      page.height=height;\n  }\n  (void) CloseBlob(image);\n  /*\n    Render PCL with the GhostPCL delegate.\n  */\n  if ((page.width == 0) || (page.height == 0))\n    (void) ParseAbsoluteGeometry(PSPageGeometry,&page);\n  if (image_info->page != (char *) NULL)\n    (void) ParseAbsoluteGeometry(image_info->page,&page);\n  (void) FormatLocaleString(geometry,MagickPathExtent,\"%.20gx%.20g\",(double)\n    page.width,(double) page.height);\n  if (image_info->monochrome != MagickFalse)\n    delegate_info=GetDelegateInfo(\"pcl:mono\",(char *) NULL,exception);\n  else\n     if (cmyk != MagickFalse)\n       delegate_info=GetDelegateInfo(\"pcl:cmyk\",(char *) NULL,exception);\n     else\n       delegate_info=GetDelegateInfo(\"pcl:color\",(char *) NULL,exception);\n  if (delegate_info == (const DelegateInfo *) NULL)\n    {\n      image=DestroyImage(image);\n      return((Image *) NULL);\n    }\n  if ((page.width == 0) || (page.height == 0))\n    (void) ParseAbsoluteGeometry(PSPageGeometry,&page);\n  if (image_info->page != (char *) NULL)\n    (void) ParseAbsoluteGeometry(image_info->page,&page);\n  density=AcquireString(\"\");\n  options=AcquireString(\"\");\n  (void) FormatLocaleString(density,MagickPathExtent,\"%gx%g\",\n    image->resolution.x,image->resolution.y);\n  if (image_info->ping != MagickFalse)\n    (void) FormatLocaleString(density,MagickPathExtent,\"2.0x2.0\");\n  page.width=(size_t) floor(page.width*image->resolution.x/delta.x+0.5);\n  page.height=(size_t) floor(page.height*image->resolution.y/delta.y+0.5);\n  (void) FormatLocaleString(options,MagickPathExtent,\"-g%.20gx%.20g \",(double)\n    page.width,(double) page.height);\n  image=DestroyImage(image);\n  read_info=CloneImageInfo(image_info);\n  *read_info->magick='\\0';\n  if (read_info->number_scenes != 0)\n    {\n      if (read_info->number_scenes != 1)\n        (void) FormatLocaleString(options,MagickPathExtent,\"-dLastPage=%.20g\",\n          (double) (read_info->scene+read_info->number_scenes));\n      else\n        (void) FormatLocaleString(options,MagickPathExtent,\n          \"-dFirstPage=%.20g -dLastPage=%.20g\",(double) read_info->scene+1,\n          (double) (read_info->scene+read_info->number_scenes));\n      read_info->number_scenes=0;\n      if (read_info->scenes != (char *) NULL)\n        *read_info->scenes='\\0';\n    }\n  (void) CopyMagickString(filename,read_info->filename,MagickPathExtent);\n  (void) AcquireUniqueFilename(read_info->filename);\n  (void) FormatLocaleString(command,MagickPathExtent,\n    GetDelegateCommands(delegate_info),\n    read_info->antialias != MagickFalse ? 4 : 1,\n    read_info->antialias != MagickFalse ? 4 : 1,density,options,\n    read_info->filename,input_filename);\n  options=DestroyString(options);\n  density=DestroyString(density);\n  status=ExternalDelegateCommand(MagickFalse,read_info->verbose,command,\n    (char *) NULL,exception) != 0 ? MagickTrue : MagickFalse;\n  image=ReadImage(read_info,exception);\n  (void) RelinquishUniqueFileResource(read_info->filename);\n  (void) RelinquishUniqueFileResource(input_filename);\n  read_info=DestroyImageInfo(read_info);\n  if (image == (Image *) NULL)\n    ThrowReaderException(DelegateError,\"PCLDelegateFailed\");\n  if (LocaleCompare(image->magick,\"BMP\") == 0)\n    {\n      Image\n        *cmyk_image;\n\n      cmyk_image=ConsolidateCMYKImages(image,exception);\n      if (cmyk_image != (Image *) NULL)\n        {\n          image=DestroyImageList(image);\n          image=cmyk_image;\n        }\n    }\n  do\n  {\n    (void) CopyMagickString(image->filename,filename,MagickPathExtent);\n    image->page=page;\n    if (image_info->ping != MagickFalse)\n      {\n        image->magick_columns*=image->resolution.x/2.0;\n        image->magick_rows*=image->resolution.y/2.0;\n        image->columns*=image->resolution.x/2.0;\n        image->rows*=image->resolution.y/2.0;\n      }\n    next_image=SyncNextImageInList(image);\n    if (next_image != (Image *) NULL)\n      image=next_image;\n  } while (next_image != (Image *) NULL);\n  return(GetFirstImageInList(image));\n}",
        "func_hash": 164108098598115354275502589345492195560,
        "file_name": "pcl.c",
        "file_hash": 226900089914426038554396055314138187051,
        "cwe": [
            "CWE-190"
        ],
        "cve": "CVE-2022-32546",
        "cve_desc": "A vulnerability was found in ImageMagick, causing an outside the range of representable values of type 'unsigned long' at coders/pcl.c, when crafted or untrusted input is processed. This leads to a negative impact to application availability or other problems related to undefined behavior.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-32546",
        "func_name": "ReadPCLImage",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195238,
        "project": "flatpak",
        "commit_id": "e26ac7586c392b5eb35ff4609fe232c52523b2cf",
        "project_url": "https://github.com/flatpak/flatpak",
        "commit_url": "https://github.com/flatpak/flatpak/commit/e26ac7586c392b5eb35ff4609fe232c52523b2cf",
        "commit_message": "run: Add an errno value to seccomp filters\n\nAt the moment, if we block a syscall we always make it fail with EPERM,\nbut this is risky: user-space libraries can start to use new replacements\nfor old syscalls at any time, and will often treat EPERM as a fatal error.\nFor new syscalls, we should make the syscall fail with ENOSYS, which is\nindistinguishable from running on an older kernel and will cause fallback\nto an older implementation, for example clone3() to clone().\n\nIn future we should probably move from EPERM to ENOSYS for some of the\nsyscalls we already block, but for now keep the status quo.\n\nThis is a prerequisite for fixing the vulnerability tracked as\nGHSA-67h7-w3jq-vh4q.\n\nSigned-off-by: Simon McVittie <smcv@collabora.com>",
        "target": 1,
        "irrelevant": 0,
        "func_before": "setup_seccomp (FlatpakBwrap   *bwrap,\n               const char     *arch,\n               gulong          allowed_personality,\n               FlatpakRunFlags run_flags,\n               GError        **error)\n{\n  gboolean multiarch = (run_flags & FLATPAK_RUN_FLAG_MULTIARCH) != 0;\n  gboolean devel = (run_flags & FLATPAK_RUN_FLAG_DEVEL) != 0;\n\n  __attribute__((cleanup (cleanup_seccomp))) scmp_filter_ctx seccomp = NULL;\n\n  /**** BEGIN NOTE ON CODE SHARING\n   *\n   * There are today a number of different Linux container\n   * implementations.  That will likely continue for long into the\n   * future.  But we can still try to share code, and it's important\n   * to do so because it affects what library and application writers\n   * can do, and we should support code portability between different\n   * container tools.\n   *\n   * This syscall blocklist is copied from linux-user-chroot, which was in turn\n   * clearly influenced by the Sandstorm.io blocklist.\n   *\n   * If you make any changes here, I suggest sending the changes along\n   * to other sandbox maintainers.  Using the libseccomp list is also\n   * an appropriate venue:\n   * https://groups.google.com/forum/#!forum/libseccomp\n   *\n   * A non-exhaustive list of links to container tooling that might\n   * want to share this blocklist:\n   *\n   *  https://github.com/sandstorm-io/sandstorm\n   *    in src/sandstorm/supervisor.c++\n   *  https://github.com/flatpak/flatpak.git\n   *    in common/flatpak-run.c\n   *  https://git.gnome.org/browse/linux-user-chroot\n   *    in src/setup-seccomp.c\n   *\n   **** END NOTE ON CODE SHARING\n   */\n  struct\n  {\n    int                  scall;\n    struct scmp_arg_cmp *arg;\n  } syscall_blocklist[] = {\n    /* Block dmesg */\n    {SCMP_SYS (syslog)},\n    /* Useless old syscall */\n    {SCMP_SYS (uselib)},\n    /* Don't allow disabling accounting */\n    {SCMP_SYS (acct)},\n    /* 16-bit code is unnecessary in the sandbox, and modify_ldt is a\n       historic source of interesting information leaks. */\n    {SCMP_SYS (modify_ldt)},\n    /* Don't allow reading current quota use */\n    {SCMP_SYS (quotactl)},\n\n    /* Don't allow access to the kernel keyring */\n    {SCMP_SYS (add_key)},\n    {SCMP_SYS (keyctl)},\n    {SCMP_SYS (request_key)},\n\n    /* Scary VM/NUMA ops */\n    {SCMP_SYS (move_pages)},\n    {SCMP_SYS (mbind)},\n    {SCMP_SYS (get_mempolicy)},\n    {SCMP_SYS (set_mempolicy)},\n    {SCMP_SYS (migrate_pages)},\n\n    /* Don't allow subnamespace setups: */\n    {SCMP_SYS (unshare)},\n    {SCMP_SYS (mount)},\n    {SCMP_SYS (pivot_root)},\n#if defined(__s390__) || defined(__s390x__) || defined(__CRIS__)\n    /* Architectures with CONFIG_CLONE_BACKWARDS2: the child stack\n     * and flags arguments are reversed so the flags come second */\n    {SCMP_SYS (clone), &SCMP_A1 (SCMP_CMP_MASKED_EQ, CLONE_NEWUSER, CLONE_NEWUSER)},\n#else\n    /* Normally the flags come first */\n    {SCMP_SYS (clone), &SCMP_A0 (SCMP_CMP_MASKED_EQ, CLONE_NEWUSER, CLONE_NEWUSER)},\n#endif\n\n    /* Don't allow faking input to the controlling tty (CVE-2017-5226) */\n    {SCMP_SYS (ioctl), &SCMP_A1 (SCMP_CMP_MASKED_EQ, 0xFFFFFFFFu, (int) TIOCSTI)},\n  };\n\n  struct\n  {\n    int                  scall;\n    struct scmp_arg_cmp *arg;\n  } syscall_nondevel_blocklist[] = {\n    /* Profiling operations; we expect these to be done by tools from outside\n     * the sandbox.  In particular perf has been the source of many CVEs.\n     */\n    {SCMP_SYS (perf_event_open)},\n    /* Don't allow you to switch to bsd emulation or whatnot */\n    {SCMP_SYS (personality), &SCMP_A0 (SCMP_CMP_NE, allowed_personality)},\n    {SCMP_SYS (ptrace)}\n  };\n  /* Blocklist all but unix, inet, inet6 and netlink */\n  struct\n  {\n    int             family;\n    FlatpakRunFlags flags_mask;\n  } socket_family_allowlist[] = {\n    /* NOTE: Keep in numerical order */\n    { AF_UNSPEC, 0 },\n    { AF_LOCAL, 0 },\n    { AF_INET, 0 },\n    { AF_INET6, 0 },\n    { AF_NETLINK, 0 },\n    { AF_CAN, FLATPAK_RUN_FLAG_CANBUS },\n    { AF_BLUETOOTH, FLATPAK_RUN_FLAG_BLUETOOTH },\n  };\n  int last_allowed_family;\n  int i, r;\n  g_auto(GLnxTmpfile) seccomp_tmpf  = { 0, };\n\n  seccomp = seccomp_init (SCMP_ACT_ALLOW);\n  if (!seccomp)\n    return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Initialize seccomp failed\"));\n\n  if (arch != NULL)\n    {\n      uint32_t arch_id = 0;\n      const uint32_t *extra_arches = NULL;\n\n      if (strcmp (arch, \"i386\") == 0)\n        {\n          arch_id = SCMP_ARCH_X86;\n        }\n      else if (strcmp (arch, \"x86_64\") == 0)\n        {\n          arch_id = SCMP_ARCH_X86_64;\n          extra_arches = seccomp_x86_64_extra_arches;\n        }\n      else if (strcmp (arch, \"arm\") == 0)\n        {\n          arch_id = SCMP_ARCH_ARM;\n        }\n#ifdef SCMP_ARCH_AARCH64\n      else if (strcmp (arch, \"aarch64\") == 0)\n        {\n          arch_id = SCMP_ARCH_AARCH64;\n          extra_arches = seccomp_aarch64_extra_arches;\n        }\n#endif\n\n      /* We only really need to handle arches on multiarch systems.\n       * If only one arch is supported the default is fine */\n      if (arch_id != 0)\n        {\n          /* This *adds* the target arch, instead of replacing the\n             native one. This is not ideal, because we'd like to only\n             allow the target arch, but we can't really disallow the\n             native arch at this point, because then bubblewrap\n             couldn't continue running. */\n          r = seccomp_arch_add (seccomp, arch_id);\n          if (r < 0 && r != -EEXIST)\n            return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to add architecture to seccomp filter\"));\n\n          if (multiarch && extra_arches != NULL)\n            {\n              for (i = 0; extra_arches[i] != 0; i++)\n                {\n                  r = seccomp_arch_add (seccomp, extra_arches[i]);\n                  if (r < 0 && r != -EEXIST)\n                    return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to add multiarch architecture to seccomp filter\"));\n                }\n            }\n        }\n    }\n\n  /* TODO: Should we filter the kernel keyring syscalls in some way?\n   * We do want them to be used by desktop apps, but they could also perhaps\n   * leak system stuff or secrets from other apps.\n   */\n\n  for (i = 0; i < G_N_ELEMENTS (syscall_blocklist); i++)\n    {\n      int scall = syscall_blocklist[i].scall;\n      if (syscall_blocklist[i].arg)\n        r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (EPERM), scall, 1, *syscall_blocklist[i].arg);\n      else\n        r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (EPERM), scall, 0);\n      if (r < 0 && r == -EFAULT /* unknown syscall */)\n        return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to block syscall %d\"), scall);\n    }\n\n  if (!devel)\n    {\n      for (i = 0; i < G_N_ELEMENTS (syscall_nondevel_blocklist); i++)\n        {\n          int scall = syscall_nondevel_blocklist[i].scall;\n          if (syscall_nondevel_blocklist[i].arg)\n            r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (EPERM), scall, 1, *syscall_nondevel_blocklist[i].arg);\n          else\n            r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (EPERM), scall, 0);\n\n          if (r < 0 && r == -EFAULT /* unknown syscall */)\n            return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to block syscall %d\"), scall);\n        }\n    }\n\n  /* Socket filtering doesn't work on e.g. i386, so ignore failures here\n   * However, we need to user seccomp_rule_add_exact to avoid libseccomp doing\n   * something else: https://github.com/seccomp/libseccomp/issues/8 */\n  last_allowed_family = -1;\n  for (i = 0; i < G_N_ELEMENTS (socket_family_allowlist); i++)\n    {\n      int family = socket_family_allowlist[i].family;\n      int disallowed;\n\n      if (socket_family_allowlist[i].flags_mask != 0 &&\n          (socket_family_allowlist[i].flags_mask & run_flags) != socket_family_allowlist[i].flags_mask)\n        continue;\n\n      for (disallowed = last_allowed_family + 1; disallowed < family; disallowed++)\n        {\n          /* Blocklist the in-between valid families */\n          seccomp_rule_add_exact (seccomp, SCMP_ACT_ERRNO (EAFNOSUPPORT), SCMP_SYS (socket), 1, SCMP_A0 (SCMP_CMP_EQ, disallowed));\n        }\n      last_allowed_family = family;\n    }\n  /* Blocklist the rest */\n  seccomp_rule_add_exact (seccomp, SCMP_ACT_ERRNO (EAFNOSUPPORT), SCMP_SYS (socket), 1, SCMP_A0 (SCMP_CMP_GE, last_allowed_family + 1));\n\n  if (!glnx_open_anonymous_tmpfile_full (O_RDWR | O_CLOEXEC, \"/tmp\", &seccomp_tmpf, error))\n    return FALSE;\n\n  if (seccomp_export_bpf (seccomp, seccomp_tmpf.fd) != 0)\n    return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to export bpf\"));\n\n  lseek (seccomp_tmpf.fd, 0, SEEK_SET);\n\n  flatpak_bwrap_add_args_data_fd (bwrap,\n                                  \"--seccomp\", glnx_steal_fd (&seccomp_tmpf.fd), NULL);\n\n  return TRUE;\n}",
        "func_hash": 173907427135324375391340249360357936070,
        "file_name": "flatpak-run.c",
        "file_hash": 69385831422573127576569412177760237535,
        "cwe": [
            "CWE-20"
        ],
        "cve": "CVE-2021-41133",
        "cve_desc": "Flatpak is a system for building, distributing, and running sandboxed desktop applications on Linux. In versions prior to 1.10.4 and 1.12.0, Flatpak apps with direct access to AF_UNIX sockets such as those used by Wayland, Pipewire or pipewire-pulse can trick portals and other host-OS services into treating the Flatpak app as though it was an ordinary, non-sandboxed host-OS process. They can do this by manipulating the VFS using recent mount-related syscalls that are not blocked by Flatpak's denylist seccomp filter, in order to substitute a crafted `/.flatpak-info` or make that file disappear entirely. Flatpak apps that act as clients for AF_UNIX sockets such as those used by Wayland, Pipewire or pipewire-pulse can escalate the privileges that the corresponding services will believe the Flatpak app has. Note that protocols that operate entirely over the D-Bus session bus (user bus), system bus or accessibility bus are not affected by this. This is due to the use of a proxy process `xdg-dbus-proxy`, whose VFS cannot be manipulated by the Flatpak app, when interacting with these buses. Patches exist for versions 1.10.4 and 1.12.0, and as of time of publication, a patch for version 1.8.2 is being planned. There are no workarounds aside from upgrading to a patched version.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-41133",
        "func_name": "setup_seccomp",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 195242,
        "project": "tensorflow",
        "commit_id": "1b54cadd19391b60b6fcccd8d076426f7221d5e8",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/1b54cadd19391b60b6fcccd8d076426f7221d5e8",
        "commit_message": "Add missing validation to sparse dense cwise ops.\n\nPiperOrigin-RevId: 415543133\nChange-Id: I5baf3284e919338afb96178c468ad3d3cb0d956c",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext *ctx) override {\n    const Tensor *indices_t, *values_t, *shape_t, *dense_t;\n    OP_REQUIRES_OK(ctx, ctx->input(\"sp_indices\", &indices_t));\n    OP_REQUIRES_OK(ctx, ctx->input(\"sp_values\", &values_t));\n    OP_REQUIRES_OK(ctx, ctx->input(\"sp_shape\", &shape_t));\n    OP_REQUIRES_OK(ctx, ctx->input(\"dense\", &dense_t));\n\n    // Validations.\n    OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(indices_t->shape()),\n                errors::InvalidArgument(\n                    \"Input sp_indices should be a matrix but received shape: \",\n                    indices_t->shape().DebugString()));\n    OP_REQUIRES(ctx,\n                TensorShapeUtils::IsVector(values_t->shape()) &&\n                    TensorShapeUtils::IsVector(shape_t->shape()),\n                errors::InvalidArgument(\n                    \"Inputs sp_values and sp_shape should be vectors \"\n                    \"but received shapes: \",\n                    values_t->shape().DebugString(), \" and \",\n                    shape_t->shape().DebugString()));\n    OP_REQUIRES(\n        ctx, values_t->dim_size(0) == indices_t->dim_size(0),\n        errors::InvalidArgument(\n            \"The first dimension of values and indices should match. (\",\n            values_t->dim_size(0), \" vs. \", indices_t->dim_size(0), \")\"));\n\n    const auto indices_mat = indices_t->matrix<int64_t>();\n    const auto shape_vec = shape_t->vec<int64_t>();\n    const auto lhs_dims = BCast::FromShape(TensorShape(shape_vec));\n    const auto rhs_dims = BCast::FromShape(dense_t->shape());\n    BCast b(lhs_dims, rhs_dims, false);  // false for keeping the same num dims.\n\n    // True iff (size(lhs) >= size(rhs)) and all dims in lhs is greater or equal\n    // to dims in rhs (from right to left).\n    auto VecGreaterEq = [](ArraySlice<int64_t> lhs, ArraySlice<int64_t> rhs) {\n      if (lhs.size() < rhs.size()) return false;\n      for (size_t i = 0; i < rhs.size(); ++i) {\n        if (lhs[lhs.size() - 1 - i] < rhs[rhs.size() - 1 - i]) return false;\n      }\n      return true;\n    };\n    OP_REQUIRES(ctx, VecGreaterEq(lhs_dims, rhs_dims) && b.IsValid(),\n                errors::InvalidArgument(\n                    \"SparseDenseBinaryOpShared broadcasts dense to sparse \"\n                    \"only; got incompatible shapes: [\",\n                    absl::StrJoin(lhs_dims, \",\"), \"] vs. [\",\n                    absl::StrJoin(rhs_dims, \",\"), \"]\"));\n\n    Tensor *output_values = nullptr;\n    Tensor dense_gathered;\n    const int64_t nnz = indices_t->dim_size(0);\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_output(0, TensorShape({nnz}), &output_values));\n    OP_REQUIRES_OK(\n        ctx, ctx->allocate_temp(DataTypeToEnum<T>::value, TensorShape({nnz}),\n                                &dense_gathered));\n    bool op_is_div = false;\n    if (absl::StrContains(ctx->op_kernel().type_string_view(), \"Div\")) {\n      op_is_div = true;\n    }\n    // Pulls relevant entries from the dense side, with reshape and broadcasting\n    // *of the dense side* taken into account.  Use a TensorRef to avoid blowing\n    // up memory.\n    //\n    // We can directly use the sparse indices to look up dense side, because\n    // \"b.y_reshape()\" and \"b.y_bcast()\" are guaranteed to have rank \"ndims\".\n    auto dense_gathered_flat = dense_gathered.flat<T>();\n    const int ndims = lhs_dims.size();\n    switch (ndims) {\n#define CASE(NDIM)                                                             \\\n  case NDIM: {                                                                 \\\n    TensorRef<Eigen::Tensor<const T, NDIM, Eigen::RowMajor>> rhs_ref =         \\\n        dense_t->shaped<T, NDIM>(b.y_reshape())                                \\\n            .broadcast(BCast::ToIndexArray<NDIM>(b.y_bcast()));                \\\n    Eigen::array<Eigen::DenseIndex, NDIM> idx;                                 \\\n    bool indices_valid = true;                                                 \\\n    for (int i = 0; i < nnz; ++i) {                                            \\\n      for (int d = 0; d < NDIM; ++d) {                                         \\\n        idx[d] = internal::SubtleMustCopy(indices_mat(i, d));                  \\\n        if (!FastBoundsCheck(idx[d], rhs_ref.dimension(d))) {                  \\\n          indices_valid = false;                                               \\\n        }                                                                      \\\n      }                                                                        \\\n      OP_REQUIRES(                                                             \\\n          ctx, indices_valid,                                                  \\\n          errors::InvalidArgument(\"Provided indices are out-of-bounds w.r.t. \" \\\n                                  \"dense side with broadcasted shape\"));       \\\n      dense_gathered_flat(i) = rhs_ref.coeff(idx);                             \\\n      if (op_is_div) {                                                         \\\n        OP_REQUIRES(ctx, dense_gathered_flat(i) != 0,                          \\\n                    errors::InvalidArgument(                                   \\\n                        \"SparseDenseCwiseDiv cannot divide by zero,\"           \\\n                        \"but input dense tensor contains zero \"));             \\\n      }                                                                        \\\n    }                                                                          \\\n    break;                                                                     \\\n  }\n\n      CASE(1);\n      CASE(2);\n      CASE(3);\n      CASE(4);\n      CASE(5);\n      default:\n        OP_REQUIRES(\n            ctx, false,\n            errors::InvalidArgument(\"Only tensors with ranks between 1 and 5 \"\n                                    \"are currently supported.  Tensor rank: \",\n                                    ndims));\n#undef CASE\n    }\n\n    output_values->flat<T>().device(ctx->eigen_device<Device>()) =\n        values_t->flat<T>().binaryExpr(dense_gathered_flat,\n                                       typename Functor::func());\n  }",
        "func_hash": 280343339014694875612411900055184725662,
        "file_name": "sparse_dense_binary_op_shared.cc",
        "file_hash": 149048879181841547116557871950334917673,
        "cwe": [
            "CWE-190"
        ],
        "cve": "CVE-2022-23567",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The implementations of `Sparse*Cwise*` ops are vulnerable to integer overflows. These can be used to trigger large allocations (so, OOM based denial of service) or `CHECK`-fails when building new `TensorShape` objects (so, assert failures based denial of service). We are missing some validation on the shapes of the input tensors as well as directly constructing a large `TensorShape` with user-provided dimensions. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23567",
        "func_name": "Compute",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 198282,
        "project": "tensorflow",
        "commit_id": "4923de56ec94fff7770df259ab7f2288a74feb41",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/4923de56ec94fff7770df259ab7f2288a74feb41",
        "commit_message": "Don't do any work when reshaping 0 elements sparse tensor.\n\nIf reshaping to 0 elements tensor, check that input has no elements.\nIf reshaping no elements input, check that output has no elements.\n\nPiperOrigin-RevId: 388296986\nChange-Id: Iadc9fe7252e14313ca987e69bf0d7042fd10232a",
        "target": 1,
        "irrelevant": 0,
        "func_before": "void ReshapeSparseTensor(OpKernelContext *context,\n                         const Tensor &input_indices_in,\n                         const Tensor &input_shape_in,\n                         const Tensor &target_shape_in, int output_indices_idx,\n                         int output_shape_idx) {\n  OP_REQUIRES(context, TensorShapeUtils::IsMatrix(input_indices_in.shape()),\n              errors::InvalidArgument(\n                  \"Input indices should be a matrix but received shape \",\n                  input_indices_in.shape().DebugString()));\n  OP_REQUIRES(context, TensorShapeUtils::IsVector(input_shape_in.shape()),\n              errors::InvalidArgument(\n                  \"Input shape should be a vector but received shape \",\n                  input_shape_in.shape().DebugString()));\n  OP_REQUIRES(context, TensorShapeUtils::IsVector(target_shape_in.shape()),\n              errors::InvalidArgument(\n                  \"Target shape should be a vector but received shape \",\n                  target_shape_in.shape().DebugString()));\n\n  const int64_t output_rank = target_shape_in.NumElements();\n  const TensorShape input_shape(input_shape_in.vec<int64>());\n  const int64_t dense_size = input_shape.num_elements();\n  const int64_t nnz = input_indices_in.shape().dim_size(0);\n\n  // Compute the output shape. Determine product of specified dimensions, and\n  // find the index of the unspecified one.\n  TensorShape output_shape;\n  int64_t product = 1;\n  int unknown_index = -1;\n  auto target_shape = target_shape_in.vec<int64>();\n  for (int d = 0; d < output_rank; ++d) {\n    const int64_t size = target_shape(d);\n    if (size == -1) {\n      OP_REQUIRES(\n          context, unknown_index == -1,\n          errors::InvalidArgument(\"only one output dimension may be -1, \"\n                                  \"not both \",\n                                  unknown_index, \" and \", d));\n      unknown_index = d;\n      output_shape.AddDim(1);\n    } else {\n      OP_REQUIRES(context, size >= 0,\n                  errors::InvalidArgument(\"size \", d,\n                                          \" must be non-negative, not \", size));\n      product *= size;\n      output_shape.AddDim(size);\n    }\n  }\n  if (unknown_index != -1) {\n    OP_REQUIRES(\n        context, product > 0,\n        errors::InvalidArgument(\"reshape cannot infer the missing \"\n                                \"input size for an empty tensor unless all \"\n                                \"specified input sizes are non-zero\"));\n    const int64_t missing = dense_size / product;\n    OP_REQUIRES(\n        context, product * missing == dense_size,\n        errors::InvalidArgument(\n            \"Input to reshape is a SparseTensor with \", dense_size,\n            \" dense values, but the requested shape requires a multiple of \",\n            product, \". input_shape=\", input_shape.DebugString(),\n            \" output_shape=\", output_shape.DebugString()));\n    output_shape.set_dim(unknown_index, missing);\n  }\n\n  OP_REQUIRES(\n      context, output_shape.num_elements() == dense_size,\n      errors::InvalidArgument(\"Input to reshape is a tensor with \", dense_size,\n                              \" dense values, but the requested shape has \",\n                              output_shape.num_elements(),\n                              \". input_shape=\", input_shape.DebugString(),\n                              \" output_shape=\", output_shape.DebugString()));\n\n  // Optimize for reshaping to the same shape.\n  if (input_shape == output_shape) {\n    context->set_output(output_indices_idx, input_indices_in);\n    context->set_output(output_shape_idx, input_shape_in);\n    return;\n  }\n\n  Tensor *result_shape = nullptr;\n  OP_REQUIRES_OK(context, context->allocate_output(output_shape_idx,\n                                                   TensorShape({output_rank}),\n                                                   &result_shape));\n  auto output_shape_vec = result_shape->vec<int64>();\n  for (int j = 0; j < output_shape.dims(); ++j) {\n    output_shape_vec(j) = output_shape.dim_size(j);\n  }\n\n  Tensor *result_indices = nullptr;\n  OP_REQUIRES_OK(context,\n                 context->allocate_output(output_indices_idx,\n                                          TensorShape({nnz, output_rank}),\n                                          &result_indices));\n  if (nnz > 0) {\n    OP_REQUIRES_OK(context, functor::ReshapeSparseTensorFunctor<Device>()(\n                                context, input_shape, output_shape,\n                                input_indices_in.matrix<int64>(),\n                                result_indices->matrix<int64>()));\n  }\n}",
        "func_hash": 228488147174937246000179946900319201208,
        "file_name": "reshape_util.cc",
        "file_hash": 224364433068010361888882257047924749715,
        "cwe": [
            "CWE-369"
        ],
        "cve": "CVE-2021-37640",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions the implementation of `tf.raw_ops.SparseReshape` can be made to trigger an integral division by 0 exception. The [implementation](https://github.com/tensorflow/tensorflow/blob/8d72537c6abf5a44103b57b9c2e22c14f5f49698/tensorflow/core/kernels/reshape_util.cc#L176-L181) calls the reshaping functor whenever there is at least an index in the input but does not check that shape of the input or the target shape have both a non-zero number of elements. The [reshape functor](https://github.com/tensorflow/tensorflow/blob/8d72537c6abf5a44103b57b9c2e22c14f5f49698/tensorflow/core/kernels/reshape_util.cc#L40-L78) blindly divides by the dimensions of the target shape. Hence, if this is not checked, code will result in a division by 0. We have patched the issue in GitHub commit 4923de56ec94fff7770df259ab7f2288a74feb41. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1 as this is the other affected version.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37640",
        "func_name": "ReshapeSparseTensor",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 198350,
        "project": "owntone-server",
        "commit_id": "246d8ae0cef27377e5dfe9ee3ad87e864d6b6266",
        "project_url": "https://github.com/owntone/owntone-server",
        "commit_url": "https://github.com/owntone/owntone-server/commit/246d8ae0cef27377e5dfe9ee3ad87e864d6b6266",
        "commit_message": "[misc] Fix use-after-free in net_bind()\n\nThanks to Ba Jinsheng for reporting this bug",
        "target": 1,
        "irrelevant": 0,
        "func_before": "net_bind(short unsigned *port, int type, const char *log_service_name)\n{\n  struct addrinfo hints = { 0 };\n  struct addrinfo *servinfo;\n  struct addrinfo *ptr;\n  const char *cfgaddr;\n  char addr[INET6_ADDRSTRLEN];\n  char strport[8];\n  int yes = 1;\n  int no = 0;\n  int fd;\n  int ret;\n\n  cfgaddr = cfg_getstr(cfg_getsec(cfg, \"general\"), \"bind_address\");\n\n  hints.ai_socktype = (type & (SOCK_STREAM | SOCK_DGRAM)); // filter since type can be SOCK_STREAM | SOCK_NONBLOCK\n  hints.ai_family = (cfg_getbool(cfg_getsec(cfg, \"general\"), \"ipv6\")) ? AF_INET6 : AF_INET;\n  hints.ai_flags = cfgaddr ? 0 : AI_PASSIVE;\n\n  snprintf(strport, sizeof(strport), \"%hu\", *port);\n  ret = getaddrinfo(cfgaddr, strport, &hints, &servinfo);\n  if (ret < 0)\n    {\n      DPRINTF(E_LOG, L_MISC, \"Failure creating '%s' service, could not resolve '%s' (port %s): %s\\n\", log_service_name, cfgaddr ? cfgaddr : \"(ANY)\", strport, gai_strerror(ret));\n      return -1;\n    }\n\n  for (ptr = servinfo, fd = -1; ptr != NULL; ptr = ptr->ai_next)\n    {\n      if (fd >= 0)\n\tclose(fd);\n\n      fd = socket(ptr->ai_family, type | SOCK_CLOEXEC, ptr->ai_protocol);\n      if (fd < 0)\n\tcontinue;\n\n      // TODO libevent sets this, we do the same?\n      ret = setsockopt(fd, SOL_SOCKET, SO_KEEPALIVE, &yes, sizeof(yes));\n      if (ret < 0)\n\tcontinue;\n\n      ret = setsockopt(fd, SOL_SOCKET, SO_REUSEADDR, &yes, sizeof(yes));\n      if (ret < 0)\n\tcontinue;\n\n      if (ptr->ai_family == AF_INET6)\n\t{\n\t  // We want to be sure the service is dual stack\n\t  ret = setsockopt(fd, IPPROTO_IPV6, IPV6_V6ONLY, &no, sizeof(no));\n\t  if (ret < 0)\n\t    continue;\n\t}\n\n      ret = bind(fd, ptr->ai_addr, ptr->ai_addrlen);\n      if (ret < 0)\n\tcontinue;\n\n      break;\n    }\n\n  freeaddrinfo(servinfo);\n\n  if (!ptr)\n    {\n      DPRINTF(E_LOG, L_MISC, \"Could not create service '%s' with address %s, port %hu: %s\\n\", log_service_name, cfgaddr ? cfgaddr : \"(ANY)\", *port, strerror(errno));\n      goto error;\n    }\n\n  // Get the port that was assigned\n  ret = getsockname(fd, ptr->ai_addr, &ptr->ai_addrlen);\n  if (ret < 0)\n    {\n      DPRINTF(E_LOG, L_MISC, \"Could not find address of service '%s': %s\\n\", log_service_name, strerror(errno));\n      goto error;\n    }\n\n  net_port_get(port, (union net_sockaddr *)ptr->ai_addr);\n  net_address_get(addr, sizeof(addr), (union net_sockaddr *)ptr->ai_addr);\n\n  DPRINTF(E_DBG, L_MISC, \"Service '%s' bound to %s, port %hu, socket %d\\n\", log_service_name, addr, *port, fd);\n\n  return fd;\n\n error:\n  close(fd);\n  return -1;\n}",
        "func_hash": 32546260713202661418218833633405896143,
        "file_name": "misc.c",
        "file_hash": 105075321496416144885475599863207164581,
        "cwe": [
            "CWE-416"
        ],
        "cve": "CVE-2021-38383",
        "cve_desc": "OwnTone (aka owntone-server) through 28.1 has a use-after-free in net_bind() in misc.c.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-38383",
        "func_name": "net_bind",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 198374,
        "project": "tensorflow",
        "commit_id": "803404044ae7a1efac48ba82d74111fce1ddb09a",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/803404044ae7a1efac48ba82d74111fce1ddb09a",
        "commit_message": "Fix security vulnerability with LSTMBlockCellOp\n\nPiperOrigin-RevId: 446028341",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor* x_tensor = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->input(\"x\", &x_tensor));\n\n    const Tensor* cs_prev_tensor = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->input(\"cs_prev\", &cs_prev_tensor));\n\n    const Tensor* h_prev_tensor = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->input(\"h_prev\", &h_prev_tensor));\n\n    const Tensor* w_tensor = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->input(\"w\", &w_tensor));\n\n    const Tensor* wci_tensor = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->input(\"wci\", &wci_tensor));\n\n    const Tensor* wcf_tensor = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->input(\"wcf\", &wcf_tensor));\n\n    const Tensor* wco_tensor = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->input(\"wco\", &wco_tensor));\n\n    const Tensor* b_tensor = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->input(\"b\", &b_tensor));\n\n    const int64_t batch_size = x_tensor->dim_size(0);\n    const int64_t input_size = x_tensor->dim_size(1);\n    const int64_t cell_size = cs_prev_tensor->dim_size(1);\n\n    // Sanity checks for our input shapes.\n    OP_REQUIRES(ctx, cs_prev_tensor->dim_size(0) == batch_size,\n                errors::InvalidArgument(\"cs_prev.dims(0) != batch_size: \",\n                                        cs_prev_tensor->dim_size(0), \" vs. \",\n                                        batch_size));\n    OP_REQUIRES(ctx, cs_prev_tensor->dim_size(1) == cell_size,\n                errors::InvalidArgument(\"cs_prev.dims(1) != cell_size: \",\n                                        cs_prev_tensor->dim_size(1), \" vs. \",\n                                        cell_size));\n\n    OP_REQUIRES(ctx, h_prev_tensor->dim_size(0) == batch_size,\n                errors::InvalidArgument(\"h_prev.dims(0) != batch_size: \",\n                                        h_prev_tensor->dim_size(0), \" vs. \",\n                                        batch_size));\n    OP_REQUIRES(ctx, h_prev_tensor->dim_size(1) == cell_size,\n                errors::InvalidArgument(\n                    \"h_prev.dims(1) != cell_size: \", h_prev_tensor->dim_size(1),\n                    \" vs. \", cell_size));\n\n    OP_REQUIRES(ctx, w_tensor->dim_size(0) == input_size + cell_size,\n                errors::InvalidArgument(\n                    \"w.dim_size(0) != input_size + cell_size: \",\n                    w_tensor->dim_size(0), \" vs. \", input_size + cell_size));\n    OP_REQUIRES(ctx, w_tensor->dim_size(1) == cell_size * 4,\n                errors::InvalidArgument(\n                    \"w.dim_size(1) != cell_size * 4: \", w_tensor->dim_size(1),\n                    \" vs. \", cell_size * 4));\n\n    OP_REQUIRES(ctx, b_tensor->dim_size(0) == cell_size * 4,\n                errors::InvalidArgument(\n                    \"b.dim_size(0) != cell_size * 4: \", b_tensor->dim_size(0),\n                    \" vs. \", cell_size * 4));\n\n    // Allocate our output tensors.\n    Tensor* i_tensor = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->forward_input_or_allocate_output(\n                            {\"h_prev\"}, \"i\",\n                            TensorShape({batch_size, cell_size}), &i_tensor));\n\n    Tensor* cs_tensor = nullptr;\n    OP_REQUIRES_OK(\n        ctx, ctx->allocate_output(\"cs\", TensorShape({batch_size, cell_size}),\n                                  &cs_tensor));\n\n    Tensor* f_tensor = nullptr;\n    OP_REQUIRES_OK(\n        ctx, ctx->allocate_output(\"f\", TensorShape({batch_size, cell_size}),\n                                  &f_tensor));\n\n    Tensor* o_tensor = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->forward_input_or_allocate_output(\n                            {\"cs_prev\"}, \"o\",\n                            TensorShape({batch_size, cell_size}), &o_tensor));\n\n    Tensor* ci_tensor = nullptr;\n    OP_REQUIRES_OK(\n        ctx, ctx->allocate_output(\"ci\", TensorShape({batch_size, cell_size}),\n                                  &ci_tensor));\n\n    Tensor* co_tensor = nullptr;\n    OP_REQUIRES_OK(\n        ctx, ctx->allocate_output(\"co\", TensorShape({batch_size, cell_size}),\n                                  &co_tensor));\n\n    Tensor* h_tensor = nullptr;\n    OP_REQUIRES_OK(\n        ctx, ctx->allocate_output(\"h\", TensorShape({batch_size, cell_size}),\n                                  &h_tensor));\n\n    // Allocate our temp tensors.\n    Tensor xh_tensor;\n    OP_REQUIRES_OK(ctx, ctx->allocate_temp(\n                            DataTypeToEnum<T>::v(),\n                            TensorShape({batch_size, input_size + cell_size}),\n                            &xh_tensor));\n\n    Tensor gates_tensor;\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_temp(DataTypeToEnum<T>::v(),\n                                      TensorShape({batch_size, cell_size * 4}),\n                                      &gates_tensor));\n\n    const Device& device = ctx->eigen_device<Device>();\n\n    functor::LSTMBlockCellFprop<Device, T, USE_CUBLAS, gate_layout>(\n        batch_size, input_size, cell_size)(\n        ctx, device, forget_bias_, cell_clip_, use_peephole_,\n        x_tensor->matrix<T>(), cs_prev_tensor->matrix<T>(),\n        h_prev_tensor->matrix<T>(), w_tensor->matrix<T>(), wci_tensor->vec<T>(),\n        wcf_tensor->vec<T>(), wco_tensor->vec<T>(), b_tensor->vec<T>(),\n        xh_tensor.matrix<T>(), i_tensor->matrix<T>(), cs_tensor->matrix<T>(),\n        f_tensor->matrix<T>(), o_tensor->matrix<T>(), ci_tensor->matrix<T>(),\n        co_tensor->matrix<T>(), gates_tensor.matrix<T>(),\n        h_tensor->matrix<T>());\n  }",
        "func_hash": 332787893197526379241591780916041422587,
        "file_name": "lstm_ops.cc",
        "file_hash": 94555141575162353468670590418949369497,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2022-29200",
        "cve_desc": "TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, the implementation of `tf.raw_ops.LSTMBlockCell` does not fully validate the input arguments. This results in a `CHECK`-failure which can be used to trigger a denial of service attack. The code does not validate the ranks of any of the arguments to this API call. This results in `CHECK`-failures when the elements of the tensor are accessed. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-29200",
        "func_name": "Compute",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 198399,
        "project": "uftpd",
        "commit_id": "0fb2c031ce0ace07cc19cd2cb2143c4b5a63c9dd",
        "project_url": "https://github.com/troglobit/uftpd",
        "commit_url": "https://github.com/troglobit/uftpd/commit/0fb2c031ce0ace07cc19cd2cb2143c4b5a63c9dd",
        "commit_message": "FTP: Fix buffer overflow in PORT parser, reported by Aaron Esau\n\nSigned-off-by: Joachim Nilsson <troglobit@gmail.com>",
        "target": 1,
        "irrelevant": 1,
        "func_before": "static void handle_PORT(ctrl_t *ctrl, char *str)\n{\n\tint a, b, c, d, e, f;\n\tchar addr[INET_ADDRSTRLEN];\n\tstruct sockaddr_in sin;\n\n\tif (ctrl->data_sd > 0) {\n\t\tuev_io_stop(&ctrl->data_watcher);\n\t\tclose(ctrl->data_sd);\n\t\tctrl->data_sd = -1;\n\t}\n\n\t/* Convert PORT command's argument to IP address + port */\n\tsscanf(str, \"%d,%d,%d,%d,%d,%d\", &a, &b, &c, &d, &e, &f);\n\tsprintf(addr, \"%d.%d.%d.%d\", a, b, c, d);\n\n\t/* Check IPv4 address using inet_aton(), throw away converted result */\n\tif (!inet_aton(addr, &(sin.sin_addr))) {\n\t\tERR(0, \"Invalid address '%s' given to PORT command\", addr);\n\t\tsend_msg(ctrl->sd, \"500 Illegal PORT command.\\r\\n\");\n\t\treturn;\n\t}\n\n\tstrlcpy(ctrl->data_address, addr, sizeof(ctrl->data_address));\n\tctrl->data_port = e * 256 + f;\n\n\tDBG(\"Client PORT command accepted for %s:%d\", ctrl->data_address, ctrl->data_port);\n\tsend_msg(ctrl->sd, \"200 PORT command successful.\\r\\n\");\n}",
        "func_hash": 5389607465091397932741652441661168107,
        "file_name": "ftpcmd.c",
        "file_hash": 13134413350440209021234166619599968419,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2020-20276",
        "cve_desc": "An unauthenticated stack-based buffer overflow vulnerability in common.c's handle_PORT in uftpd FTP server versions 2.10 and earlier can be abused to cause a crash and could potentially lead to remote code execution.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2020-20276",
        "func_name": "handle_PORT",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 198439,
        "project": "mruby",
        "commit_id": "3cf291f72224715942beaf8553e42ba8891ab3c6",
        "project_url": "https://github.com/mruby/mruby",
        "commit_url": "https://github.com/mruby/mruby/commit/3cf291f72224715942beaf8553e42ba8891ab3c6",
        "commit_message": "vm.c: create break object before clearing GC arena.\n\nOtherwise it possibly cause use-after-free.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "mrb_vm_exec(mrb_state *mrb, const struct RProc *proc, const mrb_code *pc)\n{\n  /* mrb_assert(MRB_PROC_CFUNC_P(proc)) */\n  const mrb_irep *irep = proc->body.irep;\n  const mrb_pool_value *pool = irep->pool;\n  const mrb_sym *syms = irep->syms;\n  mrb_code insn;\n  int ai = mrb_gc_arena_save(mrb);\n  struct mrb_jmpbuf *prev_jmp = mrb->jmp;\n  struct mrb_jmpbuf c_jmp;\n  uint32_t a;\n  uint16_t b;\n  uint16_t c;\n  mrb_sym mid;\n  const struct mrb_irep_catch_handler *ch;\n\n#ifdef DIRECT_THREADED\n  static const void * const optable[] = {\n#define OPCODE(x,_) &&L_OP_ ## x,\n#include \"mruby/ops.h\"\n#undef OPCODE\n  };\n#endif\n\n  mrb_bool exc_catched = FALSE;\nRETRY_TRY_BLOCK:\n\n  MRB_TRY(&c_jmp) {\n\n  if (exc_catched) {\n    exc_catched = FALSE;\n    mrb_gc_arena_restore(mrb, ai);\n    if (mrb->exc && mrb->exc->tt == MRB_TT_BREAK)\n      goto L_BREAK;\n    goto L_RAISE;\n  }\n  mrb->jmp = &c_jmp;\n  mrb_vm_ci_proc_set(mrb->c->ci, proc);\n\n#define regs (mrb->c->ci->stack)\n  INIT_DISPATCH {\n    CASE(OP_NOP, Z) {\n      /* do nothing */\n      NEXT;\n    }\n\n    CASE(OP_MOVE, BB) {\n      regs[a] = regs[b];\n      NEXT;\n    }\n\n    CASE(OP_LOADL, BB) {\n      switch (pool[b].tt) {   /* number */\n      case IREP_TT_INT32:\n        regs[a] = mrb_int_value(mrb, (mrb_int)pool[b].u.i32);\n        break;\n      case IREP_TT_INT64:\n#if defined(MRB_INT64)\n        regs[a] = mrb_int_value(mrb, (mrb_int)pool[b].u.i64);\n        break;\n#else\n#if defined(MRB_64BIT)\n        if (INT32_MIN <= pool[b].u.i64 && pool[b].u.i64 <= INT32_MAX) {\n          regs[a] = mrb_int_value(mrb, (mrb_int)pool[b].u.i64);\n          break;\n        }\n#endif\n        goto L_INT_OVERFLOW;\n#endif\n      case IREP_TT_BIGINT:\n        goto L_INT_OVERFLOW;\n#ifndef MRB_NO_FLOAT\n      case IREP_TT_FLOAT:\n        regs[a] = mrb_float_value(mrb, pool[b].u.f);\n        break;\n#endif\n      default:\n        /* should not happen (tt:string) */\n        regs[a] = mrb_nil_value();\n        break;\n      }\n      NEXT;\n    }\n\n    CASE(OP_LOADI, BB) {\n      SET_FIXNUM_VALUE(regs[a], b);\n      NEXT;\n    }\n\n    CASE(OP_LOADINEG, BB) {\n      SET_FIXNUM_VALUE(regs[a], -b);\n      NEXT;\n    }\n\n    CASE(OP_LOADI__1,B) goto L_LOADI;\n    CASE(OP_LOADI_0,B) goto L_LOADI;\n    CASE(OP_LOADI_1,B) goto L_LOADI;\n    CASE(OP_LOADI_2,B) goto L_LOADI;\n    CASE(OP_LOADI_3,B) goto L_LOADI;\n    CASE(OP_LOADI_4,B) goto L_LOADI;\n    CASE(OP_LOADI_5,B) goto L_LOADI;\n    CASE(OP_LOADI_6,B) goto L_LOADI;\n    CASE(OP_LOADI_7, B) {\n    L_LOADI:\n      SET_FIXNUM_VALUE(regs[a], (mrb_int)insn - (mrb_int)OP_LOADI_0);\n      NEXT;\n    }\n\n    CASE(OP_LOADI16, BS) {\n      SET_FIXNUM_VALUE(regs[a], (mrb_int)(int16_t)b);\n      NEXT;\n    }\n\n    CASE(OP_LOADI32, BSS) {\n      SET_INT_VALUE(mrb, regs[a], (int32_t)(((uint32_t)b<<16)+c));\n      NEXT;\n    }\n\n    CASE(OP_LOADSYM, BB) {\n      SET_SYM_VALUE(regs[a], syms[b]);\n      NEXT;\n    }\n\n    CASE(OP_LOADNIL, B) {\n      SET_NIL_VALUE(regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_LOADSELF, B) {\n      regs[a] = regs[0];\n      NEXT;\n    }\n\n    CASE(OP_LOADT, B) {\n      SET_TRUE_VALUE(regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_LOADF, B) {\n      SET_FALSE_VALUE(regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETGV, BB) {\n      mrb_value val = mrb_gv_get(mrb, syms[b]);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETGV, BB) {\n      mrb_gv_set(mrb, syms[b], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETSV, BB) {\n      mrb_value val = mrb_vm_special_get(mrb, syms[b]);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETSV, BB) {\n      mrb_vm_special_set(mrb, syms[b], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETIV, BB) {\n      regs[a] = mrb_iv_get(mrb, regs[0], syms[b]);\n      NEXT;\n    }\n\n    CASE(OP_SETIV, BB) {\n      mrb_iv_set(mrb, regs[0], syms[b], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETCV, BB) {\n      mrb_value val;\n      val = mrb_vm_cv_get(mrb, syms[b]);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETCV, BB) {\n      mrb_vm_cv_set(mrb, syms[b], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETIDX, B) {\n      mrb_value va = regs[a], vb = regs[a+1];\n      switch (mrb_type(va)) {\n      case MRB_TT_ARRAY:\n        if (!mrb_integer_p(vb)) goto getidx_fallback;\n        regs[a] = mrb_ary_entry(va, mrb_integer(vb));\n        break;\n      case MRB_TT_HASH:\n        va = mrb_hash_get(mrb, va, vb);\n        regs[a] = va;\n        break;\n      case MRB_TT_STRING:\n        switch (mrb_type(vb)) {\n        case MRB_TT_INTEGER:\n        case MRB_TT_STRING:\n        case MRB_TT_RANGE:\n          va = mrb_str_aref(mrb, va, vb, mrb_undef_value());\n          regs[a] = va;\n          break;\n        default:\n          goto getidx_fallback;\n        }\n        break;\n      default:\n      getidx_fallback:\n        mid = MRB_OPSYM(aref);\n        goto L_SEND_SYM;\n      }\n      NEXT;\n    }\n\n    CASE(OP_SETIDX, B) {\n      c = 2;\n      mid = MRB_OPSYM(aset);\n      SET_NIL_VALUE(regs[a+3]);\n      goto L_SENDB_SYM;\n    }\n\n    CASE(OP_GETCONST, BB) {\n      mrb_value v = mrb_vm_const_get(mrb, syms[b]);\n      regs[a] = v;\n      NEXT;\n    }\n\n    CASE(OP_SETCONST, BB) {\n      mrb_vm_const_set(mrb, syms[b], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETMCNST, BB) {\n      mrb_value v = mrb_const_get(mrb, regs[a], syms[b]);\n      regs[a] = v;\n      NEXT;\n    }\n\n    CASE(OP_SETMCNST, BB) {\n      mrb_const_set(mrb, regs[a+1], syms[b], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETUPVAR, BBB) {\n      mrb_value *regs_a = regs + a;\n      struct REnv *e = uvenv(mrb, c);\n\n      if (e && b < MRB_ENV_LEN(e)) {\n        *regs_a = e->stack[b];\n      }\n      else {\n        *regs_a = mrb_nil_value();\n      }\n      NEXT;\n    }\n\n    CASE(OP_SETUPVAR, BBB) {\n      struct REnv *e = uvenv(mrb, c);\n\n      if (e) {\n        mrb_value *regs_a = regs + a;\n\n        if (b < MRB_ENV_LEN(e)) {\n          e->stack[b] = *regs_a;\n          mrb_write_barrier(mrb, (struct RBasic*)e);\n        }\n      }\n      NEXT;\n    }\n\n    CASE(OP_JMP, S) {\n      pc += (int16_t)a;\n      JUMP;\n    }\n    CASE(OP_JMPIF, BS) {\n      if (mrb_test(regs[a])) {\n        pc += (int16_t)b;\n        JUMP;\n      }\n      NEXT;\n    }\n    CASE(OP_JMPNOT, BS) {\n      if (!mrb_test(regs[a])) {\n        pc += (int16_t)b;\n        JUMP;\n      }\n      NEXT;\n    }\n    CASE(OP_JMPNIL, BS) {\n      if (mrb_nil_p(regs[a])) {\n        pc += (int16_t)b;\n        JUMP;\n      }\n      NEXT;\n    }\n\n    CASE(OP_JMPUW, S) {\n      a = (uint32_t)((pc - irep->iseq) + (int16_t)a);\n      CHECKPOINT_RESTORE(RBREAK_TAG_JUMP) {\n        struct RBreak *brk = (struct RBreak*)mrb->exc;\n        mrb_value target = mrb_break_value_get(brk);\n        mrb_assert(mrb_integer_p(target));\n        a = (uint32_t)mrb_integer(target);\n        mrb_assert(a >= 0 && a < irep->ilen);\n      }\n      CHECKPOINT_MAIN(RBREAK_TAG_JUMP) {\n        ch = catch_handler_find(mrb, mrb->c->ci, pc, MRB_CATCH_FILTER_ENSURE);\n        if (ch) {\n          /* avoiding a jump from a catch handler into the same handler */\n          if (a < mrb_irep_catch_handler_unpack(ch->begin) || a >= mrb_irep_catch_handler_unpack(ch->end)) {\n            THROW_TAGGED_BREAK(mrb, RBREAK_TAG_JUMP, proc, mrb_fixnum_value(a));\n          }\n        }\n      }\n      CHECKPOINT_END(RBREAK_TAG_JUMP);\n\n      mrb->exc = NULL; /* clear break object */\n      pc = irep->iseq + a;\n      JUMP;\n    }\n\n    CASE(OP_EXCEPT, B) {\n      mrb_value exc;\n\n      if (mrb->exc == NULL) {\n        exc = mrb_nil_value();\n      }\n      else {\n        switch (mrb->exc->tt) {\n        case MRB_TT_BREAK:\n        case MRB_TT_EXCEPTION:\n          exc = mrb_obj_value(mrb->exc);\n          break;\n        default:\n          mrb_assert(!\"bad mrb_type\");\n          exc = mrb_nil_value();\n          break;\n        }\n        mrb->exc = NULL;\n      }\n      regs[a] = exc;\n      NEXT;\n    }\n    CASE(OP_RESCUE, BB) {\n      mrb_value exc = regs[a];  /* exc on stack */\n      mrb_value e = regs[b];\n      struct RClass *ec;\n\n      switch (mrb_type(e)) {\n      case MRB_TT_CLASS:\n      case MRB_TT_MODULE:\n        break;\n      default:\n        {\n          mrb_value exc;\n\n          exc = mrb_exc_new_lit(mrb, E_TYPE_ERROR,\n                                    \"class or module required for rescue clause\");\n          mrb_exc_set(mrb, exc);\n          goto L_RAISE;\n        }\n      }\n      ec = mrb_class_ptr(e);\n      regs[b] = mrb_bool_value(mrb_obj_is_kind_of(mrb, exc, ec));\n      NEXT;\n    }\n\n    CASE(OP_RAISEIF, B) {\n      mrb_value exc = regs[a];\n      if (mrb_break_p(exc)) {\n        mrb->exc = mrb_obj_ptr(exc);\n        goto L_BREAK;\n      }\n      mrb_exc_set(mrb, exc);\n      if (mrb->exc) {\n        goto L_RAISE;\n      }\n      NEXT;\n    }\n\n    CASE(OP_SSEND, BBB) {\n      regs[a] = regs[0];\n      insn = OP_SEND;\n    }\n    goto L_SENDB;\n\n    CASE(OP_SSENDB, BBB) {\n      regs[a] = regs[0];\n    }\n    goto L_SENDB;\n\n    CASE(OP_SEND, BBB)\n    goto L_SENDB;\n\n    L_SEND_SYM:\n    c = 1;\n    /* push nil after arguments */\n    SET_NIL_VALUE(regs[a+2]);\n    goto L_SENDB_SYM;\n\n    CASE(OP_SENDB, BBB)\n    L_SENDB:\n    mid = syms[b];\n    L_SENDB_SYM:\n    {\n      mrb_callinfo *ci = mrb->c->ci;\n      mrb_method_t m;\n      struct RClass *cls;\n      mrb_value recv, blk;\n\n      ARGUMENT_NORMALIZE(a, &c, insn);\n\n      recv = regs[a];\n      cls = mrb_class(mrb, recv);\n      m = mrb_method_search_vm(mrb, &cls, mid);\n      if (MRB_METHOD_UNDEF_P(m)) {\n        m = prepare_missing(mrb, recv, mid, &cls, a, &c, blk, 0);\n        mid = MRB_SYM(method_missing);\n      }\n\n      /* push callinfo */\n      ci = cipush(mrb, a, 0, cls, NULL, mid, c);\n\n      if (MRB_METHOD_CFUNC_P(m)) {\n        if (MRB_METHOD_PROC_P(m)) {\n          struct RProc *p = MRB_METHOD_PROC(m);\n\n          mrb_vm_ci_proc_set(ci, p);\n          recv = p->body.func(mrb, recv);\n        }\n        else {\n          if (MRB_METHOD_NOARG_P(m)) {\n            check_method_noarg(mrb, ci);\n          }\n          recv = MRB_METHOD_FUNC(m)(mrb, recv);\n        }\n        mrb_gc_arena_shrink(mrb, ai);\n        if (mrb->exc) goto L_RAISE;\n        ci = mrb->c->ci;\n        if (mrb_proc_p(blk)) {\n          struct RProc *p = mrb_proc_ptr(blk);\n          if (p && !MRB_PROC_STRICT_P(p) && MRB_PROC_ENV(p) == mrb_vm_ci_env(&ci[-1])) {\n            p->flags |= MRB_PROC_ORPHAN;\n          }\n        }\n        if (!ci->u.target_class) { /* return from context modifying method (resume/yield) */\n          if (ci->cci == CINFO_RESUMED) {\n            mrb->jmp = prev_jmp;\n            return recv;\n          }\n          else {\n            mrb_assert(!MRB_PROC_CFUNC_P(ci[-1].proc));\n            proc = ci[-1].proc;\n            irep = proc->body.irep;\n            pool = irep->pool;\n            syms = irep->syms;\n          }\n        }\n        ci->stack[0] = recv;\n        /* pop stackpos */\n        ci = cipop(mrb);\n        pc = ci->pc;\n      }\n      else {\n        /* setup environment for calling method */\n        mrb_vm_ci_proc_set(ci, (proc = MRB_METHOD_PROC(m)));\n        irep = proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n        mrb_stack_extend(mrb, (irep->nregs < 4) ? 4 : irep->nregs);\n        pc = irep->iseq;\n      }\n    }\n    JUMP;\n\n    CASE(OP_CALL, Z) {\n      mrb_callinfo *ci = mrb->c->ci;\n      mrb_value recv = ci->stack[0];\n      struct RProc *m = mrb_proc_ptr(recv);\n\n      /* replace callinfo */\n      ci->u.target_class = MRB_PROC_TARGET_CLASS(m);\n      mrb_vm_ci_proc_set(ci, m);\n      if (MRB_PROC_ENV_P(m)) {\n        ci->mid = MRB_PROC_ENV(m)->mid;\n      }\n\n      /* prepare stack */\n      if (MRB_PROC_CFUNC_P(m)) {\n        recv = MRB_PROC_CFUNC(m)(mrb, recv);\n        mrb_gc_arena_shrink(mrb, ai);\n        if (mrb->exc) goto L_RAISE;\n        /* pop stackpos */\n        ci = cipop(mrb);\n        pc = ci->pc;\n        ci[1].stack[0] = recv;\n        irep = mrb->c->ci->proc->body.irep;\n      }\n      else {\n        /* setup environment for calling method */\n        proc = m;\n        irep = m->body.irep;\n        if (!irep) {\n          mrb->c->ci->stack[0] = mrb_nil_value();\n          a = 0;\n          c = OP_R_NORMAL;\n          goto L_OP_RETURN_BODY;\n        }\n        mrb_int nargs = mrb_ci_bidx(ci)+1;\n        if (nargs < irep->nregs) {\n          mrb_stack_extend(mrb, irep->nregs);\n          stack_clear(regs+nargs, irep->nregs-nargs);\n        }\n        if (MRB_PROC_ENV_P(m)) {\n          regs[0] = MRB_PROC_ENV(m)->stack[0];\n        }\n        pc = irep->iseq;\n      }\n      pool = irep->pool;\n      syms = irep->syms;\n      JUMP;\n    }\n\n    CASE(OP_SUPER, BB) {\n      mrb_method_t m;\n      struct RClass *cls;\n      mrb_callinfo *ci = mrb->c->ci;\n      mrb_value recv, blk;\n      const struct RProc *p = ci->proc;\n      mrb_sym mid = ci->mid;\n      struct RClass* target_class = MRB_PROC_TARGET_CLASS(p);\n\n      if (MRB_PROC_ENV_P(p) && p->e.env->mid && p->e.env->mid != mid) { /* alias support */\n        mid = p->e.env->mid;    /* restore old mid */\n      }\n\n      if (mid == 0 || !target_class) {\n        mrb_value exc = mrb_exc_new_lit(mrb, E_NOMETHOD_ERROR, \"super called outside of method\");\n        mrb_exc_set(mrb, exc);\n        goto L_RAISE;\n      }\n      if (target_class->flags & MRB_FL_CLASS_IS_PREPENDED) {\n        target_class = mrb_vm_ci_target_class(ci);\n      }\n      else if (target_class->tt == MRB_TT_MODULE) {\n        target_class = mrb_vm_ci_target_class(ci);\n        if (!target_class || target_class->tt != MRB_TT_ICLASS) {\n          goto super_typeerror;\n        }\n      }\n      recv = regs[0];\n      if (!mrb_obj_is_kind_of(mrb, recv, target_class)) {\n      super_typeerror: ;\n        mrb_value exc = mrb_exc_new_lit(mrb, E_TYPE_ERROR,\n                                            \"self has wrong type to call super in this context\");\n        mrb_exc_set(mrb, exc);\n        goto L_RAISE;\n      }\n\n      ARGUMENT_NORMALIZE(a, &b, OP_SUPER);\n\n      cls = target_class->super;\n      m = mrb_method_search_vm(mrb, &cls, mid);\n      if (MRB_METHOD_UNDEF_P(m)) {\n        m = prepare_missing(mrb, recv, mid, &cls, a, &b, blk, 1);\n        mid = MRB_SYM(method_missing);\n      }\n\n      /* push callinfo */\n      ci = cipush(mrb, a, 0, cls, NULL, mid, b);\n\n      /* prepare stack */\n      ci->stack[0] = recv;\n\n      if (MRB_METHOD_CFUNC_P(m)) {\n        mrb_value v;\n\n        if (MRB_METHOD_PROC_P(m)) {\n          mrb_vm_ci_proc_set(ci, MRB_METHOD_PROC(m));\n        }\n        v = MRB_METHOD_CFUNC(m)(mrb, recv);\n        mrb_gc_arena_restore(mrb, ai);\n        if (mrb->exc) goto L_RAISE;\n        ci = mrb->c->ci;\n        mrb_assert(!mrb_break_p(v));\n        if (!mrb_vm_ci_target_class(ci)) { /* return from context modifying method (resume/yield) */\n          if (ci->cci == CINFO_RESUMED) {\n            mrb->jmp = prev_jmp;\n            return v;\n          }\n          else {\n            mrb_assert(!MRB_PROC_CFUNC_P(ci[-1].proc));\n            proc = ci[-1].proc;\n            irep = proc->body.irep;\n            pool = irep->pool;\n            syms = irep->syms;\n          }\n        }\n        mrb->c->ci->stack[0] = v;\n        ci = cipop(mrb);\n        pc = ci->pc;\n      }\n      else {\n        /* setup environment for calling method */\n        mrb_vm_ci_proc_set(ci, (proc = MRB_METHOD_PROC(m)));\n        irep = proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n        mrb_stack_extend(mrb, (irep->nregs < 4) ? 4 : irep->nregs);\n        pc = irep->iseq;\n      }\n      JUMP;\n    }\n\n    CASE(OP_ARGARY, BS) {\n      mrb_int m1 = (b>>11)&0x3f;\n      mrb_int r  = (b>>10)&0x1;\n      mrb_int m2 = (b>>5)&0x1f;\n      mrb_int kd = (b>>4)&0x1;\n      mrb_int lv = (b>>0)&0xf;\n      mrb_value *stack;\n\n      if (mrb->c->ci->mid == 0 || mrb_vm_ci_target_class(mrb->c->ci) == NULL) {\n        mrb_value exc;\n\n      L_NOSUPER:\n        exc = mrb_exc_new_lit(mrb, E_NOMETHOD_ERROR, \"super called outside of method\");\n        mrb_exc_set(mrb, exc);\n        goto L_RAISE;\n      }\n      if (lv == 0) stack = regs + 1;\n      else {\n        struct REnv *e = uvenv(mrb, lv-1);\n        if (!e) goto L_NOSUPER;\n        if (MRB_ENV_LEN(e) <= m1+r+m2+1)\n          goto L_NOSUPER;\n        stack = e->stack + 1;\n      }\n      if (r == 0) {\n        regs[a] = mrb_ary_new_from_values(mrb, m1+m2, stack);\n      }\n      else {\n        mrb_value *pp = NULL;\n        struct RArray *rest;\n        mrb_int len = 0;\n\n        if (mrb_array_p(stack[m1])) {\n          struct RArray *ary = mrb_ary_ptr(stack[m1]);\n\n          pp = ARY_PTR(ary);\n          len = ARY_LEN(ary);\n        }\n        regs[a] = mrb_ary_new_capa(mrb, m1+len+m2);\n        rest = mrb_ary_ptr(regs[a]);\n        if (m1 > 0) {\n          stack_copy(ARY_PTR(rest), stack, m1);\n        }\n        if (len > 0) {\n          stack_copy(ARY_PTR(rest)+m1, pp, len);\n        }\n        if (m2 > 0) {\n          stack_copy(ARY_PTR(rest)+m1+len, stack+m1+1, m2);\n        }\n        ARY_SET_LEN(rest, m1+len+m2);\n      }\n      if (kd) {\n        regs[a+1] = stack[m1+r+m2];\n        regs[a+2] = stack[m1+r+m2+1];\n      }\n      else {\n        regs[a+1] = stack[m1+r+m2];\n      }\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_ENTER, W) {\n      mrb_int m1 = MRB_ASPEC_REQ(a);\n      mrb_int o  = MRB_ASPEC_OPT(a);\n      mrb_int r  = MRB_ASPEC_REST(a);\n      mrb_int m2 = MRB_ASPEC_POST(a);\n      mrb_int kd = (MRB_ASPEC_KEY(a) > 0 || MRB_ASPEC_KDICT(a))? 1 : 0;\n      /* unused\n      int b  = MRB_ASPEC_BLOCK(a);\n      */\n      mrb_int const len = m1 + o + r + m2;\n\n      mrb_callinfo *ci = mrb->c->ci;\n      mrb_int argc = ci->n;\n      mrb_value *argv = regs+1;\n      mrb_value * const argv0 = argv;\n      mrb_int const kw_pos = len + kd;    /* where kwhash should be */\n      mrb_int const blk_pos = kw_pos + 1; /* where block should be */\n      mrb_value blk = regs[mrb_ci_bidx(ci)];\n      mrb_value kdict = mrb_nil_value();\n\n      /* keyword arguments */\n      if (ci->nk > 0) {\n        mrb_int kidx = mrb_ci_kidx(ci);\n        kdict = regs[kidx];\n        if (!mrb_hash_p(kdict) || mrb_hash_size(mrb, kdict) == 0) {\n          kdict = mrb_nil_value();\n          ci->nk = 0;\n        }\n      }\n      if (!kd && !mrb_nil_p(kdict)) {\n        if (argc < 14) {\n          ci->n++;\n          argc++;    /* include kdict in normal arguments */\n        }\n        else if (argc == 14) {\n          /* pack arguments and kdict */\n          regs[1] = mrb_ary_new_from_values(mrb, argc+1, &regs[1]);\n          argc = ci->n = 15;\n        }\n        else {/* argc == 15 */\n          /* push kdict to packed arguments */\n          mrb_ary_push(mrb, regs[1], regs[2]);\n        }\n        ci->nk = 0;\n      }\n      if (kd && MRB_ASPEC_KEY(a) > 0 && mrb_hash_p(kdict)) {\n        kdict = mrb_hash_dup(mrb, kdict);\n      }\n\n      /* arguments is passed with Array */\n      if (argc == 15) {\n        struct RArray *ary = mrb_ary_ptr(regs[1]);\n        argv = ARY_PTR(ary);\n        argc = (int)ARY_LEN(ary);\n        mrb_gc_protect(mrb, regs[1]);\n      }\n\n      /* strict argument check */\n      if (ci->proc && MRB_PROC_STRICT_P(ci->proc)) {\n        if (argc < m1 + m2 || (r == 0 && argc > len)) {\n          argnum_error(mrb, m1+m2);\n          goto L_RAISE;\n        }\n      }\n      /* extract first argument array to arguments */\n      else if (len > 1 && argc == 1 && mrb_array_p(argv[0])) {\n        mrb_gc_protect(mrb, argv[0]);\n        argc = (int)RARRAY_LEN(argv[0]);\n        argv = RARRAY_PTR(argv[0]);\n      }\n\n      /* rest arguments */\n      mrb_value rest = mrb_nil_value();\n      if (argc < len) {\n        mrb_int mlen = m2;\n        if (argc < m1+m2) {\n          mlen = m1 < argc ? argc - m1 : 0;\n        }\n\n        /* copy mandatory and optional arguments */\n        if (argv0 != argv && argv) {\n          value_move(&regs[1], argv, argc-mlen); /* m1 + o */\n        }\n        if (argc < m1) {\n          stack_clear(&regs[argc+1], m1-argc);\n        }\n        /* copy post mandatory arguments */\n        if (mlen) {\n          value_move(&regs[len-m2+1], &argv[argc-mlen], mlen);\n        }\n        if (mlen < m2) {\n          stack_clear(&regs[len-m2+mlen+1], m2-mlen);\n        }\n        /* initialize rest arguments with empty Array */\n        if (r) {\n          rest = mrb_ary_new_capa(mrb, 0);\n          regs[m1+o+1] = rest;\n        }\n        /* skip initializer of passed arguments */\n        if (o > 0 && argc > m1+m2)\n          pc += (argc - m1 - m2)*3;\n      }\n      else {\n        mrb_int rnum = 0;\n        if (argv0 != argv) {\n          value_move(&regs[1], argv, m1+o);\n        }\n        if (r) {\n          rnum = argc-m1-o-m2;\n          rest = mrb_ary_new_from_values(mrb, rnum, argv+m1+o);\n          regs[m1+o+1] = rest;\n        }\n        if (m2 > 0 && argc-m2 > m1) {\n          value_move(&regs[m1+o+r+1], &argv[m1+o+rnum], m2);\n        }\n        pc += o*3;\n      }\n\n      /* need to be update blk first to protect blk from GC */\n      regs[blk_pos] = blk;              /* move block */\n      if (kd) {\n        if (mrb_nil_p(kdict))\n          kdict = mrb_hash_new_capa(mrb, 0);\n        regs[kw_pos] = kdict;           /* set kwhash */\n      }\n\n      /* format arguments for generated code */\n      mrb->c->ci->n = len;\n\n      /* clear local (but non-argument) variables */\n      if (irep->nlocals-blk_pos-1 > 0) {\n        stack_clear(&regs[blk_pos+1], irep->nlocals-blk_pos-1);\n      }\n      JUMP;\n    }\n\n    CASE(OP_KARG, BB) {\n      mrb_value k = mrb_symbol_value(syms[b]);\n      mrb_int kidx = mrb_ci_kidx(mrb->c->ci);\n      mrb_value kdict, v;\n\n      if (kidx < 0 || !mrb_hash_p(kdict=regs[kidx]) || !mrb_hash_key_p(mrb, kdict, k)) {\n        mrb_value str = mrb_format(mrb, \"missing keyword: %v\", k);\n        mrb_exc_set(mrb, mrb_exc_new_str(mrb, E_ARGUMENT_ERROR, str));\n        goto L_RAISE;\n      }\n      v = mrb_hash_get(mrb, kdict, k);\n      regs[a] = v;\n      mrb_hash_delete_key(mrb, kdict, k);\n      NEXT;\n    }\n\n    CASE(OP_KEY_P, BB) {\n      mrb_value k = mrb_symbol_value(syms[b]);\n      mrb_int kidx = mrb_ci_kidx(mrb->c->ci);\n      mrb_value kdict;\n      mrb_bool key_p = FALSE;\n\n      if (kidx >= 0 && mrb_hash_p(kdict=regs[kidx])) {\n        key_p = mrb_hash_key_p(mrb, kdict, k);\n      }\n      regs[a] = mrb_bool_value(key_p);\n      NEXT;\n    }\n\n    CASE(OP_KEYEND, Z) {\n      mrb_int kidx = mrb_ci_kidx(mrb->c->ci);\n      mrb_value kdict;\n\n      if (kidx >= 0 && mrb_hash_p(kdict=regs[kidx]) && !mrb_hash_empty_p(mrb, kdict)) {\n        mrb_value keys = mrb_hash_keys(mrb, kdict);\n        mrb_value key1 = RARRAY_PTR(keys)[0];\n        mrb_value str = mrb_format(mrb, \"unknown keyword: %v\", key1);\n        mrb_exc_set(mrb, mrb_exc_new_str(mrb, E_ARGUMENT_ERROR, str));\n        goto L_RAISE;\n      }\n      NEXT;\n    }\n\n    CASE(OP_BREAK, B) {\n      c = OP_R_BREAK;\n      goto L_RETURN;\n    }\n    CASE(OP_RETURN_BLK, B) {\n      c = OP_R_RETURN;\n      goto L_RETURN;\n    }\n    CASE(OP_RETURN, B)\n    c = OP_R_NORMAL;\n    L_RETURN:\n    {\n      mrb_callinfo *ci;\n\n      ci = mrb->c->ci;\n      if (ci->mid) {\n        mrb_value blk = regs[mrb_ci_bidx(ci)];\n\n        if (mrb_proc_p(blk)) {\n          struct RProc *p = mrb_proc_ptr(blk);\n\n          if (!MRB_PROC_STRICT_P(p) &&\n              ci > mrb->c->cibase && MRB_PROC_ENV(p) == mrb_vm_ci_env(&ci[-1])) {\n            p->flags |= MRB_PROC_ORPHAN;\n          }\n        }\n      }\n\n      if (mrb->exc) {\n      L_RAISE:\n        ci = mrb->c->ci;\n        if (ci == mrb->c->cibase) {\n          ch = catch_handler_find(mrb, ci, pc, MRB_CATCH_FILTER_ALL);\n          if (ch == NULL) goto L_FTOP;\n          goto L_CATCH;\n        }\n        while ((ch = catch_handler_find(mrb, ci, pc, MRB_CATCH_FILTER_ALL)) == NULL) {\n          ci = cipop(mrb);\n          if (ci[1].cci == CINFO_SKIP && prev_jmp) {\n            mrb->jmp = prev_jmp;\n            MRB_THROW(prev_jmp);\n          }\n          pc = ci[0].pc;\n          if (ci == mrb->c->cibase) {\n            ch = catch_handler_find(mrb, ci, pc, MRB_CATCH_FILTER_ALL);\n            if (ch == NULL) {\n            L_FTOP:             /* fiber top */\n              if (mrb->c == mrb->root_c) {\n                mrb->c->ci->stack = mrb->c->stbase;\n                goto L_STOP;\n              }\n              else {\n                struct mrb_context *c = mrb->c;\n\n                c->status = MRB_FIBER_TERMINATED;\n                mrb->c = c->prev;\n                c->prev = NULL;\n                goto L_RAISE;\n              }\n            }\n            break;\n          }\n        }\n      L_CATCH:\n        if (ch == NULL) goto L_STOP;\n        if (FALSE) {\n        L_CATCH_TAGGED_BREAK: /* from THROW_TAGGED_BREAK() or UNWIND_ENSURE() */\n          ci = mrb->c->ci;\n        }\n        proc = ci->proc;\n        irep = proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n        mrb_stack_extend(mrb, irep->nregs);\n        pc = irep->iseq + mrb_irep_catch_handler_unpack(ch->target);\n      }\n      else {\n        mrb_int acc;\n        mrb_value v;\n\n        ci = mrb->c->ci;\n        v = regs[a];\n        mrb_gc_protect(mrb, v);\n        switch (c) {\n        case OP_R_RETURN:\n          /* Fall through to OP_R_NORMAL otherwise */\n          if (ci->cci == CINFO_NONE && MRB_PROC_ENV_P(proc) && !MRB_PROC_STRICT_P(proc)) {\n            const struct RProc *dst;\n            mrb_callinfo *cibase;\n            cibase = mrb->c->cibase;\n            dst = top_proc(mrb, proc);\n\n            if (MRB_PROC_ENV_P(dst)) {\n              struct REnv *e = MRB_PROC_ENV(dst);\n\n              if (!MRB_ENV_ONSTACK_P(e) || (e->cxt && e->cxt != mrb->c)) {\n                localjump_error(mrb, LOCALJUMP_ERROR_RETURN);\n                goto L_RAISE;\n              }\n            }\n            /* check jump destination */\n            while (cibase <= ci && ci->proc != dst) {\n              if (ci->cci > CINFO_NONE) { /* jump cross C boundary */\n                localjump_error(mrb, LOCALJUMP_ERROR_RETURN);\n                goto L_RAISE;\n              }\n              ci--;\n            }\n            if (ci <= cibase) { /* no jump destination */\n              localjump_error(mrb, LOCALJUMP_ERROR_RETURN);\n              goto L_RAISE;\n            }\n            ci = mrb->c->ci;\n            while (cibase <= ci && ci->proc != dst) {\n              CHECKPOINT_RESTORE(RBREAK_TAG_RETURN_BLOCK) {\n                cibase = mrb->c->cibase;\n                dst = top_proc(mrb, proc);\n              }\n              CHECKPOINT_MAIN(RBREAK_TAG_RETURN_BLOCK) {\n                UNWIND_ENSURE(mrb, ci, pc, RBREAK_TAG_RETURN_BLOCK, proc, v);\n              }\n              CHECKPOINT_END(RBREAK_TAG_RETURN_BLOCK);\n              ci = cipop(mrb);\n              pc = ci->pc;\n            }\n            proc = ci->proc;\n            mrb->exc = NULL; /* clear break object */\n            break;\n          }\n          /* fallthrough */\n        case OP_R_NORMAL:\n        NORMAL_RETURN:\n          if (ci == mrb->c->cibase) {\n            struct mrb_context *c;\n            c = mrb->c;\n\n            if (!c->prev) { /* toplevel return */\n              regs[irep->nlocals] = v;\n              goto CHECKPOINT_LABEL_MAKE(RBREAK_TAG_STOP);\n            }\n            if (!c->vmexec && c->prev->ci == c->prev->cibase) {\n              mrb_value exc = mrb_exc_new_lit(mrb, E_FIBER_ERROR, \"double resume\");\n              mrb_exc_set(mrb, exc);\n              goto L_RAISE;\n            }\n            CHECKPOINT_RESTORE(RBREAK_TAG_RETURN_TOPLEVEL) {\n              c = mrb->c;\n            }\n            CHECKPOINT_MAIN(RBREAK_TAG_RETURN_TOPLEVEL) {\n              UNWIND_ENSURE(mrb, ci, pc, RBREAK_TAG_RETURN_TOPLEVEL, proc, v);\n            }\n            CHECKPOINT_END(RBREAK_TAG_RETURN_TOPLEVEL);\n            /* automatic yield at the end */\n            c->status = MRB_FIBER_TERMINATED;\n            mrb->c = c->prev;\n            mrb->c->status = MRB_FIBER_RUNNING;\n            c->prev = NULL;\n            if (c->vmexec) {\n              mrb_gc_arena_restore(mrb, ai);\n              c->vmexec = FALSE;\n              mrb->jmp = prev_jmp;\n              return v;\n            }\n            ci = mrb->c->ci;\n          }\n          CHECKPOINT_RESTORE(RBREAK_TAG_RETURN) {\n            /* do nothing */\n          }\n          CHECKPOINT_MAIN(RBREAK_TAG_RETURN) {\n            UNWIND_ENSURE(mrb, ci, pc, RBREAK_TAG_RETURN, proc, v);\n          }\n          CHECKPOINT_END(RBREAK_TAG_RETURN);\n          mrb->exc = NULL; /* clear break object */\n          break;\n        case OP_R_BREAK:\n          if (MRB_PROC_STRICT_P(proc)) goto NORMAL_RETURN;\n          if (MRB_PROC_ORPHAN_P(proc)) {\n            mrb_value exc;\n\n          L_BREAK_ERROR:\n            exc = mrb_exc_new_lit(mrb, E_LOCALJUMP_ERROR,\n                                      \"break from proc-closure\");\n            mrb_exc_set(mrb, exc);\n            goto L_RAISE;\n          }\n          if (!MRB_PROC_ENV_P(proc) || !MRB_ENV_ONSTACK_P(MRB_PROC_ENV(proc))) {\n            goto L_BREAK_ERROR;\n          }\n          else {\n            struct REnv *e = MRB_PROC_ENV(proc);\n\n            if (e->cxt != mrb->c) {\n              goto L_BREAK_ERROR;\n            }\n          }\n          CHECKPOINT_RESTORE(RBREAK_TAG_BREAK) {\n            /* do nothing */\n          }\n          CHECKPOINT_MAIN(RBREAK_TAG_BREAK) {\n            UNWIND_ENSURE(mrb, ci, pc, RBREAK_TAG_BREAK, proc, v);\n          }\n          CHECKPOINT_END(RBREAK_TAG_BREAK);\n          /* break from fiber block */\n          if (ci == mrb->c->cibase && ci->pc) {\n            struct mrb_context *c = mrb->c;\n\n            mrb->c = c->prev;\n            c->prev = NULL;\n            ci = mrb->c->ci;\n          }\n          if (ci->cci > CINFO_NONE) {\n            ci = cipop(mrb);\n            mrb_gc_arena_restore(mrb, ai);\n            mrb->c->vmexec = FALSE;\n            mrb->exc = (struct RObject*)break_new(mrb, RBREAK_TAG_BREAK, proc, v);\n            mrb->jmp = prev_jmp;\n            MRB_THROW(prev_jmp);\n          }\n          if (FALSE) {\n            struct RBreak *brk;\n\n          L_BREAK:\n            brk = (struct RBreak*)mrb->exc;\n            proc = mrb_break_proc_get(brk);\n            v = mrb_break_value_get(brk);\n            ci = mrb->c->ci;\n\n            switch (mrb_break_tag_get(brk)) {\n#define DISPATCH_CHECKPOINTS(n, i) case n: goto CHECKPOINT_LABEL_MAKE(n);\n              RBREAK_TAG_FOREACH(DISPATCH_CHECKPOINTS)\n#undef DISPATCH_CHECKPOINTS\n              default:\n                mrb_assert(!\"wrong break tag\");\n            }\n          }\n          while (mrb->c->cibase < ci && ci[-1].proc != proc->upper) {\n            if (ci[-1].cci == CINFO_SKIP) {\n              goto L_BREAK_ERROR;\n            }\n            CHECKPOINT_RESTORE(RBREAK_TAG_BREAK_UPPER) {\n              /* do nothing */\n            }\n            CHECKPOINT_MAIN(RBREAK_TAG_BREAK_UPPER) {\n              UNWIND_ENSURE(mrb, ci, pc, RBREAK_TAG_BREAK_UPPER, proc, v);\n            }\n            CHECKPOINT_END(RBREAK_TAG_BREAK_UPPER);\n            ci = cipop(mrb);\n            pc = ci->pc;\n          }\n          CHECKPOINT_RESTORE(RBREAK_TAG_BREAK_INTARGET) {\n            /* do nothing */\n          }\n          CHECKPOINT_MAIN(RBREAK_TAG_BREAK_INTARGET) {\n            UNWIND_ENSURE(mrb, ci, pc, RBREAK_TAG_BREAK_INTARGET, proc, v);\n          }\n          CHECKPOINT_END(RBREAK_TAG_BREAK_INTARGET);\n          if (ci == mrb->c->cibase) {\n            goto L_BREAK_ERROR;\n          }\n          mrb->exc = NULL; /* clear break object */\n          break;\n        default:\n          /* cannot happen */\n          break;\n        }\n        mrb_assert(ci == mrb->c->ci);\n        mrb_assert(mrb->exc == NULL);\n\n        if (mrb->c->vmexec && !mrb_vm_ci_target_class(ci)) {\n          mrb_gc_arena_restore(mrb, ai);\n          mrb->c->vmexec = FALSE;\n          mrb->jmp = prev_jmp;\n          return v;\n        }\n        acc = ci->cci;\n        ci = cipop(mrb);\n        if (acc == CINFO_SKIP || acc == CINFO_DIRECT) {\n          mrb_gc_arena_restore(mrb, ai);\n          mrb->jmp = prev_jmp;\n          return v;\n        }\n        pc = ci->pc;\n        DEBUG(fprintf(stderr, \"from :%s\\n\", mrb_sym_name(mrb, ci->mid)));\n        proc = ci->proc;\n        irep = proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n\n        ci[1].stack[0] = v;\n        mrb_gc_arena_restore(mrb, ai);\n      }\n      JUMP;\n    }\n\n    CASE(OP_BLKPUSH, BS) {\n      int m1 = (b>>11)&0x3f;\n      int r  = (b>>10)&0x1;\n      int m2 = (b>>5)&0x1f;\n      int kd = (b>>4)&0x1;\n      int lv = (b>>0)&0xf;\n      mrb_value *stack;\n\n      if (lv == 0) stack = regs + 1;\n      else {\n        struct REnv *e = uvenv(mrb, lv-1);\n        if (!e || (!MRB_ENV_ONSTACK_P(e) && e->mid == 0) ||\n            MRB_ENV_LEN(e) <= m1+r+m2+1) {\n          localjump_error(mrb, LOCALJUMP_ERROR_YIELD);\n          goto L_RAISE;\n        }\n        stack = e->stack + 1;\n      }\n      if (mrb_nil_p(stack[m1+r+m2+kd])) {\n        localjump_error(mrb, LOCALJUMP_ERROR_YIELD);\n        goto L_RAISE;\n      }\n      regs[a] = stack[m1+r+m2+kd];\n      NEXT;\n    }\n\n  L_INT_OVERFLOW:\n    {\n      mrb_value exc = mrb_exc_new_lit(mrb, E_RANGE_ERROR, \"integer overflow\");\n      mrb_exc_set(mrb, exc);\n    }\n    goto L_RAISE;\n\n#define TYPES2(a,b) ((((uint16_t)(a))<<8)|(((uint16_t)(b))&0xff))\n#define OP_MATH(op_name)                                                    \\\n  /* need to check if op is overridden */                                   \\\n  switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {                  \\\n    OP_MATH_CASE_INTEGER(op_name);                                          \\\n    OP_MATH_CASE_FLOAT(op_name, integer, float);                            \\\n    OP_MATH_CASE_FLOAT(op_name, float,  integer);                           \\\n    OP_MATH_CASE_FLOAT(op_name, float,  float);                             \\\n    OP_MATH_CASE_STRING_##op_name();                                        \\\n    default:                                                                \\\n      mid = MRB_OPSYM(op_name);                                             \\\n      goto L_SEND_SYM;                                                      \\\n  }                                                                         \\\n  NEXT;\n#define OP_MATH_CASE_INTEGER(op_name)                                       \\\n  case TYPES2(MRB_TT_INTEGER, MRB_TT_INTEGER):                              \\\n    {                                                                       \\\n      mrb_int x = mrb_integer(regs[a]), y = mrb_integer(regs[a+1]), z;      \\\n      if (mrb_int_##op_name##_overflow(x, y, &z))                           \\\n        OP_MATH_OVERFLOW_INT();                                             \\\n      else                                                                  \\\n        SET_INT_VALUE(mrb,regs[a], z);                                      \\\n    }                                                                       \\\n    break\n#ifdef MRB_NO_FLOAT\n#define OP_MATH_CASE_FLOAT(op_name, t1, t2) (void)0\n#else\n#define OP_MATH_CASE_FLOAT(op_name, t1, t2)                                     \\\n  case TYPES2(OP_MATH_TT_##t1, OP_MATH_TT_##t2):                                \\\n    {                                                                           \\\n      mrb_float z = mrb_##t1(regs[a]) OP_MATH_OP_##op_name mrb_##t2(regs[a+1]); \\\n      SET_FLOAT_VALUE(mrb, regs[a], z);                                         \\\n    }                                                                           \\\n    break\n#endif\n#define OP_MATH_OVERFLOW_INT() goto L_INT_OVERFLOW\n#define OP_MATH_CASE_STRING_add()                                           \\\n  case TYPES2(MRB_TT_STRING, MRB_TT_STRING):                                \\\n    regs[a] = mrb_str_plus(mrb, regs[a], regs[a+1]);                        \\\n    mrb_gc_arena_restore(mrb, ai);                                          \\\n    break\n#define OP_MATH_CASE_STRING_sub() (void)0\n#define OP_MATH_CASE_STRING_mul() (void)0\n#define OP_MATH_OP_add +\n#define OP_MATH_OP_sub -\n#define OP_MATH_OP_mul *\n#define OP_MATH_TT_integer MRB_TT_INTEGER\n#define OP_MATH_TT_float   MRB_TT_FLOAT\n\n    CASE(OP_ADD, B) {\n      OP_MATH(add);\n    }\n\n    CASE(OP_SUB, B) {\n      OP_MATH(sub);\n    }\n\n    CASE(OP_MUL, B) {\n      OP_MATH(mul);\n    }\n\n    CASE(OP_DIV, B) {\n#ifndef MRB_NO_FLOAT\n      mrb_float x, y, f;\n#endif\n\n      /* need to check if op is overridden */\n      switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\n      case TYPES2(MRB_TT_INTEGER,MRB_TT_INTEGER):\n        {\n          mrb_int x = mrb_integer(regs[a]);\n          mrb_int y = mrb_integer(regs[a+1]);\n          mrb_int div = mrb_div_int(mrb, x, y);\n          SET_INT_VALUE(mrb, regs[a], div);\n        }\n        NEXT;\n#ifndef MRB_NO_FLOAT\n      case TYPES2(MRB_TT_INTEGER,MRB_TT_FLOAT):\n        x = (mrb_float)mrb_integer(regs[a]);\n        y = mrb_float(regs[a+1]);\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_INTEGER):\n        x = mrb_float(regs[a]);\n        y = (mrb_float)mrb_integer(regs[a+1]);\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_FLOAT):\n        x = mrb_float(regs[a]);\n        y = mrb_float(regs[a+1]);\n        break;\n#endif\n      default:\n        mid = MRB_OPSYM(div);\n        goto L_SEND_SYM;\n      }\n\n#ifndef MRB_NO_FLOAT\n      f = mrb_div_float(x, y);\n      SET_FLOAT_VALUE(mrb, regs[a], f);\n#endif\n      NEXT;\n    }\n\n#define OP_MATHI(op_name)                                                   \\\n  /* need to check if op is overridden */                                   \\\n  switch (mrb_type(regs[a])) {                                              \\\n    OP_MATHI_CASE_INTEGER(op_name);                                         \\\n    OP_MATHI_CASE_FLOAT(op_name);                                           \\\n    default:                                                                \\\n      SET_INT_VALUE(mrb,regs[a+1], b);                                      \\\n      mid = MRB_OPSYM(op_name);                                             \\\n      goto L_SEND_SYM;                                                      \\\n  }                                                                         \\\n  NEXT;\n#define OP_MATHI_CASE_INTEGER(op_name)                                      \\\n  case MRB_TT_INTEGER:                                                      \\\n    {                                                                       \\\n      mrb_int x = mrb_integer(regs[a]), y = (mrb_int)b, z;                  \\\n      if (mrb_int_##op_name##_overflow(x, y, &z))                           \\\n        OP_MATH_OVERFLOW_INT();                                             \\\n      else                                                                  \\\n        SET_INT_VALUE(mrb,regs[a], z);                                      \\\n    }                                                                       \\\n    break\n#ifdef MRB_NO_FLOAT\n#define OP_MATHI_CASE_FLOAT(op_name) (void)0\n#else\n#define OP_MATHI_CASE_FLOAT(op_name)                                        \\\n  case MRB_TT_FLOAT:                                                        \\\n    {                                                                       \\\n      mrb_float z = mrb_float(regs[a]) OP_MATH_OP_##op_name b;              \\\n      SET_FLOAT_VALUE(mrb, regs[a], z);                                     \\\n    }                                                                       \\\n    break\n#endif\n\n    CASE(OP_ADDI, BB) {\n      OP_MATHI(add);\n    }\n\n    CASE(OP_SUBI, BB) {\n      OP_MATHI(sub);\n    }\n\n#define OP_CMP_BODY(op,v1,v2) (v1(regs[a]) op v2(regs[a+1]))\n\n#ifdef MRB_NO_FLOAT\n#define OP_CMP(op,sym) do {\\\n  int result;\\\n  /* need to check if - is overridden */\\\n  switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\\\n  case TYPES2(MRB_TT_INTEGER,MRB_TT_INTEGER):\\\n    result = OP_CMP_BODY(op,mrb_fixnum,mrb_fixnum);\\\n    break;\\\n  default:\\\n    mid = MRB_OPSYM(sym);\\\n    goto L_SEND_SYM;\\\n  }\\\n  if (result) {\\\n    SET_TRUE_VALUE(regs[a]);\\\n  }\\\n  else {\\\n    SET_FALSE_VALUE(regs[a]);\\\n  }\\\n} while(0)\n#else\n#define OP_CMP(op, sym) do {\\\n  int result;\\\n  /* need to check if - is overridden */\\\n  switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\\\n  case TYPES2(MRB_TT_INTEGER,MRB_TT_INTEGER):\\\n    result = OP_CMP_BODY(op,mrb_fixnum,mrb_fixnum);\\\n    break;\\\n  case TYPES2(MRB_TT_INTEGER,MRB_TT_FLOAT):\\\n    result = OP_CMP_BODY(op,mrb_fixnum,mrb_float);\\\n    break;\\\n  case TYPES2(MRB_TT_FLOAT,MRB_TT_INTEGER):\\\n    result = OP_CMP_BODY(op,mrb_float,mrb_fixnum);\\\n    break;\\\n  case TYPES2(MRB_TT_FLOAT,MRB_TT_FLOAT):\\\n    result = OP_CMP_BODY(op,mrb_float,mrb_float);\\\n    break;\\\n  default:\\\n    mid = MRB_OPSYM(sym);\\\n    goto L_SEND_SYM;\\\n  }\\\n  if (result) {\\\n    SET_TRUE_VALUE(regs[a]);\\\n  }\\\n  else {\\\n    SET_FALSE_VALUE(regs[a]);\\\n  }\\\n} while(0)\n#endif\n\n    CASE(OP_EQ, B) {\n      if (mrb_obj_eq(mrb, regs[a], regs[a+1])) {\n        SET_TRUE_VALUE(regs[a]);\n      }\n      else {\n        OP_CMP(==,eq);\n      }\n      NEXT;\n    }\n\n    CASE(OP_LT, B) {\n      OP_CMP(<,lt);\n      NEXT;\n    }\n\n    CASE(OP_LE, B) {\n      OP_CMP(<=,le);\n      NEXT;\n    }\n\n    CASE(OP_GT, B) {\n      OP_CMP(>,gt);\n      NEXT;\n    }\n\n    CASE(OP_GE, B) {\n      OP_CMP(>=,ge);\n      NEXT;\n    }\n\n    CASE(OP_ARRAY, BB) {\n      regs[a] = mrb_ary_new_from_values(mrb, b, &regs[a]);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n    CASE(OP_ARRAY2, BBB) {\n      regs[a] = mrb_ary_new_from_values(mrb, c, &regs[b]);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_ARYCAT, B) {\n      mrb_value splat = mrb_ary_splat(mrb, regs[a+1]);\n      if (mrb_nil_p(regs[a])) {\n        regs[a] = splat;\n      }\n      else {\n        mrb_assert(mrb_array_p(regs[a]));\n        mrb_ary_concat(mrb, regs[a], splat);\n      }\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_ARYPUSH, BB) {\n      mrb_assert(mrb_array_p(regs[a]));\n      for (mrb_int i=0; i<b; i++) {\n        mrb_ary_push(mrb, regs[a], regs[a+i+1]);\n      }\n      NEXT;\n    }\n\n    CASE(OP_ARYDUP, B) {\n      mrb_value ary = regs[a];\n      if (mrb_array_p(ary)) {\n        ary = mrb_ary_new_from_values(mrb, RARRAY_LEN(ary), RARRAY_PTR(ary));\n      }\n      else {\n        ary = mrb_ary_new_from_values(mrb, 1, &ary);\n      }\n      regs[a] = ary;\n      NEXT;\n    }\n\n    CASE(OP_AREF, BBB) {\n      mrb_value v = regs[b];\n\n      if (!mrb_array_p(v)) {\n        if (c == 0) {\n          regs[a] = v;\n        }\n        else {\n          SET_NIL_VALUE(regs[a]);\n        }\n      }\n      else {\n        v = mrb_ary_ref(mrb, v, c);\n        regs[a] = v;\n      }\n      NEXT;\n    }\n\n    CASE(OP_ASET, BBB) {\n      mrb_assert(mrb_array_p(regs[a]));\n      mrb_ary_set(mrb, regs[b], c, regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_APOST, BBB) {\n      mrb_value v = regs[a];\n      int pre  = b;\n      int post = c;\n      struct RArray *ary;\n      int len, idx;\n\n      if (!mrb_array_p(v)) {\n        v = mrb_ary_new_from_values(mrb, 1, &regs[a]);\n      }\n      ary = mrb_ary_ptr(v);\n      len = (int)ARY_LEN(ary);\n      if (len > pre + post) {\n        v = mrb_ary_new_from_values(mrb, len - pre - post, ARY_PTR(ary)+pre);\n        regs[a++] = v;\n        while (post--) {\n          regs[a++] = ARY_PTR(ary)[len-post-1];\n        }\n      }\n      else {\n        v = mrb_ary_new_capa(mrb, 0);\n        regs[a++] = v;\n        for (idx=0; idx+pre<len; idx++) {\n          regs[a+idx] = ARY_PTR(ary)[pre+idx];\n        }\n        while (idx < post) {\n          SET_NIL_VALUE(regs[a+idx]);\n          idx++;\n        }\n      }\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_INTERN, B) {\n      mrb_assert(mrb_string_p(regs[a]));\n      mrb_sym sym = mrb_intern_str(mrb, regs[a]);\n      regs[a] = mrb_symbol_value(sym);\n      NEXT;\n    }\n\n    CASE(OP_SYMBOL, BB) {\n      size_t len;\n      mrb_sym sym;\n\n      mrb_assert((pool[b].tt&IREP_TT_NFLAG)==0);\n      len = pool[b].tt >> 2;\n      if (pool[b].tt & IREP_TT_SFLAG) {\n        sym = mrb_intern_static(mrb, pool[b].u.str, len);\n      }\n      else {\n        sym  = mrb_intern(mrb, pool[b].u.str, len);\n      }\n      regs[a] = mrb_symbol_value(sym);\n      NEXT;\n    }\n\n    CASE(OP_STRING, BB) {\n      mrb_int len;\n\n      mrb_assert((pool[b].tt&IREP_TT_NFLAG)==0);\n      len = pool[b].tt >> 2;\n      if (pool[b].tt & IREP_TT_SFLAG) {\n        regs[a] = mrb_str_new_static(mrb, pool[b].u.str, len);\n      }\n      else {\n        regs[a] = mrb_str_new(mrb, pool[b].u.str, len);\n      }\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_STRCAT, B) {\n      mrb_assert(mrb_string_p(regs[a]));\n      mrb_str_concat(mrb, regs[a], regs[a+1]);\n      NEXT;\n    }\n\n    CASE(OP_HASH, BB) {\n      mrb_value hash = mrb_hash_new_capa(mrb, b);\n      int i;\n      int lim = a+b*2;\n\n      for (i=a; i<lim; i+=2) {\n        mrb_hash_set(mrb, hash, regs[i], regs[i+1]);\n      }\n      regs[a] = hash;\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_HASHADD, BB) {\n      mrb_value hash;\n      int i;\n      int lim = a+b*2+1;\n\n      hash = regs[a];\n      mrb_ensure_hash_type(mrb, hash);\n      for (i=a+1; i<lim; i+=2) {\n        mrb_hash_set(mrb, hash, regs[i], regs[i+1]);\n      }\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n    CASE(OP_HASHCAT, B) {\n      mrb_value hash = regs[a];\n\n      mrb_assert(mrb_hash_p(hash));\n      mrb_hash_merge(mrb, hash, regs[a+1]);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_LAMBDA, BB)\n    c = OP_L_LAMBDA;\n    L_MAKE_LAMBDA:\n    {\n      struct RProc *p;\n      const mrb_irep *nirep = irep->reps[b];\n\n      if (c & OP_L_CAPTURE) {\n        p = mrb_closure_new(mrb, nirep);\n      }\n      else {\n        p = mrb_proc_new(mrb, nirep);\n        p->flags |= MRB_PROC_SCOPE;\n      }\n      if (c & OP_L_STRICT) p->flags |= MRB_PROC_STRICT;\n      regs[a] = mrb_obj_value(p);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n    CASE(OP_BLOCK, BB) {\n      c = OP_L_BLOCK;\n      goto L_MAKE_LAMBDA;\n    }\n    CASE(OP_METHOD, BB) {\n      c = OP_L_METHOD;\n      goto L_MAKE_LAMBDA;\n    }\n\n    CASE(OP_RANGE_INC, B) {\n      mrb_value v = mrb_range_new(mrb, regs[a], regs[a+1], FALSE);\n      regs[a] = v;\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_RANGE_EXC, B) {\n      mrb_value v = mrb_range_new(mrb, regs[a], regs[a+1], TRUE);\n      regs[a] = v;\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_OCLASS, B) {\n      regs[a] = mrb_obj_value(mrb->object_class);\n      NEXT;\n    }\n\n    CASE(OP_CLASS, BB) {\n      struct RClass *c = 0, *baseclass;\n      mrb_value base, super;\n      mrb_sym id = syms[b];\n\n      base = regs[a];\n      super = regs[a+1];\n      if (mrb_nil_p(base)) {\n        baseclass = MRB_PROC_TARGET_CLASS(mrb->c->ci->proc);\n        if (!baseclass) baseclass = mrb->object_class;\n        base = mrb_obj_value(baseclass);\n      }\n      c = mrb_vm_define_class(mrb, base, super, id);\n      regs[a] = mrb_obj_value(c);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_MODULE, BB) {\n      struct RClass *cls = 0, *baseclass;\n      mrb_value base;\n      mrb_sym id = syms[b];\n\n      base = regs[a];\n      if (mrb_nil_p(base)) {\n        baseclass = MRB_PROC_TARGET_CLASS(mrb->c->ci->proc);\n        if (!baseclass) baseclass = mrb->object_class;\n        base = mrb_obj_value(baseclass);\n      }\n      cls = mrb_vm_define_module(mrb, base, id);\n      regs[a] = mrb_obj_value(cls);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_EXEC, BB)\n    {\n      mrb_value recv = regs[a];\n      struct RProc *p;\n      const mrb_irep *nirep = irep->reps[b];\n\n      /* prepare closure */\n      p = mrb_proc_new(mrb, nirep);\n      p->c = NULL;\n      mrb_field_write_barrier(mrb, (struct RBasic*)p, (struct RBasic*)proc);\n      MRB_PROC_SET_TARGET_CLASS(p, mrb_class_ptr(recv));\n      p->flags |= MRB_PROC_SCOPE;\n\n      /* prepare call stack */\n      cipush(mrb, a, 0, mrb_class_ptr(recv), p, 0, 0);\n\n      irep = p->body.irep;\n      pool = irep->pool;\n      syms = irep->syms;\n      mrb_stack_extend(mrb, irep->nregs);\n      stack_clear(regs+1, irep->nregs-1);\n      pc = irep->iseq;\n      JUMP;\n    }\n\n    CASE(OP_DEF, BB) {\n      struct RClass *target = mrb_class_ptr(regs[a]);\n      struct RProc *p = mrb_proc_ptr(regs[a+1]);\n      mrb_method_t m;\n      mrb_sym mid = syms[b];\n\n      MRB_METHOD_FROM_PROC(m, p);\n      mrb_define_method_raw(mrb, target, mid, m);\n      mrb_method_added(mrb, target, mid);\n      mrb_gc_arena_restore(mrb, ai);\n      regs[a] = mrb_symbol_value(mid);\n      NEXT;\n    }\n\n    CASE(OP_SCLASS, B) {\n      regs[a] = mrb_singleton_class(mrb, regs[a]);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_TCLASS, B) {\n      struct RClass *target = check_target_class(mrb);\n      if (!target) goto L_RAISE;\n      regs[a] = mrb_obj_value(target);\n      NEXT;\n    }\n\n    CASE(OP_ALIAS, BB) {\n      struct RClass *target = check_target_class(mrb);\n\n      if (!target) goto L_RAISE;\n      mrb_alias_method(mrb, target, syms[a], syms[b]);\n      mrb_method_added(mrb, target, syms[a]);\n      NEXT;\n    }\n    CASE(OP_UNDEF, B) {\n      struct RClass *target = check_target_class(mrb);\n\n      if (!target) goto L_RAISE;\n      mrb_undef_method_id(mrb, target, syms[a]);\n      NEXT;\n    }\n\n    CASE(OP_DEBUG, Z) {\n      FETCH_BBB();\n#ifdef MRB_USE_DEBUG_HOOK\n      mrb->debug_op_hook(mrb, irep, pc, regs);\n#else\n#ifndef MRB_NO_STDIO\n      printf(\"OP_DEBUG %d %d %d\\n\", a, b, c);\n#else\n      abort();\n#endif\n#endif\n      NEXT;\n    }\n\n    CASE(OP_ERR, B) {\n      size_t len = pool[a].tt >> 2;\n      mrb_value exc;\n\n      mrb_assert((pool[a].tt&IREP_TT_NFLAG)==0);\n      exc = mrb_exc_new(mrb, E_LOCALJUMP_ERROR, pool[a].u.str, len);\n      mrb_exc_set(mrb, exc);\n      goto L_RAISE;\n    }\n\n    CASE(OP_EXT1, Z) {\n      insn = READ_B();\n      switch (insn) {\n#define OPCODE(insn,ops) case OP_ ## insn: FETCH_ ## ops ## _1(); mrb->c->ci->pc = pc; goto L_OP_ ## insn ## _BODY;\n#include \"mruby/ops.h\"\n#undef OPCODE\n      }\n      pc--;\n      NEXT;\n    }\n    CASE(OP_EXT2, Z) {\n      insn = READ_B();\n      switch (insn) {\n#define OPCODE(insn,ops) case OP_ ## insn: FETCH_ ## ops ## _2(); mrb->c->ci->pc = pc; goto L_OP_ ## insn ## _BODY;\n#include \"mruby/ops.h\"\n#undef OPCODE\n      }\n      pc--;\n      NEXT;\n    }\n    CASE(OP_EXT3, Z) {\n      uint8_t insn = READ_B();\n      switch (insn) {\n#define OPCODE(insn,ops) case OP_ ## insn: FETCH_ ## ops ## _3(); mrb->c->ci->pc = pc; goto L_OP_ ## insn ## _BODY;\n#include \"mruby/ops.h\"\n#undef OPCODE\n      }\n      pc--;\n      NEXT;\n    }\n\n    CASE(OP_STOP, Z) {\n      /*        stop VM */\n      CHECKPOINT_RESTORE(RBREAK_TAG_STOP) {\n        /* do nothing */\n      }\n      CHECKPOINT_MAIN(RBREAK_TAG_STOP) {\n        UNWIND_ENSURE(mrb, mrb->c->ci, pc, RBREAK_TAG_STOP, proc, mrb_nil_value());\n      }\n      CHECKPOINT_END(RBREAK_TAG_STOP);\n    L_STOP:\n      mrb->jmp = prev_jmp;\n      if (mrb->exc) {\n        mrb_assert(mrb->exc->tt == MRB_TT_EXCEPTION);\n        return mrb_obj_value(mrb->exc);\n      }\n      return regs[irep->nlocals];\n    }\n  }\n  END_DISPATCH;\n#undef regs\n  }\n  MRB_CATCH(&c_jmp) {\n    mrb_callinfo *ci = mrb->c->ci;\n    while (ci > mrb->c->cibase && ci->cci == CINFO_DIRECT) {\n      ci = cipop(mrb);\n    }\n    exc_catched = TRUE;\n    pc = ci->pc;\n    goto RETRY_TRY_BLOCK;\n  }\n  MRB_END_EXC(&c_jmp);\n}",
        "func_hash": 109885974444796302561569813029771831944,
        "file_name": "vm.c",
        "file_hash": 83886473477345826235413068203214397377,
        "cwe": [
            "CWE-288"
        ],
        "cve": "CVE-2022-1212",
        "cve_desc": "Use-After-Free in str_escape in mruby/mruby in GitHub repository mruby/mruby prior to 3.2. Possible arbitrary code execution if being exploited.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-1212",
        "func_name": "mrb_vm_exec",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 198449,
        "project": "pjproject",
        "commit_id": "450baca94f475345542c6953832650c390889202",
        "project_url": "https://github.com/pjsip/pjproject",
        "commit_url": "https://github.com/pjsip/pjproject/commit/450baca94f475345542c6953832650c390889202",
        "commit_message": "Merge pull request from GHSA-26j7-ww69-c4qj",
        "target": 1,
        "irrelevant": 0,
        "func_before": "PJ_DEF(pj_status_t) pjstun_parse_msg( void *buf, pj_size_t buf_len, \n\t\t\t\t      pjstun_msg *msg)\n{\n    pj_uint16_t msg_type, msg_len;\n    char *p_attr;\n\n    PJ_CHECK_STACK();\n\n    msg->hdr = (pjstun_msg_hdr*)buf;\n    msg_type = pj_ntohs(msg->hdr->type);\n\n    switch (msg_type) {\n    case PJSTUN_BINDING_REQUEST:\n    case PJSTUN_BINDING_RESPONSE:\n    case PJSTUN_BINDING_ERROR_RESPONSE:\n    case PJSTUN_SHARED_SECRET_REQUEST:\n    case PJSTUN_SHARED_SECRET_RESPONSE:\n    case PJSTUN_SHARED_SECRET_ERROR_RESPONSE:\n\tbreak;\n    default:\n\tPJ_LOG(4,(THIS_FILE, \"Error: unknown msg type %d\", msg_type));\n\treturn PJLIB_UTIL_ESTUNINMSGTYPE;\n    }\n\n    msg_len = pj_ntohs(msg->hdr->length);\n    if (msg_len != buf_len - sizeof(pjstun_msg_hdr)) {\n\tPJ_LOG(4,(THIS_FILE, \"Error: invalid msg_len %d (expecting %d)\", \n\t\t\t     msg_len, buf_len - sizeof(pjstun_msg_hdr)));\n\treturn PJLIB_UTIL_ESTUNINMSGLEN;\n    }\n\n    msg->attr_count = 0;\n    p_attr = (char*)buf + sizeof(pjstun_msg_hdr);\n\n    while (msg_len > 0) {\n\tpjstun_attr_hdr **attr = &msg->attr[msg->attr_count];\n\tpj_uint32_t len;\n\tpj_uint16_t attr_type;\n\n\t*attr = (pjstun_attr_hdr*)p_attr;\n\tlen = pj_ntohs((pj_uint16_t) ((*attr)->length)) + sizeof(pjstun_attr_hdr);\n\tlen = (len + 3) & ~3;\n\n\tif (msg_len < len) {\n\t    PJ_LOG(4,(THIS_FILE, \"Error: length mismatch in attr %d\", \n\t\t\t\t msg->attr_count));\n\t    return PJLIB_UTIL_ESTUNINATTRLEN;\n\t}\n\n\tattr_type = pj_ntohs((*attr)->type);\n\tif (attr_type > PJSTUN_ATTR_REFLECTED_FROM &&\n\t    attr_type != PJSTUN_ATTR_XOR_MAPPED_ADDR)\n\t{\n\t    PJ_LOG(5,(THIS_FILE, \"Warning: unknown attr type %x in attr %d. \"\n\t\t\t\t \"Attribute was ignored.\",\n\t\t\t\t attr_type, msg->attr_count));\n\t}\n\n\tmsg_len = (pj_uint16_t)(msg_len - len);\n\tp_attr += len;\n\t++msg->attr_count;\n    }\n\n    return PJ_SUCCESS;\n}",
        "func_hash": 324794898254091416853424941566787120064,
        "file_name": "stun_simple.c",
        "file_hash": 304268271857931505815837287097781884670,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2022-31031",
        "cve_desc": "PJSIP is a free and open source multimedia communication library written in C language implementing standard based protocols such as SIP, SDP, RTP, STUN, TURN, and ICE. In versions prior to and including 2.12.1 a stack buffer overflow vulnerability affects PJSIP users that use STUN in their applications, either by: setting a STUN server in their account/media config in PJSUA/PJSUA2 level, or directly using `pjlib-util/stun_simple` API. A patch is available in commit 450baca which should be included in the next release. There are no known workarounds for this issue.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-31031",
        "func_name": "PJ_DEF",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 198452,
        "project": "tensorflow",
        "commit_id": "a989426ee1346693cc015792f11d715f6944f2b8",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/a989426ee1346693cc015792f11d715f6944f2b8",
        "commit_message": "Improve to cover scale value greater than one\n\nPiperOrigin-RevId: 433050921",
        "target": 1,
        "irrelevant": 0,
        "func_before": "void ComparisonQuantized(const TfLiteTensor* input1, const TfLiteTensor* input2,\n                         TfLiteTensor* output, bool requires_broadcast) {\n  if (input1->type == kTfLiteUInt8 || input1->type == kTfLiteInt8) {\n    auto input1_offset = -input1->params.zero_point;\n    auto input2_offset = -input2->params.zero_point;\n    const int left_shift = 8;\n\n    int32 input1_multiplier;\n    int input1_shift;\n    QuantizeMultiplierSmallerThanOneExp(input1->params.scale,\n                                        &input1_multiplier, &input1_shift);\n    int32 input2_multiplier;\n    int input2_shift;\n    QuantizeMultiplierSmallerThanOneExp(input2->params.scale,\n                                        &input2_multiplier, &input2_shift);\n\n    ComparisonParams op_params;\n    op_params.left_shift = left_shift;\n    op_params.input1_offset = input1_offset;\n    op_params.input1_multiplier = input1_multiplier;\n    op_params.input1_shift = input1_shift;\n    op_params.input2_offset = input2_offset;\n    op_params.input2_multiplier = input2_multiplier;\n    op_params.input2_shift = input2_shift;\n    if (requires_broadcast) {\n      reference_ops::BroadcastComparison4DSlowWithScaling<input_dtype, opname>(\n          op_params, GetTensorShape(input1), GetTensorData<input_dtype>(input1),\n          GetTensorShape(input2), GetTensorData<input_dtype>(input2),\n          GetTensorShape(output), GetTensorData<bool>(output));\n    } else {\n      reference_ops::ComparisonWithScaling<input_dtype, opname>(\n          op_params, GetTensorShape(input1), GetTensorData<input_dtype>(input1),\n          GetTensorShape(input2), GetTensorData<input_dtype>(input2),\n          GetTensorShape(output), GetTensorData<bool>(output));\n    }\n  }\n}",
        "func_hash": 284336502909303651692457957640037138117,
        "file_name": "comparisons.cc",
        "file_hash": 224870261654956140630544765652331160875,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2022-29212",
        "cve_desc": "TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, certain TFLite models that were created using TFLite model converter would crash when loaded in the TFLite interpreter. The culprit is that during quantization the scale of values could be greater than 1 but code was always assuming sub-unit scaling. Thus, since code was calling `QuantizeMultiplierSmallerThanOneExp`, the `TFLITE_CHECK_LT` assertion would trigger and abort the process. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-29212",
        "func_name": "ComparisonQuantized",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 198476,
        "project": "njs",
        "commit_id": "6a07c2156a07ef307b6dcf3c2ca8571a5f1af7a6",
        "project_url": "https://github.com/nginx/njs",
        "commit_url": "https://github.com/nginx/njs/commit/6a07c2156a07ef307b6dcf3c2ca8571a5f1af7a6",
        "commit_message": "Fixed recursive async function calls.\n\nPreviously, PromiseCapability record was stored (function->context)\ndirectly in function object during a function invocation.  This is\nnot correct, because PromiseCapability record should be linked to\ncurrent execution context.  As a result, function->context is\noverwritten with consecutive recursive calls which results in\nuse-after-free.\n\nThis closes #451 issue on Github.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "njs_await_fulfilled(njs_vm_t *vm, njs_value_t *args, njs_uint_t nargs,\n    njs_index_t unused)\n{\n    njs_int_t           ret;\n    njs_value_t         **cur_local, **cur_closures, **cur_temp, *value;\n    njs_frame_t         *frame, *async_frame;\n    njs_function_t      *function;\n    njs_async_ctx_t     *ctx;\n    njs_native_frame_t  *top, *async;\n\n    ctx = vm->top_frame->function->context;\n\n    value = njs_arg(args, nargs, 1);\n    if (njs_is_error(value)) {\n        goto failed;\n    }\n\n    async_frame = ctx->await;\n    async = &async_frame->native;\n    async->previous = vm->top_frame;\n\n    function = async->function;\n\n    cur_local = vm->levels[NJS_LEVEL_LOCAL];\n    cur_closures = vm->levels[NJS_LEVEL_CLOSURE];\n    cur_temp = vm->levels[NJS_LEVEL_TEMP];\n    top = vm->top_frame;\n    frame = vm->active_frame;\n\n    vm->levels[NJS_LEVEL_LOCAL] = async->local;\n    vm->levels[NJS_LEVEL_CLOSURE] = njs_function_closures(async->function);\n    vm->levels[NJS_LEVEL_TEMP] = async->temp;\n\n    vm->top_frame = async;\n    vm->active_frame = async_frame;\n\n    *njs_scope_value(vm, ctx->index) = *value;\n    vm->retval = *value;\n\n    vm->top_frame->retval = &vm->retval;\n\n    function->context = ctx->capability;\n    function->await = ctx;\n\n    ret = njs_vmcode_interpreter(vm, ctx->pc);\n\n    function->context = NULL;\n    function->await = NULL;\n\n    vm->levels[NJS_LEVEL_LOCAL] = cur_local;\n    vm->levels[NJS_LEVEL_CLOSURE] = cur_closures;\n    vm->levels[NJS_LEVEL_TEMP] = cur_temp;\n\n    vm->top_frame = top;\n    vm->active_frame = frame;\n\n    if (ret == NJS_OK) {\n        ret = njs_function_call(vm, njs_function(&ctx->capability->resolve),\n                            &njs_value_undefined, &vm->retval, 1, &vm->retval);\n\n        njs_async_context_free(vm, ctx);\n\n    } else if (ret == NJS_AGAIN) {\n        ret = NJS_OK;\n\n    } else if (ret == NJS_ERROR) {\n        if (njs_is_memory_error(vm, &vm->retval)) {\n            return NJS_ERROR;\n        }\n\n        value = &vm->retval;\n\n        goto failed;\n    }\n\n    return ret;\n\nfailed:\n\n    (void) njs_function_call(vm, njs_function(&ctx->capability->reject),\n                             &njs_value_undefined, value, 1, &vm->retval);\n\n    njs_async_context_free(vm, ctx);\n\n    return NJS_ERROR;\n}",
        "func_hash": 241518720909355358001984532864321433833,
        "file_name": "njs_async.c",
        "file_hash": 139542101989914499952242434630508544825,
        "cwe": [
            "CWE-416"
        ],
        "cve": "CVE-2022-25139",
        "cve_desc": "njs through 0.7.0, used in NGINX, was discovered to contain a heap use-after-free in njs_await_fulfilled.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-25139",
        "func_name": "njs_await_fulfilled",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 198499,
        "project": "micro-ecc",
        "commit_id": "1b5f5cea5145c96dd8791b9b2c41424fc74c2172",
        "project_url": "https://github.com/kmackay/micro-ecc",
        "commit_url": "https://github.com/kmackay/micro-ecc/commit/1b5f5cea5145c96dd8791b9b2c41424fc74c2172",
        "commit_message": "Fix for #168",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static int uECC_sign_with_k(const uint8_t *private_key,\n                            const uint8_t *message_hash,\n                            unsigned hash_size,\n                            uECC_word_t *k,\n                            uint8_t *signature,\n                            uECC_Curve curve) {\n\n    uECC_word_t tmp[uECC_MAX_WORDS];\n    uECC_word_t s[uECC_MAX_WORDS];\n    uECC_word_t *k2[2] = {tmp, s};\n#if uECC_VLI_NATIVE_LITTLE_ENDIAN\n    uECC_word_t *p = (uECC_word_t *)signature;\n#else\n    uECC_word_t p[uECC_MAX_WORDS * 2];\n#endif\n    uECC_word_t carry;\n    wordcount_t num_words = curve->num_words;\n    wordcount_t num_n_words = BITS_TO_WORDS(curve->num_n_bits);\n    bitcount_t num_n_bits = curve->num_n_bits;\n\n    /* Make sure 0 < k < curve_n */\n    if (uECC_vli_isZero(k, num_words) || uECC_vli_cmp(curve->n, k, num_n_words) != 1) {\n        return 0;\n    }\n\n    carry = regularize_k(k, tmp, s, curve);\n    EccPoint_mult(p, curve->G, k2[!carry], 0, num_n_bits + 1, curve);\n    if (uECC_vli_isZero(p, num_words)) {\n        return 0;\n    }\n\n    /* If an RNG function was specified, get a random number\n       to prevent side channel analysis of k. */\n    if (!g_rng_function) {\n        uECC_vli_clear(tmp, num_n_words);\n        tmp[0] = 1;\n    } else if (!uECC_generate_random_int(tmp, curve->n, num_n_words)) {\n        return 0;\n    }\n\n    /* Prevent side channel analysis of uECC_vli_modInv() to determine\n       bits of k / the private key by premultiplying by a random number */\n    uECC_vli_modMult(k, k, tmp, curve->n, num_n_words); /* k' = rand * k */\n    uECC_vli_modInv(k, k, curve->n, num_n_words);       /* k = 1 / k' */\n    uECC_vli_modMult(k, k, tmp, curve->n, num_n_words); /* k = 1 / k */\n\n#if uECC_VLI_NATIVE_LITTLE_ENDIAN == 0\n    uECC_vli_nativeToBytes(signature, curve->num_bytes, p); /* store r */\n#endif\n\n#if uECC_VLI_NATIVE_LITTLE_ENDIAN\n    bcopy((uint8_t *) tmp, private_key, BITS_TO_BYTES(curve->num_n_bits));\n#else\n    uECC_vli_bytesToNative(tmp, private_key, BITS_TO_BYTES(curve->num_n_bits)); /* tmp = d */\n#endif\n\n    s[num_n_words - 1] = 0;\n    uECC_vli_set(s, p, num_words);\n    uECC_vli_modMult(s, tmp, s, curve->n, num_n_words); /* s = r*d */\n\n    bits2int(tmp, message_hash, hash_size, curve);\n    uECC_vli_modAdd(s, tmp, s, curve->n, num_n_words); /* s = e + r*d */\n    uECC_vli_modMult(s, s, k, curve->n, num_n_words);  /* s = (e + r*d) / k */\n    if (uECC_vli_numBits(s, num_n_words) > (bitcount_t)curve->num_bytes * 8) {\n        return 0;\n    }\n#if uECC_VLI_NATIVE_LITTLE_ENDIAN\n    bcopy((uint8_t *) signature + curve->num_bytes, (uint8_t *) s, curve->num_bytes);\n#else\n    uECC_vli_nativeToBytes(signature + curve->num_bytes, curve->num_bytes, s);\n#endif    \n    return 1;\n}",
        "func_hash": 250707445511654521220716932779019293116,
        "file_name": "uECC.c",
        "file_hash": 221730154760089899908262595980065132519,
        "cwe": [
            "CWE-415"
        ],
        "cve": "CVE-2020-27209",
        "cve_desc": "The ECDSA operation of the micro-ecc library 1.0 is vulnerable to simple power analysis attacks which allows an adversary to extract the private ECC key.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2020-27209",
        "func_name": "uECC_sign_with_k",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 198512,
        "project": "mruby",
        "commit_id": "00acae117da1b45b318dc36531a7b0021b8097ae",
        "project_url": "https://github.com/mruby/mruby",
        "commit_url": "https://github.com/mruby/mruby/commit/00acae117da1b45b318dc36531a7b0021b8097ae",
        "commit_message": "vm.c: target class may be NULL.",
        "target": 1,
        "irrelevant": 1,
        "func_before": "mrb_vm_exec(mrb_state *mrb, const struct RProc *proc, const mrb_code *pc)\n{\n  /* mrb_assert(MRB_PROC_CFUNC_P(proc)) */\n  const mrb_irep *irep = proc->body.irep;\n  const mrb_pool_value *pool = irep->pool;\n  const mrb_sym *syms = irep->syms;\n  mrb_code insn;\n  int ai = mrb_gc_arena_save(mrb);\n  struct mrb_jmpbuf *prev_jmp = mrb->jmp;\n  struct mrb_jmpbuf c_jmp;\n  uint32_t a;\n  uint16_t b;\n  uint16_t c;\n  mrb_sym mid;\n  const struct mrb_irep_catch_handler *ch;\n\n#ifdef DIRECT_THREADED\n  static const void * const optable[] = {\n#define OPCODE(x,_) &&L_OP_ ## x,\n#include \"mruby/ops.h\"\n#undef OPCODE\n  };\n#endif\n\n  mrb_bool exc_catched = FALSE;\nRETRY_TRY_BLOCK:\n\n  MRB_TRY(&c_jmp) {\n\n  if (exc_catched) {\n    exc_catched = FALSE;\n    mrb_gc_arena_restore(mrb, ai);\n    if (mrb->exc && mrb->exc->tt == MRB_TT_BREAK)\n      goto L_BREAK;\n    goto L_RAISE;\n  }\n  mrb->jmp = &c_jmp;\n  mrb_vm_ci_proc_set(mrb->c->ci, proc);\n\n#define regs (mrb->c->ci->stack)\n  INIT_DISPATCH {\n    CASE(OP_NOP, Z) {\n      /* do nothing */\n      NEXT;\n    }\n\n    CASE(OP_MOVE, BB) {\n      regs[a] = regs[b];\n      NEXT;\n    }\n\n    CASE(OP_LOADL, BB) {\n      switch (pool[b].tt) {   /* number */\n      case IREP_TT_INT32:\n        regs[a] = mrb_int_value(mrb, (mrb_int)pool[b].u.i32);\n        break;\n      case IREP_TT_INT64:\n#if defined(MRB_INT64)\n        regs[a] = mrb_int_value(mrb, (mrb_int)pool[b].u.i64);\n        break;\n#else\n#if defined(MRB_64BIT)\n        if (INT32_MIN <= pool[b].u.i64 && pool[b].u.i64 <= INT32_MAX) {\n          regs[a] = mrb_int_value(mrb, (mrb_int)pool[b].u.i64);\n          break;\n        }\n#endif\n        goto L_INT_OVERFLOW;\n#endif\n      case IREP_TT_BIGINT:\n        goto L_INT_OVERFLOW;\n#ifndef MRB_NO_FLOAT\n      case IREP_TT_FLOAT:\n        regs[a] = mrb_float_value(mrb, pool[b].u.f);\n        break;\n#endif\n      default:\n        /* should not happen (tt:string) */\n        regs[a] = mrb_nil_value();\n        break;\n      }\n      NEXT;\n    }\n\n    CASE(OP_LOADI, BB) {\n      SET_FIXNUM_VALUE(regs[a], b);\n      NEXT;\n    }\n\n    CASE(OP_LOADINEG, BB) {\n      SET_FIXNUM_VALUE(regs[a], -b);\n      NEXT;\n    }\n\n    CASE(OP_LOADI__1,B) goto L_LOADI;\n    CASE(OP_LOADI_0,B) goto L_LOADI;\n    CASE(OP_LOADI_1,B) goto L_LOADI;\n    CASE(OP_LOADI_2,B) goto L_LOADI;\n    CASE(OP_LOADI_3,B) goto L_LOADI;\n    CASE(OP_LOADI_4,B) goto L_LOADI;\n    CASE(OP_LOADI_5,B) goto L_LOADI;\n    CASE(OP_LOADI_6,B) goto L_LOADI;\n    CASE(OP_LOADI_7, B) {\n    L_LOADI:\n      SET_FIXNUM_VALUE(regs[a], (mrb_int)insn - (mrb_int)OP_LOADI_0);\n      NEXT;\n    }\n\n    CASE(OP_LOADI16, BS) {\n      SET_FIXNUM_VALUE(regs[a], (mrb_int)(int16_t)b);\n      NEXT;\n    }\n\n    CASE(OP_LOADI32, BSS) {\n      SET_INT_VALUE(mrb, regs[a], (int32_t)(((uint32_t)b<<16)+c));\n      NEXT;\n    }\n\n    CASE(OP_LOADSYM, BB) {\n      SET_SYM_VALUE(regs[a], syms[b]);\n      NEXT;\n    }\n\n    CASE(OP_LOADNIL, B) {\n      SET_NIL_VALUE(regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_LOADSELF, B) {\n      regs[a] = regs[0];\n      NEXT;\n    }\n\n    CASE(OP_LOADT, B) {\n      SET_TRUE_VALUE(regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_LOADF, B) {\n      SET_FALSE_VALUE(regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETGV, BB) {\n      mrb_value val = mrb_gv_get(mrb, syms[b]);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETGV, BB) {\n      mrb_gv_set(mrb, syms[b], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETSV, BB) {\n      mrb_value val = mrb_vm_special_get(mrb, syms[b]);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETSV, BB) {\n      mrb_vm_special_set(mrb, syms[b], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETIV, BB) {\n      regs[a] = mrb_iv_get(mrb, regs[0], syms[b]);\n      NEXT;\n    }\n\n    CASE(OP_SETIV, BB) {\n      mrb_iv_set(mrb, regs[0], syms[b], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETCV, BB) {\n      mrb_value val;\n      val = mrb_vm_cv_get(mrb, syms[b]);\n      regs[a] = val;\n      NEXT;\n    }\n\n    CASE(OP_SETCV, BB) {\n      mrb_vm_cv_set(mrb, syms[b], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETIDX, B) {\n      mrb_value va = regs[a], vb = regs[a+1];\n      switch (mrb_type(va)) {\n      case MRB_TT_ARRAY:\n        if (!mrb_integer_p(vb)) goto getidx_fallback;\n        regs[a] = mrb_ary_entry(va, mrb_integer(vb));\n        break;\n      case MRB_TT_HASH:\n        va = mrb_hash_get(mrb, va, vb);\n        regs[a] = va;\n        break;\n      case MRB_TT_STRING:\n        switch (mrb_type(vb)) {\n        case MRB_TT_INTEGER:\n        case MRB_TT_STRING:\n        case MRB_TT_RANGE:\n          va = mrb_str_aref(mrb, va, vb, mrb_undef_value());\n          regs[a] = va;\n          break;\n        default:\n          goto getidx_fallback;\n        }\n        break;\n      default:\n      getidx_fallback:\n        mid = MRB_OPSYM(aref);\n        goto L_SEND_SYM;\n      }\n      NEXT;\n    }\n\n    CASE(OP_SETIDX, B) {\n      c = 2;\n      mid = MRB_OPSYM(aset);\n      SET_NIL_VALUE(regs[a+3]);\n      goto L_SENDB_SYM;\n    }\n\n    CASE(OP_GETCONST, BB) {\n      mrb_value v = mrb_vm_const_get(mrb, syms[b]);\n      regs[a] = v;\n      NEXT;\n    }\n\n    CASE(OP_SETCONST, BB) {\n      mrb_vm_const_set(mrb, syms[b], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETMCNST, BB) {\n      mrb_value v = mrb_const_get(mrb, regs[a], syms[b]);\n      regs[a] = v;\n      NEXT;\n    }\n\n    CASE(OP_SETMCNST, BB) {\n      mrb_const_set(mrb, regs[a+1], syms[b], regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_GETUPVAR, BBB) {\n      mrb_value *regs_a = regs + a;\n      struct REnv *e = uvenv(mrb, c);\n\n      if (e && b < MRB_ENV_LEN(e)) {\n        *regs_a = e->stack[b];\n      }\n      else {\n        *regs_a = mrb_nil_value();\n      }\n      NEXT;\n    }\n\n    CASE(OP_SETUPVAR, BBB) {\n      struct REnv *e = uvenv(mrb, c);\n\n      if (e) {\n        mrb_value *regs_a = regs + a;\n\n        if (b < MRB_ENV_LEN(e)) {\n          e->stack[b] = *regs_a;\n          mrb_write_barrier(mrb, (struct RBasic*)e);\n        }\n      }\n      NEXT;\n    }\n\n    CASE(OP_JMP, S) {\n      pc += (int16_t)a;\n      JUMP;\n    }\n    CASE(OP_JMPIF, BS) {\n      if (mrb_test(regs[a])) {\n        pc += (int16_t)b;\n        JUMP;\n      }\n      NEXT;\n    }\n    CASE(OP_JMPNOT, BS) {\n      if (!mrb_test(regs[a])) {\n        pc += (int16_t)b;\n        JUMP;\n      }\n      NEXT;\n    }\n    CASE(OP_JMPNIL, BS) {\n      if (mrb_nil_p(regs[a])) {\n        pc += (int16_t)b;\n        JUMP;\n      }\n      NEXT;\n    }\n\n    CASE(OP_JMPUW, S) {\n      a = (uint32_t)((pc - irep->iseq) + (int16_t)a);\n      CHECKPOINT_RESTORE(RBREAK_TAG_JUMP) {\n        struct RBreak *brk = (struct RBreak*)mrb->exc;\n        mrb_value target = mrb_break_value_get(brk);\n        mrb_assert(mrb_integer_p(target));\n        a = (uint32_t)mrb_integer(target);\n        mrb_assert(a >= 0 && a < irep->ilen);\n      }\n      CHECKPOINT_MAIN(RBREAK_TAG_JUMP) {\n        ch = catch_handler_find(mrb, mrb->c->ci, pc, MRB_CATCH_FILTER_ENSURE);\n        if (ch) {\n          /* avoiding a jump from a catch handler into the same handler */\n          if (a < mrb_irep_catch_handler_unpack(ch->begin) || a >= mrb_irep_catch_handler_unpack(ch->end)) {\n            THROW_TAGGED_BREAK(mrb, RBREAK_TAG_JUMP, proc, mrb_fixnum_value(a));\n          }\n        }\n      }\n      CHECKPOINT_END(RBREAK_TAG_JUMP);\n\n      mrb->exc = NULL; /* clear break object */\n      pc = irep->iseq + a;\n      JUMP;\n    }\n\n    CASE(OP_EXCEPT, B) {\n      mrb_value exc;\n\n      if (mrb->exc == NULL) {\n        exc = mrb_nil_value();\n      }\n      else {\n        switch (mrb->exc->tt) {\n        case MRB_TT_BREAK:\n        case MRB_TT_EXCEPTION:\n          exc = mrb_obj_value(mrb->exc);\n          break;\n        default:\n          mrb_assert(!\"bad mrb_type\");\n          exc = mrb_nil_value();\n          break;\n        }\n        mrb->exc = NULL;\n      }\n      regs[a] = exc;\n      NEXT;\n    }\n    CASE(OP_RESCUE, BB) {\n      mrb_value exc = regs[a];  /* exc on stack */\n      mrb_value e = regs[b];\n      struct RClass *ec;\n\n      switch (mrb_type(e)) {\n      case MRB_TT_CLASS:\n      case MRB_TT_MODULE:\n        break;\n      default:\n        {\n          mrb_value exc;\n\n          exc = mrb_exc_new_lit(mrb, E_TYPE_ERROR,\n                                    \"class or module required for rescue clause\");\n          mrb_exc_set(mrb, exc);\n          goto L_RAISE;\n        }\n      }\n      ec = mrb_class_ptr(e);\n      regs[b] = mrb_bool_value(mrb_obj_is_kind_of(mrb, exc, ec));\n      NEXT;\n    }\n\n    CASE(OP_RAISEIF, B) {\n      mrb_value exc = regs[a];\n      if (mrb_break_p(exc)) {\n        mrb->exc = mrb_obj_ptr(exc);\n        goto L_BREAK;\n      }\n      mrb_exc_set(mrb, exc);\n      if (mrb->exc) {\n        goto L_RAISE;\n      }\n      NEXT;\n    }\n\n    CASE(OP_SSEND, BBB) {\n      regs[a] = regs[0];\n      insn = OP_SEND;\n    }\n    goto L_SENDB;\n\n    CASE(OP_SSENDB, BBB) {\n      regs[a] = regs[0];\n    }\n    goto L_SENDB;\n\n    CASE(OP_SEND, BBB)\n    goto L_SENDB;\n\n    L_SEND_SYM:\n    c = 1;\n    /* push nil after arguments */\n    SET_NIL_VALUE(regs[a+2]);\n    goto L_SENDB_SYM;\n\n    CASE(OP_SENDB, BBB)\n    L_SENDB:\n    mid = syms[b];\n    L_SENDB_SYM:\n    {\n      mrb_callinfo *ci = mrb->c->ci;\n      mrb_method_t m;\n      struct RClass *cls;\n      mrb_value recv, blk;\n\n      ARGUMENT_NORMALIZE(a, &c, insn);\n\n      recv = regs[a];\n      cls = mrb_class(mrb, recv);\n      m = mrb_method_search_vm(mrb, &cls, mid);\n      if (MRB_METHOD_UNDEF_P(m)) {\n        m = prepare_missing(mrb, recv, mid, &cls, a, &c, blk, 0);\n        mid = MRB_SYM(method_missing);\n      }\n\n      /* push callinfo */\n      ci = cipush(mrb, a, 0, cls, NULL, mid, c);\n\n      if (MRB_METHOD_CFUNC_P(m)) {\n        if (MRB_METHOD_PROC_P(m)) {\n          struct RProc *p = MRB_METHOD_PROC(m);\n\n          mrb_vm_ci_proc_set(ci, p);\n          recv = p->body.func(mrb, recv);\n        }\n        else {\n          if (MRB_METHOD_NOARG_P(m)) {\n            check_method_noarg(mrb, ci);\n          }\n          recv = MRB_METHOD_FUNC(m)(mrb, recv);\n        }\n        mrb_gc_arena_shrink(mrb, ai);\n        if (mrb->exc) goto L_RAISE;\n        ci = mrb->c->ci;\n        if (mrb_proc_p(blk)) {\n          struct RProc *p = mrb_proc_ptr(blk);\n          if (p && !MRB_PROC_STRICT_P(p) && MRB_PROC_ENV(p) == mrb_vm_ci_env(&ci[-1])) {\n            p->flags |= MRB_PROC_ORPHAN;\n          }\n        }\n        if (!ci->u.target_class) { /* return from context modifying method (resume/yield) */\n          if (ci->cci == CINFO_RESUMED) {\n            mrb->jmp = prev_jmp;\n            return recv;\n          }\n          else {\n            mrb_assert(!MRB_PROC_CFUNC_P(ci[-1].proc));\n            proc = ci[-1].proc;\n            irep = proc->body.irep;\n            pool = irep->pool;\n            syms = irep->syms;\n          }\n        }\n        ci->stack[0] = recv;\n        /* pop stackpos */\n        ci = cipop(mrb);\n        pc = ci->pc;\n      }\n      else {\n        /* setup environment for calling method */\n        mrb_vm_ci_proc_set(ci, (proc = MRB_METHOD_PROC(m)));\n        irep = proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n        mrb_stack_extend(mrb, (irep->nregs < 4) ? 4 : irep->nregs);\n        pc = irep->iseq;\n      }\n    }\n    JUMP;\n\n    CASE(OP_CALL, Z) {\n      mrb_callinfo *ci = mrb->c->ci;\n      mrb_value recv = ci->stack[0];\n      struct RProc *m = mrb_proc_ptr(recv);\n\n      /* replace callinfo */\n      ci->u.target_class = MRB_PROC_TARGET_CLASS(m);\n      mrb_vm_ci_proc_set(ci, m);\n      if (MRB_PROC_ENV_P(m)) {\n        ci->mid = MRB_PROC_ENV(m)->mid;\n      }\n\n      /* prepare stack */\n      if (MRB_PROC_CFUNC_P(m)) {\n        recv = MRB_PROC_CFUNC(m)(mrb, recv);\n        mrb_gc_arena_shrink(mrb, ai);\n        if (mrb->exc) goto L_RAISE;\n        /* pop stackpos */\n        ci = cipop(mrb);\n        pc = ci->pc;\n        ci[1].stack[0] = recv;\n        irep = mrb->c->ci->proc->body.irep;\n      }\n      else {\n        /* setup environment for calling method */\n        proc = m;\n        irep = m->body.irep;\n        if (!irep) {\n          mrb->c->ci->stack[0] = mrb_nil_value();\n          a = 0;\n          c = OP_R_NORMAL;\n          goto L_OP_RETURN_BODY;\n        }\n        mrb_int nargs = mrb_ci_bidx(ci)+1;\n        if (nargs < irep->nregs) {\n          mrb_stack_extend(mrb, irep->nregs);\n          stack_clear(regs+nargs, irep->nregs-nargs);\n        }\n        if (MRB_PROC_ENV_P(m)) {\n          regs[0] = MRB_PROC_ENV(m)->stack[0];\n        }\n        pc = irep->iseq;\n      }\n      pool = irep->pool;\n      syms = irep->syms;\n      JUMP;\n    }\n\n    CASE(OP_SUPER, BB) {\n      mrb_method_t m;\n      struct RClass *cls;\n      mrb_callinfo *ci = mrb->c->ci;\n      mrb_value recv, blk;\n      const struct RProc *p = ci->proc;\n      mrb_sym mid = ci->mid;\n      struct RClass* target_class = MRB_PROC_TARGET_CLASS(p);\n\n      if (MRB_PROC_ENV_P(p) && p->e.env->mid && p->e.env->mid != mid) { /* alias support */\n        mid = p->e.env->mid;    /* restore old mid */\n      }\n\n      if (mid == 0 || !target_class) {\n        mrb_value exc = mrb_exc_new_lit(mrb, E_NOMETHOD_ERROR, \"super called outside of method\");\n        mrb_exc_set(mrb, exc);\n        goto L_RAISE;\n      }\n      if (target_class->flags & MRB_FL_CLASS_IS_PREPENDED) {\n        target_class = mrb_vm_ci_target_class(ci);\n      }\n      else if (target_class->tt == MRB_TT_MODULE) {\n        target_class = mrb_vm_ci_target_class(ci);\n        if (target_class->tt != MRB_TT_ICLASS) {\n          goto super_typeerror;\n        }\n      }\n      recv = regs[0];\n      if (!mrb_obj_is_kind_of(mrb, recv, target_class)) {\n      super_typeerror: ;\n        mrb_value exc = mrb_exc_new_lit(mrb, E_TYPE_ERROR,\n                                            \"self has wrong type to call super in this context\");\n        mrb_exc_set(mrb, exc);\n        goto L_RAISE;\n      }\n\n      ARGUMENT_NORMALIZE(a, &b, OP_SUPER);\n\n      cls = target_class->super;\n      m = mrb_method_search_vm(mrb, &cls, mid);\n      if (MRB_METHOD_UNDEF_P(m)) {\n        m = prepare_missing(mrb, recv, mid, &cls, a, &b, blk, 1);\n        mid = MRB_SYM(method_missing);\n      }\n\n      /* push callinfo */\n      ci = cipush(mrb, a, 0, cls, NULL, mid, b);\n\n      /* prepare stack */\n      ci->stack[0] = recv;\n\n      if (MRB_METHOD_CFUNC_P(m)) {\n        mrb_value v;\n\n        if (MRB_METHOD_PROC_P(m)) {\n          mrb_vm_ci_proc_set(ci, MRB_METHOD_PROC(m));\n        }\n        v = MRB_METHOD_CFUNC(m)(mrb, recv);\n        mrb_gc_arena_restore(mrb, ai);\n        if (mrb->exc) goto L_RAISE;\n        ci = mrb->c->ci;\n        mrb_assert(!mrb_break_p(v));\n        if (!mrb_vm_ci_target_class(ci)) { /* return from context modifying method (resume/yield) */\n          if (ci->cci == CINFO_RESUMED) {\n            mrb->jmp = prev_jmp;\n            return v;\n          }\n          else {\n            mrb_assert(!MRB_PROC_CFUNC_P(ci[-1].proc));\n            proc = ci[-1].proc;\n            irep = proc->body.irep;\n            pool = irep->pool;\n            syms = irep->syms;\n          }\n        }\n        mrb->c->ci->stack[0] = v;\n        ci = cipop(mrb);\n        pc = ci->pc;\n      }\n      else {\n        /* setup environment for calling method */\n        mrb_vm_ci_proc_set(ci, (proc = MRB_METHOD_PROC(m)));\n        irep = proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n        mrb_stack_extend(mrb, (irep->nregs < 4) ? 4 : irep->nregs);\n        pc = irep->iseq;\n      }\n      JUMP;\n    }\n\n    CASE(OP_ARGARY, BS) {\n      mrb_int m1 = (b>>11)&0x3f;\n      mrb_int r  = (b>>10)&0x1;\n      mrb_int m2 = (b>>5)&0x1f;\n      mrb_int kd = (b>>4)&0x1;\n      mrb_int lv = (b>>0)&0xf;\n      mrb_value *stack;\n\n      if (mrb->c->ci->mid == 0 || mrb_vm_ci_target_class(mrb->c->ci) == NULL) {\n        mrb_value exc;\n\n      L_NOSUPER:\n        exc = mrb_exc_new_lit(mrb, E_NOMETHOD_ERROR, \"super called outside of method\");\n        mrb_exc_set(mrb, exc);\n        goto L_RAISE;\n      }\n      if (lv == 0) stack = regs + 1;\n      else {\n        struct REnv *e = uvenv(mrb, lv-1);\n        if (!e) goto L_NOSUPER;\n        if (MRB_ENV_LEN(e) <= m1+r+m2+1)\n          goto L_NOSUPER;\n        stack = e->stack + 1;\n      }\n      if (r == 0) {\n        regs[a] = mrb_ary_new_from_values(mrb, m1+m2, stack);\n      }\n      else {\n        mrb_value *pp = NULL;\n        struct RArray *rest;\n        mrb_int len = 0;\n\n        if (mrb_array_p(stack[m1])) {\n          struct RArray *ary = mrb_ary_ptr(stack[m1]);\n\n          pp = ARY_PTR(ary);\n          len = ARY_LEN(ary);\n        }\n        regs[a] = mrb_ary_new_capa(mrb, m1+len+m2);\n        rest = mrb_ary_ptr(regs[a]);\n        if (m1 > 0) {\n          stack_copy(ARY_PTR(rest), stack, m1);\n        }\n        if (len > 0) {\n          stack_copy(ARY_PTR(rest)+m1, pp, len);\n        }\n        if (m2 > 0) {\n          stack_copy(ARY_PTR(rest)+m1+len, stack+m1+1, m2);\n        }\n        ARY_SET_LEN(rest, m1+len+m2);\n      }\n      if (kd) {\n        regs[a+1] = stack[m1+r+m2];\n        regs[a+2] = stack[m1+r+m2+1];\n      }\n      else {\n        regs[a+1] = stack[m1+r+m2];\n      }\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_ENTER, W) {\n      mrb_int m1 = MRB_ASPEC_REQ(a);\n      mrb_int o  = MRB_ASPEC_OPT(a);\n      mrb_int r  = MRB_ASPEC_REST(a);\n      mrb_int m2 = MRB_ASPEC_POST(a);\n      mrb_int kd = (MRB_ASPEC_KEY(a) > 0 || MRB_ASPEC_KDICT(a))? 1 : 0;\n      /* unused\n      int b  = MRB_ASPEC_BLOCK(a);\n      */\n      mrb_int const len = m1 + o + r + m2;\n\n      mrb_callinfo *ci = mrb->c->ci;\n      mrb_int argc = ci->n;\n      mrb_value *argv = regs+1;\n      mrb_value * const argv0 = argv;\n      mrb_int const kw_pos = len + kd;    /* where kwhash should be */\n      mrb_int const blk_pos = kw_pos + 1; /* where block should be */\n      mrb_value blk = regs[mrb_ci_bidx(ci)];\n      mrb_value kdict = mrb_nil_value();\n\n      /* keyword arguments */\n      if (ci->nk > 0) {\n        mrb_int kidx = mrb_ci_kidx(ci);\n        kdict = regs[kidx];\n        if (!mrb_hash_p(kdict) || mrb_hash_size(mrb, kdict) == 0) {\n          kdict = mrb_nil_value();\n          ci->nk = 0;\n        }\n      }\n      if (!kd && !mrb_nil_p(kdict)) {\n        if (argc < 14) {\n          ci->n++;\n          argc++;    /* include kdict in normal arguments */\n        }\n        else if (argc == 14) {\n          /* pack arguments and kdict */\n          regs[1] = mrb_ary_new_from_values(mrb, argc+1, &regs[1]);\n          argc = ci->n = 15;\n        }\n        else {/* argc == 15 */\n          /* push kdict to packed arguments */\n          mrb_ary_push(mrb, regs[1], regs[2]);\n        }\n        ci->nk = 0;\n      }\n      if (kd && MRB_ASPEC_KEY(a) > 0 && mrb_hash_p(kdict)) {\n        kdict = mrb_hash_dup(mrb, kdict);\n      }\n\n      /* arguments is passed with Array */\n      if (argc == 15) {\n        struct RArray *ary = mrb_ary_ptr(regs[1]);\n        argv = ARY_PTR(ary);\n        argc = (int)ARY_LEN(ary);\n        mrb_gc_protect(mrb, regs[1]);\n      }\n\n      /* strict argument check */\n      if (ci->proc && MRB_PROC_STRICT_P(ci->proc)) {\n        if (argc < m1 + m2 || (r == 0 && argc > len)) {\n          argnum_error(mrb, m1+m2);\n          goto L_RAISE;\n        }\n      }\n      /* extract first argument array to arguments */\n      else if (len > 1 && argc == 1 && mrb_array_p(argv[0])) {\n        mrb_gc_protect(mrb, argv[0]);\n        argc = (int)RARRAY_LEN(argv[0]);\n        argv = RARRAY_PTR(argv[0]);\n      }\n\n      /* rest arguments */\n      mrb_value rest = mrb_nil_value();\n      if (argc < len) {\n        mrb_int mlen = m2;\n        if (argc < m1+m2) {\n          mlen = m1 < argc ? argc - m1 : 0;\n        }\n\n        /* copy mandatory and optional arguments */\n        if (argv0 != argv && argv) {\n          value_move(&regs[1], argv, argc-mlen); /* m1 + o */\n        }\n        if (argc < m1) {\n          stack_clear(&regs[argc+1], m1-argc);\n        }\n        /* copy post mandatory arguments */\n        if (mlen) {\n          value_move(&regs[len-m2+1], &argv[argc-mlen], mlen);\n        }\n        if (mlen < m2) {\n          stack_clear(&regs[len-m2+mlen+1], m2-mlen);\n        }\n        /* initialize rest arguments with empty Array */\n        if (r) {\n          rest = mrb_ary_new_capa(mrb, 0);\n          regs[m1+o+1] = rest;\n        }\n        /* skip initializer of passed arguments */\n        if (o > 0 && argc > m1+m2)\n          pc += (argc - m1 - m2)*3;\n      }\n      else {\n        mrb_int rnum = 0;\n        if (argv0 != argv) {\n          value_move(&regs[1], argv, m1+o);\n        }\n        if (r) {\n          rnum = argc-m1-o-m2;\n          rest = mrb_ary_new_from_values(mrb, rnum, argv+m1+o);\n          regs[m1+o+1] = rest;\n        }\n        if (m2 > 0 && argc-m2 > m1) {\n          value_move(&regs[m1+o+r+1], &argv[m1+o+rnum], m2);\n        }\n        pc += o*3;\n      }\n\n      /* need to be update blk first to protect blk from GC */\n      regs[blk_pos] = blk;              /* move block */\n      if (kd) {\n        if (mrb_nil_p(kdict))\n          kdict = mrb_hash_new_capa(mrb, 0);\n        regs[kw_pos] = kdict;           /* set kwhash */\n      }\n\n      /* format arguments for generated code */\n      mrb->c->ci->n = len;\n\n      /* clear local (but non-argument) variables */\n      if (irep->nlocals-blk_pos-1 > 0) {\n        stack_clear(&regs[blk_pos+1], irep->nlocals-blk_pos-1);\n      }\n      JUMP;\n    }\n\n    CASE(OP_KARG, BB) {\n      mrb_value k = mrb_symbol_value(syms[b]);\n      mrb_int kidx = mrb_ci_kidx(mrb->c->ci);\n      mrb_value kdict, v;\n\n      if (kidx < 0 || !mrb_hash_p(kdict=regs[kidx]) || !mrb_hash_key_p(mrb, kdict, k)) {\n        mrb_value str = mrb_format(mrb, \"missing keyword: %v\", k);\n        mrb_exc_set(mrb, mrb_exc_new_str(mrb, E_ARGUMENT_ERROR, str));\n        goto L_RAISE;\n      }\n      v = mrb_hash_get(mrb, kdict, k);\n      regs[a] = v;\n      mrb_hash_delete_key(mrb, kdict, k);\n      NEXT;\n    }\n\n    CASE(OP_KEY_P, BB) {\n      mrb_value k = mrb_symbol_value(syms[b]);\n      mrb_int kidx = mrb_ci_kidx(mrb->c->ci);\n      mrb_value kdict;\n      mrb_bool key_p = FALSE;\n\n      if (kidx >= 0 && mrb_hash_p(kdict=regs[kidx])) {\n        key_p = mrb_hash_key_p(mrb, kdict, k);\n      }\n      regs[a] = mrb_bool_value(key_p);\n      NEXT;\n    }\n\n    CASE(OP_KEYEND, Z) {\n      mrb_int kidx = mrb_ci_kidx(mrb->c->ci);\n      mrb_value kdict;\n\n      if (kidx >= 0 && mrb_hash_p(kdict=regs[kidx]) && !mrb_hash_empty_p(mrb, kdict)) {\n        mrb_value keys = mrb_hash_keys(mrb, kdict);\n        mrb_value key1 = RARRAY_PTR(keys)[0];\n        mrb_value str = mrb_format(mrb, \"unknown keyword: %v\", key1);\n        mrb_exc_set(mrb, mrb_exc_new_str(mrb, E_ARGUMENT_ERROR, str));\n        goto L_RAISE;\n      }\n      NEXT;\n    }\n\n    CASE(OP_BREAK, B) {\n      c = OP_R_BREAK;\n      goto L_RETURN;\n    }\n    CASE(OP_RETURN_BLK, B) {\n      c = OP_R_RETURN;\n      goto L_RETURN;\n    }\n    CASE(OP_RETURN, B)\n    c = OP_R_NORMAL;\n    L_RETURN:\n    {\n      mrb_callinfo *ci;\n\n      ci = mrb->c->ci;\n      if (ci->mid) {\n        mrb_value blk = regs[mrb_ci_bidx(ci)];\n\n        if (mrb_proc_p(blk)) {\n          struct RProc *p = mrb_proc_ptr(blk);\n\n          if (!MRB_PROC_STRICT_P(p) &&\n              ci > mrb->c->cibase && MRB_PROC_ENV(p) == mrb_vm_ci_env(&ci[-1])) {\n            p->flags |= MRB_PROC_ORPHAN;\n          }\n        }\n      }\n\n      if (mrb->exc) {\n      L_RAISE:\n        ci = mrb->c->ci;\n        if (ci == mrb->c->cibase) {\n          ch = catch_handler_find(mrb, ci, pc, MRB_CATCH_FILTER_ALL);\n          if (ch == NULL) goto L_FTOP;\n          goto L_CATCH;\n        }\n        while ((ch = catch_handler_find(mrb, ci, pc, MRB_CATCH_FILTER_ALL)) == NULL) {\n          ci = cipop(mrb);\n          if (ci[1].cci == CINFO_SKIP && prev_jmp) {\n            mrb->jmp = prev_jmp;\n            MRB_THROW(prev_jmp);\n          }\n          pc = ci[0].pc;\n          if (ci == mrb->c->cibase) {\n            ch = catch_handler_find(mrb, ci, pc, MRB_CATCH_FILTER_ALL);\n            if (ch == NULL) {\n            L_FTOP:             /* fiber top */\n              if (mrb->c == mrb->root_c) {\n                mrb->c->ci->stack = mrb->c->stbase;\n                goto L_STOP;\n              }\n              else {\n                struct mrb_context *c = mrb->c;\n\n                c->status = MRB_FIBER_TERMINATED;\n                mrb->c = c->prev;\n                c->prev = NULL;\n                goto L_RAISE;\n              }\n            }\n            break;\n          }\n        }\n      L_CATCH:\n        if (ch == NULL) goto L_STOP;\n        if (FALSE) {\n        L_CATCH_TAGGED_BREAK: /* from THROW_TAGGED_BREAK() or UNWIND_ENSURE() */\n          ci = mrb->c->ci;\n        }\n        proc = ci->proc;\n        irep = proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n        mrb_stack_extend(mrb, irep->nregs);\n        pc = irep->iseq + mrb_irep_catch_handler_unpack(ch->target);\n      }\n      else {\n        mrb_int acc;\n        mrb_value v;\n\n        ci = mrb->c->ci;\n        v = regs[a];\n        mrb_gc_protect(mrb, v);\n        switch (c) {\n        case OP_R_RETURN:\n          /* Fall through to OP_R_NORMAL otherwise */\n          if (ci->cci == CINFO_NONE && MRB_PROC_ENV_P(proc) && !MRB_PROC_STRICT_P(proc)) {\n            const struct RProc *dst;\n            mrb_callinfo *cibase;\n            cibase = mrb->c->cibase;\n            dst = top_proc(mrb, proc);\n\n            if (MRB_PROC_ENV_P(dst)) {\n              struct REnv *e = MRB_PROC_ENV(dst);\n\n              if (!MRB_ENV_ONSTACK_P(e) || (e->cxt && e->cxt != mrb->c)) {\n                localjump_error(mrb, LOCALJUMP_ERROR_RETURN);\n                goto L_RAISE;\n              }\n            }\n            /* check jump destination */\n            while (cibase <= ci && ci->proc != dst) {\n              if (ci->cci > CINFO_NONE) { /* jump cross C boundary */\n                localjump_error(mrb, LOCALJUMP_ERROR_RETURN);\n                goto L_RAISE;\n              }\n              ci--;\n            }\n            if (ci <= cibase) { /* no jump destination */\n              localjump_error(mrb, LOCALJUMP_ERROR_RETURN);\n              goto L_RAISE;\n            }\n            ci = mrb->c->ci;\n            while (cibase <= ci && ci->proc != dst) {\n              CHECKPOINT_RESTORE(RBREAK_TAG_RETURN_BLOCK) {\n                cibase = mrb->c->cibase;\n                dst = top_proc(mrb, proc);\n              }\n              CHECKPOINT_MAIN(RBREAK_TAG_RETURN_BLOCK) {\n                UNWIND_ENSURE(mrb, ci, pc, RBREAK_TAG_RETURN_BLOCK, proc, v);\n              }\n              CHECKPOINT_END(RBREAK_TAG_RETURN_BLOCK);\n              ci = cipop(mrb);\n              pc = ci->pc;\n            }\n            proc = ci->proc;\n            mrb->exc = NULL; /* clear break object */\n            break;\n          }\n          /* fallthrough */\n        case OP_R_NORMAL:\n        NORMAL_RETURN:\n          if (ci == mrb->c->cibase) {\n            struct mrb_context *c;\n            c = mrb->c;\n\n            if (!c->prev) { /* toplevel return */\n              regs[irep->nlocals] = v;\n              goto CHECKPOINT_LABEL_MAKE(RBREAK_TAG_STOP);\n            }\n            if (!c->vmexec && c->prev->ci == c->prev->cibase) {\n              mrb_value exc = mrb_exc_new_lit(mrb, E_FIBER_ERROR, \"double resume\");\n              mrb_exc_set(mrb, exc);\n              goto L_RAISE;\n            }\n            CHECKPOINT_RESTORE(RBREAK_TAG_RETURN_TOPLEVEL) {\n              c = mrb->c;\n            }\n            CHECKPOINT_MAIN(RBREAK_TAG_RETURN_TOPLEVEL) {\n              UNWIND_ENSURE(mrb, ci, pc, RBREAK_TAG_RETURN_TOPLEVEL, proc, v);\n            }\n            CHECKPOINT_END(RBREAK_TAG_RETURN_TOPLEVEL);\n            /* automatic yield at the end */\n            c->status = MRB_FIBER_TERMINATED;\n            mrb->c = c->prev;\n            mrb->c->status = MRB_FIBER_RUNNING;\n            c->prev = NULL;\n            if (c->vmexec) {\n              mrb_gc_arena_restore(mrb, ai);\n              c->vmexec = FALSE;\n              mrb->jmp = prev_jmp;\n              return v;\n            }\n            ci = mrb->c->ci;\n          }\n          CHECKPOINT_RESTORE(RBREAK_TAG_RETURN) {\n            /* do nothing */\n          }\n          CHECKPOINT_MAIN(RBREAK_TAG_RETURN) {\n            UNWIND_ENSURE(mrb, ci, pc, RBREAK_TAG_RETURN, proc, v);\n          }\n          CHECKPOINT_END(RBREAK_TAG_RETURN);\n          mrb->exc = NULL; /* clear break object */\n          break;\n        case OP_R_BREAK:\n          if (MRB_PROC_STRICT_P(proc)) goto NORMAL_RETURN;\n          if (MRB_PROC_ORPHAN_P(proc)) {\n            mrb_value exc;\n\n          L_BREAK_ERROR:\n            exc = mrb_exc_new_lit(mrb, E_LOCALJUMP_ERROR,\n                                      \"break from proc-closure\");\n            mrb_exc_set(mrb, exc);\n            goto L_RAISE;\n          }\n          if (!MRB_PROC_ENV_P(proc) || !MRB_ENV_ONSTACK_P(MRB_PROC_ENV(proc))) {\n            goto L_BREAK_ERROR;\n          }\n          else {\n            struct REnv *e = MRB_PROC_ENV(proc);\n\n            if (e->cxt != mrb->c) {\n              goto L_BREAK_ERROR;\n            }\n          }\n          CHECKPOINT_RESTORE(RBREAK_TAG_BREAK) {\n            /* do nothing */\n          }\n          CHECKPOINT_MAIN(RBREAK_TAG_BREAK) {\n            UNWIND_ENSURE(mrb, ci, pc, RBREAK_TAG_BREAK, proc, v);\n          }\n          CHECKPOINT_END(RBREAK_TAG_BREAK);\n          /* break from fiber block */\n          if (ci == mrb->c->cibase && ci->pc) {\n            struct mrb_context *c = mrb->c;\n\n            mrb->c = c->prev;\n            c->prev = NULL;\n            ci = mrb->c->ci;\n          }\n          if (ci->cci > CINFO_NONE) {\n            ci = cipop(mrb);\n            mrb_gc_arena_restore(mrb, ai);\n            mrb->c->vmexec = FALSE;\n            mrb->exc = (struct RObject*)break_new(mrb, RBREAK_TAG_BREAK, proc, v);\n            mrb->jmp = prev_jmp;\n            MRB_THROW(prev_jmp);\n          }\n          if (FALSE) {\n            struct RBreak *brk;\n\n          L_BREAK:\n            brk = (struct RBreak*)mrb->exc;\n            proc = mrb_break_proc_get(brk);\n            v = mrb_break_value_get(brk);\n            ci = mrb->c->ci;\n\n            switch (mrb_break_tag_get(brk)) {\n#define DISPATCH_CHECKPOINTS(n, i) case n: goto CHECKPOINT_LABEL_MAKE(n);\n              RBREAK_TAG_FOREACH(DISPATCH_CHECKPOINTS)\n#undef DISPATCH_CHECKPOINTS\n              default:\n                mrb_assert(!\"wrong break tag\");\n            }\n          }\n          while (mrb->c->cibase < ci && ci[-1].proc != proc->upper) {\n            if (ci[-1].cci == CINFO_SKIP) {\n              goto L_BREAK_ERROR;\n            }\n            CHECKPOINT_RESTORE(RBREAK_TAG_BREAK_UPPER) {\n              /* do nothing */\n            }\n            CHECKPOINT_MAIN(RBREAK_TAG_BREAK_UPPER) {\n              UNWIND_ENSURE(mrb, ci, pc, RBREAK_TAG_BREAK_UPPER, proc, v);\n            }\n            CHECKPOINT_END(RBREAK_TAG_BREAK_UPPER);\n            ci = cipop(mrb);\n            pc = ci->pc;\n          }\n          CHECKPOINT_RESTORE(RBREAK_TAG_BREAK_INTARGET) {\n            /* do nothing */\n          }\n          CHECKPOINT_MAIN(RBREAK_TAG_BREAK_INTARGET) {\n            UNWIND_ENSURE(mrb, ci, pc, RBREAK_TAG_BREAK_INTARGET, proc, v);\n          }\n          CHECKPOINT_END(RBREAK_TAG_BREAK_INTARGET);\n          if (ci == mrb->c->cibase) {\n            goto L_BREAK_ERROR;\n          }\n          mrb->exc = NULL; /* clear break object */\n          break;\n        default:\n          /* cannot happen */\n          break;\n        }\n        mrb_assert(ci == mrb->c->ci);\n        mrb_assert(mrb->exc == NULL);\n\n        if (mrb->c->vmexec && !mrb_vm_ci_target_class(ci)) {\n          mrb_gc_arena_restore(mrb, ai);\n          mrb->c->vmexec = FALSE;\n          mrb->jmp = prev_jmp;\n          return v;\n        }\n        acc = ci->cci;\n        ci = cipop(mrb);\n        if (acc == CINFO_SKIP || acc == CINFO_DIRECT) {\n          mrb_gc_arena_restore(mrb, ai);\n          mrb->jmp = prev_jmp;\n          return v;\n        }\n        pc = ci->pc;\n        DEBUG(fprintf(stderr, \"from :%s\\n\", mrb_sym_name(mrb, ci->mid)));\n        proc = ci->proc;\n        irep = proc->body.irep;\n        pool = irep->pool;\n        syms = irep->syms;\n\n        ci[1].stack[0] = v;\n        mrb_gc_arena_restore(mrb, ai);\n      }\n      JUMP;\n    }\n\n    CASE(OP_BLKPUSH, BS) {\n      int m1 = (b>>11)&0x3f;\n      int r  = (b>>10)&0x1;\n      int m2 = (b>>5)&0x1f;\n      int kd = (b>>4)&0x1;\n      int lv = (b>>0)&0xf;\n      mrb_value *stack;\n\n      if (lv == 0) stack = regs + 1;\n      else {\n        struct REnv *e = uvenv(mrb, lv-1);\n        if (!e || (!MRB_ENV_ONSTACK_P(e) && e->mid == 0) ||\n            MRB_ENV_LEN(e) <= m1+r+m2+1) {\n          localjump_error(mrb, LOCALJUMP_ERROR_YIELD);\n          goto L_RAISE;\n        }\n        stack = e->stack + 1;\n      }\n      if (mrb_nil_p(stack[m1+r+m2+kd])) {\n        localjump_error(mrb, LOCALJUMP_ERROR_YIELD);\n        goto L_RAISE;\n      }\n      regs[a] = stack[m1+r+m2+kd];\n      NEXT;\n    }\n\n  L_INT_OVERFLOW:\n    {\n      mrb_value exc = mrb_exc_new_lit(mrb, E_RANGE_ERROR, \"integer overflow\");\n      mrb_exc_set(mrb, exc);\n    }\n    goto L_RAISE;\n\n#define TYPES2(a,b) ((((uint16_t)(a))<<8)|(((uint16_t)(b))&0xff))\n#define OP_MATH(op_name)                                                    \\\n  /* need to check if op is overridden */                                   \\\n  switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {                  \\\n    OP_MATH_CASE_INTEGER(op_name);                                          \\\n    OP_MATH_CASE_FLOAT(op_name, integer, float);                            \\\n    OP_MATH_CASE_FLOAT(op_name, float,  integer);                           \\\n    OP_MATH_CASE_FLOAT(op_name, float,  float);                             \\\n    OP_MATH_CASE_STRING_##op_name();                                        \\\n    default:                                                                \\\n      mid = MRB_OPSYM(op_name);                                             \\\n      goto L_SEND_SYM;                                                      \\\n  }                                                                         \\\n  NEXT;\n#define OP_MATH_CASE_INTEGER(op_name)                                       \\\n  case TYPES2(MRB_TT_INTEGER, MRB_TT_INTEGER):                              \\\n    {                                                                       \\\n      mrb_int x = mrb_integer(regs[a]), y = mrb_integer(regs[a+1]), z;      \\\n      if (mrb_int_##op_name##_overflow(x, y, &z))                           \\\n        OP_MATH_OVERFLOW_INT();                                             \\\n      else                                                                  \\\n        SET_INT_VALUE(mrb,regs[a], z);                                      \\\n    }                                                                       \\\n    break\n#ifdef MRB_NO_FLOAT\n#define OP_MATH_CASE_FLOAT(op_name, t1, t2) (void)0\n#else\n#define OP_MATH_CASE_FLOAT(op_name, t1, t2)                                     \\\n  case TYPES2(OP_MATH_TT_##t1, OP_MATH_TT_##t2):                                \\\n    {                                                                           \\\n      mrb_float z = mrb_##t1(regs[a]) OP_MATH_OP_##op_name mrb_##t2(regs[a+1]); \\\n      SET_FLOAT_VALUE(mrb, regs[a], z);                                         \\\n    }                                                                           \\\n    break\n#endif\n#define OP_MATH_OVERFLOW_INT() goto L_INT_OVERFLOW\n#define OP_MATH_CASE_STRING_add()                                           \\\n  case TYPES2(MRB_TT_STRING, MRB_TT_STRING):                                \\\n    regs[a] = mrb_str_plus(mrb, regs[a], regs[a+1]);                        \\\n    mrb_gc_arena_restore(mrb, ai);                                          \\\n    break\n#define OP_MATH_CASE_STRING_sub() (void)0\n#define OP_MATH_CASE_STRING_mul() (void)0\n#define OP_MATH_OP_add +\n#define OP_MATH_OP_sub -\n#define OP_MATH_OP_mul *\n#define OP_MATH_TT_integer MRB_TT_INTEGER\n#define OP_MATH_TT_float   MRB_TT_FLOAT\n\n    CASE(OP_ADD, B) {\n      OP_MATH(add);\n    }\n\n    CASE(OP_SUB, B) {\n      OP_MATH(sub);\n    }\n\n    CASE(OP_MUL, B) {\n      OP_MATH(mul);\n    }\n\n    CASE(OP_DIV, B) {\n#ifndef MRB_NO_FLOAT\n      mrb_float x, y, f;\n#endif\n\n      /* need to check if op is overridden */\n      switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\n      case TYPES2(MRB_TT_INTEGER,MRB_TT_INTEGER):\n        {\n          mrb_int x = mrb_integer(regs[a]);\n          mrb_int y = mrb_integer(regs[a+1]);\n          mrb_int div = mrb_div_int(mrb, x, y);\n          SET_INT_VALUE(mrb, regs[a], div);\n        }\n        NEXT;\n#ifndef MRB_NO_FLOAT\n      case TYPES2(MRB_TT_INTEGER,MRB_TT_FLOAT):\n        x = (mrb_float)mrb_integer(regs[a]);\n        y = mrb_float(regs[a+1]);\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_INTEGER):\n        x = mrb_float(regs[a]);\n        y = (mrb_float)mrb_integer(regs[a+1]);\n        break;\n      case TYPES2(MRB_TT_FLOAT,MRB_TT_FLOAT):\n        x = mrb_float(regs[a]);\n        y = mrb_float(regs[a+1]);\n        break;\n#endif\n      default:\n        mid = MRB_OPSYM(div);\n        goto L_SEND_SYM;\n      }\n\n#ifndef MRB_NO_FLOAT\n      f = mrb_div_float(x, y);\n      SET_FLOAT_VALUE(mrb, regs[a], f);\n#endif\n      NEXT;\n    }\n\n#define OP_MATHI(op_name)                                                   \\\n  /* need to check if op is overridden */                                   \\\n  switch (mrb_type(regs[a])) {                                              \\\n    OP_MATHI_CASE_INTEGER(op_name);                                         \\\n    OP_MATHI_CASE_FLOAT(op_name);                                           \\\n    default:                                                                \\\n      SET_INT_VALUE(mrb,regs[a+1], b);                                      \\\n      mid = MRB_OPSYM(op_name);                                             \\\n      goto L_SEND_SYM;                                                      \\\n  }                                                                         \\\n  NEXT;\n#define OP_MATHI_CASE_INTEGER(op_name)                                      \\\n  case MRB_TT_INTEGER:                                                      \\\n    {                                                                       \\\n      mrb_int x = mrb_integer(regs[a]), y = (mrb_int)b, z;                  \\\n      if (mrb_int_##op_name##_overflow(x, y, &z))                           \\\n        OP_MATH_OVERFLOW_INT();                                             \\\n      else                                                                  \\\n        SET_INT_VALUE(mrb,regs[a], z);                                      \\\n    }                                                                       \\\n    break\n#ifdef MRB_NO_FLOAT\n#define OP_MATHI_CASE_FLOAT(op_name) (void)0\n#else\n#define OP_MATHI_CASE_FLOAT(op_name)                                        \\\n  case MRB_TT_FLOAT:                                                        \\\n    {                                                                       \\\n      mrb_float z = mrb_float(regs[a]) OP_MATH_OP_##op_name b;              \\\n      SET_FLOAT_VALUE(mrb, regs[a], z);                                     \\\n    }                                                                       \\\n    break\n#endif\n\n    CASE(OP_ADDI, BB) {\n      OP_MATHI(add);\n    }\n\n    CASE(OP_SUBI, BB) {\n      OP_MATHI(sub);\n    }\n\n#define OP_CMP_BODY(op,v1,v2) (v1(regs[a]) op v2(regs[a+1]))\n\n#ifdef MRB_NO_FLOAT\n#define OP_CMP(op,sym) do {\\\n  int result;\\\n  /* need to check if - is overridden */\\\n  switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\\\n  case TYPES2(MRB_TT_INTEGER,MRB_TT_INTEGER):\\\n    result = OP_CMP_BODY(op,mrb_fixnum,mrb_fixnum);\\\n    break;\\\n  default:\\\n    mid = MRB_OPSYM(sym);\\\n    goto L_SEND_SYM;\\\n  }\\\n  if (result) {\\\n    SET_TRUE_VALUE(regs[a]);\\\n  }\\\n  else {\\\n    SET_FALSE_VALUE(regs[a]);\\\n  }\\\n} while(0)\n#else\n#define OP_CMP(op, sym) do {\\\n  int result;\\\n  /* need to check if - is overridden */\\\n  switch (TYPES2(mrb_type(regs[a]),mrb_type(regs[a+1]))) {\\\n  case TYPES2(MRB_TT_INTEGER,MRB_TT_INTEGER):\\\n    result = OP_CMP_BODY(op,mrb_fixnum,mrb_fixnum);\\\n    break;\\\n  case TYPES2(MRB_TT_INTEGER,MRB_TT_FLOAT):\\\n    result = OP_CMP_BODY(op,mrb_fixnum,mrb_float);\\\n    break;\\\n  case TYPES2(MRB_TT_FLOAT,MRB_TT_INTEGER):\\\n    result = OP_CMP_BODY(op,mrb_float,mrb_fixnum);\\\n    break;\\\n  case TYPES2(MRB_TT_FLOAT,MRB_TT_FLOAT):\\\n    result = OP_CMP_BODY(op,mrb_float,mrb_float);\\\n    break;\\\n  default:\\\n    mid = MRB_OPSYM(sym);\\\n    goto L_SEND_SYM;\\\n  }\\\n  if (result) {\\\n    SET_TRUE_VALUE(regs[a]);\\\n  }\\\n  else {\\\n    SET_FALSE_VALUE(regs[a]);\\\n  }\\\n} while(0)\n#endif\n\n    CASE(OP_EQ, B) {\n      if (mrb_obj_eq(mrb, regs[a], regs[a+1])) {\n        SET_TRUE_VALUE(regs[a]);\n      }\n      else {\n        OP_CMP(==,eq);\n      }\n      NEXT;\n    }\n\n    CASE(OP_LT, B) {\n      OP_CMP(<,lt);\n      NEXT;\n    }\n\n    CASE(OP_LE, B) {\n      OP_CMP(<=,le);\n      NEXT;\n    }\n\n    CASE(OP_GT, B) {\n      OP_CMP(>,gt);\n      NEXT;\n    }\n\n    CASE(OP_GE, B) {\n      OP_CMP(>=,ge);\n      NEXT;\n    }\n\n    CASE(OP_ARRAY, BB) {\n      regs[a] = mrb_ary_new_from_values(mrb, b, &regs[a]);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n    CASE(OP_ARRAY2, BBB) {\n      regs[a] = mrb_ary_new_from_values(mrb, c, &regs[b]);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_ARYCAT, B) {\n      mrb_value splat = mrb_ary_splat(mrb, regs[a+1]);\n      if (mrb_nil_p(regs[a])) {\n        regs[a] = splat;\n      }\n      else {\n        mrb_assert(mrb_array_p(regs[a]));\n        mrb_ary_concat(mrb, regs[a], splat);\n      }\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_ARYPUSH, BB) {\n      mrb_assert(mrb_array_p(regs[a]));\n      for (mrb_int i=0; i<b; i++) {\n        mrb_ary_push(mrb, regs[a], regs[a+i+1]);\n      }\n      NEXT;\n    }\n\n    CASE(OP_ARYDUP, B) {\n      mrb_value ary = regs[a];\n      if (mrb_array_p(ary)) {\n        ary = mrb_ary_new_from_values(mrb, RARRAY_LEN(ary), RARRAY_PTR(ary));\n      }\n      else {\n        ary = mrb_ary_new_from_values(mrb, 1, &ary);\n      }\n      regs[a] = ary;\n      NEXT;\n    }\n\n    CASE(OP_AREF, BBB) {\n      mrb_value v = regs[b];\n\n      if (!mrb_array_p(v)) {\n        if (c == 0) {\n          regs[a] = v;\n        }\n        else {\n          SET_NIL_VALUE(regs[a]);\n        }\n      }\n      else {\n        v = mrb_ary_ref(mrb, v, c);\n        regs[a] = v;\n      }\n      NEXT;\n    }\n\n    CASE(OP_ASET, BBB) {\n      mrb_assert(mrb_array_p(regs[a]));\n      mrb_ary_set(mrb, regs[b], c, regs[a]);\n      NEXT;\n    }\n\n    CASE(OP_APOST, BBB) {\n      mrb_value v = regs[a];\n      int pre  = b;\n      int post = c;\n      struct RArray *ary;\n      int len, idx;\n\n      if (!mrb_array_p(v)) {\n        v = mrb_ary_new_from_values(mrb, 1, &regs[a]);\n      }\n      ary = mrb_ary_ptr(v);\n      len = (int)ARY_LEN(ary);\n      if (len > pre + post) {\n        v = mrb_ary_new_from_values(mrb, len - pre - post, ARY_PTR(ary)+pre);\n        regs[a++] = v;\n        while (post--) {\n          regs[a++] = ARY_PTR(ary)[len-post-1];\n        }\n      }\n      else {\n        v = mrb_ary_new_capa(mrb, 0);\n        regs[a++] = v;\n        for (idx=0; idx+pre<len; idx++) {\n          regs[a+idx] = ARY_PTR(ary)[pre+idx];\n        }\n        while (idx < post) {\n          SET_NIL_VALUE(regs[a+idx]);\n          idx++;\n        }\n      }\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_INTERN, B) {\n      mrb_assert(mrb_string_p(regs[a]));\n      mrb_sym sym = mrb_intern_str(mrb, regs[a]);\n      regs[a] = mrb_symbol_value(sym);\n      NEXT;\n    }\n\n    CASE(OP_SYMBOL, BB) {\n      size_t len;\n      mrb_sym sym;\n\n      mrb_assert((pool[b].tt&IREP_TT_NFLAG)==0);\n      len = pool[b].tt >> 2;\n      if (pool[b].tt & IREP_TT_SFLAG) {\n        sym = mrb_intern_static(mrb, pool[b].u.str, len);\n      }\n      else {\n        sym  = mrb_intern(mrb, pool[b].u.str, len);\n      }\n      regs[a] = mrb_symbol_value(sym);\n      NEXT;\n    }\n\n    CASE(OP_STRING, BB) {\n      mrb_int len;\n\n      mrb_assert((pool[b].tt&IREP_TT_NFLAG)==0);\n      len = pool[b].tt >> 2;\n      if (pool[b].tt & IREP_TT_SFLAG) {\n        regs[a] = mrb_str_new_static(mrb, pool[b].u.str, len);\n      }\n      else {\n        regs[a] = mrb_str_new(mrb, pool[b].u.str, len);\n      }\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_STRCAT, B) {\n      mrb_assert(mrb_string_p(regs[a]));\n      mrb_str_concat(mrb, regs[a], regs[a+1]);\n      NEXT;\n    }\n\n    CASE(OP_HASH, BB) {\n      mrb_value hash = mrb_hash_new_capa(mrb, b);\n      int i;\n      int lim = a+b*2;\n\n      for (i=a; i<lim; i+=2) {\n        mrb_hash_set(mrb, hash, regs[i], regs[i+1]);\n      }\n      regs[a] = hash;\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_HASHADD, BB) {\n      mrb_value hash;\n      int i;\n      int lim = a+b*2+1;\n\n      hash = regs[a];\n      mrb_ensure_hash_type(mrb, hash);\n      for (i=a+1; i<lim; i+=2) {\n        mrb_hash_set(mrb, hash, regs[i], regs[i+1]);\n      }\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n    CASE(OP_HASHCAT, B) {\n      mrb_value hash = regs[a];\n\n      mrb_assert(mrb_hash_p(hash));\n      mrb_hash_merge(mrb, hash, regs[a+1]);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_LAMBDA, BB)\n    c = OP_L_LAMBDA;\n    L_MAKE_LAMBDA:\n    {\n      struct RProc *p;\n      const mrb_irep *nirep = irep->reps[b];\n\n      if (c & OP_L_CAPTURE) {\n        p = mrb_closure_new(mrb, nirep);\n      }\n      else {\n        p = mrb_proc_new(mrb, nirep);\n        p->flags |= MRB_PROC_SCOPE;\n      }\n      if (c & OP_L_STRICT) p->flags |= MRB_PROC_STRICT;\n      regs[a] = mrb_obj_value(p);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n    CASE(OP_BLOCK, BB) {\n      c = OP_L_BLOCK;\n      goto L_MAKE_LAMBDA;\n    }\n    CASE(OP_METHOD, BB) {\n      c = OP_L_METHOD;\n      goto L_MAKE_LAMBDA;\n    }\n\n    CASE(OP_RANGE_INC, B) {\n      mrb_value v = mrb_range_new(mrb, regs[a], regs[a+1], FALSE);\n      regs[a] = v;\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_RANGE_EXC, B) {\n      mrb_value v = mrb_range_new(mrb, regs[a], regs[a+1], TRUE);\n      regs[a] = v;\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_OCLASS, B) {\n      regs[a] = mrb_obj_value(mrb->object_class);\n      NEXT;\n    }\n\n    CASE(OP_CLASS, BB) {\n      struct RClass *c = 0, *baseclass;\n      mrb_value base, super;\n      mrb_sym id = syms[b];\n\n      base = regs[a];\n      super = regs[a+1];\n      if (mrb_nil_p(base)) {\n        baseclass = MRB_PROC_TARGET_CLASS(mrb->c->ci->proc);\n        if (!baseclass) baseclass = mrb->object_class;\n        base = mrb_obj_value(baseclass);\n      }\n      c = mrb_vm_define_class(mrb, base, super, id);\n      regs[a] = mrb_obj_value(c);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_MODULE, BB) {\n      struct RClass *cls = 0, *baseclass;\n      mrb_value base;\n      mrb_sym id = syms[b];\n\n      base = regs[a];\n      if (mrb_nil_p(base)) {\n        baseclass = MRB_PROC_TARGET_CLASS(mrb->c->ci->proc);\n        if (!baseclass) baseclass = mrb->object_class;\n        base = mrb_obj_value(baseclass);\n      }\n      cls = mrb_vm_define_module(mrb, base, id);\n      regs[a] = mrb_obj_value(cls);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_EXEC, BB)\n    {\n      mrb_value recv = regs[a];\n      struct RProc *p;\n      const mrb_irep *nirep = irep->reps[b];\n\n      /* prepare closure */\n      p = mrb_proc_new(mrb, nirep);\n      p->c = NULL;\n      mrb_field_write_barrier(mrb, (struct RBasic*)p, (struct RBasic*)proc);\n      MRB_PROC_SET_TARGET_CLASS(p, mrb_class_ptr(recv));\n      p->flags |= MRB_PROC_SCOPE;\n\n      /* prepare call stack */\n      cipush(mrb, a, 0, mrb_class_ptr(recv), p, 0, 0);\n\n      irep = p->body.irep;\n      pool = irep->pool;\n      syms = irep->syms;\n      mrb_stack_extend(mrb, irep->nregs);\n      stack_clear(regs+1, irep->nregs-1);\n      pc = irep->iseq;\n      JUMP;\n    }\n\n    CASE(OP_DEF, BB) {\n      struct RClass *target = mrb_class_ptr(regs[a]);\n      struct RProc *p = mrb_proc_ptr(regs[a+1]);\n      mrb_method_t m;\n      mrb_sym mid = syms[b];\n\n      MRB_METHOD_FROM_PROC(m, p);\n      mrb_define_method_raw(mrb, target, mid, m);\n      mrb_method_added(mrb, target, mid);\n      mrb_gc_arena_restore(mrb, ai);\n      regs[a] = mrb_symbol_value(mid);\n      NEXT;\n    }\n\n    CASE(OP_SCLASS, B) {\n      regs[a] = mrb_singleton_class(mrb, regs[a]);\n      mrb_gc_arena_restore(mrb, ai);\n      NEXT;\n    }\n\n    CASE(OP_TCLASS, B) {\n      struct RClass *target = check_target_class(mrb);\n      if (!target) goto L_RAISE;\n      regs[a] = mrb_obj_value(target);\n      NEXT;\n    }\n\n    CASE(OP_ALIAS, BB) {\n      struct RClass *target = check_target_class(mrb);\n\n      if (!target) goto L_RAISE;\n      mrb_alias_method(mrb, target, syms[a], syms[b]);\n      mrb_method_added(mrb, target, syms[a]);\n      NEXT;\n    }\n    CASE(OP_UNDEF, B) {\n      struct RClass *target = check_target_class(mrb);\n\n      if (!target) goto L_RAISE;\n      mrb_undef_method_id(mrb, target, syms[a]);\n      NEXT;\n    }\n\n    CASE(OP_DEBUG, Z) {\n      FETCH_BBB();\n#ifdef MRB_USE_DEBUG_HOOK\n      mrb->debug_op_hook(mrb, irep, pc, regs);\n#else\n#ifndef MRB_NO_STDIO\n      printf(\"OP_DEBUG %d %d %d\\n\", a, b, c);\n#else\n      abort();\n#endif\n#endif\n      NEXT;\n    }\n\n    CASE(OP_ERR, B) {\n      size_t len = pool[a].tt >> 2;\n      mrb_value exc;\n\n      mrb_assert((pool[a].tt&IREP_TT_NFLAG)==0);\n      exc = mrb_exc_new(mrb, E_LOCALJUMP_ERROR, pool[a].u.str, len);\n      mrb_exc_set(mrb, exc);\n      goto L_RAISE;\n    }\n\n    CASE(OP_EXT1, Z) {\n      insn = READ_B();\n      switch (insn) {\n#define OPCODE(insn,ops) case OP_ ## insn: FETCH_ ## ops ## _1(); mrb->c->ci->pc = pc; goto L_OP_ ## insn ## _BODY;\n#include \"mruby/ops.h\"\n#undef OPCODE\n      }\n      pc--;\n      NEXT;\n    }\n    CASE(OP_EXT2, Z) {\n      insn = READ_B();\n      switch (insn) {\n#define OPCODE(insn,ops) case OP_ ## insn: FETCH_ ## ops ## _2(); mrb->c->ci->pc = pc; goto L_OP_ ## insn ## _BODY;\n#include \"mruby/ops.h\"\n#undef OPCODE\n      }\n      pc--;\n      NEXT;\n    }\n    CASE(OP_EXT3, Z) {\n      uint8_t insn = READ_B();\n      switch (insn) {\n#define OPCODE(insn,ops) case OP_ ## insn: FETCH_ ## ops ## _3(); mrb->c->ci->pc = pc; goto L_OP_ ## insn ## _BODY;\n#include \"mruby/ops.h\"\n#undef OPCODE\n      }\n      pc--;\n      NEXT;\n    }\n\n    CASE(OP_STOP, Z) {\n      /*        stop VM */\n      CHECKPOINT_RESTORE(RBREAK_TAG_STOP) {\n        /* do nothing */\n      }\n      CHECKPOINT_MAIN(RBREAK_TAG_STOP) {\n        UNWIND_ENSURE(mrb, mrb->c->ci, pc, RBREAK_TAG_STOP, proc, mrb_nil_value());\n      }\n      CHECKPOINT_END(RBREAK_TAG_STOP);\n    L_STOP:\n      mrb->jmp = prev_jmp;\n      if (mrb->exc) {\n        mrb_assert(mrb->exc->tt == MRB_TT_EXCEPTION);\n        return mrb_obj_value(mrb->exc);\n      }\n      return regs[irep->nlocals];\n    }\n  }\n  END_DISPATCH;\n#undef regs\n  }\n  MRB_CATCH(&c_jmp) {\n    mrb_callinfo *ci = mrb->c->ci;\n    while (ci > mrb->c->cibase && ci->cci == CINFO_DIRECT) {\n      ci = cipop(mrb);\n    }\n    exc_catched = TRUE;\n    pc = ci->pc;\n    goto RETRY_TRY_BLOCK;\n  }\n  MRB_END_EXC(&c_jmp);\n}",
        "func_hash": 214632234325372237977713260759937528043,
        "file_name": "vm.c",
        "file_hash": 170767380435846497188487321763087479620,
        "cwe": [
            "CWE-476"
        ],
        "cve": "CVE-2022-1201",
        "cve_desc": "NULL Pointer Dereference in mrb_vm_exec with super in GitHub repository mruby/mruby prior to 3.2. This vulnerability is capable of making the mruby interpreter crash, thus affecting the availability of the system.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-1201",
        "func_name": "mrb_vm_exec",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 198523,
        "project": "tensorflow",
        "commit_id": "5ecec9c6fbdbc6be03295685190a45e7eee726ab",
        "project_url": "https://github.com/tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/5ecec9c6fbdbc6be03295685190a45e7eee726ab",
        "commit_message": "Prevent use after free.\n\nA very old version of the code used `result` as a simple pointer to a resource. Two years later, the pointer got changed to a `unique_ptr` but author forgot to remove the call to `Unref`. Three years after that, we finally uncover the UAF.\n\nPiperOrigin-RevId: 387924872\nChange-Id: I70fb6f199164de49fac20c168132a07b84903f9b",
        "target": 1,
        "irrelevant": 0,
        "func_before": "  void Compute(OpKernelContext* context) override {\n    // Get the stamp token.\n    const Tensor* stamp_token_t;\n    OP_REQUIRES_OK(context, context->input(\"stamp_token\", &stamp_token_t));\n    int64_t stamp_token = stamp_token_t->scalar<int64>()();\n\n    // Get the tree ensemble proto.\n    const Tensor* tree_ensemble_serialized_t;\n    OP_REQUIRES_OK(context, context->input(\"tree_ensemble_serialized\",\n                                           &tree_ensemble_serialized_t));\n    std::unique_ptr<BoostedTreesEnsembleResource> result(\n        new BoostedTreesEnsembleResource());\n    if (!result->InitFromSerialized(\n            tree_ensemble_serialized_t->scalar<tstring>()(), stamp_token)) {\n      result->Unref();\n      OP_REQUIRES(\n          context, false,\n          errors::InvalidArgument(\"Unable to parse tree ensemble proto.\"));\n    }\n\n    // Only create one, if one does not exist already. Report status for all\n    // other exceptions.\n    auto status =\n        CreateResource(context, HandleFromInput(context, 0), result.release());\n    if (status.code() != tensorflow::error::ALREADY_EXISTS) {\n      OP_REQUIRES_OK(context, status);\n    }\n  }",
        "func_hash": 151034027968901870222536100864741418474,
        "file_name": "resource_ops.cc",
        "file_hash": 40939400980967911969144269399937980796,
        "cwe": [
            "CWE-416"
        ],
        "cve": "CVE-2021-37652",
        "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions the implementation for `tf.raw_ops.BoostedTreesCreateEnsemble` can result in a use after free error if an attacker supplies specially crafted arguments. The [implementation](https://github.com/tensorflow/tensorflow/blob/f24faa153ad31a4b51578f8181d3aaab77a1ddeb/tensorflow/core/kernels/boosted_trees/resource_ops.cc#L55) uses a reference counted resource and decrements the refcount if the initialization fails, as it should. However, when the code was written, the resource was represented as a naked pointer but later refactoring has changed it to be a smart pointer. Thus, when the pointer leaves the scope, a subsequent `free`-ing of the resource occurs, but this fails to take into account that the refcount has already reached 0, thus the resource has been already freed. During this double-free process, members of the resource object are accessed for cleanup but they are invalid as the entire resource has been freed. We have patched the issue in GitHub commit 5ecec9c6fbdbc6be03295685190a45e7eee726ab. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37652",
        "func_name": "Compute",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 198545,
        "project": "u-boot",
        "commit_id": "8f8c04bf1ebbd2f72f1643e7ad9617dafa6e5409",
        "project_url": "https://github.com/u-boot/u-boot",
        "commit_url": "https://github.com/u-boot/u-boot/commit/8f8c04bf1ebbd2f72f1643e7ad9617dafa6e5409",
        "commit_message": "i2c: fix stack buffer overflow vulnerability in i2c md command\n\nWhen running \"i2c md 0 0 80000100\", the function do_i2c_md parses the\nlength into an unsigned int variable named length. The value is then\nmoved to a signed variable:\n\n    int nbytes = length;\n    #define DISP_LINE_LEN 16\n    int linebytes = (nbytes > DISP_LINE_LEN) ? DISP_LINE_LEN : nbytes;\n    ret = dm_i2c_read(dev, addr, linebuf, linebytes);\n\nOn systems where integers are 32 bits wide, 0x80000100 is a negative\nvalue to \"nbytes > DISP_LINE_LEN\" is false and linebytes gets assigned\n0x80000100 instead of 16.\n\nThe consequence is that the function which reads from the i2c device\n(dm_i2c_read or i2c_read) is called with a 16-byte stack buffer to fill\nbut with a size parameter which is too large. In some cases, this could\ntrigger a crash. But with some i2c drivers, such as drivers/i2c/nx_i2c.c\n(used with \"nexell,s5pxx18-i2c\" bus), the size is actually truncated to\na 16-bit integer. This is because function i2c_transfer expects an\nunsigned short length. In such a case, an attacker who can control the\nresponse of an i2c device can overwrite the return address of a function\nand execute arbitrary code through Return-Oriented Programming.\n\nFix this issue by using unsigned integers types in do_i2c_md. While at\nit, make also alen unsigned, as signed sizes can cause vulnerabilities\nwhen people forgot to check that they can be negative.\n\nSigned-off-by: Nicolas Iooss <nicolas.iooss+uboot@ledger.fr>\nReviewed-by: Heiko Schocher <hs@denx.de>",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static int do_i2c_md(struct cmd_tbl *cmdtp, int flag, int argc,\n\t\t     char *const argv[])\n{\n\tuint\tchip;\n\tuint\taddr, length;\n\tint alen;\n\tint\tj, nbytes, linebytes;\n\tint ret;\n#if CONFIG_IS_ENABLED(DM_I2C)\n\tstruct udevice *dev;\n#endif\n\n\t/* We use the last specified parameters, unless new ones are\n\t * entered.\n\t */\n\tchip   = i2c_dp_last_chip;\n\taddr   = i2c_dp_last_addr;\n\talen   = i2c_dp_last_alen;\n\tlength = i2c_dp_last_length;\n\n\tif (argc < 3)\n\t\treturn CMD_RET_USAGE;\n\n\tif ((flag & CMD_FLAG_REPEAT) == 0) {\n\t\t/*\n\t\t * New command specified.\n\t\t */\n\n\t\t/*\n\t\t * I2C chip address\n\t\t */\n\t\tchip = hextoul(argv[1], NULL);\n\n\t\t/*\n\t\t * I2C data address within the chip.  This can be 1 or\n\t\t * 2 bytes long.  Some day it might be 3 bytes long :-).\n\t\t */\n\t\taddr = hextoul(argv[2], NULL);\n\t\talen = get_alen(argv[2], DEFAULT_ADDR_LEN);\n\t\tif (alen > 3)\n\t\t\treturn CMD_RET_USAGE;\n\n\t\t/*\n\t\t * If another parameter, it is the length to display.\n\t\t * Length is the number of objects, not number of bytes.\n\t\t */\n\t\tif (argc > 3)\n\t\t\tlength = hextoul(argv[3], NULL);\n\t}\n\n#if CONFIG_IS_ENABLED(DM_I2C)\n\tret = i2c_get_cur_bus_chip(chip, &dev);\n\tif (!ret && alen != -1)\n\t\tret = i2c_set_chip_offset_len(dev, alen);\n\tif (ret)\n\t\treturn i2c_report_err(ret, I2C_ERR_READ);\n#endif\n\n\t/*\n\t * Print the lines.\n\t *\n\t * We buffer all read data, so we can make sure data is read only\n\t * once.\n\t */\n\tnbytes = length;\n\tdo {\n\t\tunsigned char\tlinebuf[DISP_LINE_LEN];\n\t\tunsigned char\t*cp;\n\n\t\tlinebytes = (nbytes > DISP_LINE_LEN) ? DISP_LINE_LEN : nbytes;\n\n#if CONFIG_IS_ENABLED(DM_I2C)\n\t\tret = dm_i2c_read(dev, addr, linebuf, linebytes);\n#else\n\t\tret = i2c_read(chip, addr, alen, linebuf, linebytes);\n#endif\n\t\tif (ret)\n\t\t\treturn i2c_report_err(ret, I2C_ERR_READ);\n\t\telse {\n\t\t\tprintf(\"%04x:\", addr);\n\t\t\tcp = linebuf;\n\t\t\tfor (j=0; j<linebytes; j++) {\n\t\t\t\tprintf(\" %02x\", *cp++);\n\t\t\t\taddr++;\n\t\t\t}\n\t\t\tputs (\"    \");\n\t\t\tcp = linebuf;\n\t\t\tfor (j=0; j<linebytes; j++) {\n\t\t\t\tif ((*cp < 0x20) || (*cp > 0x7e))\n\t\t\t\t\tputs (\".\");\n\t\t\t\telse\n\t\t\t\t\tprintf(\"%c\", *cp);\n\t\t\t\tcp++;\n\t\t\t}\n\t\t\tputc ('\\n');\n\t\t}\n\t\tnbytes -= linebytes;\n\t} while (nbytes > 0);\n\n\ti2c_dp_last_chip   = chip;\n\ti2c_dp_last_addr   = addr;\n\ti2c_dp_last_alen   = alen;\n\ti2c_dp_last_length = length;\n\n\treturn 0;\n}",
        "func_hash": 336388644236353594568664801027238457577,
        "file_name": "i2c.c",
        "file_hash": 135764079202241918781821738561519186738,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2022-34835",
        "cve_desc": "In Das U-Boot through 2022.07-rc5, an integer signedness error and resultant stack-based buffer overflow in the \"i2c md\" command enables the corruption of the return address pointer of the do_i2c_md function.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-34835",
        "func_name": "do_i2c_md",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 198552,
        "project": "engine",
        "commit_id": "7df766124f87768b43b9e8947c5a01e17545772c",
        "project_url": "https://github.com/gost-engine/engine",
        "commit_url": "https://github.com/gost-engine/engine/commit/7df766124f87768b43b9e8947c5a01e17545772c",
        "commit_message": "Fix buffer overrun in creating key transport blob according to RFC 9189, 4.2.4.2\n\nResolves: CVE-2022-29242",
        "target": 1,
        "irrelevant": 0,
        "func_before": "static int pkey_GOST_ECcp_encrypt(EVP_PKEY_CTX *pctx, unsigned char *out,\n                           size_t *out_len, const unsigned char *key,\n                           size_t key_len)\n{\n    GOST_KEY_TRANSPORT *gkt = NULL;\n    EVP_PKEY *pubk = EVP_PKEY_CTX_get0_pkey(pctx);\n    struct gost_pmeth_data *data = EVP_PKEY_CTX_get_data(pctx);\n    int pkey_nid = EVP_PKEY_base_id(pubk);\n    ASN1_OBJECT *crypt_params_obj = (pkey_nid == NID_id_GostR3410_2001 || pkey_nid == NID_id_GostR3410_2001DH) ?\n        OBJ_nid2obj(NID_id_Gost28147_89_CryptoPro_A_ParamSet) :\n        OBJ_nid2obj(NID_id_tc26_gost_28147_param_Z);\n    const struct gost_cipher_info *param =\n        get_encryption_params(crypt_params_obj);\n    unsigned char ukm[8], shared_key[32], crypted_key[44];\n    int ret = 0;\n    int key_is_ephemeral = 1;\n    gost_ctx cctx;\n    EVP_PKEY *sec_key = EVP_PKEY_CTX_get0_peerkey(pctx);\n    if (data->shared_ukm_size) {\n        memcpy(ukm, data->shared_ukm, 8);\n    } else {\n        if (RAND_bytes(ukm, 8) <= 0) {\n            GOSTerr(GOST_F_PKEY_GOST_ECCP_ENCRYPT, GOST_R_RNG_ERROR);\n            return 0;\n        }\n    }\n    if (!param)\n        goto err;\n    /* Check for private key in the peer_key of context */\n    if (sec_key) {\n        key_is_ephemeral = 0;\n        if (!gost_get0_priv_key(sec_key)) {\n            GOSTerr(GOST_F_PKEY_GOST_ECCP_ENCRYPT,\n                    GOST_R_NO_PRIVATE_PART_OF_NON_EPHEMERAL_KEYPAIR);\n            goto err;\n        }\n    } else {\n        key_is_ephemeral = 1;\n        if (out) {\n            sec_key = EVP_PKEY_new();\n            if (!EVP_PKEY_assign(sec_key, EVP_PKEY_base_id(pubk), EC_KEY_new())\n                || !EVP_PKEY_copy_parameters(sec_key, pubk)\n                || !gost_ec_keygen(EVP_PKEY_get0(sec_key))) {\n                GOSTerr(GOST_F_PKEY_GOST_ECCP_ENCRYPT,\n                        GOST_R_ERROR_COMPUTING_SHARED_KEY);\n                goto err;\n            }\n        }\n    }\n    if (out) {\n        int dgst_nid = NID_undef;\n        EVP_PKEY_get_default_digest_nid(pubk, &dgst_nid);\n        if (dgst_nid == NID_id_GostR3411_2012_512)\n            dgst_nid = NID_id_GostR3411_2012_256;\n\n        if (!VKO_compute_key(shared_key,\n                             EC_KEY_get0_public_key(EVP_PKEY_get0(pubk)),\n                             EVP_PKEY_get0(sec_key), ukm, 8, dgst_nid)) {\n            GOSTerr(GOST_F_PKEY_GOST_ECCP_ENCRYPT,\n                    GOST_R_ERROR_COMPUTING_SHARED_KEY);\n            goto err;\n        }\n        gost_init(&cctx, param->sblock);\n        keyWrapCryptoPro(&cctx, shared_key, ukm, key, crypted_key);\n    }\n    gkt = GOST_KEY_TRANSPORT_new();\n    if (!gkt) {\n        goto err;\n    }\n    if (!ASN1_OCTET_STRING_set(gkt->key_agreement_info->eph_iv, ukm, 8)) {\n        goto err;\n    }\n    if (!ASN1_OCTET_STRING_set(gkt->key_info->imit, crypted_key + 40, 4)) {\n        goto err;\n    }\n    if (!ASN1_OCTET_STRING_set\n        (gkt->key_info->encrypted_key, crypted_key + 8, 32)) {\n        goto err;\n    }\n    if (key_is_ephemeral) {\n        if (!X509_PUBKEY_set\n            (&gkt->key_agreement_info->ephem_key, out ? sec_key : pubk)) {\n            GOSTerr(GOST_F_PKEY_GOST_ECCP_ENCRYPT,\n                    GOST_R_CANNOT_PACK_EPHEMERAL_KEY);\n            goto err;\n        }\n    }\n    ASN1_OBJECT_free(gkt->key_agreement_info->cipher);\n    gkt->key_agreement_info->cipher = OBJ_nid2obj(param->nid);\n    if (key_is_ephemeral)\n        EVP_PKEY_free(sec_key);\n    if (!key_is_ephemeral) {\n        /* Set control \"public key from client certificate used\" */\n        if (EVP_PKEY_CTX_ctrl(pctx, -1, -1, EVP_PKEY_CTRL_PEER_KEY, 3, NULL)\n            <= 0) {\n            GOSTerr(GOST_F_PKEY_GOST_ECCP_ENCRYPT, GOST_R_CTRL_CALL_FAILED);\n            goto err;\n        }\n    }\n    if ((*out_len = i2d_GOST_KEY_TRANSPORT(gkt, out ? &out : NULL)) > 0)\n        ret = 1;\n    OPENSSL_cleanse(shared_key, sizeof(shared_key));\n    GOST_KEY_TRANSPORT_free(gkt);\n    return ret;\n err:\n    OPENSSL_cleanse(shared_key, sizeof(shared_key));\n    if (key_is_ephemeral)\n        EVP_PKEY_free(sec_key);\n    GOST_KEY_TRANSPORT_free(gkt);\n    return -1;\n}",
        "func_hash": 89031298057192357207711119163171237832,
        "file_name": "gost_ec_keyx.c",
        "file_hash": 151021593107318778140165694464640459536,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2022-29242",
        "cve_desc": "GOST engine is a reference implementation of the Russian GOST crypto algorithms for OpenSSL. TLS clients using GOST engine when ciphersuite `TLS_GOSTR341112_256_WITH_KUZNYECHIK_CTR_OMAC` is agreed and the server uses 512 bit GOST secret keys are vulnerable to buffer overflow. GOST engine version 3.0.1 contains a patch for this issue. Disabling ciphersuite `TLS_GOSTR341112_256_WITH_KUZNYECHIK_CTR_OMAC` is a possible workaround.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-29242",
        "func_name": "pkey_GOST_ECcp_encrypt",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 198556,
        "project": "mruby",
        "commit_id": "da48e7dbb20024c198493b8724adae1b842083aa",
        "project_url": "https://github.com/mruby/mruby",
        "commit_url": "https://github.com/mruby/mruby/commit/da48e7dbb20024c198493b8724adae1b842083aa",
        "commit_message": "fiber.c: should pack 15+ arguments in an array.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "fiber_switch(mrb_state *mrb, mrb_value self, mrb_int len, const mrb_value *a, mrb_bool resume, mrb_bool vmexec)\n{\n  struct mrb_context *c = fiber_check(mrb, self);\n  struct mrb_context *old_c = mrb->c;\n  enum mrb_fiber_state status;\n  mrb_value value;\n\n  fiber_check_cfunc(mrb, c);\n  status = c->status;\n  switch (status) {\n  case MRB_FIBER_TRANSFERRED:\n    if (resume) {\n      mrb_raise(mrb, E_FIBER_ERROR, \"resuming transferred fiber\");\n    }\n    break;\n  case MRB_FIBER_RUNNING:\n  case MRB_FIBER_RESUMED:\n    mrb_raise(mrb, E_FIBER_ERROR, \"double resume\");\n    break;\n  case MRB_FIBER_TERMINATED:\n    mrb_raise(mrb, E_FIBER_ERROR, \"resuming dead fiber\");\n    break;\n  default:\n    break;\n  }\n  old_c->status = resume ? MRB_FIBER_RESUMED : MRB_FIBER_TRANSFERRED;\n  c->prev = resume ? mrb->c : (c->prev ? c->prev : mrb->root_c);\n  fiber_switch_context(mrb, c);\n  if (status == MRB_FIBER_CREATED) {\n    mrb_value *b, *e;\n\n    if (!c->ci->proc) {\n      mrb_raise(mrb, E_FIBER_ERROR, \"double resume (current)\");\n    }\n    mrb_stack_extend(mrb, len+2); /* for receiver and (optional) block */\n    b = c->stbase+1;\n    e = b + len;\n    while (b<e) {\n      *b++ = *a++;\n    }\n    if (vmexec) {\n      c->ci--;                    /* pop dummy callinfo */\n    }\n    c->cibase->n = len;\n    value = c->stbase[0] = MRB_PROC_ENV(c->cibase->proc)->stack[0];\n  }\n  else {\n    value = fiber_result(mrb, a, len);\n    if (vmexec) {\n      c->ci[1].stack[0] = value;\n    }\n  }\n\n  if (vmexec) {\n    c->vmexec = TRUE;\n    value = mrb_vm_exec(mrb, c->ci->proc, c->ci->pc);\n    mrb->c = old_c;\n  }\n  else {\n    MARK_CONTEXT_MODIFY(c);\n  }\n  return value;\n}",
        "func_hash": 47008074931842386485122959067604053158,
        "file_name": "fiber.c",
        "file_hash": 246157146670999327331490014943475085458,
        "cwe": [
            "CWE-703"
        ],
        "cve": "CVE-2022-0890",
        "cve_desc": "NULL Pointer Dereference in GitHub repository mruby/mruby prior to 3.2.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-0890",
        "func_name": "fiber_switch",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 198566,
        "project": "libmobi",
        "commit_id": "eafc415bc6067e72577f70d6dd5acbf057ce6e6f",
        "project_url": "https://github.com/bfabiszewski/libmobi",
        "commit_url": "https://github.com/bfabiszewski/libmobi/commit/eafc415bc6067e72577f70d6dd5acbf057ce6e6f",
        "commit_message": "Fix wrong boundary checks in inflections parser resulting in stack buffer over-read with corrupt input",
        "target": 1,
        "irrelevant": 1,
        "func_before": "MOBI_RET mobi_decode_infl(unsigned char *decoded, int *decoded_size, const unsigned char *rule) {\n    int pos = *decoded_size;\n    char mod = 'i';\n    char dir = '<';\n    char olddir;\n    unsigned char c;\n    while ((c = *rule++)) {\n        if (c <= 4) {\n            mod = (c <= 2) ? 'i' : 'd'; /* insert, delete */\n            olddir = dir;\n            dir = (c & 2) ? '<' : '>'; /* left, right */\n            if (olddir != dir && olddir) {\n                pos = (c & 2) ? *decoded_size : 0;\n            }\n        }\n        else if (c > 10 && c < 20) {\n            if (dir == '>') {\n                pos = *decoded_size;\n            }\n            pos -= c - 10;\n            dir = 0;\n            if (pos < 0 || pos > *decoded_size) {\n                debug_print(\"Position setting failed (%s)\\n\", decoded);\n                return MOBI_DATA_CORRUPT;\n            }\n        }\n        else {\n            if (mod == 'i') {\n                const unsigned char *s = decoded + pos;\n                unsigned char *d = decoded + pos + 1;\n                const int l = *decoded_size - pos;\n                if (l < 0 || d + l > decoded + INDX_INFLBUF_SIZEMAX) {\n                    debug_print(\"Out of buffer in %s at pos: %i\\n\", decoded, pos);\n                    return MOBI_DATA_CORRUPT;\n                }\n                memmove(d, s, (size_t) l);\n                decoded[pos] = c;\n                (*decoded_size)++;\n                if (dir == '>') { pos++; }\n            } else {\n                if (dir == '<') { pos--; }\n                const unsigned char *s = decoded + pos + 1;\n                unsigned char *d = decoded + pos;\n                const int l = *decoded_size - pos;\n                if (l < 0 || d + l > decoded + INDX_INFLBUF_SIZEMAX) {\n                    debug_print(\"Out of buffer in %s at pos: %i\\n\", decoded, pos);\n                    return MOBI_DATA_CORRUPT;\n                }\n                if (decoded[pos] != c) {\n                    debug_print(\"Character mismatch in %s at pos: %i (%c != %c)\\n\", decoded, pos, decoded[pos], c);\n                    return MOBI_DATA_CORRUPT;\n                }\n                memmove(d, s, (size_t) l);\n                (*decoded_size)--;\n            }\n        }\n    }\n    return MOBI_SUCCESS;\n}",
        "func_hash": 38529228609046084805262566640890540140,
        "file_name": "index.c",
        "file_hash": 309095437889005741044332361577356993393,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2022-1533",
        "cve_desc": "Buffer Over-read in GitHub repository bfabiszewski/libmobi prior to 0.11. This vulnerability is capable of arbitrary code execution.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-1533",
        "func_name": "mobi_decode_infl",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 198588,
        "project": "vim",
        "commit_id": "0e8e938d497260dd57be67b4966cb27a5f72376f",
        "project_url": "https://github.com/vim/vim",
        "commit_url": "https://github.com/vim/vim/commit/0e8e938d497260dd57be67b4966cb27a5f72376f",
        "commit_message": "patch 8.2.5122: lisp indenting my run over the end of the line\n\nProblem:    Lisp indenting my run over the end of the line.\nSolution:   Check for NUL earlier.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "get_lisp_indent(void)\n{\n    pos_T\t*pos, realpos, paren;\n    int\t\tamount;\n    char_u\t*that;\n    colnr_T\tcol;\n    colnr_T\tfirsttry;\n    int\t\tparencount, quotecount;\n    int\t\tvi_lisp;\n\n    // Set vi_lisp to use the vi-compatible method\n    vi_lisp = (vim_strchr(p_cpo, CPO_LISP) != NULL);\n\n    realpos = curwin->w_cursor;\n    curwin->w_cursor.col = 0;\n\n    if ((pos = findmatch(NULL, '(')) == NULL)\n\tpos = findmatch(NULL, '[');\n    else\n    {\n\tparen = *pos;\n\tpos = findmatch(NULL, '[');\n\tif (pos == NULL || LT_POSP(pos, &paren))\n\t    pos = &paren;\n    }\n    if (pos != NULL)\n    {\n\t// Extra trick: Take the indent of the first previous non-white\n\t// line that is at the same () level.\n\tamount = -1;\n\tparencount = 0;\n\n\twhile (--curwin->w_cursor.lnum >= pos->lnum)\n\t{\n\t    if (linewhite(curwin->w_cursor.lnum))\n\t\tcontinue;\n\t    for (that = ml_get_curline(); *that != NUL; ++that)\n\t    {\n\t\tif (*that == ';')\n\t\t{\n\t\t    while (*(that + 1) != NUL)\n\t\t\t++that;\n\t\t    continue;\n\t\t}\n\t\tif (*that == '\\\\')\n\t\t{\n\t\t    if (*(that + 1) != NUL)\n\t\t\t++that;\n\t\t    continue;\n\t\t}\n\t\tif (*that == '\"' && *(that + 1) != NUL)\n\t\t{\n\t\t    while (*++that && *that != '\"')\n\t\t    {\n\t\t\t// skipping escaped characters in the string\n\t\t\tif (*that == '\\\\')\n\t\t\t{\n\t\t\t    if (*++that == NUL)\n\t\t\t\tbreak;\n\t\t\t    if (that[1] == NUL)\n\t\t\t    {\n\t\t\t\t++that;\n\t\t\t\tbreak;\n\t\t\t    }\n\t\t\t}\n\t\t    }\n\t\t}\n\t\tif (*that == '(' || *that == '[')\n\t\t    ++parencount;\n\t\telse if (*that == ')' || *that == ']')\n\t\t    --parencount;\n\t    }\n\t    if (parencount == 0)\n\t    {\n\t\tamount = get_indent();\n\t\tbreak;\n\t    }\n\t}\n\n\tif (amount == -1)\n\t{\n\t    curwin->w_cursor.lnum = pos->lnum;\n\t    curwin->w_cursor.col = pos->col;\n\t    col = pos->col;\n\n\t    that = ml_get_curline();\n\n\t    if (vi_lisp && get_indent() == 0)\n\t\tamount = 2;\n\t    else\n\t    {\n\t\tchar_u *line = that;\n\n\t\tamount = 0;\n\t\twhile (*that && col)\n\t\t{\n\t\t    amount += lbr_chartabsize_adv(line, &that, (colnr_T)amount);\n\t\t    col--;\n\t\t}\n\n\t\t// Some keywords require \"body\" indenting rules (the\n\t\t// non-standard-lisp ones are Scheme special forms):\n\t\t//\n\t\t// (let ((a 1))    instead    (let ((a 1))\n\t\t//   (...))\t      of\t   (...))\n\n\t\tif (!vi_lisp && (*that == '(' || *that == '[')\n\t\t\t\t\t\t      && lisp_match(that + 1))\n\t\t    amount += 2;\n\t\telse\n\t\t{\n\t\t    that++;\n\t\t    amount++;\n\t\t    firsttry = amount;\n\n\t\t    while (VIM_ISWHITE(*that))\n\t\t    {\n\t\t\tamount += lbr_chartabsize(line, that, (colnr_T)amount);\n\t\t\t++that;\n\t\t    }\n\n\t\t    if (*that && *that != ';') // not a comment line\n\t\t    {\n\t\t\t// test *that != '(' to accommodate first let/do\n\t\t\t// argument if it is more than one line\n\t\t\tif (!vi_lisp && *that != '(' && *that != '[')\n\t\t\t    firsttry++;\n\n\t\t\tparencount = 0;\n\t\t\tquotecount = 0;\n\n\t\t\tif (vi_lisp\n\t\t\t\t|| (*that != '\"'\n\t\t\t\t    && *that != '\\''\n\t\t\t\t    && *that != '#'\n\t\t\t\t    && (*that < '0' || *that > '9')))\n\t\t\t{\n\t\t\t    while (*that\n\t\t\t\t    && (!VIM_ISWHITE(*that)\n\t\t\t\t\t|| quotecount\n\t\t\t\t\t|| parencount)\n\t\t\t\t    && (!((*that == '(' || *that == '[')\n\t\t\t\t\t    && !quotecount\n\t\t\t\t\t    && !parencount\n\t\t\t\t\t    && vi_lisp)))\n\t\t\t    {\n\t\t\t\tif (*that == '\"')\n\t\t\t\t    quotecount = !quotecount;\n\t\t\t\tif ((*that == '(' || *that == '[')\n\t\t\t\t\t\t\t       && !quotecount)\n\t\t\t\t    ++parencount;\n\t\t\t\tif ((*that == ')' || *that == ']')\n\t\t\t\t\t\t\t       && !quotecount)\n\t\t\t\t    --parencount;\n\t\t\t\tif (*that == '\\\\' && *(that+1) != NUL)\n\t\t\t\t    amount += lbr_chartabsize_adv(\n\t\t\t\t\t\tline, &that, (colnr_T)amount);\n\t\t\t\tamount += lbr_chartabsize_adv(\n\t\t\t\t\t\tline, &that, (colnr_T)amount);\n\t\t\t    }\n\t\t\t}\n\t\t\twhile (VIM_ISWHITE(*that))\n\t\t\t{\n\t\t\t    amount += lbr_chartabsize(\n\t\t\t\t\t\t line, that, (colnr_T)amount);\n\t\t\t    that++;\n\t\t\t}\n\t\t\tif (!*that || *that == ';')\n\t\t\t    amount = firsttry;\n\t\t    }\n\t\t}\n\t    }\n\t}\n    }\n    else\n\tamount = 0;\t// no matching '(' or '[' found, use zero indent\n\n    curwin->w_cursor = realpos;\n\n    return amount;\n}",
        "func_hash": 267243770561266702154763100814181771713,
        "file_name": "indent.c",
        "file_hash": 46571564835107155022160222786721867171,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2022-2125",
        "cve_desc": "Heap-based Buffer Overflow in GitHub repository vim/vim prior to 8.2.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-2125",
        "func_name": "get_lisp_indent",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 198662,
        "project": "vim",
        "commit_id": "dc5490e2cbc8c16022a23b449b48c1bd0083f366",
        "project_url": "https://github.com/vim/vim",
        "commit_url": "https://github.com/vim/vim/commit/dc5490e2cbc8c16022a23b449b48c1bd0083f366",
        "commit_message": "patch 8.2.4215: illegal memory access when copying lines in Visual mode\n\nProblem:    Illegal memory access when copying lines in Visual mode.\nSolution:   Adjust the Visual position after copying lines.",
        "target": 1,
        "irrelevant": 0,
        "func_before": "ex_copy(linenr_T line1, linenr_T line2, linenr_T n)\n{\n    linenr_T\tcount;\n    char_u\t*p;\n\n    count = line2 - line1 + 1;\n    if ((cmdmod.cmod_flags & CMOD_LOCKMARKS) == 0)\n    {\n\tcurbuf->b_op_start.lnum = n + 1;\n\tcurbuf->b_op_end.lnum = n + count;\n\tcurbuf->b_op_start.col = curbuf->b_op_end.col = 0;\n    }\n\n    /*\n     * there are three situations:\n     * 1. destination is above line1\n     * 2. destination is between line1 and line2\n     * 3. destination is below line2\n     *\n     * n = destination (when starting)\n     * curwin->w_cursor.lnum = destination (while copying)\n     * line1 = start of source (while copying)\n     * line2 = end of source (while copying)\n     */\n    if (u_save(n, n + 1) == FAIL)\n\treturn;\n\n    curwin->w_cursor.lnum = n;\n    while (line1 <= line2)\n    {\n\t// need to use vim_strsave() because the line will be unlocked within\n\t// ml_append()\n\tp = vim_strsave(ml_get(line1));\n\tif (p != NULL)\n\t{\n\t    ml_append(curwin->w_cursor.lnum, p, (colnr_T)0, FALSE);\n\t    vim_free(p);\n\t}\n\t// situation 2: skip already copied lines\n\tif (line1 == n)\n\t    line1 = curwin->w_cursor.lnum;\n\t++line1;\n\tif (curwin->w_cursor.lnum < line1)\n\t    ++line1;\n\tif (curwin->w_cursor.lnum < line2)\n\t    ++line2;\n\t++curwin->w_cursor.lnum;\n    }\n\n    appended_lines_mark(n, count);\n\n    msgmore((long)count);\n}",
        "func_hash": 97186272074546929960699343746519426256,
        "file_name": "ex_cmds.c",
        "file_hash": 233687213068218474878856624724146444666,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2022-0361",
        "cve_desc": "Heap-based Buffer Overflow in GitHub repository vim/vim prior to 8.2.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-0361",
        "func_name": "ex_copy",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 198692,
        "project": "ipsec",
        "commit_id": "7bab09631c2a303f87a7eb7e3d69e888673b9b7e",
        "project_url": "https://git.kernel.org/pub/scm/linux/kernel/git/klassert/ipsec",
        "commit_url": "https://git.kernel.org/pub/scm/linux/kernel/git/klassert/ipsec.git/commit/?id=7bab09631c2a303f87a7eb7e3d69e888673b9b7e",
        "commit_message": "xfrm: policy: check policy direction value\n\nThe 'dir' parameter in xfrm_migrate() is a user-controlled byte which is used\nas an array index. This can lead to an out-of-bound access, kernel lockup and\nDoS. Add a check for the 'dir' value.\n\nThis fixes CVE-2017-11600.\n\nReferences: https://bugzilla.redhat.com/show_bug.cgi?id=1474928\nFixes: 80c9abaabf42 (\"[XFRM]: Extension for dynamic update of endpoint address(es)\")\nCc: <stable@vger.kernel.org> # v2.6.21-rc1\nReported-by: \"bo Zhang\" <zhangbo5891001@gmail.com>\nSigned-off-by: Vladis Dronov <vdronov@redhat.com>\nSigned-off-by: Steffen Klassert <steffen.klassert@secunet.com>",
        "target": 1,
        "irrelevant": 0,
        "func_before": "int xfrm_migrate(const struct xfrm_selector *sel, u8 dir, u8 type,\n\t\t struct xfrm_migrate *m, int num_migrate,\n\t\t struct xfrm_kmaddress *k, struct net *net,\n\t\t struct xfrm_encap_tmpl *encap)\n{\n\tint i, err, nx_cur = 0, nx_new = 0;\n\tstruct xfrm_policy *pol = NULL;\n\tstruct xfrm_state *x, *xc;\n\tstruct xfrm_state *x_cur[XFRM_MAX_DEPTH];\n\tstruct xfrm_state *x_new[XFRM_MAX_DEPTH];\n\tstruct xfrm_migrate *mp;\n\n\tif ((err = xfrm_migrate_check(m, num_migrate)) < 0)\n\t\tgoto out;\n\n\t/* Stage 1 - find policy */\n\tif ((pol = xfrm_migrate_policy_find(sel, dir, type, net)) == NULL) {\n\t\terr = -ENOENT;\n\t\tgoto out;\n\t}\n\n\t/* Stage 2 - find and update state(s) */\n\tfor (i = 0, mp = m; i < num_migrate; i++, mp++) {\n\t\tif ((x = xfrm_migrate_state_find(mp, net))) {\n\t\t\tx_cur[nx_cur] = x;\n\t\t\tnx_cur++;\n\t\t\txc = xfrm_state_migrate(x, mp, encap);\n\t\t\tif (xc) {\n\t\t\t\tx_new[nx_new] = xc;\n\t\t\t\tnx_new++;\n\t\t\t} else {\n\t\t\t\terr = -ENODATA;\n\t\t\t\tgoto restore_state;\n\t\t\t}\n\t\t}\n\t}\n\n\t/* Stage 3 - update policy */\n\tif ((err = xfrm_policy_migrate(pol, m, num_migrate)) < 0)\n\t\tgoto restore_state;\n\n\t/* Stage 4 - delete old state(s) */\n\tif (nx_cur) {\n\t\txfrm_states_put(x_cur, nx_cur);\n\t\txfrm_states_delete(x_cur, nx_cur);\n\t}\n\n\t/* Stage 5 - announce */\n\tkm_migrate(sel, dir, type, m, num_migrate, k, encap);\n\n\txfrm_pol_put(pol);\n\n\treturn 0;\nout:\n\treturn err;\n\nrestore_state:\n\tif (pol)\n\t\txfrm_pol_put(pol);\n\tif (nx_cur)\n\t\txfrm_states_put(x_cur, nx_cur);\n\tif (nx_new)\n\t\txfrm_states_delete(x_new, nx_new);\n\n\treturn err;\n}",
        "func_hash": 263415810499121443569228863944466057298,
        "file_name": "xfrm_policy.c",
        "file_hash": 279839085612343169676292983391622616816,
        "cwe": [
            "CWE-125"
        ],
        "cve": "CVE-2017-11600",
        "cve_desc": "net/xfrm/xfrm_policy.c in the Linux kernel through 4.12.3, when CONFIG_XFRM_MIGRATE is enabled, does not ensure that the dir value of xfrm_userpolicy_id is XFRM_POLICY_MAX or less, which allows local users to cause a denial of service (out-of-bounds access) or possibly have unspecified other impact via an XFRM_MSG_MIGRATE xfrm Netlink message.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2017-11600",
        "func_name": "xfrm_migrate",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 198695,
        "project": "MilkyTracker",
        "commit_id": "fd607a3439fcdd0992e5efded3c16fc79c804e34",
        "project_url": "https://github.com/milkytracker/MilkyTracker",
        "commit_url": "https://github.com/milkytracker/MilkyTracker/commit/fd607a3439fcdd0992e5efded3c16fc79c804e34",
        "commit_message": "Fix #184: Heap overflow in S3M loader",
        "target": 1,
        "irrelevant": 1,
        "func_before": "mp_sint32 LoaderS3M::load(XMFileBase& f, XModule* module)\n{\t\n\tmodule->cleanUp();\n\n\t// this will make code much easier to read\n\tTXMHeader*\t\theader = &module->header;\n\tTXMInstrument*\tinstr  = module->instr;\n\tTXMSample*\t\tsmp\t   = module->smp;\n\tTXMPattern*\t\tphead  = module->phead;\t\n\n\t// we're already out of memory here\n\tif (!phead || !instr || !smp)\n\t\treturn MP_OUT_OF_MEMORY;\n\t\n\tf.read(&header->name,1,28);\n\theader->whythis1a = f.readByte();\n\t\n\tif (f.readByte() != 16) \n\t\treturn MP_LOADER_FAILED;\t// no ST3 module\n\t\n\tf.readByte(); // skip something\n\tf.readByte(); // skip something\n\t\n\theader->ordnum = f.readWord(); // number of positions in order list (songlength)\n\t\n\tmp_ubyte* orders = new mp_ubyte[header->ordnum];\n\tif (orders == NULL) \n\t\treturn MP_OUT_OF_MEMORY;\n\t\n\theader->insnum = f.readWord(); // number of instruments\n\theader->patnum = f.readWord(); // number of patterns\t\n\t\n\tmp_sint32 flags = f.readWord(); // st3 flags\t\n\n\tmp_sint32 Cvt = f.readWord();\n\n\theader->flags = XModule::MODULE_ST3NEWINSTRUMENT | XModule::MODULE_ST3DUALCOMMANDS;\n\n\tif (Cvt == 0x1300 || (flags & 64))\n\t\theader->flags |= module->MODULE_OLDS3MVOLSLIDES;\n\t\t\n\theader->flags |= module->MODULE_ST3NOTECUT;\n\t\n\t/*mp_uword Ffi = */f.readWord();\n\t\n\tf.read(header->sig,1,4);\n\t\n\theader->mainvol = module->vol64to255(f.readByte()); // initial main volume\n\t\n\theader->tempo = f.readByte(); // tempo\n\t\n\theader->speed = f.readByte(); // speed\n\t\n\tf.readByte(); // global volume? skipped...\n\t\n\tf.readByte(); // ignore GUS click removal\n\t\n\t/*mp_ubyte dp = */f.readByte();\n\t\n\tf.readDword();\t// skip something\n\tf.readDword();\t// skip something\n\tf.readWord();\t// skip some more...\n\t\n\tmp_ubyte channelSettings[32];\n\tf.read(channelSettings,1,32);\n\t\n\tmp_sint32 numChannels = 0;\n\t\n\tfor (numChannels = 0; numChannels < 32; numChannels++)\n\t\tif (channelSettings[numChannels] == 255)\n\t\t\tbreak;\n\t\n\theader->channum = numChannels; // number of channels\n\t\n\tf.read(orders,1,header->ordnum);\n\t\n\tmp_sint32 j = 0, i = 0;\n\tfor (i = 0; i < header->ordnum; i++)\n\t{\n\t\tif (orders[i] == 255) \n\t\t\tbreak;\n\t\t\n\t\theader->ord[j++] = orders[i];\t\t\n\t}\n\t\n\theader->ordnum = j; // final songlength\n\t\n\tdelete[] orders;\n\t\n\tmp_uword* insParaPtrs = new mp_uword[header->insnum];\n\t\n\tif (insParaPtrs == NULL)\n\t\treturn MP_OUT_OF_MEMORY;\n\t\n\tf.readWords(insParaPtrs,header->insnum);\n\t\n\tmp_uword* patParaPtrs = new mp_uword[header->patnum];\n\t\n\tif (patParaPtrs == NULL)\n\t{\n\t\tdelete[] insParaPtrs;\n\t\treturn MP_OUT_OF_MEMORY;\n\t}\n\t\n\tf.readWords(patParaPtrs,header->patnum);\n\t\n\t//for (i = 0; i < header->insnum; i++)\n\t//{\n\t//\tprintf(\"%x\\n\",insParaPtrs[i]*16);\n\t//}\n\t\t\n\t//////////////////////\n\t// read instruments //\n\t//////////////////////\n\tmp_uint32* samplePtrs = new mp_uint32[header->insnum];\n\tif (samplePtrs == NULL)\n\t{\n\t\tdelete[] insParaPtrs;\n\t\tdelete[] patParaPtrs;\n\t\treturn MP_OUT_OF_MEMORY;\n\t}\n\t\n\tmemset(samplePtrs,0,sizeof(mp_uint32)*header->insnum);\n\t\n\tmp_sint32 s = 0;\n\tfor (i = 0; i < header->insnum; i++)\n\t{\n\t\tmp_uint32 insOffs = insParaPtrs[i]*16;\n\n\t\tif (insOffs)\n\t\t{\n\t\t\tf.seekWithBaseOffset(insOffs);\n\t\t\n\t\t\t// We can only read that if it's a sample\n\t\t\tmp_ubyte type = f.readByte();\n\t\t\t\n\t\t\tif (type == 1)\n\t\t\t{\n\t\t\t\tf.read(smp[s].name,1,12);\t// read dos filename\n\t\t\n\t\t\t\tmp_ubyte bOffs = f.readByte();\n\t\t\t\tmp_uword wOffs = f.readWord();\n\t\t\t\t\n\t\t\t\t// stupid fileoffsets\n\t\t\t\tsamplePtrs[i] = (((mp_uint32)bOffs<<16)+(mp_uint32)wOffs)*16;\n\t\t\t\t\n\t\t\t\tsmp[s].flags = 1;\n\t\t\t\tsmp[s].pan = 0x80;\n\t\t\t\t\n\t\t\t\tsmp[s].samplen = f.readDword();\n\t\t\t\tsmp[s].loopstart = f.readDword();\n\t\t\t\tmp_sint32 looplen = ((mp_sint32)f.readDword() - (mp_sint32)smp[s].loopstart);\n\t\t\t\tif (looplen < 0) \n\t\t\t\t\tlooplen = 0;\n\t\t\t\tsmp[s].looplen = looplen;\n\t\t\t\t\n\t\t\t\tsmp[s].vol = module->vol64to255(f.readByte());\n\t\t\t\t\n\t\t\t\tf.readByte(); // skip something\n\t\t\t\t\n\t\t\t\tsmp[s].res = f.readByte() == 0x04 ? 0xAD : 0; // packing\n\t\t\t\t\n\t\t\t\tmp_ubyte flags = f.readByte();\n\t\t\t\t\n\t\t\t\t// looping\n\t\t\t\tif (flags & 1)\n\t\t\t\t{\n\t\t\t\t\tsmp[s].type = 1;\t\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\t// 16 bit sample\n\t\t\t\tif (flags & 4)\n\t\t\t\t{\n\t\t\t\t\tsmp[s].type |= 16;\n\t\t\t\t\tsmp[s].samplen >>= 1;\n\t\t\t\t\tsmp[s].loopstart >>= 1;\n\t\t\t\t\tsmp[s].looplen >>= 1;\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tmp_uint32 c4spd = f.readDword();\n\t\t\t\t\n\t\t\t\tXModule::convertc4spd(c4spd,&smp[s].finetune,&smp[s].relnote);\n\n#ifdef VERBOSE\n\t\t\t\tprintf(\"%i, %i\\n\",c4spd,module->getc4spd(smp[s].relnote,smp[s].finetune));\t\t\t\t\n#endif\n\n\t\t\t\tf.readDword(); // skip something\n\t\t\t\t\n\t\t\t\tf.readDword(); // skip two internal words\n\t\t\t\t\n\t\t\t\tf.readDword(); // skip internal dword\n\n\t\t\t\tf.read(instr[i].name,1,28); // instrument name\n\t\t\t\t\n\t\t\t\tf.readDword(); // skip signature\n\t\t\t\t\n\t\t\t\tif (samplePtrs[i] && smp[s].samplen)\n\t\t\t\t{\n\t\t\t\t\tinstr[i].samp=1;\n\t\t\t\t\tfor (j=0;j<120;j++) \n\t\t\t\t\t\tinstr[i].snum[j] = s;\n\t\t\t\t\ts++;\n\t\t\t\t}\n\t\t\t}\n\t\t\telse if (type == 0)\n\t\t\t{\n\t\t\t\tsamplePtrs[i] = 0;\n\t\t\t\n\t\t\t\tmp_ubyte buffer[12];\n\t\t\t\tf.read(buffer,1,12);\t// read dos filename\n\t\t\n\t\t\t\tf.readByte();\n\t\t\t\tf.readWord();\n\t\t\t\t\n\t\t\t\tf.readDword();\n\t\t\t\tf.readDword();\n\t\t\t\tf.readDword();\n\t\t\t\tf.readByte();\n\t\t\t\tf.readByte(); // skip something\n\t\t\t\tf.readByte(); // skip packing\n\t\t\t\t\n\t\t\t\tf.readByte();\n\t\t\t\t\n\t\t\t\tf.readDword();\n\t\t\t\t\n\t\t\t\tf.readDword(); // skip something\n\t\t\t\t\n\t\t\t\tf.readDword(); // skip two internal words\n\t\t\t\t\n\t\t\t\tf.readDword(); // skip internal dword\n\n\t\t\t\tf.read(instr[i].name,1,28); // instrument name\n\t\t\t\t\n\t\t\t\tf.readDword(); // skip signature\t\t\t\t\n\t\t\t}\n\t\t\telse \n\t\t\t{\n\t\t\t\tsamplePtrs[i] = 0;\n\t\t\t}\n\t\t\t\n\t\t}\n\n\t}\n\t\n\t//////////////////////\n\t// read patterns\t//\n\t//////////////////////\n\tmp_ubyte* pattern = new mp_ubyte[64*32*5];\n\tif (pattern == NULL)\n\t{\n\t\tdelete[] insParaPtrs;\n\t\tdelete[] patParaPtrs;\n\t\tdelete[] samplePtrs;\n\t\treturn MP_OUT_OF_MEMORY;\n\t}\n\t\n\tmp_uint32 songMaxChannels = 1;\n\t\n\tfor (i = 0; i < header->patnum; i++)\n\t{\n\t\tfor (j = 0; j < 32*64; j++)\n\t\t{\n\t\t\tpattern[j*5] = 0xFF;\n\t\t\tpattern[j*5+1] = 0;\n\t\t\tpattern[j*5+2] = 0xFF;\n\t\t\tpattern[j*5+3] = 0xFF;\n\t\t\tpattern[j*5+4] = 0;\n\t\t}\n\t\t\n\t\tmp_uint32 patOffs = patParaPtrs[i]*16;\n\t\t\n\t\tmp_uint32 maxChannels = 1;\t\t\t\n\t\t\n\t\tif (patOffs)\n\t\t{\n\t\t\tf.seekWithBaseOffset(patOffs);\n\t\t\t\n\t\t\tmp_uint32 size = f.readWord();\n\t\t\t\n\t\t\tif (size > 2)\n\t\t\t{\n\t\t\t\tsize-=2;\n\t\t\t\t\n\t\t\t\tmp_ubyte* packed = new mp_ubyte[size+5];\n\t\t\t\tif (packed == NULL)\n\t\t\t\t{\n\t\t\t\t\tdelete[] insParaPtrs;\n\t\t\t\t\tdelete[] patParaPtrs;\n\t\t\t\t\tdelete[] samplePtrs;\n\t\t\t\t\tdelete[] pattern;\n\t\t\t\t\treturn MP_OUT_OF_MEMORY;\t\t\t\t\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tmemset(packed, 0, size);\n\t\t\t\tf.read(packed, 1, size);\n\t\t\t\t\n\t\t\t\tmp_uint32 index = 0;\n\t\t\t\tmp_uint32 row = 0;\n\t\t\t\t\n\t\t\t\twhile (index<size)\n\t\t\t\t{\n\t\t\t\t\t\n\t\t\t\t\tmp_ubyte pi = safeRead(packed, index, size);\n\t\t\t\t\t\n\t\t\t\t\tif (pi == 0) \n\t\t\t\t\t{\n\t\t\t\t\t\trow++;\n\t\t\t\t\t\t// one more safety net for incorrectly saved pattern sizes\n\t\t\t\t\t\tif (row >= 64)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tint i = 0;\n\t\t\t\t\t\t\ti++;\n\t\t\t\t\t\t\ti--;\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t\t\n\t\t\t\t\tmp_uint32 chn = pi&31;\n\t\t\t\t\t\n\t\t\t\t\tif (chn>maxChannels && (pi & (32+64+128)))\n\t\t\t\t\t{\n\t\t\t\t\t\tmaxChannels = chn;\n\t\t\t\t\t}\n\t\t\t\t\t\n\t\t\t\t\tmp_ubyte* slot = pattern+(row*32*5)+chn*5;\n\t\t\t\t\t\n\t\t\t\t\tif (pi & 32)\n\t\t\t\t\t{\n\t\t\t\t\t\tslot[0] = safeRead(packed, index, size, 0xFF);\n\t\t\t\t\t\tslot[1] = safeRead(packed, index, size);\n\t\t\t\t\t}\n\t\t\t\t\tif (pi & 64)\n\t\t\t\t\t{\n\t\t\t\t\t\tslot[2] = safeRead(packed, index, size, 0xFF);\n\t\t\t\t\t}\n\t\t\t\t\tif (pi & 128)\n\t\t\t\t\t{\n\t\t\t\t\t\tslot[3] = safeRead(packed, index, size, 0xFF);\n\t\t\t\t\t\tslot[4] = safeRead(packed, index, size);\n\t\t\t\t\t}\n\t\t\t\t\t\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tmaxChannels++;\n\t\t\t\t\n\t\t\t\tif (maxChannels > header->channum)\n\t\t\t\t\tmaxChannels = header->channum;\n\t\t\t\t\n\t\t\t\tdelete[] packed;\n\t\t\t}\n\t\t\t\n\t\t\tif (maxChannels > songMaxChannels)\n\t\t\t\tsongMaxChannels = maxChannels;\n\t\t\t\n\t\t}\n\t\t\n\t\tconvertS3MPattern(&phead[i], pattern, maxChannels, i);\n\t\t\n\t\t\n\t}\n\t\n\tif (header->channum > songMaxChannels)\n\t\theader->channum = songMaxChannels;\n\t\n\tdelete[] pattern;\n\tdelete[] insParaPtrs;\n\tdelete[] patParaPtrs;\n\t\n\ts = 0;\n\tfor (i = 0; i < header->insnum; i++)\n\t{\n\t\tmp_uint32 smpOffs = samplePtrs[i];\n\n\t\tif (smpOffs)\n\t\t{\n\t\t\tf.seekWithBaseOffset(smpOffs);\n\t\t\t\n\t\t\tif (!smp[s].samplen)\n\t\t\t\tcontinue;\n\n\t\t\tbool adpcm = (smp[s].res == 0xAD);\n\n\t\t\tmp_sint32 result = module->loadModuleSample(f, s, \n\t\t\t\t\t\t\t\t\t\t  adpcm ? XModule::ST_PACKING_ADPCM : XModule::ST_UNSIGNED, \n\t\t\t\t\t\t\t\t\t\t  adpcm ? (XModule::ST_16BIT | XModule::ST_PACKING_ADPCM) : (XModule::ST_16BIT | XModule::ST_UNSIGNED));\n\t\t\tif (result != MP_OK)\n\t\t\t{\n\t\t\t\tdelete[] samplePtrs;\n\t\t\t\treturn result;\n\t\t\t}\n\t\t\t\n\t\t\tif (adpcm)\n\t\t\t\t// no longer needed\n\t\t\t\tsmp[s].res = 0;\t\t\t\n\t\t\t\t\t\t\t\n\t\t\ts++;\n\t\t\t\n\t\t}\n\n\t}\n\t\n\tdelete[] samplePtrs;\n\t\n\theader->smpnum = s;\n\t\n\tstrcpy(header->tracker,\"Screamtracker 3\");\n\t\n\tmodule->setDefaultPanning();\n\t\n\tmodule->postProcessSamples();\n\t\n\treturn MP_OK;\t\n}",
        "func_hash": 83839366626583868665259951755341094581,
        "file_name": "LoaderS3M.cpp",
        "file_hash": 183144652101625968491560243513367539209,
        "cwe": [
            "CWE-787"
        ],
        "cve": "CVE-2019-14464",
        "cve_desc": "XMFile::read in XMFile.cpp in milkyplay in MilkyTracker 1.02.00 has a heap-based buffer overflow.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2019-14464",
        "func_name": "LoaderS3M::load",
        "diff": [],
        "func_after": []
    },
    {
        "idx": 198703,
        "project": "LibRaw",
        "commit_id": "4606c28f494a750892c5c1ac7903e62dd1c6fdb5",
        "project_url": "https://github.com/LibRaw/LibRaw",
        "commit_url": "https://github.com/LibRaw/LibRaw/commit/4606c28f494a750892c5c1ac7903e62dd1c6fdb5",
        "commit_message": "0.16.1: fix for dcraw ljpeg_start() vulnerability",
        "target": 1,
        "irrelevant": 0,
        "func_before": "int CLASS ljpeg_start (struct jhead *jh, int info_only)\n{\n  int c, tag, len;\n  uchar data[0x10000];\n  const uchar *dp;\n\n  memset (jh, 0, sizeof *jh);\n  jh->restart = INT_MAX;\n  fread (data, 2, 1, ifp);\n  if (data[1] != 0xd8) return 0;\n  do {\n    fread (data, 2, 2, ifp);\n    tag =  data[0] << 8 | data[1];\n    len = (data[2] << 8 | data[3]) - 2;\n    if (tag <= 0xff00) return 0;\n    fread (data, 1, len, ifp);\n    switch (tag) {\n      case 0xffc3:\n\tjh->sraw = ((data[7] >> 4) * (data[7] & 15) - 1) & 3;\n      case 0xffc0:\n\tjh->bits = data[0];\n\tjh->high = data[1] << 8 | data[2];\n\tjh->wide = data[3] << 8 | data[4];\n\tjh->clrs = data[5] + jh->sraw;\n\tif (len == 9 && !dng_version) getc(ifp);\n\tbreak;\n      case 0xffc4:\n\tif (info_only) break;\n\tfor (dp = data; dp < data+len && (c = *dp++) < 4; )\n\t  jh->free[c] = jh->huff[c] = make_decoder_ref (&dp);\n\tbreak;\n      case 0xffda:\n\tjh->psv = data[1+data[0]*2];\n\tjh->bits -= data[3+data[0]*2] & 15;\n\tbreak;\n      case 0xffdd:\n\tjh->restart = data[0] << 8 | data[1];\n    }\n  } while (tag != 0xffda);\n  if (info_only) return 1;\n  if (jh->clrs > 6 || !jh->huff[0]) return 0;\n  FORC(5) if (!jh->huff[c+1]) jh->huff[c+1] = jh->huff[c];\n  if (jh->sraw) {\n    FORC(4)        jh->huff[2+c] = jh->huff[1];\n    FORC(jh->sraw) jh->huff[1+c] = jh->huff[0];\n  }\n  jh->row = (ushort *) calloc (jh->wide*jh->clrs, 4);\n  merror (jh->row, \"ljpeg_start()\");\n  return zero_after_ff = 1;\n}",
        "func_hash": 130689334179908551360949370308005940309,
        "file_name": "dcraw.c",
        "file_hash": 16246307575535149063752681880088000458,
        "cwe": [
            "CWE-189"
        ],
        "cve": "CVE-2015-3885",
        "cve_desc": "Integer overflow in the ljpeg_start function in dcraw 7.00 and earlier allows remote attackers to cause a denial of service (crash) via a crafted image, which triggers a buffer overflow, related to the len variable.",
        "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2015-3885",
        "func_name": "ljpeg_start",
        "diff": [],
        "func_after": []
    }
]