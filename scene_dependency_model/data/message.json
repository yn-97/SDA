[
    {
        "commit_id": "d563131ef23cbc756026f839a82598c8445bc45f",
        "repo": "torvalds/linux",
        "msg": "rsi: release skb if rsi_prepare_beacon fails\n\nIn rsi_send_beacon, if rsi_prepare_beacon fails the allocated skb should\nbe released.\n\nSigned-off-by: Navid Emamdoost <navid.emamdoost@gmail.com>\nSigned-off-by: Kalle Valo <kvalo@codeaurora.org>A memory leak in the rsi_send_beacon() function in drivers/net/wireless/rsi/rsi_91x_mgmt.c in the Linux kernel through 5.3.11 allows attackers to cause a denial of service (memory consumption) by triggering rsi_prepare_beacon() failures, aka CID-d563131ef23c.",
        "filename": "rsi_91x_mgmt.c",
        "diff": "diff --git a/drivers/net/wireless/rsi/rsi_91x_mgmt.c b/drivers/net/wireless/rsi/rsi_91x_mgmt.c\nindex 6c7f26ef6476ae..9cc8a335d519da 100644\n--- a/drivers/net/wireless/rsi/rsi_91x_mgmt.c\n+++ b/drivers/net/wireless/rsi/rsi_91x_mgmt.c\n@@ -1756,6 +1756,7 @@ static int rsi_send_beacon(struct rsi_common *common)\n \t\tskb_pull(skb, (64 - dword_align_bytes));\n \tif (rsi_prepare_beacon(common, skb)) {\n \t\trsi_dbg(ERR_ZONE, \"Failed to prepare beacon\\n\");\n+\t\tdev_kfree_skb(skb);\n \t\treturn -EINVAL;\n \t}\n \tskb_queue_tail(&common->tx_queue[MGMT_BEACON_Q], skb);\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "53f82e6e2e858a0a62fd1a2ff47e9866693382e6",
        "repo": "LuaJIT/LuaJIT",
        "msg": "Fix frame traversal for __gc handler frames.\n\nReported by Changochen.LuaJit through 2.1.0-beta3 has an out-of-bounds read because __gc handler frame traversal is mishandled.",
        "filename": "lj_err.c",
        "diff": "diff --git a/src/lj_err.c b/src/lj_err.c\nindex caa7487f28..e3e0c2eb7e 100644\n--- a/src/lj_err.c\n+++ b/src/lj_err.c\n@@ -529,6 +529,7 @@ static ptrdiff_t finderrfunc(lua_State *L)\n       if (cframe_canyield(cf)) return 0;\n       if (cframe_errfunc(cf) >= 0)\n \treturn cframe_errfunc(cf);\n+      cf = cframe_prev(cf);\n       frame = frame_prevd(frame);\n       break;\n     case FRAME_PCALL:\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "0a557045476a2969c7079aec9eeb29d02f2809c6",
        "repo": "radare/radare2",
        "msg": "Fix oobread and unaligned casts in the NE entrypoint logic ##crash\n\n* Reported by @hmsec via huntr.dev\n* Reproducer: nepocaligns\n* BountyID: ec538fa4-06c6-4050-a141-f60153ddeaacOut-of-bounds Read in r_bin_ne_get_entrypoints function in GitHub repository radareorg/radare2 prior to 5.6.8. This vulnerability may allow attackers to read sensitive information or cause a crash.",
        "filename": "ne.c",
        "diff": "diff --git a/libr/bin/format/ne/ne.c b/libr/bin/format/ne/ne.c\nindex b907d56e93b17..32aa589e8b7d5 100644\n--- a/libr/bin/format/ne/ne.c\n+++ b/libr/bin/format/ne/ne.c\n@@ -408,14 +408,21 @@ RList *r_bin_ne_get_entrypoints(r_bin_ne_obj_t *bin) {\n \t\t\t\toff += 2;\n \t\t\t\tut8 segnum = *(bin->entry_table + off);\n \t\t\t\toff++;\n-\t\t\t\tut16 segoff = *(ut16 *)(bin->entry_table + off);\n-\t\t\t\tif (segnum > 0) {\n+\t\t\t\tif (off > bin->ne_header->EntryTableLength) {\n+\t\t\t\t\tbreak;\n+\t\t\t\t}\n+\t\t\t\tut16 segoff = r_read_le16 (bin->entry_table + off);\n+\t\t\t\tif (segnum > 0 && segnum < bin->ne_header->SegCount) {\n \t\t\t\t\tentry->paddr = (ut64)bin->segment_entries[segnum - 1].offset * bin->alignment + segoff;\n \t\t\t\t}\n \t\t\t} else { // Fixed\n+\t\t\t\tif (off + 2 >= bin->ne_header->EntryTableLength) {\n+\t\t\t\t\tbreak;\n+\t\t\t\t}\n+\t\t\t\tut16 delta = r_read_le16 (bin->entry_table + off);\n \t\t\t\tif (bundle_type < bin->ne_header->SegCount) {\n \t\t\t\t\tentry->paddr = (ut64)bin->segment_entries[bundle_type - 1].offset\n-\t\t\t\t\t\t* bin->alignment + *(ut16 *)(bin->entry_table + off);\n+\t\t\t\t\t\t* bin->alignment + delta;\n \t\t\t\t}\n \t\t\t}\n \t\t\toff += 2;\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "9f740868fc36761de27df3935513bdebf8852d19",
        "repo": "stefanberger/swtpm",
        "msg": "swtpm: Check header size indicator against expected size (CID 375869)\n\nThis fix addresses Coverity issue CID 375869.\n\nCheck the header size indicated in the header of the state against the\nexpected size and return an error code in case the header size indicator\nis different. There was only one header size so far since blobheader was\nintroduced, so we don't need to deal with different sizes.\n\nWithout this fix a specially craft header could have cause out-of-bounds\naccesses on the byte array containing the swtpm's state.\n\nSigned-off-by: Stefan Berger <stefanb@linux.ibm.com>swtpm is a libtpms-based TPM emulator with socket, character device, and Linux CUSE interface. Versions prior to 0.5.3, 0.6.2, and 0.7.1 are vulnerable to out-of-bounds read. A specially crafted header of swtpm's state, where the blobheader's hdrsize indicator has an invalid value, may cause an out-of-bounds access when the byte array representing the state of the TPM is accessed. This will likely crash swtpm or prevent it from starting since the state cannot be understood. Users should upgrade to swtpm v0.5.3, v0.6.2, or v0.7.1 to receive a patch. There are currently no known workarounds.",
        "filename": "swtpm_nvfile.c",
        "diff": "diff --git a/src/swtpm/swtpm_nvstore.c b/src/swtpm/swtpm_nvstore.c\nindex 437088370..144d8975e 100644\n--- a/src/swtpm/swtpm_nvstore.c\n+++ b/src/swtpm/swtpm_nvstore.c\n@@ -1075,6 +1075,7 @@ SWTPM_NVRAM_CheckHeader(unsigned char *data, uint32_t length,\n                         uint8_t *hdrversion, bool quiet)\n {\n     blobheader *bh = (blobheader *)data;\n+    uint16_t hdrsize;\n \n     if (length < sizeof(bh)) {\n         if (!quiet)\n@@ -1100,8 +1101,16 @@ SWTPM_NVRAM_CheckHeader(unsigned char *data, uint32_t length,\n         return TPM_BAD_VERSION;\n     }\n \n+    hdrsize = ntohs(bh->hdrsize);\n+    if (hdrsize != sizeof(blobheader)) {\n+        logprintf(STDERR_FILENO,\n+                  \"bad header size: %u != %zu\\n\",\n+                  hdrsize, sizeof(blobheader));\n+        return TPM_BAD_DATASIZE;\n+    }\n+\n     *hdrversion = bh->version;\n-    *dataoffset = ntohs(bh->hdrsize);\n+    *dataoffset = hdrsize;\n     *hdrflags = ntohs(bh->flags);\n \n     return TPM_SUCCESS;\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "8423f0b6d513b259fdab9c9bf4aaa6188d054c2d",
        "repo": "torvalds/linux",
        "msg": "ALSA: pcm: oss: Fix race at SNDCTL_DSP_SYNC\n\nThere is a small race window at snd_pcm_oss_sync() that is called from\nOSS PCM SNDCTL_DSP_SYNC ioctl; namely the function calls\nsnd_pcm_oss_make_ready() at first, then takes the params_lock mutex\nfor the rest.  When the stream is set up again by another thread\nbetween them, it leads to inconsistency, and may result in unexpected\nresults such as NULL dereference of OSS buffer as a fuzzer spotted\nrecently.\n\nThe fix is simply to cover snd_pcm_oss_make_ready() call into the same\nparams_lock mutex with snd_pcm_oss_make_ready_locked() variant.\n\nReported-and-tested-by: butt3rflyh4ck <butterflyhuangxx@gmail.com>\nReviewed-by: Jaroslav Kysela <perex@perex.cz>\nCc: <stable@vger.kernel.org>\nLink: https://lore.kernel.org/r/CAFcO6XN7JDM4xSXGhtusQfS2mSBcx50VJKwQpCq=WeLt57aaZA@mail.gmail.com\nLink: https://lore.kernel.org/r/20220905060714.22549-1-tiwai@suse.de\nSigned-off-by: Takashi Iwai <tiwai@suse.de>A race condition flaw was found in the Linux kernel sound subsystem due to improper locking. It could lead to a NULL pointer dereference while handling the SNDCTL_DSP_SYNC ioctl. A privileged local user (root or member of the audio group) could use this flaw to crash the system, resulting in a denial of service condition",
        "filename": "None",
        "diff": "diff --git a/sound/core/oss/pcm_oss.c b/sound/core/oss/pcm_oss.c\nindex 90c3a367d7de9a..02df915eb3c66a 100644\n--- a/sound/core/oss/pcm_oss.c\n+++ b/sound/core/oss/pcm_oss.c\n@@ -1672,14 +1672,14 @@ static int snd_pcm_oss_sync(struct snd_pcm_oss_file *pcm_oss_file)\n \t\truntime = substream->runtime;\n \t\tif (atomic_read(&substream->mmap_count))\n \t\t\tgoto __direct;\n-\t\terr = snd_pcm_oss_make_ready(substream);\n-\t\tif (err < 0)\n-\t\t\treturn err;\n \t\tatomic_inc(&runtime->oss.rw_ref);\n \t\tif (mutex_lock_interruptible(&runtime->oss.params_lock)) {\n \t\t\tatomic_dec(&runtime->oss.rw_ref);\n \t\t\treturn -ERESTARTSYS;\n \t\t}\n+\t\terr = snd_pcm_oss_make_ready_locked(substream);\n+\t\tif (err < 0)\n+\t\t\tgoto unlock;\n \t\tformat = snd_pcm_oss_format_from(runtime->oss.format);\n \t\twidth = snd_pcm_format_physical_width(format);\n \t\tif (runtime->oss.buffer_used > 0) {\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "233087ca063686964a53c829d547c7571e3f67bf",
        "repo": "torvalds/linux",
        "msg": "floppy: disable FDRAWCMD by default\n\nMinh Yuan reported a concurrency use-after-free issue in the floppy code\nbetween raw_cmd_ioctl and seek_interrupt.\n\n[ It turns out this has been around, and that others have reported the\n  KASAN splats over the years, but Minh Yuan had a reproducer for it and\n  so gets primary credit for reporting it for this fix   - Linus ]\n\nThe problem is, this driver tends to break very easily and nowadays,\nnobody is expected to use FDRAWCMD anyway since it was used to\nmanipulate non-standard formats.  The risk of breaking the driver is\nhigher than the risk presented by this race, and accessing the device\nrequires privileges anyway.\n\nLet's just add a config option to completely disable this ioctl and\nleave it disabled by default.  Distros shouldn't use it, and only those\nrunning on antique hardware might need to enable it.\n\nLink: https://lore.kernel.org/all/000000000000b71cdd05d703f6bf@google.com/\nLink: https://lore.kernel.org/lkml/CAKcFiNC=MfYVW-Jt9A3=FPJpTwCD2PL_ULNCpsCVE5s8ZeBQgQ@mail.gmail.com\nLink: https://lore.kernel.org/all/CAEAjamu1FRhz6StCe_55XY5s389ZP_xmCF69k987En+1z53=eg@mail.gmail.com\nReported-by: Minh Yuan <yuanmingbuaa@gmail.com>\nReported-by: syzbot+8e8958586909d62b6840@syzkaller.appspotmail.com\nReported-by: cruise k <cruise4k@gmail.com>\nReported-by: Kyungtae Kim <kt0755@gmail.com>\nSuggested-by: Linus Torvalds <torvalds@linuxfoundation.org>\nTested-by: Denis Efremov <efremov@linux.com>\nSigned-off-by: Willy Tarreau <w@1wt.eu>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>Rejected reason: DO NOT USE THIS CANDIDATE NUMBER. ConsultIDs: CVE-2022-33981. Reason: This candidate is a reservation duplicate of CVE-2022-33981. Notes: All CVE users should reference CVE-2022-33981 instead of this candidate. All references and descriptions in this candidate have been removed to prevent accidental usage",
        "filename": "floppy.c",
        "diff": "diff --git a/drivers/block/Kconfig b/drivers/block/Kconfig\nindex 519b6d38d4df65..fdb81f2794cde1 100644\n--- a/drivers/block/Kconfig\n+++ b/drivers/block/Kconfig\n@@ -33,6 +33,22 @@ config BLK_DEV_FD\n \t  To compile this driver as a module, choose M here: the\n \t  module will be called floppy.\n \n+config BLK_DEV_FD_RAWCMD\n+\tbool \"Support for raw floppy disk commands (DEPRECATED)\"\n+\tdepends on BLK_DEV_FD\n+\thelp\n+\t  If you want to use actual physical floppies and expect to do\n+\t  special low-level hardware accesses to them (access and use\n+\t  non-standard formats, for example), then enable this.\n+\n+\t  Note that the code enabled by this option is rarely used and\n+\t  might be unstable or insecure, and distros should not enable it.\n+\n+\t  Note: FDRAWCMD is deprecated and will be removed from the kernel\n+\t  in the near future.\n+\n+\t  If unsure, say N.\n+\n config AMIGA_FLOPPY\n \ttristate \"Amiga floppy support\"\n \tdepends on AMIGA\ndiff --git a/drivers/block/floppy.c b/drivers/block/floppy.c\nindex 8c647532e3ce99..d5b9ff9bcbb2b8 100644\n--- a/drivers/block/floppy.c\n+++ b/drivers/block/floppy.c\n@@ -2982,6 +2982,8 @@ static const char *drive_name(int type, int drive)\n \t\treturn \"(null)\";\n }\n \n+#ifdef CONFIG_BLK_DEV_FD_RAWCMD\n+\n /* raw commands */\n static void raw_cmd_done(int flag)\n {\n@@ -3181,6 +3183,35 @@ static int raw_cmd_ioctl(int cmd, void __user *param)\n \treturn ret;\n }\n \n+static int floppy_raw_cmd_ioctl(int type, int drive, int cmd,\n+\t\t\t\tvoid __user *param)\n+{\n+\tint ret;\n+\n+\tpr_warn_once(\"Note: FDRAWCMD is deprecated and will be removed from the kernel in the near future.\\n\");\n+\n+\tif (type)\n+\t\treturn -EINVAL;\n+\tif (lock_fdc(drive))\n+\t\treturn -EINTR;\n+\tset_floppy(drive);\n+\tret = raw_cmd_ioctl(cmd, param);\n+\tif (ret == -EINTR)\n+\t\treturn -EINTR;\n+\tprocess_fd_request();\n+\treturn ret;\n+}\n+\n+#else /* CONFIG_BLK_DEV_FD_RAWCMD */\n+\n+static int floppy_raw_cmd_ioctl(int type, int drive, int cmd,\n+\t\t\t\tvoid __user *param)\n+{\n+\treturn -EOPNOTSUPP;\n+}\n+\n+#endif\n+\n static int invalidate_drive(struct block_device *bdev)\n {\n \t/* invalidate the buffer track to force a reread */\n@@ -3369,7 +3400,6 @@ static int fd_locked_ioctl(struct block_device *bdev, fmode_t mode, unsigned int\n {\n \tint drive = (long)bdev->bd_disk->private_data;\n \tint type = ITYPE(drive_state[drive].fd_device);\n-\tint i;\n \tint ret;\n \tint size;\n \tunion inparam {\n@@ -3520,16 +3550,7 @@ static int fd_locked_ioctl(struct block_device *bdev, fmode_t mode, unsigned int\n \t\toutparam = &write_errors[drive];\n \t\tbreak;\n \tcase FDRAWCMD:\n-\t\tif (type)\n-\t\t\treturn -EINVAL;\n-\t\tif (lock_fdc(drive))\n-\t\t\treturn -EINTR;\n-\t\tset_floppy(drive);\n-\t\ti = raw_cmd_ioctl(cmd, (void __user *)param);\n-\t\tif (i == -EINTR)\n-\t\t\treturn -EINTR;\n-\t\tprocess_fd_request();\n-\t\treturn i;\n+\t\treturn floppy_raw_cmd_ioctl(type, drive, cmd, (void __user *)param);\n \tcase FDTWADDLE:\n \t\tif (lock_fdc(drive))\n \t\t\treturn -EINTR;\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "8700af2cc18c919b2a83e74e0479038fd113c15d",
        "repo": "torvalds/linux",
        "msg": "RDMA/rtrs-clt: Fix possible double free in error case\n\nCallback function rtrs_clt_dev_release() for put_device() calls kfree(clt)\nto free memory. We shouldn't call kfree(clt) again, and we can't use the\nclt after kfree too.\n\nReplace device_register() with device_initialize() and device_add() so that\ndev_set_name can() be used appropriately.\n\nMove mutex_destroy() to the release function so it can be called in\nthe alloc_clt err path.\n\nFixes: eab098246625 (\"RDMA/rtrs-clt: Refactor the failure cases in alloc_clt\")\nLink: https://lore.kernel.org/r/20220217030929.323849-1-haris.iqbal@ionos.com\nReported-by: Miaoqian Lin <linmq006@gmail.com>\nSigned-off-by: Md Haris Iqbal <haris.iqbal@ionos.com>\nReviewed-by: Jack Wang <jinpu.wang@ionos.com>\nSigned-off-by: Jason Gunthorpe <jgg@nvidia.com>drivers/infiniband/ulp/rtrs/rtrs-clt.c in the Linux kernel before 5.16.12 has a double free related to rtrs_clt_dev_release.",
        "filename": "rtrs-clt.c",
        "diff": "diff --git a/drivers/infiniband/ulp/rtrs/rtrs-clt.c b/drivers/infiniband/ulp/rtrs/rtrs-clt.c\nindex 7c3f98e57889f8..6164b07a164427 100644\n--- a/drivers/infiniband/ulp/rtrs/rtrs-clt.c\n+++ b/drivers/infiniband/ulp/rtrs/rtrs-clt.c\n@@ -2682,6 +2682,8 @@ static void rtrs_clt_dev_release(struct device *dev)\n \tstruct rtrs_clt_sess *clt = container_of(dev, struct rtrs_clt_sess,\n \t\t\t\t\t\t dev);\n \n+\tmutex_destroy(&clt->paths_ev_mutex);\n+\tmutex_destroy(&clt->paths_mutex);\n \tkfree(clt);\n }\n \n@@ -2711,6 +2713,8 @@ static struct rtrs_clt_sess *alloc_clt(const char *sessname, size_t paths_num,\n \t\treturn ERR_PTR(-ENOMEM);\n \t}\n \n+\tclt->dev.class = rtrs_clt_dev_class;\n+\tclt->dev.release = rtrs_clt_dev_release;\n \tuuid_gen(&clt->paths_uuid);\n \tINIT_LIST_HEAD_RCU(&clt->paths_list);\n \tclt->paths_num = paths_num;\n@@ -2727,43 +2731,41 @@ static struct rtrs_clt_sess *alloc_clt(const char *sessname, size_t paths_num,\n \tinit_waitqueue_head(&clt->permits_wait);\n \tmutex_init(&clt->paths_ev_mutex);\n \tmutex_init(&clt->paths_mutex);\n+\tdevice_initialize(&clt->dev);\n \n-\tclt->dev.class = rtrs_clt_dev_class;\n-\tclt->dev.release = rtrs_clt_dev_release;\n \terr = dev_set_name(&clt->dev, \"%s\", sessname);\n \tif (err)\n-\t\tgoto err;\n+\t\tgoto err_put;\n+\n \t/*\n \t * Suppress user space notification until\n \t * sysfs files are created\n \t */\n \tdev_set_uevent_suppress(&clt->dev, true);\n-\terr = device_register(&clt->dev);\n-\tif (err) {\n-\t\tput_device(&clt->dev);\n-\t\tgoto err;\n-\t}\n+\terr = device_add(&clt->dev);\n+\tif (err)\n+\t\tgoto err_put;\n \n \tclt->kobj_paths = kobject_create_and_add(\"paths\", &clt->dev.kobj);\n \tif (!clt->kobj_paths) {\n \t\terr = -ENOMEM;\n-\t\tgoto err_dev;\n+\t\tgoto err_del;\n \t}\n \terr = rtrs_clt_create_sysfs_root_files(clt);\n \tif (err) {\n \t\tkobject_del(clt->kobj_paths);\n \t\tkobject_put(clt->kobj_paths);\n-\t\tgoto err_dev;\n+\t\tgoto err_del;\n \t}\n \tdev_set_uevent_suppress(&clt->dev, false);\n \tkobject_uevent(&clt->dev.kobj, KOBJ_ADD);\n \n \treturn clt;\n-err_dev:\n-\tdevice_unregister(&clt->dev);\n-err:\n+err_del:\n+\tdevice_del(&clt->dev);\n+err_put:\n \tfree_percpu(clt->pcpu_path);\n-\tkfree(clt);\n+\tput_device(&clt->dev);\n \treturn ERR_PTR(err);\n }\n \n@@ -2771,9 +2773,10 @@ static void free_clt(struct rtrs_clt_sess *clt)\n {\n \tfree_permits(clt);\n \tfree_percpu(clt->pcpu_path);\n-\tmutex_destroy(&clt->paths_ev_mutex);\n-\tmutex_destroy(&clt->paths_mutex);\n-\t/* release callback will free clt in last put */\n+\n+\t/*\n+\t * release callback will free clt and destroy mutexes in last put\n+\t */\n \tdevice_unregister(&clt->dev);\n }\n \n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "4e061a43b3453a9856d34250c3913175c45afe9d",
        "repo": "hexchat/hexchat",
        "msg": "Clean up handling CAP LSDirectory traversal vulnerability in the client in HexChat 2.11.0 allows remote IRC servers to read or modify arbitrary files via a .. (dot dot) in the server name.",
        "filename": "inbound.c",
        "diff": "diff --git a/src/common/inbound.c b/src/common/inbound.c\nindex ef26890b9..645cc824a 100644\n--- a/src/common/inbound.c\n+++ b/src/common/inbound.c\n@@ -1699,20 +1699,37 @@ inbound_cap_ack (server *serv, char *nick, char *extensions,\n \t}\n }\n \n+static const char * const supported_caps[] = {\n+\t\"identify-msg\",\n+\n+\t/* IRCv3.1 */\n+\t\"multi-prefix\",\n+\t\"away-notify\",\n+\t\"account-notify\",\n+\t\"extended-join\",\n+\t/* \"sasl\", Handled manually */\n+\n+\t/* IRCv3.2 */\n+\t\"server-time\"\n+\t\"userhost-in-names\",\n+\n+\t/* ZNC */\n+\t\"znc.in/server-time-iso\",\n+\t\"znc.in/server-time\",\n+};\n+\n void\n inbound_cap_ls (server *serv, char *nick, char *extensions_str,\n \t\t\t\t\t const message_tags_data *tags_data)\n {\n \tchar buffer[256];\t/* buffer for requesting capabilities and emitting the signal */\n-\tguint32 want_cap; /* format the CAP REQ string based on previous capabilities being requested or not */\n-\tguint32 want_sasl; /* CAP END shouldn't be sent when SASL is requested, it needs further responses */\n+\tgboolean want_cap = FALSE; /* format the CAP REQ string based on previous capabilities being requested or not */\n+\tgboolean want_sasl = FALSE; /* CAP END shouldn't be sent when SASL is requested, it needs further responses */\n \tchar **extensions;\n \tint i;\n \n \tEMIT_SIGNAL_TIMESTAMP (XP_TE_CAPLIST, serv->server_session, nick,\n \t\t\t\t\t\t\t\t  extensions_str, NULL, NULL, 0, tags_data->timestamp);\n-\twant_cap = 0;\n-\twant_sasl = 0;\n \n \textensions = g_strsplit (extensions_str, \" \", 0);\n \n@@ -1721,66 +1738,27 @@ inbound_cap_ls (server *serv, char *nick, char *extensions_str,\n \tfor (i=0; extensions[i]; i++)\n \t{\n \t\tconst char *extension = extensions[i];\n+\t\tgsize x;\n \n-\t\tif (!strcmp (extension, \"identify-msg\"))\n-\t\t{\n-\t\t\tstrcat (buffer, \"identify-msg \");\n-\t\t\twant_cap = 1;\n-\t\t}\n-\t\tif (!strcmp (extension, \"multi-prefix\"))\n-\t\t{\n-\t\t\tstrcat (buffer, \"multi-prefix \");\n-\t\t\twant_cap = 1;\n-\t\t}\n-\t\tif (!strcmp (extension, \"away-notify\"))\n-\t\t{\n-\t\t\tstrcat (buffer, \"away-notify \");\n-\t\t\twant_cap = 1;\n-\t\t}\n-\t\tif (!strcmp (extension, \"account-notify\"))\n-\t\t{\n-\t\t\tstrcat (buffer, \"account-notify \");\n-\t\t\twant_cap = 1;\n-\t\t}\n-\t\tif (!strcmp (extension, \"extended-join\"))\n-\t\t{\n-\t\t\tstrcat (buffer, \"extended-join \");\n-\t\t\twant_cap = 1;\n-\t\t}\n-\t\tif (!strcmp (extension, \"userhost-in-names\"))\n+\t\t/* if the SASL password is set AND auth mode is set to SASL, request SASL auth */\n+\t\tif (!g_strcmp0 (extension, \"sasl\") &&\n+\t\t\t((serv->loginmethod == LOGIN_SASL && strlen (serv->password) != 0)\n+\t\t\t\t|| (serv->loginmethod == LOGIN_SASLEXTERNAL && serv->have_cert)))\n \t\t{\n-\t\t\tstrcat (buffer, \"userhost-in-names \");\n-\t\t\twant_cap = 1;\n+\t\t\twant_cap = TRUE;\n+\t\t\twant_sasl = TRUE;\n+\t\t\tg_strlcat (buffer, \"sasl \", sizeof(buffer));\n+\t\t\tcontinue;\n \t\t}\n \n-\t\t/* bouncers can prefix a name space to the extension so we should use.\n-\t\t * znc <= 1.0 uses \"znc.in/server-time\" and newer use \"znc.in/server-time-iso\".\n-\t\t */\n-\t\tif (!strcmp (extension, \"znc.in/server-time-iso\"))\n-\t\t{\n-\t\t\tstrcat (buffer, \"znc.in/server-time-iso \");\n-\t\t\twant_cap = 1;\n-\t\t}\n-\t\tif (!strcmp (extension, \"znc.in/server-time\"))\n-\t\t{\n-\t\t\tstrcat (buffer, \"znc.in/server-time \");\n-\t\t\twant_cap = 1;\n-\t\t}\n-\t\tif (prefs.hex_irc_cap_server_time\n-\t\t\t && !strcmp (extension, \"server-time\"))\n+\t\tfor (x = 0; x < G_N_ELEMENTS(supported_caps); ++x)\n \t\t{\n-\t\t\tstrcat (buffer, \"server-time \");\n-\t\t\twant_cap = 1;\n-\t\t}\n-\t\t\n-\t\t/* if the SASL password is set AND auth mode is set to SASL, request SASL auth */\n-\t\tif (!strcmp (extension, \"sasl\")\n-\t\t\t&& ((serv->loginmethod == LOGIN_SASL && strlen (serv->password) != 0)\n-\t\t\t|| (serv->loginmethod == LOGIN_SASLEXTERNAL && serv->have_cert)))\n-\t\t{\n-\t\t\tstrcat (buffer, \"sasl \");\n-\t\t\twant_cap = 1;\n-\t\t\twant_sasl = 1;\n+\t\t\tif (!g_strcmp0 (extension, supported_caps[x]))\n+\t\t\t{\n+\t\t\t\tg_strlcat (buffer, extension, sizeof(buffer));\n+\t\t\t\tg_strlcat (buffer, \" \", sizeof(buffer));\n+\t\t\t\twant_cap = TRUE;\n+\t\t\t}\n \t\t}\n \t}\n \n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "acdc3ae571dfae0e045cf09a295280127db65c7f",
        "repo": "puma/puma",
        "msg": "Merge pull request from GHSA-48w2-rm65-62xx\n\n* Fix HTTP request smuggling vulnerability\n\nSee GHSA-48w2-rm65-62xx or CVE-2021-41136 for more info.\n\n* 4.3.9 release note\n\n* 5.5.1 release note\n\n* 5.5.1Puma is a HTTP 1.1 server for Ruby/Rack applications. Prior to versions 5.5.1 and 4.3.9, using `puma` with a proxy which forwards HTTP header values which contain the LF character could allow HTTP request smugggling. A client could smuggle a request through a proxy, causing the proxy to send a response back to another unknown client. The only proxy which has this behavior, as far as the Puma team is aware of, is Apache Traffic Server. If the proxy uses persistent connections and the client adds another request in via HTTP pipelining, the proxy may mistake it as the first request's body. Puma, however, would see it as two requests, and when processing the second request, send back a response that the proxy does not expect. If the proxy has reused the persistent connection to Puma to send another request for a different client, the second response from the first client will be sent to the second client. This vulnerability was patched in Puma 5.5.1 and 4.3.9. As a workaround, do not use Apache Traffic Server with `puma`.",
        "filename": "http11_parser.c",
        "diff": "diff --git a/History.md b/History.md\nindex be3d97d552..f2c72b3bca 100644\n--- a/History.md\n+++ b/History.md\n@@ -1,3 +1,8 @@\n+## 5.5.1 / 2021-10-12\n+\n+* Security\n+  * Do not allow LF as a line ending in a header (CVE-2021-41136)\n+\n ## 5.5.0 / 2021-09-19\n \n * Features\n@@ -251,6 +256,11 @@\n   * Support parallel tests in verbose progress reporting ([#2223])\n   * Refactor error handling in server accept loop ([#2239])\n \n+## 4.3.9 / 2021-10-12\n+\n+* Security\n+  * Do not allow LF as a line ending in a header (CVE-2021-41136)\n+\n ## 4.3.8 / 2021-05-11\n \n * Security\ndiff --git a/ext/puma_http11/http11_parser.c b/ext/puma_http11/http11_parser.c\nindex 2da0263e3e..6c571b34ee 100644\n--- a/ext/puma_http11/http11_parser.c\n+++ b/ext/puma_http11/http11_parser.c\n@@ -426,10 +426,13 @@ case 17:\n case 18:\n #line 428 \"ext/puma_http11/http11_parser.c\"\n \tswitch( (*p) ) {\n+\t\tcase 9: goto tr25;\n \t\tcase 13: goto tr26;\n \t\tcase 32: goto tr27;\n \t}\n-\tgoto tr25;\n+\tif ( 33 <= (*p) && (*p) <= 126 )\n+\t\tgoto tr25;\n+\tgoto st0;\n tr25:\n #line 46 \"ext/puma_http11/http11_parser.rl\"\n \t{ MARK(mark, p); }\n@@ -438,10 +441,14 @@ case 18:\n \tif ( ++p == pe )\n \t\tgoto _test_eof19;\n case 19:\n-#line 442 \"ext/puma_http11/http11_parser.c\"\n-\tif ( (*p) == 13 )\n-\t\tgoto tr29;\n-\tgoto st19;\n+#line 445 \"ext/puma_http11/http11_parser.c\"\n+\tswitch( (*p) ) {\n+\t\tcase 9: goto st19;\n+\t\tcase 13: goto tr29;\n+\t}\n+\tif ( 32 <= (*p) && (*p) <= 126 )\n+\t\tgoto st19;\n+\tgoto st0;\n tr9:\n #line 53 \"ext/puma_http11/http11_parser.rl\"\n \t{\n@@ -484,7 +491,7 @@ case 19:\n \tif ( ++p == pe )\n \t\tgoto _test_eof20;\n case 20:\n-#line 488 \"ext/puma_http11/http11_parser.c\"\n+#line 495 \"ext/puma_http11/http11_parser.c\"\n \tswitch( (*p) ) {\n \t\tcase 32: goto tr31;\n \t\tcase 60: goto st0;\n@@ -505,7 +512,7 @@ case 20:\n \tif ( ++p == pe )\n \t\tgoto _test_eof21;\n case 21:\n-#line 509 \"ext/puma_http11/http11_parser.c\"\n+#line 516 \"ext/puma_http11/http11_parser.c\"\n \tswitch( (*p) ) {\n \t\tcase 32: goto tr33;\n \t\tcase 60: goto st0;\n@@ -526,7 +533,7 @@ case 21:\n \tif ( ++p == pe )\n \t\tgoto _test_eof22;\n case 22:\n-#line 530 \"ext/puma_http11/http11_parser.c\"\n+#line 537 \"ext/puma_http11/http11_parser.c\"\n \tswitch( (*p) ) {\n \t\tcase 43: goto st22;\n \t\tcase 58: goto st23;\n@@ -551,7 +558,7 @@ case 22:\n \tif ( ++p == pe )\n \t\tgoto _test_eof23;\n case 23:\n-#line 555 \"ext/puma_http11/http11_parser.c\"\n+#line 562 \"ext/puma_http11/http11_parser.c\"\n \tswitch( (*p) ) {\n \t\tcase 32: goto tr8;\n \t\tcase 34: goto st0;\n@@ -571,7 +578,7 @@ case 23:\n \tif ( ++p == pe )\n \t\tgoto _test_eof24;\n case 24:\n-#line 575 \"ext/puma_http11/http11_parser.c\"\n+#line 582 \"ext/puma_http11/http11_parser.c\"\n \tswitch( (*p) ) {\n \t\tcase 32: goto tr37;\n \t\tcase 34: goto st0;\n@@ -594,7 +601,7 @@ case 24:\n \tif ( ++p == pe )\n \t\tgoto _test_eof25;\n case 25:\n-#line 598 \"ext/puma_http11/http11_parser.c\"\n+#line 605 \"ext/puma_http11/http11_parser.c\"\n \tswitch( (*p) ) {\n \t\tcase 32: goto tr41;\n \t\tcase 34: goto st0;\n@@ -614,7 +621,7 @@ case 25:\n \tif ( ++p == pe )\n \t\tgoto _test_eof26;\n case 26:\n-#line 618 \"ext/puma_http11/http11_parser.c\"\n+#line 625 \"ext/puma_http11/http11_parser.c\"\n \tswitch( (*p) ) {\n \t\tcase 32: goto tr44;\n \t\tcase 34: goto st0;\ndiff --git a/ext/puma_http11/http11_parser_common.rl b/ext/puma_http11/http11_parser_common.rl\nindex ba5f8a56d6..5eba09f2c0 100644\n--- a/ext/puma_http11/http11_parser_common.rl\n+++ b/ext/puma_http11/http11_parser_common.rl\n@@ -43,7 +43,7 @@\n \n   field_name = ( token -- \":\" )+ >start_field $snake_upcase_field %write_field;\n \n-  field_value = any* >start_value %write_value;\n+  field_value = ( print | \"\\t\" )* >start_value %write_value;\n \n   message_header = field_name \":\" \" \"* field_value :> CRLF;\n \ndiff --git a/ext/puma_http11/org/jruby/puma/Http11Parser.java b/ext/puma_http11/org/jruby/puma/Http11Parser.java\nindex 0bba664f4e..f5db1b6987 100644\n--- a/ext/puma_http11/org/jruby/puma/Http11Parser.java\n+++ b/ext/puma_http11/org/jruby/puma/Http11Parser.java\n@@ -34,9 +34,9 @@ private static short[] init__puma_parser_key_offsets_0()\n {\n \treturn new short [] {\n \t    0,    0,    8,   17,   27,   29,   30,   31,   32,   33,   34,   36,\n-\t   39,   41,   44,   45,   61,   62,   78,   80,   81,   89,   97,  107,\n-\t  115,  124,  132,  140,  149,  158,  167,  176,  185,  194,  203,  212,\n-\t  221,  230,  239,  248,  257,  266,  275,  284,  293,  302,  303\n+\t   39,   41,   44,   45,   61,   62,   78,   83,   87,   95,  103,  113,\n+\t  121,  130,  138,  146,  155,  164,  173,  182,  191,  200,  209,  218,\n+\t  227,  236,  245,  254,  263,  272,  281,  290,  299,  308,  309\n \t};\n }\n \n@@ -52,14 +52,13 @@ private static char[] init__puma_parser_trans_keys_0()\n \t   46,   48,   57,   48,   57,   13,   48,   57,   10,   13,   33,  124,\n \t  126,   35,   39,   42,   43,   45,   46,   48,   57,   65,   90,   94,\n \t  122,   10,   33,   58,  124,  126,   35,   39,   42,   43,   45,   46,\n-\t   48,   57,   65,   90,   94,  122,   13,   32,   13,   32,   60,   62,\n-\t  127,    0,   31,   34,   35,   32,   60,   62,  127,    0,   31,   34,\n-\t   35,   43,   58,   45,   46,   48,   57,   65,   90,   97,  122,   32,\n-\t   34,   35,   60,   62,  127,    0,   31,   32,   34,   35,   60,   62,\n-\t   63,  127,    0,   31,   32,   34,   35,   60,   62,  127,    0,   31,\n-\t   32,   34,   35,   60,   62,  127,    0,   31,   32,   36,   95,   45,\n-\t   46,   48,   57,   65,   90,   32,   36,   95,   45,   46,   48,   57,\n-\t   65,   90,   32,   36,   95,   45,   46,   48,   57,   65,   90,   32,\n+\t   48,   57,   65,   90,   94,  122,    9,   13,   32,   33,  126,    9,\n+\t   13,   32,  126,   32,   60,   62,  127,    0,   31,   34,   35,   32,\n+\t   60,   62,  127,    0,   31,   34,   35,   43,   58,   45,   46,   48,\n+\t   57,   65,   90,   97,  122,   32,   34,   35,   60,   62,  127,    0,\n+\t   31,   32,   34,   35,   60,   62,   63,  127,    0,   31,   32,   34,\n+\t   35,   60,   62,  127,    0,   31,   32,   34,   35,   60,   62,  127,\n+\t    0,   31,   32,   36,   95,   45,   46,   48,   57,   65,   90,   32,\n \t   36,   95,   45,   46,   48,   57,   65,   90,   32,   36,   95,   45,\n \t   46,   48,   57,   65,   90,   32,   36,   95,   45,   46,   48,   57,\n \t   65,   90,   32,   36,   95,   45,   46,   48,   57,   65,   90,   32,\n@@ -71,7 +70,8 @@ private static char[] init__puma_parser_trans_keys_0()\n \t   65,   90,   32,   36,   95,   45,   46,   48,   57,   65,   90,   32,\n \t   36,   95,   45,   46,   48,   57,   65,   90,   32,   36,   95,   45,\n \t   46,   48,   57,   65,   90,   32,   36,   95,   45,   46,   48,   57,\n-\t   65,   90,   32,    0\n+\t   65,   90,   32,   36,   95,   45,   46,   48,   57,   65,   90,   32,\n+\t   36,   95,   45,   46,   48,   57,   65,   90,   32,    0\n \t};\n }\n \n@@ -82,7 +82,7 @@ private static byte[] init__puma_parser_single_lengths_0()\n {\n \treturn new byte [] {\n \t    0,    2,    3,    4,    2,    1,    1,    1,    1,    1,    0,    1,\n-\t    0,    1,    1,    4,    1,    4,    2,    1,    4,    4,    2,    6,\n+\t    0,    1,    1,    4,    1,    4,    3,    2,    4,    4,    2,    6,\n \t    7,    6,    6,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n \t    3,    3,    3,    3,    3,    3,    3,    3,    3,    1,    0\n \t};\n@@ -95,7 +95,7 @@ private static byte[] init__puma_parser_range_lengths_0()\n {\n \treturn new byte [] {\n \t    0,    3,    3,    3,    0,    0,    0,    0,    0,    0,    1,    1,\n-\t    1,    1,    0,    6,    0,    6,    0,    0,    2,    2,    4,    1,\n+\t    1,    1,    0,    6,    0,    6,    1,    1,    2,    2,    4,    1,\n \t    1,    1,    1,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n \t    3,    3,    3,    3,    3,    3,    3,    3,    3,    0,    0\n \t};\n@@ -108,9 +108,9 @@ private static short[] init__puma_parser_index_offsets_0()\n {\n \treturn new short [] {\n \t    0,    0,    6,   13,   21,   24,   26,   28,   30,   32,   34,   36,\n-\t   39,   41,   44,   46,   57,   59,   70,   73,   75,   82,   89,   96,\n-\t  104,  113,  121,  129,  136,  143,  150,  157,  164,  171,  178,  185,\n-\t  192,  199,  206,  213,  220,  227,  234,  241,  248,  255,  257\n+\t   39,   41,   44,   46,   57,   59,   70,   75,   79,   86,   93,  100,\n+\t  108,  117,  125,  133,  140,  147,  154,  161,  168,  175,  182,  189,\n+\t  196,  203,  210,  217,  224,  231,  238,  245,  252,  259,  261\n \t};\n }\n \n@@ -125,23 +125,23 @@ private static byte[] init__puma_parser_indicies_0()\n \t   10,    1,   11,    1,   12,    1,   13,    1,   14,    1,   15,    1,\n \t   16,   15,    1,   17,    1,   18,   17,    1,   19,    1,   20,   21,\n \t   21,   21,   21,   21,   21,   21,   21,   21,    1,   22,    1,   23,\n-\t   24,   23,   23,   23,   23,   23,   23,   23,   23,    1,   26,   27,\n-\t   25,   29,   28,   30,    1,    1,    1,    1,    1,   31,   32,    1,\n-\t    1,    1,    1,    1,   33,   34,   35,   34,   34,   34,   34,    1,\n-\t    8,    1,    9,    1,    1,    1,    1,   35,   36,    1,   38,    1,\n-\t    1,   39,    1,    1,   37,   40,    1,   42,    1,    1,    1,    1,\n-\t   41,   43,    1,   45,    1,    1,    1,    1,   44,    2,   46,   46,\n-\t   46,   46,   46,    1,    2,   47,   47,   47,   47,   47,    1,    2,\n-\t   48,   48,   48,   48,   48,    1,    2,   49,   49,   49,   49,   49,\n-\t    1,    2,   50,   50,   50,   50,   50,    1,    2,   51,   51,   51,\n-\t   51,   51,    1,    2,   52,   52,   52,   52,   52,    1,    2,   53,\n-\t   53,   53,   53,   53,    1,    2,   54,   54,   54,   54,   54,    1,\n-\t    2,   55,   55,   55,   55,   55,    1,    2,   56,   56,   56,   56,\n-\t   56,    1,    2,   57,   57,   57,   57,   57,    1,    2,   58,   58,\n-\t   58,   58,   58,    1,    2,   59,   59,   59,   59,   59,    1,    2,\n-\t   60,   60,   60,   60,   60,    1,    2,   61,   61,   61,   61,   61,\n-\t    1,    2,   62,   62,   62,   62,   62,    1,    2,   63,   63,   63,\n-\t   63,   63,    1,    2,    1,    1,    0\n+\t   24,   23,   23,   23,   23,   23,   23,   23,   23,    1,   25,   26,\n+\t   27,   25,    1,   28,   29,   28,    1,   30,    1,    1,    1,    1,\n+\t    1,   31,   32,    1,    1,    1,    1,    1,   33,   34,   35,   34,\n+\t   34,   34,   34,    1,    8,    1,    9,    1,    1,    1,    1,   35,\n+\t   36,    1,   38,    1,    1,   39,    1,    1,   37,   40,    1,   42,\n+\t    1,    1,    1,    1,   41,   43,    1,   45,    1,    1,    1,    1,\n+\t   44,    2,   46,   46,   46,   46,   46,    1,    2,   47,   47,   47,\n+\t   47,   47,    1,    2,   48,   48,   48,   48,   48,    1,    2,   49,\n+\t   49,   49,   49,   49,    1,    2,   50,   50,   50,   50,   50,    1,\n+\t    2,   51,   51,   51,   51,   51,    1,    2,   52,   52,   52,   52,\n+\t   52,    1,    2,   53,   53,   53,   53,   53,    1,    2,   54,   54,\n+\t   54,   54,   54,    1,    2,   55,   55,   55,   55,   55,    1,    2,\n+\t   56,   56,   56,   56,   56,    1,    2,   57,   57,   57,   57,   57,\n+\t    1,    2,   58,   58,   58,   58,   58,    1,    2,   59,   59,   59,\n+\t   59,   59,    1,    2,   60,   60,   60,   60,   60,    1,    2,   61,\n+\t   61,   61,   61,   61,    1,    2,   62,   62,   62,   62,   62,    1,\n+\t    2,   63,   63,   63,   63,   63,    1,    2,    1,    1,    0\n \t};\n }\n \ndiff --git a/lib/puma/const.rb b/lib/puma/const.rb\nindex dbe42b21c0..24528572d6 100644\n--- a/lib/puma/const.rb\n+++ b/lib/puma/const.rb\n@@ -100,7 +100,7 @@ class UnsupportedOption < RuntimeError\n   # too taxing on performance.\n   module Const\n \n-    PUMA_VERSION = VERSION = \"5.5.0\".freeze\n+    PUMA_VERSION = VERSION = \"5.5.1\".freeze\n     CODE_NAME = \"Zawgyi\".freeze\n \n     PUMA_SERVER_STRING = ['puma', PUMA_VERSION, CODE_NAME].join(' ').freeze\ndiff --git a/test/test_http11.rb b/test/test_http11.rb\nindex 9e49b7b376..1d7f11589e 100644\n--- a/test/test_http11.rb\n+++ b/test/test_http11.rb\n@@ -208,4 +208,34 @@ def test_trims_whitespace_from_headers\n \n     assert_equal \"Strip This\", req[\"HTTP_X_STRIP_ME\"]\n   end\n+\n+  def test_newline_smuggler\n+    parser = Puma::HttpParser.new\n+    req = {}\n+    http = \"GET / HTTP/1.1\\r\\nHost: localhost:8080\\r\\nDummy: x\\nDummy2: y\\r\\n\\r\\n\"\n+\n+    parser.execute(req, http, 0) rescue nil # We test the raise elsewhere.\n+\n+    assert parser.error?, \"Parser SHOULD have error\"\n+  end\n+\n+  def test_newline_smuggler_two\n+    parser = Puma::HttpParser.new\n+    req = {}\n+    http = \"GET / HTTP/1.1\\r\\nHost: localhost:8080\\r\\nDummy: x\\r\\nDummy: y\\nDummy2: z\\r\\n\\r\\n\"\n+\n+    parser.execute(req, http, 0) rescue nil\n+\n+    assert parser.error?, \"Parser SHOULD have error\"\n+  end\n+\n+  def test_htab_in_header_val\n+    parser = Puma::HttpParser.new\n+    req = {}\n+    http = \"GET / HTTP/1.1\\r\\nHost: localhost:8080\\r\\nDummy: Valid\\tValue\\r\\n\\r\\n\"\n+\n+    parser.execute(req, http, 0)\n+\n+    assert_equal \"Valid\\tValue\", req['HTTP_DUMMY']\n+  end\n end\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "e4b777c7b7c144cd16a0ea96108267b1004fe6c9",
        "repo": "hpjansson/chafa",
        "msg": "libnsgif: Fix null pointer deref on frameless GIF input\n\nA crafted GIF file with no frame data could cause a null pointer\ndereference leading to denial of service (crash). Reported by\n@JieyongMa via huntr.dev.chafa: NULL Pointer Dereference in function gif_internal_decode_frame at libnsgif.c:599 allows attackers to cause a denial of service (crash) via a crafted input file. in GitHub repository hpjansson/chafa prior to 1.10.2. chafa: NULL Pointer Dereference in function gif_internal_decode_frame at libnsgif.c:599 allows attackers to cause a denial of service (crash) via a crafted input file.",
        "filename": "libnsgif.c",
        "diff": "diff --git a/libnsgif/libnsgif.c b/libnsgif/libnsgif.c\nindex fc4bda22..fa55d7b5 100644\n--- a/libnsgif/libnsgif.c\n+++ b/libnsgif/libnsgif.c\n@@ -595,6 +595,12 @@ gif_internal_decode_frame(gif_animation *gif,\n         unsigned int x, y, decode_y, burst_bytes;\n         register unsigned char colour;\n \n+        /* If the GIF has no frame data, frame holders will not be allocated in\n+         * gif_initialise() */\n+        if (gif->frames == NULL) {\n+                return GIF_INSUFFICIENT_DATA;\n+        }\n+\n         /* Ensure this frame is supposed to be decoded */\n         if (gif->frames[frame].display == false) {\n                 return GIF_OK;\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "f12129f1714f7d2301935bb21d896609bdac221c",
        "repo": "vim/vim",
        "msg": "patch 9.0.0020: with some completion reading past end of string\n\nProblem:    With some completion reading past end of string.\nSolution:   Check the length of the string.Out-of-bounds Read in GitHub repository vim/vim prior to 9.0.",
        "filename": "insexpand.c",
        "diff": "diff --git a/src/insexpand.c b/src/insexpand.c\nindex 4a5feac9dc1f7..734550ffd231f 100644\n--- a/src/insexpand.c\n+++ b/src/insexpand.c\n@@ -2209,11 +2209,21 @@ ins_compl_stop(int c, int prev_mode, int retval)\n     // but only do this, if the Popup is still visible\n     if (c == Ctrl_E)\n     {\n+\tchar_u *p = NULL;\n+\n \tins_compl_delete();\n \tif (compl_leader != NULL)\n-\t    ins_bytes(compl_leader + get_compl_len());\n+\t    p = compl_leader;\n \telse if (compl_first_match != NULL)\n-\t    ins_bytes(compl_orig_text + get_compl_len());\n+\t    p = compl_orig_text;\n+\tif (p != NULL)\n+\t{\n+\t    int\t    compl_len = get_compl_len();\n+\t    int\t    len = (int)STRLEN(p);\n+\n+\t    if (len > compl_len)\n+\t\tins_bytes_len(p + compl_len, len - compl_len);\n+\t}\n \tretval = TRUE;\n     }\n \ndiff --git a/src/testdir/test_ins_complete.vim b/src/testdir/test_ins_complete.vim\nindex 365c646a19c65..20c2b4f48f414 100644\n--- a/src/testdir/test_ins_complete.vim\n+++ b/src/testdir/test_ins_complete.vim\n@@ -2184,4 +2184,12 @@ func Test_complete_smartindent()\n   delfunction! FooBarComplete\n endfunc\n \n+func Test_complete_overrun()\n+  \" this was going past the end of the copied text\n+  new\n+  sil norm si\u0094\u00140\u0003s\u000f0\u0018\f\u0005\n+  bwipe!\n+endfunc\n+\n+\n \" vim: shiftwidth=2 sts=2 expandtab\ndiff --git a/src/version.c b/src/version.c\nindex 42e9135e1f6d0..26cb768a82541 100644\n--- a/src/version.c\n+++ b/src/version.c\n@@ -735,6 +735,8 @@ static char *(features[]) =\n \n static int included_patches[] =\n {   /* Add new patch number below this line */\n+/**/\n+    20,\n /**/\n     19,\n /**/\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "077b465c33f0aec05a49cd2ca456f9a1b112e896",
        "repo": "pjsip/pjproject",
        "msg": "Merge pull request from GHSA-7fw8-54cv-r7pmPJSIP is a free and open source multimedia communication library written in C language implementing standard based protocols such as SIP, SDP, RTP, STUN, TURN, and ICE. In versions 2.11.1 and prior, parsing an incoming SIP message that contains a malformed multipart can potentially cause out-of-bound read access. This issue affects all PJSIP users that accept SIP multipart. The patch is available as commit in the `master` branch. There are no known workarounds.",
        "filename": "scanner.c",
        "diff": "diff --git a/pjlib-util/src/pjlib-util/scanner.c b/pjlib-util/src/pjlib-util/scanner.c\nindex 27a0b88310..a54edf2d8e 100644\n--- a/pjlib-util/src/pjlib-util/scanner.c\n+++ b/pjlib-util/src/pjlib-util/scanner.c\n@@ -444,16 +444,21 @@ PJ_DEF(void) pj_scan_get_n( pj_scanner *scanner,\n \n PJ_DEF(int) pj_scan_get_char( pj_scanner *scanner )\n {\n-    int chr = *scanner->curptr;\n+    register char *s = scanner->curptr;\n+    int chr;\n \n-    if (!chr) {\n+    if (s >= scanner->end || !*s) {\n \tpj_scan_syntax_err(scanner);\n \treturn 0;\n     }\n \n-    ++scanner->curptr;\n+    chr = *s;\n \n-    if (PJ_SCAN_IS_PROBABLY_SPACE(*scanner->curptr) && scanner->skip_ws) {\n+    ++s;\n+    scanner->curptr = s;\n+    if (PJ_SCAN_CHECK_EOF(s) && PJ_SCAN_IS_PROBABLY_SPACE(*s) &&\n+    \tscanner->skip_ws)\n+    {\n \tpj_scan_skip_whitespace(scanner);\n     }\n     return chr;\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "feaa4e7f7399c51ee6f52deb84dc3f795b4035d6",
        "repo": "radare/radare2",
        "msg": "Fix null deref in xnu.kernelcache ##crash\n\n* Reported by @xshad3 via huntr.devNULL Pointer Dereference in GitHub repository radareorg/radare2 prior to 5.6.0.",
        "filename": "bin_xnu_kernelcache.c",
        "diff": "diff --git a/libr/bin/p/bin_xnu_kernelcache.c b/libr/bin/p/bin_xnu_kernelcache.c\nindex 36b1c2db08744..df5b1fe7d0c3e 100644\n--- a/libr/bin/p/bin_xnu_kernelcache.c\n+++ b/libr/bin/p/bin_xnu_kernelcache.c\n@@ -242,7 +242,9 @@ static bool load_buffer(RBinFile *bf, void **bin_obj, RBuffer *buf, ut64 loadadd\n \n beach:\n \tr_buf_free (fbuf);\n-\tobj->cache_buf = NULL;\n+\tif (obj) {\n+\t\tobj->cache_buf = NULL;\n+\t}\n \tMACH0_(mach0_free) (main_mach0);\n \treturn false;\n }\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "6e28703a8e41f775f64e442c5d11ce1ff599aa3f",
        "repo": "vim/vim",
        "msg": "patch 8.2.4359: crash when repeatedly using :retab\n\nProblem:    crash when repeatedly using :retab.\nSolution:   Bail out when the line is getting too long.Heap-based Buffer Overflow in GitHub repository vim/vim prior to 8.2.",
        "filename": "indent.c",
        "diff": "diff --git a/src/indent.c b/src/indent.c\nindex 9b137b0b425a9..232c534973af6 100644\n--- a/src/indent.c\n+++ b/src/indent.c\n@@ -1750,6 +1750,11 @@ ex_retab(exarg_T *eap)\n \t    if (ptr[col] == NUL)\n \t\tbreak;\n \t    vcol += chartabsize(ptr + col, (colnr_T)vcol);\n+\t    if (vcol >= MAXCOL)\n+\t    {\n+\t\temsg(_(e_resulting_text_too_long));\n+\t\tbreak;\n+\t    }\n \t    if (has_mbyte)\n \t\tcol += (*mb_ptr2len)(ptr + col);\n \t    else\ndiff --git a/src/testdir/test_retab.vim b/src/testdir/test_retab.vim\nindex c7190aaa6699d..6133e8fb4abca 100644\n--- a/src/testdir/test_retab.vim\n+++ b/src/testdir/test_retab.vim\n@@ -70,6 +70,8 @@ func Test_retab()\n   call assert_equal(\"    a       b        c    \",         Retab('!', 3))\n   call assert_equal(\"    a       b        c    \",         Retab('',  5))\n   call assert_equal(\"    a       b        c    \",         Retab('!', 5))\n+\n+  set tabstop& expandtab&\n endfunc\n \n func Test_retab_error()\n@@ -80,4 +82,21 @@ func Test_retab_error()\n   call assert_fails('ret 80000000000000000000', 'E475:')\n endfunc\n \n+func Test_retab_endless()\n+  new\n+  call setline(1, \"\\t0\\t\")\n+  let caught = 'no'\n+  try\n+    while 1\n+      set ts=4000\n+      retab 4\n+    endwhile\n+  catch /E1240/\n+    let caught = 'yes'\n+  endtry\n+  bwipe!\n+  set tabstop&\n+endfunc\n+\n+\n \" vim: shiftwidth=2 sts=2 expandtab\ndiff --git a/src/version.c b/src/version.c\nindex 636757c3b6a61..aaafadf89de70 100644\n--- a/src/version.c\n+++ b/src/version.c\n@@ -750,6 +750,8 @@ static char *(features[]) =\n \n static int included_patches[] =\n {   /* Add new patch number below this line */\n+/**/\n+    4359,\n /**/\n     4358,\n /**/\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "2813f38e021c6e6581c0c88fcf107e41788bc835",
        "repo": "vim/vim",
        "msg": "patch 8.2.5072: using uninitialized value and freed memory in spell command\n\nProblem:    Using uninitialized value and freed memory in spell command.\nSolution:   Initialize \"attr\".  Check for empty line early.Use After Free in GitHub repository vim/vim prior to 8.2.",
        "filename": "spell.c",
        "diff": "diff --git a/src/spell.c b/src/spell.c\nindex 48a2203e3f042b..d866a2df7265c1 100644\n--- a/src/spell.c\n+++ b/src/spell.c\n@@ -1275,7 +1275,7 @@ spell_move_to(\n     char_u\t*line;\n     char_u\t*p;\n     char_u\t*endp;\n-    hlf_T\tattr;\n+    hlf_T\tattr = 0;\n     int\t\tlen;\n #ifdef FEAT_SYN_HL\n     int\t\thas_syntax = syntax_present(wp);\n@@ -1308,6 +1308,8 @@ spell_move_to(\n \n     while (!got_int)\n     {\n+\tint empty_line;\n+\n \tline = ml_get_buf(wp->w_buffer, lnum, FALSE);\n \n \tlen = (int)STRLEN(line);\n@@ -1340,7 +1342,9 @@ spell_move_to(\n \t}\n \n \t// Copy the line into \"buf\" and append the start of the next line if\n-\t// possible.\n+\t// possible.  Note: this ml_get_buf() may make \"line\" invalid, check\n+\t// for empty line first.\n+\tempty_line = *skipwhite(line) == NUL;\n \tSTRCPY(buf, line);\n \tif (lnum < wp->w_buffer->b_ml.ml_line_count)\n \t    spell_cat_line(buf + STRLEN(buf),\n@@ -1487,7 +1491,7 @@ spell_move_to(\n \t    --capcol;\n \n \t    // But after empty line check first word in next line\n-\t    if (*skipwhite(line) == NUL)\n+\t    if (empty_line)\n \t\tcapcol = 0;\n \t}\n \ndiff --git a/src/testdir/test_spell_utf8.vim b/src/testdir/test_spell_utf8.vim\nindex ef08f953521c79..f9f85a63ae99f8 100644\n--- a/src/testdir/test_spell_utf8.vim\n+++ b/src/testdir/test_spell_utf8.vim\n@@ -802,5 +802,20 @@ func Test_word_index()\n   call delete('Xtmpfile')\n endfunc\n \n+func Test_check_empty_line()\n+  \" This was using freed memory\n+  enew\n+  spellgood! \ufb02\n+  norm z=\n+  norm yy\n+  sil! norm P]svc\n+  norm P]s\n+\n+  \" set 'encoding' to clear the wordt list\n+  set enc=latin1\n+  set enc=utf-8\n+  bwipe!\n+endfunc\n+\n \n \" vim: shiftwidth=2 sts=2 expandtab\ndiff --git a/src/version.c b/src/version.c\nindex ebfd0d45feef0b..8f5a4ff71b607d 100644\n--- a/src/version.c\n+++ b/src/version.c\n@@ -734,6 +734,8 @@ static char *(features[]) =\n \n static int included_patches[] =\n {   /* Add new patch number below this line */\n+/**/\n+    5072,\n /**/\n     5071,\n /**/\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "3a5474f9102cbdc10fbd9e7b1b2c8d3f3f45d91b",
        "repo": "milkytracker/MilkyTracker",
        "msg": "Fix possible stack corruption with XM instrument headers claiming a size of less than 4\n\nCloses #275MilkyTracker v1.03.00 was discovered to contain a stack overflow via the component LoaderXM::load. This vulnerability is triggered when the program is supplied a crafted XM module file.",
        "filename": "LoaderXM.cpp",
        "diff": "diff --git a/src/milkyplay/LoaderXM.cpp b/src/milkyplay/LoaderXM.cpp\nindex f87f5c11..303e3493 100644\n--- a/src/milkyplay/LoaderXM.cpp\n+++ b/src/milkyplay/LoaderXM.cpp\n@@ -478,7 +478,7 @@ mp_sint32 LoaderXM::load(XMFileBase& f, XModule* module)\n \t\t\n \t\t\tf.readDwords(&instr[y].size,1);\n \t\t\t\n-\t\t\tif (instr[y].size < 29)\n+\t\t\tif (instr[y].size >= 4 && instr[y].size < 29)\n \t\t\t{\n \t\t\t\tmp_ubyte buffer[29];\n \t\t\t\tmemset(buffer, 0, sizeof(buffer));\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "37f47958b8a2a44abc60614271d9537e7f14e51a",
        "repo": "vim/vim",
        "msg": "patch 8.2.4253: using freed memory when substitute with function call\n\nProblem:    Using freed memory when substitute uses a recursive function call.\nSolution:   Make a copy of the substitute text.Use After Free in GitHub repository vim/vim prior to 8.2.",
        "filename": "ex_cmds.c",
        "diff": "diff --git a/src/ex_cmds.c b/src/ex_cmds.c\nindex 099d9cfeedd78..9d99571f72ab8 100644\n--- a/src/ex_cmds.c\n+++ b/src/ex_cmds.c\n@@ -3687,6 +3687,7 @@ ex_substitute(exarg_T *eap)\n     int\t\tsave_do_all;\t\t// remember user specified 'g' flag\n     int\t\tsave_do_ask;\t\t// remember user specified 'c' flag\n     char_u\t*pat = NULL, *sub = NULL;\t// init for GCC\n+    char_u\t*sub_copy = NULL;\n     int\t\tdelimiter;\n     int\t\tsublen;\n     int\t\tgot_quit = FALSE;\n@@ -3980,11 +3981,20 @@ ex_substitute(exarg_T *eap)\n     sub_firstline = NULL;\n \n     /*\n-     * ~ in the substitute pattern is replaced with the old pattern.\n-     * We do it here once to avoid it to be replaced over and over again.\n-     * But don't do it when it starts with \"\\=\", then it's an expression.\n+     * If the substitute pattern starts with \"\\=\" then it's an expression.\n+     * Make a copy, a recursive function may free it.\n+     * Otherwise, '~' in the substitute pattern is replaced with the old\n+     * pattern.  We do it here once to avoid it to be replaced over and over\n+     * again.\n      */\n-    if (!(sub[0] == '\\\\' && sub[1] == '='))\n+    if (sub[0] == '\\\\' && sub[1] == '=')\n+    {\n+\tsub = vim_strsave(sub);\n+\tif (sub == NULL)\n+\t    return;\n+\tsub_copy = sub;\n+    }\n+    else\n \tsub = regtilde(sub, magic_isset());\n \n     /*\n@@ -4790,6 +4800,7 @@ ex_substitute(exarg_T *eap)\n #endif\n \n     vim_regfree(regmatch.regprog);\n+    vim_free(sub_copy);\n \n     // Restore the flag values, they can be used for \":&&\".\n     subflags.do_all = save_do_all;\ndiff --git a/src/testdir/test_substitute.vim b/src/testdir/test_substitute.vim\nindex 0806fd2de6267..35b6b8a0245d3 100644\n--- a/src/testdir/test_substitute.vim\n+++ b/src/testdir/test_substitute.vim\n@@ -980,4 +980,21 @@ func Test_substitute_gdefault()\n   bw!\n endfunc\n \n+\" This was using \"old_sub\" after it was freed.\n+func Test_using_old_sub()\n+  set compatible maxfuncdepth=10\n+  new\n+  call setline(1, 'some text.')\n+  func Repl()\n+    ~\n+    s/\n+  endfunc\n+  silent!  s/\\%')/\\=Repl()\n+\n+  delfunc Repl\n+  bwipe!\n+  set nocompatible\n+endfunc\n+\n+\n \" vim: shiftwidth=2 sts=2 expandtab\ndiff --git a/src/version.c b/src/version.c\nindex e5499ade6628a..25dcfe316bef2 100644\n--- a/src/version.c\n+++ b/src/version.c\n@@ -750,6 +750,8 @@ static char *(features[]) =\n \n static int included_patches[] =\n {   /* Add new patch number below this line */\n+/**/\n+    4253,\n /**/\n     4252,\n /**/\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "389ecc365a7c61404ba078a72c3fa5a3cf1b4101",
        "repo": "ImageMagick/ImageMagick",
        "msg": "https://github.com/ImageMagick/ImageMagick/issues/1221The ReadMATImageV4 function in coders/mat.c in ImageMagick 7.0.8-7 uses an uninitialized variable, leading to memory corruption.",
        "filename": "mat.c",
        "diff": "diff --git a/coders/mat.c b/coders/mat.c\nindex 5858ff53457..d3a2db86b2b 100644\n--- a/coders/mat.c\n+++ b/coders/mat.c\n@@ -631,9 +631,9 @@ static Image *ReadMATImageV4(const ImageInfo *image_info,Image *image,\n   unsigned int\n     depth;\n \n-\n   quantum_info=(QuantumInfo *) NULL;\n   (void) SeekBlob(image,0,SEEK_SET);\n+  status=MagickTrue;\n   while (EOFBlob(image) == MagickFalse)\n   {\n     /*\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "e2f5dc151e2e79058e93924e6d35510557f0535d",
        "repo": "Exim/exim",
        "msg": "Check configure file permissions even for non-default files if still privileged\n\n(Bug 1044, CVE-2010-4345)Exim 4.72 and earlier allows local users to gain privileges by leveraging the ability of the exim user account to specify an alternate configuration file with a directive that contains arbitrary commands, as demonstrated by the spool_directory directive.",
        "filename": "readconf.c",
        "diff": "diff --git a/doc/doc-txt/ChangeLog b/doc/doc-txt/ChangeLog\nindex 99a6f176b3..0063c6be00 100644\n--- a/doc/doc-txt/ChangeLog\n+++ b/doc/doc-txt/ChangeLog\n@@ -78,6 +78,11 @@ DW/22 Bugzilla 1044: CVE-2010-4345 - partial fix: restrict default behaviour\n       of CONFIGURE_OWNER and CONFIGURE_GROUP options to no longer allow a\n       configuration file which is writeable by the Exim user or group.\n \n+DW/23 Bugzilla 1044: CVE-2010-4345 - part two: extend checks for writeability\n+      of configuration files to cover files specified with the -C option if\n+      they are going to be used with root privileges, not just the default\n+      configuration file.\n+\n \n Exim version 4.72\n -----------------\ndiff --git a/src/src/exim.c b/src/src/exim.c\nindex 50950faa50..0d8f244927 100644\n--- a/src/src/exim.c\n+++ b/src/src/exim.c\n@@ -1848,6 +1848,7 @@ for (i = 1; i < argc; i++)\n \n       config_main_filelist = argrest;\n       config_changed = TRUE;\n+      trusted_config = FALSE;\n       }\n     break;\n \n@@ -3046,7 +3047,7 @@ values (such as the path name). If running in the test harness, pretend that\n configuration file changes and macro definitions haven't happened. */\n \n if ((                                            /* EITHER */\n-    (config_changed || macros != NULL) &&        /* Config changed, and */\n+    (!trusted_config || macros != NULL) &&       /* Config changed, and */\n     real_uid != root_uid &&                      /* Not root, and */\n     #ifndef ALT_CONFIG_ROOT_ONLY                 /* (when not locked out) */\n     real_uid != exim_uid &&                      /* Not exim, and */\n@@ -3265,7 +3266,7 @@ If ALT_CONFIG_ROOT_ONLY is defined, we don't know whether we were called by the\n built-in exim user or one defined in the configuration. In either event,\n re-enable log processing, assuming the sysadmin knows what they are doing. */\n \n-if (removed_privilege && (config_changed || macros != NULL) &&\n+if (removed_privilege && (!trusted_config || macros != NULL) &&\n     real_uid == exim_uid)\n   {\n   #ifdef ALT_CONFIG_ROOT_ONLY\n@@ -3277,7 +3278,7 @@ if (removed_privilege && (config_changed || macros != NULL) &&\n   else\n     log_write(0, LOG_MAIN|LOG_PANIC,\n       \"exim user (uid=%d) is defined only at runtime; privilege lost for %s\",\n-      (int)exim_uid, config_changed? \"-C\" : \"-D\");\n+      (int)exim_uid, trusted_config? \"-D\" : \"-C\");\n   #endif\n   }\n \ndiff --git a/src/src/globals.c b/src/src/globals.c\nindex 9b77d876b2..f77fbcc637 100644\n--- a/src/src/globals.c\n+++ b/src/src/globals.c\n@@ -1268,6 +1268,7 @@ tree_node  *tree_nonrecipients = NULL;\n tree_node  *tree_unusable      = NULL;\n \n BOOL    trusted_caller         = FALSE;\n+BOOL    trusted_config         = TRUE;\n gid_t  *trusted_groups         = NULL;\n uid_t  *trusted_users          = NULL;\n uschar *timezone_string        = US TIMEZONE_DEFAULT;\ndiff --git a/src/src/globals.h b/src/src/globals.h\nindex d66880e67e..62dd6b04a3 100644\n--- a/src/src/globals.h\n+++ b/src/src/globals.h\n@@ -783,6 +783,7 @@ extern tree_node *tree_nonrecipients;  /* Tree of nonrecipient addresses */\n extern tree_node *tree_unusable;       /* Tree of unusable addresses */\n \n extern BOOL    trusted_caller;         /* Caller is trusted */\n+extern BOOL    trusted_config;         /* Configuration file is trusted */\n extern gid_t  *trusted_groups;         /* List of trusted groups */\n extern uid_t  *trusted_users;          /* List of trusted users */\n extern uschar *timezone_string;        /* Required timezone setting */\ndiff --git a/src/src/readconf.c b/src/src/readconf.c\nindex 0803058340..118ccf5feb 100644\n--- a/src/src/readconf.c\n+++ b/src/src/readconf.c\n@@ -2874,10 +2874,10 @@ else\n       \"configuration file %s\", filename));\n   }\n \n-/* Check the status of the file we have opened, unless it was specified on\n-the command line, in which case privilege was given away at the start. */\n+/* Check the status of the file we have opened, if we have retained root\n+privileges. */\n \n-if (!config_changed)\n+if (trusted_config)\n   {\n   if (fstat(fileno(config_file), &statbuf) != 0)\n     log_write(0, LOG_MAIN|LOG_PANIC_DIE, \"failed to stat configuration file %s\",\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "817b8b9c5396d2b2d92311b46719aad5d3339dbe",
        "repo": "torvalds/linux",
        "msg": "HID: elo: fix memory leak in elo_probe\n\nWhen hid_parse() in elo_probe() fails, it forgets to call usb_put_dev to\ndecrease the refcount.\n\nFix this by adding usb_put_dev() in the error handling code of elo_probe().\n\nFixes: fbf42729d0e9 (\"HID: elo: update the reference count of the usb device structure\")\nReported-by: syzkaller <syzkaller@googlegroups.com>\nSigned-off-by: Dongliang Mu <mudongliangabcd@gmail.com>\nSigned-off-by: Jiri Kosina <jkosina@suse.cz>In drivers/hid/hid-elo.c in the Linux kernel before 5.16.11, a memory leak exists for a certain hid_parse error condition.",
        "filename": "hid-elo.c",
        "diff": "diff --git a/drivers/hid/hid-elo.c b/drivers/hid/hid-elo.c\nindex 8e960d7b233b3a..9b42b0cdeef06b 100644\n--- a/drivers/hid/hid-elo.c\n+++ b/drivers/hid/hid-elo.c\n@@ -262,6 +262,7 @@ static int elo_probe(struct hid_device *hdev, const struct hid_device_id *id)\n \n \treturn 0;\n err_free:\n+\tusb_put_dev(udev);\n \tkfree(priv);\n \treturn ret;\n }\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "cf6771c857eb9a290e2c19ddacfdd3ed98b27618",
        "repo": "gpac/gpac",
        "msg": "fixed #1898A Segmentation fault caused by null pointer dereference vulnerability eists in Gpac through 1.0.2 via the avc_parse_slice function in av_parsers.c when using mp4box, which causes a denial of service.",
        "filename": "av_parsers.c",
        "diff": "diff --git a/src/media_tools/av_parsers.c b/src/media_tools/av_parsers.c\nindex 4ea0db8a90..0cc096d1a3 100644\n--- a/src/media_tools/av_parsers.c\n+++ b/src/media_tools/av_parsers.c\n@@ -4705,8 +4705,12 @@ u32 gf_bs_read_ue_log_idx3(GF_BitStream *bs, const char *fname, s32 idx1, s32 id\n \t}\n \n \tif (nb_lead) {\n+\t\tu32 leads=1;\n \t\tval = gf_bs_read_int(bs, nb_lead);\n-\t\tval += (1 << nb_lead) - 1;\n+\t\tleads <<= nb_lead;\n+\t\tleads -= 1;\n+\t\tval += leads;\n+//\t\tval += (1 << nb_lead) - 1;\n \t\tbits += nb_lead;\n \t}\n \n@@ -5671,7 +5675,7 @@ static s32 avc_parse_slice(GF_BitStream *bs, AVCState *avc, Bool svc_idr_flag, A\n \tif (si->slice_type > 9) return -1;\n \n \tpps_id = gf_bs_read_ue_log(bs, \"pps_id\");\n-\tif (pps_id > 255) return -1;\n+\tif ((pps_id<0) || (pps_id > 255)) return -1;\n \tsi->pps = &avc->pps[pps_id];\n \tif (!si->pps->slice_group_count) return -2;\n \tsi->sps = &avc->sps[si->pps->sps_id];\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "955059813cc325dc1db5e2daa6221271406d4439",
        "repo": "tensorflow/tensorflow",
        "msg": "Check for type inference error on node construction.\n\nPiperOrigin-RevId: 409415804\nChange-Id: Ieb6e020906b96f522bf8e2fa103715ddbbdc434aTensorflow is an Open Source Machine Learning Framework. A `GraphDef` from a TensorFlow `SavedModel` can be maliciously altered to cause a TensorFlow process to crash due to encountering a `StatusOr` value that is an error and forcibly extracting the value from it. We have patched the issue in multiple GitHub commits and these will be included in TensorFlow 2.8.0 and TensorFlow 2.7.1, as both are affected.",
        "filename": "graph.cc",
        "diff": "diff --git a/tensorflow/core/graph/graph.cc b/tensorflow/core/graph/graph.cc\nindex 397a45c97737ab..2e3703b66030f4 100644\n--- a/tensorflow/core/graph/graph.cc\n+++ b/tensorflow/core/graph/graph.cc\n@@ -561,6 +561,11 @@ Node* Graph::AddNode(NodeDef node_def, Status* status) {\n     VLOG(3) << \"AddNode: found type constructor for \" << node_def.name();\n     const auto ctor_type =\n         full_type::SpecializeType(AttrSlice(node_def), op_reg_data->op_def);\n+    if (!ctor_type.ok()) {\n+      *status = errors::InvalidArgument(\"type error: \",\n+                                        ctor_type.status().ToString());\n+      return nullptr;\n+    }\n     const FullTypeDef ctor_typedef = ctor_type.ValueOrDie();\n     if (ctor_typedef.type_id() != TFT_UNSET) {\n       *(node_def.mutable_experimental_type()) = ctor_typedef;\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "d4fa336fbcc388f89095b184ba6d99422cfc676c",
        "repo": "PCRE2Project/pcre2",
        "msg": "Fix incorrect value reading in JIT.An out-of-bounds read vulnerability was discovered in the PCRE2 library in the compile_xclass_matchingpath() function of the pcre2_jit_compile.c file. This involves a unicode property matching issue in JIT-compiled regular expressions. The issue occurs because the character was not fully read in case-less matching within JIT.",
        "filename": "pcre2_jit_compile.c",
        "diff": "diff --git a/src/pcre2_jit_compile.c b/src/pcre2_jit_compile.c\nindex 94f6a5887..7fcdac863 100644\n--- a/src/pcre2_jit_compile.c\n+++ b/src/pcre2_jit_compile.c\n@@ -7489,7 +7489,7 @@ while (*cc != XCL_END)\n     {\n     SLJIT_ASSERT(*cc == XCL_PROP || *cc == XCL_NOTPROP);\n     cc++;\n-    if (*cc == PT_CLIST && *cc == XCL_PROP)\n+    if (*cc == PT_CLIST && cc[-1] == XCL_PROP)\n       {\n       other_cases = PRIV(ucd_caseless_sets) + cc[1];\n       while (*other_cases != NOTACHAR)\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "0a365c029e437be0349c31f8d4c9926b69fa3fa1",
        "repo": "tensorflow/tensorflow",
        "msg": "Prevent null pointer dereference in constant folding.\n\nUnder certain conditions, an invalid protobuf saved model with invalid nodes would be loaded. During optimization phase, Grappler optimizer will then dereference a null pointer.\n\nPiperOrigin-RevId: 409683530\nChange-Id: I1f10340a7ec384bc9bc587300390f1078cf5caa0Tensorflow is an Open Source Machine Learning Framework. Under certain scenarios, Grappler component of TensorFlow can trigger a null pointer dereference. There are 2 places where this can occur, for the same malicious alteration of a `SavedModel` file (fixing the first one would trigger the same dereference in the second place). First, during constant folding, the `GraphDef` might not have the required nodes for the binary operation. If a node is missing, the correposning `mul_*child` would be null, and the dereference in the subsequent line would be incorrect. We have a similar issue during `IsIdentityConsumingSwitch`. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "filename": "constant_folding.cc",
        "diff": "diff --git a/tensorflow/core/grappler/optimizers/constant_folding.cc b/tensorflow/core/grappler/optimizers/constant_folding.cc\nindex 281806be20259f..a05823f71d09f4 100644\n--- a/tensorflow/core/grappler/optimizers/constant_folding.cc\n+++ b/tensorflow/core/grappler/optimizers/constant_folding.cc\n@@ -3505,6 +3505,9 @@ bool ConstantFolding::MulConvPushDown(GraphDef* optimized_graph, NodeDef* node,\n \n   NodeDef* mul_left_child = node_map_->GetNode(node->input(0));\n   NodeDef* mul_right_child = node_map_->GetNode(node->input(1));\n+  if (mul_left_child == nullptr || mul_right_child == nullptr) {\n+    return false;\n+  }\n   // One child must be constant, and the second must be Conv op.\n   const bool left_child_is_constant = IsReallyConstant(*mul_left_child);\n   const bool right_child_is_constant = IsReallyConstant(*mul_right_child);\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "adbbabdb0d3abb3cdeac69e38a96de1d678b24b3",
        "repo": "tensorflow/tensorflow",
        "msg": "Further validate sparse tensor for `SparseCount`: indices must be valid within dense shape.\n\nPiperOrigin-RevId: 414888122\nChange-Id: I4552bd74c135ecd4bcb5448acc0a3ce9402d8286Tensorflow is an Open Source Machine Learning Framework. The implementation of `SparseCountSparseOutput` is vulnerable to a heap overflow. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "filename": "count_ops.cc",
        "diff": "diff --git a/tensorflow/core/kernels/count_ops.cc b/tensorflow/core/kernels/count_ops.cc\nindex 1f99e0783e26f6..cc101b66f81403 100644\n--- a/tensorflow/core/kernels/count_ops.cc\n+++ b/tensorflow/core/kernels/count_ops.cc\n@@ -206,6 +206,23 @@ class SparseCount : public OpKernel {\n     OP_REQUIRES(context, shape.NumElements() > 0,\n                 errors::InvalidArgument(\n                     \"The shape argument requires at least one element.\"));\n+    // Validate indices: each index must be valid for the corresponding\n+    // dimension. This could be possibly done better.\n+    const auto indices_values = indices.matrix<int64_t>();\n+    const auto shape_vector = shape.vec<int64_t>();\n+    int num_values = values.NumElements();  // same as first dim of indices\n+    int rank = indices.shape().dim_size(1);\n+    for (int i = 0; i < num_values; ++i) {\n+      for (int j = 0; j < rank; ++j) {\n+        OP_REQUIRES(\n+            context,\n+            indices_values(i, j) >= 0 && indices_values(i, j) < shape_vector(j),\n+            errors::InvalidArgument(\n+                \"Invalid index value at \", i, \": dimension \", j, \" has value \",\n+                indices_values(i, j), \" which is not in [0, \", shape_vector(j),\n+                \") (as given by dense shape \", shape.DebugString()));\n+      }\n+    }\n \n     if (use_weights) {\n       OP_REQUIRES(\n@@ -217,11 +234,8 @@ class SparseCount : public OpKernel {\n     }\n \n     bool is_1d = shape.NumElements() == 1;\n-    auto shape_vector = shape.flat<int64_t>();\n     int num_batches = is_1d ? 1 : shape_vector(0);\n-    int num_values = values.NumElements();\n \n-    const auto indices_values = indices.matrix<int64_t>();\n     const auto values_values = values.flat<T>();\n     const auto weight_values = weights.flat<W>();\n \n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "ef1d027be116f25e25bb94a60da491c2cf55bd0b",
        "repo": "tensorflow/tensorflow",
        "msg": "Prevent copying uninitialized data in `AssignOp`.\n\nThis prevents harder to debug undefined behaviors that cannot be traced back to the original tensor after assignments occur earlier in the graph execution. Several of these undefined behaviors are just reference bindings to null pointers, which are caught when running under ubsan/asan.\n\nPiperOrigin-RevId: 408654780\nChange-Id: Iad2ec40d43f5fd7ea016c20283356c12d5ddeab1Tensorflow is an Open Source Machine Learning Framework. The implementation of `AssignOp` can result in copying uninitialized data to a new tensor. This later results in undefined behavior. The implementation has a check that the left hand side of the assignment is initialized (to minimize number of allocations), but does not check that the right hand side is also initialized. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "filename": "assign_op.h",
        "diff": "diff --git a/tensorflow/core/kernels/assign_op.h b/tensorflow/core/kernels/assign_op.h\nindex ca822a58cdacc4..1e84436b27e0d8 100644\n--- a/tensorflow/core/kernels/assign_op.h\n+++ b/tensorflow/core/kernels/assign_op.h\n@@ -50,6 +50,12 @@ class AssignOp : public OpKernel {\n     // We always return the input ref.\n     context->forward_ref_input_to_ref_output(0, 0);\n \n+    // Prevent copying uninitialized data, to solve harder to debug undefined\n+    // behaviors that cannot be traced back to the original tensor.\n+    OP_REQUIRES(\n+        context, rhs.IsInitialized(),\n+        errors::Internal(\"Right hand side of AssignOp is not initialized\"));\n+\n     // We can't always know how this value will be used downstream, so make\n     // conservative assumptions in specifying constraints on the memory\n     // allocation attributes, unless the Grappler graph analysis determined that\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "ae3c99767a27f5c6c584162e2adc6a5d0eb2c54e",
        "repo": "mruby/mruby",
        "msg": "codegen.c: fixed a bug in hash code generation with `!val`.NULL Pointer Dereference in Homebrew mruby prior to 3.2.",
        "filename": "codegen.c",
        "diff": "diff --git a/mrbgems/mruby-compiler/core/codegen.c b/mrbgems/mruby-compiler/core/codegen.c\nindex 8c906fa21c..a7420a62ba 100644\n--- a/mrbgems/mruby-compiler/core/codegen.c\n+++ b/mrbgems/mruby-compiler/core/codegen.c\n@@ -1603,7 +1603,7 @@ gen_hash(codegen_scope *s, node *tree, int val, int limit)\n \n   while (tree) {\n     if (nint(tree->car->car->car) == NODE_KW_REST_ARGS) {\n-      if (len > 0) {\n+      if (val && len > 0) {\n         pop_n(len*2);\n         if (!update) {\n           genop_2(s, OP_HASH, cursp(), len);\n@@ -1615,7 +1615,7 @@ gen_hash(codegen_scope *s, node *tree, int val, int limit)\n         push();\n       }\n       codegen(s, tree->car->cdr, val);\n-      if (len > 0 || update) {\n+      if (val && (len > 0 || update)) {\n         pop(); pop();\n         genop_1(s, OP_HASHCAT, cursp());\n         push();\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "f57315566d7094f322b784947093406c2aea0d7d",
        "repo": "tensorflow/tensorflow",
        "msg": "Add a check for Key being scalar tensor for MapStage and OrderedMapStage ops.\n\nAccording to documentation[1][2], key must be int64 value, but this wasn't enforced and the ops would fail with check failure for non-scalar key value.\n\n[1]https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/ordered-map-stage\n[2]https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/map-stage\n\nPiperOrigin-RevId: 413822112\nChange-Id: I9d118faf990e6361900aa32272eff486ad9f0e2eTensorflow is an Open Source Machine Learning Framework. The implementation of `MapStage` is vulnerable a `CHECK`-fail if the key tensor is not a scalar. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "filename": "map_stage_op.cc",
        "diff": "diff --git a/tensorflow/core/kernels/map_stage_op.cc b/tensorflow/core/kernels/map_stage_op.cc\nindex aee53ae78d3af8..463e2a8ced5c2d 100644\n--- a/tensorflow/core/kernels/map_stage_op.cc\n+++ b/tensorflow/core/kernels/map_stage_op.cc\n@@ -536,6 +536,11 @@ class MapStageOp : public OpKernel {\n     OP_REQUIRES(ctx, key_tensor->NumElements() > 0,\n                 errors::InvalidArgument(\"key must not be empty\"));\n \n+    OP_REQUIRES(ctx, key_tensor->NumElements() == 1,\n+                errors::InvalidArgument(\n+                    \"key must be an int64 scalar, got tensor with shape: \",\n+                    key_tensor->shape()));\n+\n     // Create copy for insertion into Staging Area\n     Tensor key(*key_tensor);\n \ndiff --git a/tensorflow/python/kernel_tests/data_structures/map_stage_op_test.py b/tensorflow/python/kernel_tests/data_structures/map_stage_op_test.py\nindex 313b5244ee15c3..8600ad1f8d726b 100644\n--- a/tensorflow/python/kernel_tests/data_structures/map_stage_op_test.py\n+++ b/tensorflow/python/kernel_tests/data_structures/map_stage_op_test.py\n@@ -12,8 +12,11 @@\n # See the License for the specific language governing permissions and\n # limitations under the License.\n # ==============================================================================\n-from tensorflow.python.framework import errors\n+import numpy as np\n+\n+from tensorflow.python.framework import constant_op\n from tensorflow.python.framework import dtypes\n+from tensorflow.python.framework import errors\n from tensorflow.python.framework import ops\n from tensorflow.python.framework import test_util\n from tensorflow.python.ops import array_ops\n@@ -28,7 +31,7 @@ class MapStageTest(test.TestCase):\n \n   @test_util.run_deprecated_v1\n   def testSimple(self):\n-    with ops.Graph().as_default() as G:\n+    with ops.Graph().as_default() as g:\n       with ops.device('/cpu:0'):\n         x = array_ops.placeholder(dtypes.float32)\n         pi = array_ops.placeholder(dtypes.int64)\n@@ -40,9 +43,9 @@ def testSimple(self):\n         k, y = stager.get(gi)\n         y = math_ops.reduce_max(math_ops.matmul(y, y))\n \n-    G.finalize()\n+    g.finalize()\n \n-    with self.session(graph=G) as sess:\n+    with self.session(graph=g) as sess:\n       sess.run(stage, feed_dict={x: -1, pi: 0})\n       for i in range(10):\n         _, yval = sess.run([stage, y], feed_dict={x: i, pi: i + 1, gi: i})\n@@ -50,7 +53,7 @@ def testSimple(self):\n \n   @test_util.run_deprecated_v1\n   def testMultiple(self):\n-    with ops.Graph().as_default() as G:\n+    with ops.Graph().as_default() as g:\n       with ops.device('/cpu:0'):\n         x = array_ops.placeholder(dtypes.float32)\n         pi = array_ops.placeholder(dtypes.int64)\n@@ -62,9 +65,9 @@ def testMultiple(self):\n         k, (z, y) = stager.get(gi)\n         y = math_ops.reduce_max(z * math_ops.matmul(y, y))\n \n-    G.finalize()\n+    g.finalize()\n \n-    with self.session(graph=G) as sess:\n+    with self.session(graph=g) as sess:\n       sess.run(stage, feed_dict={x: -1, pi: 0})\n       for i in range(10):\n         _, yval = sess.run([stage, y], feed_dict={x: i, pi: i + 1, gi: i})\n@@ -73,26 +76,25 @@ def testMultiple(self):\n \n   @test_util.run_deprecated_v1\n   def testDictionary(self):\n-    with ops.Graph().as_default() as G:\n+    with ops.Graph().as_default() as g:\n       with ops.device('/cpu:0'):\n         x = array_ops.placeholder(dtypes.float32)\n         pi = array_ops.placeholder(dtypes.int64)\n         gi = array_ops.placeholder(dtypes.int64)\n         v = 2. * (array_ops.zeros([128, 128]) + x)\n       with ops.device(test.gpu_device_name()):\n-        stager = data_flow_ops.MapStagingArea(\n-            [dtypes.float32, dtypes.float32],\n-            shapes=[[], [128, 128]],\n-            names=['x', 'v'])\n+        stager = data_flow_ops.MapStagingArea([dtypes.float32, dtypes.float32],\n+                                              shapes=[[], [128, 128]],\n+                                              names=['x', 'v'])\n         stage = stager.put(pi, {'x': x, 'v': v})\n         key, ret = stager.get(gi)\n         z = ret['x']\n         y = ret['v']\n         y = math_ops.reduce_max(z * math_ops.matmul(y, y))\n \n-    G.finalize()\n+    g.finalize()\n \n-    with self.session(graph=G) as sess:\n+    with self.session(graph=g) as sess:\n       sess.run(stage, feed_dict={x: -1, pi: 0})\n       for i in range(10):\n         _, yval = sess.run([stage, y], feed_dict={x: i, pi: i + 1, gi: i})\n@@ -102,7 +104,7 @@ def testDictionary(self):\n   def testColocation(self):\n     gpu_dev = test.gpu_device_name()\n \n-    with ops.Graph().as_default() as G:\n+    with ops.Graph().as_default() as g:\n       with ops.device('/cpu:0'):\n         x = array_ops.placeholder(dtypes.float32)\n         v = 2. * (array_ops.zeros([128, 128]) + x)\n@@ -119,58 +121,56 @@ def testColocation(self):\n         self.assertEqual(y.device, '/device:CPU:0')\n         self.assertEqual(z[0].device, '/device:CPU:0')\n \n-    G.finalize()\n+    g.finalize()\n \n   @test_util.run_deprecated_v1\n   def testPeek(self):\n-    with ops.Graph().as_default() as G:\n+    with ops.Graph().as_default() as g:\n       with ops.device('/cpu:0'):\n         x = array_ops.placeholder(dtypes.int32, name='x')\n         pi = array_ops.placeholder(dtypes.int64)\n         gi = array_ops.placeholder(dtypes.int64)\n         p = array_ops.placeholder(dtypes.int32, name='p')\n       with ops.device(test.gpu_device_name()):\n-        stager = data_flow_ops.MapStagingArea(\n-            [\n-                dtypes.int32,\n-            ], shapes=[[]])\n+        stager = data_flow_ops.MapStagingArea([\n+            dtypes.int32,\n+        ], shapes=[[]])\n         stage = stager.put(pi, [x], [0])\n         peek = stager.peek(gi)\n         size = stager.size()\n \n-    G.finalize()\n+    g.finalize()\n \n     n = 10\n \n-    with self.session(graph=G) as sess:\n+    with self.session(graph=g) as sess:\n       for i in range(n):\n         sess.run(stage, feed_dict={x: i, pi: i})\n \n       for i in range(n):\n-        self.assertTrue(sess.run(peek, feed_dict={gi: i})[0] == i)\n+        self.assertEqual(sess.run(peek, feed_dict={gi: i})[0], i)\n \n-      self.assertTrue(sess.run(size) == 10)\n+      self.assertEqual(sess.run(size), 10)\n \n   @test_util.run_deprecated_v1\n   def testSizeAndClear(self):\n-    with ops.Graph().as_default() as G:\n+    with ops.Graph().as_default() as g:\n       with ops.device('/cpu:0'):\n         x = array_ops.placeholder(dtypes.float32, name='x')\n         pi = array_ops.placeholder(dtypes.int64)\n         gi = array_ops.placeholder(dtypes.int64)\n         v = 2. * (array_ops.zeros([128, 128]) + x)\n       with ops.device(test.gpu_device_name()):\n-        stager = data_flow_ops.MapStagingArea(\n-            [dtypes.float32, dtypes.float32],\n-            shapes=[[], [128, 128]],\n-            names=['x', 'v'])\n+        stager = data_flow_ops.MapStagingArea([dtypes.float32, dtypes.float32],\n+                                              shapes=[[], [128, 128]],\n+                                              names=['x', 'v'])\n         stage = stager.put(pi, {'x': x, 'v': v})\n         size = stager.size()\n         clear = stager.clear()\n \n-    G.finalize()\n+    g.finalize()\n \n-    with self.session(graph=G) as sess:\n+    with self.session(graph=g) as sess:\n       sess.run(stage, feed_dict={x: -1, pi: 3})\n       self.assertEqual(sess.run(size), 1)\n       sess.run(stage, feed_dict={x: -1, pi: 1})\n@@ -182,22 +182,23 @@ def testSizeAndClear(self):\n   def testCapacity(self):\n     capacity = 3\n \n-    with ops.Graph().as_default() as G:\n+    with ops.Graph().as_default() as g:\n       with ops.device('/cpu:0'):\n         x = array_ops.placeholder(dtypes.int32, name='x')\n         pi = array_ops.placeholder(dtypes.int64, name='pi')\n         gi = array_ops.placeholder(dtypes.int64, name='gi')\n       with ops.device(test.gpu_device_name()):\n-        stager = data_flow_ops.MapStagingArea(\n-            [\n-                dtypes.int32,\n-            ], capacity=capacity, shapes=[[]])\n+        stager = data_flow_ops.MapStagingArea([\n+            dtypes.int32,\n+        ],\n+                                              capacity=capacity,\n+                                              shapes=[[]])\n \n       stage = stager.put(pi, [x], [0])\n       get = stager.get()\n       size = stager.size()\n \n-    G.finalize()\n+    g.finalize()\n \n     from six.moves import queue as Queue\n     import threading\n@@ -205,7 +206,7 @@ def testCapacity(self):\n     queue = Queue.Queue()\n     n = 8\n \n-    with self.session(graph=G) as sess:\n+    with self.session(graph=g) as sess:\n       # Stage data in a separate thread which will block\n       # when it hits the staging area's capacity and thus\n       # not fill the queue with n tokens\n@@ -234,13 +235,13 @@ def thread_run():\n                                              capacity))\n \n       # Should have capacity elements in the staging area\n-      self.assertTrue(sess.run(size) == capacity)\n+      self.assertEqual(sess.run(size), capacity)\n \n       # Clear the staging area completely\n       for i in range(n):\n         sess.run(get)\n \n-      self.assertTrue(sess.run(size) == 0)\n+      self.assertEqual(sess.run(size), 0)\n \n   @test_util.run_deprecated_v1\n   def testMemoryLimit(self):\n@@ -248,28 +249,28 @@ def testMemoryLimit(self):\n     chunk = 200 * 1024  # 256K\n     capacity = memory_limit // chunk\n \n-    with ops.Graph().as_default() as G:\n+    with ops.Graph().as_default() as g:\n       with ops.device('/cpu:0'):\n         x = array_ops.placeholder(dtypes.uint8, name='x')\n         pi = array_ops.placeholder(dtypes.int64, name='pi')\n         gi = array_ops.placeholder(dtypes.int64, name='gi')\n       with ops.device(test.gpu_device_name()):\n-        stager = data_flow_ops.MapStagingArea(\n-            [dtypes.uint8], memory_limit=memory_limit, shapes=[[]])\n+        stager = data_flow_ops.MapStagingArea([dtypes.uint8],\n+                                              memory_limit=memory_limit,\n+                                              shapes=[[]])\n         stage = stager.put(pi, [x], [0])\n         get = stager.get()\n         size = stager.size()\n \n-    G.finalize()\n+    g.finalize()\n \n     from six.moves import queue as Queue\n     import threading\n-    import numpy as np\n \n     queue = Queue.Queue()\n     n = 8\n \n-    with self.session(graph=G) as sess:\n+    with self.session(graph=g) as sess:\n       # Stage data in a separate thread which will block\n       # when it hits the staging area's capacity and thus\n       # not fill the queue with n tokens\n@@ -299,56 +300,57 @@ def thread_run():\n                                              capacity))\n \n       # Should have capacity elements in the staging area\n-      self.assertTrue(sess.run(size) == capacity)\n+      self.assertEqual(sess.run(size), capacity)\n \n       # Clear the staging area completely\n       for i in range(n):\n         sess.run(get)\n \n-      self.assertTrue(sess.run(size) == 0)\n+      self.assertEqual(sess.run(size), 0)\n \n   @test_util.run_deprecated_v1\n   def testOrdering(self):\n     import six\n     import random\n \n-    with ops.Graph().as_default() as G:\n+    with ops.Graph().as_default() as g:\n       with ops.device('/cpu:0'):\n         x = array_ops.placeholder(dtypes.int32, name='x')\n         pi = array_ops.placeholder(dtypes.int64, name='pi')\n         gi = array_ops.placeholder(dtypes.int64, name='gi')\n       with ops.device(test.gpu_device_name()):\n-        stager = data_flow_ops.MapStagingArea(\n-            [\n-                dtypes.int32,\n-            ], shapes=[[]], ordered=True)\n+        stager = data_flow_ops.MapStagingArea([\n+            dtypes.int32,\n+        ],\n+                                              shapes=[[]],\n+                                              ordered=True)\n         stage = stager.put(pi, [x], [0])\n         get = stager.get()\n         size = stager.size()\n \n-    G.finalize()\n+    g.finalize()\n \n     n = 10\n \n-    with self.session(graph=G) as sess:\n+    with self.session(graph=g) as sess:\n       # Keys n-1..0\n       keys = list(reversed(six.moves.range(n)))\n \n       for i in keys:\n         sess.run(stage, feed_dict={pi: i, x: i})\n \n-      self.assertTrue(sess.run(size) == n)\n+      self.assertEqual(sess.run(size), n)\n \n       # Check that key, values come out in ascending order\n       for i, k in enumerate(reversed(keys)):\n         get_key, values = sess.run(get)\n         self.assertTrue(i == k == get_key == values)\n \n-      self.assertTrue(sess.run(size) == 0)\n+      self.assertEqual(sess.run(size), 0)\n \n   @test_util.run_deprecated_v1\n   def testPartialDictInsert(self):\n-    with ops.Graph().as_default() as G:\n+    with ops.Graph().as_default() as g:\n       with ops.device('/cpu:0'):\n         x = array_ops.placeholder(dtypes.float32)\n         f = array_ops.placeholder(dtypes.float32)\n@@ -366,41 +368,39 @@ def testPartialDictInsert(self):\n         size = stager.size()\n         isize = stager.incomplete_size()\n \n-    G.finalize()\n+    g.finalize()\n \n-    with self.session(graph=G) as sess:\n+    with self.session(graph=g) as sess:\n       # 0 complete and incomplete entries\n-      self.assertTrue(sess.run([size, isize]) == [0, 0])\n+      self.assertEqual(sess.run([size, isize]), [0, 0])\n       # Stage key 0, x and f tuple entries\n       sess.run(stage_xf, feed_dict={pi: 0, x: 1, f: 2})\n-      self.assertTrue(sess.run([size, isize]) == [0, 1])\n+      self.assertEqual(sess.run([size, isize]), [0, 1])\n       # Stage key 1, x and f tuple entries\n       sess.run(stage_xf, feed_dict={pi: 1, x: 1, f: 2})\n-      self.assertTrue(sess.run([size, isize]) == [0, 2])\n+      self.assertEqual(sess.run([size, isize]), [0, 2])\n \n       # Now complete key 0 with tuple entry v\n       sess.run(stage_v, feed_dict={pi: 0, v: 1})\n       # 1 complete and 1 incomplete entry\n-      self.assertTrue(sess.run([size, isize]) == [1, 1])\n+      self.assertEqual(sess.run([size, isize]), [1, 1])\n       # We can now obtain tuple associated with key 0\n-      self.assertTrue(\n-          sess.run([key, ret], feed_dict={\n-              gi: 0\n-          }) == [0, {\n+      self.assertEqual(\n+          sess.run([key, ret], feed_dict={gi: 0}),\n+          [0, {\n               'x': 1,\n               'f': 2,\n               'v': 1\n           }])\n \n       # 0 complete and 1 incomplete entry\n-      self.assertTrue(sess.run([size, isize]) == [0, 1])\n+      self.assertEqual(sess.run([size, isize]), [0, 1])\n       # Now complete key 1 with tuple entry v\n       sess.run(stage_v, feed_dict={pi: 1, v: 3})\n       # We can now obtain tuple associated with key 1\n-      self.assertTrue(\n-          sess.run([key, ret], feed_dict={\n-              gi: 1\n-          }) == [1, {\n+      self.assertEqual(\n+          sess.run([key, ret], feed_dict={gi: 1}),\n+          [1, {\n               'x': 1,\n               'f': 2,\n               'v': 3\n@@ -408,7 +408,7 @@ def testPartialDictInsert(self):\n \n   @test_util.run_deprecated_v1\n   def testPartialIndexInsert(self):\n-    with ops.Graph().as_default() as G:\n+    with ops.Graph().as_default() as g:\n       with ops.device('/cpu:0'):\n         x = array_ops.placeholder(dtypes.float32)\n         f = array_ops.placeholder(dtypes.float32)\n@@ -424,35 +424,35 @@ def testPartialIndexInsert(self):\n         size = stager.size()\n         isize = stager.incomplete_size()\n \n-    G.finalize()\n+    g.finalize()\n \n-    with self.session(graph=G) as sess:\n+    with self.session(graph=g) as sess:\n       # 0 complete and incomplete entries\n-      self.assertTrue(sess.run([size, isize]) == [0, 0])\n+      self.assertEqual(sess.run([size, isize]), [0, 0])\n       # Stage key 0, x and f tuple entries\n       sess.run(stage_xf, feed_dict={pi: 0, x: 1, f: 2})\n-      self.assertTrue(sess.run([size, isize]) == [0, 1])\n+      self.assertEqual(sess.run([size, isize]), [0, 1])\n       # Stage key 1, x and f tuple entries\n       sess.run(stage_xf, feed_dict={pi: 1, x: 1, f: 2})\n-      self.assertTrue(sess.run([size, isize]) == [0, 2])\n+      self.assertEqual(sess.run([size, isize]), [0, 2])\n \n       # Now complete key 0 with tuple entry v\n       sess.run(stage_v, feed_dict={pi: 0, v: 1})\n       # 1 complete and 1 incomplete entry\n-      self.assertTrue(sess.run([size, isize]) == [1, 1])\n+      self.assertEqual(sess.run([size, isize]), [1, 1])\n       # We can now obtain tuple associated with key 0\n-      self.assertTrue(sess.run([key, ret], feed_dict={gi: 0}) == [0, [1, 1, 2]])\n+      self.assertEqual(sess.run([key, ret], feed_dict={gi: 0}), [0, [1, 1, 2]])\n \n       # 0 complete and 1 incomplete entry\n-      self.assertTrue(sess.run([size, isize]) == [0, 1])\n+      self.assertEqual(sess.run([size, isize]), [0, 1])\n       # Now complete key 1 with tuple entry v\n       sess.run(stage_v, feed_dict={pi: 1, v: 3})\n       # We can now obtain tuple associated with key 1\n-      self.assertTrue(sess.run([key, ret], feed_dict={gi: 1}) == [1, [1, 3, 2]])\n+      self.assertEqual(sess.run([key, ret], feed_dict={gi: 1}), [1, [1, 3, 2]])\n \n   @test_util.run_deprecated_v1\n   def testPartialDictGetsAndPeeks(self):\n-    with ops.Graph().as_default() as G:\n+    with ops.Graph().as_default() as g:\n       with ops.device('/cpu:0'):\n         x = array_ops.placeholder(dtypes.float32)\n         f = array_ops.placeholder(dtypes.float32)\n@@ -476,40 +476,38 @@ def testPartialDictGetsAndPeeks(self):\n         size = stager.size()\n         isize = stager.incomplete_size()\n \n-    G.finalize()\n+    g.finalize()\n \n-    with self.session(graph=G) as sess:\n+    with self.session(graph=g) as sess:\n       # 0 complete and incomplete entries\n-      self.assertTrue(sess.run([size, isize]) == [0, 0])\n+      self.assertEqual(sess.run([size, isize]), [0, 0])\n       # Stage key 0, x and f tuple entries\n       sess.run(stage_xf, feed_dict={pi: 0, x: 1, f: 2})\n-      self.assertTrue(sess.run([size, isize]) == [0, 1])\n+      self.assertEqual(sess.run([size, isize]), [0, 1])\n       # Stage key 1, x and f tuple entries\n       sess.run(stage_xf, feed_dict={pi: 1, x: 1, f: 2})\n-      self.assertTrue(sess.run([size, isize]) == [0, 2])\n+      self.assertEqual(sess.run([size, isize]), [0, 2])\n \n       # Now complete key 0 with tuple entry v\n       sess.run(stage_v, feed_dict={pi: 0, v: 1})\n       # 1 complete and 1 incomplete entry\n-      self.assertTrue(sess.run([size, isize]) == [1, 1])\n+      self.assertEqual(sess.run([size, isize]), [1, 1])\n \n       # We can now peek at 'x' and 'f' values associated with key 0\n-      self.assertTrue(sess.run(peek_xf, feed_dict={pei: 0}) == {'x': 1, 'f': 2})\n+      self.assertEqual(sess.run(peek_xf, feed_dict={pei: 0}), {'x': 1, 'f': 2})\n       # Peek at 'v' value associated with key 0\n-      self.assertTrue(sess.run(peek_v, feed_dict={pei: 0}) == {'v': 1})\n+      self.assertEqual(sess.run(peek_v, feed_dict={pei: 0}), {'v': 1})\n       # 1 complete and 1 incomplete entry\n-      self.assertTrue(sess.run([size, isize]) == [1, 1])\n+      self.assertEqual(sess.run([size, isize]), [1, 1])\n \n       # We can now obtain 'x' and 'f' values associated with key 0\n-      self.assertTrue(\n-          sess.run([key_xf, get_xf], feed_dict={\n-              gi: 0\n-          }) == [0, {\n+      self.assertEqual(\n+          sess.run([key_xf, get_xf], feed_dict={gi: 0}), [0, {\n               'x': 1,\n               'f': 2\n           }])\n       # Still have 1 complete and 1 incomplete entry\n-      self.assertTrue(sess.run([size, isize]) == [1, 1])\n+      self.assertEqual(sess.run([size, isize]), [1, 1])\n \n       # We can no longer get 'x' and 'f' from key 0\n       with self.assertRaises(errors.InvalidArgumentError) as cm:\n@@ -517,40 +515,36 @@ def testPartialDictGetsAndPeeks(self):\n \n       exc_str = (\"Tensor at index '0' for key '0' \" 'has already been removed.')\n \n-      self.assertTrue(exc_str in cm.exception.message)\n+      self.assertIn(exc_str, cm.exception.message)\n \n       # Obtain 'v' value associated with key 0\n-      self.assertTrue(\n-          sess.run([key_v, get_v], feed_dict={\n-              gi: 0\n-          }) == [0, {\n+      self.assertEqual(\n+          sess.run([key_v, get_v], feed_dict={gi: 0}), [0, {\n               'v': 1\n           }])\n       # 0 complete and 1 incomplete entry\n-      self.assertTrue(sess.run([size, isize]) == [0, 1])\n+      self.assertEqual(sess.run([size, isize]), [0, 1])\n \n       # Now complete key 1 with tuple entry v\n       sess.run(stage_v, feed_dict={pi: 1, v: 1})\n       # 1 complete and 1 incomplete entry\n-      self.assertTrue(sess.run([size, isize]) == [1, 0])\n+      self.assertEqual(sess.run([size, isize]), [1, 0])\n \n       # Pop without key to obtain 'x' and 'f' values associated with key 1\n-      self.assertTrue(sess.run([pop_key_xf, pop_xf]) == [1, {'x': 1, 'f': 2}])\n+      self.assertEqual(sess.run([pop_key_xf, pop_xf]), [1, {'x': 1, 'f': 2}])\n       # still 1 complete and 1 incomplete entry\n-      self.assertTrue(sess.run([size, isize]) == [1, 0])\n+      self.assertEqual(sess.run([size, isize]), [1, 0])\n       # We can now obtain 'x' and 'f' values associated with key 1\n-      self.assertTrue(\n-          sess.run([pop_key_v, pop_v], feed_dict={\n-              pi: 1\n-          }) == [1, {\n+      self.assertEqual(\n+          sess.run([pop_key_v, pop_v], feed_dict={pi: 1}), [1, {\n               'v': 1\n           }])\n       # Nothing is left\n-      self.assertTrue(sess.run([size, isize]) == [0, 0])\n+      self.assertEqual(sess.run([size, isize]), [0, 0])\n \n   @test_util.run_deprecated_v1\n   def testPartialIndexGets(self):\n-    with ops.Graph().as_default() as G:\n+    with ops.Graph().as_default() as g:\n       with ops.device('/cpu:0'):\n         x = array_ops.placeholder(dtypes.float32)\n         f = array_ops.placeholder(dtypes.float32)\n@@ -568,28 +562,72 @@ def testPartialIndexGets(self):\n         size = stager.size()\n         isize = stager.incomplete_size()\n \n-    G.finalize()\n+    g.finalize()\n \n-    with self.session(graph=G) as sess:\n+    with self.session(graph=g) as sess:\n       # Stage complete tuple\n       sess.run(stage_xvf, feed_dict={pi: 0, x: 1, f: 2, v: 3})\n \n-      self.assertTrue(sess.run([size, isize]) == [1, 0])\n+      self.assertEqual(sess.run([size, isize]), [1, 0])\n \n       # Partial get using indices\n-      self.assertTrue(\n-          sess.run([key_xf, get_xf], feed_dict={\n-              gi: 0\n-          }) == [0, [1, 2]])\n+      self.assertEqual(\n+          sess.run([key_xf, get_xf], feed_dict={gi: 0}), [0, [1, 2]])\n \n       # Still some of key 0 left\n-      self.assertTrue(sess.run([size, isize]) == [1, 0])\n+      self.assertEqual(sess.run([size, isize]), [1, 0])\n \n       # Partial get of remaining index\n-      self.assertTrue(sess.run([key_v, get_v], feed_dict={gi: 0}) == [0, [3]])\n+      self.assertEqual(sess.run([key_v, get_v], feed_dict={gi: 0}), [0, [3]])\n \n       # All gone\n-      self.assertTrue(sess.run([size, isize]) == [0, 0])\n+      self.assertEqual(sess.run([size, isize]), [0, 0])\n+\n+  @test_util.run_deprecated_v1\n+  def testNonScalarKeyOrderedMap(self):\n+    with ops.Graph().as_default() as g:\n+      x = array_ops.placeholder(dtypes.float32)\n+      v = 2. * (array_ops.zeros([128, 128]) + x)\n+      t = data_flow_ops.gen_data_flow_ops.ordered_map_stage(\n+          key=constant_op.constant(value=[1], shape=(1, 3), dtype=dtypes.int64),\n+          indices=np.array([[6]]),\n+          values=[x, v],\n+          dtypes=[dtypes.int64],\n+          capacity=0,\n+          memory_limit=0,\n+          container='container1',\n+          shared_name='',\n+          name=None)\n+\n+    g.finalize()\n+\n+    with self.session(graph=g) as sess:\n+      with self.assertRaisesRegex(errors.InvalidArgumentError,\n+                                  'key must be an int64 scalar'):\n+        sess.run(t, feed_dict={x: 1})\n+\n+  @test_util.run_deprecated_v1\n+  def testNonScalarKeyUnorderedMap(self):\n+    with ops.Graph().as_default() as g:\n+      x = array_ops.placeholder(dtypes.float32)\n+      v = 2. * (array_ops.zeros([128, 128]) + x)\n+      t = data_flow_ops.gen_data_flow_ops.map_stage(\n+          key=constant_op.constant(value=[1], shape=(1, 3), dtype=dtypes.int64),\n+          indices=np.array([[6]]),\n+          values=[x, v],\n+          dtypes=[dtypes.int64],\n+          capacity=0,\n+          memory_limit=0,\n+          container='container1',\n+          shared_name='',\n+          name=None)\n+\n+    g.finalize()\n+\n+    with self.session(graph=g) as sess:\n+      with self.assertRaisesRegex(errors.InvalidArgumentError,\n+                                  'key must be an int64 scalar'):\n+        sess.run(t, feed_dict={x: 1})\n \n \n if __name__ == '__main__':\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "c8c083cb750606b2da81582cd8e43b442bb143e6",
        "repo": "mruby/mruby",
        "msg": "codegen.c: need to pack argument when `n==13` too.\n\nBecause we have extra 2 arguments coming (kw and rhs).Out-of-bounds Read in mrb_get_args in GitHub repository mruby/mruby prior to 3.2. Possible arbitrary code execution if being exploited.",
        "filename": "codegen.c",
        "diff": "diff --git a/mrbgems/mruby-compiler/core/codegen.c b/mrbgems/mruby-compiler/core/codegen.c\nindex 8f7b5b0133..e222094be3 100644\n--- a/mrbgems/mruby-compiler/core/codegen.c\n+++ b/mrbgems/mruby-compiler/core/codegen.c\n@@ -1905,7 +1905,7 @@ gen_assignment(codegen_scope *s, node *tree, node *rhs, int sp, int val)\n           }\n         }\n         if (tree->cdr->car) {       /* keyword arguments */\n-          if (n == 14) {\n+          if (n == 13 || n == 14) {\n             pop_n(n);\n             genop_2(s, OP_ARRAY, cursp(), n);\n             push();\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "03fca626a95130ab80f86adada54b29d27242759",
        "repo": "uWebSockets/uWebSockets",
        "msg": "Fix overflow of triggered topicsuWebSockets 18.11.0 and 18.12.0 has a stack-based buffer overflow in uWS::TopicTree::trimTree (called from uWS::TopicTree::unsubscribeAll). NOTE: the vendor's position is that this is \"a minor issue or not even an issue at all\" because the developer of an application (that uses uWebSockets) should not be allowing the large number of triggered topics to accumulate",
        "filename": "TopicTree.h",
        "diff": "diff --git a/src/TopicTree.h b/src/TopicTree.h\nindex 0b945b348..80dd180da 100644\n--- a/src/TopicTree.h\n+++ b/src/TopicTree.h\n@@ -124,10 +124,6 @@ struct TopicTree {\n \n     /* Should be getData and commit? */\n     void publish(Topic *iterator, size_t start, size_t stop, std::string_view topic, std::pair<std::string_view, std::string_view> message) {\n-        /* If we already have 64 triggered topics make sure to drain it here */\n-        if (numTriggeredTopics == 64) {\n-            drain();\n-        }\n \n         /* Iterate over all segments in given topic */\n         for (; stop != std::string::npos; start = stop + 1) {\n@@ -151,6 +147,11 @@ struct TopicTree {\n \n                 /* Add this topic to triggered */\n                 if (!iterator->terminatingWildcardChild->triggered) {\n+                    /* If we already have 64 triggered topics make sure to drain it here */\n+                    if (numTriggeredTopics == 64) {\n+                        drain();\n+                    }\n+\n                     triggeredTopics[numTriggeredTopics++] = iterator->terminatingWildcardChild;\n                     iterator->terminatingWildcardChild->triggered = true;\n                 }\n@@ -175,6 +176,11 @@ struct TopicTree {\n \n         /* Add this topic to triggered */\n         if (!iterator->triggered) {\n+            /* If we already have 64 triggered topics make sure to drain it here */\n+            if (numTriggeredTopics == 64) {\n+                drain();\n+            }\n+\n             triggeredTopics[numTriggeredTopics++] = iterator;\n             iterator->triggered = true;\n         }\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "37897226a1a31f982bfefdc4aeefc2e50355c73c",
        "repo": "radare/radare2",
        "msg": "Fix use-after-free in iobank rbtree usage ##io\n\n* See havoc4 bin for reproducer\n* Reported via huntr.dev by 'Cen Zhang'Use After Free in GitHub repository radareorg/radare2 prior to 5.6.0.",
        "filename": "io_bank.c",
        "diff": "diff --git a/libr/io/io_bank.c b/libr/io/io_bank.c\nindex 228e422d65633..882dfc48d18f0 100644\n--- a/libr/io/io_bank.c\n+++ b/libr/io/io_bank.c\n@@ -230,7 +230,10 @@ R_API bool r_io_bank_map_add_top(RIO *io, const ut32 bankid, const ut32 mapid) {\n \t\t//delete all submaps that are completly included in sm\n \t\tRRBNode *next = r_rbnode_next (entry);\n \t\t// this can be optimized, there is no need to do search here\n-\t\tr_crbtree_delete (bank->submaps, entry->data, _find_sm_by_from_vaddr_cb, NULL);\n+\t\tbool a = r_crbtree_delete (bank->submaps, entry->data, _find_sm_by_from_vaddr_cb, NULL);\n+\t\tif (!a) {\n+\t\t\tbreak;\n+\t\t}\n \t\tentry = next;\n \t}\n \tif (entry && r_io_submap_from (((RIOSubMap *)entry->data)) <= r_io_submap_to (sm)) {\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "462fca2c666e0cd2b60d6d2593a7216a83047aaf",
        "repo": "flatpak/flatpak",
        "msg": "run: Don't allow chroot()\n\nIf we don't allow pivot_root() then there seems no reason why we should\nallow chroot().\n\nPartially fixes GHSA-67h7-w3jq-vh4q.\n\nSigned-off-by: Simon McVittie <smcv@collabora.com>Flatpak is a system for building, distributing, and running sandboxed desktop applications on Linux. In versions prior to 1.10.4 and 1.12.0, Flatpak apps with direct access to AF_UNIX sockets such as those used by Wayland, Pipewire or pipewire-pulse can trick portals and other host-OS services into treating the Flatpak app as though it was an ordinary, non-sandboxed host-OS process. They can do this by manipulating the VFS using recent mount-related syscalls that are not blocked by Flatpak's denylist seccomp filter, in order to substitute a crafted `/.flatpak-info` or make that file disappear entirely. Flatpak apps that act as clients for AF_UNIX sockets such as those used by Wayland, Pipewire or pipewire-pulse can escalate the privileges that the corresponding services will believe the Flatpak app has. Note that protocols that operate entirely over the D-Bus session bus (user bus), system bus or accessibility bus are not affected by this. This is due to the use of a proxy process `xdg-dbus-proxy`, whose VFS cannot be manipulated by the Flatpak app, when interacting with these buses. Patches exist for versions 1.10.4 and 1.12.0, and as of time of publication, a patch for version 1.8.2 is being planned. There are no workarounds aside from upgrading to a patched version.",
        "filename": "flatpak-run.c",
        "diff": "diff --git a/common/flatpak-run.c b/common/flatpak-run.c\nindex a6ef5042af..7861343795 100644\n--- a/common/flatpak-run.c\n+++ b/common/flatpak-run.c\n@@ -2937,6 +2937,7 @@ setup_seccomp (FlatpakBwrap   *bwrap,\n     {SCMP_SYS (umount), EPERM},\n     {SCMP_SYS (umount2), EPERM},\n     {SCMP_SYS (pivot_root), EPERM},\n+    {SCMP_SYS (chroot), EPERM},\n #if defined(__s390__) || defined(__s390x__) || defined(__CRIS__)\n     /* Architectures with CONFIG_CLONE_BACKWARDS2: the child stack\n      * and flags arguments are reversed so the flags come second */\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "5e2ea2b13bd98f53e29964ca26bb0d602a8a12b9",
        "repo": "squid-cache/squid",
        "msg": "Improve handling of Gopher responses (#1022)In Squid 3.x through 3.5.28, 4.x through 4.17, and 5.x before 5.6, due to improper buffer management, a Denial of Service can occur when processing long Gopher server responses.",
        "filename": "gopher.cc",
        "diff": "diff --git a/src/gopher.cc b/src/gopher.cc\nindex 95afd9528f1..409c1808c62 100644\n--- a/src/gopher.cc\n+++ b/src/gopher.cc\n@@ -365,7 +365,6 @@ gopherToHTML(GopherStateData * gopherState, char *inbuf, int len)\n     char *lpos = NULL;\n     char *tline = NULL;\n     LOCAL_ARRAY(char, line, TEMP_BUF_SIZE);\n-    LOCAL_ARRAY(char, tmpbuf, TEMP_BUF_SIZE);\n     char *name = NULL;\n     char *selector = NULL;\n     char *host = NULL;\n@@ -375,7 +374,6 @@ gopherToHTML(GopherStateData * gopherState, char *inbuf, int len)\n     char gtype;\n     StoreEntry *entry = NULL;\n \n-    memset(tmpbuf, '\\0', TEMP_BUF_SIZE);\n     memset(line, '\\0', TEMP_BUF_SIZE);\n \n     entry = gopherState->entry;\n@@ -410,7 +408,7 @@ gopherToHTML(GopherStateData * gopherState, char *inbuf, int len)\n         return;\n     }\n \n-    String outbuf;\n+    SBuf outbuf;\n \n     if (!gopherState->HTML_header_added) {\n         if (gopherState->conversion == GopherStateData::HTML_CSO_RESULT)\n@@ -582,37 +580,34 @@ gopherToHTML(GopherStateData * gopherState, char *inbuf, int len)\n                         break;\n                     }\n \n-                    memset(tmpbuf, '\\0', TEMP_BUF_SIZE);\n-\n                     if ((gtype == GOPHER_TELNET) || (gtype == GOPHER_3270)) {\n                         if (strlen(escaped_selector) != 0)\n-                            snprintf(tmpbuf, TEMP_BUF_SIZE, \"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"telnet://%s@%s%s%s/\\\">%s</A>\\n\",\n+                            outbuf.appendf(\"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"telnet://%s@%s%s%s/\\\">%s</A>\\n\",\n                                      icon_url, escaped_selector, rfc1738_escape_part(host),\n                                      *port ? \":\" : \"\", port, html_quote(name));\n                         else\n-                            snprintf(tmpbuf, TEMP_BUF_SIZE, \"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"telnet://%s%s%s/\\\">%s</A>\\n\",\n+                            outbuf.appendf(\"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"telnet://%s%s%s/\\\">%s</A>\\n\",\n                                      icon_url, rfc1738_escape_part(host), *port ? \":\" : \"\",\n                                      port, html_quote(name));\n \n                     } else if (gtype == GOPHER_INFO) {\n-                        snprintf(tmpbuf, TEMP_BUF_SIZE, \"\\t%s\\n\", html_quote(name));\n+                        outbuf.appendf(\"\\t%s\\n\", html_quote(name));\n                     } else {\n                         if (strncmp(selector, \"GET /\", 5) == 0) {\n                             /* WWW link */\n-                            snprintf(tmpbuf, TEMP_BUF_SIZE, \"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"http://%s/%s\\\">%s</A>\\n\",\n+                            outbuf.appendf(\"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"http://%s/%s\\\">%s</A>\\n\",\n                                      icon_url, host, rfc1738_escape_unescaped(selector + 5), html_quote(name));\n                         } else if (gtype == GOPHER_WWW) {\n-                            snprintf(tmpbuf, TEMP_BUF_SIZE, \"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"%s\\\">%s</A>\\n\",\n+                            outbuf.appendf(\"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"gopher://%s/%c%s\\\">%s</A>\\n\",\n                                      icon_url, rfc1738_escape_unescaped(selector), html_quote(name));\n                         } else {\n                             /* Standard link */\n-                            snprintf(tmpbuf, TEMP_BUF_SIZE, \"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"gopher://%s/%c%s\\\">%s</A>\\n\",\n+                            outbuf.appendf(\"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"gopher://%s/%c%s\\\">%s</A>\\n\",\n                                      icon_url, host, gtype, escaped_selector, html_quote(name));\n                         }\n                     }\n \n                     safe_free(escaped_selector);\n-                    outbuf.append(tmpbuf);\n                 } else {\n                     memset(line, '\\0', TEMP_BUF_SIZE);\n                     continue;\n@@ -645,13 +640,12 @@ gopherToHTML(GopherStateData * gopherState, char *inbuf, int len)\n                     break;\n \n                 if (gopherState->cso_recno != recno) {\n-                    snprintf(tmpbuf, TEMP_BUF_SIZE, \"</PRE><HR noshade size=\\\"1px\\\"><H2>Record# %d<br><i>%s</i></H2>\\n<PRE>\", recno, html_quote(result));\n+                    outbuf.appendf(\"</PRE><HR noshade size=\\\"1px\\\"><H2>Record# %d<br><i>%s</i></H2>\\n<PRE>\", recno, html_quote(result));\n                     gopherState->cso_recno = recno;\n                 } else {\n-                    snprintf(tmpbuf, TEMP_BUF_SIZE, \"%s\\n\", html_quote(result));\n+                    outbuf.appendf(\"%s\\n\", html_quote(result));\n                 }\n \n-                outbuf.append(tmpbuf);\n                 break;\n             } else {\n                 int code;\n@@ -679,8 +673,7 @@ gopherToHTML(GopherStateData * gopherState, char *inbuf, int len)\n \n                 case 502: { /* Too Many Matches */\n                     /* Print the message the server returns */\n-                    snprintf(tmpbuf, TEMP_BUF_SIZE, \"</PRE><HR noshade size=\\\"1px\\\"><H2>%s</H2>\\n<PRE>\", html_quote(result));\n-                    outbuf.append(tmpbuf);\n+                    outbuf.appendf(\"</PRE><HR noshade size=\\\"1px\\\"><H2>%s</H2>\\n<PRE>\", html_quote(result));\n                     break;\n                 }\n \n@@ -696,13 +689,12 @@ gopherToHTML(GopherStateData * gopherState, char *inbuf, int len)\n \n     }               /* while loop */\n \n-    if (outbuf.size() > 0) {\n-        entry->append(outbuf.rawBuf(), outbuf.size());\n+    if (outbuf.length() > 0) {\n+        entry->append(outbuf.rawContent(), outbuf.length());\n         /* now let start sending stuff to client */\n         entry->flush();\n     }\n \n-    outbuf.clean();\n     return;\n }\n \n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "30ac5e5236b790accd1f25347eebf2dc8c6c1bcb",
        "repo": "gpac/gpac",
        "msg": "fixed #1897The binary MP4Box in Gpac 1.0.1 has a double-free vulnerability in the gf_text_get_utf8_line function in load_text.c, which allows attackers to cause a denial of service, even code execution and escalation of privileges.",
        "filename": "load_text.c",
        "diff": "diff --git a/src/filters/load_text.c b/src/filters/load_text.c\nindex 4f41d2d3bf..b82d2991b1 100644\n--- a/src/filters/load_text.c\n+++ b/src/filters/load_text.c\n@@ -255,7 +255,7 @@ char *gf_text_get_utf8_line(char *szLine, u32 lineSize, FILE *txt_in, s32 unicod\n {\n \tu32 i, j, len;\n \tchar *sOK;\n-\tchar szLineConv[1024];\n+\tchar szLineConv[2048];\n \tunsigned short *sptr;\n \n \tmemset(szLine, 0, sizeof(char)*lineSize);\n@@ -328,7 +328,7 @@ char *gf_text_get_utf8_line(char *szLine, u32 lineSize, FILE *txt_in, s32 unicod\n \t\t}\n \t}\n \tsptr = (u16 *)szLine;\n-\ti = (u32) gf_utf8_wcstombs(szLineConv, 1024, (const unsigned short **) &sptr);\n+\ti = (u32) gf_utf8_wcstombs(szLineConv, 2048, (const unsigned short **) &sptr);\n \tszLineConv[i] = 0;\n \tstrcpy(szLine, szLineConv);\n \t/*this is ugly indeed: since input is UTF16-LE, there are many chances the gf_fgets never reads the \\0 after a \\n*/\n@@ -2338,6 +2338,8 @@ static GF_Err gf_text_process_sub(GF_Filter *filter, GF_TXTIn *ctx)\n \t\twhile (szLine[i+1] && szLine[i+1]!='}') {\n \t\t\tszTime[i] = szLine[i+1];\n \t\t\ti++;\n+\t\t\tif (i>=19)\n+\t\t\t\tbreak;\n \t\t}\n \t\tszTime[i] = 0;\n \t\tctx->start = atoi(szTime);\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "08d7b00c0a5a20926363849f611729f53f3ec022",
        "repo": "tensorflow/tensorflow",
        "msg": "Fix Segfault in Concat V2 shape function.\n\nPiperOrigin-RevId: 412120654\nChange-Id: I3ff915faea694f9ad8b00024e9af2de9909011beTensorflow is an Open Source Machine Learning Framework. The implementation of shape inference for `ConcatV2` can be used to trigger a denial of service attack via a segfault caused by a type confusion. The `axis` argument is translated into `concat_dim` in the `ConcatShapeHelper` helper function. Then, a value for `min_rank` is computed based on `concat_dim`. This is then used to validate that the `values` tensor has at least the required rank. However, `WithRankAtLeast` receives the lower bound as a 64-bits value and then compares it against the maximum 32-bits integer value that could be represented. Due to the fact that `min_rank` is a 32-bits value and the value of `axis`, the `rank` argument is a negative value, so the error check is bypassed. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "filename": "common_shape_fns.cc",
        "diff": "diff --git a/tensorflow/core/framework/common_shape_fns.cc b/tensorflow/core/framework/common_shape_fns.cc\nindex 95f2670e0571da..4a5ce9ae661ffd 100644\n--- a/tensorflow/core/framework/common_shape_fns.cc\n+++ b/tensorflow/core/framework/common_shape_fns.cc\n@@ -2005,7 +2005,7 @@ Status ConcatShapeHelper(InferenceContext* c, int start_value_index,\n   }\n \n   // Minimum required number of dimensions.\n-  const int min_rank = concat_dim < 0 ? -concat_dim : concat_dim + 1;\n+  const int64 min_rank = concat_dim < 0 ? -concat_dim : concat_dim + 1;\n \n   ShapeHandle output_before;\n   ShapeHandle output_after;\ndiff --git a/tensorflow/python/kernel_tests/array_ops/concat_op_test.py b/tensorflow/python/kernel_tests/array_ops/concat_op_test.py\nindex a957665903176f..a5460861f9dd8b 100644\n--- a/tensorflow/python/kernel_tests/array_ops/concat_op_test.py\n+++ b/tensorflow/python/kernel_tests/array_ops/concat_op_test.py\n@@ -16,6 +16,7 @@\n \n import numpy as np\n \n+from tensorflow.python.eager import def_function\n from tensorflow.python.framework import constant_op\n from tensorflow.python.framework import dtypes\n from tensorflow.python.framework import errors_impl\n@@ -570,6 +571,17 @@ def testConcatInvalidAxis(self):\n         t2 = [2]\n         gen_array_ops.concat_v2([t1, t2], 1).eval()\n \n+  def testConcatInvalidAxisInTfFunction(self):\n+\n+    @def_function.function\n+    def concat_wrapper():\n+      y = gen_array_ops.concat_v2(\n+          values=[[1, 2, 3], [4, 5, 6]], axis=0xb500005b)\n+      return y\n+\n+    with self.assertRaises(ValueError):\n+      concat_wrapper()\n+\n   def testConcatNegativeAxis(self):\n     with test_util.use_gpu():\n       t1 = [[1, 2, 3], [4, 5, 6]]\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "b03c9f252526bb42fbd1b87b9f5e339c3cf2390a",
        "repo": "gpac/gpac",
        "msg": "fixed #1890The binary MP4Box in Gpac 1.0.1 has a double-free vulnerability in the gf_list_del function in list.c, which allows attackers to cause a denial of service.",
        "filename": "box_code_meta.c",
        "diff": "diff --git a/src/isomedia/box_code_meta.c b/src/isomedia/box_code_meta.c\nindex e3f0556c00..cdd0948a6d 100644\n--- a/src/isomedia/box_code_meta.c\n+++ b/src/isomedia/box_code_meta.c\n@@ -282,7 +282,8 @@ GF_Err iloc_box_read(GF_Box *s, GF_BitStream *bs)\n \t}\n \n \tfor (i = 0; i < item_count; i++) {\n-\t\tGF_ItemLocationEntry *location_entry = (GF_ItemLocationEntry *)gf_malloc(sizeof(GF_ItemLocationEntry));\n+\t\tGF_ItemLocationEntry *location_entry;\n+\t\tGF_SAFEALLOC(location_entry, GF_ItemLocationEntry);\n \t\tif (!location_entry) return GF_OUT_OF_MEM;\n \n \t\tgf_list_add(ptr->location_entries, location_entry);\n@@ -311,7 +312,8 @@ GF_Err iloc_box_read(GF_Box *s, GF_BitStream *bs)\n \t\textent_count = gf_bs_read_u16(bs);\n \t\tlocation_entry->extent_entries = gf_list_new();\n \t\tfor (j = 0; j < extent_count; j++) {\n-\t\t\tGF_ItemExtentEntry *extent_entry = (GF_ItemExtentEntry *)gf_malloc(sizeof(GF_ItemExtentEntry));\n+\t\t\tGF_ItemExtentEntry *extent_entry;\n+\t\t\tGF_SAFEALLOC(extent_entry, GF_ItemExtentEntry);\n \t\t\tif (!extent_entry) return GF_OUT_OF_MEM;\n \t\t\t\n \t\t\tgf_list_add(location_entry->extent_entries, extent_entry);\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "5ce0c906ed8599d218036b18b78e8126a496f137",
        "repo": "gpac/gpac",
        "msg": "fixed #1892A Segmentation fault exists casued by null pointer dereference exists in Gpac through 1.0.1 via the naludmx_create_avc_decoder_config function in reframe_nalu.c when using mp4box, which causes a denial of service.",
        "filename": "reframe_nalu.c",
        "diff": "diff --git a/src/filters/reframe_nalu.c b/src/filters/reframe_nalu.c\nindex 5077805819..aad8ad9640 100644\n--- a/src/filters/reframe_nalu.c\n+++ b/src/filters/reframe_nalu.c\n@@ -1680,8 +1680,10 @@ static void naludmx_queue_param_set(GF_NALUDmxCtx *ctx, char *data, u32 size, u3\n {\n \tGF_List *list = NULL, *alt_list = NULL;\n \tGF_NALUFFParam *sl;\n-\tu32 i, count;\n-\tu32 crc = gf_crc_32(data, size);\n+\tu32 i, count, crc;\n+\n+\tif (!size) return;\n+\tcrc = gf_crc_32(data, size);\n \n \tif (ctx->codecid==GF_CODECID_HEVC) {\n \t\tswitch (ps_type) {\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "e952a89b7026b98fe8cbe626514a93ed68b7c510",
        "repo": "tensorflow/tensorflow",
        "msg": "Prevent overflow in sparse dense cwise ops.\n\nPiperOrigin-RevId: 415543171\nChange-Id: I22dab7c41be2121ab5efe5403ca0e2f9b7cb24b8Tensorflow is an Open Source Machine Learning Framework. The implementations of `Sparse*Cwise*` ops are vulnerable to integer overflows. These can be used to trigger large allocations (so, OOM based denial of service) or `CHECK`-fails when building new `TensorShape` objects (so, assert failures based denial of service). We are missing some validation on the shapes of the input tensors as well as directly constructing a large `TensorShape` with user-provided dimensions. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "filename": "sparse_dense_binary_op_shared.cc",
        "diff": "diff --git a/tensorflow/core/kernels/sparse_dense_binary_op_shared.cc b/tensorflow/core/kernels/sparse_dense_binary_op_shared.cc\nindex db27abfda7e537..29534bf0a2625c 100644\n--- a/tensorflow/core/kernels/sparse_dense_binary_op_shared.cc\n+++ b/tensorflow/core/kernels/sparse_dense_binary_op_shared.cc\n@@ -99,7 +99,9 @@ class SparseDenseBinaryOpShared : public OpKernel {\n \n     const auto indices_mat = indices_t->matrix<int64_t>();\n     const auto shape_vec = shape_t->vec<int64_t>();\n-    const auto lhs_dims = BCast::FromShape(TensorShape(shape_vec));\n+    TensorShape lhs_shape;\n+    OP_REQUIRES_OK(ctx, TensorShape::BuildTensorShape(shape_vec, &lhs_shape));\n+    const auto lhs_dims = BCast::FromShape(lhs_shape);\n     const auto rhs_dims = BCast::FromShape(dense_t->shape());\n     BCast b(lhs_dims, rhs_dims, false);  // false for keeping the same num dims.\n \n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "b9bd6cfd1c50e6807846af9a86f9b83cafc9c8ae",
        "repo": "tensorflow/tensorflow",
        "msg": "Prevent integer overflow in `OpLevelCostEstimator::CalculateOutputSize`.\n\nIn order to not change the API, we return a negative value in case of overflow. A better fix is to change the API to return a status instead.\n\nPiperOrigin-RevId: 408701427\nChange-Id: Idf31e7f0bf18ca824d084fdd355e1f653f145c20Tensorflow is an Open Source Machine Learning Framework. The implementation of `OpLevelCostEstimator::CalculateOutputSize` is vulnerable to an integer overflow if an attacker can create an operation which would involve tensors with large enough number of elements. We can have a large enough number of dimensions in `output_shape.dim()` or just a small number of dimensions being large enough to cause an overflow in the multiplication. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "filename": "op_level_cost_estimator.cc",
        "diff": "diff --git a/tensorflow/core/grappler/costs/BUILD b/tensorflow/core/grappler/costs/BUILD\nindex 66e0c6cd7c5f15..b267a0f2787f34 100644\n--- a/tensorflow/core/grappler/costs/BUILD\n+++ b/tensorflow/core/grappler/costs/BUILD\n@@ -340,6 +340,7 @@ cc_library(\n         \"//tensorflow/core:lib\",\n         \"//tensorflow/core:protos_all_cc\",\n         \"//tensorflow/core/grappler/clusters:utils\",\n+        \"//tensorflow/core/util:overflow\",\n     ] + tf_protos_grappler(),\n )\n \ndiff --git a/tensorflow/core/grappler/costs/op_level_cost_estimator.cc b/tensorflow/core/grappler/costs/op_level_cost_estimator.cc\nindex 10acbf54595da4..5e328542ab1452 100644\n--- a/tensorflow/core/grappler/costs/op_level_cost_estimator.cc\n+++ b/tensorflow/core/grappler/costs/op_level_cost_estimator.cc\n@@ -27,6 +27,7 @@ limitations under the License.\n #include \"tensorflow/core/grappler/costs/op_context.h\"\n #include \"tensorflow/core/grappler/costs/utils.h\"\n #include \"tensorflow/core/platform/errors.h\"\n+#include \"tensorflow/core/util/overflow.h\"\n \n namespace tensorflow {\n namespace grappler {\n@@ -1607,7 +1608,14 @@ int64_t OpLevelCostEstimator::CalculateOutputSize(const OpInfo& op_info,\n     auto output_shape = MaybeGetMinimumShape(original_output_shape, num_dims,\n                                              found_unknown_shapes);\n     for (const auto& dim : output_shape.dim()) {\n-      output_size *= dim.size();\n+      int64_t new_output_size =\n+          MultiplyWithoutOverflow(output_size, dim.size());\n+      if (new_output_size < 0) {\n+        VLOG(1) << \"Overflow encountered when estimating cost, multiplying \"\n+                << output_size << \" with \" << dim.size();\n+        return -1;\n+      }\n+      output_size = new_output_size;\n     }\n     total_output_size += output_size;\n     VLOG(1) << \"Output Size: \" << output_size\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "002408c3696b173863228223d535f9de72a101a9",
        "repo": "tensorflow/tensorflow",
        "msg": "Add negative bound check for row and column pooling_sequence in FractionalAvgPoolGrad op to avoid out of bound heap access\n\nPiperOrigin-RevId: 413837346\nChange-Id: I2b86034101df31bee161abcb781755e236c7bccdTensorflow is an Open Source Machine Learning Framework. The implementation of `FractionalAvgPoolGrad` does not consider cases where the input tensors are invalid allowing an attacker to read from outside of bounds of heap. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "filename": "fractional_avg_pool_op.cc",
        "diff": "diff --git a/tensorflow/core/kernels/fractional_avg_pool_op.cc b/tensorflow/core/kernels/fractional_avg_pool_op.cc\nindex afc72287edadc1..b3e65aeaee22f8 100644\n--- a/tensorflow/core/kernels/fractional_avg_pool_op.cc\n+++ b/tensorflow/core/kernels/fractional_avg_pool_op.cc\n@@ -311,15 +311,26 @@ class FractionalAvgPoolGradOp : public OpKernel {\n     for (int64_t b = 0; b < out_batch; ++b) {\n       for (int64_t r = 0; r < out_rows; ++r) {\n         const int64_t in_row_start = row_seq_tensor_flat(r);\n+\n         int64_t in_row_end = overlapping_ ? row_seq_tensor_flat(r + 1)\n                                           : row_seq_tensor_flat(r + 1) - 1;\n         in_row_end = std::min(in_row_end, in_max_row_index);\n+        OP_REQUIRES(context, in_row_start >= 0 && in_row_end >= 0,\n+                    errors::InvalidArgument(\n+                        \"Row sequence tensor values must not be negative, got \",\n+                        row_seq_tensor_flat));\n+\n         for (int64_t c = 0; c < out_cols; ++c) {\n           const int64_t in_col_start = col_seq_tensor_flat(c);\n           int64_t in_col_end = overlapping_ ? col_seq_tensor_flat(c + 1)\n                                             : col_seq_tensor_flat(c + 1) - 1;\n           in_col_end = std::min(in_col_end, in_max_col_index);\n \n+          OP_REQUIRES(\n+              context, in_col_start >= 0 && in_col_end >= 0,\n+              errors::InvalidArgument(\n+                  \"Column sequence tensor values must not be negative, got \",\n+                  col_seq_tensor_flat));\n           const int64_t num_elements_in_pooling_cell =\n               (in_row_end - in_row_start + 1) * (in_col_end - in_col_start + 1);\n           const int64_t out_index = (b * out_rows + r) * out_cols + c;\ndiff --git a/tensorflow/python/kernel_tests/nn_ops/fractional_avg_pool_op_test.py b/tensorflow/python/kernel_tests/nn_ops/fractional_avg_pool_op_test.py\nindex ae75c424264622..7b153ae1ed7084 100644\n--- a/tensorflow/python/kernel_tests/nn_ops/fractional_avg_pool_op_test.py\n+++ b/tensorflow/python/kernel_tests/nn_ops/fractional_avg_pool_op_test.py\n@@ -20,6 +20,7 @@\n \n from tensorflow.python.framework import constant_op\n from tensorflow.python.framework import dtypes\n+from tensorflow.python.framework import errors\n from tensorflow.python.framework import test_util\n from tensorflow.python.ops import array_ops\n from tensorflow.python.ops import gen_nn_ops\n@@ -306,6 +307,32 @@ def testDifferentInputTensorShape(self):\n           input_b, row_seq, col_seq, overlapping)\n       self.assertSequenceEqual(expected.shape, actual.shape)\n \n+  def testNegativeSeqValuesForGradOp(self):\n+    with self.assertRaisesRegex(\n+        errors.InvalidArgumentError,\n+        r\"Row sequence tensor values must not be negative.*\"):\n+      y = nn_ops.gen_nn_ops.fractional_avg_pool_grad(\n+          orig_input_tensor_shape=[2, 2, 2, 2],\n+          out_backprop=[[[[1, 2], [3, 4], [5, 6]], [[7, 8], [9, 10], [11,\n+                                                                      12]]]],\n+          row_pooling_sequence=[-10, 1, 2, 3],\n+          col_pooling_sequence=[1, 2, 3, 4],\n+          overlapping=True)\n+\n+      self.evaluate(y)\n+      with self.assertRaisesRegex(\n+          errors.InvalidArgumentError,\n+          r\"Column sequence tensor values must not be negative.*\"):\n+        z = nn_ops.gen_nn_ops.fractional_avg_pool_grad(\n+            orig_input_tensor_shape=[2, 2, 2, 2],\n+            out_backprop=[[[[1, 2], [3, 4], [5, 6]], [[7, 8], [9, 10], [11,\n+                                                                        12]]]],\n+            row_pooling_sequence=[10, 1, 2, 3],\n+            col_pooling_sequence=[1, 2, -3, 4],\n+            overlapping=True)\n+\n+        self.evaluate(z)\n+\n \n class FractionalAvgPoolGradTest(test.TestCase):\n   \"\"\"Tests for FractionalAvgPoolGrad.\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "cff267650c6a1b266e4b4500f69fbc49cdd773c5",
        "repo": "tensorflow/tensorflow",
        "msg": "Fix tf.raw_ops.DeleteSessionTensor vulnerability with invalid `handle`.\n\nCheck that `handle` input is actually a scalar before treating it as such.\n\nPiperOrigin-RevId: 445228994TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, the implementation of `tf.raw_ops.DeleteSessionTensor` does not fully validate the input arguments. This results in a `CHECK`-failure which can be used to trigger a denial of service attack. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.",
        "filename": "session_ops.cc",
        "diff": "diff --git a/tensorflow/core/kernels/session_ops.cc b/tensorflow/core/kernels/session_ops.cc\nindex bb47288b1575ad..2feb79a24e329e 100644\n--- a/tensorflow/core/kernels/session_ops.cc\n+++ b/tensorflow/core/kernels/session_ops.cc\n@@ -134,6 +134,8 @@ class DeleteSessionTensorOp : public OpKernel {\n \n   void Compute(OpKernelContext* ctx) override {\n     const Tensor& handle = ctx->input(0);\n+    OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(handle.shape()),\n+                errors::InvalidArgument(\"`handle` must be scalar\"));\n     const string& name = handle.scalar<tstring>()();\n     auto session_state = ctx->session_state();\n     OP_REQUIRES(ctx, session_state != nullptr,\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "f09caa532b6e1ac8d2aa61b7832c78c5b79300c6",
        "repo": "tensorflow/tensorflow",
        "msg": "Fix EinsumHelper::ParseEquation to avoid uninitialized accesses.\n\nEinsumHelper::ParseEquation is supposed to return true or false in\ninput_has_ellipsis and output_has_ellipsis to indicate whether there is\nellipsis in the inputs and output. Previously, when there is no ellipsis in the\ninputs or output, the routine doesn't assign false to the variables. This\nchange initializes the two variables with false to fix the problem.\nPiperOrigin-RevId: 391772004\nChange-Id: I17b6c88aadef4131470378e48cced054bf252e86TensorFlow is an open source platform for machine learning. In affeced versions during execution, `EinsumHelper::ParseEquation()` is supposed to set the flags in `input_has_ellipsis` vector and `*output_has_ellipsis` boolean to indicate whether there is ellipsis in the corresponding inputs and output. However, the code only changes these flags to `true` and never assigns `false`. This results in unitialized variable access if callers assume that `EinsumHelper::ParseEquation()` always sets these flags. The fix will be included in TensorFlow 2.7.0. We will also cherrypick this commit on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.",
        "filename": "einsum_op_impl.h",
        "diff": "diff --git a/tensorflow/core/kernels/linalg/einsum_op_impl.h b/tensorflow/core/kernels/linalg/einsum_op_impl.h\nindex 5c41e38954d626..6f64334555131c 100644\n--- a/tensorflow/core/kernels/linalg/einsum_op_impl.h\n+++ b/tensorflow/core/kernels/linalg/einsum_op_impl.h\n@@ -153,6 +153,7 @@ struct EinsumHelper {\n     input_has_ellipsis->resize(num_inputs);\n     for (int i = 0; i < num_inputs; ++i) {\n       input_label_counts->at(i).resize(num_labels);\n+      input_has_ellipsis->at(i) = false;\n       for (const int label : input_labels->at(i)) {\n         if (label != kEllipsisLabel)\n           input_label_counts->at(i)[label] += 1;\n@@ -161,6 +162,7 @@ struct EinsumHelper {\n       }\n     }\n     output_label_counts->resize(num_labels);\n+    *output_has_ellipsis = false;\n     for (const int label : *output_labels) {\n       if (label != kEllipsisLabel)\n         output_label_counts->at(label) += 1;\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "68867bf01239d9e1048f98cbad185bf4761bedd3",
        "repo": "tensorflow/tensorflow",
        "msg": "Prevent unitialized variable use in grappler.\n\nPiperOrigin-RevId: 399702928\nChange-Id: Id7e75451fbff297692dfb687f60ea04b25c96b24TensorFlow is an open source platform for machine learning. In affected versions TensorFlow's Grappler optimizer has a use of unitialized variable. If the `train_nodes` vector (obtained from the saved model that gets optimized) does not contain a `Dequeue` node, then `dequeue_node` is left unitialized. The fix will be included in TensorFlow 2.7.0. We will also cherrypick this commit on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.",
        "filename": "auto_parallel.cc",
        "diff": "diff --git a/tensorflow/core/grappler/optimizers/auto_parallel.cc b/tensorflow/core/grappler/optimizers/auto_parallel.cc\nindex 097a57ce364b61..0865892796b898 100644\n--- a/tensorflow/core/grappler/optimizers/auto_parallel.cc\n+++ b/tensorflow/core/grappler/optimizers/auto_parallel.cc\n@@ -152,7 +152,7 @@ Status AutoParallel::Initialize(const GrapplerItem& item) {\n   TF_RETURN_IF_ERROR(ComputeTransitiveFanin(graph_, item.fetch, &train_nodes));\n   LOG(INFO) << \"Number of training nodes: \" << train_nodes.size();\n \n-  const NodeDef* dequeue_node;\n+  const NodeDef* dequeue_node = nullptr;\n   for (const auto& train_node : train_nodes) {\n     if (IsDequeueOp(*train_node)) {\n       dequeue_node = train_node;\ndiff --git a/tensorflow/core/grappler/optimizers/auto_parallel_test.cc b/tensorflow/core/grappler/optimizers/auto_parallel_test.cc\nindex 1c3186f1ee6e68..3af03a09613883 100644\n--- a/tensorflow/core/grappler/optimizers/auto_parallel_test.cc\n+++ b/tensorflow/core/grappler/optimizers/auto_parallel_test.cc\n@@ -126,6 +126,30 @@ TEST_F(AutoParallelTest, SimpleParallel) {\n   EXPECT_EQ(\"^AutoParallel-Control-Fetch\", node_gradient.input(0));\n }\n \n+TEST_F(AutoParallelTest, SimpleParallelNoDequeue) {\n+  tensorflow::Scope s = tensorflow::Scope::DisabledShapeInferenceScope();\n+  Output constant_a = ops::Const(s.WithOpName(\"constant_a\"), 1.0f, {1});\n+  Output constant_c = ops::Const(s.WithOpName(\"constant_c\"), 1.0f, {1});\n+  Output constant_b = ops::Const(s.WithOpName(\"constant_b\"), 1, {1});\n+  Output var = ops::Variable(s.WithOpName(\"var\"), {1}, DT_FLOAT);\n+  Output assign = ops::Assign(s.WithOpName(\"assign\"), {var}, {constant_a});\n+  Output add = ops::AddN(s.WithOpName(\"add\"), {constant_a, constant_c});\n+  Output learning_rate = ops::Const(s.WithOpName(\"learning_rate\"), 0.01f, {1});\n+  Output apply_gradient = ops::ApplyGradientDescent(\n+      s.WithOpName(\"apply_gradient\"), {var}, {learning_rate}, {add});\n+\n+  GrapplerItem item;\n+  item.init_ops.push_back(\"assign\");\n+  item.fetch.push_back(\"apply_gradient\");\n+  item.init_ops.push_back(\"assign\");\n+  TF_CHECK_OK(s.ToGraphDef(&item.graph));\n+\n+  AutoParallel parallel(2);\n+  GraphDef output;\n+  Status status = parallel.Optimize(nullptr, item, &output);\n+  TF_EXPECT_OK(status);\n+}\n+\n }  // namespace\n }  // namespace grappler\n }  // namespace tensorflow\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "4071d8e2f6c45c1955a811fee757ca2adbe462c1",
        "repo": "tensorflow/tensorflow",
        "msg": "Fix FPE issue with `tf.raw_ops.Reverse`.\n\nPiperOrigin-RevId: 371176973\nChange-Id: Ic6d483bfc95313ec2299c2d1c956cfe96c96626cTensorFlow is an end-to-end open source platform for machine learning. An attacker can cause a denial of service via a FPE runtime error in `tf.raw_ops.Reverse`. This is because the implementation(https://github.com/tensorflow/tensorflow/blob/36229ea9e9451dac14a8b1f4711c435a1d84a594/tensorflow/core/kernels/reverse_op.cc#L75-L76) performs a division based on the first dimension of the tensor argument. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
        "filename": "reverse_op.cc",
        "diff": "diff --git a/tensorflow/core/kernels/reverse_op.cc b/tensorflow/core/kernels/reverse_op.cc\nindex 5555a141b6c7bd..560fac71336679 100644\n--- a/tensorflow/core/kernels/reverse_op.cc\n+++ b/tensorflow/core/kernels/reverse_op.cc\n@@ -155,6 +155,12 @@ class ReverseOp : public OpKernel {\n \n   void Compute(OpKernelContext* context) override {\n     const Tensor& input = context->input(0);\n+    // If input is provided, check to make sure the first dimension is valid.\n+    if (input.dims() > 0) {\n+      OP_REQUIRES(\n+          context, input.dim_size(0) != 0,\n+          errors::InvalidArgument(\"Invalid input first dimension. Found 0.\"));\n+    }\n     const Tensor& dims = context->input(1);\n \n     if (TensorShapeUtils::IsScalar(input.shape())) {\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "9e82dce6e6bd1f36a57e08fa85af213e2b2f2622",
        "repo": "tensorflow/tensorflow",
        "msg": "Fix NPE in restoring code.\n\nPiperOrigin-RevId: 388303253\nChange-Id: Ia8c68568cb854bca538909a182b31a618d68ce55TensorFlow is an end-to-end open source platform for machine learning. When restoring tensors via raw APIs, if the tensor name is not provided, TensorFlow can be tricked into dereferencing a null pointer. Alternatively, attackers can read memory outside the bounds of heap allocated data by providing some tensor names but not enough for a successful restoration. The [implementation](https://github.com/tensorflow/tensorflow/blob/47a06f40411a69c99f381495f490536972152ac0/tensorflow/core/kernels/save_restore_tensor.cc#L158-L159) retrieves the tensor list corresponding to the `tensor_name` user controlled input and immediately retrieves the tensor at the restoration index (controlled via `preferred_shard` argument). This occurs without validating that the provided list has enough values. If the list is empty this results in dereferencing a null pointer (undefined behavior). If, however, the list has some elements, if the restoration index is outside the bounds this results in heap OOB read. We have patched the issue in GitHub commit 9e82dce6e6bd1f36a57e08fa85af213e2b2f2622. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "filename": "save_restore_tensor.cc",
        "diff": "diff --git a/tensorflow/core/kernels/save_restore_tensor.cc b/tensorflow/core/kernels/save_restore_tensor.cc\nindex 953c1dfb6290b4..dcbed428a5a5ac 100644\n--- a/tensorflow/core/kernels/save_restore_tensor.cc\n+++ b/tensorflow/core/kernels/save_restore_tensor.cc\n@@ -151,11 +151,18 @@ void RestoreTensor(OpKernelContext* context,\n         context, size == 1,\n         errors::InvalidArgument(\n             \"Input 0 (file_pattern) must be a string scalar; got a tensor of \",\n-            size, \"elements\"));\n+            size, \" elements\"));\n   }\n   const string& file_pattern = file_pattern_t.flat<tstring>()(0);\n \n   const Tensor& tensor_name_t = context->input(1);\n+  {\n+    const int64_t size = tensor_name_t.NumElements();\n+    OP_REQUIRES(context, size > restore_index,\n+                errors::InvalidArgument(\n+                    \"Input 1 (file_pattern) must be a have at least \",\n+                    restore_index + 1, \" elements\"));\n+  }\n   const string& tensor_name = tensor_name_t.flat<tstring>()(restore_index);\n \n   // If we cannot find a cached reader we will allocate our own.\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "dc7de8d3d604426c7a6e628d90cb9fb88e7b4c2c",
        "repo": "gpac/gpac",
        "msg": "fixed #2212Use After Free in GitHub repository gpac/gpac prior to 2.1-DEV.",
        "filename": "field_decode.c",
        "diff": "diff --git a/src/bifs/field_decode.c b/src/bifs/field_decode.c\nindex 5537da7d3d..65d045b02a 100644\n--- a/src/bifs/field_decode.c\n+++ b/src/bifs/field_decode.c\n@@ -427,64 +427,71 @@ GF_Err BD_DecMFFieldVec(GF_BifsDecoder * codec, GF_BitStream *bs, GF_Node *node,\n \t\t\te = gf_bifs_dec_sf_field(codec, bs, node, &sffield, GF_FALSE);\n \t\t\tif (e) return e;\n \t\t}\n-\t} else {\n-\t\tlast = NULL;\n-\t\tfor (i=0; i<nbFields; i++) {\n-\t\t\tGF_Node *new_node = gf_bifs_dec_node(codec, bs, field->NDTtype);\n-\t\t\tif (new_node) {\n-\t\t\t\te = gf_node_register(new_node, is_mem_com ? NULL : node);\n-\t\t\t\tif (e) return e;\n-\n-\t\t\t\tif (node) {\n-\t\t\t\t\t/*special case for QP, register as the current QP*/\n-\t\t\t\t\tif (gf_node_get_tag(new_node) == TAG_MPEG4_QuantizationParameter) {\n-\t\t\t\t\t\tqp_local = ((M_QuantizationParameter *)new_node)->isLocal;\n-\t\t\t\t\t\t/*we have a QP in the same scope, remove previous\n-\t\t\t\t\t\tNB: we assume this is the right behavior, the spec doesn't say\n-\t\t\t\t\t\twhether QP is cumulative or not*/\n-\t\t\t\t\t\tif (qp_on) gf_bifs_dec_qp_remove(codec, GF_FALSE);\n+\t\treturn GF_OK;\n+\t}\n \n-\t\t\t\t\t\te = gf_bifs_dec_qp_set(codec, new_node);\n-\t\t\t\t\t\tif (e) return e;\n-\t\t\t\t\t\tqp_on = 1;\n-\t\t\t\t\t\tif (qp_local) qp_local = 2;\n-\t\t\t\t\t\tif (codec->force_keep_qp) {\n-\t\t\t\t\t\t\te = gf_node_list_add_child_last(field->far_ptr, new_node, &last);\n-\t\t\t\t\t\t\tif (e) return e;\n-\t\t\t\t\t\t} else {\n-\t\t\t\t\t\t\tgf_node_register(new_node, NULL);\n-\t\t\t\t\t\t\tgf_node_unregister(new_node, node);\n-\t\t\t\t\t\t}\n-\t\t\t\t\t} else {\n+\te = GF_OK;\n+\tlast = NULL;\n+\tfor (i=0; i<nbFields; i++) {\n+\t\tGF_Node *new_node = gf_bifs_dec_node(codec, bs, field->NDTtype);\n+\t\tif (new_node) {\n+\t\t\te = gf_node_register(new_node, is_mem_com ? NULL : node);\n+\t\t\tif (e) goto exit;\n+\n+\t\t\tif (node) {\n+\t\t\t\t/*special case for QP, register as the current QP*/\n+\t\t\t\tif (gf_node_get_tag(new_node) == TAG_MPEG4_QuantizationParameter) {\n+\t\t\t\t\tqp_local = ((M_QuantizationParameter *)new_node)->isLocal;\n+\t\t\t\t\t/*we have a QP in the same scope, remove previous\n+\t\t\t\t\tNB: we assume this is the right behavior, the spec doesn't say\n+\t\t\t\t\twhether QP is cumulative or not*/\n+\t\t\t\t\tif (qp_on) gf_bifs_dec_qp_remove(codec, GF_FALSE);\n+\n+\t\t\t\t\te = gf_bifs_dec_qp_set(codec, new_node);\n+\t\t\t\t\tif (e) goto exit;\n+\t\t\t\t\tqp_on = 1;\n+\t\t\t\t\tif (qp_local) qp_local = 2;\n+\t\t\t\t\tif (codec->force_keep_qp) {\n \t\t\t\t\t\te = gf_node_list_add_child_last(field->far_ptr, new_node, &last);\n-\t\t\t\t\t\tif (e) return e;\n+\t\t\t\t\t\tif (e) goto exit;\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tgf_node_register(new_node, NULL);\n+\t\t\t\t\t\tgf_node_unregister(new_node, node);\n \t\t\t\t\t}\n+\t\t\t\t} else {\n+\t\t\t\t\te = gf_node_list_add_child_last(field->far_ptr, new_node, &last);\n+\t\t\t\t\tif (e) goto exit;\n \t\t\t\t}\n-\t\t\t\t/*proto coding*/\n-\t\t\t\telse if (codec->pCurrentProto) {\n-\t\t\t\t\t/*TO DO: what happens if this is a QP node on the interface ?*/\n-\t\t\t\t\te = gf_node_list_add_child_last( (GF_ChildNodeItem **)field->far_ptr, new_node, &last);\n-\t\t\t\t\tif (e) return e;\n-\t\t\t\t}\n-\t\t\t} else {\n-\t\t\t\treturn codec->LastError ? codec->LastError : GF_NON_COMPLIANT_BITSTREAM;\n \t\t\t}\n+\t\t\t/*proto coding*/\n+\t\t\telse if (codec->pCurrentProto) {\n+\t\t\t\t/*TO DO: what happens if this is a QP node on the interface ?*/\n+\t\t\t\te = gf_node_list_add_child_last( (GF_ChildNodeItem **)field->far_ptr, new_node, &last);\n+\t\t\t\tif (e)goto exit;\n+\t\t\t}\n+\t\t} else {\n+\t\t\te = codec->LastError ? codec->LastError : GF_NON_COMPLIANT_BITSTREAM;\n+\t\t\tgoto exit;\n \t\t}\n-\t\t/*according to the spec, the QP applies to the current node itself, not just children.\n-\t\tIf IsLocal is TRUE remove the node*/\n-\t\tif (qp_on && qp_local) {\n-\t\t\tif (qp_local == 2) {\n+\t}\n+\n+exit:\n+\n+\t/*according to the spec, the QP applies to the current node itself, not just children.\n+\tIf IsLocal is TRUE remove the node*/\n+\tif (qp_on && qp_local) {\n+\t\tif (qp_local == 2) {\n //\t\t\t\tqp_local = 1;\n-\t\t\t} else {\n-\t\t\t\t//ask to get rid of QP and reactivate if we had a QP when entering the node\n-\t\t\t\tgf_bifs_dec_qp_remove(codec, initial_qp);\n+\t\t} else {\n+\t\t\t//ask to get rid of QP and reactivate if we had a QP when entering the node\n+\t\t\tgf_bifs_dec_qp_remove(codec, initial_qp);\n //\t\t\t\tqp_local = 0;\n-\t\t\t}\n \t\t}\n \t}\n+\n \t/*finally delete the QP if any (local or not) as we get out of this node*/\n \tif (qp_on) gf_bifs_dec_qp_remove(codec, GF_TRUE);\n-\treturn GF_OK;\n+\treturn e;\n }\n \n \n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "187035b9726710b4fe11d565c7808975c930895d",
        "repo": "thorfdbg/libjpeg",
        "msg": "The code now checks for consistency of the MCU sizes across\nhierarchical levels, and fails in case they are different.libjpeg 1.63 has a heap-based buffer over-read in HierarchicalBitmapRequester::FetchRegion in hierarchicalbitmaprequester.cpp because the MCU size can be different between allocation and use.",
        "filename": "hierarchicalbitmaprequester.cpp",
        "diff": "diff --git a/README b/README\nindex 40ef320..124c958 100644\n--- a/README\n+++ b/README\n@@ -460,6 +460,8 @@ out-of-bounds symbol triggered and out-of-bounds array access and could\n have crashed the decoder. The code is now more carefully changing the\r\n validity of the symbols and aborts with an error if it finds illegal\r\n codes.\r\n+The code now also checks the consistency of the MCU sizes in the\r\n+hierarchical process and fails if they differ across levels.\r\n \r\n --------------------------------------------------------------------------\r\n \r\ndiff --git a/README.history b/README.history\nindex 672d08d..09f0d87 100644\n--- a/README.history\n+++ b/README.history\n@@ -564,5 +564,7 @@ out-of-bounds symbol triggered and out-of-bounds array access and could\n have crashed the decoder. The code is now more carefully changing the\r\n validity of the symbols and aborts with an error if it finds illegal\r\n codes.\r\n+The code now also checks the consistency of the MCU sizes in the\r\n+hierarchical process and fails if they differ across levels.\r\n \r\n --------------------------------------------------------------------------\r\ndiff --git a/control/hierarchicalbitmaprequester.cpp b/control/hierarchicalbitmaprequester.cpp\nindex 14aefd1..bc636f6 100644\n--- a/control/hierarchicalbitmaprequester.cpp\n+++ b/control/hierarchicalbitmaprequester.cpp\n@@ -45,7 +45,7 @@\n ** decoding. It also keeps the top-level color transformer and the\n ** toplevel subsampling expander.\n **\n-** $Id: hierarchicalbitmaprequester.cpp,v 1.42 2020/04/08 10:05:41 thor Exp $\n+** $Id: hierarchicalbitmaprequester.cpp,v 1.43 2022/05/24 05:42:35 thor Exp $\n **\n */\n \n@@ -245,6 +245,16 @@ void HierarchicalBitmapRequester::PrepareForDecoding(void)\n       UBYTE sx = comp->SubXOf();\n       UBYTE sy = comp->SubYOf();\n \n+      if (m_pLargestScale) {\n+        class Frame *frame = m_pLargestScale->FrameOf();\n+        while(frame) {\n+          if (frame->ComponentOf(i)->SubXOf() != sx || frame->ComponentOf(i)->SubYOf() != sy)\n+            JPG_THROW(MALFORMED_STREAM,\"HierarchicalBitmapRequester::PrepareForDecoding\",\n+                      \"component subsampling is inconsistent across hierarchical levels\");\n+          frame = frame->NextOf();\n+        }\n+      }\n+\n       if (sx > 1 || sy > 1) {\n         m_ppUpsampler[i] = UpsamplerBase::CreateUpsampler(m_pEnviron,sx,sy,\n                                                           m_ulPixelWidth,m_ulPixelHeight,\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "0efd112bb62f566877750ad62ee828bff579b4e2",
        "repo": "babelouest/glewlwyd",
        "msg": "Fix fido2 signature validation bugscheme/webauthn.c in Glewlwyd SSO server through 2.5.3 has a buffer overflow during FIDO2 signature validation in webauthn registration.",
        "filename": "webauthn.c",
        "diff": "diff --git a/src/scheme/webauthn.c b/src/scheme/webauthn.c\nindex 282405528..5b4eb8a4f 100644\n--- a/src/scheme/webauthn.c\n+++ b/src/scheme/webauthn.c\n@@ -1543,7 +1543,7 @@ static json_t * check_attestation_fido_u2f(json_t * j_params, unsigned char * cr\n   gnutls_pubkey_t pubkey = NULL;\n   gnutls_x509_crt_t cert = NULL;\n   gnutls_datum_t cert_dat, data, signature, cert_issued_by;\n-  unsigned char data_signed[200], client_data_hash[32], cert_export[32], cert_export_b64[64];\n+  unsigned char * data_signed = NULL, client_data_hash[32], cert_export[32], cert_export_b64[64];\n   size_t data_signed_offset = 0, client_data_hash_len = 32, cert_export_len = 32, cert_export_b64_len = 0;\n   \n   if (j_error != NULL) {\n@@ -1632,6 +1632,12 @@ static json_t * check_attestation_fido_u2f(json_t * j_params, unsigned char * cr\n         break;\n       }\n       \n+      if ((data_signed = o_malloc(rpid_hash_len+client_data_hash_len+credential_id_len+cert_x_len+cert_y_len+2)) == NULL) {\n+        y_log_message(Y_LOG_LEVEL_DEBUG, \"check_attestation_fido_u2f - Error allocating data_signed\");\n+        json_array_append_new(j_error, json_string(\"Internal error\"));\n+        break;\n+      }\n+      \n       // Build bytestring to verify signature\n       data_signed[0] = 0x0;\n       data_signed_offset = 1;\n@@ -1666,6 +1672,7 @@ static json_t * check_attestation_fido_u2f(json_t * j_params, unsigned char * cr\n       }\n       \n     } while (0);\n+    o_free(data_signed);\n     \n     if (json_array_size(j_error)) {\n       j_return = json_pack(\"{sisO}\", \"result\", G_ERROR_PARAM, \"error\", j_error);\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "098e7762d909bac47ce1dbabe6dfd06294cb9d58",
        "repo": "tensorflow/tensorflow",
        "msg": "Fix tf.raw_ops.QuantizeAndDequantizeV4Grad vulnerability with invalid input_min or input_max.\n\nCheck that argument is actually a scalar before treating it as such.\n\nPiperOrigin-RevId: 445198280TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, the implementation of `tf.raw_ops.QuantizeAndDequantizeV4Grad` does not fully validate the input arguments. This results in a `CHECK`-failure which can be used to trigger a denial of service attack. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.",
        "filename": "quantize_and_dequantize_op.cc",
        "diff": "diff --git a/tensorflow/core/kernels/quantize_and_dequantize_op.cc b/tensorflow/core/kernels/quantize_and_dequantize_op.cc\nindex d63a49a04be621..da9257fb9c9af1 100644\n--- a/tensorflow/core/kernels/quantize_and_dequantize_op.cc\n+++ b/tensorflow/core/kernels/quantize_and_dequantize_op.cc\n@@ -174,13 +174,13 @@ class QuantizeAndDequantizeV4GradientOp : public OpKernel {\n     OP_REQUIRES(ctx,\n                 input_min_tensor.dims() == 0 || input_min_tensor.dims() == 1,\n                 errors::InvalidArgument(\n-                    \"Input min tensor must have dimension 1. Recieved \",\n+                    \"Input min tensor must have dimension 0 or 1. Received \",\n                     input_min_tensor.dims(), \".\"));\n     const Tensor& input_max_tensor = ctx->input(3);\n     OP_REQUIRES(ctx,\n                 input_max_tensor.dims() == 0 || input_max_tensor.dims() == 1,\n                 errors::InvalidArgument(\n-                    \"Input max tensor must have dimension 1. Recieved \",\n+                    \"Input max tensor must have dimension 0 or 1. Received \",\n                     input_max_tensor.dims(), \".\"));\n     if (axis_ != -1) {\n       OP_REQUIRES(\n@@ -203,6 +203,12 @@ class QuantizeAndDequantizeV4GradientOp : public OpKernel {\n                    ctx->allocate_output(2, min_max_shape, &input_max_backprop));\n \n     if (axis_ == -1) {\n+      OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(input_min_tensor.shape()),\n+                  errors::InvalidArgument(\n+                      \"input_min must be a scalar if axis is unspecified\"));\n+      OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(input_max_tensor.shape()),\n+                  errors::InvalidArgument(\n+                      \"input_max must be a scalar if axis is unspecified\"));\n       functor::QuantizeAndDequantizeOneScaleGradientFunctor<Device, T> f;\n       f(ctx->eigen_device<Device>(), gradient.template flat<T>(),\n         input.template flat<T>(), input_min_tensor.scalar<T>(),\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "84d4b53122e0fa0280c7872350b89d5777dabbb2",
        "repo": "wolfSSL/wolfMQTT",
        "msg": "Fix wolfmqtt-fuzzer: Null-dereference WRITE in MqttProps_FreewolfSSL wolfMQTT 1.9 has a heap-based buffer overflow in MqttDecode_Disconnect (called from MqttClient_DecodePacket and MqttClient_WaitType).",
        "filename": "mqtt_client.c",
        "diff": "diff --git a/src/mqtt_client.c b/src/mqtt_client.c\nindex d06fac66a..d392cc5f0 100644\n--- a/src/mqtt_client.c\n+++ b/src/mqtt_client.c\n@@ -906,8 +906,9 @@ static int MqttClient_WaitType(MqttClient *client, void *packet_obj,\n             /* Determine if we received data for this request */\n             if ((wait_type == MQTT_PACKET_TYPE_ANY ||\n                  wait_type == packet_type ||\n-                 MqttIsPubRespPacket(packet_type) == MqttIsPubRespPacket(wait_type)) &&\n-               (wait_packet_id == 0 || wait_packet_id == packet_id))\n+                 (MqttIsPubRespPacket(packet_type) &&\n+                  MqttIsPubRespPacket(wait_type))) &&\n+                (wait_packet_id == 0 || wait_packet_id == packet_id))\n             {\n                 use_packet_obj = packet_obj;\n                 waitMatchFound = 1;\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "ad48705bf1f04b4221a5f5b07715ac48b3160d53",
        "repo": "nginx/njs",
        "msg": "Fixed frame allocation from an awaited frame.\n\nnjs_function_frame_save() is used to save the awaited frame when \"await\"\ninstruction is encountered. The saving was done as a memcpy() of\nexisting runtime frame.\n\nnjs_function_frame_alloc() is used to alloc a new function frame, this\nfunction tries to use a spare preallocated memory from the previous\nframe first.  Previously, this function might result in \"use-after-free\"\nwhen invoked from a restored frame saved with njs_function_frame_save().\nBecause njs_function_frame_save() left pointers to the spare memory of\nthe original frame which may be already free when saved frame is\nrestored.\n\nThe fix is to erase fields for the spare memory from the saved frame.\n\nThis closes #469 issue on Github.nginx njs 0.7.2 is affected suffers from Use-after-free in njs_function_frame_alloc() when it try to invoke from a restored frame saved with njs_function_frame_save().",
        "filename": "njs_function.c",
        "diff": "diff --git a/src/njs_function.c b/src/njs_function.c\nindex c9d4d9732..78857e01e 100644\n--- a/src/njs_function.c\n+++ b/src/njs_function.c\n@@ -811,9 +811,13 @@ njs_function_frame_save(njs_vm_t *vm, njs_frame_t *frame, u_char *pc)\n     njs_native_frame_t  *active, *native;\n \n     *frame = *vm->active_frame;\n+\n     frame->previous_active_frame = NULL;\n \n     native = &frame->native;\n+    native->size = 0;\n+    native->free = NULL;\n+    native->free_size = 0;\n \n     active = &vm->active_frame->native;\n     value_count = njs_function_frame_value_count(active);\ndiff --git a/test/js/async_recursive_large.t.js b/test/js/async_recursive_large.t.js\nnew file mode 100644\nindex 000000000..423e8d01e\n--- /dev/null\n+++ b/test/js/async_recursive_large.t.js\n@@ -0,0 +1,26 @@\n+/*---\n+includes: [compareArray.js]\n+flags: [async]\n+---*/\n+\n+let stages = [];\n+\n+async function f(v) {\n+    if (v == 1000) {\n+        return;\n+    }\n+\n+    stages.push(`f>${v}`);\n+\n+    await \"X\";\n+\n+    await f(v + 1);\n+\n+    stages.push(`f<${v}`);\n+}\n+\n+f(0)\n+.then(v => {\n+    assert.sameValue(stages.length, 2000);\n+})\n+.then($DONE, $DONE);\ndiff --git a/test/js/async_recursive_mid.t.js b/test/js/async_recursive_mid.t.js\nindex 4d3a9fd19..6b6779629 100644\n--- a/test/js/async_recursive_mid.t.js\n+++ b/test/js/async_recursive_mid.t.js\n@@ -6,7 +6,7 @@ flags: [async]\n let stages = [];\n \n async function f(v) {\n-    if (v == 3) {\n+    if (v == 1000) {\n         return;\n     }\n \n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "abcced051cb1bd8fb05046ac3b6023a7ebcc4578",
        "repo": "tensorflow/tensorflow",
        "msg": "Prevent crashes when loading tensor slices with unsupported types.\n\nAlso fix the `Tensor(const TensorShape&)` constructor swapping the LOG(FATAL)\nmessages for the unset and unsupported types.\n\nPiperOrigin-RevId: 392695027\nChange-Id: I4beda7db950db951d273e3259a7c8534ece49354TensorFlow is an open source platform for machine learning. In affected versions an attacker can trigger undefined behavior, integer overflows, segfaults and `CHECK`-fail crashes if they can change saved checkpoints from outside of TensorFlow. This is because the checkpoints loading infrastructure is missing validation for invalid file formats. The fixes will be included in TensorFlow 2.7.0. We will also cherrypick these commits on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.",
        "filename": "tensor_slice_reader.cc",
        "diff": "diff --git a/tensorflow/core/framework/BUILD b/tensorflow/core/framework/BUILD\nindex 88550b3205ff58..11fe921173ae40 100644\n--- a/tensorflow/core/framework/BUILD\n+++ b/tensorflow/core/framework/BUILD\n@@ -835,6 +835,7 @@ tf_cuda_library(\n         \"//tensorflow/core/lib/strings:str_util\",\n         \"//tensorflow/core/lib/strings:strcat\",\n         \"//tensorflow/core/platform:abi\",\n+        \"//tensorflow/core/platform:errors\",\n         \"//tensorflow/core/platform:logging\",\n         \"//tensorflow/core/platform:macros\",\n         \"//tensorflow/core/platform:platform_port\",\ndiff --git a/tensorflow/core/framework/tensor.cc b/tensorflow/core/framework/tensor.cc\nindex 2abd8fce1c4276..5e26bf05c03ca9 100644\n--- a/tensorflow/core/framework/tensor.cc\n+++ b/tensorflow/core/framework/tensor.cc\n@@ -52,6 +52,7 @@ limitations under the License.\n #include \"tensorflow/core/lib/gtl/inlined_vector.h\"\n #include \"tensorflow/core/lib/strings/str_util.h\"\n #include \"tensorflow/core/lib/strings/strcat.h\"\n+#include \"tensorflow/core/platform/errors.h\"\n #include \"tensorflow/core/platform/logging.h\"\n #include \"tensorflow/core/platform/macros.h\"\n #include \"tensorflow/core/platform/protobuf.h\"\n@@ -723,11 +724,11 @@ bool Tensor::RefCountIsOne() const {\n // The macro CASES() expands to a switch statement conditioned on\n // TYPE_ENUM. Each case expands the STMTS after a typedef for T.\n #define SINGLE_ARG(...) __VA_ARGS__\n-#define CASE(TYPE, STMTS)             \\\n-  case DataTypeToEnum<TYPE>::value: { \\\n-    typedef TYPE T;                   \\\n-    STMTS;                            \\\n-    break;                            \\\n+#define CASE(TYPE, STMTS)               \\\n+  case DataTypeToEnum<TYPE>::value: {   \\\n+    typedef TF_ATTRIBUTE_UNUSED TYPE T; \\\n+    STMTS;                              \\\n+    break;                              \\\n   }\n #define CASES_WITH_DEFAULT(TYPE_ENUM, STMTS, INVALID, DEFAULT) \\\n   switch (TYPE_ENUM) {                                         \\\n@@ -763,9 +764,8 @@ bool Tensor::RefCountIsOne() const {\n   }\n \n #define CASES(TYPE_ENUM, STMTS)                                      \\\n-  CASES_WITH_DEFAULT(TYPE_ENUM, STMTS,                               \\\n-                     LOG(FATAL) << \"Unexpected type: \" << TYPE_ENUM; \\\n-                     , LOG(FATAL) << \"Type not set\";)\n+  CASES_WITH_DEFAULT(TYPE_ENUM, STMTS, LOG(FATAL) << \"Type not set\"; \\\n+                     , LOG(FATAL) << \"Unexpected type: \" << TYPE_ENUM;)\n \n Tensor::Tensor(Allocator* a, DataType type, const TensorShape& shape)\n     : shape_(shape), buf_(nullptr) {\n@@ -795,6 +795,16 @@ Tensor::Tensor(Allocator* a, DataType type, const TensorShape& shape,\n   }\n }\n \n+Status Tensor::BuildTensor(DataType type, const TensorShape& shape,\n+                           Tensor* out_tensor) {\n+  // Avoid crashes due to invalid or unsupported types.\n+  CASES_WITH_DEFAULT(\n+      type, {}, return errors::InvalidArgument(\"Type not set\"),\n+      return errors::InvalidArgument(\"Unexpected type: \", DataType_Name(type)));\n+  *out_tensor = Tensor(type, shape);\n+  return Status::OK();\n+}\n+\n // NOTE(mrry): The default allocator for a Tensor (when none is specified) is\n // the default CPU allocator for NUMA zone 0. Accessing that currently involves\n // acquiring a lock, which guards initialization of the per-NUMA zone\ndiff --git a/tensorflow/core/framework/tensor.h b/tensorflow/core/framework/tensor.h\nindex dd66f995ecbcd7..d4ffb1106e40c1 100644\n--- a/tensorflow/core/framework/tensor.h\n+++ b/tensorflow/core/framework/tensor.h\n@@ -170,6 +170,15 @@ class Tensor {\n   /// for details.\n   explicit Tensor(DataType type);\n \n+  /// \\brief Initializes a tensor with the input `type` and `shape`, or returns\n+  /// an error and leaves `out_tensor` unmodified. This factory method should be\n+  /// used instead of the corresponding constructor if calling code cannot\n+  /// validate that the `DataType` is valid and supported.\n+  ///\n+  /// The underlying buffer is allocated using a `CPUAllocator`.\n+  static Status BuildTensor(DataType type, const TensorShape& shape,\n+                            Tensor* out_tensor);\n+\n  private:\n   // A tag type for selecting the `Tensor` constructor overload that creates a\n   // scalar tensor in host memory.\ndiff --git a/tensorflow/core/util/tensor_slice_reader.cc b/tensorflow/core/util/tensor_slice_reader.cc\nindex 58c4c22ce7a9e2..00911b13f34914 100644\n--- a/tensorflow/core/util/tensor_slice_reader.cc\n+++ b/tensorflow/core/util/tensor_slice_reader.cc\n@@ -248,7 +248,9 @@ Status TensorSliceReader::GetTensor(\n     slice = tss->Slices().begin()->second.slice;\n   }\n \n-  std::unique_ptr<tensorflow::Tensor> t(new tensorflow::Tensor(type, shape));\n+  std::unique_ptr<tensorflow::Tensor> t(new tensorflow::Tensor);\n+  Status s = tensorflow::Tensor::BuildTensor(type, shape, t.get());\n+  if (!s.ok()) return s;\n   bool success = false;\n \n #define READER_COPY(dt)                                                  \\\ndiff --git a/tensorflow/core/util/tensor_slice_reader_test.cc b/tensorflow/core/util/tensor_slice_reader_test.cc\nindex e6e65fc2e6c96d..9bd3063d4ebec3 100644\n--- a/tensorflow/core/util/tensor_slice_reader_test.cc\n+++ b/tensorflow/core/util/tensor_slice_reader_test.cc\n@@ -13,15 +13,19 @@ See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*/\n \n-#include <utility>\n-\n #include \"tensorflow/core/util/tensor_slice_reader.h\"\n \n+#include <utility>\n+#include <vector>\n+\n #include \"tensorflow/core/framework/types.h\"\n #include \"tensorflow/core/framework/versions.pb.h\"\n #include \"tensorflow/core/lib/core/status_test_util.h\"\n #include \"tensorflow/core/lib/core/stringpiece.h\"\n+#include \"tensorflow/core/lib/io/iterator.h\"\n #include \"tensorflow/core/lib/io/path.h\"\n+#include \"tensorflow/core/lib/io/table.h\"\n+#include \"tensorflow/core/lib/io/table_builder.h\"\n #include \"tensorflow/core/lib/strings/str_util.h\"\n #include \"tensorflow/core/lib/strings/strcat.h\"\n #include \"tensorflow/core/platform/env.h\"\n@@ -30,6 +34,7 @@ limitations under the License.\n #include \"tensorflow/core/platform/test.h\"\n #include \"tensorflow/core/platform/types.h\"\n #include \"tensorflow/core/public/version.h\"\n+#include \"tensorflow/core/util/saved_tensor_slice.pb.h\"\n #include \"tensorflow/core/util/saved_tensor_slice_util.h\"\n #include \"tensorflow/core/util/tensor_slice_reader_cache.h\"\n #include \"tensorflow/core/util/tensor_slice_writer.h\"\n@@ -309,6 +314,102 @@ TEST_SIMPLE_INT(int16, int32)\n TEST_SIMPLE_INT(int8, int32)\n TEST_SIMPLE_INT(uint8, int32)\n \n+// Modifies the SavedTensorSlices messages in a checkpoint to allow creating\n+// malformed or unsupported checkpoints.\n+void MutateSavedTensorSlices(\n+    const std::string& fname,\n+    const std::function<std::string(SavedTensorSlices)>& mutator) {\n+  table::Options options;\n+  options.compression = table::kNoCompression;\n+\n+  // Read all entres from the table.\n+  std::vector<std::pair<std::string, std::string>> entries;\n+  {\n+    std::unique_ptr<RandomAccessFile> file;\n+    TF_CHECK_OK(Env::Default()->NewRandomAccessFile(fname, &file));\n+    uint64 file_size;\n+    TF_CHECK_OK(Env::Default()->GetFileSize(fname, &file_size));\n+    table::Table* t;\n+    TF_CHECK_OK(table::Table::Open(options, file.get(), file_size, &t));\n+    std::unique_ptr<table::Table> table(t);\n+    std::unique_ptr<table::Iterator> it(table->NewIterator());\n+    for (it->Seek(\"\"); it->Valid(); it->Next()) {\n+      entries.emplace_back(it->key(), it->value());\n+    }\n+    TF_CHECK_OK(it->status());\n+  }\n+\n+  // Rewrite the table, mutating each value.\n+  {\n+    std::unique_ptr<WritableFile> file;\n+    TF_CHECK_OK(Env::Default()->NewWritableFile(fname, &file));\n+    table::TableBuilder builder(options, file.get());\n+    for (const auto& entry : entries) {\n+      SavedTensorSlices sts;\n+      CHECK(sts.ParseFromString(entry.second));\n+      builder.Add(entry.first, mutator(std::move(sts)));\n+    }\n+    TF_CHECK_OK(builder.Finish());\n+    TF_CHECK_OK(file->Close());\n+  }\n+}\n+\n+TEST(TensorSliceReaderTest, MissingTensorType) {\n+  const string fname = io::JoinPath(testing::TmpDir(), \"invalid_checkpoint\");\n+  TensorSliceWriter writer(fname, CreateTableTensorSliceBuilder);\n+  const int32 data[] = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9};\n+  TensorShape shape({4, 5});\n+  TensorSlice slice = TensorSlice::ParseOrDie(\"0,2:-\");\n+  TF_CHECK_OK(writer.Add(\"test\", shape, slice, data));\n+  TF_CHECK_OK(writer.Finish());\n+\n+  MutateSavedTensorSlices(fname, [](SavedTensorSlices sts) {\n+    if (sts.has_meta()) {\n+      for (auto& tensor : *sts.mutable_meta()->mutable_tensor()) {\n+        tensor.clear_type();\n+      }\n+    }\n+    return sts.SerializeAsString();\n+  });\n+\n+  TensorSliceReader reader(fname, OpenTableTensorSliceReader);\n+  TF_CHECK_OK(reader.status());\n+\n+  // The tensor should be present, but loading it should fail due to the\n+  // unset (invalid) type.\n+  EXPECT_TRUE(reader.HasTensor(\"test\", nullptr, nullptr));\n+  std::unique_ptr<Tensor> tensor;\n+  EXPECT_FALSE(reader.GetTensor(\"test\", &tensor).ok());\n+}\n+\n+TEST(TensorSliceReaderTest, UnsupportedTensorType) {\n+  const string fname = io::JoinPath(testing::TmpDir(), \"int32_ref_checkpoint\");\n+  TensorSliceWriter writer(fname, CreateTableTensorSliceBuilder);\n+  const int32 data[] = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9};\n+  TensorShape shape({4, 5});\n+  TensorSlice slice = TensorSlice::ParseOrDie(\"0,2:-\");\n+  TF_CHECK_OK(writer.Add(\"test\", shape, slice, data));\n+  TF_CHECK_OK(writer.Finish());\n+\n+  MutateSavedTensorSlices(fname, [](SavedTensorSlices sts) {\n+    if (sts.has_meta()) {\n+      for (auto& tensor : *sts.mutable_meta()->mutable_tensor()) {\n+        tensor.set_type(DT_INT32_REF);\n+      }\n+    }\n+    return sts.SerializeAsString();\n+  });\n+\n+  TensorSliceReader reader(fname, OpenTableTensorSliceReader);\n+  TF_CHECK_OK(reader.status());\n+\n+  // The tensor should be present, but loading it should fail due to the\n+  // unsupported type.\n+  EXPECT_TRUE(reader.HasTensor(\"test\", nullptr, nullptr));\n+  std::unique_ptr<Tensor> tensor;\n+  EXPECT_FALSE(reader.GetTensor(\"test\", &tensor).ok());\n+}\n+\n void CachedTensorSliceReaderTesterHelper(\n     const TensorSliceWriter::CreateBuilderFunction& create_function,\n     const TensorSliceReader::OpenTableFunction& open_function) {\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "e84c975313e8e8e38bb2ea118196369c45c51378",
        "repo": "tensorflow/tensorflow",
        "msg": "In tf.raw_ops.BoostedTreesSparseCalculateBestFeatureSplit, limit stat_dim in stats_summary_indices to under stats_dims in stats_summary_shape\n\nPiperOrigin-RevId: 387171191\nChange-Id: I83ca8a75b22aa78c037e8b98779da6cced16bfaaTensorFlow is an end-to-end open source platform for machine learning. In affected versions an attacker can read from outside of bounds of heap allocated data by sending specially crafted illegal arguments to `BoostedTreesSparseCalculateBestFeatureSplit`. The [implementation](https://github.com/tensorflow/tensorflow/blob/84d053187cb80d975ef2b9684d4b61981bca0c41/tensorflow/core/kernels/boosted_trees/stats_ops.cc) needs to validate that each value in `stats_summary_indices` is in range. We have patched the issue in GitHub commit e84c975313e8e8e38bb2ea118196369c45c51378. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "filename": "stats_ops.cc",
        "diff": "diff --git a/tensorflow/core/kernels/boosted_trees/stats_ops.cc b/tensorflow/core/kernels/boosted_trees/stats_ops.cc\nindex 014c2ec22c9cf6..2636909855a386 100644\n--- a/tensorflow/core/kernels/boosted_trees/stats_ops.cc\n+++ b/tensorflow/core/kernels/boosted_trees/stats_ops.cc\n@@ -1050,6 +1050,13 @@ class BoostedTreesSparseCalculateBestFeatureSplitOp : public OpKernel {\n       const int32_t feature_dim = stats_summary_indices(idx, 1);\n       const int32_t bucket_id = stats_summary_indices(idx, 2);\n       const int32_t stat_dim = stats_summary_indices(idx, 3);\n+      OP_REQUIRES(context, stat_dim < stats_dims,\n+                  errors::InvalidArgument(\n+                      \"Stat dim, the sum of logits dim and hessian dim in \"\n+                      \"stats_summary_indices, cannot be greater than stats \"\n+                      \"dims, the last value in stats_summary_shape, which was \",\n+                      stats_dims, \". At index (\", idx,\n+                      \", 4), stats_summary_indices contains value \", stat_dim));\n       std::pair<FeatureMapIterator, bool> const& f_insert_result = f_map.insert(\n           FeatureMapIterator::value_type(feature_dim, BucketMap()));\n       auto& b_map = f_insert_result.first->second;\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "6a40a85ff239497c6458c7dbef18f6a2736fe992",
        "repo": "nginx/njs",
        "msg": "Fixed type confusion bug while resolving promises.\n\nPreviously, the internal function njs_promise_perform_then() which\nimplements PerformPromiseThen() expects its first argument to always be\na promise instance.  This assertion might be invalid because the\nfunctions corresponding to Promise.prototype.then() and\nPromise.resolve() incorrectly verified their arguments.\n\nSpecifically, the functions recognized their first argument as promise\nif it was an object which was an Promise or had Promise object in its\nprototype chain.  The later condition is not correct because internal\nslots are not inherited according to the spec.\n\nThis closes #447 issue in Github.njs through 0.7.1, used in NGINX, was discovered to contain a control flow hijack caused by a Type Confusion vulnerability in njs_promise_perform_then().",
        "filename": "njs_promise.c",
        "diff": "diff --git a/src/njs_promise.c b/src/njs_promise.c\nindex 45ea4921c..52ae5b570 100644\n--- a/src/njs_promise.c\n+++ b/src/njs_promise.c\n@@ -771,25 +771,19 @@ njs_promise_resolve(njs_vm_t *vm, njs_value_t *constructor, njs_value_t *x)\n {\n     njs_int_t                 ret;\n     njs_value_t               value;\n-    njs_object_t              *object;\n     njs_promise_capability_t  *capability;\n \n     static const njs_value_t  string_constructor = njs_string(\"constructor\");\n \n-    if (njs_is_object(x)) {\n-        object = njs_object_proto_lookup(njs_object(x), NJS_PROMISE,\n-                                         njs_object_t);\n-\n-        if (object != NULL) {\n-            ret = njs_value_property(vm, x, njs_value_arg(&string_constructor),\n-                                     &value);\n-            if (njs_slow_path(ret == NJS_ERROR)) {\n-                return NULL;\n-            }\n+    if (njs_is_promise(x)) {\n+        ret = njs_value_property(vm, x, njs_value_arg(&string_constructor),\n+                                 &value);\n+        if (njs_slow_path(ret == NJS_ERROR)) {\n+            return NULL;\n+        }\n \n-            if (njs_values_same(&value, constructor)) {\n-                return njs_promise(x);\n-            }\n+        if (njs_values_same(&value, constructor)) {\n+            return njs_promise(x);\n         }\n     }\n \n@@ -875,19 +869,12 @@ njs_promise_prototype_then(njs_vm_t *vm, njs_value_t *args, njs_uint_t nargs,\n {\n     njs_int_t                 ret;\n     njs_value_t               *promise, *fulfilled, *rejected, constructor;\n-    njs_object_t              *object;\n     njs_function_t            *function;\n     njs_promise_capability_t  *capability;\n \n     promise = njs_argument(args, 0);\n \n-    if (njs_slow_path(!njs_is_object(promise))) {\n-        goto failed;\n-    }\n-\n-    object = njs_object_proto_lookup(njs_object(promise), NJS_PROMISE,\n-                                     njs_object_t);\n-    if (njs_slow_path(object == NULL)) {\n+    if (njs_slow_path(!njs_is_promise(promise))) {\n         goto failed;\n     }\n \n@@ -933,6 +920,8 @@ njs_promise_perform_then(njs_vm_t *vm, njs_value_t *value,\n     njs_promise_data_t      *data;\n     njs_promise_reaction_t  *fulfilled_reaction, *rejected_reaction;\n \n+    njs_assert(njs_is_promise(value));\n+\n     if (!njs_is_function(fulfilled)) {\n         fulfilled = njs_value_arg(&njs_value_undefined);\n     }\ndiff --git a/src/njs_vmcode.c b/src/njs_vmcode.c\nindex 759112550..b371c3748 100644\n--- a/src/njs_vmcode.c\n+++ b/src/njs_vmcode.c\n@@ -1895,7 +1895,7 @@ njs_vmcode_await(njs_vm_t *vm, njs_vmcode_await_t *await)\n     rejected->args_count = 1;\n     rejected->u.native = njs_await_rejected;\n \n-    njs_set_object(&val, &promise->object);\n+    njs_set_promise(&val, promise);\n     njs_set_function(&on_fulfilled, fulfilled);\n     njs_set_function(&on_rejected, rejected);\n \ndiff --git a/test/js/promise_prototype_reject_type_confusion.t.js b/test/js/promise_prototype_reject_type_confusion.t.js\nnew file mode 100644\nindex 000000000..0201f29c0\n--- /dev/null\n+++ b/test/js/promise_prototype_reject_type_confusion.t.js\n@@ -0,0 +1,11 @@\n+/*---\n+includes: []\n+flags: [async]\n+---*/\n+\n+Symbol.__proto__ = new Promise(()=>{});\n+\n+Promise.reject(Symbol)\n+.then(v => $DONOTEVALUATE())\n+.catch(err => assert.sameValue(err.name, 'Symbol'))\n+.then($DONE, $DONE);\ndiff --git a/test/js/promise_prototype_then_type_confusion.t.js b/test/js/promise_prototype_then_type_confusion.t.js\nnew file mode 100644\nindex 000000000..72b687cf3\n--- /dev/null\n+++ b/test/js/promise_prototype_then_type_confusion.t.js\n@@ -0,0 +1,11 @@\n+/*---\n+includes: []\n+flags: [async]\n+---*/\n+\n+Symbol.__proto__ = new Promise(()=>{});\n+\n+Promise.resolve(Symbol)\n+.then(v => $DONOTEVALUATE())\n+.catch(err => assert.sameValue(err.name, 'TypeError'))\n+.then($DONE, $DONE);\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "eafe4c7a326b163612f10861392622b5da5b1792",
        "repo": "nginx/njs",
        "msg": "Fixed Array.prototype.lastIndexOf() with unicode string as \"this\".\n\nPreviously, when lastIndexOf() was called with unicode string as \"this\"\nargument and a negative \"fromIndex\" argument null-pointer dererence\nmight occur because njs_string_offset() was called with invalid index\nvalue whereas njs_string_offset() should always be called with valid\nindex argument.\n\nThe fix is to verify that from index is valid.\n\nThis closes #482 issue on Github.Nginx NJS v0.7.2 was discovered to contain a segmentation violation in the function njs_string_offset at src/njs_string.c.",
        "filename": "njs_iterator.c",
        "diff": "diff --git a/src/njs_iterator.c b/src/njs_iterator.c\nindex 90c3046fb..043e4483c 100644\n--- a/src/njs_iterator.c\n+++ b/src/njs_iterator.c\n@@ -560,11 +560,14 @@ njs_object_iterate_reverse(njs_vm_t *vm, njs_iterator_args_t *args,\n         } else {\n             /* UTF-8 string. */\n \n-            p = njs_string_offset(string_prop.start, end, from);\n-            p = njs_utf8_next(p, end);\n-\n+            p = NULL;\n             i = from + 1;\n \n+            if (i > to) {\n+                p = njs_string_offset(string_prop.start, end, from);\n+                p = njs_utf8_next(p, end);\n+            }\n+\n             while (i-- > to) {\n                 pos = njs_utf8_prev(p);\n \ndiff --git a/src/test/njs_unit_test.c b/src/test/njs_unit_test.c\nindex def152aa8..0b73c77b3 100644\n--- a/src/test/njs_unit_test.c\n+++ b/src/test/njs_unit_test.c\n@@ -5103,6 +5103,9 @@ static njs_unit_test_t  njs_test[] =\n     { njs_str(\"Array.prototype.lastIndexOf.call({0:'undefined', length:0}, 'undefined')\"),\n       njs_str(\"-1\") },\n \n+    { njs_str(\"[1,0,-1,-2].map(v => Array.prototype.lastIndexOf.call('\u0424', '\u0424', v))\"),\n+      njs_str(\"0,0,0,-1\") },\n+\n     { njs_str(\"[''].lastIndexOf.call('00000000000000000000000000000\u043000')\"),\n       njs_str(\"-1\") },\n \n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "be7a4de6adfbd303ce08be4332554dff70362612",
        "repo": "tensorflow/tensorflow",
        "msg": "Ensure non-empty rt_nested_splits in tf.raw_ops.RaggedTensorToVariant\n\nPiperOrigin-RevId: 387664237\nChange-Id: Ia1700c34b5610873d63561abc86e23b46ead93b3TensorFlow is an end-to-end open source platform for machine learning. In affected versions an attacker can cause undefined behavior via binding a reference to null pointer in `tf.raw_ops.RaggedTensorToVariant`. The [implementation](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/core/kernels/ragged_tensor_to_variant_op.cc#L129) has an incomplete validation of the splits values, missing the case when the argument would be empty. We have patched the issue in GitHub commit be7a4de6adfbd303ce08be4332554dff70362612. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "filename": "ragged_tensor_to_variant_op.cc",
        "diff": "diff --git a/tensorflow/core/kernels/ragged_tensor_to_variant_op.cc b/tensorflow/core/kernels/ragged_tensor_to_variant_op.cc\nindex 687289cd38077a..ab86863e3a987f 100644\n--- a/tensorflow/core/kernels/ragged_tensor_to_variant_op.cc\n+++ b/tensorflow/core/kernels/ragged_tensor_to_variant_op.cc\n@@ -157,6 +157,12 @@ class RaggedTensorToVariantOp : public OpKernel {\n       return;\n     }\n \n+    // Checked here instead of at input in case batched_input_ is false\n+    OP_REQUIRES(context, ragged_nested_splits_len > 0,\n+                errors::InvalidArgument(\n+                    \"rt_nested_splits must be a list of one or more, but \"\n+                    \"received rt_nested_splits of length 0.\"));\n+\n     // Unbatch the Ragged Tensor and encode the components.\n     std::vector<RaggedTensorVariant> unbatched_ragged_input;\n     auto batched_splits_top_vec =\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "c79ba87153ee343401dbe9d1954d7f79e521eb14",
        "repo": "tensorflow/tensorflow",
        "msg": "Make Transpose's shape inference function validate that negative `perm` values are within the tensor's rank.\n\nPiperOrigin-RevId: 403252853\nChange-Id: Ia6b31b45b237312668bb31c2c3b3c7bbce2d2610TensorFlow is an open source platform for machine learning. In affected versions the shape inference function for `Transpose` is vulnerable to a heap buffer overflow. This occurs whenever `perm` contains negative elements. The shape inference function does not validate that the indices in `perm` are all valid. The fix will be included in TensorFlow 2.7.0. We will also cherrypick this commit on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.",
        "filename": "array_ops.cc",
        "diff": "diff --git a/tensorflow/core/ops/array_ops.cc b/tensorflow/core/ops/array_ops.cc\nindex 64bd4f38478542..14c9efae1ddd3b 100644\n--- a/tensorflow/core/ops/array_ops.cc\n+++ b/tensorflow/core/ops/array_ops.cc\n@@ -168,7 +168,7 @@ Status TransposeShapeFn(InferenceContext* c) {\n \n     for (int32_t i = 0; i < rank; ++i) {\n       int64_t in_idx = data[i];\n-      if (in_idx >= rank) {\n+      if (in_idx >= rank || in_idx <= -rank) {\n         return errors::InvalidArgument(\"perm dim \", in_idx,\n                                        \" is out of range of input rank \", rank);\n       }\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "bb6a0383ed553c286f87ca88c207f6774d5c4a8f",
        "repo": "tensorflow/tensorflow",
        "msg": "Prevent heap OOB read in TFLite's `gather_nd.cc`.\n\nPassing negative indices is illegal but there was a missing check so that resulted in OOB accesses.\n\nPiperOrigin-RevId: 387208551\nChange-Id: I6b7a8a62d3e7c13a16d81619e5bc23ae2cdbc7fdTensorFlow is an end-to-end open source platform for machine learning. In affected versions TFLite's [`GatherNd` implementation](https://github.com/tensorflow/tensorflow/blob/149562d49faa709ea80df1d99fc41d005b81082a/tensorflow/lite/kernels/gather_nd.cc#L124) does not support negative indices but there are no checks for this situation. Hence, an attacker can read arbitrary data from the heap by carefully crafting a model with negative values in `indices`. Similar issue exists in [`Gather` implementation](https://github.com/tensorflow/tensorflow/blob/149562d49faa709ea80df1d99fc41d005b81082a/tensorflow/lite/kernels/gather.cc). We have patched the issue in GitHub commits bb6a0383ed553c286f87ca88c207f6774d5c4a8f and eb921122119a6b6e470ee98b89e65d721663179d. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "filename": "gather_nd.cc",
        "diff": "diff --git a/tensorflow/lite/kernels/gather_nd.cc b/tensorflow/lite/kernels/gather_nd.cc\nindex 3ded771382569e..c39917b478505f 100644\n--- a/tensorflow/lite/kernels/gather_nd.cc\n+++ b/tensorflow/lite/kernels/gather_nd.cc\n@@ -123,6 +123,17 @@ TfLiteStatus GatherNdString(const TfLiteTensor* params,\n template <typename IndicesT>\n TfLiteStatus EvalGatherNd(TfLiteContext* context, const TfLiteTensor* params,\n                           const TfLiteTensor* indices, TfLiteTensor* output) {\n+  bool indices_has_only_positive_elements = true;\n+  const auto* indices_values = GetTensorData<IndicesT>(indices);\n+  const size_t num_indices = indices->bytes / sizeof(IndicesT);\n+  for (size_t i = 0; i < num_indices; i++) {\n+    if (indices_values[i] < 0) {\n+      indices_has_only_positive_elements = false;\n+      break;\n+    }\n+  }\n+  TF_LITE_ENSURE(context, indices_has_only_positive_elements);\n+\n   switch (params->type) {\n     case kTfLiteFloat32:\n       return GatherNd<float, IndicesT>(params, indices, output);\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "f9a70e79391f6d7c2a912d785239ee8effc1922d",
        "repo": "bonzini/qemu",
        "msg": "ui/vnc: limit client_cut_text msg payload size\n\ncurrently a malicious client could define a payload\nsize of 2^32 - 1 bytes and send up to that size of\ndata to the vnc server. The server would allocated\nthat amount of memory which could easily create an\nout of memory condition.\n\nThis patch limits the payload size to 1MB max.\n\nPlease note that client_cut_text messages are currently\nsilently ignored.\n\nSigned-off-by: Peter Lieven <pl@kamp.de>\nSigned-off-by: Gerd Hoffmann <kraxel@redhat.com>Integer overflow in the VNC display driver in QEMU before 2.1.0 allows attachers to cause a denial of service (process crash) via a CLIENT_CUT_TEXT message, which triggers an infinite loop.",
        "filename": "vnc.c",
        "diff": "diff --git a/ui/vnc.c b/ui/vnc.c\nindex 14a86c36ce66..19ce988f5509 100644\n--- a/ui/vnc.c\n+++ b/ui/vnc.c\n@@ -2165,13 +2165,20 @@ static int protocol_client_msg(VncState *vs, uint8_t *data, size_t len)\n         pointer_event(vs, read_u8(data, 1), read_u16(data, 2), read_u16(data, 4));\n         break;\n     case VNC_MSG_CLIENT_CUT_TEXT:\n-        if (len == 1)\n+        if (len == 1) {\n             return 8;\n-\n+        }\n         if (len == 8) {\n             uint32_t dlen = read_u32(data, 4);\n-            if (dlen > 0)\n+            if (dlen > (1 << 20)) {\n+                error_report(\"vnc: client_cut_text msg payload has %u bytes\"\n+                             \" which exceeds our limit of 1MB.\", dlen);\n+                vnc_client_error(vs);\n+                break;\n+            }\n+            if (dlen > 0) {\n                 return 8 + dlen;\n+            }\n         }\n \n         client_cut_text(vs, read_u32(data, 4), data + 8);\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "368af875869a204b4ac552b9ddda59f6a46a56ec",
        "repo": "tensorflow/tensorflow",
        "msg": "Avoid buffer overflow when loading tensors with insufficient data from checkpoints.\n\n`CopyDataFromTensorSliceToTensorSlice` does not (and cannot conveniently)\nprovide any bounds checking on its own, so the size is instead checked prior\nto passing unvalidated data to that function.\n\nPiperOrigin-RevId: 392971286\nChange-Id: If2073b36d4d5eedd386329f56729395fd7effee1TensorFlow is an open source platform for machine learning. In affected versions an attacker can trigger undefined behavior, integer overflows, segfaults and `CHECK`-fail crashes if they can change saved checkpoints from outside of TensorFlow. This is because the checkpoints loading infrastructure is missing validation for invalid file formats. The fixes will be included in TensorFlow 2.7.0. We will also cherrypick these commits on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.",
        "filename": "tensor_slice_reader.h",
        "diff": "diff --git a/tensorflow/core/util/saved_tensor_slice_util.h b/tensorflow/core/util/saved_tensor_slice_util.h\nindex d0b08b3c294e06..b992061a15df93 100644\n--- a/tensorflow/core/util/saved_tensor_slice_util.h\n+++ b/tensorflow/core/util/saved_tensor_slice_util.h\n@@ -59,6 +59,9 @@ Status ParseShapeAndSlice(const string& shape_and_slice, TensorShape* shape,\n template <typename T>\n struct SaveTypeTraits;\n \n+template <typename T>\n+int TensorProtoDataSize(const TensorProto& t);\n+\n template <typename T>\n const typename SaveTypeTraits<T>::SavedType* TensorProtoData(\n     const TensorProto& t);\n@@ -95,6 +98,10 @@ void Fill(T* data, size_t n, TensorProto* t);\n #define TENSOR_PROTO_EXTRACT_TYPE(TYPE, FIELD, FTYPE)             \\\n   TENSOR_PROTO_EXTRACT_TYPE_HELPER(TYPE, FIELD, FTYPE, FTYPE)     \\\n   template <>                                                     \\\n+  inline int TensorProtoDataSize<TYPE>(const TensorProto& t) {    \\\n+    return t.FIELD##_val_size();                                  \\\n+  }                                                               \\\n+  template <>                                                     \\\n   inline void Fill(const TYPE* data, size_t n, TensorProto* t) {  \\\n     typename protobuf::RepeatedField<FTYPE> copy(data, data + n); \\\n     t->mutable_##FIELD##_val()->Swap(&copy);                      \\\n@@ -104,6 +111,10 @@ void Fill(T* data, size_t n, TensorProto* t);\n #define TENSOR_PROTO_EXTRACT_TYPE_COMPLEX(TYPE, FIELD, FTYPE)       \\\n   TENSOR_PROTO_EXTRACT_TYPE_HELPER(TYPE, FIELD, FTYPE, TYPE)        \\\n   template <>                                                       \\\n+  inline int TensorProtoDataSize<TYPE>(const TensorProto& t) {      \\\n+    return t.FIELD##_val_size() / 2;                                \\\n+  }                                                                 \\\n+  template <>                                                       \\\n   inline void Fill(const TYPE* data, size_t n, TensorProto* t) {    \\\n     const FTYPE* sub = reinterpret_cast<const FTYPE*>(data);        \\\n     typename protobuf::RepeatedField<FTYPE> copy(sub, sub + 2 * n); \\\n@@ -136,6 +147,11 @@ TENSOR_PROTO_EXTRACT_TYPE(quint16, int, int32);\n template <>\n struct SaveTypeTraits<qint32> : SaveTypeTraits<int32> {};\n \n+template <>\n+inline int TensorProtoDataSize<qint32>(const TensorProto& t) {\n+  return t.int_val_size();\n+}\n+\n template <>\n inline const int32* TensorProtoData<qint32>(const TensorProto& t) {\n   static_assert(SaveTypeTraits<qint32>::supported,\n@@ -158,6 +174,11 @@ struct SaveTypeTraits<Eigen::half> {\n   typedef protobuf::RepeatedField<int32> RepeatedField;\n };\n \n+template <>\n+inline int TensorProtoDataSize<Eigen::half>(const TensorProto& t) {\n+  return t.half_val_size();\n+}\n+\n template <>\n inline const int* TensorProtoData<Eigen::half>(const TensorProto& t) {\n   return t.half_val().data();\n@@ -187,6 +208,11 @@ struct SaveTypeTraits<tstring> {\n   typedef protobuf::RepeatedPtrField<string> RepeatedField;\n };\n \n+template <>\n+inline int TensorProtoDataSize<tstring>(const TensorProto& t) {\n+  return t.string_val_size();\n+}\n+\n template <>\n inline const string* const* TensorProtoData<tstring>(const TensorProto& t) {\n   static_assert(SaveTypeTraits<tstring>::supported,\ndiff --git a/tensorflow/core/util/tensor_slice_reader.h b/tensorflow/core/util/tensor_slice_reader.h\nindex 0fb2e11bf8dd08..bc0a91523fe36c 100644\n--- a/tensorflow/core/util/tensor_slice_reader.h\n+++ b/tensorflow/core/util/tensor_slice_reader.h\n@@ -181,6 +181,22 @@ bool TensorSliceReader::CopySliceData(const string& name,\n               << slice_s.DebugString() << \": computed key = \" << key;\n       return false;\n     }\n+    // Ensure the TensorSlice contains the expected amount of data.\n+    TensorShape shp_s;\n+    Status s = slice_s.SliceTensorShape(tss->shape(), &shp_s);\n+    if (!s.ok()) {\n+      VLOG(1) << \"Failed to slice tensor \" << name << \", slice \"\n+              << slice_s.DebugString() << \": \" << s;\n+      return false;\n+    }\n+    if (checkpoint::TensorProtoDataSize<T>(sts.data().data()) !=\n+        shp_s.num_elements()) {\n+      VLOG(1) << \"Tensor \" << name << \", slice \" << slice_s.DebugString()\n+              << \" had an unexpected amount of data: expected = \"\n+              << shp_s.num_elements() << \", got = \"\n+              << checkpoint::TensorProtoDataSize<T>(sts.data().data());\n+      return false;\n+    }\n     CopyDataFromTensorSliceToTensorSlice(\n         tss->shape(), slice_s, slice,\n         checkpoint::TensorProtoData<T>(sts.data().data()), data);\ndiff --git a/tensorflow/core/util/tensor_slice_reader_test.cc b/tensorflow/core/util/tensor_slice_reader_test.cc\nindex 53993862385e3e..efb2d9d9748fd5 100644\n--- a/tensorflow/core/util/tensor_slice_reader_test.cc\n+++ b/tensorflow/core/util/tensor_slice_reader_test.cc\n@@ -459,6 +459,33 @@ TEST(TensorSliceReaderTest, InvalidTensorSlice) {\n   EXPECT_FALSE(reader.status().ok());\n }\n \n+TEST(TensorSliceReaderTest, MissingTensorData) {\n+  const string fname =\n+      io::JoinPath(testing::TmpDir(), \"missing_data_checkpoint\");\n+  TensorSliceWriter writer(fname, CreateTableTensorSliceBuilder);\n+  const int32 data[] = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9};\n+  TF_ASSERT_OK(writer.Add(\"test\", TensorShape({4, 5}),\n+                          TensorSlice::ParseOrDie(\"0,2:-\"), data));\n+  TF_ASSERT_OK(writer.Finish());\n+\n+  MutateSavedTensorSlices(fname, [&](SavedTensorSlices sts) {\n+    if (sts.has_data()) {\n+      // Replace the data with only 4 elements.\n+      Fill(data, 4, sts.mutable_data()->mutable_data());\n+    }\n+    return sts.SerializeAsString();\n+  });\n+\n+  TensorSliceReader reader(fname, OpenTableTensorSliceReader);\n+  TF_ASSERT_OK(reader.status());\n+\n+  // The tensor should be present, but loading it should fail due to the missing\n+  // data.\n+  EXPECT_TRUE(reader.HasTensor(\"test\", nullptr, nullptr));\n+  std::unique_ptr<Tensor> tensor;\n+  EXPECT_FALSE(reader.GetTensor(\"test\", &tensor).ok());\n+}\n+\n void CachedTensorSliceReaderTesterHelper(\n     const TensorSliceWriter::CreateBuilderFunction& create_function,\n     const TensorSliceReader::OpenTableFunction& open_function) {\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "4aacb30888638da75023e6601149415b39763d76",
        "repo": "tensorflow/tensorflow",
        "msg": "Disallow division by zero FPE in `tf.raw_ops.ResourceScatterDiv`\n\nHad to update a test that was broken.\n\nPiperOrigin-RevId: 388516976\nChange-Id: Ic358e6bf0559e011539974d453fc7aa18b427e9cTensorFlow is an end-to-end open source platform for machine learning. In affected versions the implementation of `tf.raw_ops.ResourceScatterDiv` is vulnerable to a division by 0 error. The [implementation](https://github.com/tensorflow/tensorflow/blob/8d72537c6abf5a44103b57b9c2e22c14f5f49698/tensorflow/core/kernels/resource_variable_ops.cc#L865) uses a common class for all binary operations but fails to treat the division by 0 case separately. We have patched the issue in GitHub commit 4aacb30888638da75023e6601149415b39763d76. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "filename": "resource_variable_ops.cc",
        "diff": "diff --git a/tensorflow/core/kernels/resource_variable_ops.cc b/tensorflow/core/kernels/resource_variable_ops.cc\nindex b81a7a517ea6d2..1a74774785f946 100644\n--- a/tensorflow/core/kernels/resource_variable_ops.cc\n+++ b/tensorflow/core/kernels/resource_variable_ops.cc\n@@ -873,6 +873,35 @@ TF_CALL_GPU_NUMBER_TYPES(REGISTER_GATHER_ND_GPU);\n #undef REGISTER_GATHER_ND_ALL_INDICES\n #undef REGISTER_GATHER_ND_FULL\n \n+namespace {\n+\n+template <typename Device>\n+bool isCPUDevice() {\n+  return false;\n+}\n+\n+template <>\n+bool isCPUDevice<CPUDevice>() {\n+  return true;\n+}\n+\n+template <typename T>\n+bool ValidateInput(const Tensor& updates) {\n+  const auto updates_flat = updates.flat<T>();\n+  const T zero(0);\n+  for (int i = 0; i < updates.NumElements(); i++) {\n+    if (updates_flat(i) == zero) return false;\n+  }\n+  return true;\n+}\n+\n+template <>\n+bool ValidateInput<Variant>(const Tensor& updates) {\n+  return true;\n+}\n+\n+}  // namespace\n+\n template <typename Device, typename T, typename Index, scatter_op::UpdateOp op>\n class ResourceScatterUpdateOp : public OpKernel {\n  public:\n@@ -939,6 +968,12 @@ class ResourceScatterUpdateOp : public OpKernel {\n                                 \" indexing: \", params->dim_size(0), \" > \",\n                                 std::numeric_limits<Index>::max()));\n \n+    // Prevent division by 0\n+    if (isCPUDevice<Device>() && op == tensorflow::scatter_op::UpdateOp::DIV) {\n+      OP_REQUIRES(c, ValidateInput<T>(updates),\n+                  errors::InvalidArgument(\"updates must not contain 0\"));\n+    }\n+\n     if (N > 0) {\n       auto indices_flat = indices.flat<Index>();\n       auto params_flat = params->flat_outer_dims<T>();\ndiff --git a/tensorflow/python/distribute/sharded_variable_test.py b/tensorflow/python/distribute/sharded_variable_test.py\nindex 9e1a32dc70286c..cb61cd5715aca1 100644\n--- a/tensorflow/python/distribute/sharded_variable_test.py\n+++ b/tensorflow/python/distribute/sharded_variable_test.py\n@@ -175,8 +175,9 @@ def func():\n                             'scatter_update')\n   def test_scatter_ops_even_partition(self, op):\n     v = variables_lib.Variable(array_ops.zeros((30, 1)))\n+    # Make sure values does not contain 0 due to testing `scatter_div`!\n     sparse_delta = ops.IndexedSlices(\n-        values=constant_op.constant([[0.], [1.], [2.], [3.], [4.]]),\n+        values=constant_op.constant([[1.], [2.], [3.], [4.], [5.]]),\n         indices=constant_op.constant([0, 10, 12, 21, 22]))\n \n     v0 = variables_lib.Variable(array_ops.zeros((10, 1)))\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "35bf0b7b048d715f671eb68974fb6b4af6528c67",
        "repo": "ClusterLabs/booth",
        "msg": "Revert \"Refactor: main: substitute is_auth_req macro\"\n\nThis reverts commit da79b8ba28ad4837a0fee13e5f8fb6f89fe0e24c.\n\nauthfile != authkey\n\nSigned-off-by: Jan Friesse <jfriesse@redhat.com>The authfile directive in the booth config file is ignored, preventing use of authentication in communications from node to node. As a result, nodes that do not have the correct authentication key are not prevented from communicating with other nodes in the cluster.",
        "filename": "main.c",
        "diff": "diff --git a/src/main.c b/src/main.c\nindex b50a8834..b4a174f4 100644\n--- a/src/main.c\n+++ b/src/main.c\n@@ -364,7 +364,7 @@ static int setup_config(int type)\n \tif (rv < 0)\n \t\tgoto out;\n \n-\tif (is_auth_req()) {\n+\tif (booth_conf->authfile[0] != '\\0') {\n \t\trv = read_authkey();\n \t\tif (rv < 0)\n \t\t\tgoto out;\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "20cb18724b0bf6c09071a3f53434c4eec53cc147",
        "repo": "tensorflow/tensorflow",
        "msg": "Allow 0 for number of segments in `unsorted_segment_join_op.cc`\n\nRelated to the fix for #55305\n\nPiperOrigin-RevId: 443157549TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, the implementation of `tf.raw_ops.UnsortedSegmentJoin` does not fully validate the input arguments. This results in a `CHECK`-failure which can be used to trigger a denial of service attack. The code assumes `num_segments` is a positive scalar but there is no validation. Since this value is used to allocate the output tensor, a negative value would result in a `CHECK`-failure (assertion failure), as per TFSA-2021-198. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.",
        "filename": "unsorted_segment_join_op.cc",
        "diff": "diff --git a/tensorflow/core/kernels/unsorted_segment_join_op.cc b/tensorflow/core/kernels/unsorted_segment_join_op.cc\nindex 860cec8010042c..c8445ca4c4c596 100644\n--- a/tensorflow/core/kernels/unsorted_segment_join_op.cc\n+++ b/tensorflow/core/kernels/unsorted_segment_join_op.cc\n@@ -94,8 +94,10 @@ class UnsortedSegmentJoinOp : public OpKernel {\n                 errors::InvalidArgument(\"Number of segments cannot be empty.\"));\n     auto num_segments = num_segments_tensor.scalar<NUM_SEGMENTS_TYPE>()();\n \n-    OP_REQUIRES(context, num_segments > 0,\n-                errors::InvalidArgument(\"Number of segments must be positive\"));\n+    OP_REQUIRES(\n+        context, num_segments >= 0,\n+        errors::InvalidArgument(\n+            \"Number of segments must be non-negative but got \", num_segments));\n     OP_REQUIRES(context, segment_dims != 0,\n                 errors::InvalidArgument(\"Segment_id cannot have rank 0\"));\n \n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "b1d0296a937fe278239bdfac840a3fd0e93b3ee9",
        "repo": "mruby/mruby",
        "msg": "class.c: clear method cache after `remove_method`.heap-buffer-overflow in mrb_vm_exec in mruby/mruby in GitHub repository mruby/mruby prior to 3.2. Possible arbitrary code execution if being exploited.",
        "filename": "class.c",
        "diff": "diff --git a/src/class.c b/src/class.c\nindex 37fc4e68a4..68a0ff0843 100644\n--- a/src/class.c\n+++ b/src/class.c\n@@ -2361,7 +2361,10 @@ mrb_remove_method(mrb_state *mrb, struct RClass *c, mrb_sym mid)\n   MRB_CLASS_ORIGIN(c);\n   h = c->mt;\n \n-  if (h && mt_del(mrb, h, mid)) return;\n+  if (h && mt_del(mrb, h, mid)) {\n+    mrb_mc_clear_by_class(mrb, c);\n+    return;\n+  }\n   mrb_name_error(mrb, mid, \"method '%n' not defined in %C\", mid, c);\n }\n \n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "579261dcd446385831fe4f7457d802a59685121d",
        "repo": "tensorflow/tensorflow",
        "msg": "Fix crash in MatrixSolve when inputs have different batch dimensions.\n\nBefore, the process would crash or certain elements would be silently ignored. Now an InvalidArgument is raised.\n\nPiperOrigin-RevId: 384844020\nChange-Id: Iba44417e383bdd0e1abc4012bfca83b2377dd335TensorFlow is an open source platform for machine learning. In affected versions several TensorFlow operations are missing validation for the shapes of the tensor arguments involved in the call. Depending on the API, this can result in undefined behavior and segfault or `CHECK`-fail related crashes but in some scenarios writes and reads from heap populated arrays are also possible. We have discovered these issues internally via tooling while working on improving/testing GPU op determinism. As such, we don't have reproducers and there will be multiple fixes for these issues. These fixes will be included in TensorFlow 2.7.0. We will also cherrypick these commits on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.",
        "filename": "matrix_solve_op.cc",
        "diff": "diff --git a/tensorflow/core/kernels/linalg/matrix_solve_op.cc b/tensorflow/core/kernels/linalg/matrix_solve_op.cc\nindex 70f02bddf9b785..aeb0203b4a337d 100644\n--- a/tensorflow/core/kernels/linalg/matrix_solve_op.cc\n+++ b/tensorflow/core/kernels/linalg/matrix_solve_op.cc\n@@ -143,15 +143,22 @@ class MatrixSolveOpGpu : public AsyncOpKernel {\n                       done);\n     OP_REQUIRES_ASYNC(\n         context, input.dim_size(ndims - 2) == n,\n-        errors::InvalidArgument(\"Input matrices must be squares, got\",\n+        errors::InvalidArgument(\"Input matrices must be squares, got \",\n                                 input.dim_size(ndims - 2), \" != \", n),\n         done);\n     OP_REQUIRES_ASYNC(context, rhs.dim_size(ndims - 2) == n,\n                       errors::InvalidArgument(\n                           \"Input matrix and right-hand side must have the \"\n-                          \"same number of rows, got\",\n+                          \"same number of rows, got \",\n                           n, \" != \", rhs.dim_size(ndims - 2)),\n                       done);\n+    for (int dim = 0; dim < ndims - 2; dim++) {\n+      OP_REQUIRES_ASYNC(\n+          context, input.dim_size(dim) == rhs.dim_size(dim),\n+          errors::InvalidArgument(\n+              \"All input tensors must have the same outer dimensions.\"),\n+          done);\n+    }\n \n     // Allocate output.\n     Tensor* output;\ndiff --git a/tensorflow/python/kernel_tests/matrix_solve_op_test.py b/tensorflow/python/kernel_tests/matrix_solve_op_test.py\nindex 0d149de2acb5e5..1739b2272be810 100644\n--- a/tensorflow/python/kernel_tests/matrix_solve_op_test.py\n+++ b/tensorflow/python/kernel_tests/matrix_solve_op_test.py\n@@ -112,6 +112,12 @@ def testWrongDimensions(self):\n     with self.assertRaises((ValueError, errors_impl.InvalidArgumentError)):\n       self.evaluate(linalg_ops.matrix_solve(matrix, rhs))\n \n+    # The matrix and right-hand side should have the same batch dimensions\n+    matrix = np.random.normal(size=(2, 6, 2, 2))\n+    rhs = np.random.normal(size=(2, 3, 2, 2))\n+    with self.assertRaises((ValueError, errors_impl.InvalidArgumentError)):\n+      self.evaluate(linalg_ops.matrix_solve(matrix, rhs))\n+\n   def testNotInvertible(self):\n     # The input should be invertible.\n     with self.assertRaisesOpError(\"Input matrix is not invertible.\"):\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "cebe3c45d76357d201c65bdbbf0dbe6e8a63bbdb",
        "repo": "tensorflow/tensorflow",
        "msg": "Fix tf.raw_ops.StagePeek vulnerability with invalid `index`.\n\nCheck that input is actually a scalar before treating it as such.\n\nPiperOrigin-RevId: 445524908TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, the implementation of `tf.raw_ops.StagePeek` does not fully validate the input arguments. This results in a `CHECK`-failure which can be used to trigger a denial of service attack. The code assumes `index` is a scalar but there is no validation for this before accessing its value. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.",
        "filename": "stage_op.cc",
        "diff": "diff --git a/tensorflow/core/kernels/stage_op.cc b/tensorflow/core/kernels/stage_op.cc\nindex 55c9db22ddf527..f7bb42f9c52b7d 100644\n--- a/tensorflow/core/kernels/stage_op.cc\n+++ b/tensorflow/core/kernels/stage_op.cc\n@@ -258,6 +258,8 @@ class StagePeekOp : public OpKernel {\n     core::ScopedUnref scope(buf);\n     Buffer::Tuple tuple;\n \n+    OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(ctx->input(0).shape()),\n+                errors::InvalidArgument(\"index must be scalar\"));\n     std::size_t index = ctx->input(0).scalar<int>()();\n \n     OP_REQUIRES_OK(ctx, buf->Peek(index, &tuple));\ndiff --git a/tensorflow/python/kernel_tests/data_structures/stage_op_test.py b/tensorflow/python/kernel_tests/data_structures/stage_op_test.py\nindex c720155f3b6c90..d12624f1065928 100644\n--- a/tensorflow/python/kernel_tests/data_structures/stage_op_test.py\n+++ b/tensorflow/python/kernel_tests/data_structures/stage_op_test.py\n@@ -13,6 +13,7 @@\n # limitations under the License.\n # ==============================================================================\n from tensorflow.python.framework import dtypes\n+from tensorflow.python.framework import errors\n from tensorflow.python.framework import ops\n from tensorflow.python.framework import test_util\n from tensorflow.python.ops import array_ops\n@@ -134,6 +135,16 @@ def testPeek(self):\n       for i in range(10):\n         self.assertTrue(sess.run(peek, feed_dict={p: i}) == [i])\n \n+  def testPeekBadIndex(self):\n+    stager = data_flow_ops.StagingArea([\n+        dtypes.int32,\n+    ], shapes=[[10]])\n+    stager.put([array_ops.zeros([10], dtype=dtypes.int32)])\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                'must be scalar'):\n+      self.evaluate(stager.peek([]))\n+\n   @test_util.run_deprecated_v1\n   def testSizeAndClear(self):\n     with ops.Graph().as_default() as G:\ndiff --git a/tensorflow/python/ops/data_flow_ops.py b/tensorflow/python/ops/data_flow_ops.py\nindex 0076e54833de6c..42fd28c8cc1e60 100644\n--- a/tensorflow/python/ops/data_flow_ops.py\n+++ b/tensorflow/python/ops/data_flow_ops.py\n@@ -1737,7 +1737,7 @@ def _check_put_dtypes(self, vals, indices=None):\n \n     # Sanity check number of values\n     if not len(vals) <= len(self._dtypes):\n-      raise ValueError(f\"Unexpected number of inputs {len(vals)} vs\"\n+      raise ValueError(f\"Unexpected number of inputs {len(vals)} vs \"\n                        f\"{len(self._dtypes)}\")\n \n     tensors = []\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "71460d72ec07df766dab0a4d52687529f3efcf0a",
        "repo": "gpac/gpac",
        "msg": "fixed #1876GPAC version before commit 71460d72ec07df766dab0a4d52687529f3efcf0a (version v1.0.1 onwards) contains loop with unreachable exit condition ('infinite loop') vulnerability in ISOBMFF reader filter, isoffin_read.c. Function isoffin_process() can result in DoS by infinite loop. To exploit, the victim must open a specially crafted mp4 file.",
        "filename": "isoffin_read.c",
        "diff": "diff --git a/src/filters/isoffin_read.c b/src/filters/isoffin_read.c\nindex 899d3508a5..1f0d3742b5 100644\n--- a/src/filters/isoffin_read.c\n+++ b/src/filters/isoffin_read.c\n@@ -1453,6 +1453,13 @@ static GF_Err isoffin_process(GF_Filter *filter)\n \t\t\t\t\tgf_filter_pid_set_eos(ch->pid);\n \t\t\t\t}\n \t\t\t\tbreak;\n+\t\t\t} else if (ch->last_state==GF_ISOM_INVALID_FILE) {\n+\t\t\t\tif (!ch->eos_sent) {\n+\t\t\t\t\tch->eos_sent = GF_TRUE;\n+\t\t\t\t\tread->eos_signaled = GF_TRUE;\n+\t\t\t\t\tgf_filter_pid_set_eos(ch->pid);\n+\t\t\t\t}\n+\t\t\t\treturn ch->last_state;\n \t\t\t} else {\n \t\t\t\tread->force_fetch = GF_TRUE;\n \t\t\t\tbreak;\ndiff --git a/src/filters/isoffin_read_ch.c b/src/filters/isoffin_read_ch.c\nindex c9bde63876..90f5972eb1 100644\n--- a/src/filters/isoffin_read_ch.c\n+++ b/src/filters/isoffin_read_ch.c\n@@ -479,6 +479,10 @@ void isor_reader_get_sample(ISOMChannel *ch)\n \t\t\t\tif (!ch->has_edit_list && ch->sample_num)\n \t\t\t\t\tch->sample_num--;\n \t\t\t} else {\n+\t\t\t\tif (ch->to_init && ch->sample_num) {\n+\t\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[IsoMedia] Failed to fetch initial sample %d for track %d\\n\"));\n+\t\t\t\t\tch->last_state = GF_ISOM_INVALID_FILE;\n+\t\t\t\t}\n \t\t\t\tif (ch->sample_num >= gf_isom_get_sample_count(ch->owner->mov, ch->track)) {\n \t\t\t\t\tch->last_state = GF_EOS;\n \t\t\t\t}\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "67bfd9feeecfb3c61d80f0e46d89c170fbee682b",
        "repo": "tensorflow/tensorflow",
        "msg": "Make SparseFillEmptyRows validate that the length of `values` must be equal to the number of index tuples.\n\nPiperOrigin-RevId: 399969549\nChange-Id: I3c2f2ca1c1d2cc88bb5951c6958b38c16e9436c8TensorFlow is an open source platform for machine learning. In affected versions the implementation of `SparseFillEmptyRows` can be made to trigger a heap OOB access. This occurs whenever the size of `indices` does not match the size of `values`. The fix will be included in TensorFlow 2.7.0. We will also cherrypick this commit on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.",
        "filename": "sparse_fill_empty_rows_op.cc",
        "diff": "diff --git a/tensorflow/core/kernels/sparse_fill_empty_rows_op.cc b/tensorflow/core/kernels/sparse_fill_empty_rows_op.cc\nindex e0c7e18090b66d..59eb6076ed528b 100644\n--- a/tensorflow/core/kernels/sparse_fill_empty_rows_op.cc\n+++ b/tensorflow/core/kernels/sparse_fill_empty_rows_op.cc\n@@ -24,11 +24,13 @@ limitations under the License.\n #include <vector>\n \n #include \"tensorflow/core/framework/op_kernel.h\"\n+#include \"tensorflow/core/framework/op_requires.h\"\n #include \"tensorflow/core/framework/register_types.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n #include \"tensorflow/core/framework/tensor_util.h\"\n #include \"tensorflow/core/framework/types.h\"\n #include \"tensorflow/core/lib/gtl/inlined_vector.h\"\n+#include \"tensorflow/core/platform/errors.h\"\n #include \"tensorflow/core/util/sparse/sparse_tensor.h\"\n \n namespace tensorflow {\n@@ -222,6 +224,12 @@ void SparseFillEmptyRowsOpImpl(OpKernelContext* context,\n                     errors::InvalidArgument(\"values must be a vector, saw: \",\n                                             values_t.shape().DebugString()),\n                     done);\n+  OP_REQUIRES_ASYNC(\n+      context, indices_t.dim_size(0) == values_t.dim_size(0),\n+      errors::InvalidArgument(\"The length of `values` (\", values_t.dim_size(0),\n+                              \") must match the first dimension of `indices` (\",\n+                              indices_t.dim_size(0), \").\"),\n+      done);\n   OP_REQUIRES_ASYNC(\n       context, TensorShapeUtils::IsScalar(default_value_t.shape()),\n       errors::InvalidArgument(\"default_value must be a scalar, saw: \",\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "11ced8467eccad9c7cb94867708be8fa5c66c730",
        "repo": "tensorflow/tensorflow",
        "msg": "Fix UB in SparseTensorDenseAdd\n\nAdded more input validation to avoid nullptr dereferencing and array index\nout of bounds issues.\n\nPiperOrigin-RevId: 446192704TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, the implementation of `tf.raw_ops.SparseTensorDenseAdd` does not fully validate the input arguments. In this case, a reference gets bound to a `nullptr` during kernel execution. This is undefined behavior. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.",
        "filename": "sparse_tensor_dense_add_op.cc",
        "diff": "diff --git a/tensorflow/core/kernels/sparse_tensor_dense_add_op.cc b/tensorflow/core/kernels/sparse_tensor_dense_add_op.cc\nindex 48803e4b939800..6d6b05bf70f30a 100644\n--- a/tensorflow/core/kernels/sparse_tensor_dense_add_op.cc\n+++ b/tensorflow/core/kernels/sparse_tensor_dense_add_op.cc\n@@ -18,6 +18,7 @@ limitations under the License.\n #include \"tensorflow/core/kernels/sparse_tensor_dense_add_op.h\"\n \n #include \"tensorflow/core/framework/op_kernel.h\"\n+#include \"tensorflow/core/framework/op_requires.h\"\n #include \"tensorflow/core/framework/register_types.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n #include \"tensorflow/core/framework/tensor_util.h\"\n@@ -47,6 +48,17 @@ Status ValidateInputs(const Tensor *a_indices, const Tensor *a_values,\n         a_values->shape().DebugString(), \" and \",\n         a_shape->shape().DebugString());\n   }\n+  int64_t nnz = a_indices->dim_size(0);\n+  int64_t ndims = a_indices->dim_size(1);\n+  if (a_values->dim_size(0) != nnz) {\n+    return errors::InvalidArgument(\"Dimensions \", nnz, \" and \",\n+                                   a_values->dim_size(0),\n+                                   \" are not compatible\");\n+  }\n+  if (a_shape->dim_size(0) != ndims) {\n+    return errors::InvalidArgument(\"Dimensions \", ndims, \" and \",\n+                                   a_shape->dim_size(0), \" are not compatible\");\n+  }\n   if (a_shape->NumElements() != b->dims()) {\n     return errors::InvalidArgument(\n         \"Two operands have different ranks; received: \", a_shape->NumElements(),\n@@ -61,6 +73,24 @@ Status ValidateInputs(const Tensor *a_indices, const Tensor *a_values,\n           a_shape_flat(i), \" vs dense side \", b->dim_size(i));\n     }\n   }\n+\n+  // Check for invalid indices.\n+  const auto a_indices_mat = a_indices->flat_inner_dims<Index>();\n+\n+  for (int64_t zidx = 0; zidx < nnz; ++zidx) {\n+    for (int64_t didx = 0; didx < ndims; ++didx) {\n+      const Index idx = a_indices_mat(zidx, didx);\n+      if (idx < 0 || idx >= a_shape_flat(didx)) {\n+        return errors::InvalidArgument(\n+            \"Sparse tensor has an invalid index on dimension \", didx,\n+            \": \"\n+            \"a_indices(\",\n+            zidx, \",\", didx, \") = \", idx,\n+            \", dense tensor shape: \", a_shape_flat);\n+      }\n+    }\n+  }\n+\n   return Status::OK();\n }\n \ndiff --git a/tensorflow/python/kernel_tests/sparse_ops/sparse_add_op_test.py b/tensorflow/python/kernel_tests/sparse_ops/sparse_add_op_test.py\nindex 61ad45fb5e273e..821184af5b5699 100644\n--- a/tensorflow/python/kernel_tests/sparse_ops/sparse_add_op_test.py\n+++ b/tensorflow/python/kernel_tests/sparse_ops/sparse_add_op_test.py\n@@ -189,7 +189,6 @@ def testSparseTensorDenseAddGradients(self):\n                                                     [(nnz,), (n, m)], s, (n, m))\n       self.assertLess(err, 1e-3)\n \n-  @test_util.run_deprecated_v1\n   def testInvalidSparseTensor(self):\n     with test_util.force_cpu():\n       shape = [2, 2]\n@@ -201,12 +200,49 @@ def testInvalidSparseTensor(self):\n           [[1, 3]],  # ...so is 3.\n       ]:\n         sparse = sparse_tensor.SparseTensorValue(bad_idx, val, shape)\n-        s = sparse_ops.sparse_add(sparse, dense)\n-\n-        with self.assertRaisesRegex(errors_impl.InvalidArgumentError,\n-                                    \"invalid index\"):\n+        with self.assertRaisesRegex(\n+            (ValueError, errors_impl.InvalidArgumentError), \"invalid index\"):\n+          s = sparse_ops.sparse_add(sparse, dense)\n           self.evaluate(s)\n \n+  def _testSparseDenseInvalidInputs(self,\n+                                    a_indices,\n+                                    a_values,\n+                                    a_shape,\n+                                    b,\n+                                    expected_error=\"\"):\n+    # Public API call to sparse-dense add.\n+    with self.assertRaisesRegex((ValueError, errors_impl.InvalidArgumentError),\n+                                expected_error):\n+      a = sparse_tensor.SparseTensor(a_indices, a_values, a_shape)\n+      self.evaluate(sparse_ops.sparse_add(a, b))\n+    # Directly call generated kernel, by-passing SparseTensor validation.\n+    with self.assertRaisesRegex((ValueError, errors_impl.InvalidArgumentError),\n+                                expected_error):\n+      self.evaluate(\n+          sparse_ops.gen_sparse_ops.sparse_tensor_dense_add(\n+              a_indices, a_values, a_shape, b))\n+\n+  def testSparseDenseInvalidInputs(self):\n+    self._testSparseDenseInvalidInputs(\n+        a_indices=constant_op.constant(0, shape=[17, 2], dtype=dtypes.int64),\n+        a_values=constant_op.constant(0, shape=[5], dtype=dtypes.float32),\n+        a_shape=constant_op.constant([3, 4], dtype=dtypes.int64),\n+        b=constant_op.constant(1, shape=[3, 4], dtype=dtypes.float32),\n+        expected_error=\"Dimensions 17 and 5 are not compatible\")\n+    self._testSparseDenseInvalidInputs(\n+        a_indices=constant_op.constant(0, shape=[17, 4], dtype=dtypes.int64),\n+        a_values=constant_op.constant(0, shape=[17], dtype=dtypes.float32),\n+        a_shape=constant_op.constant([3, 4], dtype=dtypes.int64),\n+        b=constant_op.constant(1, shape=[3, 4], dtype=dtypes.float32),\n+        expected_error=\"Dimensions 4 and 2 are not compatible\")\n+    self._testSparseDenseInvalidInputs(\n+        a_indices=constant_op.constant(7, shape=[17, 2], dtype=dtypes.int64),\n+        a_values=constant_op.constant(0, shape=[17], dtype=dtypes.float32),\n+        a_shape=constant_op.constant([3, 4], dtype=dtypes.int64),\n+        b=constant_op.constant(1, shape=[3, 4], dtype=dtypes.float32),\n+        expected_error=\"invalid index\")\n+\n ######################## Benchmarking code\n \n \ndiff --git a/tensorflow/python/kernel_tests/sparse_ops/sparse_ops_test.py b/tensorflow/python/kernel_tests/sparse_ops/sparse_ops_test.py\nindex 4972d1d25f08f1..684d1f98432b53 100644\n--- a/tensorflow/python/kernel_tests/sparse_ops/sparse_ops_test.py\n+++ b/tensorflow/python/kernel_tests/sparse_ops/sparse_ops_test.py\n@@ -665,7 +665,7 @@ def testInvalidIndices(self):\n class SparseAddTest(test_util.TensorFlowTestCase):\n \n   def testValuesInVariable(self):\n-    indices = constant_op.constant([[1]], dtype=dtypes.int64)\n+    indices = constant_op.constant([[0]], dtype=dtypes.int64)\n     values = variables.Variable([1], trainable=False, dtype=dtypes.float32)\n     shape = constant_op.constant([1], dtype=dtypes.int64)\n \n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "8b39afdad9a0761e0a5d4af1a762bd9a6daef572",
        "repo": "nginx/njs",
        "msg": "Fixed Array.prototype.sort() when arr size is changed in a comparator.\n\nThis fixed #468 issue on Github.Nginx NJS v0.7.2 was discovered to contain a segmentation violation in the function njs_array_prototype_sort at src/njs_array.c.",
        "filename": "njs_array.c",
        "diff": "diff --git a/src/njs_array.c b/src/njs_array.c\nindex 81a7c1555..0b8c7b919 100644\n--- a/src/njs_array.c\n+++ b/src/njs_array.c\n@@ -2696,7 +2696,7 @@ njs_array_prototype_sort(njs_vm_t *vm, njs_value_t *args, njs_uint_t nargs,\n         goto exception;\n     }\n \n-    if (njs_fast_path(fast_path)) {\n+    if (njs_fast_path(fast_path && njs_is_fast_array(this))) {\n         array = njs_array(this);\n         start = array->start;\n \ndiff --git a/src/test/njs_unit_test.c b/src/test/njs_unit_test.c\nindex 186defa1a..25e066c32 100644\n--- a/src/test/njs_unit_test.c\n+++ b/src/test/njs_unit_test.c\n@@ -6989,6 +6989,9 @@ static njs_unit_test_t  njs_test[] =\n     { njs_str(\"[1,2].sort(1)\"),\n       njs_str(\"TypeError: comparefn must be callable or undefined\") },\n \n+    { njs_str(\"var a = [1,2]; a.sort(() => {a.length = 65535}); a.length\"),\n+      njs_str(\"65535\") },\n+\n     /*\n       Array.prototype.keys()\n       Array.prototype.values()\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "a4e138660270e7599793fa438cd7b2fc2ce215a6",
        "repo": "tensorflow/tensorflow",
        "msg": "Add remaining validation to `sdca_internal.cc`\n\nPiperOrigin-RevId: 387738010\nChange-Id: I28eedcfd87a53aaf34deb075acea1f8c95470808TensorFlow is an end-to-end open source platform for machine learning. In affected versions an attacker can read from outside of bounds of heap allocated data by sending specially crafted illegal arguments to `tf.raw_ops.SdcaOptimizerV2`. The [implementation](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/core/kernels/sdca_internal.cc#L320-L353) does not check that the length of `example_labels` is the same as the number of examples. We have patched the issue in GitHub commit a4e138660270e7599793fa438cd7b2fc2ce215a6. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "filename": "sdca_internal.cc",
        "diff": "diff --git a/tensorflow/core/kernels/sdca_internal.cc b/tensorflow/core/kernels/sdca_internal.cc\nindex 6c4a63b270c25b..164f9382724cac 100644\n--- a/tensorflow/core/kernels/sdca_internal.cc\n+++ b/tensorflow/core/kernels/sdca_internal.cc\n@@ -380,6 +380,11 @@ Status Examples::Initialize(OpKernelContext* const context,\n   const Tensor* example_labels_t;\n   TF_RETURN_IF_ERROR(context->input(\"example_labels\", &example_labels_t));\n   auto example_labels = example_labels_t->flat<float>();\n+  if (example_labels.size() != num_examples) {\n+    return errors::InvalidArgument(\"Expected \", num_examples,\n+                                   \" example labels but got \",\n+                                   example_labels.size());\n+  }\n \n   OpInputList dense_features_inputs;\n   TF_RETURN_IF_ERROR(\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "f5a038e6893019ee471b6a57490cf7a495673816",
        "repo": "gpac/gpac",
        "msg": "fixed #1885Segmentation fault vulnerability exists in Gpac through 1.0.1 via the gf_odf_size_descriptor function in desc_private.c when using mp4box, which causes a denial of service.",
        "filename": "isom_hinter.c",
        "diff": "diff --git a/src/media_tools/isom_hinter.c b/src/media_tools/isom_hinter.c\nindex eacef641fe..6d823b1484 100644\n--- a/src/media_tools/isom_hinter.c\n+++ b/src/media_tools/isom_hinter.c\n@@ -1241,7 +1241,7 @@ GF_Err gf_hinter_finalize(GF_ISOFile *file, GF_SDP_IODProfile IOD_Profile, u32 b\n \t\tif (gf_isom_get_sample_count(file, sceneT)==1) {\n \t\t\tsamp = gf_isom_get_sample(file, sceneT, 1, &descIndex);\n \t\t\tif (samp && gf_hinter_can_embbed_data(samp->data, samp->dataLength, GF_STREAM_SCENE)) {\n-\n+\t\t\t\tInitSL_NULL(&slc);\n \t\t\t\tslc.timeScale = slc.timestampResolution = gf_isom_get_media_timescale(file, sceneT);\n \t\t\t\tslc.OCRResolution = 1000;\n \t\t\t\tslc.startCTS = samp->DTS+samp->CTS_Offset;\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "aaa28a508903041dd7399d4159a8ace9766b022f",
        "repo": "mruby/mruby",
        "msg": "vm.c: stack may be reallocated in functions calls.\n\nProbably due to recursive VM calls via `mrb_funcall()`.User after free in mrb_vm_exec in GitHub repository mruby/mruby prior to 3.2.",
        "filename": "vm.c",
        "diff": "diff --git a/src/vm.c b/src/vm.c\nindex 8b81031a37..fd17e90cc4 100644\n--- a/src/vm.c\n+++ b/src/vm.c\n@@ -1394,14 +1394,16 @@ mrb_vm_exec(mrb_state *mrb, const struct RProc *proc, const mrb_code *pc)\n         regs[a] = mrb_ary_entry(va, mrb_integer(vb));\n         break;\n       case MRB_TT_HASH:\n-        regs[a] = mrb_hash_get(mrb, va, vb);\n+        va = mrb_hash_get(mrb, va, vb);\n+        regs[a] = va;\n         break;\n       case MRB_TT_STRING:\n         switch (mrb_type(vb)) {\n         case MRB_TT_INTEGER:\n         case MRB_TT_STRING:\n         case MRB_TT_RANGE:\n-          regs[a] = mrb_str_aref(mrb, va, vb, mrb_undef_value());\n+          va = mrb_str_aref(mrb, va, vb, mrb_undef_value());\n+          regs[a] = va;\n           break;\n         default:\n           goto getidx_fallback;\n@@ -1423,7 +1425,8 @@ mrb_vm_exec(mrb_state *mrb, const struct RProc *proc, const mrb_code *pc)\n     }\n \n     CASE(OP_GETCONST, BB) {\n-      regs[a] = mrb_vm_const_get(mrb, syms[b]);\n+      mrb_value v = mrb_vm_const_get(mrb, syms[b]);\n+      regs[a] = v;\n       NEXT;\n     }\n \n@@ -1433,7 +1436,8 @@ mrb_vm_exec(mrb_state *mrb, const struct RProc *proc, const mrb_code *pc)\n     }\n \n     CASE(OP_GETMCNST, BB) {\n-      regs[a] = mrb_const_get(mrb, regs[a], syms[b]);\n+      mrb_value v = mrb_const_get(mrb, regs[a], syms[b]);\n+      regs[a] = v;\n       NEXT;\n     }\n \n@@ -2014,14 +2018,15 @@ mrb_vm_exec(mrb_state *mrb, const struct RProc *proc, const mrb_code *pc)\n     CASE(OP_KARG, BB) {\n       mrb_value k = mrb_symbol_value(syms[b]);\n       mrb_int kidx = mrb_ci_kidx(mrb->c->ci);\n-      mrb_value kdict;\n+      mrb_value kdict, v;\n \n       if (kidx < 0 || !mrb_hash_p(kdict=regs[kidx]) || !mrb_hash_key_p(mrb, kdict, k)) {\n         mrb_value str = mrb_format(mrb, \"missing keyword: %v\", k);\n         mrb_exc_set(mrb, mrb_exc_new_str(mrb, E_ARGUMENT_ERROR, str));\n         goto L_RAISE;\n       }\n-      regs[a] = mrb_hash_get(mrb, kdict, k);\n+      v = mrb_hash_get(mrb, kdict, k);\n+      regs[a] = v;\n       mrb_hash_delete_key(mrb, kdict, k);\n       NEXT;\n     }\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "81af26364c21c196dd21fb5e14c7fa9ce7debd17",
        "repo": "nginx/njs",
        "msg": "Fixed Object.defineProperty() when a recursive descriptor is provided.\n\nThis closes #481 issue on Github.Nginx NJS v0.7.2 was discovered to contain a segmentation violation in the function njs_array_convert_to_slow_array at src/njs_array.c.",
        "filename": "njs_array.c",
        "diff": "diff --git a/src/njs_array.c b/src/njs_array.c\nindex ec3a5da93..2367420dc 100644\n--- a/src/njs_array.c\n+++ b/src/njs_array.c\n@@ -142,6 +142,10 @@ njs_array_convert_to_slow_array(njs_vm_t *vm, njs_array_t *array)\n     njs_value_t        index, value;\n     njs_object_prop_t  *prop;\n \n+    if (njs_slow_path(!array->object.fast_array)) {\n+        return NJS_OK;\n+    }\n+\n     njs_set_array(&value, array);\n     array->object.fast_array = 0;\n \ndiff --git a/src/test/njs_unit_test.c b/src/test/njs_unit_test.c\nindex 87d8d46c0..77ec044e1 100644\n--- a/src/test/njs_unit_test.c\n+++ b/src/test/njs_unit_test.c\n@@ -13837,6 +13837,16 @@ static njs_unit_test_t  njs_test[] =\n               \"d.enumerable && d.writable && d.configurable\"),\n       njs_str(\"true\") },\n \n+    { njs_str(\"const arr = [1,2];\"\n+              \"function f(arg) {\"\n+              \"        const desc = {get: arg};\"\n+              \"        Object.defineProperty(desc, 'set', desc);\"\n+              \"        Object.defineProperty(arr, 1, desc);\"\n+              \"}\"\n+              \"f(f);\"\n+              \"njs.dump(arr)\"),\n+      njs_str(\"[1,'[Getter]']\") },\n+\n     { njs_str(\"Object.defineProperties()\"),\n       njs_str(\"TypeError: Object.defineProperties is called on non-object\") },\n \n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "9a133d73ae4b4664d22bd1aa6d654fec13c52ee1",
        "repo": "tensorflow/tensorflow",
        "msg": "Prevent segfault in `GetSessionHandle{,V2}`.\n\nIn eager mode, session state is null.\n\nPiperOrigin-RevId: 332548597\nChange-Id: If094812c2e094044220b9ba28f7d7601be042f38In eager mode, TensorFlow before versions 1.15.4, 2.0.3, 2.1.2, 2.2.1 and 2.3.1 does not set the session state. Hence, calling `tf.raw_ops.GetSessionHandle` or `tf.raw_ops.GetSessionHandleV2` results in a null pointer dereference In linked snippet, in eager mode, `ctx->session_state()` returns `nullptr`. Since code immediately dereferences this, we get a segmentation fault. The issue is patched in commit 9a133d73ae4b4664d22bd1aa6d654fec13c52ee1, and is released in TensorFlow versions 1.15.4, 2.0.3, 2.1.2, 2.2.1, or 2.3.1.",
        "filename": "session_ops.cc",
        "diff": "diff --git a/tensorflow/core/kernels/session_ops.cc b/tensorflow/core/kernels/session_ops.cc\nindex 9e67fec3c20a53..ee81ad27632622 100644\n--- a/tensorflow/core/kernels/session_ops.cc\n+++ b/tensorflow/core/kernels/session_ops.cc\n@@ -16,6 +16,7 @@ limitations under the License.\n // See docs in ../ops/data_flow_ops.cc.\n \n #include <limits.h>\n+\n #include <vector>\n \n #include \"tensorflow/core/common_runtime/device.h\"\n@@ -27,6 +28,7 @@ limitations under the License.\n #include \"tensorflow/core/framework/types.h\"\n #include \"tensorflow/core/lib/core/errors.h\"\n #include \"tensorflow/core/lib/gtl/map_util.h\"\n+#include \"tensorflow/core/platform/errors.h\"\n #include \"tensorflow/core/platform/logging.h\"\n #include \"tensorflow/core/platform/macros.h\"\n #include \"tensorflow/core/platform/mutex.h\"\n@@ -42,7 +44,11 @@ class GetSessionHandleOp : public OpKernel {\n \n   void Compute(OpKernelContext* ctx) override {\n     const Tensor& val = ctx->input(0);\n-    int64 id = ctx->session_state()->GetNewId();\n+    auto session_state = ctx->session_state();\n+    OP_REQUIRES(ctx, session_state != nullptr,\n+                errors::FailedPrecondition(\n+                    \"GetSessionHandle called on null session state\"));\n+    int64 id = session_state->GetNewId();\n     TensorStore::TensorAndKey tk{val, id, requested_device()};\n     OP_REQUIRES_OK(ctx, ctx->tensor_store()->AddTensor(name(), tk));\n \ndiff --git a/tensorflow/python/ops/raw_ops_test.py b/tensorflow/python/ops/raw_ops_test.py\nindex ee20d58d2f0fdd..6706ef194b221a 100644\n--- a/tensorflow/python/ops/raw_ops_test.py\n+++ b/tensorflow/python/ops/raw_ops_test.py\n@@ -25,6 +25,7 @@\n from tensorflow.python.framework import errors\n from tensorflow.python.framework import ops\n from tensorflow.python.framework import test_util\n+from tensorflow.python.ops import gen_data_flow_ops\n from tensorflow.python.ops import gen_math_ops\n from tensorflow.python.ops import gen_string_ops\n from tensorflow.python.platform import test\n@@ -79,6 +80,13 @@ def testStringNGramsBadDataSplits(self, splits):\n               pad_width=0,\n               preserve_short_sequences=False))\n \n+  def testGetSessionHandle(self):\n+    if context.executing_eagerly():\n+      with self.assertRaisesRegex(\n+          errors.FailedPreconditionError,\n+          \"GetSessionHandle called on null session state\"):\n+        gen_data_flow_ops.GetSessionHandle(value=[1])\n+\n \n if __name__ == \"__main__\":\n   ops.enable_eager_execution()\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "701cfaca222a82afbeeb17496bd718baa65a67d2",
        "repo": "tensorflow/tensorflow",
        "msg": "Fix heap out of bounds error in tf.raw_ops.SparseCountSparseOutput shape inference when it is called with invalid inputs, and add a test for it.\n\nPiperOrigin-RevId: 405766415\nChange-Id: I77d244ef35f351ef7b6f821efd959cac2c66db24TensorFlow is an open source platform for machine learning. In affected versions the shape inference functions for `SparseCountSparseOutput` can trigger a read outside of bounds of heap allocated array. The fix will be included in TensorFlow 2.7.0. We will also cherrypick this commit on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.",
        "filename": "count_ops.cc",
        "diff": "diff --git a/tensorflow/core/ops/count_ops.cc b/tensorflow/core/ops/count_ops.cc\nindex 4f9631310df924..aa6c0437337af2 100644\n--- a/tensorflow/core/ops/count_ops.cc\n+++ b/tensorflow/core/ops/count_ops.cc\n@@ -41,6 +41,8 @@ Status DenseCountSparseOutputShapeFn(InferenceContext *c) {\n }\n \n Status SparseCountSparseOutputShapeFn(InferenceContext *c) {\n+  ShapeHandle unused;\n+  TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 2, &unused));\n   auto rank = c->Dim(c->input(0), 1);\n   auto nvals = c->UnknownDim();\n   c->set_output(0, c->Matrix(nvals, rank));  // out.indices\ndiff --git a/tensorflow/python/ops/bincount_ops_test.py b/tensorflow/python/ops/bincount_ops_test.py\nindex 3c7a2a5da9daf6..de7d1423870d76 100644\n--- a/tensorflow/python/ops/bincount_ops_test.py\n+++ b/tensorflow/python/ops/bincount_ops_test.py\n@@ -831,6 +831,25 @@ def test_ragged_input_different_shape_fails(self):\n       self.evaluate(bincount_ops.sparse_bincount(x, weights=weights, axis=-1))\n \n \n+class RawOpsHeapOobTest(test.TestCase, parameterized.TestCase):\n+\n+  @test_util.run_v1_only(\"Test security error\")\n+  def testSparseCountSparseOutputBadIndicesShapeTooSmall(self):\n+    indices = [1]\n+    values = [[1]]\n+    weights = []\n+    dense_shape = [10]\n+    with self.assertRaisesRegex(ValueError,\n+                                \"Shape must be rank 2 but is rank 1 for\"):\n+      self.evaluate(\n+          gen_count_ops.SparseCountSparseOutput(\n+              indices=indices,\n+              values=values,\n+              dense_shape=dense_shape,\n+              weights=weights,\n+              binary_output=True))\n+\n+\n @test_util.run_all_in_graph_and_eager_modes\n @test_util.disable_tfrt\n class RawOpsTest(test.TestCase, parameterized.TestCase):\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "0eb02422d5161767e9983bdaa5c429762d3477ce",
        "repo": "tildearrow/furnace",
        "msg": "fix possible pattern crash\n\nissue #325A denial of service vulnerability was found in tildearrow Furnace. It has been classified as problematic. This is due to an incomplete fix of CVE-2022-1211. It is possible to initiate the attack remotely but it requires user interaction. The issue got fixed with the patch 0eb02422d5161767e9983bdaa5c429762d3477ce.",
        "filename": "pattern.cpp",
        "diff": "diff --git a/src/gui/pattern.cpp b/src/gui/pattern.cpp\nindex d6b6fce70d..d56196d6c8 100644\n--- a/src/gui/pattern.cpp\n+++ b/src/gui/pattern.cpp\n@@ -282,27 +282,33 @@ inline void FurnaceGUI::patternRow(int i, bool isPlaying, float lineHeight, int\n           sprintf(id,\"..##PE%d_%d_%d\",k,i,j);\n           ImGui::PushStyleColor(ImGuiCol_Text,inactiveColor);\n         } else {\n-          sprintf(id,\"%.2X##PE%d_%d_%d\",pat->data[i][index],k,i,j);\n-          if (pat->data[i][index]<0x10) {\n-            ImGui::PushStyleColor(ImGuiCol_Text,uiColors[fxColors[pat->data[i][index]]]);\n-          } else if (pat->data[i][index]<0x20) {\n-            ImGui::PushStyleColor(ImGuiCol_Text,uiColors[GUI_COLOR_PATTERN_EFFECT_SYS_PRIMARY]);\n-          } else if (pat->data[i][index]<0x30) {\n-            ImGui::PushStyleColor(ImGuiCol_Text,uiColors[GUI_COLOR_PATTERN_EFFECT_SYS_SECONDARY]);\n-          } else if (pat->data[i][index]<0x48) {\n-            ImGui::PushStyleColor(ImGuiCol_Text,uiColors[GUI_COLOR_PATTERN_EFFECT_SYS_PRIMARY]);\n-          } else if (pat->data[i][index]<0x90) {\n-            ImGui::PushStyleColor(ImGuiCol_Text,uiColors[GUI_COLOR_PATTERN_EFFECT_INVALID]);\n-          } else if (pat->data[i][index]<0xa0) {\n-            ImGui::PushStyleColor(ImGuiCol_Text,uiColors[GUI_COLOR_PATTERN_EFFECT_MISC]);\n-          } else if (pat->data[i][index]<0xc0) {\n-            ImGui::PushStyleColor(ImGuiCol_Text,uiColors[GUI_COLOR_PATTERN_EFFECT_INVALID]);\n-          } else if (pat->data[i][index]<0xd0) {\n-            ImGui::PushStyleColor(ImGuiCol_Text,uiColors[GUI_COLOR_PATTERN_EFFECT_SPEED]);\n-          } else if (pat->data[i][index]<0xe0) {\n+          if (pat->data[i][index]>0xff) {\n+            sprintf(id,\"??##PE%d_%d_%d\",k,i,j);\n             ImGui::PushStyleColor(ImGuiCol_Text,uiColors[GUI_COLOR_PATTERN_EFFECT_INVALID]);\n           } else {\n-            ImGui::PushStyleColor(ImGuiCol_Text,uiColors[extFxColors[pat->data[i][index]-0xe0]]);\n+            const unsigned char data=pat->data[i][index];\n+            sprintf(id,\"%.2X##PE%d_%d_%d\",data,k,i,j);\n+            if (data<0x10) {\n+              ImGui::PushStyleColor(ImGuiCol_Text,uiColors[fxColors[data]]);\n+            } else if (data<0x20) {\n+              ImGui::PushStyleColor(ImGuiCol_Text,uiColors[GUI_COLOR_PATTERN_EFFECT_SYS_PRIMARY]);\n+            } else if (data<0x30) {\n+              ImGui::PushStyleColor(ImGuiCol_Text,uiColors[GUI_COLOR_PATTERN_EFFECT_SYS_SECONDARY]);\n+            } else if (data<0x48) {\n+              ImGui::PushStyleColor(ImGuiCol_Text,uiColors[GUI_COLOR_PATTERN_EFFECT_SYS_PRIMARY]);\n+            } else if (data<0x90) {\n+              ImGui::PushStyleColor(ImGuiCol_Text,uiColors[GUI_COLOR_PATTERN_EFFECT_INVALID]);\n+            } else if (data<0xa0) {\n+              ImGui::PushStyleColor(ImGuiCol_Text,uiColors[GUI_COLOR_PATTERN_EFFECT_MISC]);\n+            } else if (data<0xc0) {\n+              ImGui::PushStyleColor(ImGuiCol_Text,uiColors[GUI_COLOR_PATTERN_EFFECT_INVALID]);\n+            } else if (data<0xd0) {\n+              ImGui::PushStyleColor(ImGuiCol_Text,uiColors[GUI_COLOR_PATTERN_EFFECT_SPEED]);\n+            } else if (data<0xe0) {\n+              ImGui::PushStyleColor(ImGuiCol_Text,uiColors[GUI_COLOR_PATTERN_EFFECT_INVALID]);\n+            } else {\n+              ImGui::PushStyleColor(ImGuiCol_Text,uiColors[extFxColors[data-0xe0]]);\n+            }\n           }\n         }\n         ImGui::SameLine(0.0f,0.0f);\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "1e206baedf8bef0334cca3eb92bab134ef525a28",
        "repo": "tensorflow/tensorflow",
        "msg": "Prevent a division by 0 in division ops.\n\nPiperOrigin-RevId: 385223169\nChange-Id: Ia4228960b5d2aa44480385f74bdd70d21a3613c3TensorFlow is an end-to-end open source platform for machine learning. In affected versions the implementation of division in TFLite is [vulnerable to a division by 0 error](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/lite/kernels/div.cc). There is no check that the divisor tensor does not contain zero elements. We have patched the issue in GitHub commit 1e206baedf8bef0334cca3eb92bab134ef525a28. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "filename": "div.cc",
        "diff": "diff --git a/tensorflow/lite/kernels/div.cc b/tensorflow/lite/kernels/div.cc\nindex f744b4ba1b7f63..51623a969d1b11 100644\n--- a/tensorflow/lite/kernels/div.cc\n+++ b/tensorflow/lite/kernels/div.cc\n@@ -216,9 +216,23 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_OK(context,\n                     GetOutputSafe(context, node, kOutputTensor, &output));\n \n-  if (output->type == kTfLiteFloat32 || output->type == kTfLiteInt32) {\n+  // TODO(b/193904910): This can written with C++ templates\n+#define TF_LITE_CHECK_DIV_NON_ZERO(data_type)                       \\\n+  const auto* input2_data = GetTensorData<data_type>(input2);       \\\n+  const size_t input2_elements = input2->bytes / sizeof(data_type); \\\n+  for (size_t i = 0; i < input2_elements; i++) {                    \\\n+    TF_LITE_ENSURE(context, input2_data[i] != 0);                   \\\n+  }\n+\n+  if (output->type == kTfLiteFloat32) {\n+    // Div by zero seems ok in this case, just like in TF case infinities are\n+    // returned. So we don't do a check at this point.\n+    EvalDiv<kernel_type>(context, node, params, data, input1, input2, output);\n+  } else if (output->type == kTfLiteInt32) {\n+    TF_LITE_CHECK_DIV_NON_ZERO(int32_t);\n     EvalDiv<kernel_type>(context, node, params, data, input1, input2, output);\n   } else if (output->type == kTfLiteUInt8) {\n+    TF_LITE_CHECK_DIV_NON_ZERO(uint8_t);\n     TF_LITE_ENSURE_OK(\n         context, EvalQuantized<kernel_type>(context, node, params, data, input1,\n                                             input2, output));\n@@ -229,6 +243,7 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n         output->type);\n     return kTfLiteError;\n   }\n+#undef TF_LITE_CHECK_DIV_NON_ZERO\n \n   return kTfLiteOk;\n }\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "a51f951b878c2b73c1d8e2f1518c7cdc5fb82c3f",
        "repo": "gpac/gpac",
        "msg": "fixed #1782 (fuzz)Memory leak in the afra_box_read function in MP4Box in GPAC 1.0.1 allows attackers to read memory via a crafted file.",
        "filename": "box_code_adobe.c",
        "diff": "diff --git a/applications/mp4box/main.c b/applications/mp4box/main.c\nindex e0215f77ed..db6c067796 100644\n--- a/applications/mp4box/main.c\n+++ b/applications/mp4box/main.c\n@@ -5439,6 +5439,14 @@ static u32 mp4box_cleanup(u32 ret_code) {\n \t}\n \tif (logfile) gf_fclose(logfile);\n \tgf_sys_close();\n+\n+#ifdef GPAC_MEMORY_TRACKING\n+\tif (mem_track && (gf_memory_size() || gf_file_handles_count() )) {\n+\t\tgf_log_set_tool_level(GF_LOG_MEMORY, GF_LOG_INFO);\n+\t\tgf_memory_print();\n+\t}\n+#endif\n+\n \treturn ret_code;\n }\n \ndiff --git a/src/isomedia/box_code_adobe.c b/src/isomedia/box_code_adobe.c\nindex fe46191915..bb80f3ce89 100644\n--- a/src/isomedia/box_code_adobe.c\n+++ b/src/isomedia/box_code_adobe.c\n@@ -408,6 +408,7 @@ GF_Err afra_box_read(GF_Box *s, GF_BitStream *bs)\n \tfor (i=0; i<ptr->entry_count; i++) {\n \t\tGF_AfraEntry *ae = gf_malloc(sizeof(GF_AfraEntry));\n \t\tif (!ae) return GF_OUT_OF_MEM;\n+\t\tgf_list_insert(ptr->local_access_entries, ae, i);\n \n \t\tISOM_DECREASE_SIZE(ptr, 8)\n \t\tae->time = gf_bs_read_u64(bs);\n@@ -418,8 +419,6 @@ GF_Err afra_box_read(GF_Box *s, GF_BitStream *bs)\n \t\t\tISOM_DECREASE_SIZE(ptr, 4)\n \t\t\tae->offset = gf_bs_read_u32(bs);\n \t\t}\n-\n-\t\tgf_list_insert(ptr->local_access_entries, ae, i);\n \t}\n \n \tif (ptr->global_entries) {\n@@ -428,6 +427,8 @@ GF_Err afra_box_read(GF_Box *s, GF_BitStream *bs)\n \t\tfor (i=0; i<ptr->global_entry_count; i++) {\n \t\t\tGF_GlobalAfraEntry *ae = gf_malloc(sizeof(GF_GlobalAfraEntry));\n \t\t\tif (!ae) return GF_OUT_OF_MEM;\n+\t\t\tgf_list_insert(ptr->global_access_entries, ae, i);\n+\n \t\t\tISOM_DECREASE_SIZE(ptr, 8)\n \t\t\tae->time = gf_bs_read_u64(bs);\n \t\t\tif (ptr->long_ids) {\n@@ -448,8 +449,6 @@ GF_Err afra_box_read(GF_Box *s, GF_BitStream *bs)\n \t\t\t\tae->afra_offset = gf_bs_read_u32(bs);\n \t\t\t\tae->offset_from_afra = gf_bs_read_u32(bs);\n \t\t\t}\n-\n-\t\t\tgf_list_insert(ptr->global_access_entries, ae, i);\n \t\t}\n \t}\n \n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "9e62869465573cb2d9b5053f1fa02a81fce21d69",
        "repo": "tensorflow/tensorflow",
        "msg": "Add more validation to `RequantizationRangePerChannel`.\n\nPiperOrigin-RevId: 387693946\nChange-Id: Ife8dcbdb021bec4787eef6a4361dd08f17c14bd6TensorFlow is an end-to-end open source platform for machine learning. In affected versions due to incomplete validation in MKL implementation of requantization, an attacker can trigger undefined behavior via binding a reference to a null pointer or can access data outside the bounds of heap allocated arrays. The [implementation](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/core/kernels/mkl/mkl_requantization_range_per_channel_op.cc) does not validate the dimensions of the `input` tensor. A similar issue occurs in `MklRequantizePerChannelOp`. The [implementation](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/core/kernels/mkl/mkl_requantize_per_channel_op.cc) does not perform full validation for all the input arguments. We have patched the issue in GitHub commit 9e62869465573cb2d9b5053f1fa02a81fce21d69 and in the Github commit 203214568f5bc237603dbab6e1fd389f1572f5c9. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "filename": "mkl_requantization_range_per_channel_op.cc",
        "diff": "diff --git a/tensorflow/core/kernels/mkl/mkl_requantization_range_per_channel_op.cc b/tensorflow/core/kernels/mkl/mkl_requantization_range_per_channel_op.cc\nindex 24dabb07ca067a..a38df2450d1942 100644\n--- a/tensorflow/core/kernels/mkl/mkl_requantization_range_per_channel_op.cc\n+++ b/tensorflow/core/kernels/mkl/mkl_requantization_range_per_channel_op.cc\n@@ -57,6 +57,20 @@ class MklRequantizationRangePerChannelOp : public OpKernel {\n         ctx, input_max.dim_size(0) == depth,\n         errors::InvalidArgument(\"input_max has incorrect size, expected \",\n                                 depth, \" was \", input_max.dim_size(0)));\n+    OP_REQUIRES(\n+        ctx, input_min.NumElements() == depth,\n+        errors::InvalidArgument(\"input_min must have the same number of \"\n+                                \"elements as input_max, got \",\n+                                input_min.NumElements(), \" and \", depth));\n+    OP_REQUIRES(ctx, input.NumElements() > 0,\n+                errors::InvalidArgument(\"input must not be empty\"));\n+    OP_REQUIRES(ctx, input.dims() == 4,\n+                errors::InvalidArgument(\"input must be in NHWC format\"));\n+    OP_REQUIRES(\n+        ctx, input.dim_size(3) == depth,\n+        errors::InvalidArgument(\n+            \"input must have same number of channels as length of input_min: \",\n+            input.dim_size(3), \" vs \", depth));\n \n     const float* input_min_data = input_min.flat<float>().data();\n     const float* input_max_data = input_max.flat<float>().data();\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "a4d97934d51cb88954cc49161dc1d151f64afb6b",
        "repo": "mruby/mruby",
        "msg": "vm.c: check if target_class is NULL (when prepended).Out-of-bounds Read in mrb_obj_is_kind_of in in GitHub repository mruby/mruby prior to 3.2. # Impact: Possible arbitrary code execution if being exploited.",
        "filename": "vm.c",
        "diff": "diff --git a/src/vm.c b/src/vm.c\nindex 5013c877d4..aa043b06ae 100644\n--- a/src/vm.c\n+++ b/src/vm.c\n@@ -1750,10 +1750,7 @@ mrb_vm_exec(mrb_state *mrb, const struct RProc *proc, const mrb_code *pc)\n         mrb_exc_set(mrb, exc);\n         goto L_RAISE;\n       }\n-      if (target_class->flags & MRB_FL_CLASS_IS_PREPENDED) {\n-        target_class = mrb_vm_ci_target_class(ci);\n-      }\n-      else if (target_class->tt == MRB_TT_MODULE) {\n+      if ((target_class->flags & MRB_FL_CLASS_IS_PREPENDED) || target_class->tt == MRB_TT_MODULE) {\n         target_class = mrb_vm_ci_target_class(ci);\n         if (!target_class || target_class->tt != MRB_TT_ICLASS) {\n           goto super_typeerror;\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "47338393f1f79558f6144213409f09f81d7c4837",
        "repo": "FreeRTOS/FreeRTOS-Kernel",
        "msg": "add assert for addition overflow on queue creation (#225)The kernel in Amazon Web Services FreeRTOS before 10.4.3 has an integer overflow in queue.c for queue creation.",
        "filename": "queue.c",
        "diff": "diff --git a/queue.c b/queue.c\nindex d2e27e55a5..b01dfd11ff 100644\n--- a/queue.c\n+++ b/queue.c\n@@ -397,6 +397,9 @@ BaseType_t xQueueGenericReset( QueueHandle_t xQueue,\n         /* Check for multiplication overflow. */\r\n         configASSERT( ( uxItemSize == 0 ) || ( uxQueueLength == ( xQueueSizeInBytes / uxItemSize ) ) );\r\n \r\n+        /* Check for addition overflow. */\r\n+        configASSERT( ( sizeof( Queue_t ) + xQueueSizeInBytes ) >  xQueueSizeInBytes );\r\n+\r\n         /* Allocate the queue and storage area.  Justification for MISRA\r\n          * deviation as follows:  pvPortMalloc() always ensures returned memory\r\n          * blocks are aligned per the requirements of the MCU stack.  In this case\r\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "a67083ff4b8dcbb7ee2839da6338032030d712b0",
        "repo": "facebookincubator/mvfst",
        "msg": "Close connection if we derive an extra 1-rtt write cipher\n\nSummary: Fixes CVE-2021-24029\n\nReviewed By: mjoras, lnicco\n\nDifferential Revision: D26613890\n\nfbshipit-source-id: 19bb2be2c731808144e1a074ece313fba11f1945A packet of death scenario is possible in mvfst via a specially crafted message during a QUIC session, which causes a crash via a failed assertion. Per QUIC specification, this particular message should be treated as a connection error. This issue affects mvfst versions prior to commit a67083ff4b8dcbb7ee2839da6338032030d712b0 and proxygen versions prior to v2021.03.15.00.",
        "filename": "ServerStateMachine.cpp",
        "diff": "diff --git a/quic/server/state/ServerStateMachine.cpp b/quic/server/state/ServerStateMachine.cpp\nindex a5f42f8ef..eaa609e56 100644\n--- a/quic/server/state/ServerStateMachine.cpp\n+++ b/quic/server/state/ServerStateMachine.cpp\n@@ -311,7 +311,10 @@ void updateHandshakeState(QuicServerConnectionState& conn) {\n       conn.qLogger->addTransportStateUpdate(kDerivedOneRttWriteCipher);\n     }\n     QUIC_TRACE(fst_trace, conn, \"derived 1-rtt write cipher\");\n-    CHECK(!conn.oneRttWriteCipher.get());\n+    if (conn.oneRttWriteCipher) {\n+      throw QuicTransportException(\n+          \"Duplicate 1-rtt write cipher\", TransportErrorCode::CRYPTO_ERROR);\n+    }\n     conn.oneRttWriteCipher = std::move(oneRttWriteCipher);\n \n     updatePacingOnKeyEstablished(conn);\ndiff --git a/quic/server/test/QuicServerTransportTest.cpp b/quic/server/test/QuicServerTransportTest.cpp\nindex 07e22bcf9..404a78b80 100644\n--- a/quic/server/test/QuicServerTransportTest.cpp\n+++ b/quic/server/test/QuicServerTransportTest.cpp\n@@ -4265,6 +4265,21 @@ TEST_P(QuicServerTransportHandshakeTest, TestD6DStartCallback) {\n   server->removeObserver(mockObserver.get());\n }\n \n+TEST_F(QuicUnencryptedServerTransportTest, DuplicateOneRttWriteCipher) {\n+  setupClientReadCodec();\n+  recvClientHello();\n+  recvClientFinished();\n+  loopForWrites();\n+  try {\n+    recvClientHello();\n+    recvClientFinished();\n+    FAIL();\n+  } catch (const std::runtime_error& ex) {\n+    EXPECT_THAT(ex.what(), HasSubstr(\"Crypto error\"));\n+  }\n+  EXPECT_TRUE(server->isClosed());\n+}\n+\n TEST_F(QuicServerTransportTest, TestRegisterAndHandleTransportKnobParams) {\n   int flag = 0;\n   server->registerKnobParamHandler(\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "4746b577931e926a49e50de9720a4946de3069a7",
        "repo": "thorfdbg/libjpeg",
        "msg": "Fixed handling of empty JPEG-LS scans.There is an assertion failure in SingleComponentLSScan::ParseMCU in singlecomponentlsscan.cpp in libjpeg before 1.64 via an empty JPEG-LS scan.",
        "filename": "sampleinterleavedlsscan.cpp",
        "diff": "diff --git a/README b/README\nindex 124c958..3cff2da 100644\n--- a/README\n+++ b/README\n@@ -40,7 +40,7 @@ Standard JPEG compression, with 444 (aka \"no\") subsampling:\n \r\n $ jpeg -q <quality> infile.ppm outfile.jpg\r\n \r\n-Standard JPEG compression, with 422 subsampling:\r\n+Standard JPEG compression, with 420 subsampling:\r\n \r\n $ jpeg -q <quality> -s 1x1,2x2,2x2 infile.ppm outfile.jpg\r\n \r\ndiff --git a/codestream/sampleinterleavedlsscan.cpp b/codestream/sampleinterleavedlsscan.cpp\nindex e92c309..e3cfe47 100644\n--- a/codestream/sampleinterleavedlsscan.cpp\n+++ b/codestream/sampleinterleavedlsscan.cpp\n@@ -42,7 +42,7 @@\n ** A JPEG LS scan interleaving samples of several components,\n ** sample by sample.\n **\n-** $Id: sampleinterleavedlsscan.cpp,v 1.15 2014/11/14 15:41:32 thor Exp $\n+** $Id: sampleinterleavedlsscan.cpp,v 1.16 2022/06/08 10:54:55 thor Exp $\n **\n */\n \n@@ -112,9 +112,12 @@ bool SampleInterleavedLSScan::ParseMCU(void)\n   if (lines > 8) {\n     lines = 8;\n   }\n+\n+  if (lines == 0)\n+    return false;\n+  \n   if (m_pFrame->HeightOf() > 0)\n     m_ulRemaining[0] -= lines;\n-  assert(lines > 0);\n   assert(m_ucCount < 4);\n \n   //\ndiff --git a/codestream/singlecomponentlsscan.cpp b/codestream/singlecomponentlsscan.cpp\nindex 76310d6..cabc82c 100644\n--- a/codestream/singlecomponentlsscan.cpp\n+++ b/codestream/singlecomponentlsscan.cpp\n@@ -41,7 +41,7 @@\n /*\n ** A JPEG LS scan covering only a single component.\n **\n-** $Id: singlecomponentlsscan.cpp,v 1.18 2014/11/14 15:41:32 thor Exp $\n+** $Id: singlecomponentlsscan.cpp,v 1.19 2022/06/08 10:54:55 thor Exp $\n **\n */\n \n@@ -96,8 +96,9 @@ bool SingleComponentLSScan::ParseMCU(void)\n   }\n   if (m_pFrame->HeightOf() > 0)\n     m_ulRemaining[0] -= lines;\n-  \n-  assert(lines > 0);\n+\n+  if (lines == 0)\n+    return false;\n \n   // Loop over lines and columns\n   do {\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "4746b577931e926a49e50de9720a4946de3069a7",
        "repo": "thorfdbg/libjpeg",
        "msg": "Fixed handling of empty JPEG-LS scans.There is an assertion failure in SingleComponentLSScan::ParseMCU in singlecomponentlsscan.cpp in libjpeg before 1.64 via an empty JPEG-LS scan.",
        "filename": "singlecomponentlsscan.cpp",
        "diff": "diff --git a/README b/README\nindex 124c958..3cff2da 100644\n--- a/README\n+++ b/README\n@@ -40,7 +40,7 @@ Standard JPEG compression, with 444 (aka \"no\") subsampling:\n \r\n $ jpeg -q <quality> infile.ppm outfile.jpg\r\n \r\n-Standard JPEG compression, with 422 subsampling:\r\n+Standard JPEG compression, with 420 subsampling:\r\n \r\n $ jpeg -q <quality> -s 1x1,2x2,2x2 infile.ppm outfile.jpg\r\n \r\ndiff --git a/codestream/sampleinterleavedlsscan.cpp b/codestream/sampleinterleavedlsscan.cpp\nindex e92c309..e3cfe47 100644\n--- a/codestream/sampleinterleavedlsscan.cpp\n+++ b/codestream/sampleinterleavedlsscan.cpp\n@@ -42,7 +42,7 @@\n ** A JPEG LS scan interleaving samples of several components,\n ** sample by sample.\n **\n-** $Id: sampleinterleavedlsscan.cpp,v 1.15 2014/11/14 15:41:32 thor Exp $\n+** $Id: sampleinterleavedlsscan.cpp,v 1.16 2022/06/08 10:54:55 thor Exp $\n **\n */\n \n@@ -112,9 +112,12 @@ bool SampleInterleavedLSScan::ParseMCU(void)\n   if (lines > 8) {\n     lines = 8;\n   }\n+\n+  if (lines == 0)\n+    return false;\n+  \n   if (m_pFrame->HeightOf() > 0)\n     m_ulRemaining[0] -= lines;\n-  assert(lines > 0);\n   assert(m_ucCount < 4);\n \n   //\ndiff --git a/codestream/singlecomponentlsscan.cpp b/codestream/singlecomponentlsscan.cpp\nindex 76310d6..cabc82c 100644\n--- a/codestream/singlecomponentlsscan.cpp\n+++ b/codestream/singlecomponentlsscan.cpp\n@@ -41,7 +41,7 @@\n /*\n ** A JPEG LS scan covering only a single component.\n **\n-** $Id: singlecomponentlsscan.cpp,v 1.18 2014/11/14 15:41:32 thor Exp $\n+** $Id: singlecomponentlsscan.cpp,v 1.19 2022/06/08 10:54:55 thor Exp $\n **\n */\n \n@@ -96,8 +96,9 @@ bool SingleComponentLSScan::ParseMCU(void)\n   }\n   if (m_pFrame->HeightOf() > 0)\n     m_ulRemaining[0] -= lines;\n-  \n-  assert(lines > 0);\n+\n+  if (lines == 0)\n+    return false;\n \n   // Loop over lines and columns\n   do {\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "37592ad86c6ca934d34740012213e467acc4a3b0",
        "repo": "gpac/gpac",
        "msg": "fixed #2163GPAC 2.1-DEV-rev87-g053aae8-master. has a Null Pointer Dereference vulnerability in gf_isom_parse_movie_boxes_internal due to improper return value handling of GF_SKIP_BOX, which causes a Denial of Service. This vulnerability was fixed in commit 37592ad.",
        "filename": "isom_intern.c",
        "diff": "diff --git a/src/isomedia/box_funcs.c b/src/isomedia/box_funcs.c\nindex 310511db4e..7a79233fab 100644\n--- a/src/isomedia/box_funcs.c\n+++ b/src/isomedia/box_funcs.c\n@@ -310,8 +310,10 @@ GF_Err gf_isom_box_parse_ex(GF_Box **outBox, GF_BitStream *bs, u32 parent_type,\n \tif (e && (e != GF_ISOM_INCOMPLETE_FILE)) {\n \t\tgf_isom_box_del(newBox);\n \t\t*outBox = NULL;\n+\t\tif (is_root_box && (e==GF_SKIP_BOX))\n+\t\t\te = GF_ISOM_INVALID_FILE;\n \n-\t\tif (!skip_logs) {\n+\t\tif (!skip_logs && (e!=GF_SKIP_BOX)) {\n \t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[iso file] Read Box \\\"%s\\\" (start \"LLU\") failed (%s) - skipping\\n\", gf_4cc_to_str(type), start, gf_error_to_string(e)));\n \t\t}\n \t\t//we don't try to reparse known boxes that have been failing (too dangerous)\ndiff --git a/src/isomedia/isom_intern.c b/src/isomedia/isom_intern.c\nindex 09a720649a..242209c3fc 100644\n--- a/src/isomedia/isom_intern.c\n+++ b/src/isomedia/isom_intern.c\n@@ -373,7 +373,8 @@ static GF_Err gf_isom_parse_movie_boxes_internal(GF_ISOFile *mov, u32 *boxType,\n \t\te = gf_isom_parse_root_box(&a, mov->movieFileMap->bs, boxType, bytesMissing, progressive_mode);\n \n \t\tif (e >= 0) {\n-\n+\t\t\t//safety check, should never happen\n+\t\t\tif (!a) return GF_ISOM_INVALID_FILE;\n \t\t} else if (e == GF_ISOM_INCOMPLETE_FILE) {\n \t\t\t/*our mdat is uncomplete, only valid for READ ONLY files...*/\n \t\t\tif (mov->openMode != GF_ISOM_OPEN_READ) {\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "02cc160e29d20631de3859c6653184e3f876b9d7",
        "repo": "tensorflow/tensorflow",
        "msg": "Prevent nullptr deref in SparseTensorSliceDataset\n\nThe arguments must determine a valid sparse tensor. This means that when indices are empty then the values must be empty too (and the reverse).\n\nAlso added test, by modifying existing test with empty sparse tensor to now run with an invalid sparse tensor input.\n\nPiperOrigin-RevId: 388562757\nChange-Id: Id8b54cd7c2316025b4f9a77292c8fb5344d17609TensorFlow is an end-to-end open source platform for machine learning. When a user does not supply arguments that determine a valid sparse tensor, `tf.raw_ops.SparseTensorSliceDataset` implementation can be made to dereference a null pointer. The [implementation](https://github.com/tensorflow/tensorflow/blob/8d72537c6abf5a44103b57b9c2e22c14f5f49698/tensorflow/core/kernels/data/sparse_tensor_slice_dataset_op.cc#L240-L251) has some argument validation but fails to consider the case when either `indices` or `values` are provided for an empty sparse tensor when the other is not. If `indices` is empty, then [code that performs validation](https://github.com/tensorflow/tensorflow/blob/8d72537c6abf5a44103b57b9c2e22c14f5f49698/tensorflow/core/kernels/data/sparse_tensor_slice_dataset_op.cc#L260-L261) (i.e., checking that the indices are monotonically increasing) results in a null pointer dereference. If `indices` as provided by the user is empty, then `indices` in the C++ code above is backed by an empty `std::vector`, hence calling `indices->dim_size(0)` results in null pointer dereferencing (same as calling `std::vector::at()` on an empty vector). We have patched the issue in GitHub commit 02cc160e29d20631de3859c6653184e3f876b9d7. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "filename": "sparse_tensor_slice_dataset_op.cc",
        "diff": "diff --git a/tensorflow/core/kernels/data/sparse_tensor_slice_dataset_op.cc b/tensorflow/core/kernels/data/sparse_tensor_slice_dataset_op.cc\nindex 00b71d41a7ca1e..58bb4b0b6d8065 100644\n--- a/tensorflow/core/kernels/data/sparse_tensor_slice_dataset_op.cc\n+++ b/tensorflow/core/kernels/data/sparse_tensor_slice_dataset_op.cc\n@@ -241,6 +241,17 @@ class SparseTensorSliceDatasetOp : public DatasetOpKernel {\n                 errors::InvalidArgument(\n                     \"Input indices should be a matrix but received shape \",\n                     indices->shape().DebugString()));\n+\n+    const auto num_indices = indices->NumElements();\n+    const auto num_values = values->NumElements();\n+    if (num_indices == 0 || num_values == 0) {\n+      OP_REQUIRES(ctx, num_indices == num_values,\n+                  errors::InvalidArgument(\n+                      \"If indices or values are empty, the other one must also \"\n+                      \"be. Got indices of shape \",\n+                      indices->shape().DebugString(), \" and values of shape \",\n+                      values->shape().DebugString()));\n+    }\n     OP_REQUIRES(ctx, TensorShapeUtils::IsVector(values->shape()),\n                 errors::InvalidArgument(\n                     \"Input values should be a vector but received shape \",\ndiff --git a/tensorflow/python/data/kernel_tests/from_sparse_tensor_slices_test.py b/tensorflow/python/data/kernel_tests/from_sparse_tensor_slices_test.py\nindex 25ecbf20680b3f..8f93530010caec 100644\n--- a/tensorflow/python/data/kernel_tests/from_sparse_tensor_slices_test.py\n+++ b/tensorflow/python/data/kernel_tests/from_sparse_tensor_slices_test.py\n@@ -118,6 +118,26 @@ def testEmptySparseTensorSlices(self):\n       with self.assertRaises(errors.OutOfRangeError):\n         sess.run(get_next)\n \n+  @combinations.generate(combinations.combine(tf_api_version=1, mode=[\"graph\"]))\n+  def testEmptySparseTensorSlicesInvalid(self):\n+    \"\"\"Test a dataset based on invalid `tf.sparse.SparseTensor`.\"\"\"\n+    st = array_ops.sparse_placeholder(dtypes.float64)\n+    iterator = dataset_ops.make_initializable_iterator(\n+        dataset_ops.Dataset.from_sparse_tensor_slices(st))\n+    init_op = iterator.initializer\n+\n+    with self.cached_session() as sess:\n+      # Test with an empty sparse tensor but with non empty values.\n+      empty_indices = np.empty((0, 4), dtype=np.int64)\n+      non_empty_values = [1, 2, 3, 4]\n+      empty_dense_shape = [0, 4, 37, 9]\n+      sparse_feed = sparse_tensor.SparseTensorValue(empty_indices,\n+                                                    non_empty_values,\n+                                                    empty_dense_shape)\n+      # Here, we expect the test to fail when running the feed.\n+      with self.assertRaises(errors.InvalidArgumentError):\n+        sess.run(init_op, feed_dict={st: sparse_feed})\n+\n   @combinations.generate(combinations.combine(tf_api_version=2, mode=[\"eager\"]))\n   def testFromSparseTensorSlicesError(self):\n     with self.assertRaises(AttributeError):\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "8a84f7a2b5a2b27ecf88d25bad9ac777cd2f7992",
        "repo": "tensorflow/tensorflow",
        "msg": "Ensure num_streams >= 0 in tf.raw_ops.BoostedTreesCreateQuantileStreamResource\n\nPiperOrigin-RevId: 387452765\nChange-Id: I9990c760e177fabca6a3b9b4612ceeaeeba51495TensorFlow is an end-to-end open source platform for machine learning. In affected versions an attacker can cause a denial of service in `boosted_trees_create_quantile_stream_resource` by using negative arguments. The [implementation](https://github.com/tensorflow/tensorflow/blob/84d053187cb80d975ef2b9684d4b61981bca0c41/tensorflow/core/kernels/boosted_trees/quantile_ops.cc#L96) does not validate that `num_streams` only contains non-negative numbers. In turn, [this results in using this value to allocate memory](https://github.com/tensorflow/tensorflow/blob/84d053187cb80d975ef2b9684d4b61981bca0c41/tensorflow/core/kernels/boosted_trees/quantiles/quantile_stream_resource.h#L31-L40). However, `reserve` receives an unsigned integer so there is an implicit conversion from a negative value to a large positive unsigned. This results in a crash from the standard library. We have patched the issue in GitHub commit 8a84f7a2b5a2b27ecf88d25bad9ac777cd2f7992. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "filename": "quantile_ops.cc",
        "diff": "diff --git a/tensorflow/core/kernels/boosted_trees/quantile_ops.cc b/tensorflow/core/kernels/boosted_trees/quantile_ops.cc\nindex c245b25aab0fbf..13a0056060e92a 100644\n--- a/tensorflow/core/kernels/boosted_trees/quantile_ops.cc\n+++ b/tensorflow/core/kernels/boosted_trees/quantile_ops.cc\n@@ -116,6 +116,9 @@ class BoostedTreesCreateQuantileStreamResourceOp : public OpKernel {\n     const Tensor* num_streams_t;\n     OP_REQUIRES_OK(context, context->input(kNumStreamsName, &num_streams_t));\n     int64_t num_streams = num_streams_t->scalar<int64>()();\n+    OP_REQUIRES(context, num_streams >= 0,\n+                errors::InvalidArgument(\n+                    \"Num_streams input cannot be a negative integer\"));\n \n     auto result =\n         new QuantileStreamResource(epsilon, max_elements_, num_streams);\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "62acb7753b0e3c0d3ab3c15057b0a65222313334",
        "repo": "jsummers/deark",
        "msg": "pict,macrsrc: Fixed a bug that could cause division by 0\n\nFound by F. \u00c7elik.In Deark before v1.5.8, a specially crafted input file can cause a division by zero in (src/fmtutil.c) because of the value of pixelsize.",
        "filename": "fmtutil.c",
        "diff": "diff --git a/src/fmtutil.c b/src/fmtutil.c\nindex f7e9ac1b..ab728413 100644\n--- a/src/fmtutil.c\n+++ b/src/fmtutil.c\n@@ -1618,7 +1618,9 @@ void fmtutil_macbitmap_read_pixmap_only_fields(deark *c, dbuf *f, struct fmtutil\n \tde_dbg(c, \"pixel type=%d, bits/pixel=%d, components/pixel=%d, bits/comp=%d\",\n \t\t(int)bi->pixeltype, (int)bi->pixelsize, (int)bi->cmpcount, (int)bi->cmpsize);\n \n-\tbi->pdwidth = (bi->rowbytes*8)/bi->pixelsize;\n+\tif(bi->pixelsize>0) {\n+\t\tbi->pdwidth = (bi->rowbytes*8)/bi->pixelsize;\n+\t}\n \tif(bi->pdwidth < bi->npwidth) {\n \t\tbi->pdwidth = bi->npwidth;\n \t}\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "0c8a2a2cd1056b7dc403eacb5d2c0eec6ce47c6f",
        "repo": "php/php-src",
        "msg": "Fix for bug #72790 and bug #72799\n\n(cherry picked from commit a14fdb9746262549bbbb96abb87338bacd147e1b)\n\nConflicts:\n\text/wddx/wddx.cext/wddx/wddx.c in PHP before 5.6.25 and 7.x before 7.0.10 allows remote attackers to cause a denial of service (NULL pointer dereference and application crash) or possibly have unspecified other impact via an invalid wddxPacket XML document that is mishandled in a wddx_deserialize call, as demonstrated by a stray element inside a boolean element, leading to incorrect pop processing.",
        "filename": "wddx.c",
        "diff": "diff --git a/ext/wddx/tests/bug72790.phpt b/ext/wddx/tests/bug72790.phpt\nnew file mode 100644\nindex 0000000000000..a60524bdaf19e\n--- /dev/null\n+++ b/ext/wddx/tests/bug72790.phpt\n@@ -0,0 +1,35 @@\n+--TEST--\n+Bug 72790: wddx_deserialize null dereference with invalid xml\n+--SKIPIF--\n+<?php\n+if (!extension_loaded('wddx')) {\n+    die('skip. wddx not available');\n+}\n+?>\n+--FILE--\n+<?php\n+\n+$xml = <<< XML\n+<?xml version='1.0' ?>\n+<!DOCTYPE wddxPacket SYSTEM 'wddx_0100.dtd'>\n+<wddxPacket version='1.0'>\n+        |array>\n+                <var name=\"XXXX\">\n+                        <boolean value=\"this\">\n+                        </boolean>\n+                </var>\n+                <var name=\"YYYY\">\n+                        <var name=\"UUUU\">\n+                                <var name=\"EZEZ\">\n+                                </var>\n+                        </var>\n+                </var>\n+        </array>\n+</wddxPacket>\n+XML;\n+\n+$array = wddx_deserialize($xml);\n+var_dump($array);\n+?>\n+--EXPECT--\n+NULL\n\\ No newline at end of file\ndiff --git a/ext/wddx/tests/bug72799.phpt b/ext/wddx/tests/bug72799.phpt\nnew file mode 100644\nindex 0000000000000..5861d5538f49f\n--- /dev/null\n+++ b/ext/wddx/tests/bug72799.phpt\n@@ -0,0 +1,28 @@\n+--TEST--\n+Bug #72799: wddx_deserialize null dereference in php_wddx_pop_element\n+--SKIPIF--\n+<?php\n+if (!extension_loaded('wddx')) {\n+    die('skip. wddx not available');\n+}\n+?>\n+--FILE--\n+<?php\n+\n+$xml = <<<XML\n+<?xml version='1.0'?>\n+<!DOCTYPE wddxPacket SYSTEM 'wddx_0100.dtd'>\n+<wddxPacket version=\"1.0\">\n+    <var name=\"XXXX\">\n+        <boolean value=\"1\">\n+            <dateTime>1998-06-12T04:32:12+00</dateTime>\n+        </boolean>\n+    </var>\n+</wddxPacket>\n+XML;\n+\n+$array = wddx_deserialize($xml);\n+var_dump($array);\n+?>\n+--EXPECT--\n+NULL\n\\ No newline at end of file\ndiff --git a/ext/wddx/wddx.c b/ext/wddx/wddx.c\nindex d28cb7a0acbef..11cf0be62e30c 100644\n--- a/ext/wddx/wddx.c\n+++ b/ext/wddx/wddx.c\n@@ -886,10 +886,10 @@ static void php_wddx_pop_element(void *user_data, const XML_Char *name)\n \t\tif (Z_TYPE(ent1->data) == IS_UNDEF) {\n \t\t\tif (stack->top > 1) {\n \t\t\t\tstack->top--;\n+\t\t\t\tefree(ent1);\n \t\t\t} else {\n \t\t\t\tstack->done = 1;\n \t\t\t}\n-\t\t\tefree(ent1);\n \t\t\treturn;\n \t\t}\n \n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "e4571b8c5e9ffa1e85c0c671995bd4dcc5c75091",
        "repo": "torvalds/linux",
        "msg": "btrfs: fix NULL pointer dereference when deleting device by invalid id\n\n[BUG]\nIt's easy to trigger NULL pointer dereference, just by removing a\nnon-existing device id:\n\n # mkfs.btrfs -f -m single -d single /dev/test/scratch1 \\\n\t\t\t\t     /dev/test/scratch2\n # mount /dev/test/scratch1 /mnt/btrfs\n # btrfs device remove 3 /mnt/btrfs\n\nThen we have the following kernel NULL pointer dereference:\n\n BUG: kernel NULL pointer dereference, address: 0000000000000000\n #PF: supervisor read access in kernel mode\n #PF: error_code(0x0000) - not-present page\n PGD 0 P4D 0\n Oops: 0000 [#1] PREEMPT SMP NOPTI\n CPU: 9 PID: 649 Comm: btrfs Not tainted 5.14.0-rc3-custom+ #35\n Hardware name: QEMU Standard PC (Q35 + ICH9, 2009), BIOS 0.0.0 02/06/2015\n RIP: 0010:btrfs_rm_device+0x4de/0x6b0 [btrfs]\n  btrfs_ioctl+0x18bb/0x3190 [btrfs]\n  ? lock_is_held_type+0xa5/0x120\n  ? find_held_lock.constprop.0+0x2b/0x80\n  ? do_user_addr_fault+0x201/0x6a0\n  ? lock_release+0xd2/0x2d0\n  ? __x64_sys_ioctl+0x83/0xb0\n  __x64_sys_ioctl+0x83/0xb0\n  do_syscall_64+0x3b/0x90\n  entry_SYSCALL_64_after_hwframe+0x44/0xae\n\n[CAUSE]\nCommit a27a94c2b0c7 (\"btrfs: Make btrfs_find_device_by_devspec return\nbtrfs_device directly\") moves the \"missing\" device path check into\nbtrfs_rm_device().\n\nBut btrfs_rm_device() itself can have case where it only receives\n@devid, with NULL as @device_path.\n\nIn that case, calling strcmp() on NULL will trigger the NULL pointer\ndereference.\n\nBefore that commit, we handle the \"missing\" case inside\nbtrfs_find_device_by_devspec(), which will not check @device_path at all\nif @devid is provided, thus no way to trigger the bug.\n\n[FIX]\nBefore calling strcmp(), also make sure @device_path is not NULL.\n\nFixes: a27a94c2b0c7 (\"btrfs: Make btrfs_find_device_by_devspec return btrfs_device directly\")\nCC: stable@vger.kernel.org # 5.4+\nReported-by: butt3rflyh4ck <butterflyhuangxx@gmail.com>\nReviewed-by: Anand Jain <anand.jain@oracle.com>\nSigned-off-by: Qu Wenruo <wqu@suse.com>\nReviewed-by: David Sterba <dsterba@suse.com>\nSigned-off-by: David Sterba <dsterba@suse.com>A NULL pointer dereference flaw was found in the btrfs_rm_device function in fs/btrfs/volumes.c in the Linux Kernel, where triggering the bug requires \u2018CAP_SYS_ADMIN\u2019. This flaw allows a local attacker to crash the system or leak kernel internal information. The highest threat from this vulnerability is to system availability.",
        "filename": "volumes.c",
        "diff": "diff --git a/fs/btrfs/volumes.c b/fs/btrfs/volumes.c\nindex 536e60c6ade3cb..7fec0c68b744b9 100644\n--- a/fs/btrfs/volumes.c\n+++ b/fs/btrfs/volumes.c\n@@ -2074,7 +2074,7 @@ int btrfs_rm_device(struct btrfs_fs_info *fs_info, const char *device_path,\n \n \tif (IS_ERR(device)) {\n \t\tif (PTR_ERR(device) == -ENOENT &&\n-\t\t    strcmp(device_path, \"missing\") == 0)\n+\t\t    device_path && strcmp(device_path, \"missing\") == 0)\n \t\t\tret = BTRFS_ERROR_DEV_MISSING_NOT_FOUND;\n \t\telse\n \t\t\tret = PTR_ERR(device);\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "d072ed6aff835c174e856ce3a428163c0da9e8f4",
        "repo": "ImageMagick/ImageMagick",
        "msg": "Skip MNG CLIP chunk with out-of-range object IDsIn ImageMagick before 6.9.9-0 and 7.x before 7.0.6-1, the ReadOneMNGImage function in coders/png.c has an out-of-bounds read with the MNG CLIP chunk.",
        "filename": "png.c",
        "diff": "diff --git a/coders/png.c b/coders/png.c\nindex d6d33ee3603..ea6dce6ab5f 100644\n--- a/coders/png.c\n+++ b/coders/png.c\n@@ -5899,6 +5899,9 @@ static Image *ReadOneMNGImage(MngInfo* mng_info, const ImageInfo *image_info,\n \n                 for (i=(int) first_object; i <= (int) last_object; i++)\n                 {\n+                  if ((i < 0) || (i >= MNG_MAX_OBJECTS))\n+                    continue;\n+\n                   if (mng_info->exists[i] && !mng_info->frozen[i])\n                     {\n                       MngBox\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "9fae8f43accef8ea65d4a8ae9cdf297c46cfe29a",
        "repo": "pjsip/pjproject",
        "msg": "Merge pull request from GHSA-p6g5-v97c-w5q4\n\n* Prevent heap buffer overflow when parsing DNS packets\n\n* Make sure packet parsing doesn't advance beyond max/end\n\n* Update checks\n\n* Remove  check\n\nCo-authored-by: sauwming <ming@teluu.com>PJSIP is a free and open source multimedia communication library written in C. A buffer overflow vulnerability in versions 2.12 and prior affects applications that use PJSIP DNS resolution. It doesn't affect PJSIP users who utilize an external resolver. This vulnerability is related to CVE-2023-27585. The difference is that this issue is in parsing the query record `parse_rr()`, while the issue in CVE-2023-27585 is in `parse_query()`. A patch is available in the `master` branch of the `pjsip/pjproject` GitHub repository. A workaround is to disable DNS resolution in PJSIP config (by setting `nameserver_count` to zero) or use an external resolver instead.",
        "filename": "dns.c",
        "diff": "diff --git a/pjlib-util/src/pjlib-util/dns.c b/pjlib-util/src/pjlib-util/dns.c\nindex df47c83b9d..1f712eeced 100644\n--- a/pjlib-util/src/pjlib-util/dns.c\n+++ b/pjlib-util/src/pjlib-util/dns.c\n@@ -159,8 +159,13 @@ static pj_status_t get_name_len(int rec_counter, const pj_uint8_t *pkt,\n \t} else {\n \t    unsigned label_len = *p;\n \n-\t    /* Check that label length is valid */\n-\t    if (pkt+label_len > max)\n+\t    /* Check that label length is valid.\n+\t     * Each label consists of an octet length (of size 1) followed\n+\t     * by the octet of the specified length (label_len). Then it\n+\t     * must be followed by either another label's octet length or\n+\t     * a zero length octet (that terminates the sequence).\n+\t     */\n+\t    if (p+1+label_len+1 > max)\n \t\treturn PJLIB_UTIL_EDNSINNAMEPTR;\n \n \t    p += (label_len + 1);\n@@ -170,9 +175,6 @@ static pj_status_t get_name_len(int rec_counter, const pj_uint8_t *pkt,\n \t\t++label_len;\n \t    \n \t    *name_len += label_len;\n-\n-\t    if (p >= max)\n-\t\treturn PJLIB_UTIL_EDNSINSIZE;\n \t}\n     }\n     ++p;\n@@ -222,8 +224,13 @@ static pj_status_t get_name(int rec_counter, const pj_uint8_t *pkt,\n \t} else {\n \t    unsigned label_len = *p;\n \n-\t    /* Check that label length is valid */\n-\t    if (pkt+label_len > max)\n+\t    /* Check that label length is valid.\n+\t     * Each label consists of an octet length (of size 1) followed\n+\t     * by the octet of the specified length (label_len). Then it\n+\t     * must be followed by either another label's octet length or\n+\t     * a zero length octet (that terminates the sequence).\n+\t     */\n+\t    if (p+1+label_len+1 > max)\n \t\treturn PJLIB_UTIL_EDNSINNAMEPTR;\n \n \t    pj_memcpy(name->ptr + name->slen, p+1, label_len);\n@@ -234,9 +241,6 @@ static pj_status_t get_name(int rec_counter, const pj_uint8_t *pkt,\n \t\t*(name->ptr + name->slen) = '.';\n \t\t++name->slen;\n \t    }\n-\n-\t    if (p >= max)\n-\t\treturn PJLIB_UTIL_EDNSINSIZE;\n \t}\n     }\n \n@@ -269,6 +273,10 @@ static pj_status_t parse_query(pj_dns_parsed_query *q, pj_pool_t *pool,\n \n     p = (start + name_part_len);\n \n+    /* Check the size can accomodate next few fields. */\n+    if (p + 4 > max)\n+    \treturn PJLIB_UTIL_EDNSINSIZE;\n+\n     /* Get the type */\n     pj_memcpy(&q->type, p, 2);\n     q->type = pj_ntohs(q->type);\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "30721cf564cb029d34535446d6a5a6357bebc8e7",
        "repo": "tensorflow/tensorflow",
        "msg": "Fix tf.raw_ops.EditDistance vulnerability with negative indices.\n\nCheck that indices are non-negative. Fix several identical code sites.\nClean up grammar in error message.\n\nPiperOrigin-RevId: 445442017TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, the implementation of `tf.raw_ops.EditDistance` has incomplete validation. Users can pass negative values to cause a segmentation fault based denial of service. In multiple places throughout the code, one may compute an index for a write operation. However, the existing validation only checks against the upper bound of the array. Hence, it is possible to write before the array by massaging the input to generate negative values for `loc`. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.",
        "filename": "edit_distance_op.cc",
        "diff": "diff --git a/tensorflow/core/kernels/edit_distance_op.cc b/tensorflow/core/kernels/edit_distance_op.cc\nindex 3ff290e92b6103..3ed0f012b83ceb 100644\n--- a/tensorflow/core/kernels/edit_distance_op.cc\n+++ b/tensorflow/core/kernels/edit_distance_op.cc\n@@ -203,9 +203,9 @@ class EditDistanceOp : public OpKernel {\n         auto loc = std::inner_product(g_truth.begin(), g_truth.end(),\n                                       output_strides.begin(), int64_t{0});\n         OP_REQUIRES(\n-            ctx, loc < output_elements,\n+            ctx, 0 <= loc && loc < output_elements,\n             errors::Internal(\"Got an inner product \", loc,\n-                             \" which would require in writing to outside of \"\n+                             \" which would require writing to outside of \"\n                              \"the buffer for the output tensor (max elements \",\n                              output_elements, \")\"));\n         output_t(loc) =\n@@ -218,9 +218,9 @@ class EditDistanceOp : public OpKernel {\n         auto loc = std::inner_product(g_hypothesis.begin(), g_hypothesis.end(),\n                                       output_strides.begin(), int64_t{0});\n         OP_REQUIRES(\n-            ctx, loc < output_elements,\n+            ctx, 0 <= loc && loc < output_elements,\n             errors::Internal(\"Got an inner product \", loc,\n-                             \" which would require in writing to outside of \"\n+                             \" which would require writing to outside of \"\n                              \"the buffer for the output tensor (max elements \",\n                              output_elements, \")\"));\n         output_t(loc) = hypothesis_seq.size();\n@@ -232,9 +232,9 @@ class EditDistanceOp : public OpKernel {\n         auto loc = std::inner_product(g_truth.begin(), g_truth.end(),\n                                       output_strides.begin(), int64_t{0});\n         OP_REQUIRES(\n-            ctx, loc < output_elements,\n+            ctx, 0 <= loc && loc < output_elements,\n             errors::Internal(\"Got an inner product \", loc,\n-                             \" which would require in writing to outside of \"\n+                             \" which would require writing to outside of \"\n                              \"the buffer for the output tensor (max elements \",\n                              output_elements, \")\"));\n         output_t(loc) = (normalize_) ? 1.0 : truth_seq.size();\n@@ -248,9 +248,9 @@ class EditDistanceOp : public OpKernel {\n       auto loc = std::inner_product(g_hypothesis.begin(), g_hypothesis.end(),\n                                     output_strides.begin(), int64_t{0});\n       OP_REQUIRES(\n-          ctx, loc < output_elements,\n+          ctx, 0 <= loc && loc < output_elements,\n           errors::Internal(\"Got an inner product \", loc,\n-                           \" which would require in writing to outside of the \"\n+                           \" which would require writing to outside of the \"\n                            \"buffer for the output tensor (max elements \",\n                            output_elements, \")\"));\n       output_t(loc) = hypothesis_seq.size();\n@@ -266,9 +266,9 @@ class EditDistanceOp : public OpKernel {\n       auto loc = std::inner_product(g_truth.begin(), g_truth.end(),\n                                     output_strides.begin(), int64_t{0});\n       OP_REQUIRES(\n-          ctx, loc < output_elements,\n+          ctx, 0 <= loc && loc < output_elements,\n           errors::Internal(\"Got an inner product \", loc,\n-                           \" which would require in writing to outside of the \"\n+                           \" which would require writing to outside of the \"\n                            \"buffer for the output tensor (max elements \",\n                            output_elements, \")\"));\n       output_t(loc) = (normalize_) ? 1.0 : truth_seq.size();\ndiff --git a/tensorflow/python/kernel_tests/array_ops/edit_distance_op_test.py b/tensorflow/python/kernel_tests/array_ops/edit_distance_op_test.py\nindex 9996a4f621e4bf..b74024aa60c8b6 100644\n--- a/tensorflow/python/kernel_tests/array_ops/edit_distance_op_test.py\n+++ b/tensorflow/python/kernel_tests/array_ops/edit_distance_op_test.py\n@@ -207,6 +207,24 @@ def testEditDistanceZeroLengthHypothesisAndTruth(self):\n         normalize=True,\n         expected_output=expected_output)\n \n+  def testEditDistanceBadIndices(self):\n+    hypothesis_indices = np.full((3, 3), -1250999896764, dtype=np.int64)\n+    hypothesis_values = np.empty(3, dtype=np.int64)\n+    hypothesis_shape = np.empty(3, dtype=np.int64)\n+    truth_indices = np.full((3, 3), -1250999896764, dtype=np.int64)\n+    truth_values = np.full([3], 2, dtype=np.int64)\n+    truth_shape = np.full([3], 2, dtype=np.int64)\n+    expected_output = []  # dummy; ignored\n+\n+    self._testEditDistance(\n+        hypothesis=(hypothesis_indices, hypothesis_values, hypothesis_shape),\n+        truth=(truth_indices, truth_values, truth_shape),\n+        normalize=False,\n+        expected_output=expected_output,\n+        expected_err_re=(r\"inner product -\\d+ which would require writing \"\n+                         \"to outside of the buffer for the output tensor\")\n+    )\n+\n \n if __name__ == \"__main__\":\n   test.main()\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "3dbe11b37d65c8472faf0654410068e5500b3adb",
        "repo": "gpac/gpac",
        "msg": "fixed #2175MP4Box is a component of GPAC-2.0.0, which is a widely-used third-party package on RPM Fusion. When MP4Box tries to parse a MP4 file, it calls the function `diST_box_read()` to read from video. In this function, it allocates a buffer `str` with fixed length. However, content read from `bs` is controllable by user, so is the length, which causes a buffer overflow.",
        "filename": "box_code_3gpp.c",
        "diff": "diff --git a/src/isomedia/box_code_3gpp.c b/src/isomedia/box_code_3gpp.c\nindex 3f9ff05692..928a5575f2 100644\n--- a/src/isomedia/box_code_3gpp.c\n+++ b/src/isomedia/box_code_3gpp.c\n@@ -1128,20 +1128,12 @@ void diST_box_del(GF_Box *s)\n \n GF_Err diST_box_read(GF_Box *s, GF_BitStream *bs)\n {\n-\tu32 i;\n-\tchar str[1024];\n \tGF_DIMSScriptTypesBox *p = (GF_DIMSScriptTypesBox *)s;\n \n-\ti=0;\n-\tstr[0]=0;\n-\twhile (1) {\n-\t\tstr[i] = gf_bs_read_u8(bs);\n-\t\tif (!str[i]) break;\n-\t\ti++;\n-\t}\n-\tISOM_DECREASE_SIZE(p, i);\n-\n-\tp->content_script_types = gf_strdup(str);\n+\tp->content_script_types = gf_malloc(sizeof(char) * (s->size+1));\n+\tif (!p->content_script_types) return GF_OUT_OF_MEM;\n+\tgf_bs_read_data(bs, p->content_script_types, s->size);\n+\tp->content_script_types[s->size] = 0;\n \treturn GF_OK;\n }\n \n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "b619c6f865715ca3b15ef1842b5b95edbaa710ad",
        "repo": "tensorflow/tensorflow",
        "msg": "Use BuildTensorShapeBase when parsing unverified TensorShapes during checkpoint loading.\n\nThis avoids crashing when the TensorShape has negative dimensions.\n\nPiperOrigin-RevId: 392769882\nChange-Id: Id1f7ae7fcf8142193556af47abfda81b13d3cce4TensorFlow is an open source platform for machine learning. In affected versions an attacker can trigger undefined behavior, integer overflows, segfaults and `CHECK`-fail crashes if they can change saved checkpoints from outside of TensorFlow. This is because the checkpoints loading infrastructure is missing validation for invalid file formats. The fixes will be included in TensorFlow 2.7.0. We will also cherrypick these commits on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.",
        "filename": "tensor_slice_reader.cc",
        "diff": "diff --git a/tensorflow/core/util/tensor_slice_reader.cc b/tensorflow/core/util/tensor_slice_reader.cc\nindex 00911b13f34914..da5ac17ee0eaef 100644\n--- a/tensorflow/core/util/tensor_slice_reader.cc\n+++ b/tensorflow/core/util/tensor_slice_reader.cc\n@@ -168,7 +168,9 @@ void TensorSliceReader::LoadShard(int shard) const {\n                           \"checkpoint\");\n   if (!status_.ok()) return;\n   for (const SavedSliceMeta& ssm : sts.meta().tensor()) {\n-    TensorShape ssm_shape(ssm.shape());\n+    TensorShape ssm_shape;\n+    status_ = TensorShape::BuildTensorShapeBase(ssm.shape(), &ssm_shape);\n+    if (!status_.ok()) return;\n     for (const TensorSliceProto& tsp : ssm.slice()) {\n       TensorSlice ss_slice(tsp);\n       status_ = RegisterTensorSlice(ssm.name(), ssm_shape, ssm.type(), fname,\ndiff --git a/tensorflow/core/util/tensor_slice_reader_test.cc b/tensorflow/core/util/tensor_slice_reader_test.cc\nindex 9bd3063d4ebec3..382e29ab321984 100644\n--- a/tensorflow/core/util/tensor_slice_reader_test.cc\n+++ b/tensorflow/core/util/tensor_slice_reader_test.cc\n@@ -18,6 +18,7 @@ limitations under the License.\n #include <utility>\n #include <vector>\n \n+#include \"tensorflow/core/framework/tensor_shape.pb.h\"\n #include \"tensorflow/core/framework/types.h\"\n #include \"tensorflow/core/framework/versions.pb.h\"\n #include \"tensorflow/core/lib/core/status_test_util.h\"\n@@ -410,6 +411,31 @@ TEST(TensorSliceReaderTest, UnsupportedTensorType) {\n   EXPECT_FALSE(reader.GetTensor(\"test\", &tensor).ok());\n }\n \n+TEST(TensorSliceReaderTest, NegativeTensorShapeDimension) {\n+  const string fname =\n+      io::JoinPath(testing::TmpDir(), \"negative_dim_checkpoint\");\n+  TensorSliceWriter writer(fname, CreateTableTensorSliceBuilder);\n+  const int32 data[] = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9};\n+  TF_CHECK_OK(writer.Add(\"test\", TensorShape({4, 5}),\n+                         TensorSlice::ParseOrDie(\"0,2:-\"), data));\n+  TF_CHECK_OK(writer.Finish());\n+\n+  MutateSavedTensorSlices(fname, [](SavedTensorSlices sts) {\n+    if (sts.has_meta()) {\n+      for (auto& tensor : *sts.mutable_meta()->mutable_tensor()) {\n+        for (auto& dim : *tensor.mutable_shape()->mutable_dim()) {\n+          dim.set_size(-dim.size());\n+        }\n+      }\n+    }\n+    return sts.SerializeAsString();\n+  });\n+\n+  TensorSliceReader reader(fname, OpenTableTensorSliceReader);\n+  // The negative dimension should cause loading to fail.\n+  EXPECT_FALSE(reader.status().ok());\n+}\n+\n void CachedTensorSliceReaderTesterHelper(\n     const TensorSliceWriter::CreateBuilderFunction& create_function,\n     const TensorSliceReader::OpenTableFunction& open_function) {\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "a74702c630e108125e71898398737baec8f02238",
        "repo": "litespeedtech/lsquic",
        "msg": "Release 3.1.0liblsquic/lsquic_qenc_hdl.c in LiteSpeed QUIC (aka LSQUIC) before 3.1.0 mishandles MAX_TABLE_CAPACITY.",
        "filename": "lsquic_qenc_hdl.c",
        "diff": "diff --git a/APIs.txt b/APIs.txt\nindex 8186f88ef..16d5d0003 100644\n--- a/APIs.txt\n+++ b/APIs.txt\n@@ -1,4 +1,4 @@\n-# Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE.\n+# Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE.\n LSQUIC APIs\n ===========\n \ndiff --git a/CHANGELOG b/CHANGELOG\nindex 32cf6a03a..eec807dd6 100644\n--- a/CHANGELOG\n+++ b/CHANGELOG\n@@ -1,3 +1,14 @@\n+2022-05-06\n+    - 3.1.0\n+    - Better handling of transport parameter max_table_capcity < 32\n+    - Fix NULL pointer dereference in handshake\n+    - Fix 0-RTT transport parameter validation (issue #367)\n+    - Remove unnecessary debug log to avoid NULL pointer dereference\n+    - Tick connection on datagram write (pull #314)\n+    - Do not dispatch write event for FINISHED stream\n+    - Tweaks for CMake configuration (pull #354 #369 #370 #373 #374)\n+    - Update ls-qpack to 2.3.0\n+\n 2022-01-10\n     - 3.0.4\n     - Fix overly strict assert()\ndiff --git a/CMakeLists.txt b/CMakeLists.txt\nindex 5ddd90692..65c477689 100644\n--- a/CMakeLists.txt\n+++ b/CMakeLists.txt\n@@ -1,4 +1,4 @@\n-# Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE.\n+# Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE.\n cmake_minimum_required(VERSION 3.0...3.23)\n \n \n@@ -336,11 +336,3 @@ INSTALL(FILES\n     include/lsxpack_header.h\n     DESTINATION ${CMAKE_INSTALL_INCLUDEDIR}/lsquic\n )\n-\n-if(WIN32)\n-    # The other file in wincompat is not used in installed headers\n-    INSTALL(FILES\n-        wincompat/vc_compat.h\n-        DESTINATION ${CMAKE_INSTALL_INCLUDEDIR}/lsquic\n-    )\n-endif()\ndiff --git a/CONTRIBUTORS.txt b/CONTRIBUTORS.txt\nindex d5fd6a714..930337616 100644\n--- a/CONTRIBUTORS.txt\n+++ b/CONTRIBUTORS.txt\n@@ -1,4 +1,4 @@\n-# Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE.\n+# Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE.\n In addition to the LiteSpeed QUIC Team, the following people contributed\n to the LiteSpeed QUIC and HTTP/3 Library:\n \ndiff --git a/EXAMPLES.txt b/EXAMPLES.txt\nindex 612bb71e5..5bedbb7a4 100644\n--- a/EXAMPLES.txt\n+++ b/EXAMPLES.txt\n@@ -1,4 +1,4 @@\n-# Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE.\n+# Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE.\n LSQUIC Examples\n ===============\n \ndiff --git a/LICENSE b/LICENSE\nindex b825fe57b..8a83a86a5 100644\n--- a/LICENSE\n+++ b/LICENSE\n@@ -1,6 +1,6 @@\n MIT License\n \n-Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc\n+Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc\n \n Permission is hereby granted, free of charge, to any person obtaining a copy\n of this software and associated documentation files (the \"Software\"), to deal\ndiff --git a/bin/CMakeLists.txt b/bin/CMakeLists.txt\nindex 34f9cacf1..0872f115f 100644\n--- a/bin/CMakeLists.txt\n+++ b/bin/CMakeLists.txt\n@@ -1,4 +1,4 @@\n-# Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE.\n+# Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE.\n \n include_directories(${CMAKE_CURRENT_BINARY_DIR})\n LIST(APPEND LIBS ${EVENT_LIB})\ndiff --git a/bin/duck_client.c b/bin/duck_client.c\nindex 307c74870..30484e442 100644\n--- a/bin/duck_client.c\n+++ b/bin/duck_client.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * duck_client.c -- The siduck client.  See\n  *      https://tools.ietf.org/html/draft-pardue-quic-siduck-00\ndiff --git a/bin/duck_server.c b/bin/duck_server.c\nindex fae70a1b3..543b9f1aa 100644\n--- a/bin/duck_server.c\n+++ b/bin/duck_server.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * A duck quacks!  The server for the siduck protocol:\n  *      https://tools.ietf.org/html/draft-pardue-quic-siduck-00\ndiff --git a/bin/echo_client.c b/bin/echo_client.c\nindex d0c9b6851..a0e7fffe7 100644\n--- a/bin/echo_client.c\n+++ b/bin/echo_client.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * echo_client.c -- This is really a \"line client:\" it connects to QUIC server\n  * and sends it stuff, line by line.  It works in tandem with echo_server.\ndiff --git a/bin/echo_server.c b/bin/echo_server.c\nindex 3750d84d6..73e10fd65 100644\n--- a/bin/echo_server.c\n+++ b/bin/echo_server.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * echo_server.c -- QUIC server that echoes back input line by line\n  */\ndiff --git a/bin/http_client.c b/bin/http_client.c\nindex 134315383..33f638bce 100644\n--- a/bin/http_client.c\n+++ b/bin/http_client.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * http_client.c -- A simple HTTP/QUIC client\n  */\ndiff --git a/bin/http_server.c b/bin/http_server.c\nindex 3c2cc0776..c5b2caf80 100644\n--- a/bin/http_server.c\n+++ b/bin/http_server.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * http_server.c -- A simple HTTP/QUIC server\n  *\ndiff --git a/bin/md5_client.c b/bin/md5_client.c\nindex 64526626b..926b721e1 100644\n--- a/bin/md5_client.c\n+++ b/bin/md5_client.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * md5_client.c -- This client sends one or more files to MD5 QUIC server\n  *                 for MD5 sum calculation.\ndiff --git a/bin/md5_server.c b/bin/md5_server.c\nindex b36768eb9..c5acd3afa 100644\n--- a/bin/md5_server.c\n+++ b/bin/md5_server.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * md5_server.c -- Read one or more streams from the client and return\n  *                 MD5 sum of the payload.\ndiff --git a/bin/perf_client.c b/bin/perf_client.c\nindex 314ea8dc7..f9cf2913b 100644\n--- a/bin/perf_client.c\n+++ b/bin/perf_client.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * perf_client.c -- Implements the \"perf\" client, see\n  *      https://tools.ietf.org/html/draft-banks-quic-performance-00\ndiff --git a/bin/perf_server.c b/bin/perf_server.c\nindex 0ecebe101..d43cc6219 100644\n--- a/bin/perf_server.c\n+++ b/bin/perf_server.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * perf_server.c -- Implements the \"perf\" server, see\n  *      https://tools.ietf.org/html/draft-banks-quic-performance-00\ndiff --git a/bin/prog.c b/bin/prog.c\nindex 0affcb195..b779f92a9 100644\n--- a/bin/prog.c\n+++ b/bin/prog.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #ifndef WIN32\n #include <arpa/inet.h>\ndiff --git a/bin/prog.h b/bin/prog.h\nindex 804d05422..1638d2328 100644\n--- a/bin/prog.h\n+++ b/bin/prog.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * prog.h -- common setup and options for QUIC program\n  */\ndiff --git a/bin/test_cert.c b/bin/test_cert.c\nindex af1f8d0ed..e00bde8ec 100644\n--- a/bin/test_cert.c\n+++ b/bin/test_cert.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <errno.h>\n #include <stdio.h>\n #include <stdlib.h>\ndiff --git a/bin/test_cert.h b/bin/test_cert.h\nindex 25ed43bdb..4614b57c1 100644\n--- a/bin/test_cert.h\n+++ b/bin/test_cert.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef TEST_CERT_H\n #define TEST_CERT_H\n \ndiff --git a/bin/test_common.c b/bin/test_common.c\nindex 174fde748..685947d5f 100644\n--- a/bin/test_common.c\n+++ b/bin/test_common.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #if __GNUC__\n #define _GNU_SOURCE     /* For struct in6_pktinfo */\n #endif\ndiff --git a/bin/test_common.h b/bin/test_common.h\nindex 5bb291af3..4ad747295 100644\n--- a/bin/test_common.h\n+++ b/bin/test_common.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * Test client's and server's common components.\n  */\ndiff --git a/docs/conf.py b/docs/conf.py\nindex 028b6ddf1..1b6001470 100644\n--- a/docs/conf.py\n+++ b/docs/conf.py\n@@ -20,13 +20,13 @@\n # -- Project information -----------------------------------------------------\n \n project = u'lsquic'\n-copyright = u'2021, LiteSpeed Technologies'\n+copyright = u'2022, LiteSpeed Technologies'\n author = u'LiteSpeed Technologies'\n \n # The short X.Y version\n-version = u'3.0'\n+version = u'3.1'\n # The full version, including alpha/beta/rc tags\n-release = u'3.0.4'\n+release = u'3.1.0'\n \n \n # -- General configuration ---------------------------------------------------\ndiff --git a/include/lsquic.h b/include/lsquic.h\nindex 71c9e3c49..0cba9bb9e 100644\n--- a/include/lsquic.h\n+++ b/include/lsquic.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef __LSQUIC_H__\n #define __LSQUIC_H__\n \n@@ -24,8 +24,8 @@ extern \"C\" {\n #endif\n \n #define LSQUIC_MAJOR_VERSION 3\n-#define LSQUIC_MINOR_VERSION 0\n-#define LSQUIC_PATCH_VERSION 4\n+#define LSQUIC_MINOR_VERSION 1\n+#define LSQUIC_PATCH_VERSION 0\n \n /**\n  * Engine flags:\ndiff --git a/include/lsquic_types.h b/include/lsquic_types.h\nindex 92d752ba8..e76e4c98c 100644\n--- a/include/lsquic_types.h\n+++ b/include/lsquic_types.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef __LSQUIC_TYPES_H__\n #define __LSQUIC_TYPES_H__\n \ndiff --git a/include/lsxpack_header.h b/include/lsxpack_header.h\nindex e4719934b..9c05c7544 100644\n--- a/include/lsxpack_header.h\n+++ b/include/lsxpack_header.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef LSXPACK_HEADER_H_v206\n #define LSXPACK_HEADER_H_v206\n \ndiff --git a/src/CMakeLists.txt b/src/CMakeLists.txt\nindex 356322f3f..5494fea3b 100644\n--- a/src/CMakeLists.txt\n+++ b/src/CMakeLists.txt\n@@ -1,4 +1,4 @@\n-# Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE.\n+# Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE.\n cmake_minimum_required(VERSION 3.0...3.23)\n \n add_subdirectory(liblsquic)\ndiff --git a/src/liblsquic/CMakeLists.txt b/src/liblsquic/CMakeLists.txt\nindex e8cdde837..d462e7590 100644\n--- a/src/liblsquic/CMakeLists.txt\n+++ b/src/liblsquic/CMakeLists.txt\n@@ -1,4 +1,4 @@\n-# Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE.\n+# Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE.\n SET(lsquic_STAT_SRCS\n     ls-qpack/lsqpack.c\n     lsquic_adaptive_cc.c\n@@ -159,3 +159,4 @@ install(\n     DESTINATION share/lsquic\n     NAMESPACE lsquic::\n     FILE lsquic-targets.cmake)\n+\ndiff --git a/src/liblsquic/common_cert_set_2.c b/src/liblsquic/common_cert_set_2.c\nindex 4e41de0f0..fb0e06fa7 100644\n--- a/src/liblsquic/common_cert_set_2.c\n+++ b/src/liblsquic/common_cert_set_2.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /* Copyright (c) 2015 The Chromium Authors. All rights reserved.\n  * Use of this source code is governed by a BSD-style license that can be\n  * found in the LICENSE.chrome file.\ndiff --git a/src/liblsquic/common_cert_set_2a.inc b/src/liblsquic/common_cert_set_2a.inc\nindex 403417aeb..e9ea3cf3b 100644\n--- a/src/liblsquic/common_cert_set_2a.inc\n+++ b/src/liblsquic/common_cert_set_2a.inc\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /* Copyright (c) 2015 The Chromium Authors. All rights reserved.\n  * Use of this source code is governed by a BSD-style license that can be\n  * found in the LICENSE.chrome file.\ndiff --git a/src/liblsquic/common_cert_set_2b.inc b/src/liblsquic/common_cert_set_2b.inc\nindex 586af45b4..45f0e3171 100644\n--- a/src/liblsquic/common_cert_set_2b.inc\n+++ b/src/liblsquic/common_cert_set_2b.inc\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /* Copyright (c) 2015 The Chromium Authors. All rights reserved.\n  * Use of this source code is governed by a BSD-style license that can be\n  * found in the LICENSE.chrome file.\ndiff --git a/src/liblsquic/common_cert_set_3.c b/src/liblsquic/common_cert_set_3.c\nindex 1e6d40197..671054387 100644\n--- a/src/liblsquic/common_cert_set_3.c\n+++ b/src/liblsquic/common_cert_set_3.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /* Copyright (c) 2015 The Chromium Authors. All rights reserved.\n  * Use of this source code is governed by a BSD-style license that can be\n  * found in the LICENSE.chrome file.\ndiff --git a/src/liblsquic/common_cert_set_3a.inc b/src/liblsquic/common_cert_set_3a.inc\nindex de6677703..d12d4de1a 100644\n--- a/src/liblsquic/common_cert_set_3a.inc\n+++ b/src/liblsquic/common_cert_set_3a.inc\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /* Copyright (c) 2015 The Chromium Authors. All rights reserved.\n  * Use of this source code is governed by a BSD-style license that can be\n  * found in the LICENSE.chrome file.\ndiff --git a/src/liblsquic/common_cert_set_3b.inc b/src/liblsquic/common_cert_set_3b.inc\nindex 5f080b753..4ad584bb9 100644\n--- a/src/liblsquic/common_cert_set_3b.inc\n+++ b/src/liblsquic/common_cert_set_3b.inc\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /* Copyright (c) 2015 The Chromium Authors. All rights reserved.\n  * Use of this source code is governed by a BSD-style license that can be\n  * found in the LICENSE.chrome file.\ndiff --git a/src/liblsquic/fiu-local.h b/src/liblsquic/fiu-local.h\nindex 7c295ebea..a63f44b0d 100644\n--- a/src/liblsquic/fiu-local.h\n+++ b/src/liblsquic/fiu-local.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n \n /* libfiu - Fault Injection in Userspace\n  *\ndiff --git a/src/liblsquic/ls-sfparser.c b/src/liblsquic/ls-sfparser.c\nindex 03bcc4647..281670fd5 100644\n--- a/src/liblsquic/ls-sfparser.c\n+++ b/src/liblsquic/ls-sfparser.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #line 2 \"ls-sfparser.c\"\n #line 2 \"ls-sfparser.l\"\n /*\ndiff --git a/src/liblsquic/ls-sfparser.h b/src/liblsquic/ls-sfparser.h\nindex 152ba6881..571f73bd2 100644\n--- a/src/liblsquic/ls-sfparser.h\n+++ b/src/liblsquic/ls-sfparser.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n MIT License\n \ndiff --git a/src/liblsquic/lsquic_adaptive_cc.c b/src/liblsquic/lsquic_adaptive_cc.c\nindex a789476a7..cc1aefa5a 100644\n--- a/src/liblsquic/lsquic_adaptive_cc.c\n+++ b/src/liblsquic/lsquic_adaptive_cc.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /* lsquic_adaptive_cc.c -- adaptive congestion controller */\n \n #include <inttypes.h>\ndiff --git a/src/liblsquic/lsquic_adaptive_cc.h b/src/liblsquic/lsquic_adaptive_cc.h\nindex 8b8fe4953..36ea760b1 100644\n--- a/src/liblsquic/lsquic_adaptive_cc.h\n+++ b/src/liblsquic/lsquic_adaptive_cc.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_adaptive_cc.h -- Adaptive congestion controller\n  *\ndiff --git a/src/liblsquic/lsquic_alarmset.c b/src/liblsquic/lsquic_alarmset.c\nindex 0b98597e5..5a72ee356 100644\n--- a/src/liblsquic/lsquic_alarmset.c\n+++ b/src/liblsquic/lsquic_alarmset.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_alarmset.c -- A set of alarms\n  */\ndiff --git a/src/liblsquic/lsquic_alarmset.h b/src/liblsquic/lsquic_alarmset.h\nindex 6c1d4c1ac..fd6ea7d58 100644\n--- a/src/liblsquic/lsquic_alarmset.h\n+++ b/src/liblsquic/lsquic_alarmset.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_alarmset.h -- A set of alarms\n  */\ndiff --git a/src/liblsquic/lsquic_arr.c b/src/liblsquic/lsquic_arr.c\nindex f28c743f6..e3828c564 100644\n--- a/src/liblsquic/lsquic_arr.c\n+++ b/src/liblsquic/lsquic_arr.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_arr.c\n  */\ndiff --git a/src/liblsquic/lsquic_arr.h b/src/liblsquic/lsquic_arr.h\nindex 994eacf1e..881b771a7 100644\n--- a/src/liblsquic/lsquic_arr.h\n+++ b/src/liblsquic/lsquic_arr.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_arr.h -- Array\n  */\ndiff --git a/src/liblsquic/lsquic_attq.c b/src/liblsquic/lsquic_attq.c\nindex e00cb197b..4a3eb59fc 100644\n--- a/src/liblsquic/lsquic_attq.c\n+++ b/src/liblsquic/lsquic_attq.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_attq.c -- Advisory Tick Time Queue\n  *\ndiff --git a/src/liblsquic/lsquic_attq.h b/src/liblsquic/lsquic_attq.h\nindex bcc3a222d..c13c80de0 100644\n--- a/src/liblsquic/lsquic_attq.h\n+++ b/src/liblsquic/lsquic_attq.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_attq.h -- Advisory Tick Time Queue\n  */\ndiff --git a/src/liblsquic/lsquic_bbr.c b/src/liblsquic/lsquic_bbr.c\nindex 3d5f83592..5bd83a7fb 100644\n--- a/src/liblsquic/lsquic_bbr.c\n+++ b/src/liblsquic/lsquic_bbr.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n // Copyright 2016 The Chromium Authors. All rights reserved.\n // Use of this source code is governed by a BSD-style license that can be\n // found in the LICENSE.chrome file.\ndiff --git a/src/liblsquic/lsquic_bbr.h b/src/liblsquic/lsquic_bbr.h\nindex 699080903..89634c62a 100644\n--- a/src/liblsquic/lsquic_bbr.h\n+++ b/src/liblsquic/lsquic_bbr.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef LSQUIC_BBR_H\n #define LSQUIC_BBR_H\n \ndiff --git a/src/liblsquic/lsquic_bw_sampler.c b/src/liblsquic/lsquic_bw_sampler.c\nindex 3bf7be8b2..2d6541623 100644\n--- a/src/liblsquic/lsquic_bw_sampler.c\n+++ b/src/liblsquic/lsquic_bw_sampler.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <inttypes.h>\n #include <stddef.h>\ndiff --git a/src/liblsquic/lsquic_bw_sampler.h b/src/liblsquic/lsquic_bw_sampler.h\nindex 51ca3bfe0..ec2d8e83e 100644\n--- a/src/liblsquic/lsquic_bw_sampler.h\n+++ b/src/liblsquic/lsquic_bw_sampler.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef LSQUIC_BW_SAMPLER_H\n #define LSQUIC_BW_SAMPLER_H 1\n \ndiff --git a/src/liblsquic/lsquic_byteswap.h b/src/liblsquic/lsquic_byteswap.h\nindex bf23ace29..fdb9ab3a3 100644\n--- a/src/liblsquic/lsquic_byteswap.h\n+++ b/src/liblsquic/lsquic_byteswap.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef LSQUIC_BYTESWAP_H\n #define LSQUIC_BYTESWAP_H 1\n \ndiff --git a/src/liblsquic/lsquic_cfcw.c b/src/liblsquic/lsquic_cfcw.c\nindex c51067c68..d845aaa2b 100644\n--- a/src/liblsquic/lsquic_cfcw.c\n+++ b/src/liblsquic/lsquic_cfcw.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <inttypes.h>\n #include <stdint.h>\n #include <stdlib.h>\ndiff --git a/src/liblsquic/lsquic_chsk_stream.c b/src/liblsquic/lsquic_chsk_stream.c\nindex 307a5e696..6cc86b50b 100644\n--- a/src/liblsquic/lsquic_chsk_stream.c\n+++ b/src/liblsquic/lsquic_chsk_stream.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * Stream/crypto handshake adapter for the client side.\n  *\ndiff --git a/src/liblsquic/lsquic_chsk_stream.h b/src/liblsquic/lsquic_chsk_stream.h\nindex dada4a149..fe9db8d69 100644\n--- a/src/liblsquic/lsquic_chsk_stream.h\n+++ b/src/liblsquic/lsquic_chsk_stream.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * Stream/crypto handshake adapter for the client side.\n  */\ndiff --git a/src/liblsquic/lsquic_cong_ctl.h b/src/liblsquic/lsquic_cong_ctl.h\nindex bfcc1c7ed..31957d7a9 100644\n--- a/src/liblsquic/lsquic_cong_ctl.h\n+++ b/src/liblsquic/lsquic_cong_ctl.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_cong_ctl.h -- congestion control interface\n  */\ndiff --git a/src/liblsquic/lsquic_conn.c b/src/liblsquic/lsquic_conn.c\nindex 028b1d931..f76550dc2 100644\n--- a/src/liblsquic/lsquic_conn.c\n+++ b/src/liblsquic/lsquic_conn.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <inttypes.h>\n #include <string.h>\ndiff --git a/src/liblsquic/lsquic_conn.h b/src/liblsquic/lsquic_conn.h\nindex 4979240a9..200ba0f2c 100644\n--- a/src/liblsquic/lsquic_conn.h\n+++ b/src/liblsquic/lsquic_conn.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_conn.h -- Connection interface\n  *\ndiff --git a/src/liblsquic/lsquic_conn_flow.h b/src/liblsquic/lsquic_conn_flow.h\nindex 91b41aee5..8fa8587d4 100644\n--- a/src/liblsquic/lsquic_conn_flow.h\n+++ b/src/liblsquic/lsquic_conn_flow.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_conn_flow.h -- Connection flow control-related functions\n  */\ndiff --git a/src/liblsquic/lsquic_conn_public.h b/src/liblsquic/lsquic_conn_public.h\nindex 21e31f10b..c6bbb3afe 100644\n--- a/src/liblsquic/lsquic_conn_public.h\n+++ b/src/liblsquic/lsquic_conn_public.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_conn_public.h -- Connection's \"public interface\"\n  *\ndiff --git a/src/liblsquic/lsquic_crand.c b/src/liblsquic/lsquic_crand.c\nindex 58880f080..61b77a8c3 100644\n--- a/src/liblsquic/lsquic_crand.c\n+++ b/src/liblsquic/lsquic_crand.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <openssl/rand.h>\n #include <stdint.h>\n \ndiff --git a/src/liblsquic/lsquic_crand.h b/src/liblsquic/lsquic_crand.h\nindex 2333b571d..9e9d904b7 100644\n--- a/src/liblsquic/lsquic_crand.h\n+++ b/src/liblsquic/lsquic_crand.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_crand.h -- cached random bytes\n  *\ndiff --git a/src/liblsquic/lsquic_crt_compress.c b/src/liblsquic/lsquic_crt_compress.c\nindex 42539a20b..c6da73b51 100644\n--- a/src/liblsquic/lsquic_crt_compress.c\n+++ b/src/liblsquic/lsquic_crt_compress.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdbool.h>\n #include <string.h>\ndiff --git a/src/liblsquic/lsquic_crt_compress.h b/src/liblsquic/lsquic_crt_compress.h\nindex f9b708ef0..07a819de7 100644\n--- a/src/liblsquic/lsquic_crt_compress.h\n+++ b/src/liblsquic/lsquic_crt_compress.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef __LSQUIC_CRT_COMPRESS_H__\n #define __LSQUIC_CRT_COMPRESS_H__\n \ndiff --git a/src/liblsquic/lsquic_crypto.c b/src/liblsquic/lsquic_crypto.c\nindex b24c76d42..2dbf692e2 100644\n--- a/src/liblsquic/lsquic_crypto.c\n+++ b/src/liblsquic/lsquic_crypto.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <string.h>\n \ndiff --git a/src/liblsquic/lsquic_crypto.h b/src/liblsquic/lsquic_crypto.h\nindex 045580016..5a9d194ed 100644\n--- a/src/liblsquic/lsquic_crypto.h\n+++ b/src/liblsquic/lsquic_crypto.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n \n #ifndef __LSQUIC_CRYPTO_H__\n #define __LSQUIC_CRYPTO_H__\ndiff --git a/src/liblsquic/lsquic_cubic.c b/src/liblsquic/lsquic_cubic.c\nindex 0d2376374..a4efeacde 100644\n--- a/src/liblsquic/lsquic_cubic.c\n+++ b/src/liblsquic/lsquic_cubic.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_cubic.c -- LSQUIC CUBIC implementation.\n  */\ndiff --git a/src/liblsquic/lsquic_cubic.h b/src/liblsquic/lsquic_cubic.h\nindex 6f7b25090..8eef0967b 100644\n--- a/src/liblsquic/lsquic_cubic.h\n+++ b/src/liblsquic/lsquic_cubic.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_cubic.h -- CUBIC congestion control protocol.\n  */\ndiff --git a/src/liblsquic/lsquic_data_in_if.h b/src/liblsquic/lsquic_data_in_if.h\nindex 6deb8e006..b31161c50 100644\n--- a/src/liblsquic/lsquic_data_in_if.h\n+++ b/src/liblsquic/lsquic_data_in_if.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_data_in_if.h -- DATA in interface\n  */\ndiff --git a/src/liblsquic/lsquic_di_error.c b/src/liblsquic/lsquic_di_error.c\nindex 1bc901852..755eea139 100644\n--- a/src/liblsquic/lsquic_di_error.c\n+++ b/src/liblsquic/lsquic_di_error.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_di_error.c -- A placeholder when things go wrong\n  *\ndiff --git a/src/liblsquic/lsquic_di_hash.c b/src/liblsquic/lsquic_di_hash.c\nindex c889ffd38..900ab5817 100644\n--- a/src/liblsquic/lsquic_di_hash.c\n+++ b/src/liblsquic/lsquic_di_hash.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_di_hash.c -- Copy incoming data into a hash\n  *\ndiff --git a/src/liblsquic/lsquic_di_nocopy.c b/src/liblsquic/lsquic_di_nocopy.c\nindex 0fe8b4bb3..a9de76622 100644\n--- a/src/liblsquic/lsquic_di_nocopy.c\n+++ b/src/liblsquic/lsquic_di_nocopy.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_di_nocopy.c -- The \"no-copy\" data in stream.\n  *\ndiff --git a/src/liblsquic/lsquic_enc_sess.h b/src/liblsquic/lsquic_enc_sess.h\nindex 3e784e812..f45c15f7d 100644\n--- a/src/liblsquic/lsquic_enc_sess.h\n+++ b/src/liblsquic/lsquic_enc_sess.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef LSQUIC_ENC_SESS_H\n #define LSQUIC_ENC_SESS_H 1\n \ndiff --git a/src/liblsquic/lsquic_enc_sess_common.c b/src/liblsquic/lsquic_enc_sess_common.c\nindex 2270b49c3..69b2c443b 100644\n--- a/src/liblsquic/lsquic_enc_sess_common.c\n+++ b/src/liblsquic/lsquic_enc_sess_common.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <stddef.h>\n #include <stdint.h>\n #include <string.h>\ndiff --git a/src/liblsquic/lsquic_enc_sess_ietf.c b/src/liblsquic/lsquic_enc_sess_ietf.c\nindex 115cd9f0f..726f96c78 100644\n--- a/src/liblsquic/lsquic_enc_sess_ietf.c\n+++ b/src/liblsquic/lsquic_enc_sess_ietf.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_enc_sess_ietf.c -- Crypto session for IETF QUIC\n  */\ndiff --git a/src/liblsquic/lsquic_eng_hist.c b/src/liblsquic/lsquic_eng_hist.c\nindex 783bd9fd0..d8abf7f53 100644\n--- a/src/liblsquic/lsquic_eng_hist.c\n+++ b/src/liblsquic/lsquic_eng_hist.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <time.h>\n #ifdef WIN32\n #include <vc_compat.h>\ndiff --git a/src/liblsquic/lsquic_eng_hist.h b/src/liblsquic/lsquic_eng_hist.h\nindex 4bd6ddbbc..df14504e5 100644\n--- a/src/liblsquic/lsquic_eng_hist.h\n+++ b/src/liblsquic/lsquic_eng_hist.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_eng_hist.h - Engine history.\n  *\ndiff --git a/src/liblsquic/lsquic_engine.c b/src/liblsquic/lsquic_engine.c\nindex c3dcff5a1..0202e7455 100644\n--- a/src/liblsquic/lsquic_engine.c\n+++ b/src/liblsquic/lsquic_engine.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_engine.c - QUIC engine\n  */\ndiff --git a/src/liblsquic/lsquic_engine_public.h b/src/liblsquic/lsquic_engine_public.h\nindex ff5f2b495..88aa8432c 100644\n--- a/src/liblsquic/lsquic_engine_public.h\n+++ b/src/liblsquic/lsquic_engine_public.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_engine_public.h -- Engine's \"public interface\"\n  *\ndiff --git a/src/liblsquic/lsquic_ev_log.c b/src/liblsquic/lsquic_ev_log.c\nindex 69573ef2e..cd9e48d41 100644\n--- a/src/liblsquic/lsquic_ev_log.c\n+++ b/src/liblsquic/lsquic_ev_log.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef WIN32\n #include <arpa/inet.h>\n #else\ndiff --git a/src/liblsquic/lsquic_ev_log.h b/src/liblsquic/lsquic_ev_log.h\nindex c32bcd072..5e4a9f4e5 100644\n--- a/src/liblsquic/lsquic_ev_log.h\n+++ b/src/liblsquic/lsquic_ev_log.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_ev_log.h -- Event logger\n  */\ndiff --git a/src/liblsquic/lsquic_frab_list.c b/src/liblsquic/lsquic_frab_list.c\nindex 6da9cf12c..8083c3299 100644\n--- a/src/liblsquic/lsquic_frab_list.c\n+++ b/src/liblsquic/lsquic_frab_list.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_frab_list.c -- List of buffer for simple reading and writing\n  */\ndiff --git a/src/liblsquic/lsquic_frab_list.h b/src/liblsquic/lsquic_frab_list.h\nindex 2691c5f6f..23dc3cf8e 100644\n--- a/src/liblsquic/lsquic_frab_list.h\n+++ b/src/liblsquic/lsquic_frab_list.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_frab_list.h -- List of buffer for simple reading and writing\n  *\ndiff --git a/src/liblsquic/lsquic_frame_common.c b/src/liblsquic/lsquic_frame_common.c\nindex 01ba74ae4..26907b702 100644\n--- a/src/liblsquic/lsquic_frame_common.c\n+++ b/src/liblsquic/lsquic_frame_common.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <stdint.h>\n \n #include \"lsquic_frame_common.h\"\ndiff --git a/src/liblsquic/lsquic_frame_common.h b/src/liblsquic/lsquic_frame_common.h\nindex b3d10740a..a41bbf47e 100644\n--- a/src/liblsquic/lsquic_frame_common.h\n+++ b/src/liblsquic/lsquic_frame_common.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_frame_common.h\n  */\ndiff --git a/src/liblsquic/lsquic_frame_reader.c b/src/liblsquic/lsquic_frame_reader.c\nindex 15d3bf964..771f92264 100644\n--- a/src/liblsquic/lsquic_frame_reader.c\n+++ b/src/liblsquic/lsquic_frame_reader.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_frame_reader.c -- Read HTTP frames from stream\n  */\ndiff --git a/src/liblsquic/lsquic_frame_reader.h b/src/liblsquic/lsquic_frame_reader.h\nindex 0559ab989..1a55d043f 100644\n--- a/src/liblsquic/lsquic_frame_reader.h\n+++ b/src/liblsquic/lsquic_frame_reader.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_frame_reader.h -- Read HTTP frames from stream\n  */\ndiff --git a/src/liblsquic/lsquic_frame_writer.c b/src/liblsquic/lsquic_frame_writer.c\nindex 8332437bd..ae1919dd5 100644\n--- a/src/liblsquic/lsquic_frame_writer.c\n+++ b/src/liblsquic/lsquic_frame_writer.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_frame_writer.c -- write frames to HEADERS stream.\n  *\ndiff --git a/src/liblsquic/lsquic_frame_writer.h b/src/liblsquic/lsquic_frame_writer.h\nindex d087912be..ae7a3c298 100644\n--- a/src/liblsquic/lsquic_frame_writer.h\n+++ b/src/liblsquic/lsquic_frame_writer.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_frame_writer.h -- write frames to HEADERS stream.\n  */\ndiff --git a/src/liblsquic/lsquic_full_conn.c b/src/liblsquic/lsquic_full_conn.c\nindex 26b9ad89f..81632dd1a 100644\n--- a/src/liblsquic/lsquic_full_conn.c\n+++ b/src/liblsquic/lsquic_full_conn.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_full_conn.c -- A \"full\" connection object has full functionality\n  */\ndiff --git a/src/liblsquic/lsquic_full_conn.h b/src/liblsquic/lsquic_full_conn.h\nindex 78cd3d090..f2e514e98 100644\n--- a/src/liblsquic/lsquic_full_conn.h\n+++ b/src/liblsquic/lsquic_full_conn.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef LSQUIC_FULL_CONN_H\n #define LSQUIC_FULL_CONN_H\n \ndiff --git a/src/liblsquic/lsquic_full_conn_ietf.c b/src/liblsquic/lsquic_full_conn_ietf.c\nindex 15231b953..5af1642c6 100644\n--- a/src/liblsquic/lsquic_full_conn_ietf.c\n+++ b/src/liblsquic/lsquic_full_conn_ietf.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_full_conn_ietf.c -- IETF QUIC connection.\n  */\ndiff --git a/src/liblsquic/lsquic_global.c b/src/liblsquic/lsquic_global.c\nindex c16da90b9..9556842c2 100644\n--- a/src/liblsquic/lsquic_global.c\n+++ b/src/liblsquic/lsquic_global.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * Global state\n  */\ndiff --git a/src/liblsquic/lsquic_handshake.c b/src/liblsquic/lsquic_handshake.c\nindex 429814114..d292f72d0 100644\n--- a/src/liblsquic/lsquic_handshake.c\n+++ b/src/liblsquic/lsquic_handshake.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #define _GNU_SOURCE         /* for memmem */\n \n #include <assert.h>\ndiff --git a/src/liblsquic/lsquic_handshake.h b/src/liblsquic/lsquic_handshake.h\nindex d16fedac9..323c93945 100644\n--- a/src/liblsquic/lsquic_handshake.h\n+++ b/src/liblsquic/lsquic_handshake.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef LSQUIC_HANDSHAKE_H\n #define LSQUIC_HANDSHAKE_H 1\n \ndiff --git a/src/liblsquic/lsquic_hash.c b/src/liblsquic/lsquic_hash.c\nindex 7ac07b340..1ca16121d 100644\n--- a/src/liblsquic/lsquic_hash.c\n+++ b/src/liblsquic/lsquic_hash.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_hash.c\n  */\ndiff --git a/src/liblsquic/lsquic_hash.h b/src/liblsquic/lsquic_hash.h\nindex 9fb99e8b0..ccc7c1846 100644\n--- a/src/liblsquic/lsquic_hash.h\n+++ b/src/liblsquic/lsquic_hash.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_hash.c -- A generic hash\n  */\ndiff --git a/src/liblsquic/lsquic_hcsi_reader.c b/src/liblsquic/lsquic_hcsi_reader.c\nindex 8b365b636..f50ac675d 100644\n--- a/src/liblsquic/lsquic_hcsi_reader.c\n+++ b/src/liblsquic/lsquic_hcsi_reader.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <inttypes.h>\n #include <stddef.h>\ndiff --git a/src/liblsquic/lsquic_hcsi_reader.h b/src/liblsquic/lsquic_hcsi_reader.h\nindex 75a91ea5d..62609fb37 100644\n--- a/src/liblsquic/lsquic_hcsi_reader.h\n+++ b/src/liblsquic/lsquic_hcsi_reader.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_hcsi_reader.h -- HTTP Control Stream Incoming (HCSI) reader\n  */\ndiff --git a/src/liblsquic/lsquic_hcso_writer.c b/src/liblsquic/lsquic_hcso_writer.c\nindex efc968249..d1576714e 100644\n--- a/src/liblsquic/lsquic_hcso_writer.c\n+++ b/src/liblsquic/lsquic_hcso_writer.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_hcso_writer.c - write to outgoing HTTP Control Stream\n  */\ndiff --git a/src/liblsquic/lsquic_hcso_writer.h b/src/liblsquic/lsquic_hcso_writer.h\nindex 8809e4443..115e300eb 100644\n--- a/src/liblsquic/lsquic_hcso_writer.h\n+++ b/src/liblsquic/lsquic_hcso_writer.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_hcso_writer.h\n  */\ndiff --git a/src/liblsquic/lsquic_headers.h b/src/liblsquic/lsquic_headers.h\nindex a8fe33aa2..8a9d5a9fe 100644\n--- a/src/liblsquic/lsquic_headers.h\n+++ b/src/liblsquic/lsquic_headers.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef LSQUIC_HEADERS_H\n #define LSQUIC_HEADERS_H 1\n \ndiff --git a/src/liblsquic/lsquic_headers_stream.c b/src/liblsquic/lsquic_headers_stream.c\nindex c69feda76..dadd19793 100644\n--- a/src/liblsquic/lsquic_headers_stream.c\n+++ b/src/liblsquic/lsquic_headers_stream.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * HEADERS stream logic\n  */\ndiff --git a/src/liblsquic/lsquic_headers_stream.h b/src/liblsquic/lsquic_headers_stream.h\nindex fcf309a1f..b0895c527 100644\n--- a/src/liblsquic/lsquic_headers_stream.h\n+++ b/src/liblsquic/lsquic_headers_stream.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_headers_stream.h -- HEADERS stream interface\n  */\ndiff --git a/src/liblsquic/lsquic_hkdf.c b/src/liblsquic/lsquic_hkdf.c\nindex ba48d568a..0928bf30e 100644\n--- a/src/liblsquic/lsquic_hkdf.c\n+++ b/src/liblsquic/lsquic_hkdf.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stddef.h>\n #include <string.h>\ndiff --git a/src/liblsquic/lsquic_hkdf.h b/src/liblsquic/lsquic_hkdf.h\nindex 93b344b0a..97b0d36e2 100644\n--- a/src/liblsquic/lsquic_hkdf.h\n+++ b/src/liblsquic/lsquic_hkdf.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef LSQUIC_HKDF_H\n #define LSQUIC_HKDF_H 1\n \ndiff --git a/src/liblsquic/lsquic_hpi.c b/src/liblsquic/lsquic_hpi.c\nindex 1c78268e5..5ab96690e 100644\n--- a/src/liblsquic/lsquic_hpi.c\n+++ b/src/liblsquic/lsquic_hpi.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_hpi.c - implementation of (Extensible) HTTP Priority Iterator.\n  */\ndiff --git a/src/liblsquic/lsquic_hpi.h b/src/liblsquic/lsquic_hpi.h\nindex 45bc44b3a..d4a3fff7f 100644\n--- a/src/liblsquic/lsquic_hpi.h\n+++ b/src/liblsquic/lsquic_hpi.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_hpi.h - HPI: (Extensible) HTTP Priority Iterator\n  *\ndiff --git a/src/liblsquic/lsquic_hq.h b/src/liblsquic/lsquic_hq.h\nindex d972e780d..062dfa730 100644\n--- a/src/liblsquic/lsquic_hq.h\n+++ b/src/liblsquic/lsquic_hq.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_hq.h -- HTTP/3 (originally \"HTTP over QUIC\" or HQ) types\n  */\ndiff --git a/src/liblsquic/lsquic_hspack_valid.c b/src/liblsquic/lsquic_hspack_valid.c\nindex 30d7792a5..a30b3e666 100644\n--- a/src/liblsquic/lsquic_hspack_valid.c\n+++ b/src/liblsquic/lsquic_hspack_valid.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_hspack_valid.c -- Handshake packet validator.\n  *\ndiff --git a/src/liblsquic/lsquic_http.c b/src/liblsquic/lsquic_http.c\nindex af07512e2..dd2402adf 100644\n--- a/src/liblsquic/lsquic_http.c\n+++ b/src/liblsquic/lsquic_http.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /* Various HTTP-related functions. */\n \n #include <stddef.h>\ndiff --git a/src/liblsquic/lsquic_http1x_if.c b/src/liblsquic/lsquic_http1x_if.c\nindex b8fd90704..8710017a8 100644\n--- a/src/liblsquic/lsquic_http1x_if.c\n+++ b/src/liblsquic/lsquic_http1x_if.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <ctype.h>\n #include <stddef.h>\ndiff --git a/src/liblsquic/lsquic_http1x_if.h b/src/liblsquic/lsquic_http1x_if.h\nindex 5edd6fd31..1ba771b1d 100644\n--- a/src/liblsquic/lsquic_http1x_if.h\n+++ b/src/liblsquic/lsquic_http1x_if.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef LSQUIC_HTTP1X_IF_H\n #define LSQUIC_HTTP1X_IF_H 1\n \ndiff --git a/src/liblsquic/lsquic_ietf.h b/src/liblsquic/lsquic_ietf.h\nindex 0f7ed2f01..0c83061c6 100644\n--- a/src/liblsquic/lsquic_ietf.h\n+++ b/src/liblsquic/lsquic_ietf.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef LSQUIC_IETF_H\n #define LSQUIC_IETF_H 1\n \ndiff --git a/src/liblsquic/lsquic_int_types.h b/src/liblsquic/lsquic_int_types.h\nindex 9b48d1a3b..dd7d67b78 100644\n--- a/src/liblsquic/lsquic_int_types.h\n+++ b/src/liblsquic/lsquic_int_types.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef LSQUIC_INT_TYPES_H\n #define LSQUIC_INT_TYPES_H 1\n \ndiff --git a/src/liblsquic/lsquic_logger.c b/src/liblsquic/lsquic_logger.c\nindex 785bccdcf..07edb5ab9 100644\n--- a/src/liblsquic/lsquic_logger.c\n+++ b/src/liblsquic/lsquic_logger.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * LSQUIC Logger implementation.\n  */\ndiff --git a/src/liblsquic/lsquic_logger.h b/src/liblsquic/lsquic_logger.h\nindex 1d0d393b8..2d84eba89 100644\n--- a/src/liblsquic/lsquic_logger.h\n+++ b/src/liblsquic/lsquic_logger.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_logger.h -- logging functions and macros.\n  *\ndiff --git a/src/liblsquic/lsquic_malo.c b/src/liblsquic/lsquic_malo.c\nindex 45e72aacf..f14dbd525 100644\n--- a/src/liblsquic/lsquic_malo.c\n+++ b/src/liblsquic/lsquic_malo.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_malo.c -- malo allocator implementation.\n  *\ndiff --git a/src/liblsquic/lsquic_malo.h b/src/liblsquic/lsquic_malo.h\nindex 270bca383..9f701d368 100644\n--- a/src/liblsquic/lsquic_malo.h\n+++ b/src/liblsquic/lsquic_malo.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_malo.h -- Fast allocator for fixed-sized objects.\n  */\ndiff --git a/src/liblsquic/lsquic_min_heap.c b/src/liblsquic/lsquic_min_heap.c\nindex 4935756d5..818f1cb88 100644\n--- a/src/liblsquic/lsquic_min_heap.c\n+++ b/src/liblsquic/lsquic_min_heap.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_min_heap.c\n  */\ndiff --git a/src/liblsquic/lsquic_min_heap.h b/src/liblsquic/lsquic_min_heap.h\nindex 35ada4a87..b45fca02a 100644\n--- a/src/liblsquic/lsquic_min_heap.h\n+++ b/src/liblsquic/lsquic_min_heap.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_min_heap.h -- Min-heap for pointers\n  */\ndiff --git a/src/liblsquic/lsquic_mini_conn.c b/src/liblsquic/lsquic_mini_conn.c\nindex 94cda81eb..d7aa161f7 100644\n--- a/src/liblsquic/lsquic_mini_conn.c\n+++ b/src/liblsquic/lsquic_mini_conn.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_mini_conn.c -- Mini connection.\n  *\ndiff --git a/src/liblsquic/lsquic_mini_conn.h b/src/liblsquic/lsquic_mini_conn.h\nindex ddff7755f..80334add1 100644\n--- a/src/liblsquic/lsquic_mini_conn.h\n+++ b/src/liblsquic/lsquic_mini_conn.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_mini_conn.h -- Mini-connection\n  *\ndiff --git a/src/liblsquic/lsquic_mini_conn_ietf.c b/src/liblsquic/lsquic_mini_conn_ietf.c\nindex 5e6c26c79..f2ed267ab 100644\n--- a/src/liblsquic/lsquic_mini_conn_ietf.c\n+++ b/src/liblsquic/lsquic_mini_conn_ietf.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_mini_conn_ietf.c -- Mini connection used by the IETF QUIC\n  */\ndiff --git a/src/liblsquic/lsquic_mini_conn_ietf.h b/src/liblsquic/lsquic_mini_conn_ietf.h\nindex 2347bf363..9d0eec406 100644\n--- a/src/liblsquic/lsquic_mini_conn_ietf.h\n+++ b/src/liblsquic/lsquic_mini_conn_ietf.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_mini_conn_ietf.h -- Mini connection used by the IETF QUIC\n  */\ndiff --git a/src/liblsquic/lsquic_minmax.c b/src/liblsquic/lsquic_minmax.c\nindex 4eb5f0f9f..d6a184974 100644\n--- a/src/liblsquic/lsquic_minmax.c\n+++ b/src/liblsquic/lsquic_minmax.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * Based on Google code released under BSD license here:\n  *  https://groups.google.com/forum/#!topic/bbr-dev/3RTgkzi5ZD8\ndiff --git a/src/liblsquic/lsquic_minmax.h b/src/liblsquic/lsquic_minmax.h\nindex cf1420fe0..ad1ed9151 100644\n--- a/src/liblsquic/lsquic_minmax.h\n+++ b/src/liblsquic/lsquic_minmax.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef LSQUIC_MINMAX_H\n #define LSQUIC_MINMAX_H\n \ndiff --git a/src/liblsquic/lsquic_mm.c b/src/liblsquic/lsquic_mm.c\nindex 3e2141e6f..3315ebb0a 100644\n--- a/src/liblsquic/lsquic_mm.c\n+++ b/src/liblsquic/lsquic_mm.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_mm.c -- Memory manager.\n  */\ndiff --git a/src/liblsquic/lsquic_mm.h b/src/liblsquic/lsquic_mm.h\nindex 9575998d3..01c1fbb0d 100644\n--- a/src/liblsquic/lsquic_mm.h\n+++ b/src/liblsquic/lsquic_mm.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_mm.h -- Memory manager.\n  *\ndiff --git a/src/liblsquic/lsquic_pacer.c b/src/liblsquic/lsquic_pacer.c\nindex af188caa6..22842c56e 100644\n--- a/src/liblsquic/lsquic_pacer.c\n+++ b/src/liblsquic/lsquic_pacer.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <inttypes.h>\n #include <stdint.h>\ndiff --git a/src/liblsquic/lsquic_pacer.h b/src/liblsquic/lsquic_pacer.h\nindex 131d94db6..883c2a697 100644\n--- a/src/liblsquic/lsquic_pacer.h\n+++ b/src/liblsquic/lsquic_pacer.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef LSQUIC_PACER_H\n #define LSQUIC_PACER_H 1\n \ndiff --git a/src/liblsquic/lsquic_packet_common.c b/src/liblsquic/lsquic_packet_common.c\nindex ae959ba58..de55ead69 100644\n--- a/src/liblsquic/lsquic_packet_common.c\n+++ b/src/liblsquic/lsquic_packet_common.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_packet_common.c -- some common packet-related routines\n  */\ndiff --git a/src/liblsquic/lsquic_packet_common.h b/src/liblsquic/lsquic_packet_common.h\nindex 886ef467f..e4f0e85ee 100644\n--- a/src/liblsquic/lsquic_packet_common.h\n+++ b/src/liblsquic/lsquic_packet_common.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef LSQUIC_PACKET_COMMON_H\n #define LSQUIC_PACKET_COMMON_H 1\n \ndiff --git a/src/liblsquic/lsquic_packet_gquic.c b/src/liblsquic/lsquic_packet_gquic.c\nindex 016170727..21a9c4b7e 100644\n--- a/src/liblsquic/lsquic_packet_gquic.c\n+++ b/src/liblsquic/lsquic_packet_gquic.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <stdint.h>\n #include <stdlib.h>\n \ndiff --git a/src/liblsquic/lsquic_packet_gquic.h b/src/liblsquic/lsquic_packet_gquic.h\nindex e430b9935..5628c3487 100644\n--- a/src/liblsquic/lsquic_packet_gquic.h\n+++ b/src/liblsquic/lsquic_packet_gquic.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef LSQUIC_PACKET_GQUIC_H\n #define LSQUIC_PACKET_GQUIC_H 1\n \ndiff --git a/src/liblsquic/lsquic_packet_ietf.h b/src/liblsquic/lsquic_packet_ietf.h\nindex 35c4a601d..d8014cc6d 100644\n--- a/src/liblsquic/lsquic_packet_ietf.h\n+++ b/src/liblsquic/lsquic_packet_ietf.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef LSQUIC_PACKET_IETF_H\n #define LSQUIC_PACKET_IETF_H 1\n \ndiff --git a/src/liblsquic/lsquic_packet_in.c b/src/liblsquic/lsquic_packet_in.c\nindex 83d9731c7..3bc73a62c 100644\n--- a/src/liblsquic/lsquic_packet_in.c\n+++ b/src/liblsquic/lsquic_packet_in.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdint.h>\n #include <string.h>\ndiff --git a/src/liblsquic/lsquic_packet_in.h b/src/liblsquic/lsquic_packet_in.h\nindex 1efc91828..4974497e6 100644\n--- a/src/liblsquic/lsquic_packet_in.h\n+++ b/src/liblsquic/lsquic_packet_in.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_packet_in.h\n  */\ndiff --git a/src/liblsquic/lsquic_packet_out.c b/src/liblsquic/lsquic_packet_out.c\nindex 271e3c8ec..241c7a271 100644\n--- a/src/liblsquic/lsquic_packet_out.c\n+++ b/src/liblsquic/lsquic_packet_out.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_packet_out.c\n  */\ndiff --git a/src/liblsquic/lsquic_packet_out.h b/src/liblsquic/lsquic_packet_out.h\nindex 5d8820f53..29c59dd1a 100644\n--- a/src/liblsquic/lsquic_packet_out.h\n+++ b/src/liblsquic/lsquic_packet_out.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_packet_out.h -- Structure and routines dealing with packet_out\n  */\ndiff --git a/src/liblsquic/lsquic_packet_resize.c b/src/liblsquic/lsquic_packet_resize.c\nindex 92d73880b..58ff02720 100644\n--- a/src/liblsquic/lsquic_packet_resize.c\n+++ b/src/liblsquic/lsquic_packet_resize.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /* Functions to resize packets */\n \n #include <assert.h>\ndiff --git a/src/liblsquic/lsquic_packet_resize.h b/src/liblsquic/lsquic_packet_resize.h\nindex 5510c8e22..bfb4c482a 100644\n--- a/src/liblsquic/lsquic_packet_resize.h\n+++ b/src/liblsquic/lsquic_packet_resize.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_packet_resize.h -- functions to resize packets\n  */\ndiff --git a/src/liblsquic/lsquic_parse.h b/src/liblsquic/lsquic_parse.h\nindex 0ddb7598d..4b7594d88 100644\n--- a/src/liblsquic/lsquic_parse.h\n+++ b/src/liblsquic/lsquic_parse.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef LSQUIC_PARSE_H\n #define LSQUIC_PARSE_H 1\n \ndiff --git a/src/liblsquic/lsquic_parse_Q046.c b/src/liblsquic/lsquic_parse_Q046.c\nindex ecb062dc0..c6fc7b801 100644\n--- a/src/liblsquic/lsquic_parse_Q046.c\n+++ b/src/liblsquic/lsquic_parse_Q046.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_parse_Q046.c -- Parsing functions specific to GQUIC Q046\n  */\ndiff --git a/src/liblsquic/lsquic_parse_Q050.c b/src/liblsquic/lsquic_parse_Q050.c\nindex 029a1f4a0..f61fb1680 100644\n--- a/src/liblsquic/lsquic_parse_Q050.c\n+++ b/src/liblsquic/lsquic_parse_Q050.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_parse_Q050.c -- Parsing functions specific to GQUIC Q050\n  */\ndiff --git a/src/liblsquic/lsquic_parse_common.c b/src/liblsquic/lsquic_parse_common.c\nindex ee7bcc5cb..ffb9282c6 100644\n--- a/src/liblsquic/lsquic_parse_common.c\n+++ b/src/liblsquic/lsquic_parse_common.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <string.h>\n #include <sys/queue.h>\ndiff --git a/src/liblsquic/lsquic_parse_common.h b/src/liblsquic/lsquic_parse_common.h\nindex f1d051d9c..ca9b08d2a 100644\n--- a/src/liblsquic/lsquic_parse_common.h\n+++ b/src/liblsquic/lsquic_parse_common.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_parse_common.h\n  */\ndiff --git a/src/liblsquic/lsquic_parse_gquic_be.c b/src/liblsquic/lsquic_parse_gquic_be.c\nindex f5f2f405b..dd4d3c143 100644\n--- a/src/liblsquic/lsquic_parse_gquic_be.c\n+++ b/src/liblsquic/lsquic_parse_gquic_be.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_parse_gquic_be.c -- Parsing functions specific to big-endian\n  *                              (now only Q043) GQUIC.\ndiff --git a/src/liblsquic/lsquic_parse_gquic_be.h b/src/liblsquic/lsquic_parse_gquic_be.h\nindex 4f8f0bd8c..5d3935958 100644\n--- a/src/liblsquic/lsquic_parse_gquic_be.h\n+++ b/src/liblsquic/lsquic_parse_gquic_be.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef LSQUIC_PARSE_GQUIC_BE_H\n #define LSQUIC_PARSE_GQUIC_BE_H\n \ndiff --git a/src/liblsquic/lsquic_parse_gquic_common.c b/src/liblsquic/lsquic_parse_gquic_common.c\nindex cfaecc88f..18bc46e8d 100644\n--- a/src/liblsquic/lsquic_parse_gquic_common.c\n+++ b/src/liblsquic/lsquic_parse_gquic_common.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_parse_gquic_common.c -- Parsing functions common to GQUIC\n  */\ndiff --git a/src/liblsquic/lsquic_parse_ietf.h b/src/liblsquic/lsquic_parse_ietf.h\nindex 6ec1664f2..91f855eda 100644\n--- a/src/liblsquic/lsquic_parse_ietf.h\n+++ b/src/liblsquic/lsquic_parse_ietf.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef LSQUIC_PARSE_IETF_H\n #define LSQUIC_PARSE_IETF_H 1\n \ndiff --git a/src/liblsquic/lsquic_parse_ietf_v1.c b/src/liblsquic/lsquic_parse_ietf_v1.c\nindex 7638028f7..d73502e3e 100644\n--- a/src/liblsquic/lsquic_parse_ietf_v1.c\n+++ b/src/liblsquic/lsquic_parse_ietf_v1.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_parse_ietf_v1.c -- Parsing functions specific to IETF QUIC v1\n  */\ndiff --git a/src/liblsquic/lsquic_parse_iquic_common.c b/src/liblsquic/lsquic_parse_iquic_common.c\nindex d4c1a6464..f5b6b3816 100644\n--- a/src/liblsquic/lsquic_parse_iquic_common.c\n+++ b/src/liblsquic/lsquic_parse_iquic_common.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * Parsing routines shared by all IETF QUIC versions.\n  */\ndiff --git a/src/liblsquic/lsquic_pr_queue.c b/src/liblsquic/lsquic_pr_queue.c\nindex e605c6774..82fb5b5b6 100644\n--- a/src/liblsquic/lsquic_pr_queue.c\n+++ b/src/liblsquic/lsquic_pr_queue.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_pr_queue.c -- packet request queue.\n  */\ndiff --git a/src/liblsquic/lsquic_pr_queue.h b/src/liblsquic/lsquic_pr_queue.h\nindex 439f4bd8a..e528fe99b 100644\n--- a/src/liblsquic/lsquic_pr_queue.h\n+++ b/src/liblsquic/lsquic_pr_queue.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_pr_queue.h -- a queue of packet requests\n  *\ndiff --git a/src/liblsquic/lsquic_purga.c b/src/liblsquic/lsquic_purga.c\nindex 817e354ca..e4007d2e9 100644\n--- a/src/liblsquic/lsquic_purga.c\n+++ b/src/liblsquic/lsquic_purga.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <errno.h>\n #include <inttypes.h>\n #include <stddef.h>\ndiff --git a/src/liblsquic/lsquic_purga.h b/src/liblsquic/lsquic_purga.h\nindex c28e06a29..152465d3a 100644\n--- a/src/liblsquic/lsquic_purga.h\n+++ b/src/liblsquic/lsquic_purga.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_purga.h -- Purgatory for CIDs\n  *\ndiff --git a/src/liblsquic/lsquic_push_promise.h b/src/liblsquic/lsquic_push_promise.h\nindex cf936d083..a6abdfa3a 100644\n--- a/src/liblsquic/lsquic_push_promise.h\n+++ b/src/liblsquic/lsquic_push_promise.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef LSQUIC_PUSH_PROMISE_H\n #define LSQUIC_PUSH_PROMISE_H 1\n \ndiff --git a/src/liblsquic/lsquic_qdec_hdl.c b/src/liblsquic/lsquic_qdec_hdl.c\nindex 73381a515..4a6c3abc7 100644\n--- a/src/liblsquic/lsquic_qdec_hdl.c\n+++ b/src/liblsquic/lsquic_qdec_hdl.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_qdec_hdl.c -- QPACK decoder streams handler\n  */\ndiff --git a/src/liblsquic/lsquic_qdec_hdl.h b/src/liblsquic/lsquic_qdec_hdl.h\nindex 8c349c6b8..f2c67297a 100644\n--- a/src/liblsquic/lsquic_qdec_hdl.h\n+++ b/src/liblsquic/lsquic_qdec_hdl.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_qdec_hdl.h -- QPACK decoder streams handler\n  *\ndiff --git a/src/liblsquic/lsquic_qenc_hdl.c b/src/liblsquic/lsquic_qenc_hdl.c\nindex 42a667533..8251ea8d5 100644\n--- a/src/liblsquic/lsquic_qenc_hdl.c\n+++ b/src/liblsquic/lsquic_qenc_hdl.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_qenc_hdl.c -- QPACK encoder streams handler\n  */\n@@ -34,6 +34,7 @@\n #define LSQUIC_LOG_CONN_ID lsquic_conn_log_cid(qeh->qeh_conn)\n #include \"lsquic_logger.h\"\n \n+#define QENC_MIN_DYN_TABLE_SIZE 32u\n \n static int\n qeh_write_type (struct qpack_enc_hdl *qeh)\n@@ -123,6 +124,8 @@ lsquic_qeh_settings (struct qpack_enc_hdl *qeh, unsigned max_table_size,\n     enc_opts = LSQPACK_ENC_OPT_STAGE_2\n              | (server ? LSQPACK_ENC_OPT_SERVER : 0);\n     qeh->qeh_tsu_sz = sizeof(qeh->qeh_tsu_buf);\n+    if (QENC_MIN_DYN_TABLE_SIZE > dyn_table_size)\n+        dyn_table_size = 0;\n     if (0 != lsqpack_enc_init(&qeh->qeh_encoder, (void *) qeh->qeh_conn,\n                 max_table_size, dyn_table_size, max_risked_streams, enc_opts,\n                 qeh->qeh_tsu_buf, &qeh->qeh_tsu_sz))\ndiff --git a/src/liblsquic/lsquic_qenc_hdl.h b/src/liblsquic/lsquic_qenc_hdl.h\nindex 37736dd87..8e0bba2a6 100644\n--- a/src/liblsquic/lsquic_qenc_hdl.h\n+++ b/src/liblsquic/lsquic_qenc_hdl.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_qenc_hdl.h -- QPACK encoder streams handler\n  *\ndiff --git a/src/liblsquic/lsquic_qlog.c b/src/liblsquic/lsquic_qlog.c\nindex 469aa516e..cde7b5309 100644\n--- a/src/liblsquic/lsquic_qlog.c\n+++ b/src/liblsquic/lsquic_qlog.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <stdlib.h>\n #include <stdio.h>\n #include <errno.h>\ndiff --git a/src/liblsquic/lsquic_qlog.h b/src/liblsquic/lsquic_qlog.h\nindex 61d2f71d2..60aacd43b 100644\n--- a/src/liblsquic/lsquic_qlog.h\n+++ b/src/liblsquic/lsquic_qlog.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_qlog.h -- QLOG Event logger\n  */\ndiff --git a/src/liblsquic/lsquic_qpack_dec_logger.h b/src/liblsquic/lsquic_qpack_dec_logger.h\nindex c9739d3eb..0add551fc 100644\n--- a/src/liblsquic/lsquic_qpack_dec_logger.h\n+++ b/src/liblsquic/lsquic_qpack_dec_logger.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /* This header file is included into lsqpack.c */\n \n #include \"lsquic.h\"\ndiff --git a/src/liblsquic/lsquic_qpack_enc_logger.h b/src/liblsquic/lsquic_qpack_enc_logger.h\nindex 9dbf85858..ff4d48eb2 100644\n--- a/src/liblsquic/lsquic_qpack_enc_logger.h\n+++ b/src/liblsquic/lsquic_qpack_enc_logger.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /* This header file is included into lsqpack.c */\n \n #include \"lsquic.h\"\ndiff --git a/src/liblsquic/lsquic_qpack_exp.c b/src/liblsquic/lsquic_qpack_exp.c\nindex f25dc71cd..fae37cc74 100644\n--- a/src/liblsquic/lsquic_qpack_exp.c\n+++ b/src/liblsquic/lsquic_qpack_exp.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <inttypes.h>\n #include <stdio.h>\n #include <stdlib.h>\ndiff --git a/src/liblsquic/lsquic_qpack_exp.h b/src/liblsquic/lsquic_qpack_exp.h\nindex 7f39708b5..235b61574 100644\n--- a/src/liblsquic/lsquic_qpack_exp.h\n+++ b/src/liblsquic/lsquic_qpack_exp.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /* QPACK Experiment record */\n \n #ifndef LSQUIC_QPACK_EXP_H\ndiff --git a/src/liblsquic/lsquic_qtags.h b/src/liblsquic/lsquic_qtags.h\nindex beade102b..9d3e02c40 100644\n--- a/src/liblsquic/lsquic_qtags.h\n+++ b/src/liblsquic/lsquic_qtags.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef LSQUIC_QTAGS_H\n #define LSQUIC_QTAGS_H 1\n \ndiff --git a/src/liblsquic/lsquic_rechist.c b/src/liblsquic/lsquic_rechist.c\nindex 98350efc4..3ec413011 100644\n--- a/src/liblsquic/lsquic_rechist.c\n+++ b/src/liblsquic/lsquic_rechist.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_rechist.c -- History of received packets.\n  */\ndiff --git a/src/liblsquic/lsquic_rechist.h b/src/liblsquic/lsquic_rechist.h\nindex 0f7894b98..8c4ea2821 100644\n--- a/src/liblsquic/lsquic_rechist.h\n+++ b/src/liblsquic/lsquic_rechist.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_rechist.h -- History of received packets.\n  *\ndiff --git a/src/liblsquic/lsquic_rtt.c b/src/liblsquic/lsquic_rtt.c\nindex 90edf2139..6cbba5bee 100644\n--- a/src/liblsquic/lsquic_rtt.c\n+++ b/src/liblsquic/lsquic_rtt.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_rtt.c -- RTT calculation\n  */\ndiff --git a/src/liblsquic/lsquic_rtt.h b/src/liblsquic/lsquic_rtt.h\nindex e31331d05..f9a3cd924 100644\n--- a/src/liblsquic/lsquic_rtt.h\n+++ b/src/liblsquic/lsquic_rtt.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_rtt.h -- RTT calculation\n  */\ndiff --git a/src/liblsquic/lsquic_send_ctl.c b/src/liblsquic/lsquic_send_ctl.c\nindex 1574ca495..70a291e14 100644\n--- a/src/liblsquic/lsquic_send_ctl.c\n+++ b/src/liblsquic/lsquic_send_ctl.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_send_ctl.c -- Logic for sending and sent packets\n  */\ndiff --git a/src/liblsquic/lsquic_send_ctl.h b/src/liblsquic/lsquic_send_ctl.h\nindex 565fd11b6..01156371b 100644\n--- a/src/liblsquic/lsquic_send_ctl.h\n+++ b/src/liblsquic/lsquic_send_ctl.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef LSQUIC_SEND_CTL_H\n #define LSQUIC_SEND_CTL_H 1\n \ndiff --git a/src/liblsquic/lsquic_senhist.c b/src/liblsquic/lsquic_senhist.c\nindex ca123af38..d63c2a4ce 100644\n--- a/src/liblsquic/lsquic_senhist.c\n+++ b/src/liblsquic/lsquic_senhist.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_senhist.c -- Sent history implementation\n  */\ndiff --git a/src/liblsquic/lsquic_senhist.h b/src/liblsquic/lsquic_senhist.h\nindex 8120c8c90..5d451d1f9 100644\n--- a/src/liblsquic/lsquic_senhist.h\n+++ b/src/liblsquic/lsquic_senhist.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_senhist.h -- History sent packets.\n  *\ndiff --git a/src/liblsquic/lsquic_set.c b/src/liblsquic/lsquic_set.c\nindex 66d97d3f6..143332444 100644\n--- a/src/liblsquic/lsquic_set.c\n+++ b/src/liblsquic/lsquic_set.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_set.c -- A set implementation.\n  *\ndiff --git a/src/liblsquic/lsquic_set.h b/src/liblsquic/lsquic_set.h\nindex 09e6989fb..f910bbadc 100644\n--- a/src/liblsquic/lsquic_set.h\n+++ b/src/liblsquic/lsquic_set.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_set.h -- A set implementation.\n  *\ndiff --git a/src/liblsquic/lsquic_sfcw.c b/src/liblsquic/lsquic_sfcw.c\nindex 1b14be3b2..d8e88166c 100644\n--- a/src/liblsquic/lsquic_sfcw.c\n+++ b/src/liblsquic/lsquic_sfcw.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <inttypes.h>\n #include <stdint.h>\n #include <stdlib.h>\ndiff --git a/src/liblsquic/lsquic_sfcw.h b/src/liblsquic/lsquic_sfcw.h\nindex a20691035..795cdc380 100644\n--- a/src/liblsquic/lsquic_sfcw.h\n+++ b/src/liblsquic/lsquic_sfcw.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_sfcw.h -- Stream flow control window functions\n  */\ndiff --git a/src/liblsquic/lsquic_shsk_stream.c b/src/liblsquic/lsquic_shsk_stream.c\nindex b71709769..f87001f7d 100644\n--- a/src/liblsquic/lsquic_shsk_stream.c\n+++ b/src/liblsquic/lsquic_shsk_stream.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * Stream/crypto handshake adapter for the server side.  Since on the server\n  * side, the handshake logic is handled in mini conn, this adapter does not\ndiff --git a/src/liblsquic/lsquic_shsk_stream.h b/src/liblsquic/lsquic_shsk_stream.h\nindex edc230c4f..86d0a021a 100644\n--- a/src/liblsquic/lsquic_shsk_stream.h\n+++ b/src/liblsquic/lsquic_shsk_stream.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * Stream/crypto handshake adapter for the server side.  See implementation\n  * for more comments and explanation.\ndiff --git a/src/liblsquic/lsquic_sizes.h b/src/liblsquic/lsquic_sizes.h\nindex 2d92ad422..2e4313e9c 100644\n--- a/src/liblsquic/lsquic_sizes.h\n+++ b/src/liblsquic/lsquic_sizes.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef LSQUIC_SIZES_H\n #define LSQUIC_SIZES_H 1\n \ndiff --git a/src/liblsquic/lsquic_spi.c b/src/liblsquic/lsquic_spi.c\nindex 47e81a908..b8dfde431 100644\n--- a/src/liblsquic/lsquic_spi.c\n+++ b/src/liblsquic/lsquic_spi.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_spi.c - implementation of Stream Priority Iterator.\n  */\ndiff --git a/src/liblsquic/lsquic_spi.h b/src/liblsquic/lsquic_spi.h\nindex e1ff6f5eb..450e1a278 100644\n--- a/src/liblsquic/lsquic_spi.h\n+++ b/src/liblsquic/lsquic_spi.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_spi.h - SPI: Stream Priority Iterator\n  *\ndiff --git a/src/liblsquic/lsquic_stock_shi.c b/src/liblsquic/lsquic_stock_shi.c\nindex 5a45582dd..eca31f5aa 100644\n--- a/src/liblsquic/lsquic_stock_shi.c\n+++ b/src/liblsquic/lsquic_stock_shi.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_stock_shi.c\n  */\ndiff --git a/src/liblsquic/lsquic_stock_shi.h b/src/liblsquic/lsquic_stock_shi.h\nindex 4f62e4248..49d240bb3 100644\n--- a/src/liblsquic/lsquic_stock_shi.h\n+++ b/src/liblsquic/lsquic_stock_shi.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_stock_shi.h - Stock shared hash interface implementation.\n  */\ndiff --git a/src/liblsquic/lsquic_str.c b/src/liblsquic/lsquic_str.c\nindex e0f3ea052..371c37789 100644\n--- a/src/liblsquic/lsquic_str.c\n+++ b/src/liblsquic/lsquic_str.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_str.c\n  *\ndiff --git a/src/liblsquic/lsquic_str.h b/src/liblsquic/lsquic_str.h\nindex 1eb7e2bbc..eb0f0cc4a 100644\n--- a/src/liblsquic/lsquic_str.h\n+++ b/src/liblsquic/lsquic_str.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_str.h -- Some string routines.\n  */\ndiff --git a/src/liblsquic/lsquic_stream.c b/src/liblsquic/lsquic_stream.c\nindex 906497d57..accb30473 100644\n--- a/src/liblsquic/lsquic_stream.c\n+++ b/src/liblsquic/lsquic_stream.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_stream.c -- stream processing\n  */\ndiff --git a/src/liblsquic/lsquic_stream.h b/src/liblsquic/lsquic_stream.h\nindex cbbc0d4f3..5058ea9cc 100644\n--- a/src/liblsquic/lsquic_stream.h\n+++ b/src/liblsquic/lsquic_stream.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef LSQUIC_STREAM_H\n #define LSQUIC_STREAM_H\n \ndiff --git a/src/liblsquic/lsquic_tokgen.c b/src/liblsquic/lsquic_tokgen.c\nindex 01fee268d..28dc214b8 100644\n--- a/src/liblsquic/lsquic_tokgen.c\n+++ b/src/liblsquic/lsquic_tokgen.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stddef.h>\n #include <stdlib.h>\ndiff --git a/src/liblsquic/lsquic_tokgen.h b/src/liblsquic/lsquic_tokgen.h\nindex c7501206e..b405a49f8 100644\n--- a/src/liblsquic/lsquic_tokgen.h\n+++ b/src/liblsquic/lsquic_tokgen.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef LSQUIC_TOKEN_H\n #define LSQUIC_TOKEN_H 1\n \ndiff --git a/src/liblsquic/lsquic_trans_params.c b/src/liblsquic/lsquic_trans_params.c\nindex bf6b468d8..188d54c1d 100644\n--- a/src/liblsquic/lsquic_trans_params.c\n+++ b/src/liblsquic/lsquic_trans_params.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_trans_params.c\n  */\ndiff --git a/src/liblsquic/lsquic_trans_params.h b/src/liblsquic/lsquic_trans_params.h\nindex 22d101b67..edf2df4a1 100644\n--- a/src/liblsquic/lsquic_trans_params.h\n+++ b/src/liblsquic/lsquic_trans_params.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_trans_params.h -- Transport parameters types and functions.\n  */\ndiff --git a/src/liblsquic/lsquic_trechist.c b/src/liblsquic/lsquic_trechist.c\nindex c7cefe37c..bb6d4adba 100644\n--- a/src/liblsquic/lsquic_trechist.c\n+++ b/src/liblsquic/lsquic_trechist.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <limits.h>\n #include <stddef.h>\ndiff --git a/src/liblsquic/lsquic_trechist.h b/src/liblsquic/lsquic_trechist.h\nindex 5c3bcd3bf..6b69e0efd 100644\n--- a/src/liblsquic/lsquic_trechist.h\n+++ b/src/liblsquic/lsquic_trechist.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * Tiny receive history.  It is used in IETF mini connection, where we want\n  * to use as little memory as possible.  This data structure is an array of\ndiff --git a/src/liblsquic/lsquic_util.c b/src/liblsquic/lsquic_util.c\nindex 7b2ba211b..e377cc8f9 100644\n--- a/src/liblsquic/lsquic_util.c\n+++ b/src/liblsquic/lsquic_util.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * Utility functions\n  */\ndiff --git a/src/liblsquic/lsquic_util.h b/src/liblsquic/lsquic_util.h\nindex e2c22a113..8989f9f84 100644\n--- a/src/liblsquic/lsquic_util.h\n+++ b/src/liblsquic/lsquic_util.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_util.h -- Utility functions\n  */\ndiff --git a/src/liblsquic/lsquic_varint.c b/src/liblsquic/lsquic_varint.c\nindex 237ad3e32..fd9c1ca01 100644\n--- a/src/liblsquic/lsquic_varint.c\n+++ b/src/liblsquic/lsquic_varint.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_varint.c -- routines dealing with IETF QUIC varint.\n  */\ndiff --git a/src/liblsquic/lsquic_varint.h b/src/liblsquic/lsquic_varint.h\nindex 50a7bd3f1..e7f44bdb1 100644\n--- a/src/liblsquic/lsquic_varint.h\n+++ b/src/liblsquic/lsquic_varint.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef LSQUIC_VARINT_H\n #define LSQUIC_VARINT_H 1\n \ndiff --git a/src/liblsquic/lsquic_ver_neg.h b/src/liblsquic/lsquic_ver_neg.h\nindex a52c09859..63fafb46d 100644\n--- a/src/liblsquic/lsquic_ver_neg.h\n+++ b/src/liblsquic/lsquic_ver_neg.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #ifndef LSQUIC_VER_NEG_H\n #define LSQUIC_VER_NEG_H\n \ndiff --git a/src/liblsquic/lsquic_version.c b/src/liblsquic/lsquic_version.c\nindex ac2bb1acf..25d477e24 100644\n--- a/src/liblsquic/lsquic_version.c\n+++ b/src/liblsquic/lsquic_version.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <string.h>\n \n #include \"lsquic.h\"\ndiff --git a/src/liblsquic/lsquic_version.h b/src/liblsquic/lsquic_version.h\nindex 46cf26085..2c047a5a9 100644\n--- a/src/liblsquic/lsquic_version.h\n+++ b/src/liblsquic/lsquic_version.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * lsquic_version.h -- version manipulation routines\n  */\ndiff --git a/src/liblsquic/lsquic_xxhash.c b/src/liblsquic/lsquic_xxhash.c\nindex fc50769b9..38568821b 100644\n--- a/src/liblsquic/lsquic_xxhash.c\n+++ b/src/liblsquic/lsquic_xxhash.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n xxHash - Fast Hash algorithm\n Copyright (C) 2012-2014, Yann Collet.\ndiff --git a/src/liblsquic/lsquic_xxhash.h b/src/liblsquic/lsquic_xxhash.h\nindex 4a92f415f..d89bf4d7c 100644\n--- a/src/liblsquic/lsquic_xxhash.h\n+++ b/src/liblsquic/lsquic_xxhash.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n    xxHash - Extremely Fast Hash algorithm\n    Header File\ndiff --git a/tests/CMakeLists.txt b/tests/CMakeLists.txt\nindex 7aee69b62..fab22d334 100644\n--- a/tests/CMakeLists.txt\n+++ b/tests/CMakeLists.txt\n@@ -1,4 +1,4 @@\n-# Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE.\n+# Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE.\n INCLUDE_DIRECTORIES(../src/liblsquic)\n \n ENABLE_TESTING()\ndiff --git a/tests/graph_cubic.c b/tests/graph_cubic.c\nindex bf56da43d..f91ce6954 100644\n--- a/tests/graph_cubic.c\n+++ b/tests/graph_cubic.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * This is not really a test: this program prints out cwnd histogram\n  * for visual inspection.\ndiff --git a/tests/mini_parse.c b/tests/mini_parse.c\nindex e05e2299f..108f91f94 100644\n--- a/tests/mini_parse.c\n+++ b/tests/mini_parse.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * Convert from our hexdump format to binary:\n  *\ndiff --git a/tests/test_ack.c b/tests/test_ack.c\nindex ed866cba0..dbe856a7f 100644\n--- a/tests/test_ack.c\n+++ b/tests/test_ack.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /* Test both generation and parsing of IETF ACK frames */\n \n #include <assert.h>\ndiff --git a/tests/test_ack_merge.c b/tests/test_ack_merge.c\nindex e84fecd95..da3654efb 100644\n--- a/tests/test_ack_merge.c\n+++ b/tests/test_ack_merge.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /* Test ACK merge */\n \n #include <assert.h>\ndiff --git a/tests/test_ackgen_gquic_be.c b/tests/test_ackgen_gquic_be.c\nindex 2ddf21815..2247288a8 100644\n--- a/tests/test_ackgen_gquic_be.c\n+++ b/tests/test_ackgen_gquic_be.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * Test how ACK frame is encoded.  Receive history module is tested by a\n  * separate unit test.\ndiff --git a/tests/test_ackparse_gquic_be.c b/tests/test_ackparse_gquic_be.c\nindex 2b783e83e..1b8c9debd 100644\n--- a/tests/test_ackparse_gquic_be.c\n+++ b/tests/test_ackparse_gquic_be.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdio.h>\n #include <stdlib.h>\ndiff --git a/tests/test_ackparse_ietf.c b/tests/test_ackparse_ietf.c\nindex 0af1f08c0..78708c651 100644\n--- a/tests/test_ackparse_ietf.c\n+++ b/tests/test_ackparse_ietf.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdio.h>\n #include <stdlib.h>\ndiff --git a/tests/test_alarmset.c b/tests/test_alarmset.c\nindex 301a021de..faf7f6e82 100644\n--- a/tests/test_alarmset.c\n+++ b/tests/test_alarmset.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdio.h>\n #include <stdlib.h>\ndiff --git a/tests/test_alt_svc_ver.c b/tests/test_alt_svc_ver.c\nindex b8d13d53f..e3c5184d4 100644\n--- a/tests/test_alt_svc_ver.c\n+++ b/tests/test_alt_svc_ver.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <string.h>\n \ndiff --git a/tests/test_arr.c b/tests/test_arr.c\nindex e27069bda..0a4e36662 100644\n--- a/tests/test_arr.c\n+++ b/tests/test_arr.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n \n #include \"lsquic_arr.h\"\ndiff --git a/tests/test_attq.c b/tests/test_attq.c\nindex 36849f2de..8901972e5 100644\n--- a/tests/test_attq.c\n+++ b/tests/test_attq.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdlib.h>\n #include <sys/queue.h>\ndiff --git a/tests/test_blocked_gquic_be.c b/tests/test_blocked_gquic_be.c\nindex e198e60cb..2ab947cf0 100644\n--- a/tests/test_blocked_gquic_be.c\n+++ b/tests/test_blocked_gquic_be.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdio.h>\n #include <stdlib.h>\ndiff --git a/tests/test_bw_sampler.c b/tests/test_bw_sampler.c\nindex 3011126c1..07796e290 100644\n--- a/tests/test_bw_sampler.c\n+++ b/tests/test_bw_sampler.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /* Test adapted from Chromium bandwidth_sampler_test.cc */\n // Copyright 2016 The Chromium Authors. All rights reserved.\n \ndiff --git a/tests/test_chlo_gen.c b/tests/test_chlo_gen.c\nindex 4c3d5a500..b40a77cb8 100644\n--- a/tests/test_chlo_gen.c\n+++ b/tests/test_chlo_gen.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * test_chlo_gen.c -- Test Client Hello generation.\n  */\ndiff --git a/tests/test_clear_aead.c b/tests/test_clear_aead.c\nindex 939ad3c3b..e0538370c 100644\n--- a/tests/test_clear_aead.c\n+++ b/tests/test_clear_aead.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * See\n  *  https://github.com/quicwg/base-drafts/wiki/Test-Vector-for-the-Clear-Text-AEAD-key-derivation\ndiff --git a/tests/test_conn_close_gquic_be.c b/tests/test_conn_close_gquic_be.c\nindex 085078646..c0608ba2b 100644\n--- a/tests/test_conn_close_gquic_be.c\n+++ b/tests/test_conn_close_gquic_be.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdio.h>\n #include <stdlib.h>\ndiff --git a/tests/test_conn_hash.c b/tests/test_conn_hash.c\nindex 5d1870c14..590672b00 100644\n--- a/tests/test_conn_hash.c\n+++ b/tests/test_conn_hash.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdint.h>\n #include <stdio.h>\ndiff --git a/tests/test_crypto_gen.c b/tests/test_crypto_gen.c\nindex 77589cd7d..7e6ac98fd 100644\n--- a/tests/test_crypto_gen.c\n+++ b/tests/test_crypto_gen.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdio.h>\n #include <stdlib.h>\ndiff --git a/tests/test_cubic.c b/tests/test_cubic.c\nindex b8f0b0d8b..295c1e3d9 100644\n--- a/tests/test_cubic.c\n+++ b/tests/test_cubic.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdio.h>\n #include <stdlib.h>\ndiff --git a/tests/test_dec.c b/tests/test_dec.c\nindex 3836bade6..b48bd5b11 100644\n--- a/tests/test_dec.c\n+++ b/tests/test_dec.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * test_dec.c -- Benchmark decryption using aligned and non-aligned buffers.\n  */\ndiff --git a/tests/test_di_nocopy.c b/tests/test_di_nocopy.c\nindex d90489e1e..441cbed2b 100644\n--- a/tests/test_di_nocopy.c\n+++ b/tests/test_di_nocopy.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * Test the \"nocopy\" data in stream\n  */\ndiff --git a/tests/test_elision.c b/tests/test_elision.c\nindex 13f4685c2..e6bef80a3 100644\n--- a/tests/test_elision.c\n+++ b/tests/test_elision.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <errno.h>\n #include <stdio.h>\ndiff --git a/tests/test_engine_ctor.c b/tests/test_engine_ctor.c\nindex 39e83ace1..5e9f67712 100644\n--- a/tests/test_engine_ctor.c\n+++ b/tests/test_engine_ctor.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdlib.h>\n #include <string.h>\ndiff --git a/tests/test_export_key.c b/tests/test_export_key.c\nindex b674cf72e..7e0de9c4a 100644\n--- a/tests/test_export_key.c\n+++ b/tests/test_export_key.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdlib.h>\n #include <string.h>\ndiff --git a/tests/test_frame_chop.c b/tests/test_frame_chop.c\nindex 6d906f1ef..518b849bf 100644\n--- a/tests/test_frame_chop.c\n+++ b/tests/test_frame_chop.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * Write several things to HEADERS stream and check the results.  What\n  * varies is the amount of bytes that are written to stream every time.\ndiff --git a/tests/test_frame_reader.c b/tests/test_frame_reader.c\nindex 0028e8e53..0d71a940a 100644\n--- a/tests/test_frame_reader.c\n+++ b/tests/test_frame_reader.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <errno.h>\n #include <stdio.h>\ndiff --git a/tests/test_frame_rw.c b/tests/test_frame_rw.c\nindex 7d13876ab..f4b7dbbf0 100644\n--- a/tests/test_frame_rw.c\n+++ b/tests/test_frame_rw.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * Generate a few thousand headers, frame them using frame writer, read them\n  * using frame reader, parse them, and compare with the original list: the\ndiff --git a/tests/test_frame_writer.c b/tests/test_frame_writer.c\nindex 7f5825481..12b5b1dc9 100644\n--- a/tests/test_frame_writer.c\n+++ b/tests/test_frame_writer.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <errno.h>\n #include <stdio.h>\ndiff --git a/tests/test_goaway_gquic_be.c b/tests/test_goaway_gquic_be.c\nindex b4a14801e..a3db7f9bd 100644\n--- a/tests/test_goaway_gquic_be.c\n+++ b/tests/test_goaway_gquic_be.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdio.h>\n #include <stdlib.h>\ndiff --git a/tests/test_h3_framing.c b/tests/test_h3_framing.c\nindex 9e4c951ef..cf6d25237 100644\n--- a/tests/test_h3_framing.c\n+++ b/tests/test_h3_framing.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * test_h3_framing.c -- test generation of H3 frames\n  */\ndiff --git a/tests/test_hcsi_reader.c b/tests/test_hcsi_reader.c\nindex 74432c8c1..8e688e64e 100644\n--- a/tests/test_hcsi_reader.c\n+++ b/tests/test_hcsi_reader.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <inttypes.h>\n #include <stdlib.h>\ndiff --git a/tests/test_hkdf.c b/tests/test_hkdf.c\nindex d699ae54a..a29ab4e70 100644\n--- a/tests/test_hkdf.c\n+++ b/tests/test_hkdf.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <string.h>\n #include <openssl/ssl.h>\ndiff --git a/tests/test_hpi.c b/tests/test_hpi.c\nindex a601b28f3..d08e3d11a 100644\n--- a/tests/test_hpi.c\n+++ b/tests/test_hpi.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <errno.h>\n #include <stdio.h>\ndiff --git a/tests/test_lsquic_hash.c b/tests/test_lsquic_hash.c\nindex 36fb625bf..f56390195 100644\n--- a/tests/test_lsquic_hash.c\n+++ b/tests/test_lsquic_hash.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdint.h>\n #include <stdio.h>\ndiff --git a/tests/test_malo.c b/tests/test_malo.c\nindex f7e67f2ff..4f6615ed0 100644\n--- a/tests/test_malo.c\n+++ b/tests/test_malo.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdint.h>\n #include <stdio.h>\ndiff --git a/tests/test_min_heap.c b/tests/test_min_heap.c\nindex 80100c930..cdd56d267 100644\n--- a/tests/test_min_heap.c\n+++ b/tests/test_min_heap.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /* Test min heap or benchmark heap creation */\n \n /* Floyd mechanism has been removed.  It's not faster. */\ndiff --git a/tests/test_minmax.c b/tests/test_minmax.c\nindex 6bebe86e8..60e071ec6 100644\n--- a/tests/test_minmax.c\n+++ b/tests/test_minmax.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /* Tests adopted from Chromium windowed_filter_test.cc */\n // Copyright (c) 2016 The Chromium Authors. All rights reserved.\n \ndiff --git a/tests/test_packet_out.c b/tests/test_packet_out.c\nindex 2b7441080..35478edf0 100644\n--- a/tests/test_packet_out.c\n+++ b/tests/test_packet_out.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <errno.h>\n #include <stdio.h>\ndiff --git a/tests/test_packet_resize.c b/tests/test_packet_resize.c\nindex 360f668b5..bc121bb38 100644\n--- a/tests/test_packet_resize.c\n+++ b/tests/test_packet_resize.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /* Test packet resizing */\n \n #include <assert.h>\ndiff --git a/tests/test_packno_len.c b/tests/test_packno_len.c\nindex 6cca758cf..9292ba35f 100644\n--- a/tests/test_packno_len.c\n+++ b/tests/test_packno_len.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdio.h>\n #include <stdlib.h>\ndiff --git a/tests/test_parse_packet_in.c b/tests/test_parse_packet_in.c\nindex 648725596..66ab19828 100644\n--- a/tests/test_parse_packet_in.c\n+++ b/tests/test_parse_packet_in.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdint.h>\n #include <stdlib.h>\ndiff --git a/tests/test_purga.c b/tests/test_purga.c\nindex a79e3ec24..28e7ac3f7 100644\n--- a/tests/test_purga.c\n+++ b/tests/test_purga.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdlib.h>\n #include <string.h>\ndiff --git a/tests/test_qlog.c b/tests/test_qlog.c\nindex 9d916e75b..fc8f40f9a 100644\n--- a/tests/test_qlog.c\n+++ b/tests/test_qlog.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdio.h>\n #include <stdlib.h>\ndiff --git a/tests/test_quic_be_floats.c b/tests/test_quic_be_floats.c\nindex e1f21d7f4..209b20517 100644\n--- a/tests/test_quic_be_floats.c\n+++ b/tests/test_quic_be_floats.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdio.h>\n #include <stdlib.h>\ndiff --git a/tests/test_rechist.c b/tests/test_rechist.c\nindex cc46ffd10..a41323fc5 100644\n--- a/tests/test_rechist.c\n+++ b/tests/test_rechist.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <inttypes.h>\n #include <stdio.h>\ndiff --git a/tests/test_reg_pkt_headergen.c b/tests/test_reg_pkt_headergen.c\nindex 481379c38..dbf400ded 100644\n--- a/tests/test_reg_pkt_headergen.c\n+++ b/tests/test_reg_pkt_headergen.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdio.h>\n #include <stdlib.h>\ndiff --git a/tests/test_rst_stream_gquic_be.c b/tests/test_rst_stream_gquic_be.c\nindex 26126b827..49971634b 100644\n--- a/tests/test_rst_stream_gquic_be.c\n+++ b/tests/test_rst_stream_gquic_be.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdio.h>\n #include <stdlib.h>\ndiff --git a/tests/test_rst_stream_ietf.c b/tests/test_rst_stream_ietf.c\nindex 5c912fa07..c43be944f 100644\n--- a/tests/test_rst_stream_ietf.c\n+++ b/tests/test_rst_stream_ietf.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdio.h>\n #include <stdlib.h>\ndiff --git a/tests/test_rtt.c b/tests/test_rtt.c\nindex 63c10112b..430046e6a 100644\n--- a/tests/test_rtt.c\n+++ b/tests/test_rtt.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdio.h>\n #include <stdlib.h>\ndiff --git a/tests/test_send_headers.c b/tests/test_send_headers.c\nindex daa0d5dd6..5e709793b 100644\n--- a/tests/test_send_headers.c\n+++ b/tests/test_send_headers.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * test_send_headers.c -- Test what happens when lsquic_stream_send_headers()\n  * is called.\ndiff --git a/tests/test_senhist.c b/tests/test_senhist.c\nindex 35a151099..4804bef29 100644\n--- a/tests/test_senhist.c\n+++ b/tests/test_senhist.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdio.h>\n #include <stdlib.h>\ndiff --git a/tests/test_set.c b/tests/test_set.c\nindex dd3280e63..28ce4a3d0 100644\n--- a/tests/test_set.c\n+++ b/tests/test_set.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdio.h>\n #include <stdlib.h>\ndiff --git a/tests/test_sfcw.c b/tests/test_sfcw.c\nindex 7905c0c23..67c659883 100644\n--- a/tests/test_sfcw.c\n+++ b/tests/test_sfcw.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdio.h>\n #include <stdint.h>\ndiff --git a/tests/test_shi.c b/tests/test_shi.c\nindex 24bf756e7..138c7f7e6 100644\n--- a/tests/test_shi.c\n+++ b/tests/test_shi.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdlib.h>\n #include <string.h>\ndiff --git a/tests/test_some_packets.c b/tests/test_some_packets.c\nindex 79dce845d..88766b45e 100644\n--- a/tests/test_some_packets.c\n+++ b/tests/test_some_packets.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /* Tests in this file have been migrated out of maintest.c */\n /* TODO: fix warnings */\n \ndiff --git a/tests/test_spi.c b/tests/test_spi.c\nindex 2f1a6001f..b603a4cd7 100644\n--- a/tests/test_spi.c\n+++ b/tests/test_spi.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <errno.h>\n #include <stdio.h>\ndiff --git a/tests/test_stop_waiting_gquic_be.c b/tests/test_stop_waiting_gquic_be.c\nindex 87b996d4c..d1195c2f7 100644\n--- a/tests/test_stop_waiting_gquic_be.c\n+++ b/tests/test_stop_waiting_gquic_be.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdio.h>\n #include <stdlib.h>\ndiff --git a/tests/test_stream.c b/tests/test_stream.c\nindex 860136923..8597530b3 100644\n--- a/tests/test_stream.c\n+++ b/tests/test_stream.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <errno.h>\n #include <stdio.h>\ndiff --git a/tests/test_streamgen.c b/tests/test_streamgen.c\nindex a4b13c58a..a46340d79 100644\n--- a/tests/test_streamgen.c\n+++ b/tests/test_streamgen.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdio.h>\n #include <stdlib.h>\ndiff --git a/tests/test_streamparse.c b/tests/test_streamparse.c\nindex 8013cf4b5..e776f654e 100644\n--- a/tests/test_streamparse.c\n+++ b/tests/test_streamparse.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdio.h>\n #include <stdlib.h>\ndiff --git a/tests/test_tokgen.c b/tests/test_tokgen.c\nindex 9650e20c0..0bc8e63fa 100644\n--- a/tests/test_tokgen.c\n+++ b/tests/test_tokgen.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdio.h>\n #include <string.h>\ndiff --git a/tests/test_trapa.c b/tests/test_trapa.c\nindex f3c4ed604..a0e7e89d7 100644\n--- a/tests/test_trapa.c\n+++ b/tests/test_trapa.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*\n  * test_trapa.c -- Test transport parameters.\n  */\ndiff --git a/tests/test_trechist.c b/tests/test_trechist.c\nindex f0040c220..163bfca1a 100644\n--- a/tests/test_trechist.c\n+++ b/tests/test_trechist.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /* Tests based on rechist tests */\n \n #include <assert.h>\ndiff --git a/tests/test_varint.c b/tests/test_varint.c\nindex 3f98c4386..b6779b727 100644\n--- a/tests/test_varint.c\n+++ b/tests/test_varint.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stddef.h>\n #include <stdint.h>\ndiff --git a/tests/test_ver_nego.c b/tests/test_ver_nego.c\nindex 9a0217fe3..e753d0a99 100644\n--- a/tests/test_ver_nego.c\n+++ b/tests/test_ver_nego.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdio.h>\n #include <stdlib.h>\ndiff --git a/tests/test_wuf_gquic_be.c b/tests/test_wuf_gquic_be.c\nindex 00fc868e3..992c78bc1 100644\n--- a/tests/test_wuf_gquic_be.c\n+++ b/tests/test_wuf_gquic_be.c\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #include <assert.h>\n #include <stdio.h>\n #include <stdlib.h>\ndiff --git a/wincompat/README.txt b/wincompat/README.txt\nindex 18f7680b3..a5ced1f76 100644\n--- a/wincompat/README.txt\n+++ b/wincompat/README.txt\n@@ -1,4 +1,4 @@\n-# Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE.\n+# Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE.\n - only debug and release are expected in the Cmakelists.txt. If you need a different config, please follow the model in that file to add it.\n \n - vcpkg does not have boringssl, so you'll have to build it yourself. Follow the instructions at the boringssl repository.\ndiff --git a/wincompat/sys/queue.h b/wincompat/sys/queue.h\nindex 4bc39ab23..e15d61af2 100644\n--- a/wincompat/sys/queue.h\n+++ b/wincompat/sys/queue.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n /*-\n  * SPDX-License-Identifier: BSD-3-Clause\n  *\ndiff --git a/wincompat/vc_compat.h b/wincompat/vc_compat.h\nindex 251e971f2..f5369a7d7 100644\n--- a/wincompat/vc_compat.h\n+++ b/wincompat/vc_compat.h\n@@ -1,4 +1,4 @@\n-/* Copyright (c) 2017 - 2021 LiteSpeed Technologies Inc.  See LICENSE. */\n+/* Copyright (c) 2017 - 2022 LiteSpeed Technologies Inc.  See LICENSE. */\n #pragma once\n #include <Windows.h>\n #include <winsock2.h>\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "0a9f9a7410681e55362f8311537ebc7be9ad0fbe",
        "repo": "saschahauer/barebox",
        "msg": "crypto: digest: use crypto_memneq()\n\nWhen verifying a digest it is important not to leak timing information\nthrough memcmp(). Use crypto_memneq() instead.\n\nSigned-off-by: Sascha Hauer <s.hauer@pengutronix.de>crypto/digest.c in Pengutronix barebox through 2021.07.0 leaks timing information because memcmp is used during digest verification.",
        "filename": "digest.c",
        "diff": "diff --git a/crypto/digest.c b/crypto/digest.c\nindex d23245e15f..621d384168 100644\n--- a/crypto/digest.c\n+++ b/crypto/digest.c\n@@ -22,6 +22,7 @@\n #include <errno.h>\n #include <module.h>\n #include <linux/err.h>\n+#include <crypto.h>\n #include <crypto/internal.h>\n \n static LIST_HEAD(digests);\n@@ -47,8 +48,10 @@ int digest_generic_verify(struct digest *d, const unsigned char *md)\n \tif (ret)\n \t\tgoto end;\n \n-\tret = memcmp(md, tmp, len);\n-\tret = ret ? -EINVAL : 0;\n+\tif (crypto_memneq(md, tmp, len))\n+\t\tret = -EINVAL;\n+\telse\n+\t\tret = 0;\n end:\n \tfree(tmp);\n \treturn ret;\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "409510c588b1eec1ae33511ae97a21eb8e110895",
        "repo": "vim/vim",
        "msg": "patch 8.2.5050: using freed memory when searching for pattern in path\n\nProblem:    Using freed memory when searching for pattern in path.\nSolution:   Make a copy of the line.Use After Free in GitHub repository vim/vim prior to 8.2.",
        "filename": "search.c",
        "diff": "diff --git a/src/search.c b/src/search.c\nindex ea72ec7fb9d786..35dc89b8fe4acb 100644\n--- a/src/search.c\n+++ b/src/search.c\n@@ -3305,6 +3305,21 @@ update_search_stat(\n }\n \n #if defined(FEAT_FIND_ID) || defined(PROTO)\n+\n+/*\n+ * Get line \"lnum\" and copy it into \"buf[LSIZE]\".\n+ * The copy is made because the regexp may make the line invalid when using a\n+ * mark.\n+ */\n+    static char_u *\n+get_line_and_copy(linenr_T lnum, char_u *buf)\n+{\n+    char_u *line = ml_get(lnum);\n+\n+    vim_strncpy(buf, line, LSIZE - 1);\n+    return buf;\n+}\n+\n /*\n  * Find identifiers or defines in included files.\n  * If p_ic && compl_status_sol() then ptr must be in lowercase.\n@@ -3409,7 +3424,7 @@ find_pattern_in_path(\n \tend_lnum = curbuf->b_ml.ml_line_count;\n     if (lnum > end_lnum)\t\t// do at least one line\n \tlnum = end_lnum;\n-    line = ml_get(lnum);\n+    line = get_line_and_copy(lnum, file_line);\n \n     for (;;)\n     {\n@@ -3738,7 +3753,7 @@ find_pattern_in_path(\n \t\t    {\n \t\t\tif (lnum >= end_lnum)\n \t\t\t    goto exit_matched;\n-\t\t\tline = ml_get(++lnum);\n+\t\t\tline = get_line_and_copy(++lnum, file_line);\n \t\t    }\n \t\t    else if (vim_fgets(line = file_line,\n \t\t\t\t\t\t      LSIZE, files[depth].fp))\n@@ -3950,7 +3965,7 @@ find_pattern_in_path(\n \t{\n \t    if (++lnum > end_lnum)\n \t\tbreak;\n-\t    line = ml_get(lnum);\n+\t    line = get_line_and_copy(lnum, file_line);\n \t}\n \talready = NULL;\n     }\ndiff --git a/src/testdir/test_tagjump.vim b/src/testdir/test_tagjump.vim\nindex aacfb9baeb56fc..060cc3b188c8e4 100644\n--- a/src/testdir/test_tagjump.vim\n+++ b/src/testdir/test_tagjump.vim\n@@ -1290,6 +1290,17 @@ func Test_inc_search()\n   close!\n endfunc\n \n+\" this was using a line from ml_get() freed by the regexp\n+func Test_isearch_copy_line()\n+  new\n+  norm o\n+  norm \u00160\n+  0norm o\n+  sil! norm bc0\n+  sil! isearch \\%')\n+  bwipe!\n+endfunc\n+\n \" Test for :dsearch, :dlist, :djump and :dsplit commands\n \" Test for [d, ]d, [D, ]D, [ CTRL-D, ] CTRL-D and CTRL-W d commands\n func Test_macro_search()\ndiff --git a/src/version.c b/src/version.c\nindex 97ca8ce5cb40af..ba8688bc55c961 100644\n--- a/src/version.c\n+++ b/src/version.c\n@@ -734,6 +734,8 @@ static char *(features[]) =\n \n static int included_patches[] =\n {   /* Add new patch number below this line */\n+/**/\n+    5050,\n /**/\n     5049,\n /**/\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "44db8213d38c39877d2148eff6a72f4beccfb94e",
        "repo": "vim/vim",
        "msg": "patch 8.2.4219: reading before the start of the line\n\nProblem:    Reading before the start of the line.\nSolution:   Check boundary before trying to read the character.Heap-based Buffer Overflow in GitHub repository vim/vim prior to 8.2.",
        "filename": "register.c",
        "diff": "diff --git a/src/register.c b/src/register.c\nindex d604bae6b0debf..03f7f4ec9604ce 100644\n--- a/src/register.c\n+++ b/src/register.c\n@@ -1474,7 +1474,7 @@ yank_copy_line(struct block_def *bd, long y_idx, int exclude_trailing_space)\n     {\n \tint s = bd->textlen + bd->endspaces;\n \n-\twhile (VIM_ISWHITE(*(bd->textstart + s - 1)) && s > 0)\n+\twhile (s > 0 && VIM_ISWHITE(*(bd->textstart + s - 1)))\n \t{\n \t    s = s - (*mb_head_off)(bd->textstart, bd->textstart + s - 1) - 1;\n \t    pnew--;\ndiff --git a/src/testdir/test_visual.vim b/src/testdir/test_visual.vim\nindex b2beda08d0aa84..af54615c48a104 100644\n--- a/src/testdir/test_visual.vim\n+++ b/src/testdir/test_visual.vim\n@@ -1247,6 +1247,13 @@ func Test_visual_put_blockedit_zy_and_zp()\n   bw!\n endfunc\n \n+func Test_visual_block_yank_zy()\n+  new\n+  \" this was reading before the start of the line\n+  exe \"norm o\\<C-T>\\<Esc>\\<C-V>zy\"\n+  bwipe!\n+endfunc\n+\n func Test_visual_block_with_virtualedit()\n   CheckScreendump\n \ndiff --git a/src/version.c b/src/version.c\nindex 9dcf34928f8def..a3efb046bdf583 100644\n--- a/src/version.c\n+++ b/src/version.c\n@@ -750,6 +750,8 @@ static char *(features[]) =\n \n static int included_patches[] =\n {   /* Add new patch number below this line */\n+/**/\n+    4219,\n /**/\n     4218,\n /**/\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "47068ae07a5fa3aa9a1879cdfe98a9ce0f339299",
        "repo": "mruby/mruby",
        "msg": "vm.c: packed arguments length may be zero for `send` method.Heap-based Buffer Overflow in Homebrew mruby prior to 3.2.",
        "filename": "vm.c",
        "diff": "diff --git a/src/vm.c b/src/vm.c\nindex 9cb50847f2..aa5569503e 100644\n--- a/src/vm.c\n+++ b/src/vm.c\n@@ -689,9 +689,11 @@ mrb_f_send(mrb_state *mrb, mrb_value self)\n   regs = mrb->c->ci->stack+1;\n \n   if (n == 0) {\n+  argnum_error:\n     mrb_argnum_error(mrb, 0, 1, -1);\n   }\n   else if (n == 15) {\n+    if (RARRAY_LEN(regs[0]) == 0) goto argnum_error;\n     name = mrb_obj_to_sym(mrb, RARRAY_PTR(regs[0])[0]);\n   }\n   else {\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "c535bad50d5812d27ee5b22b54371bddec411514",
        "repo": "gpac/gpac",
        "msg": "fixed #2194Use After Free in GitHub repository gpac/gpac prior to v2.1.0-DEV.",
        "filename": "memory_decoder.c",
        "diff": "diff --git a/src/bifs/memory_decoder.c b/src/bifs/memory_decoder.c\nindex 74d635750d..1fc8c99638 100644\n--- a/src/bifs/memory_decoder.c\n+++ b/src/bifs/memory_decoder.c\n@@ -178,7 +178,12 @@ static GF_Err BM_ParseGlobalQuantizer(GF_BifsDecoder *codec, GF_BitStream *bs, G\n \tcodec->scenegraph->global_qp = NULL;\n \n \tif (gf_node_get_tag(node) != TAG_MPEG4_QuantizationParameter) {\n-\t\tgf_node_unregister(node, NULL);\n+\t\t//if node was just created (num_instances == 0), unregister\n+\t\t//otherwise (USE node) don't do anything\n+\t\tif (!node->sgprivate->num_instances) {\n+\t\t\tnode->sgprivate->num_instances = 1;\n+\t\t\tgf_node_unregister(node, NULL);\n+\t\t}\n \t\treturn GF_NON_COMPLIANT_BITSTREAM;\n \t}\n \n@@ -188,7 +193,8 @@ static GF_Err BM_ParseGlobalQuantizer(GF_BifsDecoder *codec, GF_BitStream *bs, G\n \tcodec->scenegraph->global_qp = node;\n \n \t/*register TWICE: once for the command, and for the scenegraph globalQP*/\n-\tnode->sgprivate->num_instances = 2;\n+\tgf_node_unregister(node, NULL);\n+\tgf_node_unregister(node, NULL);\n \n \tcom = gf_sg_command_new(codec->current_graph, GF_SG_GLOBAL_QUANTIZER);\n \tinf = gf_sg_command_field_new(com);\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "7731e8dfbe4a56773be5dc94d631611211156659",
        "repo": "tensorflow/tensorflow",
        "msg": "Don't constant-fold DT_RESOURCE constants.\n\nPiperOrigin-RevId: 391803952\nChange-Id: I0ea3ec31d3e7dfda0f03b4027a237f08d00a3091TensorFlow is an open source platform for machine learning. In affected versions during TensorFlow's Grappler optimizer phase, constant folding might attempt to deep copy a resource tensor. This results in a segfault, as these tensors are supposed to not change. The fix will be included in TensorFlow 2.7.0. We will also cherrypick this commit on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.",
        "filename": "constant_folding.cc",
        "diff": "diff --git a/tensorflow/core/common_runtime/constant_folding.cc b/tensorflow/core/common_runtime/constant_folding.cc\nindex 8367e5ff6aff34..ca75dc9f19160a 100644\n--- a/tensorflow/core/common_runtime/constant_folding.cc\n+++ b/tensorflow/core/common_runtime/constant_folding.cc\n@@ -30,6 +30,7 @@ limitations under the License.\n #include \"tensorflow/core/framework/log_memory.h\"\n #include \"tensorflow/core/framework/op_kernel.h\"\n #include \"tensorflow/core/framework/types.h\"\n+#include \"tensorflow/core/framework/types.pb.h\"\n #include \"tensorflow/core/graph/algorithm.h\"\n #include \"tensorflow/core/graph/node_builder.h\"\n #include \"tensorflow/core/graph/subgraph.h\"\n@@ -223,7 +224,8 @@ bool IsConstantFoldable(\n     std::unordered_map<const Node*, std::vector<Tensor>>*\n         shape_replacement_map) {\n   if (n->IsConstant()) {\n-    return true;\n+    // Skip constant folding resources as they cannot be deep copied.\n+    return n->output_type(0) != DT_RESOURCE;\n   }\n   if (MaybeReplaceShapeOp(n, shape_map, shape_replacement_map)) {\n     return true;\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "eb921122119a6b6e470ee98b89e65d721663179d",
        "repo": "tensorflow/tensorflow",
        "msg": "Prevent heap OOB read in TFLite's `gather.cc`.\n\nPassing negative indices is illegal but there was a missing check so that resulted in OOB accesses.\n\nPiperOrigin-RevId: 387231300\nChange-Id: I3111b54b2f232638d795be17efc46abe4ede6bf8TensorFlow is an end-to-end open source platform for machine learning. In affected versions TFLite's [`GatherNd` implementation](https://github.com/tensorflow/tensorflow/blob/149562d49faa709ea80df1d99fc41d005b81082a/tensorflow/lite/kernels/gather_nd.cc#L124) does not support negative indices but there are no checks for this situation. Hence, an attacker can read arbitrary data from the heap by carefully crafting a model with negative values in `indices`. Similar issue exists in [`Gather` implementation](https://github.com/tensorflow/tensorflow/blob/149562d49faa709ea80df1d99fc41d005b81082a/tensorflow/lite/kernels/gather.cc). We have patched the issue in GitHub commits bb6a0383ed553c286f87ca88c207f6774d5c4a8f and eb921122119a6b6e470ee98b89e65d721663179d. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "filename": "gather.cc",
        "diff": "diff --git a/tensorflow/lite/kernels/gather.cc b/tensorflow/lite/kernels/gather.cc\nindex 9fe94821230c00..bdc2139d0fe7a5 100644\n--- a/tensorflow/lite/kernels/gather.cc\n+++ b/tensorflow/lite/kernels/gather.cc\n@@ -117,8 +117,20 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n }\n \n template <typename InputT, typename PositionsT>\n-TfLiteStatus Gather(const TfLiteGatherParams& params, const TfLiteTensor* input,\n-                    const TfLiteTensor* positions, TfLiteTensor* output) {\n+TfLiteStatus Gather(TfLiteContext* context, const TfLiteGatherParams& params,\n+                    const TfLiteTensor* input, const TfLiteTensor* positions,\n+                    TfLiteTensor* output) {\n+  const PositionsT* indexes = GetTensorData<PositionsT>(positions);\n+  bool indices_has_only_positive_elements = true;\n+  const size_t num_indices = positions->bytes / sizeof(PositionsT);\n+  for (size_t i = 0; i < num_indices; i++) {\n+    if (indexes[i] < 0) {\n+      indices_has_only_positive_elements = false;\n+      break;\n+    }\n+  }\n+  TF_LITE_ENSURE(context, indices_has_only_positive_elements);\n+\n   tflite::GatherParams op_params;\n   op_params.axis = params.axis;\n   op_params.batch_dims = params.batch_dims;\n@@ -134,7 +146,18 @@ TfLiteStatus GatherStrings(TfLiteContext* context, const TfLiteTensor* input,\n                            const TfLiteTensor* positions,\n                            TfLiteTensor* output) {\n   DynamicBuffer buffer;\n+\n   const PositionT* indexes = GetTensorData<PositionT>(positions);\n+  bool indices_has_only_positive_elements = true;\n+  const size_t num_indices = positions->bytes / sizeof(PositionT);\n+  for (size_t i = 0; i < num_indices; i++) {\n+    if (indexes[i] < 0) {\n+      indices_has_only_positive_elements = false;\n+      break;\n+    }\n+  }\n+  TF_LITE_ENSURE(context, indices_has_only_positive_elements);\n+\n   const PositionT num_strings = GetStringCount(input);\n   const int num_indexes = NumElements(positions);\n \n@@ -163,19 +186,26 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   if (positions->type == kTfLiteInt32) {\n     switch (input->type) {\n       case kTfLiteFloat32:\n-        return Gather<float, int32_t>(*params, input, positions, output);\n+        return Gather<float, int32_t>(context, *params, input, positions,\n+                                      output);\n       case kTfLiteUInt8:\n-        return Gather<uint8_t, int32_t>(*params, input, positions, output);\n+        return Gather<uint8_t, int32_t>(context, *params, input, positions,\n+                                        output);\n       case kTfLiteInt8:\n-        return Gather<int8_t, int32_t>(*params, input, positions, output);\n+        return Gather<int8_t, int32_t>(context, *params, input, positions,\n+                                       output);\n       case kTfLiteInt16:\n-        return Gather<int16_t, int32_t>(*params, input, positions, output);\n+        return Gather<int16_t, int32_t>(context, *params, input, positions,\n+                                        output);\n       case kTfLiteInt32:\n-        return Gather<int32_t, int32_t>(*params, input, positions, output);\n+        return Gather<int32_t, int32_t>(context, *params, input, positions,\n+                                        output);\n       case kTfLiteInt64:\n-        return Gather<int64_t, int32_t>(*params, input, positions, output);\n+        return Gather<int64_t, int32_t>(context, *params, input, positions,\n+                                        output);\n       case kTfLiteBool:\n-        return Gather<bool, int32_t>(*params, input, positions, output);\n+        return Gather<bool, int32_t>(context, *params, input, positions,\n+                                     output);\n       case kTfLiteString:\n         return GatherStrings<int32_t>(context, input, positions, output);\n       default:\n@@ -187,19 +217,26 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   if (positions->type == kTfLiteInt64) {\n     switch (input->type) {\n       case kTfLiteFloat32:\n-        return Gather<float, int64_t>(*params, input, positions, output);\n+        return Gather<float, int64_t>(context, *params, input, positions,\n+                                      output);\n       case kTfLiteUInt8:\n-        return Gather<uint8_t, int64_t>(*params, input, positions, output);\n+        return Gather<uint8_t, int64_t>(context, *params, input, positions,\n+                                        output);\n       case kTfLiteInt8:\n-        return Gather<int8_t, int64_t>(*params, input, positions, output);\n+        return Gather<int8_t, int64_t>(context, *params, input, positions,\n+                                       output);\n       case kTfLiteInt16:\n-        return Gather<int16_t, int64_t>(*params, input, positions, output);\n+        return Gather<int16_t, int64_t>(context, *params, input, positions,\n+                                        output);\n       case kTfLiteInt32:\n-        return Gather<int32_t, int64_t>(*params, input, positions, output);\n+        return Gather<int32_t, int64_t>(context, *params, input, positions,\n+                                        output);\n       case kTfLiteInt64:\n-        return Gather<int64_t, int64_t>(*params, input, positions, output);\n+        return Gather<int64_t, int64_t>(context, *params, input, positions,\n+                                        output);\n       case kTfLiteBool:\n-        return Gather<bool, int64_t>(*params, input, positions, output);\n+        return Gather<bool, int64_t>(context, *params, input, positions,\n+                                     output);\n       case kTfLiteString:\n         return GatherStrings<int64_t>(context, input, positions, output);\n       default:\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "96f364a1ca3009f98980021c4b32be5fdcca33a1",
        "repo": "tensorflow/tensorflow",
        "msg": "Validate axis input in tf.raw_ops.QuantizeAndDequantizeV4Grad\n\nPiperOrigin-RevId: 388291385\nChange-Id: I3bab68dc61d935afa96c0da021a7b722c6dc8dc8TensorFlow is an end-to-end open source platform for machine learning. In affected versions the implementation of `tf.raw_ops.QuantizeAndDequantizeV4Grad` is vulnerable to an integer overflow issue caused by converting a signed integer value to an unsigned one and then allocating memory based on this value. The [implementation](https://github.com/tensorflow/tensorflow/blob/8d72537c6abf5a44103b57b9c2e22c14f5f49698/tensorflow/core/kernels/quantize_and_dequantize_op.cc#L126) uses the `axis` value as the size argument to `absl::InlinedVector` constructor. But, the constructor uses an unsigned type for the argument, so the implicit conversion transforms the negative value to a large integer. We have patched the issue in GitHub commit 96f364a1ca3009f98980021c4b32be5fdcca33a1. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, and TensorFlow 2.4.3, as these are also affected and still in supported range.",
        "filename": "quantize_and_dequantize_op.cc",
        "diff": "diff --git a/tensorflow/core/kernels/quantize_and_dequantize_op.cc b/tensorflow/core/kernels/quantize_and_dequantize_op.cc\nindex 540d900f9f8696..d63a49a04be621 100644\n--- a/tensorflow/core/kernels/quantize_and_dequantize_op.cc\n+++ b/tensorflow/core/kernels/quantize_and_dequantize_op.cc\n@@ -158,6 +158,13 @@ class QuantizeAndDequantizeV4GradientOp : public OpKernel {\n     Tensor* input_backprop = nullptr;\n     OP_REQUIRES_OK(ctx,\n                    ctx->allocate_output(0, input.shape(), &input_backprop));\n+    OP_REQUIRES(\n+        ctx, axis_ >= -1,\n+        errors::InvalidArgument(\"Axis must be at least -1. Found \", axis_));\n+    OP_REQUIRES(ctx, (axis_ == -1 || axis_ < input.shape().dims()),\n+                errors::InvalidArgument(\n+                    \"Axis should be -1 or 0 or a positive value less than \",\n+                    input.shape().dims(), \"but given axis value was \", axis_));\n \n     OP_REQUIRES(\n         ctx, input.IsSameSize(gradient),\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "1aeeed2e4fdeffb4875c0d0b439915894594c8c6",
        "repo": "containers/crun",
        "msg": "exec: --cap do not set inheritable capabilities\n\nCloses: CVE-2022-27650\n\nSigned-off-by: Giuseppe Scrivano <gscrivan@redhat.com>A flaw was found in crun where containers were incorrectly started with non-empty default permissions. A vulnerability was found in Moby (Docker Engine) where containers were started incorrectly with non-empty inheritable Linux process capabilities. This flaw allows an attacker with access to programs with inheritable file capabilities to elevate those capabilities to the permitted set when execve(2) runs.",
        "filename": "exec.c",
        "diff": "diff --git a/src/exec.c b/src/exec.c\nindex 7a8931e5ce..c876ecd180 100644\n--- a/src/exec.c\n+++ b/src/exec.c\n@@ -304,8 +304,8 @@ crun_command_exec (struct crun_global_arguments *global_args, int argc, char **a\n           capabilities->effective = exec_options.cap;\n           capabilities->effective_len = exec_options.cap_size;\n \n-          capabilities->inheritable = dup_array (exec_options.cap, exec_options.cap_size);\n-          capabilities->inheritable_len = exec_options.cap_size;\n+          capabilities->inheritable = NULL;\n+          capabilities->inheritable_len = 0;\n \n           capabilities->bounding = dup_array (exec_options.cap, exec_options.cap_size);\n           capabilities->bounding_len = exec_options.cap_size;\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "704866eabe03a9aeda044ec91a8d0c83fc1ebdbe",
        "repo": "tensorflow/tensorflow",
        "msg": "Fix overflow CHECK issue with `tf.raw_ops.UnsortedSegmentJoin`.\n\nPiperOrigin-RevId: 370766155\nChange-Id: I33e7c6626224e1060a8a4ab51ad5d861c6d4c63eTensorFlow is an end-to-end open source platform for machine learning. An attacker can cause a denial of service by controlling the values of `num_segments` tensor argument for `UnsortedSegmentJoin`. This is because the implementation(https://github.com/tensorflow/tensorflow/blob/a2a607db15c7cd01d754d37e5448d72a13491bdb/tensorflow/core/kernels/unsorted_segment_join_op.cc#L92-L93) assumes that the `num_segments` tensor is a valid scalar. Since the tensor is empty the `CHECK` involved in `.scalar<T>()()` that checks that the number of elements is exactly 1 will be invalidated and this would result in process termination. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
        "filename": "unsorted_segment_join_op.cc",
        "diff": "diff --git a/tensorflow/core/kernels/unsorted_segment_join_op.cc b/tensorflow/core/kernels/unsorted_segment_join_op.cc\nindex 7464e165e46c8b..9acfe7fb1e4952 100644\n--- a/tensorflow/core/kernels/unsorted_segment_join_op.cc\n+++ b/tensorflow/core/kernels/unsorted_segment_join_op.cc\n@@ -90,6 +90,8 @@ class UnsortedSegmentJoinOp : public OpKernel {\n     const int32 segment_dims = segment_id_shape.dims();\n \n     const Tensor& num_segments_tensor = context->input(2);\n+    OP_REQUIRES(context, num_segments_tensor.NumElements() != 0,\n+                errors::InvalidArgument(\"Number of segments cannot be empty.\"));\n     auto num_segments = num_segments_tensor.scalar<NUM_SEGMENTS_TYPE>()();\n \n     OP_REQUIRES(context, segment_dims != 0,\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "e86605c0a336c088b638da02135ea6f9f6753618",
        "repo": "tensorflow/tensorflow",
        "msg": "Fix FPE in inpace update ops.\n\nPiperOrigin-RevId: 388303197\nChange-Id: Ib48309b6213ffe53eba81004b00e889d653e4b83TensorFlow is an end-to-end open source platform for machine learning. In affected versions an attacker can cause a floating point exception by calling inplace operations with crafted arguments that would result in a division by 0. The [implementation](https://github.com/tensorflow/tensorflow/blob/84d053187cb80d975ef2b9684d4b61981bca0c41/tensorflow/core/kernels/inplace_ops.cc#L283) has a logic error: it should skip processing if `x` and `v` are empty but the code uses `||` instead of `&&`. We have patched the issue in GitHub commit e86605c0a336c088b638da02135ea6f9f6753618. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "filename": "inplace_ops.cc",
        "diff": "diff --git a/tensorflow/core/kernels/inplace_ops.cc b/tensorflow/core/kernels/inplace_ops.cc\nindex 2c0b201af3dd81..81027c7e17ee1a 100644\n--- a/tensorflow/core/kernels/inplace_ops.cc\n+++ b/tensorflow/core/kernels/inplace_ops.cc\n@@ -225,7 +225,7 @@ class InplaceOpBase : public OpKernel {\n \n     Tensor y = x;  // This creates an alias intentionally.\n     // Skip processing if tensors are empty.\n-    if (x.NumElements() > 0 || v.NumElements() > 0) {\n+    if (x.NumElements() > 0 && v.NumElements() > 0) {\n       OP_REQUIRES_OK(ctx, DoCompute(ctx, i, v, &y));\n     }\n     ctx->set_output(0, y);\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "b5cdbf12ffcaaffecf98f22a6be5a64bb96e4f58",
        "repo": "tensorflow/tensorflow",
        "msg": "Prevent overflow due to integer conversion to unsigned.\n\nPiperOrigin-RevId: 387738045\nChange-Id: Id7e95bc07e02df1c66b72bd09f389608c87bdebeTensorFlow is an end-to-end open source platform for machine learning. In affected versions an attacker can cause denial of service in applications serving models using `tf.raw_ops.NonMaxSuppressionV5` by triggering a division by 0. The [implementation](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/core/kernels/image/non_max_suppression_op.cc#L170-L271) uses a user controlled argument to resize a `std::vector`. However, as `std::vector::resize` takes the size argument as a `size_t` and `output_size` is an `int`, there is an implicit conversion to unsigned. If the attacker supplies a negative value, this conversion results in a crash. A similar issue occurs in `CombinedNonMaxSuppression`. We have patched the issue in GitHub commit 3a7362750d5c372420aa8f0caf7bf5b5c3d0f52d and commit [b5cdbf12ffcaaffecf98f22a6be5a64bb96e4f58. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "filename": "non_max_suppression_op.cc",
        "diff": "diff --git a/tensorflow/core/kernels/image/non_max_suppression_op.cc b/tensorflow/core/kernels/image/non_max_suppression_op.cc\nindex 5cb721ed7105fa..69b05cc9d84f83 100644\n--- a/tensorflow/core/kernels/image/non_max_suppression_op.cc\n+++ b/tensorflow/core/kernels/image/non_max_suppression_op.cc\n@@ -930,6 +930,8 @@ class CombinedNonMaxSuppressionOp : public OpKernel {\n         errors::InvalidArgument(\"max_size_per_class must be 0-D, got shape \",\n                                 max_output_size.shape().DebugString()));\n     const int max_size_per_class = max_output_size.scalar<int>()();\n+    OP_REQUIRES(context, max_size_per_class > 0,\n+                errors::InvalidArgument(\"max_size_per_class must be positive\"));\n     // max_total_size: scalar\n     const Tensor& max_total_size = context->input(3);\n     OP_REQUIRES(\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "193f4fe01d7f626e2ea937450f2e0c4604420e9d",
        "repo": "radare/radare2",
        "msg": "Fix integer overflow in string search causing oobread ##crash\n\n* Reported by @greatergoodest via huntrdev\n* BountyID: 8a3dc5cb-08b3-4807-82b2-77f08c137a04\n* Reproducer bfileovfOut-of-bounds Read in GitHub repository radareorg/radare2 prior to 5.7.0.",
        "filename": "bfile.c",
        "diff": "diff --git a/libr/bin/bfile.c b/libr/bin/bfile.c\nindex 3216e5b7618d9..bb9663fff17d4 100644\n--- a/libr/bin/bfile.c\n+++ b/libr/bin/bfile.c\n@@ -178,19 +178,19 @@ static int string_scan_range(RList *list, RBinFile *bf, int min,\n \tfree (charset);\n \tRConsIsBreaked is_breaked = (bin && bin->consb.is_breaked)? bin->consb.is_breaked: NULL;\n \t// may oobread\n-\twhile (needle < to) {\n+\twhile (needle < to && needle < UT64_MAX - 4) {\n \t\tif (is_breaked && is_breaked ()) {\n \t\t\tbreak;\n \t\t}\n \t\t// smol optimization\n-\t\tif (needle + 4 < to) {\n-\t\t\tut32 n1 = r_read_le32 (buf + needle - from);\n+\t\tif (needle < to - 4) {\n+\t\t\tut32 n1 = r_read_le32 (buf + (needle - from));\n \t\t\tif (!n1) {\n \t\t\t\tneedle += 4;\n \t\t\t\tcontinue;\n \t\t\t}\n \t\t}\n-\t\trc = r_utf8_decode (buf + needle - from, to - needle, NULL);\n+\t\trc = r_utf8_decode (buf + (needle - from), to - needle, NULL);\n \t\tif (!rc) {\n \t\t\tneedle++;\n \t\t\tcontinue;\n@@ -198,7 +198,7 @@ static int string_scan_range(RList *list, RBinFile *bf, int min,\n \t\tbool addr_aligned = !(needle % 4);\n \n \t\tif (type == R_STRING_TYPE_DETECT) {\n-\t\t\tchar *w = (char *)buf + needle + rc - from;\n+\t\t\tchar *w = (char *)buf + (needle + rc - from);\n \t\t\tif (((to - needle) > 8 + rc)) {\n \t\t\t\t// TODO: support le and be\n \t\t\t\tbool is_wide32le = (needle + rc + 2 < to) && (!w[0] && !w[1] && !w[2] && w[3] && !w[4]);\n@@ -248,7 +248,7 @@ static int string_scan_range(RList *list, RBinFile *bf, int min,\n \t\t\t\t\trc = 2;\n \t\t\t\t}\n \t\t\t} else {\n-\t\t\t\trc = r_utf8_decode (buf + needle - from, to - needle, &r);\n+\t\t\t\trc = r_utf8_decode (buf + (needle - from), to - needle, &r);\n \t\t\t\tif (rc > 1) {\n \t\t\t\t\tstr_type = R_STRING_TYPE_UTF8;\n \t\t\t\t}\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "3150642acbbe254e3c3c5d2232143fa591855ac9",
        "repo": "tensorflow/tensorflow",
        "msg": "Fix tf.raw_ops.LoadAndRemapMatrix vulnerability with invalid `row_remapping`.\n\nCheck that `row_remapping` has the correct dims().\n\nPiperOrigin-RevId: 445522800TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, the implementation of `tf.raw_ops.LoadAndRemapMatrix does not fully validate the input arguments. This results in a `CHECK`-failure which can be used to trigger a denial of service attack. The code assumes `initializing_values` is a vector but there is no validation for this before accessing its value. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.",
        "filename": "load_and_remap_matrix_op.cc",
        "diff": "diff --git a/tensorflow/core/kernels/load_and_remap_matrix_op.cc b/tensorflow/core/kernels/load_and_remap_matrix_op.cc\nindex 3fa753251c0f4f..4276e16059a9c6 100644\n--- a/tensorflow/core/kernels/load_and_remap_matrix_op.cc\n+++ b/tensorflow/core/kernels/load_and_remap_matrix_op.cc\n@@ -74,6 +74,11 @@ class LoadAndRemapMatrixOp : public OpKernel {\n     std::vector<bool> row_id_present;\n     const Tensor* row_remapping_t;\n     OP_REQUIRES_OK(context, context->input(\"row_remapping\", &row_remapping_t));\n+    OP_REQUIRES(\n+        context, row_remapping_t->dims() == 1,\n+        errors::InvalidArgument(\"The `row_remapping` tensor must be 1-D, got \"\n+                                \"a tensor of shape \",\n+                                row_remapping_t->shape().DebugString()));\n     const auto row_remapping = row_remapping_t->vec<int64_t>();\n     OP_REQUIRES(context, row_remapping.size() == num_rows_,\n                 errors::InvalidArgument(strings::StrCat(\ndiff --git a/tensorflow/python/kernel_tests/io_ops/checkpoint_ops_test.py b/tensorflow/python/kernel_tests/io_ops/checkpoint_ops_test.py\nindex f357de2de7c845..91618f974b31a2 100644\n--- a/tensorflow/python/kernel_tests/io_ops/checkpoint_ops_test.py\n+++ b/tensorflow/python/kernel_tests/io_ops/checkpoint_ops_test.py\n@@ -227,6 +227,32 @@ def test_load_and_remap_all_missing_rows_and_cols(self):\n           np.reshape(initializing_values, (num_rows, num_cols)),\n           self.evaluate(remapped_matrix))\n \n+  def test_load_and_remap_invalid_dims(self):\n+    ckpt_path = constant_op.constant(\n+        '/tmp/warm_starting_util_test5kl2a3pc/tmpph76tep2/model-0',\n+        shape=[],\n+        dtype=dtypes.string)\n+    old_tensor_name = constant_op.constant(\n+        '/tmp/warm_starting_util_test5kl2a3pc/tmpph76tep2/model-0',\n+        shape=[],\n+        dtype=dtypes.string)\n+    row_remapping = constant_op.constant(0, shape=[], dtype=dtypes.int64)\n+    col_remapping = constant_op.constant(3, shape=[3], dtype=dtypes.int64)\n+    initializing_values = constant_op.constant([],\n+                                               shape=[0, 1],\n+                                               dtype=dtypes.float32)\n+    with self.cached_session(), self.assertRaisesRegex(\n+        (ValueError, errors.InvalidArgumentError), 'tensor must be 1-D'):\n+      self.evaluate(\n+          gen_checkpoint_ops.load_and_remap_matrix(\n+              ckpt_path=ckpt_path,\n+              old_tensor_name=old_tensor_name,\n+              row_remapping=row_remapping,\n+              col_remapping=col_remapping,\n+              initializing_values=initializing_values,\n+              num_rows=1,\n+              num_cols=1))\n+\n   @test_util.run_deprecated_v1\n   def test_load_and_remap_invalid_remapping(self):\n     \"\"\"Tests that errors are raised when an ID maps to multiple new IDs.\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "87158f43f05f2720a374f3e6d22a7aaa3a33f750",
        "repo": "tensorflow/tensorflow",
        "msg": "Prevent heap OOB in sparse reduction ops.\n\nPiperOrigin-RevId: 387934524\nChange-Id: I894aa30f1e454f09b471d565b4a325da49322c1aTensorFlow is an end-to-end open source platform for machine learning. In affected versions the implementation of sparse reduction operations in TensorFlow can trigger accesses outside of bounds of heap allocated data. The [implementation](https://github.com/tensorflow/tensorflow/blob/a1bc56203f21a5a4995311825ffaba7a670d7747/tensorflow/core/kernels/sparse_reduce_op.cc#L217-L228) fails to validate that each reduction group does not overflow and that each corresponding index does not point to outside the bounds of the input tensor. We have patched the issue in GitHub commit 87158f43f05f2720a374f3e6d22a7aaa3a33f750. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "filename": "sparse_reduce_op.cc",
        "diff": "diff --git a/tensorflow/core/kernels/sparse_reduce_op.cc b/tensorflow/core/kernels/sparse_reduce_op.cc\nindex 668ea5ae54084c..430be0a271742e 100644\n--- a/tensorflow/core/kernels/sparse_reduce_op.cc\n+++ b/tensorflow/core/kernels/sparse_reduce_op.cc\n@@ -219,7 +219,20 @@ class SparseReduceOp : public OpKernel {\n     sp.Reorder<T>(reduction.reorder_dims);\n     for (const auto &g : sp.group(reduction.group_by_dims)) {\n       Op::template Run<T>(ctx, reduced_val, g.template values<T>());\n+      OP_REQUIRES(ctx,\n+                  output_strides.empty() ||\n+                  (g.group().size() == output_strides.size()),\n+                  errors::Internal(\n+                      \"Expected group size and output_strides size to match\",\n+                      \", but got \", g.group().size(), \" and \",\n+                      output_strides.size()));\n       const int64_t idx = CoordinatesToFlatIndex(g.group(), output_strides);\n+      OP_REQUIRES(ctx,\n+                  idx >= 0 && idx < out_flat.size(),\n+                  errors::Internal(\n+                      \"Obtained a write index of \", idx,\n+                      \" which is outside of bounds of [0, \",\n+                      out_flat.size(), \")\"));\n       out_flat(idx) = reduced_val();\n       VLOG(2) << \"coords: \" << absl::StrJoin(g.group(), \",\")\n               << \"; idx: \" << idx << \"; group \" << Op::Name() << \": \"\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "0f931751fb20f565c4e94aa6df58d54a003cdb30",
        "repo": "tensorflow/tensorflow",
        "msg": "Validate dimensions of input tensor in `FractionalAvgPoolGrad`\n\nPiperOrigin-RevId: 388286227\nChange-Id: Ieb7566155e92acc8993a2212c76deacadc0edc8aTensorFlow is an end-to-end open source platform for machine learning. In affected versions the implementation for `tf.raw_ops.FractionalAvgPoolGrad` can be tricked into accessing data outside of bounds of heap allocated buffers. The [implementation](https://github.com/tensorflow/tensorflow/blob/f24faa153ad31a4b51578f8181d3aaab77a1ddeb/tensorflow/core/kernels/fractional_avg_pool_op.cc#L205) does not validate that the input tensor is non-empty. Thus, code constructs an empty `EigenDoubleMatrixMap` and then accesses this buffer with indices that are outside of the empty area. We have patched the issue in GitHub commit 0f931751fb20f565c4e94aa6df58d54a003cdb30. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "filename": "fractional_avg_pool_op.cc",
        "diff": "diff --git a/tensorflow/core/kernels/fractional_avg_pool_op.cc b/tensorflow/core/kernels/fractional_avg_pool_op.cc\nindex 3c80e87bcf76dc..63f8d67d93cc47 100644\n--- a/tensorflow/core/kernels/fractional_avg_pool_op.cc\n+++ b/tensorflow/core/kernels/fractional_avg_pool_op.cc\n@@ -271,6 +271,18 @@ class FractionalAvgPoolGradOp : public OpKernel {\n     const int64_t in_rows = orig_input_tensor_shape_flat(1);\n     const int64_t in_cols = orig_input_tensor_shape_flat(2);\n     const int64_t in_depth = orig_input_tensor_shape_flat(3);\n+    OP_REQUIRES(\n+        context, in_batch != 0,\n+        errors::InvalidArgument(\"Batch dimension of input must not be 0\"));\n+    OP_REQUIRES(\n+        context, in_rows != 0,\n+        errors::InvalidArgument(\"Rows dimension of input must not be 0\"));\n+    OP_REQUIRES(\n+        context, in_cols != 0,\n+        errors::InvalidArgument(\"Columns dimension of input must not be 0\"));\n+    OP_REQUIRES(\n+        context, in_depth != 0,\n+        errors::InvalidArgument(\"Depth dimension of input must not be 0\"));\n \n     constexpr int tensor_in_and_out_dims = 4;\n     // Transform orig_input_tensor_shape into TensorShape\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "429f009d2b2c09028647dd4bb7b3f6f414bbaad7",
        "repo": "tensorflow/tensorflow",
        "msg": "Add remaining missing validation to `BoostedTreesCalculateBestFeatureSplit`\n\nPiperOrigin-RevId: 387423006\nChange-Id: I8eaf30efb223011519e60707bfa751b275d3a443TensorFlow is an end-to-end open source platform for machine learning. In affected versions an attacker can generate undefined behavior via a reference binding to nullptr in `BoostedTreesCalculateBestGainsPerFeature` and similar attack can occur in `BoostedTreesCalculateBestFeatureSplitV2`. The [implementation](https://github.com/tensorflow/tensorflow/blob/84d053187cb80d975ef2b9684d4b61981bca0c41/tensorflow/core/kernels/boosted_trees/stats_ops.cc) does not validate the input values. We have patched the issue in GitHub commit 9c87c32c710d0b5b53dc6fd3bfde4046e1f7a5ad and in commit 429f009d2b2c09028647dd4bb7b3f6f414bbaad7. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "filename": "stats_ops.cc",
        "diff": "diff --git a/tensorflow/core/kernels/boosted_trees/stats_ops.cc b/tensorflow/core/kernels/boosted_trees/stats_ops.cc\nindex 2636909855a386..60c1d191f5232c 100644\n--- a/tensorflow/core/kernels/boosted_trees/stats_ops.cc\n+++ b/tensorflow/core/kernels/boosted_trees/stats_ops.cc\n@@ -14,6 +14,7 @@ limitations under the License.\n ==============================================================================*/\n \n #include <limits>\n+#include <string>\n #include <vector>\n \n #include \"third_party/eigen3/Eigen/Core\"\n@@ -22,6 +23,7 @@ limitations under the License.\n #include \"tensorflow/core/framework/tensor_shape.h\"\n #include \"tensorflow/core/kernels/boosted_trees/boosted_trees.pb.h\"\n #include \"tensorflow/core/kernels/boosted_trees/tree_helper.h\"\n+#include \"tensorflow/core/platform/errors.h\"\n #include \"tensorflow/core/platform/logging.h\"\n \n namespace tensorflow {\n@@ -254,12 +256,18 @@ class BoostedTreesCalculateBestFeatureSplitOp : public OpKernel {\n     // node_id_range\n     const Tensor* node_id_range_t;\n     OP_REQUIRES_OK(context, context->input(\"node_id_range\", &node_id_range_t));\n+    OP_REQUIRES(\n+        context, node_id_range_t->NumElements() == 2,\n+        errors::InvalidArgument(\"node_id_range argument must have shape [2]\"));\n     const auto node_id_range = node_id_range_t->vec<int32>();\n     const int32_t node_id_first = node_id_range(0);  // inclusive\n     const int32_t node_id_last = node_id_range(1);   // exclusive\n \n     const Tensor* stats_summary_t;\n     OP_REQUIRES_OK(context, context->input(\"stats_summary\", &stats_summary_t));\n+    OP_REQUIRES(\n+        context, stats_summary_t->shape().dims() == 4,\n+        errors::InvalidArgument(\"stats_summary argument must have rank 4\"));\n     TTypes<float, 4>::ConstTensor stats_summary =\n         stats_summary_t->tensor<float, 4>();\n     const int32_t feature_dims = stats_summary_t->dim_size(1);\n@@ -272,6 +280,8 @@ class BoostedTreesCalculateBestFeatureSplitOp : public OpKernel {\n \n     const Tensor* l1_t;\n     OP_REQUIRES_OK(context, context->input(\"l1\", &l1_t));\n+    OP_REQUIRES(context, l1_t->NumElements() == 1,\n+                errors::InvalidArgument(\"l1 argument must be a scalar\"));\n     const auto l1 = l1_t->scalar<float>()();\n     DCHECK_GE(l1, 0);\n     if (logits_dim_ > 1) {\n@@ -281,17 +291,25 @@ class BoostedTreesCalculateBestFeatureSplitOp : public OpKernel {\n \n     const Tensor* l2_t;\n     OP_REQUIRES_OK(context, context->input(\"l2\", &l2_t));\n+    OP_REQUIRES(context, l2_t->NumElements() == 1,\n+                errors::InvalidArgument(\"l2 argument must be a scalar\"));\n     const auto l2 = l2_t->scalar<float>()();\n     DCHECK_GE(l2, 0);\n \n     const Tensor* tree_complexity_t;\n     OP_REQUIRES_OK(context,\n                    context->input(\"tree_complexity\", &tree_complexity_t));\n+    OP_REQUIRES(\n+        context, tree_complexity_t->NumElements() == 1,\n+        errors::InvalidArgument(\"tree_complexity argument must be a scalar\"));\n     const auto tree_complexity = tree_complexity_t->scalar<float>()();\n \n     const Tensor* min_node_weight_t;\n     OP_REQUIRES_OK(context,\n                    context->input(\"min_node_weight\", &min_node_weight_t));\n+    OP_REQUIRES(\n+        context, min_node_weight_t->NumElements() == 1,\n+        errors::InvalidArgument(\"min_node_weight argument must be a scalar\"));\n     const auto min_node_weight = min_node_weight_t->scalar<float>()();\n \n     std::vector<int32> output_node_ids;\n@@ -300,7 +318,7 @@ class BoostedTreesCalculateBestFeatureSplitOp : public OpKernel {\n     std::vector<int32> output_thresholds;\n     std::vector<Eigen::VectorXf> output_left_node_contribs;\n     std::vector<Eigen::VectorXf> output_right_node_contribs;\n-    std::vector<string> output_split_types;\n+    std::vector<std::string> output_split_types;\n \n     // TODO(tanzheny) parallelize the computation.\n     // Iterate each node and find the best gain per node.\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "a6240a163cb787909703d9fc649cf861f60ddd7c",
        "repo": "ImageMagick/ImageMagick",
        "msg": "https://github.com/ImageMagick/ImageMagick/issues/131Heap-based buffer overflow in the CalcMinMax function in coders/mat.c in ImageMagick before 6.9.4-0 allows remote attackers to cause a denial of service (out-of-bounds read and application crash) via a crafted mat file.",
        "filename": "mat.c",
        "diff": "diff --git a/coders/mat.c b/coders/mat.c\nindex 93a9d8710ab..9bc442274ae 100644\n--- a/coders/mat.c\n+++ b/coders/mat.c\n@@ -925,6 +925,7 @@ RestoreMSCWarning\n   }\n       }\n     } while(z-- >= 2);\n+    quantum_info=DestroyQuantumInfo(quantum_info);\n ExitLoop:\n \n \n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "5b048e87e4e55990dae6b547add4dae59f4e1c76",
        "repo": "tensorflow/tensorflow",
        "msg": "Fix a null pointer exception in SVDF\n\nThis is due to not checking that `GetVariableInput` returns non-null tensor.\n\nAlso fix a potential null pointer exception in `GetVariableInput`.\n\nPiperOrigin-RevId: 385160147\nChange-Id: Iadf3f0705b036a9014d27caa5a8bbd91f4c4c401TensorFlow is an end-to-end open source platform for machine learning. In affected versions the implementation of SVDF in TFLite is [vulnerable to a null pointer error](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/lite/kernels/svdf.cc#L300-L313). The [`GetVariableInput` function](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/lite/kernels/kernel_util.cc#L115-L119) can return a null pointer but `GetTensorData` assumes that the argument is always a valid tensor. Furthermore, because `GetVariableInput` calls [`GetMutableInput`](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/lite/kernels/kernel_util.cc#L82-L90) which might return `nullptr`, the `tensor->is_variable` expression can also trigger a null pointer exception. We have patched the issue in GitHub commit 5b048e87e4e55990dae6b547add4dae59f4e1c76. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "filename": "kernel_util.cc",
        "diff": "diff --git a/tensorflow/lite/kernels/kernel_util.cc b/tensorflow/lite/kernels/kernel_util.cc\nindex c64a49d316b217..6a53757bbdff67 100644\n--- a/tensorflow/lite/kernels/kernel_util.cc\n+++ b/tensorflow/lite/kernels/kernel_util.cc\n@@ -119,6 +119,7 @@ TfLiteStatus GetInputSafe(const TfLiteContext* context, const TfLiteNode* node,\n TfLiteTensor* GetVariableInput(TfLiteContext* context, const TfLiteNode* node,\n                                int index) {\n   TfLiteTensor* tensor = GetMutableInput(context, node, index);\n+  if (tensor == nullptr) return nullptr;\n   return tensor->is_variable ? tensor : nullptr;\n }\n \ndiff --git a/tensorflow/lite/kernels/svdf.cc b/tensorflow/lite/kernels/svdf.cc\nindex 31b8b32c98295a..6c02508e26b1da 100644\n--- a/tensorflow/lite/kernels/svdf.cc\n+++ b/tensorflow/lite/kernels/svdf.cc\n@@ -299,6 +299,7 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n                     GetTemporarySafe(context, node, /*index=*/0, &scratch));\n \n   TfLiteTensor* state = GetVariableInput(context, node, kStateTensor);\n+  TF_LITE_ENSURE(context, state != nullptr);\n   TfLiteTensor* output;\n   TF_LITE_ENSURE_OK(context,\n                     GetOutputSafe(context, node, kOutputTensor, &output));\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "5b048e87e4e55990dae6b547add4dae59f4e1c76",
        "repo": "tensorflow/tensorflow",
        "msg": "Fix a null pointer exception in SVDF\n\nThis is due to not checking that `GetVariableInput` returns non-null tensor.\n\nAlso fix a potential null pointer exception in `GetVariableInput`.\n\nPiperOrigin-RevId: 385160147\nChange-Id: Iadf3f0705b036a9014d27caa5a8bbd91f4c4c401TensorFlow is an end-to-end open source platform for machine learning. In affected versions the implementation of SVDF in TFLite is [vulnerable to a null pointer error](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/lite/kernels/svdf.cc#L300-L313). The [`GetVariableInput` function](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/lite/kernels/kernel_util.cc#L115-L119) can return a null pointer but `GetTensorData` assumes that the argument is always a valid tensor. Furthermore, because `GetVariableInput` calls [`GetMutableInput`](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/lite/kernels/kernel_util.cc#L82-L90) which might return `nullptr`, the `tensor->is_variable` expression can also trigger a null pointer exception. We have patched the issue in GitHub commit 5b048e87e4e55990dae6b547add4dae59f4e1c76. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "filename": "svdf.cc",
        "diff": "diff --git a/tensorflow/lite/kernels/kernel_util.cc b/tensorflow/lite/kernels/kernel_util.cc\nindex c64a49d316b217..6a53757bbdff67 100644\n--- a/tensorflow/lite/kernels/kernel_util.cc\n+++ b/tensorflow/lite/kernels/kernel_util.cc\n@@ -119,6 +119,7 @@ TfLiteStatus GetInputSafe(const TfLiteContext* context, const TfLiteNode* node,\n TfLiteTensor* GetVariableInput(TfLiteContext* context, const TfLiteNode* node,\n                                int index) {\n   TfLiteTensor* tensor = GetMutableInput(context, node, index);\n+  if (tensor == nullptr) return nullptr;\n   return tensor->is_variable ? tensor : nullptr;\n }\n \ndiff --git a/tensorflow/lite/kernels/svdf.cc b/tensorflow/lite/kernels/svdf.cc\nindex 31b8b32c98295a..6c02508e26b1da 100644\n--- a/tensorflow/lite/kernels/svdf.cc\n+++ b/tensorflow/lite/kernels/svdf.cc\n@@ -299,6 +299,7 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n                     GetTemporarySafe(context, node, /*index=*/0, &scratch));\n \n   TfLiteTensor* state = GetVariableInput(context, node, kStateTensor);\n+  TF_LITE_ENSURE(context, state != nullptr);\n   TfLiteTensor* output;\n   TF_LITE_ENSURE_OK(context,\n                     GetOutputSafe(context, node, kOutputTensor, &output));\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "01cff3f986259d661103412a20745928c727326f",
        "repo": "tensorflow/tensorflow",
        "msg": "Fix heap OOB due to dimension mismatch in `ResourceScatterUpdate`\n\nPiperOrigin-RevId: 388292801\nChange-Id: Id9bd7244d98d41b1517d4771850b32782c0cc949TensorFlow is an end-to-end open source platform for machine learning. In affected versions an attacker can trigger a read from outside of bounds of heap allocated data by sending invalid arguments to `tf.raw_ops.ResourceScatterUpdate`. The [implementation](https://github.com/tensorflow/tensorflow/blob/f24faa153ad31a4b51578f8181d3aaab77a1ddeb/tensorflow/core/kernels/resource_variable_ops.cc#L919-L923) has an incomplete validation of the relationship between the shapes of `indices` and `updates`: instead of checking that the shape of `indices` is a prefix of the shape of `updates` (so that broadcasting can happen), code only checks that the number of elements in these two tensors are in a divisibility relationship. We have patched the issue in GitHub commit 01cff3f986259d661103412a20745928c727326f. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "filename": "resource_variable_ops.cc",
        "diff": "diff --git a/tensorflow/core/kernels/resource_variable_ops.cc b/tensorflow/core/kernels/resource_variable_ops.cc\nindex 8b9610724e5826..b81a7a517ea6d2 100644\n--- a/tensorflow/core/kernels/resource_variable_ops.cc\n+++ b/tensorflow/core/kernels/resource_variable_ops.cc\n@@ -955,11 +955,12 @@ class ResourceScatterUpdateOp : public OpKernel {\n                         params->dim_size(0), \")\"));\n       } else {\n         int64_t num_updates = updates.NumElements();\n-        OP_REQUIRES(c, num_updates % N == 0,\n-                    errors::InvalidArgument(\n-                        \"shape of indices (\", indices.shape().DebugString(),\n-                        \") is not compatible with the shape of updates (\",\n-                        updates.shape().DebugString(), \")\"));\n+        OP_REQUIRES(\n+            c, TensorShapeUtils::StartsWith(updates.shape(), indices.shape()),\n+            errors::InvalidArgument(\n+                \"The shape of indices (\", indices.shape().DebugString(),\n+                \") must be a prefix of the shape of updates (\",\n+                updates.shape().DebugString(), \")\"));\n         auto updates_flat = updates.shaped<T, 2>({N, num_updates / N});\n \n         functor::ScatterFunctor<Device, T, Index, op> functor;\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "a3337563c705bc8e0cf32f910b3e9e3c43d962ff",
        "repo": "saschahauer/barebox",
        "msg": "password: Use crypto_memneq() to compare hashes\n\nCryptographic verifications should be time-constant so that an attacker\ncannot get information about the secrets used by observing the system,\nso use crypto_memneq() rather than memcmp() to compare password hashes.\n\nSigned-off-by: Sascha Hauer <s.hauer@pengutronix.de>common/password.c in Pengutronix barebox through 2021.07.0 leaks timing information because strncmp is used during hash comparison.",
        "filename": "password.c",
        "diff": "diff --git a/common/password.c b/common/password.c\nindex 3f05b81c0c..aea7c7ff5d 100644\n--- a/common/password.c\n+++ b/common/password.c\n@@ -18,6 +18,7 @@\n #include <init.h>\n #include <stdlib.h>\n #include <globalvar.h>\n+#include <crypto.h>\n #include <generated/passwd.h>\n #include <crypto/pbkdf2.h>\n \n@@ -311,7 +312,7 @@ static int check_passwd(unsigned char *passwd, size_t length)\n \t\tif (ret)\n \t\t\tgoto err;\n \n-\t\tif (strncmp(passwd1_sum, key, keylen) == 0)\n+\t\tif (!crypto_memneq(passwd1_sum, key, keylen))\n \t\t\tret = 1;\n \t} else {\n \t\tret = digest_digest(d, passwd, length, passwd1_sum);\n@@ -319,7 +320,7 @@ static int check_passwd(unsigned char *passwd, size_t length)\n \t\tif (ret)\n \t\t\tgoto err;\n \n-\t\tif (strncmp(passwd1_sum, passwd2_sum, hash_len) == 0)\n+\t\tif (!crypto_memneq(passwd1_sum, passwd2_sum, hash_len))\n \t\t\tret = 1;\n \t}\n \n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "a2b743f6017d7b97af1fe49087ae15f0ac634373",
        "repo": "tensorflow/tensorflow",
        "msg": "Fix heap OOB in `tf.raw_ops.RaggedGather`\n\nPiperOrigin-RevId: 388355464\nChange-Id: If14d96231d1cd7aad7c4d1c22c1bab1576b75717TensorFlow is an end-to-end open source platform for machine learning. In affected versions if the arguments to `tf.raw_ops.RaggedGather` don't determine a valid ragged tensor code can trigger a read from outside of bounds of heap allocated buffers. The [implementation](https://github.com/tensorflow/tensorflow/blob/8d72537c6abf5a44103b57b9c2e22c14f5f49698/tensorflow/core/kernels/ragged_gather_op.cc#L70) directly reads the first dimension of a tensor shape before checking that said tensor has rank of at least 1 (i.e., it is not a scalar). Furthermore, the implementation does not check that the list given by `params_nested_splits` is not an empty list of tensors. We have patched the issue in GitHub commit a2b743f6017d7b97af1fe49087ae15f0ac634373. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "filename": "ragged_gather_op.cc",
        "diff": "diff --git a/tensorflow/core/kernels/ragged_gather_op.cc b/tensorflow/core/kernels/ragged_gather_op.cc\nindex 3bf82cba050e3b..d6d51c770bbb7a 100644\n--- a/tensorflow/core/kernels/ragged_gather_op.cc\n+++ b/tensorflow/core/kernels/ragged_gather_op.cc\n@@ -58,15 +58,21 @@ class RaggedGatherOpBase : public OpKernel {\n \n   void Compute(OpKernelContext* context) override {\n     // Get the input Tensors.\n+\n     OpInputList params_nested_splits_in;\n     OP_REQUIRES_OK(context, context->input_list(\"params_nested_splits\",\n                                                 &params_nested_splits_in));\n+    OP_REQUIRES(\n+        context, params_nested_splits_in.size() > 0,\n+        errors::InvalidArgument(\"params_nested_splits must be non empty\"));\n+\n     const Tensor& params_dense_values_in =\n         context->input(params_nested_splits_in.size());\n     const Tensor& indices_in =\n         context->input(params_nested_splits_in.size() + 1);\n \n-    DCHECK_GT(params_nested_splits_in.size(), 0);  // Enforced by REGISTER_OP.\n+    OP_REQUIRES(context, params_nested_splits_in[0].dims() > 0,\n+                errors::InvalidArgument(\"Split tensors must not be scalars\"));\n     SPLITS_TYPE num_params = params_nested_splits_in[0].dim_size(0) - 1;\n     OP_REQUIRES_OK(context, ValidateIndices(indices_in, num_params));\n \n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "65cbfac982cb1c83993a9e19aa424daee8e9f042",
        "repo": "flatpak/flatpak",
        "msg": "Ensure that bundles have metadata on install\n\nIf we have a bundle without metadata we wouldn't properly present\nthe permissions in the transaction.Flatpak is a Linux application sandboxing and distribution framework. Prior to versions 1.12.3 and 1.10.6, Flatpak doesn't properly validate that the permissions displayed to the user for an app at install time match the actual permissions granted to the app at runtime, in the case that there's a null byte in the metadata file of an app. Therefore apps can grant themselves permissions without the consent of the user. Flatpak shows permissions to the user during install by reading them from the \"xa.metadata\" key in the commit metadata. This cannot contain a null terminator, because it is an untrusted GVariant. Flatpak compares these permissions to the *actual* metadata, from the \"metadata\" file to ensure it wasn't lied to. However, the actual metadata contents are loaded in several places where they are read as simple C-style strings. That means that, if the metadata file includes a null terminator, only the content of the file from *before* the terminator gets compared to xa.metadata. Thus, any permissions that appear in the metadata file after a null terminator are applied at runtime but not shown to the user. So maliciously crafted apps can give themselves hidden permissions. Users who have Flatpaks installed from untrusted sources are at risk in case the Flatpak has a maliciously crafted metadata file, either initially or in an update. This issue is patched in versions 1.12.3 and 1.10.6. As a workaround, users can manually check the permissions of installed apps by checking the metadata file or the xa.metadata key on the commit metadata.",
        "filename": "flatpak-dir.c",
        "diff": "diff --git a/common/flatpak-dir.c b/common/flatpak-dir.c\nindex e8bf106cca..4debffea33 100644\n--- a/common/flatpak-dir.c\n+++ b/common/flatpak-dir.c\n@@ -9372,6 +9372,13 @@ flatpak_dir_ensure_bundle_remote (FlatpakDir         *self,\n   if (metadata == NULL)\n     return NULL;\n \n+  /* If we rely on metadata (to e.g. print permissions), check it exists before creating the remote */\n+  if (out_metadata && fp_metadata == NULL)\n+    {\n+      flatpak_fail_error (error, FLATPAK_ERROR_INVALID_DATA, \"No metadata in bundler header\");\n+      return NULL;\n+    }\n+\n   gpg_data = extra_gpg_data ? extra_gpg_data : included_gpg_data;\n \n   deploy_data = flatpak_dir_get_deploy_data (self, ref, FLATPAK_DEPLOY_VERSION_ANY, cancellable, NULL);\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "160c0258802d10b0600d7671b1bbea55d8e17d45",
        "repo": "postgres/postgres",
        "msg": "libpq: reject extraneous data after SSL or GSS encryption handshake.\n\nlibpq collects up to a bufferload of data whenever it reads data from\nthe socket.  When SSL or GSS encryption is requested during startup,\nany additional data received with the server's yes-or-no reply\nremained in the buffer, and would be treated as already-decrypted data\nonce the encryption handshake completed.  Thus, a man-in-the-middle\nwith the ability to inject data into the TCP connection could stuff\nsome cleartext data into the start of a supposedly encryption-protected\ndatabase session.\n\nThis could probably be abused to inject faked responses to the\nclient's first few queries, although other details of libpq's behavior\nmake that harder than it sounds.  A different line of attack is to\nexfiltrate the client's password, or other sensitive data that might\nbe sent early in the session.  That has been shown to be possible with\na server vulnerable to CVE-2021-23214.\n\nTo fix, throw a protocol-violation error if the internal buffer\nis not empty after the encryption handshake.\n\nOur thanks to Jacob Champion for reporting this problem.\n\nSecurity: CVE-2021-23222A man-in-the-middle attacker can inject false responses to the client's first few queries, despite the use of SSL certificate verification and encryption.",
        "filename": "fe-connect.c",
        "diff": "diff --git a/doc/src/sgml/protocol.sgml b/doc/src/sgml/protocol.sgml\nindex 132436c6e6842..43b74e9423e0c 100644\n--- a/doc/src/sgml/protocol.sgml\n+++ b/doc/src/sgml/protocol.sgml\n@@ -1477,6 +1477,20 @@ SELCT 1/0;<!-- this typo is intentional -->\n     and proceed without requesting <acronym>SSL</acronym>.\n    </para>\n \n+   <para>\n+    When <acronym>SSL</acronym> encryption can be performed, the server\n+    is expected to send only the single <literal>S</literal> byte and then\n+    wait for the frontend to initiate an <acronym>SSL</acronym> handshake.\n+    If additional bytes are available to read at this point, it likely\n+    means that a man-in-the-middle is attempting to perform a\n+    buffer-stuffing attack\n+    (<ulink url=\"https://www.postgresql.org/support/security/CVE-2021-23222/\">CVE-2021-23222</ulink>).\n+    Frontends should be coded either to read exactly one byte from the\n+    socket before turning the socket over to their SSL library, or to\n+    treat it as a protocol violation if they find they have read additional\n+    bytes.\n+   </para>\n+\n    <para>\n     An initial SSLRequest can also be used in a connection that is being\n     opened to send a CancelRequest message.\n@@ -1539,6 +1553,20 @@ SELCT 1/0;<!-- this typo is intentional -->\n     encryption.\n    </para>\n \n+   <para>\n+    When <acronym>GSSAPI</acronym> encryption can be performed, the server\n+    is expected to send only the single <literal>G</literal> byte and then\n+    wait for the frontend to initiate a <acronym>GSSAPI</acronym> handshake.\n+    If additional bytes are available to read at this point, it likely\n+    means that a man-in-the-middle is attempting to perform a\n+    buffer-stuffing attack\n+    (<ulink url=\"https://www.postgresql.org/support/security/CVE-2021-23222/\">CVE-2021-23222</ulink>).\n+    Frontends should be coded either to read exactly one byte from the\n+    socket before turning the socket over to their GSSAPI library, or to\n+    treat it as a protocol violation if they find they have read additional\n+    bytes.\n+   </para>\n+\n    <para>\n     An initial GSSENCRequest can also be used in a connection that is being\n     opened to send a CancelRequest message.\ndiff --git a/src/interfaces/libpq/fe-connect.c b/src/interfaces/libpq/fe-connect.c\nindex b288d346f9268..f0fdd294a401d 100644\n--- a/src/interfaces/libpq/fe-connect.c\n+++ b/src/interfaces/libpq/fe-connect.c\n@@ -3097,6 +3097,19 @@ PQconnectPoll(PGconn *conn)\n \t\t\t\tpollres = pqsecure_open_client(conn);\n \t\t\t\tif (pollres == PGRES_POLLING_OK)\n \t\t\t\t{\n+\t\t\t\t\t/*\n+\t\t\t\t\t * At this point we should have no data already buffered.\n+\t\t\t\t\t * If we do, it was received before we performed the SSL\n+\t\t\t\t\t * handshake, so it wasn't encrypted and indeed may have\n+\t\t\t\t\t * been injected by a man-in-the-middle.\n+\t\t\t\t\t */\n+\t\t\t\t\tif (conn->inCursor != conn->inEnd)\n+\t\t\t\t\t{\n+\t\t\t\t\t\tappendPQExpBufferStr(&conn->errorMessage,\n+\t\t\t\t\t\t\t\t\t\t\t libpq_gettext(\"received unencrypted data after SSL response\\n\"));\n+\t\t\t\t\t\tgoto error_return;\n+\t\t\t\t\t}\n+\n \t\t\t\t\t/* SSL handshake done, ready to send startup packet */\n \t\t\t\t\tconn->status = CONNECTION_MADE;\n \t\t\t\t\treturn PGRES_POLLING_WRITING;\n@@ -3196,6 +3209,19 @@ PQconnectPoll(PGconn *conn)\n \t\t\t\tpollres = pqsecure_open_gss(conn);\n \t\t\t\tif (pollres == PGRES_POLLING_OK)\n \t\t\t\t{\n+\t\t\t\t\t/*\n+\t\t\t\t\t * At this point we should have no data already buffered.\n+\t\t\t\t\t * If we do, it was received before we performed the GSS\n+\t\t\t\t\t * handshake, so it wasn't encrypted and indeed may have\n+\t\t\t\t\t * been injected by a man-in-the-middle.\n+\t\t\t\t\t */\n+\t\t\t\t\tif (conn->inCursor != conn->inEnd)\n+\t\t\t\t\t{\n+\t\t\t\t\t\tappendPQExpBufferStr(&conn->errorMessage,\n+\t\t\t\t\t\t\t\t\t\t\t libpq_gettext(\"received unencrypted data after GSSAPI encryption response\\n\"));\n+\t\t\t\t\t\tgoto error_return;\n+\t\t\t\t\t}\n+\n \t\t\t\t\t/* All set for startup packet */\n \t\t\t\t\tconn->status = CONNECTION_MADE;\n \t\t\t\t\treturn PGRES_POLLING_WRITING;\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "c2b31ff2d3151acb230edc3f5b1832d2c713a9e0",
        "repo": "tensorflow/tensorflow",
        "msg": "Remove a `DCHECK`-fail, log an error instead.\n\n`DCHECK` in debug mode results in crashes. TensorFlow has had multiple vulnerabilities due to this.\n\nOutside of debug mode, `DCHECK` is a no-op.\n\nA better alternative is to report an error to the log buffer and continue. This should happen both in debug mode and in prod mode.\n\nPiperOrigin-RevId: 408375925\nChange-Id: Id5b3e19c73f3fbe0cc4bba26ca44ff9607bb6356Tensorflow is an Open Source Machine Learning Framework. An attacker can trigger denial of service via assertion failure by altering a `SavedModel` on disk such that `AttrDef`s of some operation are duplicated. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "filename": "op_def_util.cc",
        "diff": "diff --git a/tensorflow/core/framework/op_def_util.cc b/tensorflow/core/framework/op_def_util.cc\nindex dcbe5f38ce88ea..6127913d9ba1f0 100644\n--- a/tensorflow/core/framework/op_def_util.cc\n+++ b/tensorflow/core/framework/op_def_util.cc\n@@ -821,9 +821,10 @@ bool RepeatedAttrDefEqual(\n     const protobuf::RepeatedPtrField<OpDef::AttrDef>& a2) {\n   std::unordered_map<string, const OpDef::AttrDef*> a1_set;\n   for (const OpDef::AttrDef& def : a1) {\n-    DCHECK(a1_set.find(def.name()) == a1_set.end())\n-        << \"AttrDef names must be unique, but '\" << def.name()\n-        << \"' appears more than once\";\n+    if (a1_set.find(def.name()) != a1_set.end()) {\n+      LOG(ERROR) << \"AttrDef names must be unique, but '\" << def.name()\n+                 << \"' appears more than once\";\n+    }\n     a1_set[def.name()] = &def;\n   }\n   for (const OpDef::AttrDef& def : a2) {\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "f68fdab93fb7f4ddb4eb438c8fe052753c9413e8",
        "repo": "tensorflow/tensorflow",
        "msg": "Add a check for pad width to be a positive value.\n\nPiperOrigin-RevId: 413275853\nChange-Id: I261a8db9dabf5ce48a806a9e58129080c9fac619Tensorflow is an Open Source Machine Learning Framework. The implementation of `StringNGrams` can be used to trigger a denial of service attack by causing an out of memory condition after an integer overflow. We are missing a validation on `pad_witdh` and that result in computing a negative value for `ngram_width` which is later used to allocate parts of the output. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "filename": "string_ngrams_op.cc",
        "diff": "diff --git a/tensorflow/core/kernels/string_ngrams_op.cc b/tensorflow/core/kernels/string_ngrams_op.cc\nindex 6acf846f95812f..07904fa04019ff 100644\n--- a/tensorflow/core/kernels/string_ngrams_op.cc\n+++ b/tensorflow/core/kernels/string_ngrams_op.cc\n@@ -152,6 +152,16 @@ class StringNGramsOp : public tensorflow::OpKernel {\n         // We don't have to worry about dynamic padding sizes here: if padding\n         // was dynamic, every sequence would have had sufficient padding to\n         // generate at least one ngram.\n+\n+        // If reached here, pad_width should be > 0, pad_width_ = -1,\n+        // which indicates max(ngram_widths) - 1 cannot be used here since\n+        // ngram_width is not known.\n+        OP_REQUIRES(\n+            context, pad_width_ >= 0,\n+            errors::InvalidArgument(\"Pad width should be >= 0 when \"\n+                                    \"preserve_short_sequences is True and \"\n+                                    \"ngram_widths are not provided, got \",\n+                                    pad_width_));\n         int ngram_width = data_length + 2 * pad_width_;\n         auto output_start = &ngrams_data[output_start_idx];\n         int num_ngrams = 1;\ndiff --git a/tensorflow/python/ops/raw_ops_test.py b/tensorflow/python/ops/raw_ops_test.py\nindex 953ab570f7d101..5097800d9ea13e 100644\n--- a/tensorflow/python/ops/raw_ops_test.py\n+++ b/tensorflow/python/ops/raw_ops_test.py\n@@ -28,7 +28,6 @@\n \n \n @test_util.run_all_in_graph_and_eager_modes\n-@test_util.disable_tfrt\n class RawOpsTest(test.TestCase, parameterized.TestCase):\n \n   def testSimple(self):\n@@ -63,8 +62,9 @@ def testDefaults(self):\n   @parameterized.parameters([[0, 8]], [[-1, 6]])\n   def testStringNGramsBadDataSplits(self, splits):\n     data = [\"aa\", \"bb\", \"cc\", \"dd\", \"ee\", \"ff\"]\n-    with self.assertRaisesRegex(errors.InvalidArgumentError,\n-                                \"Invalid split value\"):\n+    with self.assertRaisesRegex(\n+        errors.InvalidArgumentError,\n+        r\"Invalid split value|First split value must be 0\"):\n       self.evaluate(\n           gen_string_ops.string_n_grams(\n               data=data,\n@@ -76,6 +76,25 @@ def testStringNGramsBadDataSplits(self, splits):\n               pad_width=0,\n               preserve_short_sequences=False))\n \n+  def testStringSplit(self):\n+    data = [\"123456\"]\n+    data_splits = [0, 1]\n+    separator = \"a\" * 15\n+    ngram_widths = []\n+    pad_width = -5\n+    left_pad = right_pad = \"\"\n+    with self.assertRaisesRegex(errors.InvalidArgumentError,\n+                                \"Pad width should be >= 0\"):\n+      self.evaluate(gen_string_ops.string_n_grams(\n+          data=data,\n+          data_splits=data_splits,\n+          separator=separator,\n+          ngram_widths=ngram_widths,\n+          left_pad=left_pad,\n+          right_pad=right_pad,\n+          pad_width=pad_width,\n+          preserve_short_sequences=True))\n+\n   def testGetSessionHandle(self):\n     if context.executing_eagerly():\n       with self.assertRaisesRegex(\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "e4cd225557486c420f6a34411f98c575effd43dd",
        "repo": "umlaeute/v4l2loopback",
        "msg": "add explicit format specifier to printf() invocations\n\nCWE-134Depending on the way the format strings in the card label are crafted it's possible to leak kernel stack memory. There is also the possibility for DoS due to the v4l2loopback kernel module crashing when providing the card label on request (reproduce e.g. with many %s modifiers in a row).",
        "filename": "v4l2loopback.c",
        "diff": "diff --git a/v4l2loopback.c b/v4l2loopback.c\nindex 8c88ae8d..50380547 100644\n--- a/v4l2loopback.c\n+++ b/v4l2loopback.c\n@@ -756,7 +756,7 @@ static int vidioc_querycap(struct file *file, void *priv,\n \t__u32 capabilities = V4L2_CAP_STREAMING | V4L2_CAP_READWRITE;\n \n \tstrlcpy(cap->driver, \"v4l2 loopback\", sizeof(cap->driver));\n-\tsnprintf(cap->card, labellen, dev->card_label);\n+\tsnprintf(cap->card, labellen, \"%s\", dev->card_label);\n \tsnprintf(cap->bus_info, sizeof(cap->bus_info),\n \t\t \"platform:v4l2loopback-%03d\", device_nr);\n \n@@ -2494,7 +2494,7 @@ static int v4l2_loopback_add(struct v4l2_loopback_config *conf, int *ret_nr)\n \t}\n \n \tMARK();\n-\tsnprintf(dev->vdev->name, sizeof(dev->vdev->name), dev->card_label);\n+\tsnprintf(dev->vdev->name, sizeof(dev->vdev->name), \"%s\", dev->card_label);\n \n \tvdev_priv->device_nr = nr;\n \n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "045deec1cbdebb27d817008ad5df94d96a08b1bf",
        "repo": "tensorflow/tensorflow",
        "msg": "Prevent null pointer dereference in `mutable_graph_view`\n\nPiperOrigin-RevId: 409684472\nChange-Id: I577eb9d9ac470fcec0501423171e739a4ec0cb5cTensorflow is an Open Source Machine Learning Framework. Under certain scenarios, Grappler component of TensorFlow can trigger a null pointer dereference. There are 2 places where this can occur, for the same malicious alteration of a `SavedModel` file (fixing the first one would trigger the same dereference in the second place). First, during constant folding, the `GraphDef` might not have the required nodes for the binary operation. If a node is missing, the correposning `mul_*child` would be null, and the dereference in the subsequent line would be incorrect. We have a similar issue during `IsIdentityConsumingSwitch`. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "filename": "mutable_graph_view.cc",
        "diff": "diff --git a/tensorflow/core/grappler/mutable_graph_view.cc b/tensorflow/core/grappler/mutable_graph_view.cc\nindex e1eeb42e9c4f44..d70dc2e01c1484 100644\n--- a/tensorflow/core/grappler/mutable_graph_view.cc\n+++ b/tensorflow/core/grappler/mutable_graph_view.cc\n@@ -68,6 +68,9 @@ bool IsIdentityConsumingSwitch(const MutableGraphView& graph,\n     }\n \n     NodeDef* input_node = graph.GetNode(tensor_id.node());\n+    if (input_node == nullptr) {\n+      return false;\n+    }\n     return IsSwitch(*input_node);\n   }\n   return false;\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "a1e1511dde36b3f8aa27a6ec630838e7ea40e091",
        "repo": "tensorflow/tensorflow",
        "msg": "[lite] Update TfLiteIntArrayCreate to return size_t\n\nPiperOrigin-RevId: 416439896\nChange-Id: I847f69b68d1ddaff4b1e925a09b8b69c1756653bTensorflow is an Open Source Machine Learning Framework. An attacker can craft a TFLite model that would cause an integer overflow in `TfLiteIntArrayCreate`. The `TfLiteIntArrayGetSizeInBytes` returns an `int` instead of a `size_t. An attacker can control model inputs such that `computed_size` overflows the size of `int` datatype. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "filename": "common.c",
        "diff": "diff --git a/tensorflow/lite/c/common.c b/tensorflow/lite/c/common.c\nindex ef4d3ffdec555d..d149d22c567c53 100644\n--- a/tensorflow/lite/c/common.c\n+++ b/tensorflow/lite/c/common.c\n@@ -21,10 +21,10 @@ limitations under the License.\n #include <string.h>\n #endif  // TF_LITE_STATIC_MEMORY\n \n-int TfLiteIntArrayGetSizeInBytes(int size) {\n+size_t TfLiteIntArrayGetSizeInBytes(int size) {\n   static TfLiteIntArray dummy;\n \n-  int computed_size = sizeof(dummy) + sizeof(dummy.data[0]) * size;\n+  size_t computed_size = sizeof(dummy) + sizeof(dummy.data[0]) * size;\n #if defined(_MSC_VER)\n   // Context for why this is needed is in http://b/189926408#comment21\n   computed_size -= sizeof(dummy.data[0]);\n@@ -51,7 +51,7 @@ int TfLiteIntArrayEqualsArray(const TfLiteIntArray* a, int b_size,\n #ifndef TF_LITE_STATIC_MEMORY\n \n TfLiteIntArray* TfLiteIntArrayCreate(int size) {\n-  int alloc_size = TfLiteIntArrayGetSizeInBytes(size);\n+  size_t alloc_size = TfLiteIntArrayGetSizeInBytes(size);\n   if (alloc_size <= 0) return NULL;\n   TfLiteIntArray* ret = (TfLiteIntArray*)malloc(alloc_size);\n   if (!ret) return ret;\ndiff --git a/tensorflow/lite/c/common.h b/tensorflow/lite/c/common.h\nindex e02f6ef6d7c7e0..7056d1e2211323 100644\n--- a/tensorflow/lite/c/common.h\n+++ b/tensorflow/lite/c/common.h\n@@ -98,7 +98,7 @@ typedef struct TfLiteIntArray {\n \n // Given the size (number of elements) in a TfLiteIntArray, calculate its size\n // in bytes.\n-int TfLiteIntArrayGetSizeInBytes(int size);\n+size_t TfLiteIntArrayGetSizeInBytes(int size);\n \n #ifndef TF_LITE_STATIC_MEMORY\n // Create a array of a given `size` (uninitialized entries).\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "a1e1511dde36b3f8aa27a6ec630838e7ea40e091",
        "repo": "tensorflow/tensorflow",
        "msg": "[lite] Update TfLiteIntArrayCreate to return size_t\n\nPiperOrigin-RevId: 416439896\nChange-Id: I847f69b68d1ddaff4b1e925a09b8b69c1756653bTensorflow is an Open Source Machine Learning Framework. An attacker can craft a TFLite model that would cause an integer overflow in `TfLiteIntArrayCreate`. The `TfLiteIntArrayGetSizeInBytes` returns an `int` instead of a `size_t. An attacker can control model inputs such that `computed_size` overflows the size of `int` datatype. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "filename": "common.c",
        "diff": "diff --git a/tensorflow/lite/c/common.c b/tensorflow/lite/c/common.c\nindex ef4d3ffdec555d..d149d22c567c53 100644\n--- a/tensorflow/lite/c/common.c\n+++ b/tensorflow/lite/c/common.c\n@@ -21,10 +21,10 @@ limitations under the License.\n #include <string.h>\n #endif  // TF_LITE_STATIC_MEMORY\n \n-int TfLiteIntArrayGetSizeInBytes(int size) {\n+size_t TfLiteIntArrayGetSizeInBytes(int size) {\n   static TfLiteIntArray dummy;\n \n-  int computed_size = sizeof(dummy) + sizeof(dummy.data[0]) * size;\n+  size_t computed_size = sizeof(dummy) + sizeof(dummy.data[0]) * size;\n #if defined(_MSC_VER)\n   // Context for why this is needed is in http://b/189926408#comment21\n   computed_size -= sizeof(dummy.data[0]);\n@@ -51,7 +51,7 @@ int TfLiteIntArrayEqualsArray(const TfLiteIntArray* a, int b_size,\n #ifndef TF_LITE_STATIC_MEMORY\n \n TfLiteIntArray* TfLiteIntArrayCreate(int size) {\n-  int alloc_size = TfLiteIntArrayGetSizeInBytes(size);\n+  size_t alloc_size = TfLiteIntArrayGetSizeInBytes(size);\n   if (alloc_size <= 0) return NULL;\n   TfLiteIntArray* ret = (TfLiteIntArray*)malloc(alloc_size);\n   if (!ret) return ret;\ndiff --git a/tensorflow/lite/c/common.h b/tensorflow/lite/c/common.h\nindex e02f6ef6d7c7e0..7056d1e2211323 100644\n--- a/tensorflow/lite/c/common.h\n+++ b/tensorflow/lite/c/common.h\n@@ -98,7 +98,7 @@ typedef struct TfLiteIntArray {\n \n // Given the size (number of elements) in a TfLiteIntArray, calculate its size\n // in bytes.\n-int TfLiteIntArrayGetSizeInBytes(int size);\n+size_t TfLiteIntArrayGetSizeInBytes(int size);\n \n #ifndef TF_LITE_STATIC_MEMORY\n // Create a array of a given `size` (uninitialized entries).\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "ba4e8ac4dc2991e350d5cc407f8598c8d4ee70fb",
        "repo": "tensorflow/tensorflow",
        "msg": "Fix potential divide by zero error when executing FractionalMaxPool, when pooling ratio is higher than input size for a particular dimension.\n\nPiperOrigin-RevId: 412151722\nChange-Id: I06e57cbb8eca43816eff79eac264fa7aae8f7163Tensorflow is an Open Source Machine Learning Framework. The implementation of `FractionalMaxPool` can be made to crash a TensorFlow process via a division by 0. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "filename": "fractional_max_pool_op.cc",
        "diff": "diff --git a/tensorflow/core/kernels/fractional_max_pool_op.cc b/tensorflow/core/kernels/fractional_max_pool_op.cc\nindex 7519c84667409f..0722c408fba9d4 100644\n--- a/tensorflow/core/kernels/fractional_max_pool_op.cc\n+++ b/tensorflow/core/kernels/fractional_max_pool_op.cc\n@@ -83,6 +83,13 @@ class FractionalMaxPoolOp : public OpKernel {\n     std::vector<int> output_size(tensor_in_and_out_dims);\n     for (int i = 0; i < tensor_in_and_out_dims; ++i) {\n       input_size[i] = tensor_in.dim_size(i);\n+\n+      OP_REQUIRES(\n+          context, input_size[i] >= pooling_ratio_[i],\n+          errors::InvalidArgument(\"Pooling ratio is higher than input \"\n+                                  \"dimension size for dimension \",\n+                                  i, \". Input dim size: \", input_size[i],\n+                                  \" pooling ratio: \", pooling_ratio_[i]));\n     }\n     // Output size.\n     for (int i = 0; i < tensor_in_and_out_dims; ++i) {\ndiff --git a/tensorflow/python/kernel_tests/nn_ops/fractional_max_pool_op_test.py b/tensorflow/python/kernel_tests/nn_ops/fractional_max_pool_op_test.py\nindex f5b5bd92a283ea..5acacdbb7463b2 100644\n--- a/tensorflow/python/kernel_tests/nn_ops/fractional_max_pool_op_test.py\n+++ b/tensorflow/python/kernel_tests/nn_ops/fractional_max_pool_op_test.py\n@@ -20,6 +20,7 @@\n \n from tensorflow.python.framework import constant_op\n from tensorflow.python.framework import dtypes\n+from tensorflow.python.framework import errors\n from tensorflow.python.framework import test_util\n from tensorflow.python.ops import array_ops\n from tensorflow.python.ops import gen_nn_ops\n@@ -319,6 +320,24 @@ def testDeterminismExceptionThrowing(self):\n       nn_ops.fractional_max_pool(\n           rand_mat, [1, 1.5, 1.5, 1], seed=1, seed2=1, deterministic=True)\n \n+  def testPoolingRatio(self):\n+    with self.cached_session() as _:\n+      with self.assertRaisesRegex(\n+          errors.InvalidArgumentError,\n+          r\"Pooling ratio is higher than input dimension size for dimension 1.*\"\n+      ):\n+        result = nn_ops.gen_nn_ops.fractional_max_pool(\n+            value=constant_op.constant(\n+                value=[[[[1, 4, 2, 3]]]], dtype=dtypes.int64),\n+            pooling_ratio=[1.0, 1.44, 1.73, 1.0],\n+            pseudo_random=False,\n+            overlapping=False,\n+            deterministic=False,\n+            seed=0,\n+            seed2=0,\n+            name=None)\n+        self.evaluate(result)\n+\n \n class FractionalMaxPoolGradTest(test.TestCase):\n   \"\"\"Tests for FractionalMaxPoolGrad.\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "29c8abce0da56b536542f76a9ddfebdaab5b2943",
        "repo": "ImageMagick/ImageMagick6",
        "msg": "https://github.com/ImageMagick/ImageMagick/pull/4986A vulnerability was found in ImageMagick, causing an outside the range of representable values of type 'unsigned long' at coders/pcl.c, when crafted or untrusted input is processed. This leads to a negative impact to application availability or other problems related to undefined behavior.",
        "filename": "pcl.c",
        "diff": "diff --git a/coders/pcl.c b/coders/pcl.c\nindex 5e57086e45..a7456dae6c 100644\n--- a/coders/pcl.c\n+++ b/coders/pcl.c\n@@ -295,8 +295,8 @@ static Image *ReadPCLImage(const ImageInfo *image_info,ExceptionInfo *exception)\n     /*\n       Set PCL render geometry.\n     */\n-    width=(size_t) floor(bounds.x2-bounds.x1+0.5);\n-    height=(size_t) floor(bounds.y2-bounds.y1+0.5);\n+    width=(size_t) CastDoubleToLong(floor(bounds.x2-bounds.x1+0.5));\n+    height=(size_t) CastDoubleToLong(floor(bounds.y2-bounds.y1+0.5));\n     if (width > page.width)\n       page.width=width;\n     if (height > page.height)\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "64a2e1b799352ac7d7aad1989bc06e7b0f2b01db",
        "repo": "gpac/gpac",
        "msg": "fixed #2092NULL Pointer Dereference in GitHub repository gpac/gpac prior to 1.1.0.",
        "filename": "box_code_base.c",
        "diff": "diff --git a/src/isomedia/box_code_base.c b/src/isomedia/box_code_base.c\nindex b3c38310ad..126084b0ea 100644\n--- a/src/isomedia/box_code_base.c\n+++ b/src/isomedia/box_code_base.c\n@@ -11083,10 +11083,12 @@ void gitn_box_del(GF_Box *s)\n \tu32 i;\n \tGroupIdToNameBox *ptr = (GroupIdToNameBox *)s;\n \tif (ptr == NULL) return;\n-\tfor (i=0; i<ptr->nb_entries; i++) {\n-\t\tif (ptr->entries[i].name) gf_free(ptr->entries[i].name);\n+\tif (ptr->entries) {\n+\t\tfor (i=0; i<ptr->nb_entries; i++) {\n+\t\t\tif (ptr->entries[i].name) gf_free(ptr->entries[i].name);\n+\t\t}\n+\t\tgf_free(ptr->entries);\n \t}\n-\tif (ptr->entries) gf_free(ptr->entries);\n \tgf_free(ptr);\n }\n \n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "965b97e4a9650495cda5a8c210ef6684b4b9eceb",
        "repo": "tensorflow/tensorflow",
        "msg": "Properly validate sparse tensor in `SparseTensorSliceDataset`\n\nExisting validation was incomplete.\n\nPiperOrigin-RevId: 415375048\nChange-Id: I14cd18f29ede73286f3ffac35171bd15828997e9Tensorflow is an Open Source Machine Learning Framework. The implementation of `SparseTensorSliceDataset` has an undefined behavior: under certain condition it can be made to dereference a `nullptr` value. The 3 input arguments to `SparseTensorSliceDataset` represent a sparse tensor. However, there are some preconditions that these arguments must satisfy but these are not validated in the implementation. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "filename": "sparse_tensor_slice_dataset_op.cc",
        "diff": "diff --git a/tensorflow/core/kernels/data/sparse_tensor_slice_dataset_op.cc b/tensorflow/core/kernels/data/sparse_tensor_slice_dataset_op.cc\nindex c8f3db30c37f4d..c6901de5c34267 100644\n--- a/tensorflow/core/kernels/data/sparse_tensor_slice_dataset_op.cc\n+++ b/tensorflow/core/kernels/data/sparse_tensor_slice_dataset_op.cc\n@@ -240,28 +240,29 @@ class SparseTensorSliceDatasetOp : public DatasetOpKernel {\n     OP_REQUIRES_OK(ctx, ctx->input(\"dense_shape\", &dense_shape));\n \n     OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(indices->shape()),\n-                errors::InvalidArgument(\n-                    \"Input indices should be a matrix but received shape \",\n-                    indices->shape().DebugString()));\n-\n-    const auto num_indices = indices->NumElements();\n-    const auto num_values = values->NumElements();\n-    if (num_indices == 0 || num_values == 0) {\n-      OP_REQUIRES(ctx, num_indices == num_values,\n-                  errors::InvalidArgument(\n-                      \"If indices or values are empty, the other one must also \"\n-                      \"be. Got indices of shape \",\n-                      indices->shape().DebugString(), \" and values of shape \",\n-                      values->shape().DebugString()));\n-    }\n+                errors::InvalidArgument(\"Input indices must be a matrix. Got: \",\n+                                        indices->shape().DebugString()));\n     OP_REQUIRES(ctx, TensorShapeUtils::IsVector(values->shape()),\n-                errors::InvalidArgument(\n-                    \"Input values should be a vector but received shape \",\n-                    indices->shape().DebugString()));\n+                errors::InvalidArgument(\"Input values must be a vector. Got: \",\n+                                        values->shape().DebugString()));\n     OP_REQUIRES(ctx, TensorShapeUtils::IsVector(dense_shape->shape()),\n+                errors::InvalidArgument(\"Input shape must be a vector. Got: \",\n+                                        dense_shape->shape().DebugString()));\n+    OP_REQUIRES(\n+        ctx, values->shape().dim_size(0) == indices->shape().dim_size(0),\n+        errors::InvalidArgument(\n+            \"Number of values must match first dimension of indices. \", \"Got \",\n+            values->shape().dim_size(0),\n+            \" values, indices shape: \", indices->shape().DebugString()));\n+    OP_REQUIRES(\n+        ctx, dense_shape->shape().dim_size(0) == indices->shape().dim_size(1),\n+        errors::InvalidArgument(\n+            \"Number of dimensions must match second dimension of indices. \",\n+            \"Got \", dense_shape->shape().dim_size(0),\n+            \" dimensions, indices shape: \", indices->shape().DebugString()));\n+    OP_REQUIRES(ctx, dense_shape->NumElements() > 0,\n                 errors::InvalidArgument(\n-                    \"Input shape should be a vector but received shape \",\n-                    dense_shape->shape().DebugString()));\n+                    \"The shape argument requires at least one element.\"));\n \n     // We currently ensure that `sparse_tensor` is ordered in the\n     // batch dimension.\ndiff --git a/tensorflow/python/data/kernel_tests/from_sparse_tensor_slices_test.py b/tensorflow/python/data/kernel_tests/from_sparse_tensor_slices_test.py\nindex 04f2c27bb9fe72..3d8ee43272fbf8 100644\n--- a/tensorflow/python/data/kernel_tests/from_sparse_tensor_slices_test.py\n+++ b/tensorflow/python/data/kernel_tests/from_sparse_tensor_slices_test.py\n@@ -134,6 +134,25 @@ def testEmptySparseTensorSlicesInvalid(self):\n       with self.assertRaises(errors.InvalidArgumentError):\n         sess.run(init_op, feed_dict={st: sparse_feed})\n \n+  @combinations.generate(combinations.combine(tf_api_version=1, mode=[\"graph\"]))\n+  def testEmptySparseTensorSlicesInvalid2(self):\n+    \"\"\"Test a dataset based on invalid `tf.sparse.SparseTensor`.\"\"\"\n+    st = array_ops.sparse_placeholder(dtypes.float64)\n+    iterator = dataset_ops.make_initializable_iterator(\n+        dataset_ops.Dataset.from_sparse_tensor_slices(st))\n+    init_op = iterator.initializer\n+\n+    with self.cached_session() as sess:\n+      # Test with an empty sparse tensor but with non empty values.\n+      empty_indices = [[]]\n+      empty_values = []\n+      dense_shape = [1, 1]\n+      sparse_feed = sparse_tensor.SparseTensorValue(empty_indices, empty_values,\n+                                                    dense_shape)\n+      # Here, we expect the test to fail when running the feed.\n+      with self.assertRaises(errors.InvalidArgumentError):\n+        sess.run(init_op, feed_dict={st: sparse_feed})\n+\n   @combinations.generate(combinations.combine(tf_api_version=2, mode=[\"eager\"]))\n   def testFromSparseTensorSlicesError(self):\n     with self.assertRaises(AttributeError):\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "9904cb6d2eb40f679d8ff6557c22d53a3e3dc75a",
        "repo": "weechat/weechat",
        "msg": "irc: fix crash when receiving a malformed message 352 (who)\n\nThanks to Stuart Nevans Locke for reporting the issue.A Vulnerability of LG Electronic web OS TV Emulator could allow an attacker to escalate privileges and overwrite certain files. This vulnerability is due to wrong environment setting. An attacker could exploit this vulnerability through crafted configuration files and executable files.",
        "filename": "irc-protocol.c",
        "diff": "diff --git a/ChangeLog.adoc b/ChangeLog.adoc\nindex 862c4d429b2..475255e7431 100644\n--- a/ChangeLog.adoc\n+++ b/ChangeLog.adoc\n@@ -31,6 +31,7 @@ Bug fixes::\n   * core: fix memory leak in completion\n   * core: flush stdout/stderr before forking in hook_process function (issue #1441)\n   * core: fix evaluation of condition with nested \"if\" (issue #1434)\n+  * irc: fix crash when receiving a malformed message 352 (who)\n   * irc: fix crash when a new message 005 is received with longer nick prefixes\n   * irc: fix crash when receiving a malformed message 324 (channel mode)\n   * irc: add nick changes in the hotlist (except self nick change)\ndiff --git a/src/plugins/irc/irc-protocol.c b/src/plugins/irc/irc-protocol.c\nindex 05433d34e94..9238e8802f1 100644\n--- a/src/plugins/irc/irc-protocol.c\n+++ b/src/plugins/irc/irc-protocol.c\n@@ -4689,7 +4689,7 @@ IRC_PROTOCOL_CALLBACK(352)\n \n     if (argc > 8)\n     {\n-        arg_start = (strcmp (argv[8], \"*\") == 0) ? 9 : 8;\n+        arg_start = ((argc > 9) && (strcmp (argv[8], \"*\") == 0)) ? 9 : 8;\n         if (argv[arg_start][0] == ':')\n         {\n             pos_attr = NULL;\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "dabd48caf74995e605f1700344f1ff4a5d83441d",
        "repo": "facebook/hhvm",
        "msg": "Fix a json_decode crash when depth==0\n\nSummary:\nSetting depth=0 is an error, and should result in NULL, but we weren't\nchecking for it, so in the case of a single, top-level string, we\nwould reading the -1th element of the stack.\n\nDifferential Revision: D19609959\n\nfbshipit-source-id: 04ca1e0965e04b44df2d5c806a73c3da99ff66fbInsufficient boundary checks when decoding JSON in JSON_parser allows read access to out of bounds memory, potentially leading to information leak and DOS. This issue affects HHVM 4.45.0, 4.44.0, 4.43.0, 4.42.0, 4.41.0, 4.40.0, 4.39.0, versions between 4.33.0 and 4.38.0 (inclusive), versions between 4.9.0 and 4.32.0 (inclusive), and versions prior to 4.8.7.",
        "filename": "JSON_parser.cpp",
        "diff": "diff --git a/hphp/runtime/ext/json/JSON_parser.cpp b/hphp/runtime/ext/json/JSON_parser.cpp\nindex b1b4f51b2e5dc..5d3b3cfb25a2f 100644\n--- a/hphp/runtime/ext/json/JSON_parser.cpp\n+++ b/hphp/runtime/ext/json/JSON_parser.cpp\n@@ -1148,6 +1148,10 @@ bool JSON_parser(Variant &z, const char *p, int length, bool const assoc,\n   // they exceed kMaxPersistentStringBufferCapacity at exit or if the thread\n   // is explicitly flushed (e.g., due to being idle).\n   json->initSb(length);\n+  if (depth <= 0) {\n+    json->error_code = json_error_codes::JSON_ERROR_DEPTH;\n+    return false;\n+  }\n   SCOPE_EXIT {\n     constexpr int kMaxPersistentStringBufferCapacity = 256 * 1024;\n     if (json->sb_cap > kMaxPersistentStringBufferCapacity) json->flushSb();\ndiff --git a/hphp/test/slow/ext_json/decode_crash.php b/hphp/test/slow/ext_json/decode_crash.php\nnew file mode 100644\nindex 0000000000000..9944145e454ef\n--- /dev/null\n+++ b/hphp/test/slow/ext_json/decode_crash.php\n@@ -0,0 +1,3 @@\n+<?hh\n+\n+var_dump(json_decode('\"a\"', false, 0, 0));\ndiff --git a/hphp/test/slow/ext_json/decode_crash.php.expect b/hphp/test/slow/ext_json/decode_crash.php.expect\nnew file mode 100644\nindex 0000000000000..7951defec192a\n--- /dev/null\n+++ b/hphp/test/slow/ext_json/decode_crash.php.expect\n@@ -0,0 +1 @@\n+NULL\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "dbeb9a56a638e3fdcef8b691c2a2967132dae692",
        "repo": "facebook/hhvm",
        "msg": "string_number_format: Correctly handles return value of snprintf\n\nSummary: `snprintf` can return a value greater than the number of bytes copied. In case the first byte of the string is not a digit (could be '-'), size of `tmpstr` was being updated without checking `tmplen`. This resulted in either an assertion error or a heap overflow depending on whether the assertion is compiled or not.\n\nReviewed By: mofarrell, qianxuweiren\n\nDifferential Revision: D17327899\n\nfbshipit-source-id: ee53875d21e02608c6d870388eecf1464de24ff1Insufficient boundary checks when formatting numbers in number_format allows read/write access to out-of-bounds memory, potentially leading to remote code execution. This issue affects HHVM versions prior to 3.30.10, all versions between 4.0.0 and 4.8.5, all versions between 4.9.0 and 4.18.2, and versions 4.19.0, 4.19.1, 4.20.0, 4.20.1, 4.20.2, 4.21.0, 4.22.0, 4.23.0.",
        "filename": "zend-string.cpp",
        "diff": "diff --git a/hphp/runtime/base/zend-string.cpp b/hphp/runtime/base/zend-string.cpp\nindex 8a5ec8933691b..7caef317c51fd 100644\n--- a/hphp/runtime/base/zend-string.cpp\n+++ b/hphp/runtime/base/zend-string.cpp\n@@ -1618,11 +1618,15 @@ String string_number_format(double d, int dec,\n   d = php_math_round(d, dec);\n \n   // departure from PHP: we got rid of dependencies on spprintf() here.\n+  // This actually means 63 bytes for characters + 1 byte for '\\0'\n   String tmpstr(63, ReserveString);\n   tmpbuf = tmpstr.mutableData();\n   tmplen = snprintf(tmpbuf, 64, \"%.*F\", dec, d);\n+  // From the man page of snprintf, the return value is:\n+  // The number of characters that would have been written if n had been\n+  // sufficiently large, not counting the terminating null character.\n   if (tmplen < 0) return empty_string();\n-  if (tmpbuf == nullptr || !isdigit((int)tmpbuf[0])) {\n+  if (tmplen < 64 && (tmpbuf == nullptr || !isdigit((int)tmpbuf[0]))) {\n     tmpstr.setSize(tmplen);\n     return tmpstr;\n   }\ndiff --git a/hphp/test/slow/string/number_format_t53795309.php b/hphp/test/slow/string/number_format_t53795309.php\nnew file mode 100644\nindex 0000000000000..c6fee71a722f0\n--- /dev/null\n+++ b/hphp/test/slow/string/number_format_t53795309.php\n@@ -0,0 +1,9 @@\n+<?hh\n+// Copyright 2004-present Facebook. All Rights Reserved.\n+\n+<<__EntryPoint>>\n+function main() {\n+  $bin_repr = \"\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x80\";\n+  $double_num = unpack(\"dnum\", $bin_repr)['num'];\n+  var_dump(number_format($double_num, 100));\n+}\ndiff --git a/hphp/test/slow/string/number_format_t53795309.php.expect b/hphp/test/slow/string/number_format_t53795309.php.expect\nnew file mode 100644\nindex 0000000000000..f4417f7682bb5\n--- /dev/null\n+++ b/hphp/test/slow/string/number_format_t53795309.php.expect\n@@ -0,0 +1 @@\n+string(103) \"-0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\"\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "7882080388be5088e72c425b02223c02e6cb4295",
        "repo": "bonzini/qemu",
        "msg": "virtio-serial: fix ANY_LAYOUT\n\nDon't assume a specific layout for control messages.\nRequired by virtio 1.\n\nSigned-off-by: Michael S. Tsirkin <mst@redhat.com>\nReviewed-by: Amit Shah <amit.shah@redhat.com>\nReviewed-by: Jason Wang <jasowang@redhat.com>Buffer overflow in the send_control_msg function in hw/char/virtio-serial-bus.c in QEMU before 2.4.0 allows guest users to cause a denial of service (QEMU process crash) via a crafted virtio control message.",
        "filename": "virtio-serial-bus.c",
        "diff": "diff --git a/hw/char/virtio-serial-bus.c b/hw/char/virtio-serial-bus.c\nindex 78c73e5abe01..929e49c67165 100644\n--- a/hw/char/virtio-serial-bus.c\n+++ b/hw/char/virtio-serial-bus.c\n@@ -195,7 +195,8 @@ static size_t send_control_msg(VirtIOSerial *vser, void *buf, size_t len)\n         return 0;\n     }\n \n-    memcpy(elem.in_sg[0].iov_base, buf, len);\n+    /* TODO: detect a buffer that's too short, set NEEDS_RESET */\n+    iov_from_buf(elem.in_sg, elem.in_num, 0, buf, len);\n \n     virtqueue_push(vq, &elem, len);\n     virtio_notify(VIRTIO_DEVICE(vser), vq);\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "a5b89cd68c02329d793356bda85d079e9e69b4e7",
        "repo": "tensorflow/tensorflow",
        "msg": "Fix empty resource handle vulnerability.\n\nSome ops that attempt to extract a resource handle from user input\ncan lead to nullptr dereferences.  This returns an error in such\na case.\n\nPiperOrigin-RevId: 445571938TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, multiple TensorFlow operations misbehave in eager mode when the resource handle provided to them is invalid. In graph mode, it would have been impossible to perform these API calls, but migration to TF 2.x eager mode opened up this vulnerability. If the resource handle is empty, then a reference is bound to a null pointer inside TensorFlow codebase (various codepaths). This is undefined behavior. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.",
        "filename": "execute.cc",
        "diff": "diff --git a/tensorflow/core/common_runtime/eager/execute.cc b/tensorflow/core/common_runtime/eager/execute.cc\nindex dd64174a4ddeff..904996c7e64652 100644\n--- a/tensorflow/core/common_runtime/eager/execute.cc\n+++ b/tensorflow/core/common_runtime/eager/execute.cc\n@@ -304,6 +304,9 @@ Status GetDeviceForInput(const EagerOperation& op, const EagerContext& ctx,\n     const Tensor* tensor;\n     // TODO(fishx): Avoid blocking here.\n     TF_RETURN_IF_ERROR(tensor_handle->Tensor(&tensor));\n+    if (tensor->NumElements() == 0) {\n+      return errors::InvalidArgument(\"Empty resource handle\");\n+    }\n     const ResourceHandle& handle = tensor->flat<ResourceHandle>()(0);\n     device_name = handle.device();\n \n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "2e00e95473861846aa8538be87db07699d9f676d",
        "repo": "nginx/njs",
        "msg": "Fixed Array.prototype.slice() with slow \"this\" argument.\n\nPreviously, when \"this\" argument was not a fast array, but the \"deleted\" array\nwas a fast array, the \"deleted\" array may be left in uninitialized state if\n\"this\" argument had gaps.\n\nThis fix is to ensure that \"deleted\" is properly initialized.\n\nThis fixes #485 issue on Github.Nginx NJS v0.7.2 was discovered to contain a segmentation violation in the function njs_value_own_enumerate at src/njs_value.c.",
        "filename": "njs_array.c",
        "diff": "diff --git a/src/njs_array.c b/src/njs_array.c\nindex 0b8c7b919..2ceb6be7e 100644\n--- a/src/njs_array.c\n+++ b/src/njs_array.c\n@@ -1284,6 +1284,11 @@ njs_array_prototype_splice(njs_vm_t *vm, njs_value_t *args, njs_uint_t nargs,\n                 if (njs_slow_path(ret == NJS_ERROR)) {\n                     return ret;\n                 }\n+\n+            } else {\n+                if (deleted->object.fast_array) {\n+                    njs_set_invalid(&deleted->start[i]);\n+                }\n             }\n         }\n \ndiff --git a/src/test/njs_unit_test.c b/src/test/njs_unit_test.c\nindex 25e066c32..b28e34fef 100644\n--- a/src/test/njs_unit_test.c\n+++ b/src/test/njs_unit_test.c\n@@ -4869,6 +4869,15 @@ static njs_unit_test_t  njs_test[] =\n               \"Array.prototype.splice.call(obj, 2**53-2, 0, 'C');\"),\n       njs_str(\"TypeError: Invalid length\") },\n \n+    { njs_str(\"var a = {1: 'B', length: 2};\"\n+              \"Array.prototype.splice.call(a, 0)\"),\n+      njs_str(\",B\") },\n+\n+    { njs_str(\"var a = new Uint8Array();\"\n+              \"a.__proto__ = [1,2,3];\"\n+              \"a.splice(0)\"),\n+      njs_str(\",,\") },\n+\n     { njs_str(\"var a = []; a.reverse()\"),\n       njs_str(\"\") },\n \n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "38b164ace7d6ae1c367883a3d67d7f559783faad",
        "repo": "mruby/mruby",
        "msg": "codegen.c: fix a bug in `gen_values()`.\n\n- Fix limit handling that fails 15 arguments method calls.\n- Fix too early argument packing in arrays.Heap-based Buffer Overflow in Homebrew mruby prior to 3.2.",
        "filename": "codegen.c",
        "diff": "diff --git a/mrbgems/mruby-compiler/core/codegen.c b/mrbgems/mruby-compiler/core/codegen.c\nindex c49ea75141..b90eae3e85 100644\n--- a/mrbgems/mruby-compiler/core/codegen.c\n+++ b/mrbgems/mruby-compiler/core/codegen.c\n@@ -1551,7 +1551,7 @@ gen_values(codegen_scope *s, node *t, int val, int limit)\n   while (t) {\n     int is_splat = nint(t->car->car) == NODE_SPLAT;\n \n-    if (is_splat || n > limit || cursp() >= slimit) { /* flush stack */\n+    if (is_splat || cursp() >= slimit) { /* flush stack */\n       pop_n(n);\n       if (first) {\n         if (n == 0) {\n@@ -1590,6 +1590,11 @@ gen_values(codegen_scope *s, node *t, int val, int limit)\n     }\n     return -1;                  /* variable length */\n   }\n+  else if (n > limit) {\n+    pop_n(n);\n+    genop_2(s, OP_ARRAY, cursp(), n);\n+    return -1;\n+  }\n   return n;\n }\n \n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "856f87c2e97a27b256482dbe0d748b1194355a21",
        "repo": "pjsip/pjproject",
        "msg": "Merge pull request from GHSA-5x45-qp78-g4p4\n\n* Prevent infinite loop in scanning xml content\n\n* Simplify scanning method\n\n* OptimizationPJSIP is a free and open source multimedia communication library written in the C language. Versions 2.12 and prior contain a denial-of-service vulnerability that affects PJSIP users that consume PJSIP's XML parsing in their apps. Users are advised to update. There are no known workarounds.",
        "filename": "xml.c",
        "diff": "diff --git a/pjlib-util/src/pjlib-util/xml.c b/pjlib-util/src/pjlib-util/xml.c\nindex b0aad26608..5c2d8eb174 100644\n--- a/pjlib-util/src/pjlib-util/xml.c\n+++ b/pjlib-util/src/pjlib-util/xml.c\n@@ -150,6 +150,8 @@ static pj_xml_node *xml_parse_node( pj_pool_t *pool, pj_scanner *scanner)\n \tpj_scan_get_until_ch(scanner, ']', &node->content);\n \twhile (pj_scan_strcmp(scanner, \"]]>\", 3)) {\n \t    pj_str_t dummy;\n+\n+\t    pj_scan_advance_n(scanner, 1, PJ_FALSE);\n \t    pj_scan_get_until_ch(scanner, ']', &dummy);\n \t}\n \tnode->content.slen = scanner->curptr - node->content.ptr;\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "bd36c5dc9fb6d90c46fbfed8c2d67516fc571ec8",
        "repo": "rpm-software-management/rpm",
        "msg": "Validate and require subkey binding signatures on PGP public keys\n\nAll subkeys must be followed by a binding signature by the primary key\nas per the OpenPGP RFC, enforce the presence and validity in the parser.\n\nThe implementation is as kludgey as they come to work around our\nsimple-minded parser structure without touching API, to maximise\nbackportability. Store all the raw packets internally as we decode them\nto be able to access previous elements at will, needed to validate ordering\nand access the actual data. Add testcases for manipulated keys whose\nimport previously would succeed.\n\nDepends on the two previous commits:\n7b399fcb8f52566e6f3b4327197a85facd08db91 and\n236b802a4aa48711823a191d1b7f753c82a89ec5\n\nFixes CVE-2021-3521.There is a flaw in RPM's signature functionality. OpenPGP subkeys are associated with a primary key via a \"binding signature.\" RPM does not check the binding signature of subkeys prior to importing them. If an attacker is able to add or socially engineer another party to add a malicious subkey to a legitimate public key, RPM could wrongly trust a malicious signature. The greatest impact of this flaw is to data integrity. To exploit this flaw, an attacker must either compromise an RPM repository or convince an administrator to install an untrusted RPM or public key. It is strongly recommended to only use RPMs and public keys from trusted sources.",
        "filename": "rpmpgp.c",
        "diff": "diff --git a/rpmio/rpmpgp.c b/rpmio/rpmpgp.c\nindex aad7c275c9..d70802ae86 100644\n--- a/rpmio/rpmpgp.c\n+++ b/rpmio/rpmpgp.c\n@@ -1062,37 +1062,121 @@ static pgpDigParams pgpDigParamsNew(uint8_t tag)\n     return digp;\n }\n \n+static int hashKey(DIGEST_CTX hash, const struct pgpPkt *pkt, int exptag)\n+{\n+    int rc = -1;\n+    if (pkt->tag == exptag) {\n+\tuint8_t head[] = {\n+\t    0x99,\n+\t    (pkt->blen >> 8),\n+\t    (pkt->blen     ),\n+\t};\n+\n+\trpmDigestUpdate(hash, head, 3);\n+\trpmDigestUpdate(hash, pkt->body, pkt->blen);\n+\trc = 0;\n+    }\n+    return rc;\n+}\n+\n+static int pgpVerifySelf(pgpDigParams key, pgpDigParams selfsig,\n+\t\t\tconst struct pgpPkt *all, int i)\n+{\n+    int rc = -1;\n+    DIGEST_CTX hash = NULL;\n+\n+    switch (selfsig->sigtype) {\n+    case PGPSIGTYPE_SUBKEY_BINDING:\n+\thash = rpmDigestInit(selfsig->hash_algo, 0);\n+\tif (hash) {\n+\t    rc = hashKey(hash, &all[0], PGPTAG_PUBLIC_KEY);\n+\t    if (!rc)\n+\t\trc = hashKey(hash, &all[i-1], PGPTAG_PUBLIC_SUBKEY);\n+\t}\n+\tbreak;\n+    default:\n+\t/* ignore types we can't handle */\n+\trc = 0;\n+\tbreak;\n+    }\n+\n+    if (hash && rc == 0)\n+\trc = pgpVerifySignature(key, selfsig, hash);\n+\n+    rpmDigestFinal(hash, NULL, NULL, 0);\n+\n+    return rc;\n+}\n+\n int pgpPrtParams(const uint8_t * pkts, size_t pktlen, unsigned int pkttype,\n \t\t pgpDigParams * ret)\n {\n     const uint8_t *p = pkts;\n     const uint8_t *pend = pkts + pktlen;\n     pgpDigParams digp = NULL;\n-    struct pgpPkt pkt;\n+    pgpDigParams selfsig = NULL;\n+    int i = 0;\n+    int alloced = 16; /* plenty for normal cases */\n+    struct pgpPkt *all = xmalloc(alloced * sizeof(*all));\n     int rc = -1; /* assume failure */\n+    int expect = 0;\n+    int prevtag = 0;\n \n     while (p < pend) {\n-\tif (decodePkt(p, (pend - p), &pkt))\n+\tstruct pgpPkt *pkt = &all[i];\n+\tif (decodePkt(p, (pend - p), pkt))\n \t    break;\n \n \tif (digp == NULL) {\n-\t    if (pkttype && pkt.tag != pkttype) {\n+\t    if (pkttype && pkt->tag != pkttype) {\n \t\tbreak;\n \t    } else {\n-\t\tdigp = pgpDigParamsNew(pkt.tag);\n+\t\tdigp = pgpDigParamsNew(pkt->tag);\n \t    }\n \t}\n \n-\tif (pgpPrtPkt(&pkt, digp))\n+\tif (expect) {\n+\t    if (pkt->tag != expect)\n+\t\tbreak;\n+\t    selfsig = pgpDigParamsNew(pkt->tag);\n+\t}\n+\n+\tif (pgpPrtPkt(pkt, selfsig ? selfsig : digp))\n \t    break;\n \n-\tp += (pkt.body - pkt.head) + pkt.blen;\n+\tif (selfsig) {\n+\t    /* subkeys must be followed by binding signature */\n+\t    if (prevtag == PGPTAG_PUBLIC_SUBKEY) {\n+\t\tif (selfsig->sigtype != PGPSIGTYPE_SUBKEY_BINDING)\n+\t\t    break;\n+\t    }\n+\n+\t    int xx = pgpVerifySelf(digp, selfsig, all, i);\n+\n+\t    selfsig = pgpDigParamsFree(selfsig);\n+\t    if (xx)\n+\t\tbreak;\n+\t    expect = 0;\n+\t}\n+\n+\tif (pkt->tag == PGPTAG_PUBLIC_SUBKEY)\n+\t    expect = PGPTAG_SIGNATURE;\n+\tprevtag = pkt->tag;\n+\n+\ti++;\n+\tp += (pkt->body - pkt->head) + pkt->blen;\n \tif (pkttype == PGPTAG_SIGNATURE)\n \t    break;\n+\n+\tif (alloced <= i) {\n+\t    alloced *= 2;\n+\t    all = xrealloc(all, alloced * sizeof(*all));\n+\t}\n     }\n \n-    rc = (digp && (p == pend)) ? 0 : -1;\n+    rc = (digp && (p == pend) && expect == 0) ? 0 : -1;\n \n+    free(all);\n     if (ret && rc == 0) {\n \t*ret = digp;\n     } else {\ndiff --git a/tests/Makefile.am b/tests/Makefile.am\nindex b4a2e2e1ce..bc535d2833 100644\n--- a/tests/Makefile.am\n+++ b/tests/Makefile.am\n@@ -108,6 +108,9 @@ EXTRA_DIST += data/SPECS/hello-config-buildid.spec\n EXTRA_DIST += data/SPECS/hello-cd.spec\n EXTRA_DIST += data/keys/rpm.org-rsa-2048-test.pub\n EXTRA_DIST += data/keys/rpm.org-rsa-2048-test.secret\n+EXTRA_DIST += data/keys/CVE-2021-3521-badbind.asc\n+EXTRA_DIST += data/keys/CVE-2021-3521-nosubsig.asc\n+EXTRA_DIST += data/keys/CVE-2021-3521-nosubsig-last.asc\n EXTRA_DIST += data/macros.testfile\n EXTRA_DIST += data/macros.debug\n EXTRA_DIST += data/SOURCES/foo.c\ndiff --git a/tests/data/keys/CVE-2021-3521-badbind.asc b/tests/data/keys/CVE-2021-3521-badbind.asc\nnew file mode 100644\nindex 0000000000..aea00f9d7a\n--- /dev/null\n+++ b/tests/data/keys/CVE-2021-3521-badbind.asc\n@@ -0,0 +1,25 @@\n+-----BEGIN PGP PUBLIC KEY BLOCK-----\n+Version: rpm-4.17.90 (NSS-3)\n+\n+mQENBFjmORgBCAC7TMEk6wnjSs8Dr4yqSScWdU2pjcqrkTxuzdWvowcIUPZI0w/g\n+HkRqGd4apjvY2V15kjL10gk3QhFP3pZ/9p7zh8o8NHX7aGdSGDK7NOq1eFaErPRY\n+91LW9RiZ0lbOjXEzIL0KHxUiTQEmdXJT43DJMFPyW9fkCWg0OltiX618FUdWWfI8\n+eySdLur1utnqBvdEbCUvWK2RX3vQZQdvEBODnNk2pxqTyV0w6VPQ96W++lF/5Aas\n+7rUv3HIyIXxIggc8FRrnH+y9XvvHDonhTIlGnYZN4ubm9i4y3gOkrZlGTrEw7elQ\n+1QeMyG2QQEbze8YjpTm4iLABCBrRfPRaQpwrABEBAAG0IXJwbS5vcmcgUlNBIHRl\n+c3RrZXkgPHJzYUBycG0ub3JnPokBNwQTAQgAIQUCWOY5GAIbAwULCQgHAgYVCAkK\n+CwIEFgIDAQIeAQIXgAAKCRBDRFkeGWTF/MxxCACnjqFL+MmPh9W9JQKT2DcLbBzf\n+Cqo6wcEBoCOcwgRSk8dSikhARoteoa55JRJhuMyeKhhEAogE9HRmCPFdjezFTwgB\n+BDVBpO2dZ023mLXDVCYX3S8pShOgCP6Tn4wqCnYeAdLcGg106N4xcmgtcssJE+Pr\n+XzTZksbZsrTVEmL/Ym+R5w5jBfFnGk7Yw7ndwfQsfNXQb5AZynClFxnX546lcyZX\n+fEx3/e6ezw57WNOUK6WT+8b+EGovPkbetK/rGxNXuWaP6X4A/QUm8O98nCuHYFQq\n++mvNdsCBqGf7mhaRGtpHk/JgCn5rFvArMDqLVrR9hX0LdCSsH7EGE+bR3r7wuQEN\n+BFjmORgBCACk+vDZrIXQuFXEYToZVwb2attzbbJJCqD71vmZTLsW0QxuPKRgbcYY\n+zp4K4lVBnHhFrF8MOUOxJ7kQWIJZMZFt+BDcptCYurbD2H4W2xvnWViiC+LzCMzz\n+iMJT6165uefL4JHTDPxC2fFiM9yrc72LmylJNkM/vepT128J5Qv0gRUaQbHiQuS6\n+Dm/+WRnUfx3i89SV4mnBxb/Ta93GVqoOciWwzWSnwEnWYAvOb95JL4U7c5J5f/+c\n+KnQDHsW7sIiIdscsWzvgf6qs2Ra1Zrt7Fdk4+ZS2f/adagLhDO1C24sXf5XfMk5m\n+L0OGwZSr9m5s17VXxfspgU5ugc8kBJfzABEBAAE=\n+=WCfs\n+-----END PGP PUBLIC KEY BLOCK-----\n+\ndiff --git a/tests/data/keys/CVE-2021-3521-nosubsig-last.asc b/tests/data/keys/CVE-2021-3521-nosubsig-last.asc\nnew file mode 100644\nindex 0000000000..aea00f9d7a\n--- /dev/null\n+++ b/tests/data/keys/CVE-2021-3521-nosubsig-last.asc\n@@ -0,0 +1,25 @@\n+-----BEGIN PGP PUBLIC KEY BLOCK-----\n+Version: rpm-4.17.90 (NSS-3)\n+\n+mQENBFjmORgBCAC7TMEk6wnjSs8Dr4yqSScWdU2pjcqrkTxuzdWvowcIUPZI0w/g\n+HkRqGd4apjvY2V15kjL10gk3QhFP3pZ/9p7zh8o8NHX7aGdSGDK7NOq1eFaErPRY\n+91LW9RiZ0lbOjXEzIL0KHxUiTQEmdXJT43DJMFPyW9fkCWg0OltiX618FUdWWfI8\n+eySdLur1utnqBvdEbCUvWK2RX3vQZQdvEBODnNk2pxqTyV0w6VPQ96W++lF/5Aas\n+7rUv3HIyIXxIggc8FRrnH+y9XvvHDonhTIlGnYZN4ubm9i4y3gOkrZlGTrEw7elQ\n+1QeMyG2QQEbze8YjpTm4iLABCBrRfPRaQpwrABEBAAG0IXJwbS5vcmcgUlNBIHRl\n+c3RrZXkgPHJzYUBycG0ub3JnPokBNwQTAQgAIQUCWOY5GAIbAwULCQgHAgYVCAkK\n+CwIEFgIDAQIeAQIXgAAKCRBDRFkeGWTF/MxxCACnjqFL+MmPh9W9JQKT2DcLbBzf\n+Cqo6wcEBoCOcwgRSk8dSikhARoteoa55JRJhuMyeKhhEAogE9HRmCPFdjezFTwgB\n+BDVBpO2dZ023mLXDVCYX3S8pShOgCP6Tn4wqCnYeAdLcGg106N4xcmgtcssJE+Pr\n+XzTZksbZsrTVEmL/Ym+R5w5jBfFnGk7Yw7ndwfQsfNXQb5AZynClFxnX546lcyZX\n+fEx3/e6ezw57WNOUK6WT+8b+EGovPkbetK/rGxNXuWaP6X4A/QUm8O98nCuHYFQq\n++mvNdsCBqGf7mhaRGtpHk/JgCn5rFvArMDqLVrR9hX0LdCSsH7EGE+bR3r7wuQEN\n+BFjmORgBCACk+vDZrIXQuFXEYToZVwb2attzbbJJCqD71vmZTLsW0QxuPKRgbcYY\n+zp4K4lVBnHhFrF8MOUOxJ7kQWIJZMZFt+BDcptCYurbD2H4W2xvnWViiC+LzCMzz\n+iMJT6165uefL4JHTDPxC2fFiM9yrc72LmylJNkM/vepT128J5Qv0gRUaQbHiQuS6\n+Dm/+WRnUfx3i89SV4mnBxb/Ta93GVqoOciWwzWSnwEnWYAvOb95JL4U7c5J5f/+c\n+KnQDHsW7sIiIdscsWzvgf6qs2Ra1Zrt7Fdk4+ZS2f/adagLhDO1C24sXf5XfMk5m\n+L0OGwZSr9m5s17VXxfspgU5ugc8kBJfzABEBAAE=\n+=WCfs\n+-----END PGP PUBLIC KEY BLOCK-----\n+\ndiff --git a/tests/data/keys/CVE-2021-3521-nosubsig.asc b/tests/data/keys/CVE-2021-3521-nosubsig.asc\nnew file mode 100644\nindex 0000000000..3a2e7417f8\n--- /dev/null\n+++ b/tests/data/keys/CVE-2021-3521-nosubsig.asc\n@@ -0,0 +1,37 @@\n+-----BEGIN PGP PUBLIC KEY BLOCK-----\n+Version: rpm-4.17.90 (NSS-3)\n+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\n+E4XX4jtDmdZPreZALsiB\n+=rRop\n+-----END PGP PUBLIC KEY BLOCK-----\n+\ndiff --git a/tests/rpmsigdig.at b/tests/rpmsigdig.at\nindex 0f8f2b4884..c8b9f139e1 100644\n--- a/tests/rpmsigdig.at\n+++ b/tests/rpmsigdig.at\n@@ -240,6 +240,34 @@ gpg(185e6146f00650f8) = 4:185e6146f00650f8-58e63918\n [])\n AT_CLEANUP\n \n+AT_SETUP([rpmkeys --import invalid keys])\n+AT_KEYWORDS([rpmkeys import])\n+RPMDB_INIT\n+\n+AT_CHECK([\n+runroot rpmkeys --import /data/keys/CVE-2021-3521-badbind.asc\n+],\n+[1],\n+[],\n+[error: /data/keys/CVE-2021-3521-badbind.asc: key 1 import failed.]\n+)\n+AT_CHECK([\n+runroot rpmkeys --import /data/keys/CVE-2021-3521-nosubsig.asc\n+],\n+[1],\n+[],\n+[error: /data/keys/CVE-2021-3521-nosubsig.asc: key 1 import failed.]\n+)\n+\n+AT_CHECK([\n+runroot rpmkeys --import /data/keys/CVE-2021-3521-nosubsig-last.asc\n+],\n+[1],\n+[],\n+[error: /data/keys/CVE-2021-3521-nosubsig-last.asc: key 1 import failed.]\n+)\n+AT_CLEANUP\n+\n # ------------------------------\n # Test pre-built package verification\n AT_SETUP([rpmkeys -K <signed> 1])\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "e9f936d85dc1edc34fabd0a1725ec180f2316353",
        "repo": "istio/envoy",
        "msg": "CVE-2022-21654\n\ntls allows re-use when some cert validation settings have changed\n\nSigned-off-by: Yan Avlasov <yavlasov@google.com>Envoy is an open source edge and service proxy, designed for cloud-native applications. Envoy's tls allows re-use when some cert validation settings have changed from their default configuration. The only workaround for this issue is to ensure that default tls settings are used. Users are advised to upgrade.",
        "filename": "default_validator.cc",
        "diff": "diff --git a/envoy/ssl/certificate_validation_context_config.h b/envoy/ssl/certificate_validation_context_config.h\nindex d331c45ce254..1d839be7e45a 100644\n--- a/envoy/ssl/certificate_validation_context_config.h\n+++ b/envoy/ssl/certificate_validation_context_config.h\n@@ -15,6 +15,11 @@\n namespace Envoy {\n namespace Ssl {\n \n+// SECURITY NOTE\n+//\n+// When adding or changing this interface, it is likely that a change is needed to\n+// `DefaultCertValidator::updateDigestForSessionId` in\n+// `source/extensions/transport_sockets/tls/cert_validator/default_validator.cc`.\n class CertificateValidationContextConfig {\n public:\n   virtual ~CertificateValidationContextConfig() = default;\ndiff --git a/source/extensions/transport_sockets/tls/cert_validator/cert_validator.h b/source/extensions/transport_sockets/tls/cert_validator/cert_validator.h\nindex 5e0f589b4890..57d18c595210 100644\n--- a/source/extensions/transport_sockets/tls/cert_validator/cert_validator.h\n+++ b/source/extensions/transport_sockets/tls/cert_validator/cert_validator.h\n@@ -62,7 +62,10 @@ class CertValidator {\n                                     bool handshaker_provides_certificates) PURE;\n \n   /**\n-   * Called when calculation hash for session context ids\n+   * Called when calculation hash for session context ids. This hash MUST include all\n+   * configuration used to validate a peer certificate, so that if this configuration\n+   * is changed, sessions cannot be re-used and must be re-negotiated and re-validated\n+   * using the new settings.\n    *\n    * @param md the store context\n    * @param hash_buffer the buffer used for digest calculation\ndiff --git a/source/extensions/transport_sockets/tls/cert_validator/default_validator.cc b/source/extensions/transport_sockets/tls/cert_validator/default_validator.cc\nindex 3b28200b73ab..da61d6115c02 100644\n--- a/source/extensions/transport_sockets/tls/cert_validator/default_validator.cc\n+++ b/source/extensions/transport_sockets/tls/cert_validator/default_validator.cc\n@@ -378,6 +378,35 @@ void DefaultCertValidator::updateDigestForSessionId(bssl::ScopedEVP_MD_CTX& md,\n                               sizeof(std::remove_reference<decltype(hash)>::type::value_type));\n     RELEASE_ASSERT(rc == 1, Utility::getLastCryptoError().value_or(\"\"));\n   }\n+\n+  rc = EVP_DigestUpdate(md.get(), &verify_trusted_ca_, sizeof(verify_trusted_ca_));\n+  RELEASE_ASSERT(rc == 1, Utility::getLastCryptoError().value_or(\"\"));\n+\n+  if (config_ != nullptr) {\n+    for (const auto& matcher : config_->subjectAltNameMatchers()) {\n+      size_t hash = MessageUtil::hash(matcher);\n+      rc = EVP_DigestUpdate(md.get(), &hash, sizeof(hash));\n+      RELEASE_ASSERT(rc == 1, Utility::getLastCryptoError().value_or(\"\"));\n+    }\n+\n+    const std::string& crl = config_->certificateRevocationList();\n+    if (!crl.empty()) {\n+      rc = EVP_DigestUpdate(md.get(), crl.data(), crl.length());\n+      RELEASE_ASSERT(rc == 1, Utility::getLastCryptoError().value_or(\"\"));\n+    }\n+\n+    bool allow_expired = config_->allowExpiredCertificate();\n+    rc = EVP_DigestUpdate(md.get(), &allow_expired, sizeof(allow_expired));\n+    RELEASE_ASSERT(rc == 1, Utility::getLastCryptoError().value_or(\"\"));\n+\n+    auto trust_chain_verification = config_->trustChainVerification();\n+    rc = EVP_DigestUpdate(md.get(), &trust_chain_verification, sizeof(trust_chain_verification));\n+    RELEASE_ASSERT(rc == 1, Utility::getLastCryptoError().value_or(\"\"));\n+\n+    auto only_leaf_crl = config_->onlyVerifyLeafCertificateCrl();\n+    rc = EVP_DigestUpdate(md.get(), &only_leaf_crl, sizeof(only_leaf_crl));\n+    RELEASE_ASSERT(rc == 1, Utility::getLastCryptoError().value_or(\"\"));\n+  }\n }\n \n void DefaultCertValidator::addClientValidationContext(SSL_CTX* ctx, bool require_client_cert) {\ndiff --git a/test/extensions/transport_sockets/tls/ssl_socket_test.cc b/test/extensions/transport_sockets/tls/ssl_socket_test.cc\nindex 5e9d7fa605b0..06b61503fe81 100644\n--- a/test/extensions/transport_sockets/tls/ssl_socket_test.cc\n+++ b/test/extensions/transport_sockets/tls/ssl_socket_test.cc\n@@ -3373,6 +3373,164 @@ TEST_P(SslSocketTest, TicketSessionResumptionDifferentServerNames) {\n                               client_ctx_yaml, false, GetParam());\n }\n \n+// Sessions cannot be resumed even though the server certificates are the same,\n+// because of the different `verify_certificate_hash` settings.\n+TEST_P(SslSocketTest, TicketSessionResumptionDifferentVerifyCertHash) {\n+  const std::string server_ctx_yaml1 = absl::StrCat(R\"EOF(\n+  session_ticket_keys:\n+    keys:\n+      filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/ticket_key_a\"\n+  common_tls_context:\n+    tls_certificates:\n+      certificate_chain:\n+        filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/unittest_cert.pem\"\n+      private_key:\n+        filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/unittest_key.pem\"\n+    validation_context:\n+      trusted_ca:\n+        filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/ca_cert.pem\"\n+      verify_certificate_hash:\n+        - \")EOF\",\n+                                                    TEST_SAN_URI_CERT_256_HASH, \"\\\"\");\n+\n+  const std::string server_ctx_yaml2 = absl::StrCat(R\"EOF(\n+  session_ticket_keys:\n+    keys:\n+      filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/ticket_key_a\"\n+  common_tls_context:\n+    tls_certificates:\n+      certificate_chain:\n+        filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/unittest_cert.pem\"\n+      private_key:\n+        filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/unittest_key.pem\"\n+    validation_context:\n+      trusted_ca:\n+        filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/ca_cert.pem\"\n+      verify_certificate_hash:\n+        - \"0000000000000000000000000000000000000000000000000000000000000000\"\n+        - \")EOF\",\n+                                                    TEST_SAN_URI_CERT_256_HASH, \"\\\"\");\n+\n+  const std::string client_ctx_yaml = R\"EOF(\n+  common_tls_context:\n+    tls_certificates:\n+      certificate_chain:\n+        filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/san_uri_cert.pem\"\n+      private_key:\n+        filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/san_uri_key.pem\"\n+)EOF\";\n+\n+  testTicketSessionResumption(server_ctx_yaml1, {}, server_ctx_yaml1, {}, client_ctx_yaml, true,\n+                              GetParam());\n+  testTicketSessionResumption(server_ctx_yaml1, {}, server_ctx_yaml2, {}, client_ctx_yaml, false,\n+                              GetParam());\n+}\n+\n+// Sessions cannot be resumed even though the server certificates are the same,\n+// because of the different `verify_certificate_spki` settings.\n+TEST_P(SslSocketTest, TicketSessionResumptionDifferentVerifyCertSpki) {\n+  const std::string server_ctx_yaml1 = absl::StrCat(R\"EOF(\n+  session_ticket_keys:\n+    keys:\n+      filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/ticket_key_a\"\n+  common_tls_context:\n+    tls_certificates:\n+      certificate_chain:\n+        filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/unittest_cert.pem\"\n+      private_key:\n+        filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/unittest_key.pem\"\n+    validation_context:\n+      trusted_ca:\n+        filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/ca_cert.pem\"\n+      verify_certificate_spki:\n+        - \")EOF\",\n+                                                    TEST_SAN_URI_CERT_SPKI, \"\\\"\");\n+\n+  const std::string server_ctx_yaml2 = absl::StrCat(R\"EOF(\n+  session_ticket_keys:\n+    keys:\n+      filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/ticket_key_a\"\n+  common_tls_context:\n+    tls_certificates:\n+      certificate_chain:\n+        filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/unittest_cert.pem\"\n+      private_key:\n+        filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/unittest_key.pem\"\n+    validation_context:\n+      trusted_ca:\n+        filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/ca_cert.pem\"\n+      verify_certificate_spki:\n+        - \"NvqYIYSbgK2vCJpQhObf77vv+bQWtc5ek5RIOwPiC9A=\"\n+        - \")EOF\",\n+                                                    TEST_SAN_URI_CERT_SPKI, \"\\\"\");\n+\n+  const std::string client_ctx_yaml = R\"EOF(\n+  common_tls_context:\n+    tls_certificates:\n+      certificate_chain:\n+        filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/san_uri_cert.pem\"\n+      private_key:\n+        filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/san_uri_key.pem\"\n+)EOF\";\n+\n+  testTicketSessionResumption(server_ctx_yaml1, {}, server_ctx_yaml1, {}, client_ctx_yaml, true,\n+                              GetParam());\n+  testTicketSessionResumption(server_ctx_yaml1, {}, server_ctx_yaml2, {}, client_ctx_yaml, false,\n+                              GetParam());\n+}\n+\n+// Sessions cannot be resumed even though the server certificates are the same,\n+// because of the different `match_subject_alt_names` settings.\n+TEST_P(SslSocketTest, TicketSessionResumptionDifferentMatchSAN) {\n+  const std::string server_ctx_yaml1 = R\"EOF(\n+  session_ticket_keys:\n+    keys:\n+      filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/ticket_key_a\"\n+  common_tls_context:\n+    tls_certificates:\n+      certificate_chain:\n+        filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/unittest_cert.pem\"\n+      private_key:\n+        filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/unittest_key.pem\"\n+    validation_context:\n+      trusted_ca:\n+        filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/ca_cert.pem\"\n+      match_subject_alt_names:\n+        - exact: \"spiffe://lyft.com/test-team\"\n+)EOF\";\n+\n+  const std::string server_ctx_yaml2 = R\"EOF(\n+  session_ticket_keys:\n+    keys:\n+      filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/ticket_key_a\"\n+  common_tls_context:\n+    tls_certificates:\n+      certificate_chain:\n+        filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/unittest_cert.pem\"\n+      private_key:\n+        filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/unittest_key.pem\"\n+    validation_context:\n+      trusted_ca:\n+        filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/ca_cert.pem\"\n+      match_subject_alt_names:\n+        - prefix: \"spiffe://lyft.com/test-team\"\n+\")EOF\";\n+\n+  const std::string client_ctx_yaml = R\"EOF(\n+  common_tls_context:\n+    tls_certificates:\n+      certificate_chain:\n+        filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/san_uri_cert.pem\"\n+      private_key:\n+        filename: \"{{ test_rundir }}/test/extensions/transport_sockets/tls/test_data/san_uri_key.pem\"\n+)EOF\";\n+\n+  testTicketSessionResumption(server_ctx_yaml1, {}, server_ctx_yaml1, {}, client_ctx_yaml, true,\n+                              GetParam());\n+  testTicketSessionResumption(server_ctx_yaml1, {}, server_ctx_yaml2, {}, client_ctx_yaml, false,\n+                              GetParam());\n+}\n+\n // Sessions can be resumed because the server certificates are different but the CN/SANs and\n // issuer are identical\n TEST_P(SslSocketTest, TicketSessionResumptionDifferentServerCert) {\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "9425e16437439e68c7d96abef922167d68fafaff",
        "repo": "weidai11/cryptopp",
        "msg": "Fix for CVE-2015-2141. Thanks to Evgeny Sidorov for reporting. Squaring to satisfy Jacobi requirements suggested by JPM.The InvertibleRWFunction::CalculateInverse function in rw.cpp in libcrypt++ 5.6.2 does not properly blind private key operations for the Rabin-Williams digital signature algorithm, which allows remote attackers to obtain private keys via a timing attack.",
        "filename": "rw.cpp",
        "diff": "diff --git a/rw.cpp b/rw.cpp\nindex cdd9f2d22..0b9318bfd 100644\n--- a/rw.cpp\n+++ b/rw.cpp\n@@ -126,10 +126,16 @@ Integer InvertibleRWFunction::CalculateInverse(RandomNumberGenerator &rng, const\n \tDoQuickSanityCheck();\n \tModularArithmetic modn(m_n);\n \tInteger r, rInv;\n-\tdo {\t// do this in a loop for people using small numbers for testing\n+\n+\t// do this in a loop for people using small numbers for testing\n+\tdo {\n \t\tr.Randomize(rng, Integer::One(), m_n - Integer::One());\n+\t\t// Fix for CVE-2015-2141. Thanks to Evgeny Sidorov for reporting.\n+\t\t// Squaring to satisfy Jacobi requirements suggested by JPM.\n+\t\tr = modn.Square(r);\n \t\trInv = modn.MultiplicativeInverse(r);\n \t} while (rInv.IsZero());\n+\n \tInteger re = modn.Square(r);\n \tre = modn.Multiply(re, x);\t\t\t// blind\n \n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "7dfa400ded53919d986c5d3d23446a09e0cf481b",
        "repo": "libjxl/libjxl",
        "msg": "Fix handling of APNG with 0 delay_den (#313)libjxl v0.3.7 is affected by a Divide By Zero in issue in lib/extras/codec_apng.cc jxl::DecodeImageAPNG(). When encoding a malicous APNG file using cjxl, an attacker can trigger a denial of service.",
        "filename": "codec_apng.cc",
        "diff": "diff --git a/AUTHORS b/AUTHORS\nindex d74bca225ef..bc1ff2a7bb7 100644\n--- a/AUTHORS\n+++ b/AUTHORS\n@@ -16,6 +16,7 @@ Cloudinary Ltd. <*@cloudinary.com>\n Google LLC <*@google.com>\n \n # Individuals:\n+Alexander Sago <cagelight@gmail.com>\n Dirk Lemstra <dirk@lemstra.org>\n Jon Sneyers <jon@cloudinary.com>\n Pieter Wuille\ndiff --git a/lib/extras/codec_apng.cc b/lib/extras/codec_apng.cc\nindex 48b7653d8bf..bef59f6369f 100644\n--- a/lib/extras/codec_apng.cc\n+++ b/lib/extras/codec_apng.cc\n@@ -342,6 +342,8 @@ Status DecodeImageAPNG(Span<const uint8_t> bytes, ThreadPool* pool,\n           dop = chunk.p[32];\n           bop = chunk.p[33];\n \n+          if (!delay_den) delay_den = 100;\n+\n           if (w0 > cMaxPNGSize || h0 > cMaxPNGSize || x0 > cMaxPNGSize ||\n               y0 > cMaxPNGSize || x0 + w0 > w || y0 + h0 > h || dop > 2 ||\n               bop > 1) {\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "dae9900580a8888969481cd72035408091edb11b",
        "repo": "gpac/gpac",
        "msg": "fixed #1659An issue was discovered in GPAC version 0.8.0 and 1.0.1. There is an invalid pointer dereference in the function SetupWriters() in isomedia/isom_store.c.",
        "filename": "isom_store.c",
        "diff": "diff --git a/src/isomedia/isom_store.c b/src/isomedia/isom_store.c\nindex 37dfbe55a9..ee2b2cfaf2 100644\n--- a/src/isomedia/isom_store.c\n+++ b/src/isomedia/isom_store.c\n@@ -150,8 +150,14 @@ GF_Err SetupWriters(MovieWriter *mw, GF_List *writers, u8 interleaving)\n \n \ttrackCount = gf_list_count(movie->moov->trackList);\n \tfor (i = 0; i < trackCount; i++) {\n+\t\tGF_SampleTableBox *stbl;\n \t\ttrak = gf_isom_get_track(movie->moov, i+1);\n \n+\t\tstbl = (trak->Media && trak->Media->information) ? trak->Media->information->sampleTable : NULL;\n+\t\tif (!stbl || !stbl->SampleSize || !stbl->ChunkOffset || !stbl->SampleToChunk) {\n+\t\t\treturn GF_ISOM_INVALID_FILE;\n+\t\t}\n+\n \t\tGF_SAFEALLOC(writer, TrackWriter);\n \t\tif (!writer) goto exit;\n \t\twriter->sampleNumber = 1;\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "93f428fd1768df147171ed674fee1fc5ab8309ec",
        "repo": "tensorflow/tensorflow",
        "msg": "Fix nullptr deref and heap OOB access in binary cwise ops.\n\nPiperOrigin-RevId: 387936777\nChange-Id: I608b8074cec36a982cca622b7144cb2c43e6e19fTensorFlow is an end-to-end open source platform for machine learning. In affected versions an attacker can cause undefined behavior via binding a reference to null pointer in all binary cwise operations that don't require broadcasting (e.g., gradients of binary cwise operations). The [implementation](https://github.com/tensorflow/tensorflow/blob/84d053187cb80d975ef2b9684d4b61981bca0c41/tensorflow/core/kernels/cwise_ops_common.h#L264) assumes that the two inputs have exactly the same number of elements but does not check that. Hence, when the eigen functor executes it triggers heap OOB reads and undefined behavior due to binding to nullptr. We have patched the issue in GitHub commit 93f428fd1768df147171ed674fee1fc5ab8309ec. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "filename": "cwise_ops_common.h",
        "diff": "diff --git a/tensorflow/core/kernels/cwise_ops_common.h b/tensorflow/core/kernels/cwise_ops_common.h\nindex 9adc628421d046..4f2c83322ba00f 100644\n--- a/tensorflow/core/kernels/cwise_ops_common.h\n+++ b/tensorflow/core/kernels/cwise_ops_common.h\n@@ -265,6 +265,11 @@ class SimpleBinaryOp : public OpKernel {\n   void Compute(OpKernelContext* ctx) override {\n     const Tensor& in0 = ctx->input(0);\n     const Tensor& in1 = ctx->input(1);\n+    OP_REQUIRES(\n+        ctx, in0.NumElements() == in1.NumElements(),\n+        errors::InvalidArgument(\"The two arguments to a cwise op must have \"\n+                                \"same number of elements, got \",\n+                                in0.NumElements(), \" and \", in1.NumElements()));\n     auto in0_flat = in0.flat<Tin>();\n     auto in1_flat = in1.flat<Tin>();\n     const Device& eigen_device = ctx->eigen_device<Device>();\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "3c785326c63a34aa1799a639ae185bc9453cb447",
        "repo": "drogonframework/drogon",
        "msg": "Prevent malformed upload path causing arbitrary write (#1174)This affects the package drogonframework/drogon before 1.7.5. The unsafe handling of file names during upload using HttpFile::save() method may enable attackers to write files to arbitrary locations outside the designated target folder.",
        "filename": "HttpFileImpl.cc",
        "diff": "diff --git a/lib/src/HttpFileImpl.cc b/lib/src/HttpFileImpl.cc\nindex ad9c692a76..faf9394246 100644\n--- a/lib/src/HttpFileImpl.cc\n+++ b/lib/src/HttpFileImpl.cc\n@@ -18,6 +18,7 @@\n #include <drogon/MultiPart.h>\n #include <fstream>\n #include <iostream>\n+#include <algorithm>\n \n using namespace drogon;\n \n@@ -31,28 +32,45 @@ int HttpFileImpl::save(const std::string &path) const\n     assert(!path.empty());\n     if (fileName_.empty())\n         return -1;\n-    filesystem::path fsPath(utils::toNativePath(path));\n-    if (!fsPath.is_absolute() &&\n-        (!fsPath.has_parent_path() ||\n-         (fsPath.begin()->string() != \".\" && fsPath.begin()->string() != \"..\")))\n+    filesystem::path fsUploadDir(utils::toNativePath(path));\n+\n+    if (!fsUploadDir.is_absolute() && (!fsUploadDir.has_parent_path() ||\n+                                       (fsUploadDir.begin()->string() != \".\" &&\n+                                        fsUploadDir.begin()->string() != \"..\")))\n     {\n-        filesystem::path fsUploadPath(utils::toNativePath(\n-            HttpAppFrameworkImpl::instance().getUploadPath()));\n-        fsPath = fsUploadPath / fsPath;\n+        fsUploadDir = utils::toNativePath(\n+                          HttpAppFrameworkImpl::instance().getUploadPath()) /\n+                      fsUploadDir;\n     }\n-    filesystem::path fsFileName(utils::toNativePath(fileName_));\n-    if (!filesystem::exists(fsPath))\n+\n+    fsUploadDir = filesystem::weakly_canonical(fsUploadDir);\n+\n+    if (!filesystem::exists(fsUploadDir))\n     {\n-        LOG_TRACE << \"create path:\" << fsPath;\n+        LOG_TRACE << \"create path:\" << fsUploadDir;\n         drogon::error_code err;\n-        filesystem::create_directories(fsPath, err);\n+        filesystem::create_directories(fsUploadDir, err);\n         if (err)\n         {\n             LOG_SYSERR;\n             return -1;\n         }\n     }\n-    return saveTo(fsPath / fsFileName);\n+\n+    filesystem::path fsSaveToPath(filesystem::weakly_canonical(\n+        fsUploadDir / utils::toNativePath(fileName_)));\n+\n+    if (!std::equal(fsUploadDir.begin(),\n+                    fsUploadDir.end(),\n+                    fsSaveToPath.begin()))\n+    {\n+        LOG_ERROR\n+            << \"Attempt writing outside of upload directory detected. Path: \"\n+            << fileName_;\n+        return -1;\n+    }\n+\n+    return saveTo(fsSaveToPath);\n }\n int HttpFileImpl::saveAs(const std::string &fileName) const\n {\ndiff --git a/lib/tests/CMakeLists.txt b/lib/tests/CMakeLists.txt\nindex 824d5b58b1..79409527c0 100644\n--- a/lib/tests/CMakeLists.txt\n+++ b/lib/tests/CMakeLists.txt\n@@ -1,45 +1,49 @@\n link_libraries(${PROJECT_NAME})\n-set(UNITTEST_SOURCES unittests/main.cc\n-                        unittests/Base64Test.cc\n-                        unittests/UrlCodecTest.cc\n-                        unittests/GzipTest.cc\n-                        unittests/HttpViewDataTest.cc\n-                        unittests/CookieTest.cc\n-                        unittests/ClassNameTest.cc\n-                        unittests/HttpDateTest.cc\n-                        unittests/HttpHeaderTest.cc\n-                        unittests/MD5Test.cc\n-                        unittests/MsgBufferTest.cc\n-                        unittests/OStringStreamTest.cc\n-                        unittests/PubSubServiceUnittest.cc\n-                        unittests/Sha1Test.cc\n-                        ../src/ssl_funcs/Sha1.cc\n-                        ../src/HttpUtils.cc\n-                        unittests/FileTypeTest.cc\n-                        unittests/DrObjectTest.cc\n-                        unittests/HttpFullDateTest.cc\n-                        unittests/MainLoopTest.cc\n-                        unittests/CacheMapTest.cc\n-                        unittests/StringOpsTest.cc)\n+set(UNITTEST_SOURCES\n+    unittests/main.cc\n+    unittests/Base64Test.cc\n+    unittests/UrlCodecTest.cc\n+    unittests/GzipTest.cc\n+    unittests/HttpViewDataTest.cc\n+    unittests/CookieTest.cc\n+    unittests/ClassNameTest.cc\n+    unittests/HttpDateTest.cc\n+    unittests/HttpHeaderTest.cc\n+    unittests/MD5Test.cc\n+    unittests/MsgBufferTest.cc\n+    unittests/OStringStreamTest.cc\n+    unittests/PubSubServiceUnittest.cc\n+    unittests/Sha1Test.cc\n+    ../src/ssl_funcs/Sha1.cc\n+    unittests/FileTypeTest.cc\n+    unittests/DrObjectTest.cc\n+    unittests/HttpFullDateTest.cc\n+    unittests/MainLoopTest.cc\n+    unittests/CacheMapTest.cc\n+    unittests/StringOpsTest.cc)\n \n if(DROGON_CXX_STANDARD GREATER_EQUAL 20 AND HAS_COROUTINE)\n-    set(UNITTEST_SOURCES ${UNITTEST_SOURCES} unittests/CoroutineTest.cc)\n+  set(UNITTEST_SOURCES ${UNITTEST_SOURCES} unittests/CoroutineTest.cc)\n endif()\n \n if(Brotli_FOUND)\n-    set(UNITTEST_SOURCES ${UNITTEST_SOURCES} unittests/BrotliTest.cc)\n+  set(UNITTEST_SOURCES ${UNITTEST_SOURCES} unittests/BrotliTest.cc)\n endif()\n \n-if (CMAKE_CXX_COMPILER_ID MATCHES \"MSVC\" AND BUILD_DROGON_SHARED)\n-    set(UNITTEST_SOURCES ${UNITTEST_SOURCES} ../src/HttpUtils.cc)\n+if(CMAKE_CXX_COMPILER_ID MATCHES \"MSVC\" AND BUILD_DROGON_SHARED)\n+  set(UNITTEST_SOURCES ${UNITTEST_SOURCES} ../src/HttpUtils.cc)\n+else()\n+  set(UNITTEST_SOURCES ${UNITTEST_SOURCES} ../src/HttpFileImpl.cc\n+                       unittests/HttpFileTest.cc)\n endif()\n \n add_executable(unittest ${UNITTEST_SOURCES})\n \n-set(INTEGRATION_TEST_CLIENT_SOURCES integration_test/client/main.cc\n-                                    integration_test/client/WebSocketTest.cc\n-                                    integration_test/client/MultipleWsTest.cc\n-                                    integration_test/client/HttpPipeliningTest.cc)\n+set(INTEGRATION_TEST_CLIENT_SOURCES\n+    integration_test/client/main.cc\n+    integration_test/client/WebSocketTest.cc\n+    integration_test/client/MultipleWsTest.cc\n+    integration_test/client/HttpPipeliningTest.cc)\n add_executable(integration_test_client ${INTEGRATION_TEST_CLIENT_SOURCES})\n \n set(INTEGRATION_TEST_SERVER_SOURCES\n@@ -64,10 +68,11 @@ set(INTEGRATION_TEST_SERVER_SOURCES\n     integration_test/server/main.cc)\n \n if(DROGON_CXX_STANDARD GREATER_EQUAL 20 AND HAS_COROUTINE)\n-    set(INTEGRATION_TEST_SERVER_SOURCES ${INTEGRATION_TEST_SERVER_SOURCES}\n-        integration_test/server/api_v1_CoroTest.cc)\n-    set(CMAKE_CXX_STANDARD 20)\n-    set(CMAKE_CXX_STANDARD_REQUIRED TRUE)\n+  set(INTEGRATION_TEST_SERVER_SOURCES\n+      ${INTEGRATION_TEST_SERVER_SOURCES}\n+      integration_test/server/api_v1_CoroTest.cc)\n+  set(CMAKE_CXX_STANDARD 20)\n+  set(CMAKE_CXX_STANDARD_REQUIRED TRUE)\n endif(DROGON_CXX_STANDARD GREATER_EQUAL 20 AND HAS_COROUTINE)\n \n add_executable(integration_test_server ${INTEGRATION_TEST_SERVER_SOURCES})\n@@ -98,9 +103,8 @@ add_custom_command(\n           $<TARGET_FILE_DIR:integration_test_server>/a-directory)\n \n set(tests unittest integration_test_server integration_test_client)\n-set_property(TARGET ${tests}\n-             PROPERTY CXX_STANDARD ${DROGON_CXX_STANDARD})\n+set_property(TARGET ${tests} PROPERTY CXX_STANDARD ${DROGON_CXX_STANDARD})\n set_property(TARGET ${tests} PROPERTY CXX_STANDARD_REQUIRED ON)\n set_property(TARGET ${tests} PROPERTY CXX_EXTENSIONS OFF)\n \n-ParseAndAddDrogonTests(unittest)\n+parseandadddrogontests(unittest)\ndiff --git a/lib/tests/unittests/HttpFileTest.cc b/lib/tests/unittests/HttpFileTest.cc\nnew file mode 100644\nindex 0000000000..d7bd50e5c9\n--- /dev/null\n+++ b/lib/tests/unittests/HttpFileTest.cc\n@@ -0,0 +1,52 @@\n+#include \"../../lib/src/HttpFileImpl.h\"\n+#include <drogon/drogon_test.h>\n+#include <filesystem>\n+\n+using namespace drogon;\n+using namespace std;\n+\n+DROGON_TEST(HttpFile)\n+{\n+    SUBSECTION(Save)\n+    {\n+        HttpFileImpl file;\n+        file.setFileName(\"test_file_name\");\n+        file.setFile(\"test\", 4);\n+        auto out = file.save(\"./test_uploads_dir\");\n+\n+        CHECK(out == 0);\n+        CHECK(filesystem::exists(\"./test_uploads_dir/test_file_name\"));\n+\n+        filesystem::remove_all(\"./test_uploads_dir\");\n+    }\n+\n+    SUBSECTION(SavePathRelativeTraversal)\n+    {\n+        auto uploadPath = filesystem::current_path() / \"test_uploads_dir\";\n+\n+        HttpFileImpl file;\n+        file.setFileName(\"../test_malicious_file_name\");\n+        file.setFile(\"test\", 4);\n+        auto out = file.save(uploadPath.string());\n+\n+        CHECK(out == -1);\n+        CHECK(!filesystem::exists(uploadPath / \"../test_malicious_file_name\"));\n+\n+        filesystem::remove_all(uploadPath);\n+        filesystem::remove(uploadPath / \"../test_malicious_file_name\");\n+    }\n+\n+    SUBSECTION(SavePathAbsoluteTraversal)\n+    {\n+        HttpFileImpl file;\n+        file.setFileName(\"/tmp/test_malicious_file_name\");\n+        file.setFile(\"test\", 4);\n+        auto out = file.save(\"./test_uploads_dir\");\n+\n+        CHECK(out == -1);\n+        CHECK(!filesystem::exists(\"/tmp/test_malicious_file_name\"));\n+\n+        filesystem::remove_all(\"test_uploads_dir\");\n+        filesystem::remove_all(\"/tmp/test_malicious_file_name\");\n+    }\n+}\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "15691e456c7dc9bd6be203b09765b063bf4a380c",
        "repo": "tensorflow/tensorflow",
        "msg": "Prevent dereferencing of null pointers in TFLite's `add.cc`.\n\nPiperOrigin-RevId: 387244946\nChange-Id: I56094233327fbd8439b92e1dbb1262176e00eeb9TensorFlow is an end-to-end open source platform for machine learning. In affected versions an attacker can craft a TFLite model that would trigger a null pointer dereference, which would result in a crash and denial of service. The [implementation](https://github.com/tensorflow/tensorflow/blob/149562d49faa709ea80df1d99fc41d005b81082a/tensorflow/lite/kernels/internal/optimized/optimized_ops.h#L268-L285) unconditionally dereferences a pointer. We have patched the issue in GitHub commit 15691e456c7dc9bd6be203b09765b063bf4a380c. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "filename": "optimized_ops.h",
        "diff": "diff --git a/tensorflow/lite/kernels/internal/optimized/optimized_ops.h b/tensorflow/lite/kernels/internal/optimized/optimized_ops.h\nindex 241405a6bbae19..296b3923a257a9 100644\n--- a/tensorflow/lite/kernels/internal/optimized/optimized_ops.h\n+++ b/tensorflow/lite/kernels/internal/optimized/optimized_ops.h\n@@ -265,7 +265,7 @@ inline void BinaryBroadcastFiveFold(const ArithmeticParams& unswitched_params,\n       // We have broadcast y2*y3*y4 of input2 data y1 times, and now move on.\n       input2_data_reset = input2_data_ptr;\n     }\n-  } else {\n+  } else if (input1_data_ptr != nullptr) {\n     // Special case of y4 == 1, in which the innermost loop is a single\n     // element and can be combined with the next (y3) as an inner broadcast.\n     //\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "bc9c546ce7015c57c2f15c168b3d9201de679a1d",
        "repo": "tensorflow/tensorflow",
        "msg": "Prevent heap oob access in `resource_variable_ops.cc`\n\nPiperOrigin-RevId: 387936433\nChange-Id: I9e71ddaa8dbd51ec6afbf163a6b3b591f193b4f6TensorFlow is an end-to-end open source platform for machine learning. In affected versions an attacker can trigger a crash via a `CHECK`-fail in debug builds of TensorFlow using `tf.raw_ops.ResourceGather` or a read from outside the bounds of heap allocated data in the same API in a release build. The [implementation](https://github.com/tensorflow/tensorflow/blob/f24faa153ad31a4b51578f8181d3aaab77a1ddeb/tensorflow/core/kernels/resource_variable_ops.cc#L660-L668) does not check that the `batch_dims` value that the user supplies is less than the rank of the input tensor. Since the implementation uses several for loops over the dimensions of `tensor`, this results in reading data from outside the bounds of heap allocated buffer backing the tensor. We have patched the issue in GitHub commit bc9c546ce7015c57c2f15c168b3d9201de679a1d. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "filename": "resource_variable_ops.cc",
        "diff": "diff --git a/tensorflow/core/kernels/resource_variable_ops.cc b/tensorflow/core/kernels/resource_variable_ops.cc\nindex 71aead55690d65..32a0a43364deae 100644\n--- a/tensorflow/core/kernels/resource_variable_ops.cc\n+++ b/tensorflow/core/kernels/resource_variable_ops.cc\n@@ -660,6 +660,11 @@ class ResourceGatherOp : public OpKernel {\n     OP_REQUIRES(\n         c, TensorShapeUtils::IsVectorOrHigher(params.shape()),\n         errors::InvalidArgument(\"params must be at least 1 dimensional\"));\n+    OP_REQUIRES(\n+        c, params.shape().dims() >= batch_dims_,\n+        errors::InvalidArgument(\"params must have at least \", batch_dims_,\n+                                \" (batch_dims) dimensions but it has shape \",\n+                                params.shape().DebugString()));\n \n     // Check that we have enough index space\n     const int64_t N = indices.NumElements();\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "a685e3332f61cd4e59324bf3f669d36973d64270",
        "repo": "syoyo/tinyexr",
        "msg": "Make line_no with too large value(2**20) invalid. Fixes #124tinyexr 0.9.5 has a integer overflow over-write in tinyexr::DecodePixelData in tinyexr.h, related to OpenEXR code.",
        "filename": "tinyexr.h",
        "diff": "diff --git a/tinyexr.h b/tinyexr.h\nindex 564a0c0..f221637 100644\n--- a/tinyexr.h\n+++ b/tinyexr.h\n@@ -472,7 +472,7 @@ extern int LoadEXRFromMemory(float **out_rgba, int *width, int *height,\n #include <cstring>\n #include <sstream>\n \n-// #include <iostream> // debug\n+//#include <iostream> // debug\n \n #include <limits>\n #include <string>\n@@ -7013,6 +7013,11 @@ static void swap2(unsigned short *val) {\n #pragma clang diagnostic push\n #pragma clang diagnostic ignored \"-Wunused-function\"\n #endif\n+\n+#ifdef __GNUC__\n+#pragma GCC diagnostic push\n+#pragma GCC diagnostic ignored \"-Wunused-function\"\n+#endif\n static void cpy4(int *dst_val, const int *src_val) {\n   unsigned char *dst = reinterpret_cast<unsigned char *>(dst_val);\n   const unsigned char *src = reinterpret_cast<const unsigned char *>(src_val);\n@@ -7046,6 +7051,10 @@ static void cpy4(float *dst_val, const float *src_val) {\n #pragma clang diagnostic pop\n #endif\n \n+#ifdef __GNUC__\n+#pragma GCC diagnostic pop\n+#endif\n+\n static void swap4(unsigned int *val) {\n #ifdef MINIZ_LITTLE_ENDIAN\n   (void)val;\n@@ -10949,6 +10958,11 @@ static int DecodeChunk(EXRImage *exr_image, const EXRHeader *exr_header,\n \n         if (size_t(data_len) > data_size) {\n           invalid_data = true;\n+\n+        } else if ((line_no > (2 << 20)) || (line_no < -(2 << 20))) {\n+          // Too large value. Assume this is invalid\n+          // 2**20 = 1048576 = heuristic value.\n+          invalid_data = true;\n         } else if (data_len == 0) {\n           // TODO(syoyo): May be ok to raise the threshold for example `data_len\n           // < 4`\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "f72315575f78a9a773adbce0ee7d3ec33434cb76",
        "repo": "mruby/mruby",
        "msg": "codegen.c: fix a argument generation bug in array assignment.Out-of-bounds Read in GitHub repository mruby/mruby prior to 3.2.",
        "filename": "codegen.c",
        "diff": "diff --git a/mrbgems/mruby-compiler/core/codegen.c b/mrbgems/mruby-compiler/core/codegen.c\nindex 729f575661..37b1307e65 100644\n--- a/mrbgems/mruby-compiler/core/codegen.c\n+++ b/mrbgems/mruby-compiler/core/codegen.c\n@@ -1904,8 +1904,12 @@ gen_assignment(codegen_scope *s, node *tree, node *rhs, int sp, int val)\n       if (val) {\n         gen_move(s, top, cursp(), 1);\n       }\n-      if (n < 14) {\n+      if (n < 15) {\n         n++;\n+        if (n == 15) {\n+          pop_n(14);\n+          genop_2(s, OP_ARRAY, cursp(), 15);\n+        }\n       }\n       else {\n         pop();\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "505d9dcb0f7ddf9d075e729523a33d38642ae680",
        "repo": "torvalds/linux",
        "msg": "crypto: ccp - fix resource leaks in ccp_run_aes_gcm_cmd()\n\nThere are three bugs in this code:\n\n1) If we ccp_init_data() fails for &src then we need to free aad.\n   Use goto e_aad instead of goto e_ctx.\n2) The label to free the &final_wa was named incorrectly as \"e_tag\" but\n   it should have been \"e_final_wa\".  One error path leaked &final_wa.\n3) The &tag was leaked on one error path.  In that case, I added a free\n   before the goto because the resource was local to that block.\n\nFixes: 36cf515b9bbe (\"crypto: ccp - Enable support for AES GCM on v5 CCPs\")\nReported-by: \"minihanshen(\u6c88\u660e\u822a)\" <minihanshen@tencent.com>\nSigned-off-by: Dan Carpenter <dan.carpenter@oracle.com>\nReviewed-by: John Allen <john.allen@amd.com>\nTested-by: John Allen <john.allen@amd.com>\nSigned-off-by: Herbert Xu <herbert@gondor.apana.org.au>A memory leak flaw was found in the Linux kernel in the ccp_run_aes_gcm_cmd() function in drivers/crypto/ccp/ccp-ops.c, which allows attackers to cause a denial of service (memory consumption). This vulnerability is similar with the older CVE-2019-18808.",
        "filename": "ccp-ops.c",
        "diff": "diff --git a/drivers/crypto/ccp/ccp-ops.c b/drivers/crypto/ccp/ccp-ops.c\nindex bb88198c874e0e..aa4e1a5006919d 100644\n--- a/drivers/crypto/ccp/ccp-ops.c\n+++ b/drivers/crypto/ccp/ccp-ops.c\n@@ -778,7 +778,7 @@ ccp_run_aes_gcm_cmd(struct ccp_cmd_queue *cmd_q, struct ccp_cmd *cmd)\n \t\t\t\t    in_place ? DMA_BIDIRECTIONAL\n \t\t\t\t\t     : DMA_TO_DEVICE);\n \t\tif (ret)\n-\t\t\tgoto e_ctx;\n+\t\t\tgoto e_aad;\n \n \t\tif (in_place) {\n \t\t\tdst = src;\n@@ -863,7 +863,7 @@ ccp_run_aes_gcm_cmd(struct ccp_cmd_queue *cmd_q, struct ccp_cmd *cmd)\n \top.u.aes.size = 0;\n \tret = cmd_q->ccp->vdata->perform->aes(&op);\n \tif (ret)\n-\t\tgoto e_dst;\n+\t\tgoto e_final_wa;\n \n \tif (aes->action == CCP_AES_ACTION_ENCRYPT) {\n \t\t/* Put the ciphered tag after the ciphertext. */\n@@ -873,17 +873,19 @@ ccp_run_aes_gcm_cmd(struct ccp_cmd_queue *cmd_q, struct ccp_cmd *cmd)\n \t\tret = ccp_init_dm_workarea(&tag, cmd_q, authsize,\n \t\t\t\t\t   DMA_BIDIRECTIONAL);\n \t\tif (ret)\n-\t\t\tgoto e_tag;\n+\t\t\tgoto e_final_wa;\n \t\tret = ccp_set_dm_area(&tag, 0, p_tag, 0, authsize);\n-\t\tif (ret)\n-\t\t\tgoto e_tag;\n+\t\tif (ret) {\n+\t\t\tccp_dm_free(&tag);\n+\t\t\tgoto e_final_wa;\n+\t\t}\n \n \t\tret = crypto_memneq(tag.address, final_wa.address,\n \t\t\t\t    authsize) ? -EBADMSG : 0;\n \t\tccp_dm_free(&tag);\n \t}\n \n-e_tag:\n+e_final_wa:\n \tccp_dm_free(&final_wa);\n \n e_dst:\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "6da6620efad397c85493b8f8667b821403516708",
        "repo": "tensorflow/tensorflow",
        "msg": "Secure tf.raw_ops.QuantizeV2\n\nValidate size and shape of min_range and max_range\nEnsure axis is within input dims limits\n\nPiperOrigin-RevId: 387232799\nChange-Id: I36975281f7b5758e9e31a8dcc73fe610ef456318TensorFlow is an end-to-end open source platform for machine learning. In affected versions due to incomplete validation in `tf.raw_ops.QuantizeV2`, an attacker can trigger undefined behavior via binding a reference to a null pointer or can access data outside the bounds of heap allocated arrays. The [implementation](https://github.com/tensorflow/tensorflow/blob/84d053187cb80d975ef2b9684d4b61981bca0c41/tensorflow/core/kernels/quantize_op.cc#L59) has some validation but does not check that `min_range` and `max_range` both have the same non-zero number of elements. If `axis` is provided (i.e., not `-1`), then validation should check that it is a value in range for the rank of `input` tensor and then the lengths of `min_range` and `max_range` inputs match the `axis` dimension of the `input` tensor. We have patched the issue in GitHub commit 6da6620efad397c85493b8f8667b821403516708. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "filename": "quantize_op.cc",
        "diff": "diff --git a/tensorflow/core/kernels/quantize_op.cc b/tensorflow/core/kernels/quantize_op.cc\nindex f64a2188fa9547..be73d4f8291f7b 100644\n--- a/tensorflow/core/kernels/quantize_op.cc\n+++ b/tensorflow/core/kernels/quantize_op.cc\n@@ -113,7 +113,50 @@ class QuantizeV2Op : public OpKernel {\n \n     int num_slices = 1;\n     if (axis_ > -1) {\n+      OP_REQUIRES(\n+          ctx, input.dims() > axis_,\n+          errors::InvalidArgument(\n+              \"Axis is on a zero-based index, so its value must always be less \"\n+              \"than number of input's dims, but given axis value was \",\n+              axis_, \" and input's dims was \", input.dims()));\n       num_slices = input.dim_size(axis_);\n+      OP_REQUIRES(ctx, input_min_range.dims() == 1,\n+                  errors::InvalidArgument(\n+                      \"If axis is specified, min_range must be a 1-D tensor \"\n+                      \"whose size matches the axis dimension of the input and \"\n+                      \"output tensors, but min_range dims are \",\n+                      input_min_range.dims()));\n+      OP_REQUIRES(ctx, input_min_range.dim_size(0) == num_slices,\n+                  errors::InvalidArgument(\n+                      \"If axis is specified, min_range must be a 1-D tensor \"\n+                      \"whose size matches the axis dimension of the input and \"\n+                      \"output tensors, but min_range is a 1-D tensor of size \",\n+                      input_min_range.dim_size(0),\n+                      \" and input's axis dimension is of size \", num_slices));\n+      OP_REQUIRES(ctx, input_max_range.dims() == 1,\n+                  errors::InvalidArgument(\n+                      \"If axis is specified, max_range must be a 1-D tensor \"\n+                      \"whose size matches the axis dimension of the input and \"\n+                      \"output tensors, but max_range dims are \",\n+                      input_max_range.dims()));\n+      OP_REQUIRES(ctx, input_max_range.dim_size(0) == num_slices,\n+                  errors::InvalidArgument(\n+                      \"If axis is specified, max_range must be a 1-D tensor \"\n+                      \"whose size matches the axis dimension of the input and \"\n+                      \"output tensors, but max_range is a 1-D tensor of size \",\n+                      input_max_range.dim_size(0),\n+                      \" and input's axis dimension is of size \", num_slices));\n+    } else {\n+      OP_REQUIRES(ctx, input_min_range.NumElements() == 1,\n+                  errors::InvalidArgument(\n+                      \"If axis is not specified, min_range must contain a \"\n+                      \"single float element, but it contains \",\n+                      input_min_range.NumElements(), \" elements\"));\n+      OP_REQUIRES(ctx, input_max_range.NumElements() == 1,\n+                  errors::InvalidArgument(\n+                      \"If axis is not specified, max_range must contain a \"\n+                      \"single float element, but it contains \",\n+                      input_max_range.NumElements(), \" elements\"));\n     }\n \n     const TensorShape& minmax_shape = ctx->input(1).shape();\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "9ffa49496d1aae4cbbb387aac28a9e061a6ab0a6",
        "repo": "FFmpeg/FFmpeg",
        "msg": "avformat/adtsenc: return value check for init_get_bits in adts_decode_extradata\n\nAs the second argument for init_get_bits (buf) can be crafted, a return value check for this function call is necessary.\n'buf' is  part of  'AVPacket pkt'.\nreplace init_get_bits with init_get_bits8.\n\nSigned-off-by: Michael Niedermayer <michael@niedermayer.cc>adts_decode_extradata in libavformat/adtsenc.c in FFmpeg 4.4 does not check the init_get_bits return value, which is a necessary step because the second argument to init_get_bits can be crafted.",
        "filename": "adtsenc.c",
        "diff": "diff --git a/libavformat/adtsenc.c b/libavformat/adtsenc.c\nindex ba15c0a72494e..3924e678d917d 100644\n--- a/libavformat/adtsenc.c\n+++ b/libavformat/adtsenc.c\n@@ -53,9 +53,11 @@ static int adts_decode_extradata(AVFormatContext *s, ADTSContext *adts, const ui\n     GetBitContext gb;\n     PutBitContext pb;\n     MPEG4AudioConfig m4ac;\n-    int off;\n+    int off, ret;\n \n-    init_get_bits(&gb, buf, size * 8);\n+    ret = init_get_bits8(&gb, buf, size);\n+    if (ret < 0)\n+        return ret;\n     off = avpriv_mpeg4audio_get_config2(&m4ac, buf, size, 1, s);\n     if (off < 0)\n         return off;\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "ab1702c7af9959366a5ddc4a75b4357d4e9ebdc1",
        "repo": "nginx/njs",
        "msg": "Fixed typo while calculating module path length.\n\nThe issue was introduced in 77c398f26d7e (not released yet).Nginx NJS v0.7.3 was discovered to contain a stack overflow in the function njs_default_module_loader at /src/njs/src/njs_module.c. NOTE: multiple third parties dispute this report, e.g., the behavior is only found in unreleased development code that was not part of the 0.7.2, 0.7.3, or 0.7.4 release",
        "filename": "njs_module.c",
        "diff": "diff --git a/src/njs_module.c b/src/njs_module.c\nindex 16e29a57b..78206b3ba 100644\n--- a/src/njs_module.c\n+++ b/src/njs_module.c\n@@ -118,7 +118,7 @@ njs_module_path(njs_vm_t *vm, const njs_str_t *dir, njs_module_info_t *info)\n     length = info->name.length;\n \n     if (dir != NULL) {\n-        length = dir->length;\n+        length += dir->length;\n \n         if (length == 0) {\n             return NJS_DECLINED;\ndiff --git a/test/js/import_very_long_path.t.js b/test/js/import_very_long_path.t.js\nnew file mode 100644\nindex 000000000..a2a3ebff5\n--- /dev/null\n+++ b/test/js/import_very_long_path.t.js\n@@ -0,0 +1,9 @@\n+/*---\n+: []\n+paths: [test/js/module/]\n+negative:\n+  phase: runtime\n+---*/\n+\n+import name from 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx';\n+ \n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "203214568f5bc237603dbab6e1fd389f1572f5c9",
        "repo": "tensorflow/tensorflow",
        "msg": "Reorganize and add more validation to MKL requantization\n\nPiperOrigin-RevId: 387901341\nChange-Id: I2515b9034c64e113db0bcec8337d30643ab0a0f1TensorFlow is an end-to-end open source platform for machine learning. In affected versions due to incomplete validation in MKL implementation of requantization, an attacker can trigger undefined behavior via binding a reference to a null pointer or can access data outside the bounds of heap allocated arrays. The [implementation](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/core/kernels/mkl/mkl_requantization_range_per_channel_op.cc) does not validate the dimensions of the `input` tensor. A similar issue occurs in `MklRequantizePerChannelOp`. The [implementation](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/core/kernels/mkl/mkl_requantize_per_channel_op.cc) does not perform full validation for all the input arguments. We have patched the issue in GitHub commit 9e62869465573cb2d9b5053f1fa02a81fce21d69 and in the Github commit 203214568f5bc237603dbab6e1fd389f1572f5c9. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "filename": "mkl_requantize_per_channel_op.cc",
        "diff": "diff --git a/tensorflow/core/kernels/mkl/mkl_requantize_per_channel_op.cc b/tensorflow/core/kernels/mkl/mkl_requantize_per_channel_op.cc\nindex c0f9845cd4b084..6ffbd09b44f543 100644\n--- a/tensorflow/core/kernels/mkl/mkl_requantize_per_channel_op.cc\n+++ b/tensorflow/core/kernels/mkl/mkl_requantize_per_channel_op.cc\n@@ -49,35 +49,45 @@ class MklRequantizePerChannelOp : public OpKernel {\n   void Compute(OpKernelContext* ctx) override {\n     try {\n       const Tensor& input = ctx->input(kInputTensorIndex);\n+      OP_REQUIRES(\n+          ctx, input.dims() == 4,\n+          errors::InvalidArgument(\"Current RequantizePerChannel operator\"\n+                                  \"supports 4D tensors only.\"));\n+\n       const Tensor& input_min_vec = ctx->input(kInputMinVecIndex);\n+      size_t depth = input_min_vec.NumElements();\n       float* input_min_vec_data = (float*)const_cast<void*>(\n           static_cast<const void*>(input_min_vec.flat<float>().data()));\n+\n       const Tensor& input_max_vec = ctx->input(kInputMaxVecIndex);\n+      OP_REQUIRES(\n+          ctx, input_max_vec.NumElements() == depth,\n+          errors::InvalidArgument(\"input_max has incorrect size, expected \",\n+                                  depth, \" was \", input_max_vec.NumElements()));\n       float* input_max_vec_data = (float*)const_cast<void*>(\n           static_cast<const void*>(input_max_vec.flat<float>().data()));\n \n       const Tensor& input_requested_min = ctx->input(this->kRequestMinIndex);\n+      OP_REQUIRES(\n+          ctx, input_requested_min.NumElements() == 1,\n+          errors::InvalidArgument(\"requested_output_min must be a scalar\"));\n       const float input_requested_min_float =\n           input_requested_min.flat<float>()(0);\n+\n       const Tensor& input_requested_max = ctx->input(this->kRequestMaxIndex);\n+      OP_REQUIRES(\n+          ctx, input_requested_min.NumElements() == 1,\n+          errors::InvalidArgument(\"requested_output_max must be a scalar\"));\n       const float input_requested_max_float =\n           input_requested_max.flat<float>()(0);\n \n-      size_t depth = input_min_vec.NumElements();\n-      OP_REQUIRES(\n-          ctx, input.dims() == 4,\n-          errors::InvalidArgument(\"Current RequantizePerChannel operator\"\n-                                  \"supports 4D tensors only.\"));\n-      OP_REQUIRES(\n-          ctx, input_min_vec.dim_size(0) == depth,\n-          errors::InvalidArgument(\"input_min has incorrect size, expected \",\n-                                  depth, \" was \", input_min_vec.dim_size(0)));\n-      OP_REQUIRES(\n-          ctx, input_max_vec.dim_size(0) == depth,\n-          errors::InvalidArgument(\"input_max has incorrect size, expected \",\n-                                  depth, \" was \", input_max_vec.dim_size(0)));\n-\n-      if (out_type_ == DT_QINT8) DCHECK(input_requested_min_float < 0.0f);\n+      if (out_type_ == DT_QINT8) {\n+        OP_REQUIRES(ctx, input_requested_min_float < 0.0f,\n+                    errors::InvalidArgument(\n+                        \"If out_type is QINT8, requested_output_max must be \"\n+                        \"non negative, got \",\n+                        input_requested_min_float));\n+      }\n \n       const float factor = (out_type_ == DT_QINT8) ? 127.0f : 255.0f;\n       const float requested_min_max =\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "537bc7c723439b9194a358f64d871dd326c18887",
        "repo": "tensorflow/tensorflow",
        "msg": "Fix a null pointer exception caused by branching on uninitialized data.\n\nThis is due to not checking that the params for the quantization exists. If there is no quantization, we should not access the `.params` field.\n\nPiperOrigin-RevId: 385163909\nChange-Id: I2beb8d50649b6542db224c163033fbcbaa49314fTensorFlow is an end-to-end open source platform for machine learning. In affected versions all TFLite operations that use quantization can be made to use unitialized values. [For example](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/lite/kernels/depthwise_conv.cc#L198-L200). The issue stems from the fact that `quantization.params` is only valid if `quantization.type` is different that `kTfLiteNoQuantization`. However, these checks are missing in large parts of the code. We have patched the issue in GitHub commits 537bc7c723439b9194a358f64d871dd326c18887, 4a91f2069f7145aab6ba2d8cfe41be8a110c18a5 and 8933b8a21280696ab119b63263babdb54c298538. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "filename": "svdf.cc",
        "diff": "diff --git a/tensorflow/lite/kernels/svdf.cc b/tensorflow/lite/kernels/svdf.cc\nindex 6c02508e26b1da..41a71c54a8c922 100644\n--- a/tensorflow/lite/kernels/svdf.cc\n+++ b/tensorflow/lite/kernels/svdf.cc\n@@ -256,14 +256,21 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n                                                      output_temp_size_array));\n \n     // Calculate effective scales.\n+    TF_LITE_ENSURE(context, input->quantization.type != kTfLiteNoQuantization);\n     auto* input_params =\n         reinterpret_cast<TfLiteAffineQuantization*>(input->quantization.params);\n+    TF_LITE_ENSURE(context,\n+                   weights_feature->quantization.type != kTfLiteNoQuantization);\n     auto* weights_feature_params = reinterpret_cast<TfLiteAffineQuantization*>(\n         weights_feature->quantization.params);\n+    TF_LITE_ENSURE(context, state->quantization.type != kTfLiteNoQuantization);\n     auto* state_params =\n         reinterpret_cast<TfLiteAffineQuantization*>(state->quantization.params);\n+    TF_LITE_ENSURE(context,\n+                   weights_time->quantization.type != kTfLiteNoQuantization);\n     auto* weight_time_params = reinterpret_cast<TfLiteAffineQuantization*>(\n         weights_time->quantization.params);\n+    TF_LITE_ENSURE(context, output->quantization.type != kTfLiteNoQuantization);\n     auto* output_params = reinterpret_cast<TfLiteAffineQuantization*>(\n         output->quantization.params);\n     const double effective_scale_1 = input_params->scale->data[0] *\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "ee119d4a498979525046fba1c3dd3f13a039fbb1",
        "repo": "tensorflow/tensorflow",
        "msg": "Fix segmentation fault in shape inference logic.\n\nWhen running shape functions, some functions (such as `MutableHashTableShape`)\nproduce extra output information in the form of a `ShapeAndType` struct.  The\nshapes embedded in this struct are owned by an inference context that is\ncleaned up almost immediately; if the upstream code attempts to access this\nshape information, it can trigger a segfault.\n\n`ShapeRefiner` is mitigating this for normal output shapes by cloning them\n(and thus putting the newly created shape under ownership of an inference\ncontext that will not die), but we were not doing the same for shapes and\ntypes.  This commit fixes that by doing similar logic on output shapes and\ntypes.\n\nPiperOrigin-RevId: 384761124\nChange-Id: I07c0c42d29dfbb55bfa13ec1f09ef825fb0a1a1dTensorFlow is an end-to-end open source platform for machine learning. In affected versions when running shape functions, some functions (such as `MutableHashTableShape`) produce extra output information in the form of a `ShapeAndType` struct. The shapes embedded in this struct are owned by an inference context that is cleaned up almost immediately; if the upstream code attempts to access this shape information, it can trigger a segfault. `ShapeRefiner` is mitigating this for normal output shapes by cloning them (and thus putting the newly created shape under ownership of an inference context that will not die), but we were not doing the same for shapes and types. This commit fixes that by doing similar logic on output shapes and types. We have patched the issue in GitHub commit ee119d4a498979525046fba1c3dd3f13a039fbb1. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "filename": "shape_refiner.cc",
        "diff": "diff --git a/tensorflow/core/common_runtime/shape_refiner.cc b/tensorflow/core/common_runtime/shape_refiner.cc\nindex 375f809b31b369..2e29ef48189a59 100644\n--- a/tensorflow/core/common_runtime/shape_refiner.cc\n+++ b/tensorflow/core/common_runtime/shape_refiner.cc\n@@ -120,9 +120,26 @@ Status ShapeRefiner::InferShapesForFunctionSubNode(\n     TF_RETURN_IF_ERROR(outer_context->MakeShapeFromShapeProto(proto, &handle));\n     outer_context->set_output(index, handle);\n \n-    auto* resource = node_context->input_handle_shapes_and_types(0);\n+    const std::vector<ShapeAndType>* resource =\n+        node_context->input_handle_shapes_and_types(0);\n     if (resource) {\n-      outer_context->set_output_handle_shapes_and_types(index, *resource);\n+      // `ShapesAndType`s contain `ShapeHandle`s.  These `ShapeHandle`s point\n+      // to `Shape`s that are owned by a different inference context too.  We\n+      // need to copy them to the outer context to prevent them from being\n+      // destroyed before they are used.\n+      std::vector<ShapeAndType> copied_shapes_and_types;\n+      for (auto& shape_and_type : *resource) {\n+        ShapeHandle handle;\n+        TensorShapeProto proto;\n+        node_context->ShapeHandleToProto(shape_and_type.shape, &proto);\n+        TF_RETURN_IF_ERROR(\n+            outer_context->MakeShapeFromShapeProto(proto, &handle));\n+        copied_shapes_and_types.push_back(\n+            ShapeAndType(handle, shape_and_type.dtype, shape_and_type.type));\n+      }\n+\n+      outer_context->set_output_handle_shapes_and_types(\n+          index, copied_shapes_and_types);\n     }\n   }\n \n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "e6cf28c72ba2eb949ca950d834dd6d66bb01cfae",
        "repo": "tensorflow/tensorflow",
        "msg": "Validate that matrix dimension sizes in SparseMatMul are positive.\n\nPiperOrigin-RevId: 401149683\nChange-Id: Ib33eafc561a39c8741ece80b2edce6d4aae9a57dTensorFlow is an open source platform for machine learning. In affected versions the code for sparse matrix multiplication is vulnerable to undefined behavior via binding a reference to `nullptr`. This occurs whenever the dimensions of `a` or `b` are 0 or less. In the case on one of these is 0, an empty output tensor should be allocated (to conserve the invariant that output tensors are always allocated when the operation is successful) but nothing should be written to it (that is, we should return early from the kernel implementation). Otherwise, attempts to write to this empty tensor would result in heap OOB access. The fix will be included in TensorFlow 2.7.0. We will also cherrypick this commit on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.",
        "filename": "sparse_matmul_op.cc",
        "diff": "diff --git a/tensorflow/core/kernels/sparse_matmul_op.cc b/tensorflow/core/kernels/sparse_matmul_op.cc\nindex a02afafa33e3ad..6bf9dfa3d8bb75 100644\n--- a/tensorflow/core/kernels/sparse_matmul_op.cc\n+++ b/tensorflow/core/kernels/sparse_matmul_op.cc\n@@ -32,6 +32,7 @@ limitations under the License.\n #include \"tensorflow/core/kernels/fill_functor.h\"\n #include \"tensorflow/core/lib/core/blocking_counter.h\"\n #include \"tensorflow/core/lib/core/threadpool.h\"\n+#include \"tensorflow/core/platform/errors.h\"\n #include \"tensorflow/core/platform/logging.h\"\n #include \"tensorflow/core/platform/macros.h\"\n #include \"tensorflow/core/platform/mutex.h\"\n@@ -980,9 +981,18 @@ class SparseMatMulOp : public OpKernel {\n                 errors::InvalidArgument(\n                     \"Matrix size incompatible: a: \", a.shape().DebugString(),\n                     \", b: \", b.shape().DebugString()));\n+    OP_REQUIRES(ctx, m >= 0 && n >= 0 && k >= 0,\n+                errors::InvalidArgument(\n+                    \"Matrix dimensions cannot be negative: a: \",\n+                    a.shape().DebugString(), \", b: \", b.shape().DebugString()));\n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, TensorShape({m, n}), &output));\n \n+    // Return early if at least one of the output dimension size is 0.\n+    if (m == 0 || n == 0) {\n+      return;\n+    }\n+\n     if (k == 0) {\n       // If the inner dimension k in the matrix multiplication is zero, we fill\n       // the output with zeros.\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "11559e49e65bdf00922ad5ae28913ec6a198d508",
        "repo": "pjsip/pjproject",
        "msg": "Merge pull request from GHSA-vhxv-phmx-g52q\n\n* Prevent OOB read/write when parsing RTCP FB RPSI\n\n* Add log information\n\n* Modification based on comments.PJSIP is a free and open source multimedia communication library written in C. PJSIP versions 2.12 and prior do not parse incoming RTCP feedback RPSI (Reference Picture Selection Indication) packet, but any app that directly uses pjmedia_rtcp_fb_parse_rpsi() will be affected. A patch is available in the `master` branch of the `pjsip/pjproject` GitHub repository. There are currently no known workarounds.",
        "filename": "rtcp_fb.c",
        "diff": "diff --git a/pjmedia/include/pjmedia/rtcp.h b/pjmedia/include/pjmedia/rtcp.h\nindex 9fc53657ae..f4bff12cda 100644\n--- a/pjmedia/include/pjmedia/rtcp.h\n+++ b/pjmedia/include/pjmedia/rtcp.h\n@@ -115,6 +115,15 @@ typedef struct pjmedia_rtcp_common\n } pjmedia_rtcp_common;\n \n \n+/**\n+ * RTCP feedback common header.\n+ */\n+typedef struct pjmedia_rtcp_fb_common\n+{\n+    pjmedia_rtcp_common rtcp_common;\n+    pj_uint32_t\t    ssrc_src;\t/**< SSRC media source\t    */\n+} pjmedia_rtcp_fb_common;\n+\n /**\n  * This structure declares default RTCP packet (SR) that is sent by pjmedia.\n  * Incoming RTCP packet may have different format, and must be parsed\n@@ -234,6 +243,8 @@ typedef struct pjmedia_rtcp_session\n     char\t\t   *name;\t/**< Name identification.\t    */\n     pjmedia_rtcp_sr_pkt\t    rtcp_sr_pkt;/**< Cached RTCP SR packet.\t    */\n     pjmedia_rtcp_rr_pkt\t    rtcp_rr_pkt;/**< Cached RTCP RR packet.\t    */\n+    pjmedia_rtcp_fb_common  rtcp_fb_com;/**< Cached RTCP feedback common \n+\t\t\t\t\t     header packet.\t\t    */\n     \n     pjmedia_rtp_seq_session seq_ctrl;\t/**< RTCP sequence number control.  */\n     unsigned\t\t    rtp_last_ts;/**< Last timestamp in RX RTP pkt.  */\ndiff --git a/pjmedia/src/pjmedia/rtcp.c b/pjmedia/src/pjmedia/rtcp.c\nindex 4f40e7fe10..ceb1b78fcd 100644\n--- a/pjmedia/src/pjmedia/rtcp.c\n+++ b/pjmedia/src/pjmedia/rtcp.c\n@@ -242,6 +242,11 @@ PJ_DEF(void) pjmedia_rtcp_init2( pjmedia_rtcp_session *sess,\n     sess->rtcp_rr_pkt.common.pt = RTCP_RR;\n     sess->rtcp_rr_pkt.common.length = pj_htons(7);\n \n+    /* Copy to RTCP FB common header */\n+    pj_memcpy(&sess->rtcp_fb_com, &sr_pkt->common, \n+\t      sizeof(pjmedia_rtcp_common));\n+    sess->rtcp_fb_com.ssrc_src = 0;\n+\n     /* Get time and timestamp base and frequency */\n     pj_gettimeofday(&now);\n     sess->tv_base = now;\ndiff --git a/pjmedia/src/pjmedia/rtcp_fb.c b/pjmedia/src/pjmedia/rtcp_fb.c\nindex a2a0140f34..d4e444caab 100644\n--- a/pjmedia/src/pjmedia/rtcp_fb.c\n+++ b/pjmedia/src/pjmedia/rtcp_fb.c\n@@ -43,7 +43,7 @@ PJ_DEF(pj_status_t) pjmedia_rtcp_fb_build_nack(\n \t\t\t\t\tunsigned nack_cnt,\n \t\t\t\t\tconst pjmedia_rtcp_fb_nack nack[])\n {\n-    pjmedia_rtcp_common *hdr;\n+    pjmedia_rtcp_fb_common *hdr;\n     pj_uint8_t *p;\n     unsigned len, i;\n \n@@ -54,11 +54,11 @@ PJ_DEF(pj_status_t) pjmedia_rtcp_fb_build_nack(\n \treturn PJ_ETOOSMALL;\n \n     /* Build RTCP-FB NACK header */\n-    hdr = (pjmedia_rtcp_common*)buf;\n-    pj_memcpy(hdr, &session->rtcp_rr_pkt.common,  sizeof(*hdr));\n-    hdr->pt = RTCP_RTPFB;\n-    hdr->count = 1; /* FMT = 1 */\n-    hdr->length = pj_htons((pj_uint16_t)(len/4 - 1));\n+    hdr = (pjmedia_rtcp_fb_common*)buf;\n+    pj_memcpy(hdr, &session->rtcp_fb_com, sizeof(*hdr));\n+    hdr->rtcp_common.pt = RTCP_RTPFB;\n+    hdr->rtcp_common.count = 1; /* FMT = 1 */\n+    hdr->rtcp_common.length = pj_htons((pj_uint16_t)(len/4 - 1));\n \n     /* Build RTCP-FB NACK FCI */\n     p = (pj_uint8_t*)hdr + sizeof(*hdr);\n@@ -86,7 +86,7 @@ PJ_DEF(pj_status_t) pjmedia_rtcp_fb_build_pli(\n \t\t\t\t\tvoid *buf,\n \t\t\t\t\tpj_size_t *length)\n {\n-    pjmedia_rtcp_common *hdr;\n+    pjmedia_rtcp_fb_common *hdr;\n     unsigned len;\n \n     PJ_ASSERT_RETURN(session && buf && length, PJ_EINVAL);\n@@ -96,11 +96,11 @@ PJ_DEF(pj_status_t) pjmedia_rtcp_fb_build_pli(\n \treturn PJ_ETOOSMALL;\n \n     /* Build RTCP-FB PLI header */\n-    hdr = (pjmedia_rtcp_common*)buf;\n-    pj_memcpy(hdr, &session->rtcp_rr_pkt.common,  sizeof(*hdr));\n-    hdr->pt = RTCP_PSFB;\n-    hdr->count = 1; /* FMT = 1 */\n-    hdr->length = pj_htons((pj_uint16_t)(len/4 - 1));\n+    hdr = (pjmedia_rtcp_fb_common*)buf;\n+    pj_memcpy(hdr, &session->rtcp_fb_com, sizeof(*hdr));\n+    hdr->rtcp_common.pt = RTCP_PSFB;\n+    hdr->rtcp_common.count = 1; /* FMT = 1 */\n+    hdr->rtcp_common.length = pj_htons((pj_uint16_t)(len/4 - 1));\n \n     /* Finally */\n     *length = len;\n@@ -119,7 +119,7 @@ PJ_DEF(pj_status_t) pjmedia_rtcp_fb_build_sli(\n \t\t\t\t\tunsigned sli_cnt,\n \t\t\t\t\tconst pjmedia_rtcp_fb_sli sli[])\n {\n-    pjmedia_rtcp_common *hdr;\n+    pjmedia_rtcp_fb_common *hdr;\n     pj_uint8_t *p;\n     unsigned len, i;\n \n@@ -130,11 +130,11 @@ PJ_DEF(pj_status_t) pjmedia_rtcp_fb_build_sli(\n \treturn PJ_ETOOSMALL;\n \n     /* Build RTCP-FB SLI header */\n-    hdr = (pjmedia_rtcp_common*)buf;\n-    pj_memcpy(hdr, &session->rtcp_rr_pkt.common,  sizeof(*hdr));\n-    hdr->pt = RTCP_PSFB;\n-    hdr->count = 2; /* FMT = 2 */\n-    hdr->length = pj_htons((pj_uint16_t)(len/4 - 1));\n+    hdr = (pjmedia_rtcp_fb_common*)buf;\n+    pj_memcpy(hdr, &session->rtcp_fb_com, sizeof(*hdr));\n+    hdr->rtcp_common.pt = RTCP_PSFB;\n+    hdr->rtcp_common.count = 2; /* FMT = 2 */\n+    hdr->rtcp_common.length = pj_htons((pj_uint16_t)(len/4 - 1));\n \n     /* Build RTCP-FB SLI FCI */\n     p = (pj_uint8_t*)hdr + sizeof(*hdr);\n@@ -166,7 +166,7 @@ PJ_DEF(pj_status_t) pjmedia_rtcp_fb_build_rpsi(\n \t\t\t\t\t    pj_size_t *length,\n \t\t\t\t\t    const pjmedia_rtcp_fb_rpsi *rpsi)\n {\n-    pjmedia_rtcp_common *hdr;\n+    pjmedia_rtcp_fb_common *hdr;\n     pj_uint8_t *p;\n     unsigned bitlen, padlen, len;\n \n@@ -179,11 +179,11 @@ PJ_DEF(pj_status_t) pjmedia_rtcp_fb_build_rpsi(\n \treturn PJ_ETOOSMALL;\n \n     /* Build RTCP-FB RPSI header */\n-    hdr = (pjmedia_rtcp_common*)buf;\n-    pj_memcpy(hdr, &session->rtcp_rr_pkt.common,  sizeof(*hdr));\n-    hdr->pt = RTCP_PSFB;\n-    hdr->count = 3; /* FMT = 3 */\n-    hdr->length = pj_htons((pj_uint16_t)(len/4 - 1));\n+    hdr = (pjmedia_rtcp_fb_common*)buf;\n+    pj_memcpy(hdr, &session->rtcp_fb_com, sizeof(*hdr));\n+    hdr->rtcp_common.pt = RTCP_PSFB;\n+    hdr->rtcp_common.count = 3; /* FMT = 3 */\n+    hdr->rtcp_common.length = pj_htons((pj_uint16_t)(len/4 - 1));\n \n     /* Build RTCP-FB RPSI FCI */\n     p = (pj_uint8_t*)hdr + sizeof(*hdr);\n@@ -620,18 +620,18 @@ PJ_DEF(pj_status_t) pjmedia_rtcp_fb_parse_nack(\n \t\t\t\t\tunsigned *nack_cnt,\n \t\t\t\t\tpjmedia_rtcp_fb_nack nack[])\n {\n-    pjmedia_rtcp_common *hdr = (pjmedia_rtcp_common*) buf;\n+    pjmedia_rtcp_fb_common *hdr = (pjmedia_rtcp_fb_common*) buf;\n     pj_uint8_t *p;\n     unsigned cnt, i;\n \n     PJ_ASSERT_RETURN(buf && nack_cnt && nack, PJ_EINVAL);\n-    PJ_ASSERT_RETURN(length >= sizeof(pjmedia_rtcp_common), PJ_ETOOSMALL);\n+    PJ_ASSERT_RETURN(length >= sizeof(pjmedia_rtcp_fb_common), PJ_ETOOSMALL);\n \n     /* Generic NACK uses pt==RTCP_RTPFB and FMT==1 */\n-    if (hdr->pt != RTCP_RTPFB || hdr->count != 1)\n+    if (hdr->rtcp_common.pt != RTCP_RTPFB || hdr->rtcp_common.count != 1)\n \treturn PJ_ENOTFOUND;\n \n-    cnt = pj_ntohs((pj_uint16_t)hdr->length);\n+    cnt = pj_ntohs((pj_uint16_t)hdr->rtcp_common.length);\n     if (cnt > 2) cnt -= 2; else cnt = 0;\n     if (length < (cnt+3)*4)\n \treturn PJ_ETOOSMALL;\n@@ -661,7 +661,7 @@ PJ_DEF(pj_status_t) pjmedia_rtcp_fb_parse_pli(\n \t\t\t\t\tconst void *buf,\n \t\t\t\t\tpj_size_t length)\n {\n-    pjmedia_rtcp_common *hdr = (pjmedia_rtcp_common*) buf;\n+    pjmedia_rtcp_fb_common *hdr = (pjmedia_rtcp_fb_common*) buf;\n \n     PJ_ASSERT_RETURN(buf, PJ_EINVAL);\n \n@@ -669,7 +669,7 @@ PJ_DEF(pj_status_t) pjmedia_rtcp_fb_parse_pli(\n     \treturn PJ_ETOOSMALL;\n \n     /* PLI uses pt==RTCP_PSFB and FMT==1 */\n-    if (hdr->pt != RTCP_PSFB || hdr->count != 1)\n+    if (hdr->rtcp_common.pt != RTCP_PSFB || hdr->rtcp_common.count != 1)\n \treturn PJ_ENOTFOUND;\n \n     return PJ_SUCCESS;\n@@ -686,18 +686,18 @@ PJ_DEF(pj_status_t) pjmedia_rtcp_fb_parse_sli(\n \t\t\t\t\tunsigned *sli_cnt,\n \t\t\t\t\tpjmedia_rtcp_fb_sli sli[])\n {\n-    pjmedia_rtcp_common *hdr = (pjmedia_rtcp_common*) buf;\n+    pjmedia_rtcp_fb_common *hdr = (pjmedia_rtcp_fb_common*) buf;\n     pj_uint8_t *p;\n     unsigned cnt, i;\n \n     PJ_ASSERT_RETURN(buf && sli_cnt && sli, PJ_EINVAL);\n-    PJ_ASSERT_RETURN(length >= sizeof(pjmedia_rtcp_common), PJ_ETOOSMALL);\n+    PJ_ASSERT_RETURN(length >= sizeof(pjmedia_rtcp_fb_common), PJ_ETOOSMALL);\n \n     /* PLI uses pt==RTCP_PSFB and FMT==2 */\n-    if (hdr->pt != RTCP_PSFB || hdr->count != 2)\n+    if (hdr->rtcp_common.pt != RTCP_PSFB || hdr->rtcp_common.count != 2)\n \treturn PJ_ENOTFOUND;\n \n-    cnt = pj_ntohs((pj_uint16_t)hdr->length) - 2;\n+    cnt = pj_ntohs((pj_uint16_t)hdr->rtcp_common.length) - 2;\n     if (length < (cnt+3)*4)\n \treturn PJ_ETOOSMALL;\n \n@@ -730,24 +730,43 @@ PJ_DEF(pj_status_t) pjmedia_rtcp_fb_parse_rpsi(\n \t\t\t\t\tpj_size_t length,\n \t\t\t\t\tpjmedia_rtcp_fb_rpsi *rpsi)\n {\n-    pjmedia_rtcp_common *hdr = (pjmedia_rtcp_common*) buf;\n+    pjmedia_rtcp_fb_common *hdr = (pjmedia_rtcp_fb_common*) buf;\n     pj_uint8_t *p;\n     pj_uint8_t padlen;\n     pj_size_t rpsi_len;\n \n     PJ_ASSERT_RETURN(buf && rpsi, PJ_EINVAL);\n-    PJ_ASSERT_RETURN(length >= sizeof(pjmedia_rtcp_common), PJ_ETOOSMALL);\n+    PJ_ASSERT_RETURN(length >= sizeof(pjmedia_rtcp_fb_common), PJ_ETOOSMALL);\n \n     /* RPSI uses pt==RTCP_PSFB and FMT==3 */\n-    if (hdr->pt != RTCP_PSFB || hdr->count != 3)\n+    if (hdr->rtcp_common.pt != RTCP_PSFB || hdr->rtcp_common.count != 3)\n \treturn PJ_ENOTFOUND;\n \n-    rpsi_len = (pj_ntohs((pj_uint16_t)hdr->length)-2) * 4;\n+    if (hdr->rtcp_common.length < 3) {    \n+        PJ_PERROR(3, (THIS_FILE, PJ_ETOOSMALL,\n+                      \"Failed parsing FB RPSI, invalid header length\"));\n+\treturn PJ_ETOOSMALL;\n+    }\n+\n+    rpsi_len = (pj_ntohs((pj_uint16_t)hdr->rtcp_common.length)-2) * 4;\n     if (length < rpsi_len + 12)\n \treturn PJ_ETOOSMALL;\n \n     p = (pj_uint8_t*)hdr + sizeof(*hdr);\n     padlen = *p++;\n+\n+    if (padlen >= 32) {\n+        PJ_PERROR(3, (THIS_FILE, PJ_ETOOBIG,\n+                      \"Failed parsing FB RPSI, invalid RPSI padding len\"));\n+\treturn PJ_ETOOBIG;\n+    }\n+\n+    if ((rpsi_len * 8) < (unsigned)(16 + padlen)) {\n+        PJ_PERROR(3, (THIS_FILE, PJ_ETOOSMALL,\n+                      \"Failed parsing FB RPSI, invalid RPSI bit len\"));\n+\treturn PJ_ETOOSMALL;\n+    }\n+\n     rpsi->pt = (*p++ & 0x7F);\n     rpsi->rpsi_bit_len = rpsi_len*8 - 16 - padlen;\n     pj_strset(&rpsi->rpsi, (char*)p, (rpsi->rpsi_bit_len + 7)/8);\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "d6d86830705f173fca6087a3e67ceaf68db80523",
        "repo": "torvalds/linux",
        "msg": "net ticp:fix a kernel-infoleak in __tipc_sendmsg()\n\nstruct tipc_socket_addr.ref has a 4-byte hole,and __tipc_getname() currently\ncopying it to user space,causing kernel-infoleak.\n\nBUG: KMSAN: kernel-infoleak in instrument_copy_to_user include/linux/instrumented.h:121 [inline]\nBUG: KMSAN: kernel-infoleak in instrument_copy_to_user include/linux/instrumented.h:121 [inline] lib/usercopy.c:33\nBUG: KMSAN: kernel-infoleak in _copy_to_user+0x1c9/0x270 lib/usercopy.c:33 lib/usercopy.c:33\n instrument_copy_to_user include/linux/instrumented.h:121 [inline]\n instrument_copy_to_user include/linux/instrumented.h:121 [inline] lib/usercopy.c:33\n _copy_to_user+0x1c9/0x270 lib/usercopy.c:33 lib/usercopy.c:33\n copy_to_user include/linux/uaccess.h:209 [inline]\n copy_to_user include/linux/uaccess.h:209 [inline] net/socket.c:287\n move_addr_to_user+0x3f6/0x600 net/socket.c:287 net/socket.c:287\n __sys_getpeername+0x470/0x6b0 net/socket.c:1987 net/socket.c:1987\n __do_sys_getpeername net/socket.c:1997 [inline]\n __se_sys_getpeername net/socket.c:1994 [inline]\n __do_sys_getpeername net/socket.c:1997 [inline] net/socket.c:1994\n __se_sys_getpeername net/socket.c:1994 [inline] net/socket.c:1994\n __x64_sys_getpeername+0xda/0x120 net/socket.c:1994 net/socket.c:1994\n do_syscall_x64 arch/x86/entry/common.c:51 [inline]\n do_syscall_x64 arch/x86/entry/common.c:51 [inline] arch/x86/entry/common.c:82\n do_syscall_64+0x54/0xd0 arch/x86/entry/common.c:82 arch/x86/entry/common.c:82\n entry_SYSCALL_64_after_hwframe+0x44/0xae\n\nUninit was stored to memory at:\n tipc_getname+0x575/0x5e0 net/tipc/socket.c:757 net/tipc/socket.c:757\n __sys_getpeername+0x3b3/0x6b0 net/socket.c:1984 net/socket.c:1984\n __do_sys_getpeername net/socket.c:1997 [inline]\n __se_sys_getpeername net/socket.c:1994 [inline]\n __do_sys_getpeername net/socket.c:1997 [inline] net/socket.c:1994\n __se_sys_getpeername net/socket.c:1994 [inline] net/socket.c:1994\n __x64_sys_getpeername+0xda/0x120 net/socket.c:1994 net/socket.c:1994\n do_syscall_x64 arch/x86/entry/common.c:51 [inline]\n do_syscall_x64 arch/x86/entry/common.c:51 [inline] arch/x86/entry/common.c:82\n do_syscall_64+0x54/0xd0 arch/x86/entry/common.c:82 arch/x86/entry/common.c:82\n entry_SYSCALL_64_after_hwframe+0x44/0xae\n\nUninit was stored to memory at:\n msg_set_word net/tipc/msg.h:212 [inline]\n msg_set_destport net/tipc/msg.h:619 [inline]\n msg_set_word net/tipc/msg.h:212 [inline] net/tipc/socket.c:1486\n msg_set_destport net/tipc/msg.h:619 [inline] net/tipc/socket.c:1486\n __tipc_sendmsg+0x44fa/0x5890 net/tipc/socket.c:1486 net/tipc/socket.c:1486\n tipc_sendmsg+0xeb/0x140 net/tipc/socket.c:1402 net/tipc/socket.c:1402\n sock_sendmsg_nosec net/socket.c:704 [inline]\n sock_sendmsg net/socket.c:724 [inline]\n sock_sendmsg_nosec net/socket.c:704 [inline] net/socket.c:2409\n sock_sendmsg net/socket.c:724 [inline] net/socket.c:2409\n ____sys_sendmsg+0xe11/0x12c0 net/socket.c:2409 net/socket.c:2409\n ___sys_sendmsg net/socket.c:2463 [inline]\n ___sys_sendmsg net/socket.c:2463 [inline] net/socket.c:2492\n __sys_sendmsg+0x704/0x840 net/socket.c:2492 net/socket.c:2492\n __do_sys_sendmsg net/socket.c:2501 [inline]\n __se_sys_sendmsg net/socket.c:2499 [inline]\n __do_sys_sendmsg net/socket.c:2501 [inline] net/socket.c:2499\n __se_sys_sendmsg net/socket.c:2499 [inline] net/socket.c:2499\n __x64_sys_sendmsg+0xe2/0x120 net/socket.c:2499 net/socket.c:2499\n do_syscall_x64 arch/x86/entry/common.c:51 [inline]\n do_syscall_x64 arch/x86/entry/common.c:51 [inline] arch/x86/entry/common.c:82\n do_syscall_64+0x54/0xd0 arch/x86/entry/common.c:82 arch/x86/entry/common.c:82\n entry_SYSCALL_64_after_hwframe+0x44/0xae\n\nLocal variable skaddr created at:\n __tipc_sendmsg+0x2d0/0x5890 net/tipc/socket.c:1419 net/tipc/socket.c:1419\n tipc_sendmsg+0xeb/0x140 net/tipc/socket.c:1402 net/tipc/socket.c:1402\n\nBytes 4-7 of 16 are uninitialized\nMemory access of size 16 starts at ffff888113753e00\nData copied to user address 0000000020000280\n\nReported-by: syzbot+cdbd40e0c3ca02cae3b7@syzkaller.appspotmail.com\nSigned-off-by: Haimin Zhang <tcs_kernel@tencent.com>\nAcked-by: Jon Maloy <jmaloy@redhat.com>\nLink: https://lore.kernel.org/r/1640918123-14547-1-git-send-email-tcs.kernel@gmail.com\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>An information leak flaw was found due to uninitialized memory in the Linux kernel's TIPC protocol subsystem, in the way a user sends a TIPC datagram to one or more destinations. This flaw allows a local user to read some kernel memory. This issue is limited to no more than 7 bytes, and the user cannot control what is read. This flaw affects the Linux kernel versions prior to 5.17-rc1.",
        "filename": "socket.c",
        "diff": "diff --git a/net/tipc/socket.c b/net/tipc/socket.c\nindex ad570c2450be8b..3e63c83e641c56 100644\n--- a/net/tipc/socket.c\n+++ b/net/tipc/socket.c\n@@ -1461,6 +1461,8 @@ static int __tipc_sendmsg(struct socket *sock, struct msghdr *m, size_t dlen)\n \t\tmsg_set_syn(hdr, 1);\n \t}\n \n+\tmemset(&skaddr, 0, sizeof(skaddr));\n+\n \t/* Determine destination */\n \tif (atype == TIPC_SERVICE_RANGE) {\n \t\treturn tipc_sendmcast(sock, ua, m, dlen, timeout);\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "2793769ff107d8d22dadd30c6e68cd781b569550",
        "repo": "ArtifexSoftware/ghostpdl",
        "msg": "Bug 701819: fixed ordering in if expression to avoid out-of-bounds access.\n\nFixes:\n    ./sanbin/gs -dBATCH -dNOPAUSE -r965 -sOutputFile=tmp -sDEVICE=pcx16 ../bug-701819.pdfA buffer overflow vulnerability in pcx_write_rle() in contrib/japanese/gdev10v.c of Artifex Software GhostScript v9.50 allows a remote attacker to cause a denial of service via a crafted PDF file. This is fixed in v9.51.",
        "filename": "gdevpcx.c",
        "diff": "diff --git a/devices/gdevpcx.c b/devices/gdevpcx.c\nindex 1735851d2d..91de4abb65 100644\n--- a/devices/gdevpcx.c\n+++ b/devices/gdevpcx.c\n@@ -442,7 +442,7 @@ pcx_write_rle(const byte * from, const byte * end, int step, gp_file * file)\n         byte data = *from;\n \n         from += step;\n-        if (data != *from || from == end) {\n+        if (from >= end || data != *from) {\n             if (data >= 0xc0)\n                 gp_fputc(0xc1, file);\n         } else {\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "eb50fb8f3bf670bd7d1cf8fd4368ef4a73083696",
        "repo": "samba-team/samba",
        "msg": "FSCTL_GET_SHADOW_COPY_DATA: Don't return 4 extra bytes at end\n\nlabels_data_count already accounts for the unicode null character at the\nend of the array. There is no need in adding space for it again.\n\nSigned-off-by: Christof Schmitt <christof.schmitt@us.ibm.com>\nReviewed-by: Jeremy Allison <jra@samba.org>\nReviewed-by: Simo Sorce <idra@samba.org>\n\nAutobuild-User(master): Jeremy Allison <jra@samba.org>\nAutobuild-Date(master): Tue Aug  6 04:03:17 CEST 2013 on sn-devel-104Samba 3.6.6 through 3.6.23, 4.0.x before 4.0.18, and 4.1.x before 4.1.8, when a certain vfs shadow copy configuration is enabled, does not properly initialize the SRV_SNAPSHOT_ARRAY response field, which allows remote authenticated users to obtain potentially sensitive information from process memory via a (1) FSCTL_GET_SHADOW_COPY_DATA or (2) FSCTL_SRV_ENUMERATE_SNAPSHOTS request.",
        "filename": "vfs_default.c",
        "diff": "diff --git a/source3/modules/vfs_default.c b/source3/modules/vfs_default.c\nindex efb020425c8e..304ef372f3a2 100644\n--- a/source3/modules/vfs_default.c\n+++ b/source3/modules/vfs_default.c\n@@ -1141,7 +1141,7 @@ static NTSTATUS vfswrap_fsctl(struct vfs_handle_struct *handle,\n \t\tif (!labels) {\n \t\t\t*out_len = 16;\n \t\t} else {\n-\t\t\t*out_len = 12 + labels_data_count + 4;\n+\t\t\t*out_len = 12 + labels_data_count;\n \t\t}\n \n \t\tif (max_out_len < *out_len) {\n@@ -1168,7 +1168,7 @@ static NTSTATUS vfswrap_fsctl(struct vfs_handle_struct *handle,\n \t\t}\n \n \t\t/* needed_data_count 4 bytes */\n-\t\tSIVAL(cur_pdata, 8, labels_data_count + 4);\n+\t\tSIVAL(cur_pdata, 8, labels_data_count);\n \n \t\tcur_pdata += 12;\n \n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "156d3911952d73b03d7420dc3540215247db0fe8",
        "repo": "vim/vim",
        "msg": "patch 8.2.5123: using invalid index when looking for spell suggestions\n\nProblem:    Using invalid index when looking for spell suggestions.\nSolution:   Do not decrement the index when it is zero.Out-of-bounds Read in GitHub repository vim/vim prior to 8.2.",
        "filename": "spellsuggest.c",
        "diff": "diff --git a/src/spellsuggest.c b/src/spellsuggest.c\nindex 5b460a3eaaef6..8f9756534fa2e 100644\n--- a/src/spellsuggest.c\n+++ b/src/spellsuggest.c\n@@ -1973,7 +1973,8 @@ suggest_trie_walk(\n \t\t\t    sp->ts_isdiff = (newscore != 0)\n \t\t\t\t\t\t       ? DIFF_YES : DIFF_NONE;\n \t\t\t}\n-\t\t\telse if (sp->ts_isdiff == DIFF_INSERT)\n+\t\t\telse if (sp->ts_isdiff == DIFF_INSERT\n+\t\t\t\t\t\t\t    && sp->ts_fidx > 0)\n \t\t\t    // When inserting trail bytes don't advance in the\n \t\t\t    // bad word.\n \t\t\t    --sp->ts_fidx;\ndiff --git a/src/testdir/test_spell.vim b/src/testdir/test_spell.vim\nindex aa5744475338f..0fd5ed91780fb 100644\n--- a/src/testdir/test_spell.vim\n+++ b/src/testdir/test_spell.vim\n@@ -70,6 +70,16 @@ func Test_z_equal_on_invalid_utf8_word()\n   bwipe!\n endfunc\n \n+func Test_z_equal_on_single_character()\n+  \" this was decrementing the index below zero\n+  new\n+  norm a0\\\ufffd\n+  norm zW\n+  norm \u0016z=\n+\n+  bwipe!\n+endfunc\n+\n \" Test spellbadword() with argument\n func Test_spellbadword()\n   set spell\ndiff --git a/src/version.c b/src/version.c\nindex 5411e1c189f3e..0a422742f1ad2 100644\n--- a/src/version.c\n+++ b/src/version.c\n@@ -734,6 +734,8 @@ static char *(features[]) =\n \n static int included_patches[] =\n {   /* Add new patch number below this line */\n+/**/\n+    5123,\n /**/\n     5122,\n /**/\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "48f0ea79f99174fb0a62cb2354e13496ce5b7c44",
        "repo": "radare/radare2",
        "msg": "Fix null deref in ne parser ##crash\n\n* Reported by @cnitlrt via huntr.dev\n* BountyID: d8b6d239-6d7b-4783-b26b-5be848c01aa1/\n* Reproducer: nenullNULL Pointer Dereference in GitHub repository radareorg/radare2 prior to 5.6.8. This vulnerability is capable of making the radare2 crash, thus affecting the availability of the system.",
        "filename": "ne.c",
        "diff": "diff --git a/libr/bin/format/ne/ne.c b/libr/bin/format/ne/ne.c\nindex d9dc886d2177a..e61ca7049101e 100644\n--- a/libr/bin/format/ne/ne.c\n+++ b/libr/bin/format/ne/ne.c\n@@ -77,7 +77,7 @@ static char *__func_name_from_ord(const char *module, ut16 ordinal) {\n \n RList *r_bin_ne_get_segments(r_bin_ne_obj_t *bin) {\n \tint i;\n-\tif (!bin) {\n+\tif (!bin || !bin->segment_entries) {\n \t\treturn NULL;\n \t}\n \tRList *segments = r_list_newf (free);\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "bc6f28995ff88f5d82c38afcfd65406f0ae375aa",
        "repo": "bonzini/qemu",
        "msg": "hw/sd: sdhci: Correctly set the controller status for ADMA\n\nWhen an ADMA transfer is started, the codes forget to set the\ncontroller status to indicate a transfer is in progress.\n\nWith this fix, the following 2 reproducers:\n\nhttps://paste.debian.net/plain/1185136\nhttps://paste.debian.net/plain/1185141\n\ncannot be reproduced with the following QEMU command line:\n\n$ qemu-system-x86_64 -nographic -machine accel=qtest -m 512M \\\n      -nodefaults -device sdhci-pci,sd-spec-version=3 \\\n      -drive if=sd,index=0,file=null-co://,format=raw,id=mydrive \\\n      -device sd-card,drive=mydrive -qtest stdio\n\nCc: qemu-stable@nongnu.org\nFixes: CVE-2020-17380\nFixes: CVE-2020-25085\nFixes: CVE-2021-3409\nFixes: d7dfca0807a0 (\"hw/sdhci: introduce standard SD host controller\")\nReported-by: Alexander Bulekov <alxndr@bu.edu>\nReported-by: Cornelius Aschermann (Ruhr-Universit\u00e4t Bochum)\nReported-by: Sergej Schumilo (Ruhr-Universit\u00e4t Bochum)\nReported-by: Simon W\u00f6rner (Ruhr-Universit\u00e4t Bochum)\nBuglink: https://bugs.launchpad.net/qemu/+bug/1892960\nBuglink: https://bugs.launchpad.net/qemu/+bug/1909418\nBuglink: https://bugzilla.redhat.com/show_bug.cgi?id=1928146\nTested-by: Alexander Bulekov <alxndr@bu.edu>\nReviewed-by: Philippe Mathieu-Daud\u00e9 <f4bug@amsat.org>\nSigned-off-by: Bin Meng <bmeng.cn@gmail.com>\nMessage-Id: <20210303122639.20004-4-bmeng.cn@gmail.com>\nSigned-off-by: Philippe Mathieu-Daud\u00e9 <f4bug@amsat.org>The patch for CVE-2020-17380/CVE-2020-25085 was found to be ineffective, thus making QEMU vulnerable to the out-of-bounds read/write access issues previously found in the SDHCI controller emulation code. This flaw allows a malicious privileged guest to crash the QEMU process on the host, resulting in a denial of service or potential code execution. QEMU up to (including) 5.2.0 is affected by this.",
        "filename": "sdhci.c",
        "diff": "diff --git a/hw/sd/sdhci.c b/hw/sd/sdhci.c\nindex 3feb6c3a1fee..7a2003b28b32 100644\n--- a/hw/sd/sdhci.c\n+++ b/hw/sd/sdhci.c\n@@ -768,7 +768,9 @@ static void sdhci_do_adma(SDHCIState *s)\n \n         switch (dscr.attr & SDHC_ADMA_ATTR_ACT_MASK) {\n         case SDHC_ADMA_ATTR_ACT_TRAN:  /* data transfer */\n+            s->prnsts |= SDHC_DATA_INHIBIT | SDHC_DAT_LINE_ACTIVE;\n             if (s->trnmod & SDHC_TRNS_READ) {\n+                s->prnsts |= SDHC_DOING_READ;\n                 while (length) {\n                     if (s->data_count == 0) {\n                         sdbus_read_data(&s->sdbus, s->fifo_buffer, block_size);\n@@ -796,6 +798,7 @@ static void sdhci_do_adma(SDHCIState *s)\n                     }\n                 }\n             } else {\n+                s->prnsts |= SDHC_DOING_WRITE;\n                 while (length) {\n                     begin = s->data_count;\n                     if ((length + begin) < block_size) {\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "fc739a058d99c9297ef6bfd923b809d85855b9a9",
        "repo": "torvalds/linux",
        "msg": "misc: fastrpc: prevent memory leak in fastrpc_dma_buf_attach\n\nIn fastrpc_dma_buf_attach if dma_get_sgtable fails the allocated memory\nfor a should be released.\n\nSigned-off-by: Navid Emamdoost <navid.emamdoost@gmail.com>\nLink: https://lore.kernel.org/r/20190925152742.16258-1-navid.emamdoost@gmail.com\nSigned-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>A memory leak in the fastrpc_dma_buf_attach() function in drivers/misc/fastrpc.c in the Linux kernel before 5.3.9 allows attackers to cause a denial of service (memory consumption) by triggering dma_get_sgtable() failures, aka CID-fc739a058d99.",
        "filename": "fastrpc.c",
        "diff": "diff --git a/drivers/misc/fastrpc.c b/drivers/misc/fastrpc.c\nindex 47ae84afac2e1e..1b1a794d639d0d 100644\n--- a/drivers/misc/fastrpc.c\n+++ b/drivers/misc/fastrpc.c\n@@ -527,6 +527,7 @@ static int fastrpc_dma_buf_attach(struct dma_buf *dmabuf,\n \t\t\t      FASTRPC_PHYS(buffer->phys), buffer->size);\n \tif (ret < 0) {\n \t\tdev_err(buffer->dev, \"failed to get scatterlist from DMA API\\n\");\n+\t\tkfree(a);\n \t\treturn -EINVAL;\n \t}\n \n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "790a85dbd4a81d5f5d8dd02a44d84f01512ef443",
        "repo": "mirror/ncurses",
        "msg": "ncurses 6.2 - patch 20200531\n\n+ correct configure version-check/warnng for g++ to allow for 10.x\n+ re-enable \"bel\" in konsole-base (report by Nia Huang)\n+ add linux-s entry (patch by Alexandre Montaron).\n+ drop long-obsolete convert_configure.pl\n+ add test/test_parm.c, for checking tparm changes.\n+ improve parameter-checking for tparm, adding function _nc_tiparm() to\n  handle the most-used case, which accepts only numeric parameters\n  (report/testcase by \"puppet-meteor\").\n+ use a more conservative estimate of the buffer-size in lib_tparm.c's\n  save_text() and save_number(), in case the sprintf() function\n  passes-through unexpected characters from a format specifier\n  (report/testcase by \"puppet-meteor\").\n+ add a check for end-of-string in cvtchar to handle a malformed\n  string in infotocap (report/testcase by \"puppet-meteor\").An issue was discovered in ncurses through v6.2-1. _nc_captoinfo in captoinfo.c has a heap-based buffer overflow.",
        "filename": "captoinfo.c",
        "diff": "diff --git a/Ada95/aclocal.m4 b/Ada95/aclocal.m4\nindex e4ce3771a..24f69deb6 100644\n--- a/Ada95/aclocal.m4\n+++ b/Ada95/aclocal.m4\n@@ -29,7 +29,7 @@ dnl***************************************************************************\n dnl\n dnl Author: Thomas E. Dickey\n dnl\n-dnl $Id: aclocal.m4,v 1.156 2020/05/23 23:39:36 tom Exp $\n+dnl $Id: aclocal.m4,v 1.157 2020/05/31 20:52:36 tom Exp $\n dnl Macros used in NCURSES Ada95 auto-configuration script.\n dnl\n dnl These macros are maintained separately from NCURSES.  The copyright on\n@@ -1421,7 +1421,7 @@ test \"$cf_cv_gnatprep_opt_t\" = yes && GNATPREP_OPTS=\"-T $GNATPREP_OPTS\"\n AC_SUBST(GNATPREP_OPTS)\n ])dnl\n dnl ---------------------------------------------------------------------------\n-dnl CF_GNAT_GENERICS version: 4 updated: 2019/12/31 08:53:54\n+dnl CF_GNAT_GENERICS version: 5 updated: 2020/05/31 16:49:35\n dnl ----------------\n AC_DEFUN([CF_GNAT_GENERICS],\n [\n@@ -1429,7 +1429,7 @@ AC_REQUIRE([CF_GNAT_VERSION])\n \n AC_MSG_CHECKING(if GNAT supports generics)\n case $cf_cv_gnat_version in\n-(3.[[1-9]]*|[[4-9]].*)\n+(3.[[1-9]]*|[[4-9]].*|[[1-9]][[0-9]].*)\n \tcf_gnat_generics=yes\n \t;;\n (*)\ndiff --git a/Ada95/configure b/Ada95/configure\nindex 1b18acd89..61a921f16 100755\n--- a/Ada95/configure\n+++ b/Ada95/configure\n@@ -16670,7 +16670,7 @@ test \"$cf_cv_gnatprep_opt_t\" = yes && GNATPREP_OPTS=\"-T $GNATPREP_OPTS\"\n echo \"$as_me:16670: checking if GNAT supports generics\" >&5\n echo $ECHO_N \"checking if GNAT supports generics... $ECHO_C\" >&6\n case $cf_cv_gnat_version in\n-(3.[1-9]*|[4-9].*)\n+(3.[1-9]*|[4-9].*|[1-9][0-9].*)\n \tcf_gnat_generics=yes\n \t;;\n (*)\ndiff --git a/MANIFEST b/MANIFEST\nindex 61e648793..69edf1570 100644\n--- a/MANIFEST\n+++ b/MANIFEST\n@@ -235,7 +235,6 @@\n ./config.sub\n ./configure\n ./configure.in\n-./convert_configure.pl\n ./dist.mk\n ./doc/hackguide.doc\n ./doc/html/Ada95.html\n@@ -1214,6 +1213,7 @@\n ./test/test_setupterm.c\n ./test/test_sgr.c\n ./test/test_termattrs.c\n+./test/test_tparm.c\n ./test/test_vid_puts.c\n ./test/test_vidputs.c\n ./test/testaddch.c\ndiff --git a/NEWS b/NEWS\nindex 09e1555f4..07434fa20 100644\n--- a/NEWS\n+++ b/NEWS\n@@ -26,7 +26,7 @@\n -- sale, use or other dealings in this Software without prior written        --\n -- authorization.                                                            --\n -------------------------------------------------------------------------------\n--- $Id: NEWS,v 1.3491 2020/05/24 00:07:37 tom Exp $\n+-- $Id: NEWS,v 1.3502 2020/05/31 19:41:31 tom Exp $\n -------------------------------------------------------------------------------\n \n This is a log of changes that ncurses has gone through since Zeyd started\n@@ -46,6 +46,22 @@ See the AUTHORS file for the corresponding full names.\n Changes through 1.9.9e did not credit all contributions;\n it is not possible to add this information.\n \n+20200531\n+\t+ correct configure version-check/warnng for g++ to allow for 10.x\n+\t+ re-enable \"bel\" in konsole-base (report by Nia Huang)\n+\t+ add linux-s entry (patch by Alexandre Montaron).\n+\t+ drop long-obsolete convert_configure.pl \n+\t+ add test/test_parm.c, for checking tparm changes.\n+\t+ improve parameter-checking for tparm, adding function _nc_tiparm() to\n+\t  handle the most-used case, which accepts only numeric parameters\n+\t  (report/testcase by \"puppet-meteor\").\n+\t+ use a more conservative estimate of the buffer-size in lib_tparm.c's\n+\t  save_text() and save_number(), in case the sprintf() function\n+\t  passes-through unexpected characters from a format specifier\n+\t  (report/testcase by \"puppet-meteor\").\n+\t+ add a check for end-of-string in cvtchar to handle a malformed\n+\t  string in infotocap (report/testcase by \"puppet-meteor\").\n+\n 20200523\n \t+ update version-check for gnat to allow for gnat 10.x to 99.x\n \t+ fix an uninitialized variable in lib_mouse.c changes (cf: 20200502)\ndiff --git a/VERSION b/VERSION\nindex f78341a7a..18172f0ce 100644\n--- a/VERSION\n+++ b/VERSION\n@@ -1 +1 @@\n-5:0:10\t6.2\t20200523\n+5:0:10\t6.2\t20200531\ndiff --git a/aclocal.m4 b/aclocal.m4\nindex ba09e6e9e..09260c46c 100644\n--- a/aclocal.m4\n+++ b/aclocal.m4\n@@ -29,7 +29,7 @@ dnl***************************************************************************\n dnl\n dnl Author: Thomas E. Dickey 1995-on\n dnl\n-dnl $Id: aclocal.m4,v 1.913 2020/05/23 23:46:10 tom Exp $\n+dnl $Id: aclocal.m4,v 1.914 2020/05/31 20:50:13 tom Exp $\n dnl Macros used in NCURSES auto-configuration script.\n dnl\n dnl These macros are maintained separately from NCURSES.  The copyright on\n@@ -2811,7 +2811,7 @@ test \"$cf_cv_gnatprep_opt_t\" = yes && GNATPREP_OPTS=\"-T $GNATPREP_OPTS\"\n AC_SUBST(GNATPREP_OPTS)\n ])dnl\n dnl ---------------------------------------------------------------------------\n-dnl CF_GNAT_GENERICS version: 4 updated: 2019/12/31 08:53:54\n+dnl CF_GNAT_GENERICS version: 5 updated: 2020/05/31 16:49:35\n dnl ----------------\n AC_DEFUN([CF_GNAT_GENERICS],\n [\n@@ -2819,7 +2819,7 @@ AC_REQUIRE([CF_GNAT_VERSION])\n \n AC_MSG_CHECKING(if GNAT supports generics)\n case $cf_cv_gnat_version in\n-(3.[[1-9]]*|[[4-9]].*)\n+(3.[[1-9]]*|[[4-9]].*|[[1-9]][[0-9]].*)\n \tcf_gnat_generics=yes\n \t;;\n (*)\ndiff --git a/configure b/configure\nindex 2478a5a17..b3b29cef2 100755\n--- a/configure\n+++ b/configure\n@@ -1,5 +1,5 @@\n #! /bin/sh\n-# From configure.in Revision: 1.707 .\n+# From configure.in Revision: 1.709 .\n # Guess values for system-dependent variables and create Makefiles.\n # Generated by Autoconf 2.52.20200111.\n #\n@@ -3355,9 +3355,9 @@ echo \"${ECHO_T}$GXX_VERSION\" >&6\n fi\n \n case $GXX_VERSION in\n-(1*|2.[0-6]*)\n-\t# GXX=\"\"; CXX=\"\"; ac_cv_prog_gxx=no\n-\t# cf_cxx_library=no\n+([1-9][0-9].*)\n+\t;;\n+(1.*|2.[0-6]*)\n \t{ echo \"$as_me:3361: WARNING: templates do not work\" >&5\n echo \"$as_me: WARNING: templates do not work\" >&2;}\n \t;;\n@@ -20100,6 +20100,7 @@ setenv \\\n setvbuf \\\n sigaction \\\n sigvec \\\n+snprintf \\\n strdup \\\n strstr \\\n sysconf \\\n@@ -20110,13 +20111,13 @@ vsnprintf \\\n \n do\n as_ac_var=`echo \"ac_cv_func_$ac_func\" | $as_tr_sh`\n-echo \"$as_me:20113: checking for $ac_func\" >&5\n+echo \"$as_me:20114: checking for $ac_func\" >&5\n echo $ECHO_N \"checking for $ac_func... $ECHO_C\" >&6\n if eval \"test \\\"\\${$as_ac_var+set}\\\" = set\"; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 20119 \"configure\"\n+#line 20120 \"configure\"\n #include \"confdefs.h\"\n #define $ac_func autoconf_temporary\n #include <limits.h>\t/* least-intrusive standard header which defines gcc2 __stub macros */\n@@ -20147,16 +20148,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:20150: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:20151: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20153: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20154: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:20156: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:20157: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20159: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20160: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   eval \"$as_ac_var=yes\"\n else\n@@ -20166,7 +20167,7 @@ eval \"$as_ac_var=no\"\n fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n fi\n-echo \"$as_me:20169: result: `eval echo '${'$as_ac_var'}'`\" >&5\n+echo \"$as_me:20170: result: `eval echo '${'$as_ac_var'}'`\" >&5\n echo \"${ECHO_T}`eval echo '${'$as_ac_var'}'`\" >&6\n if test `eval echo '${'$as_ac_var'}'` = yes; then\n   cat >>confdefs.h <<EOF\n@@ -20178,7 +20179,7 @@ done\n \n if test \"x$ac_cv_func_getopt\" = xno && \\\n    test \"x$cf_with_progs$cf_with_tests\" != xnono; then\n-\t{ { echo \"$as_me:20181: error: getopt is required for building programs\" >&5\n+\t{ { echo \"$as_me:20182: error: getopt is required for building programs\" >&5\n echo \"$as_me: error: getopt is required for building programs\" >&2;}\n    { (exit 1); exit 1; }; }\n fi\n@@ -20187,7 +20188,7 @@ if test \"x$with_safe_sprintf\" = xyes\n then\n \tif test \"x$ac_cv_func_vsnprintf\" = xyes\n \tthen\n-\t\t{ echo \"$as_me:20190: WARNING: will use vsnprintf instead of safe-sprintf option\" >&5\n+\t\t{ echo \"$as_me:20191: WARNING: will use vsnprintf instead of safe-sprintf option\" >&5\n echo \"$as_me: WARNING: will use vsnprintf instead of safe-sprintf option\" >&2;}\n \telse\n \n@@ -20200,14 +20201,14 @@ fi\n \n if test \"x$with_getcap\" = \"xyes\" ; then\n \n-echo \"$as_me:20203: checking for terminal-capability database functions\" >&5\n+echo \"$as_me:20204: checking for terminal-capability database functions\" >&5\n echo $ECHO_N \"checking for terminal-capability database functions... $ECHO_C\" >&6\n if test \"${cf_cv_cgetent+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n \n cat >conftest.$ac_ext <<_ACEOF\n-#line 20210 \"configure\"\n+#line 20211 \"configure\"\n #include \"confdefs.h\"\n \n #include <stdlib.h>\n@@ -20227,16 +20228,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:20230: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:20231: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20233: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20234: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:20236: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:20237: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20239: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20240: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_cgetent=yes\n else\n@@ -20247,7 +20248,7 @@ fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n \n fi\n-echo \"$as_me:20250: result: $cf_cv_cgetent\" >&5\n+echo \"$as_me:20251: result: $cf_cv_cgetent\" >&5\n echo \"${ECHO_T}$cf_cv_cgetent\" >&6\n \n if test \"$cf_cv_cgetent\" = yes\n@@ -20257,14 +20258,14 @@ cat >>confdefs.h <<\\EOF\n #define HAVE_BSD_CGETENT 1\n EOF\n \n-echo \"$as_me:20260: checking if cgetent uses const parameter\" >&5\n+echo \"$as_me:20261: checking if cgetent uses const parameter\" >&5\n echo $ECHO_N \"checking if cgetent uses const parameter... $ECHO_C\" >&6\n if test \"${cf_cv_cgetent_const+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n \n cat >conftest.$ac_ext <<_ACEOF\n-#line 20267 \"configure\"\n+#line 20268 \"configure\"\n #include \"confdefs.h\"\n \n #pragma GCC diagnostic error \"-Wincompatible-pointer-types-discards-qualifiers\"\n@@ -20287,16 +20288,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:20290: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:20291: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20293: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20294: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:20296: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:20297: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20299: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20300: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_cgetent_const=yes\n else\n@@ -20307,7 +20308,7 @@ fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n \n fi\n-echo \"$as_me:20310: result: $cf_cv_cgetent_const\" >&5\n+echo \"$as_me:20311: result: $cf_cv_cgetent_const\" >&5\n echo \"${ECHO_T}$cf_cv_cgetent_const\" >&6\n \tif test \"$cf_cv_cgetent_const\" = yes\n \tthen\n@@ -20321,14 +20322,14 @@ fi\n \n fi\n \n-echo \"$as_me:20324: checking for isascii\" >&5\n+echo \"$as_me:20325: checking for isascii\" >&5\n echo $ECHO_N \"checking for isascii... $ECHO_C\" >&6\n if test \"${cf_cv_have_isascii+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n \n \tcat >conftest.$ac_ext <<_ACEOF\n-#line 20331 \"configure\"\n+#line 20332 \"configure\"\n #include \"confdefs.h\"\n #include <ctype.h>\n int\n@@ -20340,16 +20341,16 @@ int x = isascii(' ')\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:20343: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:20344: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20346: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20347: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:20349: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:20350: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20352: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20353: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_have_isascii=yes\n else\n@@ -20360,7 +20361,7 @@ fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n \n fi\n-echo \"$as_me:20363: result: $cf_cv_have_isascii\" >&5\n+echo \"$as_me:20364: result: $cf_cv_have_isascii\" >&5\n echo \"${ECHO_T}$cf_cv_have_isascii\" >&6\n test \"$cf_cv_have_isascii\" = yes &&\n cat >>confdefs.h <<\\EOF\n@@ -20368,10 +20369,10 @@ cat >>confdefs.h <<\\EOF\n EOF\n \n if test \"$ac_cv_func_sigaction\" = yes; then\n-echo \"$as_me:20371: checking whether sigaction needs _POSIX_SOURCE\" >&5\n+echo \"$as_me:20372: checking whether sigaction needs _POSIX_SOURCE\" >&5\n echo $ECHO_N \"checking whether sigaction needs _POSIX_SOURCE... $ECHO_C\" >&6\n cat >conftest.$ac_ext <<_ACEOF\n-#line 20374 \"configure\"\n+#line 20375 \"configure\"\n #include \"confdefs.h\"\n \n #include <sys/types.h>\n@@ -20385,16 +20386,16 @@ struct sigaction act\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:20388: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:20389: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20391: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20392: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:20394: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:20395: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20397: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20398: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   sigact_bad=no\n else\n@@ -20402,7 +20403,7 @@ else\n cat conftest.$ac_ext >&5\n \n cat >conftest.$ac_ext <<_ACEOF\n-#line 20405 \"configure\"\n+#line 20406 \"configure\"\n #include \"confdefs.h\"\n \n #define _POSIX_SOURCE\n@@ -20417,16 +20418,16 @@ struct sigaction act\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:20420: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:20421: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20423: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20424: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:20426: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:20427: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20429: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20430: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   sigact_bad=yes\n \n@@ -20442,11 +20443,11 @@ fi\n rm -f conftest.$ac_objext conftest.$ac_ext\n fi\n rm -f conftest.$ac_objext conftest.$ac_ext\n-echo \"$as_me:20445: result: $sigact_bad\" >&5\n+echo \"$as_me:20446: result: $sigact_bad\" >&5\n echo \"${ECHO_T}$sigact_bad\" >&6\n fi\n \n-echo \"$as_me:20449: checking if nanosleep really works\" >&5\n+echo \"$as_me:20450: checking if nanosleep really works\" >&5\n echo $ECHO_N \"checking if nanosleep really works... $ECHO_C\" >&6\n if test \"${cf_cv_func_nanosleep+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -20456,7 +20457,7 @@ if test \"$cross_compiling\" = yes; then\n   cf_cv_func_nanosleep=unknown\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 20459 \"configure\"\n+#line 20460 \"configure\"\n #include \"confdefs.h\"\n \n #include <stdio.h>\n@@ -20481,15 +20482,15 @@ int main(void) {\n \n _ACEOF\n rm -f conftest$ac_exeext\n-if { (eval echo \"$as_me:20484: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:20485: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20487: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20488: \\$? = $ac_status\" >&5\n   (exit $ac_status); } && { ac_try='./conftest$ac_exeext'\n-  { (eval echo \"$as_me:20489: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:20490: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20492: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20493: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_func_nanosleep=yes\n else\n@@ -20501,7 +20502,7 @@ fi\n rm -f core core.* *.core conftest$ac_exeext conftest.$ac_objext conftest.$ac_ext\n fi\n fi\n-echo \"$as_me:20504: result: $cf_cv_func_nanosleep\" >&5\n+echo \"$as_me:20505: result: $cf_cv_func_nanosleep\" >&5\n echo \"${ECHO_T}$cf_cv_func_nanosleep\" >&6\n \n test \"$cf_cv_func_nanosleep\" = \"yes\" &&\n@@ -20518,23 +20519,23 @@ sys/termio.h \\\n \n do\n as_ac_Header=`echo \"ac_cv_header_$ac_header\" | $as_tr_sh`\n-echo \"$as_me:20521: checking for $ac_header\" >&5\n+echo \"$as_me:20522: checking for $ac_header\" >&5\n echo $ECHO_N \"checking for $ac_header... $ECHO_C\" >&6\n if eval \"test \\\"\\${$as_ac_Header+set}\\\" = set\"; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 20527 \"configure\"\n+#line 20528 \"configure\"\n #include \"confdefs.h\"\n #include <$ac_header>\n _ACEOF\n-if { (eval echo \"$as_me:20531: \\\"$ac_cpp conftest.$ac_ext\\\"\") >&5\n+if { (eval echo \"$as_me:20532: \\\"$ac_cpp conftest.$ac_ext\\\"\") >&5\n   (eval $ac_cpp conftest.$ac_ext) 2>conftest.er1\n   ac_status=$?\n   egrep -v '^ *\\+' conftest.er1 >conftest.err\n   rm -f conftest.er1\n   cat conftest.err >&5\n-  echo \"$as_me:20537: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20538: \\$? = $ac_status\" >&5\n   (exit $ac_status); } >/dev/null; then\n   if test -s conftest.err; then\n     ac_cpp_err=$ac_c_preproc_warn_flag\n@@ -20553,7 +20554,7 @@ else\n fi\n rm -f conftest.err conftest.$ac_ext\n fi\n-echo \"$as_me:20556: result: `eval echo '${'$as_ac_Header'}'`\" >&5\n+echo \"$as_me:20557: result: `eval echo '${'$as_ac_Header'}'`\" >&5\n echo \"${ECHO_T}`eval echo '${'$as_ac_Header'}'`\" >&6\n if test `eval echo '${'$as_ac_Header'}'` = yes; then\n   cat >>confdefs.h <<EOF\n@@ -20570,10 +20571,10 @@ if test \"$ac_cv_header_termios_h\" = yes ; then\n \t(*)\ttermios_bad=maybe ;;\n \tesac\n \tif test \"$termios_bad\" = maybe ; then\n-\techo \"$as_me:20573: checking whether termios.h needs _POSIX_SOURCE\" >&5\n+\techo \"$as_me:20574: checking whether termios.h needs _POSIX_SOURCE\" >&5\n echo $ECHO_N \"checking whether termios.h needs _POSIX_SOURCE... $ECHO_C\" >&6\n \tcat >conftest.$ac_ext <<_ACEOF\n-#line 20576 \"configure\"\n+#line 20577 \"configure\"\n #include \"confdefs.h\"\n #include <termios.h>\n int\n@@ -20585,16 +20586,16 @@ struct termios foo; int x = foo.c_iflag = 1; (void)x\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:20588: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:20589: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20591: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20592: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:20594: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:20595: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20597: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20598: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   termios_bad=no\n else\n@@ -20602,7 +20603,7 @@ else\n cat conftest.$ac_ext >&5\n \n \t\tcat >conftest.$ac_ext <<_ACEOF\n-#line 20605 \"configure\"\n+#line 20606 \"configure\"\n #include \"confdefs.h\"\n \n #define _POSIX_SOURCE\n@@ -20616,16 +20617,16 @@ struct termios foo; int x = foo.c_iflag = 2; (void)x\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:20619: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:20620: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20622: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20623: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:20625: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:20626: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20628: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20629: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   termios_bad=unknown\n else\n@@ -20641,19 +20642,19 @@ rm -f conftest.$ac_objext conftest.$ac_ext\n \n fi\n rm -f conftest.$ac_objext conftest.$ac_ext\n-\techo \"$as_me:20644: result: $termios_bad\" >&5\n+\techo \"$as_me:20645: result: $termios_bad\" >&5\n echo \"${ECHO_T}$termios_bad\" >&6\n \tfi\n fi\n \n-echo \"$as_me:20649: checking for tcgetattr\" >&5\n+echo \"$as_me:20650: checking for tcgetattr\" >&5\n echo $ECHO_N \"checking for tcgetattr... $ECHO_C\" >&6\n if test \"${cf_cv_have_tcgetattr+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n \n cat >conftest.$ac_ext <<_ACEOF\n-#line 20656 \"configure\"\n+#line 20657 \"configure\"\n #include \"confdefs.h\"\n \n #include <sys/types.h>\n@@ -20681,16 +20682,16 @@ tcgetattr(1, &foo);\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:20684: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:20685: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20687: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20688: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:20690: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:20691: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20693: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20694: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_have_tcgetattr=yes\n else\n@@ -20700,21 +20701,21 @@ cf_cv_have_tcgetattr=no\n fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n fi\n-echo \"$as_me:20703: result: $cf_cv_have_tcgetattr\" >&5\n+echo \"$as_me:20704: result: $cf_cv_have_tcgetattr\" >&5\n echo \"${ECHO_T}$cf_cv_have_tcgetattr\" >&6\n test \"$cf_cv_have_tcgetattr\" = yes &&\n cat >>confdefs.h <<\\EOF\n #define HAVE_TCGETATTR 1\n EOF\n \n-echo \"$as_me:20710: checking for vsscanf function or workaround\" >&5\n+echo \"$as_me:20711: checking for vsscanf function or workaround\" >&5\n echo $ECHO_N \"checking for vsscanf function or workaround... $ECHO_C\" >&6\n if test \"${cf_cv_func_vsscanf+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n \n cat >conftest.$ac_ext <<_ACEOF\n-#line 20717 \"configure\"\n+#line 20718 \"configure\"\n #include \"confdefs.h\"\n \n #include <stdarg.h>\n@@ -20730,16 +20731,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:20733: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:20734: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20736: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20737: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:20739: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:20740: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20742: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20743: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_func_vsscanf=vsscanf\n else\n@@ -20747,7 +20748,7 @@ else\n cat conftest.$ac_ext >&5\n \n cat >conftest.$ac_ext <<_ACEOF\n-#line 20750 \"configure\"\n+#line 20751 \"configure\"\n #include \"confdefs.h\"\n \n #include <stdarg.h>\n@@ -20769,16 +20770,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:20772: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:20773: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20775: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20776: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:20778: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:20779: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20781: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20782: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_func_vsscanf=vfscanf\n else\n@@ -20786,7 +20787,7 @@ else\n cat conftest.$ac_ext >&5\n \n cat >conftest.$ac_ext <<_ACEOF\n-#line 20789 \"configure\"\n+#line 20790 \"configure\"\n #include \"confdefs.h\"\n \n #include <stdarg.h>\n@@ -20808,16 +20809,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:20811: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:20812: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20814: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20815: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:20817: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:20818: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20820: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20821: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_func_vsscanf=_doscan\n else\n@@ -20832,7 +20833,7 @@ rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n fi\n-echo \"$as_me:20835: result: $cf_cv_func_vsscanf\" >&5\n+echo \"$as_me:20836: result: $cf_cv_func_vsscanf\" >&5\n echo \"${ECHO_T}$cf_cv_func_vsscanf\" >&6\n \n case $cf_cv_func_vsscanf in\n@@ -20858,23 +20859,23 @@ unistd.h \\\n \n do\n as_ac_Header=`echo \"ac_cv_header_$ac_header\" | $as_tr_sh`\n-echo \"$as_me:20861: checking for $ac_header\" >&5\n+echo \"$as_me:20862: checking for $ac_header\" >&5\n echo $ECHO_N \"checking for $ac_header... $ECHO_C\" >&6\n if eval \"test \\\"\\${$as_ac_Header+set}\\\" = set\"; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 20867 \"configure\"\n+#line 20868 \"configure\"\n #include \"confdefs.h\"\n #include <$ac_header>\n _ACEOF\n-if { (eval echo \"$as_me:20871: \\\"$ac_cpp conftest.$ac_ext\\\"\") >&5\n+if { (eval echo \"$as_me:20872: \\\"$ac_cpp conftest.$ac_ext\\\"\") >&5\n   (eval $ac_cpp conftest.$ac_ext) 2>conftest.er1\n   ac_status=$?\n   egrep -v '^ *\\+' conftest.er1 >conftest.err\n   rm -f conftest.er1\n   cat conftest.err >&5\n-  echo \"$as_me:20877: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20878: \\$? = $ac_status\" >&5\n   (exit $ac_status); } >/dev/null; then\n   if test -s conftest.err; then\n     ac_cpp_err=$ac_c_preproc_warn_flag\n@@ -20893,7 +20894,7 @@ else\n fi\n rm -f conftest.err conftest.$ac_ext\n fi\n-echo \"$as_me:20896: result: `eval echo '${'$as_ac_Header'}'`\" >&5\n+echo \"$as_me:20897: result: `eval echo '${'$as_ac_Header'}'`\" >&5\n echo \"${ECHO_T}`eval echo '${'$as_ac_Header'}'`\" >&6\n if test `eval echo '${'$as_ac_Header'}'` = yes; then\n   cat >>confdefs.h <<EOF\n@@ -20903,7 +20904,7 @@ EOF\n fi\n done\n \n-echo \"$as_me:20906: checking for working mkstemp\" >&5\n+echo \"$as_me:20907: checking for working mkstemp\" >&5\n echo $ECHO_N \"checking for working mkstemp... $ECHO_C\" >&6\n if test \"${cf_cv_func_mkstemp+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -20914,7 +20915,7 @@ if test \"$cross_compiling\" = yes; then\n   cf_cv_func_mkstemp=maybe\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 20917 \"configure\"\n+#line 20918 \"configure\"\n #include \"confdefs.h\"\n \n #include <sys/types.h>\n@@ -20955,15 +20956,15 @@ int main(void)\n \n _ACEOF\n rm -f conftest$ac_exeext\n-if { (eval echo \"$as_me:20958: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:20959: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20961: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20962: \\$? = $ac_status\" >&5\n   (exit $ac_status); } && { ac_try='./conftest$ac_exeext'\n-  { (eval echo \"$as_me:20963: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:20964: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20966: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20967: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_func_mkstemp=yes\n \n@@ -20978,16 +20979,16 @@ rm -f core core.* *.core conftest$ac_exeext conftest.$ac_objext conftest.$ac_ext\n fi\n \n fi\n-echo \"$as_me:20981: result: $cf_cv_func_mkstemp\" >&5\n+echo \"$as_me:20982: result: $cf_cv_func_mkstemp\" >&5\n echo \"${ECHO_T}$cf_cv_func_mkstemp\" >&6\n if test \"x$cf_cv_func_mkstemp\" = xmaybe ; then\n-\techo \"$as_me:20984: checking for mkstemp\" >&5\n+\techo \"$as_me:20985: checking for mkstemp\" >&5\n echo $ECHO_N \"checking for mkstemp... $ECHO_C\" >&6\n if test \"${ac_cv_func_mkstemp+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 20990 \"configure\"\n+#line 20991 \"configure\"\n #include \"confdefs.h\"\n #define mkstemp autoconf_temporary\n #include <limits.h>\t/* least-intrusive standard header which defines gcc2 __stub macros */\n@@ -21018,16 +21019,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:21021: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:21022: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21024: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21025: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:21027: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:21028: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21030: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21031: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   ac_cv_func_mkstemp=yes\n else\n@@ -21037,7 +21038,7 @@ ac_cv_func_mkstemp=no\n fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n fi\n-echo \"$as_me:21040: result: $ac_cv_func_mkstemp\" >&5\n+echo \"$as_me:21041: result: $ac_cv_func_mkstemp\" >&5\n echo \"${ECHO_T}$ac_cv_func_mkstemp\" >&6\n \n fi\n@@ -21058,21 +21059,21 @@ else\n fi\n \n if test \"x$cross_compiling\" = xyes ; then\n-\t{ echo \"$as_me:21061: WARNING: cross compiling: assume setvbuf params not reversed\" >&5\n+\t{ echo \"$as_me:21062: WARNING: cross compiling: assume setvbuf params not reversed\" >&5\n echo \"$as_me: WARNING: cross compiling: assume setvbuf params not reversed\" >&2;}\n else\n-\techo \"$as_me:21064: checking whether setvbuf arguments are reversed\" >&5\n+\techo \"$as_me:21065: checking whether setvbuf arguments are reversed\" >&5\n echo $ECHO_N \"checking whether setvbuf arguments are reversed... $ECHO_C\" >&6\n if test \"${ac_cv_func_setvbuf_reversed+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n   if test \"$cross_compiling\" = yes; then\n-  { { echo \"$as_me:21070: error: cannot run test program while cross compiling\" >&5\n+  { { echo \"$as_me:21071: error: cannot run test program while cross compiling\" >&5\n echo \"$as_me: error: cannot run test program while cross compiling\" >&2;}\n    { (exit 1); exit 1; }; }\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 21075 \"configure\"\n+#line 21076 \"configure\"\n #include \"confdefs.h\"\n #include <stdio.h>\n /* If setvbuf has the reversed format, exit 0. */\n@@ -21089,15 +21090,15 @@ main (void)\n }\n _ACEOF\n rm -f conftest$ac_exeext\n-if { (eval echo \"$as_me:21092: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:21093: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21095: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21096: \\$? = $ac_status\" >&5\n   (exit $ac_status); } && { ac_try='./conftest$ac_exeext'\n-  { (eval echo \"$as_me:21097: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:21098: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21100: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21101: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   ac_cv_func_setvbuf_reversed=yes\n else\n@@ -21110,7 +21111,7 @@ rm -f core core.* *.core conftest$ac_exeext conftest.$ac_objext conftest.$ac_ext\n fi\n rm -f core core.* *.core\n fi\n-echo \"$as_me:21113: result: $ac_cv_func_setvbuf_reversed\" >&5\n+echo \"$as_me:21114: result: $ac_cv_func_setvbuf_reversed\" >&5\n echo \"${ECHO_T}$ac_cv_func_setvbuf_reversed\" >&6\n if test $ac_cv_func_setvbuf_reversed = yes; then\n \n@@ -21121,13 +21122,13 @@ EOF\n fi\n \n fi\n-echo \"$as_me:21124: checking for intptr_t\" >&5\n+echo \"$as_me:21125: checking for intptr_t\" >&5\n echo $ECHO_N \"checking for intptr_t... $ECHO_C\" >&6\n if test \"${ac_cv_type_intptr_t+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 21130 \"configure\"\n+#line 21131 \"configure\"\n #include \"confdefs.h\"\n $ac_includes_default\n int\n@@ -21142,16 +21143,16 @@ if (sizeof (intptr_t))\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:21145: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:21146: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21148: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21149: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:21151: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:21152: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21154: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21155: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   ac_cv_type_intptr_t=yes\n else\n@@ -21161,7 +21162,7 @@ ac_cv_type_intptr_t=no\n fi\n rm -f conftest.$ac_objext conftest.$ac_ext\n fi\n-echo \"$as_me:21164: result: $ac_cv_type_intptr_t\" >&5\n+echo \"$as_me:21165: result: $ac_cv_type_intptr_t\" >&5\n echo \"${ECHO_T}$ac_cv_type_intptr_t\" >&6\n if test $ac_cv_type_intptr_t = yes; then\n   :\n@@ -21173,13 +21174,13 @@ EOF\n \n fi\n \n-echo \"$as_me:21176: checking for ssize_t\" >&5\n+echo \"$as_me:21177: checking for ssize_t\" >&5\n echo $ECHO_N \"checking for ssize_t... $ECHO_C\" >&6\n if test \"${ac_cv_type_ssize_t+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 21182 \"configure\"\n+#line 21183 \"configure\"\n #include \"confdefs.h\"\n $ac_includes_default\n int\n@@ -21194,16 +21195,16 @@ if (sizeof (ssize_t))\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:21197: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:21198: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21200: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21201: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:21203: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:21204: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21206: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21207: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   ac_cv_type_ssize_t=yes\n else\n@@ -21213,7 +21214,7 @@ ac_cv_type_ssize_t=no\n fi\n rm -f conftest.$ac_objext conftest.$ac_ext\n fi\n-echo \"$as_me:21216: result: $ac_cv_type_ssize_t\" >&5\n+echo \"$as_me:21217: result: $ac_cv_type_ssize_t\" >&5\n echo \"${ECHO_T}$ac_cv_type_ssize_t\" >&6\n if test $ac_cv_type_ssize_t = yes; then\n   :\n@@ -21225,14 +21226,14 @@ EOF\n \n fi\n \n-echo \"$as_me:21228: checking for type sigaction_t\" >&5\n+echo \"$as_me:21229: checking for type sigaction_t\" >&5\n echo $ECHO_N \"checking for type sigaction_t... $ECHO_C\" >&6\n if test \"${cf_cv_type_sigaction+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n \n \tcat >conftest.$ac_ext <<_ACEOF\n-#line 21235 \"configure\"\n+#line 21236 \"configure\"\n #include \"confdefs.h\"\n \n #include <signal.h>\n@@ -21245,16 +21246,16 @@ sigaction_t x\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:21248: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:21249: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21251: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21252: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:21254: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:21255: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21257: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21258: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_type_sigaction=yes\n else\n@@ -21265,14 +21266,14 @@ fi\n rm -f conftest.$ac_objext conftest.$ac_ext\n fi\n \n-echo \"$as_me:21268: result: $cf_cv_type_sigaction\" >&5\n+echo \"$as_me:21269: result: $cf_cv_type_sigaction\" >&5\n echo \"${ECHO_T}$cf_cv_type_sigaction\" >&6\n test \"$cf_cv_type_sigaction\" = yes &&\n cat >>confdefs.h <<\\EOF\n #define HAVE_TYPE_SIGACTION 1\n EOF\n \n-echo \"$as_me:21275: checking declaration of size-change\" >&5\n+echo \"$as_me:21276: checking declaration of size-change\" >&5\n echo $ECHO_N \"checking declaration of size-change... $ECHO_C\" >&6\n if test \"${cf_cv_sizechange+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -21293,7 +21294,7 @@ do\n \n \tfi\n \tcat >conftest.$ac_ext <<_ACEOF\n-#line 21296 \"configure\"\n+#line 21297 \"configure\"\n #include \"confdefs.h\"\n #include <sys/types.h>\n #ifdef HAVE_TERMIOS_H\n@@ -21343,16 +21344,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:21346: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:21347: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21349: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21350: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:21352: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:21353: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21355: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21356: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_sizechange=yes\n else\n@@ -21371,7 +21372,7 @@ rm -f conftest.$ac_objext conftest.$ac_ext\n done\n \n fi\n-echo \"$as_me:21374: result: $cf_cv_sizechange\" >&5\n+echo \"$as_me:21375: result: $cf_cv_sizechange\" >&5\n echo \"${ECHO_T}$cf_cv_sizechange\" >&6\n if test \"$cf_cv_sizechange\" != no ; then\n \n@@ -21389,13 +21390,13 @@ EOF\n \tesac\n fi\n \n-echo \"$as_me:21392: checking for memmove\" >&5\n+echo \"$as_me:21393: checking for memmove\" >&5\n echo $ECHO_N \"checking for memmove... $ECHO_C\" >&6\n if test \"${ac_cv_func_memmove+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 21398 \"configure\"\n+#line 21399 \"configure\"\n #include \"confdefs.h\"\n #define memmove autoconf_temporary\n #include <limits.h>\t/* least-intrusive standard header which defines gcc2 __stub macros */\n@@ -21426,16 +21427,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:21429: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:21430: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21432: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21433: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:21435: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:21436: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21438: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21439: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   ac_cv_func_memmove=yes\n else\n@@ -21445,19 +21446,19 @@ ac_cv_func_memmove=no\n fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n fi\n-echo \"$as_me:21448: result: $ac_cv_func_memmove\" >&5\n+echo \"$as_me:21449: result: $ac_cv_func_memmove\" >&5\n echo \"${ECHO_T}$ac_cv_func_memmove\" >&6\n if test $ac_cv_func_memmove = yes; then\n   :\n else\n \n-echo \"$as_me:21454: checking for bcopy\" >&5\n+echo \"$as_me:21455: checking for bcopy\" >&5\n echo $ECHO_N \"checking for bcopy... $ECHO_C\" >&6\n if test \"${ac_cv_func_bcopy+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 21460 \"configure\"\n+#line 21461 \"configure\"\n #include \"confdefs.h\"\n #define bcopy autoconf_temporary\n #include <limits.h>\t/* least-intrusive standard header which defines gcc2 __stub macros */\n@@ -21488,16 +21489,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:21491: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:21492: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21494: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21495: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:21497: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:21498: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21500: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21501: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   ac_cv_func_bcopy=yes\n else\n@@ -21507,11 +21508,11 @@ ac_cv_func_bcopy=no\n fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n fi\n-echo \"$as_me:21510: result: $ac_cv_func_bcopy\" >&5\n+echo \"$as_me:21511: result: $ac_cv_func_bcopy\" >&5\n echo \"${ECHO_T}$ac_cv_func_bcopy\" >&6\n if test $ac_cv_func_bcopy = yes; then\n \n-\techo \"$as_me:21514: checking if bcopy does overlapping moves\" >&5\n+\techo \"$as_me:21515: checking if bcopy does overlapping moves\" >&5\n echo $ECHO_N \"checking if bcopy does overlapping moves... $ECHO_C\" >&6\n if test \"${cf_cv_good_bcopy+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -21521,7 +21522,7 @@ else\n   cf_cv_good_bcopy=unknown\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 21524 \"configure\"\n+#line 21525 \"configure\"\n #include \"confdefs.h\"\n \n int main(void) {\n@@ -21535,15 +21536,15 @@ int main(void) {\n \n _ACEOF\n rm -f conftest$ac_exeext\n-if { (eval echo \"$as_me:21538: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:21539: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21541: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21542: \\$? = $ac_status\" >&5\n   (exit $ac_status); } && { ac_try='./conftest$ac_exeext'\n-  { (eval echo \"$as_me:21543: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:21544: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21546: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21547: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_good_bcopy=yes\n else\n@@ -21556,7 +21557,7 @@ rm -f core core.* *.core conftest$ac_exeext conftest.$ac_objext conftest.$ac_ext\n fi\n \n fi\n-echo \"$as_me:21559: result: $cf_cv_good_bcopy\" >&5\n+echo \"$as_me:21560: result: $cf_cv_good_bcopy\" >&5\n echo \"${ECHO_T}$cf_cv_good_bcopy\" >&6\n \n else\n@@ -21583,13 +21584,13 @@ tty 2>&1 >/dev/null || {\n for ac_func in posix_openpt\n do\n as_ac_var=`echo \"ac_cv_func_$ac_func\" | $as_tr_sh`\n-echo \"$as_me:21586: checking for $ac_func\" >&5\n+echo \"$as_me:21587: checking for $ac_func\" >&5\n echo $ECHO_N \"checking for $ac_func... $ECHO_C\" >&6\n if eval \"test \\\"\\${$as_ac_var+set}\\\" = set\"; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 21592 \"configure\"\n+#line 21593 \"configure\"\n #include \"confdefs.h\"\n #define $ac_func autoconf_temporary\n #include <limits.h>\t/* least-intrusive standard header which defines gcc2 __stub macros */\n@@ -21620,16 +21621,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:21623: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:21624: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21626: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21627: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:21629: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:21630: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21632: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21633: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   eval \"$as_ac_var=yes\"\n else\n@@ -21639,7 +21640,7 @@ eval \"$as_ac_var=no\"\n fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n fi\n-echo \"$as_me:21642: result: `eval echo '${'$as_ac_var'}'`\" >&5\n+echo \"$as_me:21643: result: `eval echo '${'$as_ac_var'}'`\" >&5\n echo \"${ECHO_T}`eval echo '${'$as_ac_var'}'`\" >&6\n if test `eval echo '${'$as_ac_var'}'` = yes; then\n   cat >>confdefs.h <<EOF\n@@ -21649,7 +21650,7 @@ EOF\n fi\n done\n  }\n-echo \"$as_me:21652: checking if poll really works\" >&5\n+echo \"$as_me:21653: checking if poll really works\" >&5\n echo $ECHO_N \"checking if poll really works... $ECHO_C\" >&6\n if test \"${cf_cv_working_poll+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -21659,7 +21660,7 @@ if test \"$cross_compiling\" = yes; then\n   cf_cv_working_poll=unknown\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 21662 \"configure\"\n+#line 21663 \"configure\"\n #include \"confdefs.h\"\n \n #include <stdlib.h>\n@@ -21711,15 +21712,15 @@ int main(void) {\n }\n _ACEOF\n rm -f conftest$ac_exeext\n-if { (eval echo \"$as_me:21714: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:21715: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21717: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21718: \\$? = $ac_status\" >&5\n   (exit $ac_status); } && { ac_try='./conftest$ac_exeext'\n-  { (eval echo \"$as_me:21719: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:21720: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21722: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21723: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_working_poll=yes\n else\n@@ -21731,21 +21732,21 @@ fi\n rm -f core core.* *.core conftest$ac_exeext conftest.$ac_objext conftest.$ac_ext\n fi\n fi\n-echo \"$as_me:21734: result: $cf_cv_working_poll\" >&5\n+echo \"$as_me:21735: result: $cf_cv_working_poll\" >&5\n echo \"${ECHO_T}$cf_cv_working_poll\" >&6\n test \"$cf_cv_working_poll\" = \"yes\" &&\n cat >>confdefs.h <<\\EOF\n #define HAVE_WORKING_POLL 1\n EOF\n \n-echo \"$as_me:21741: checking for va_copy\" >&5\n+echo \"$as_me:21742: checking for va_copy\" >&5\n echo $ECHO_N \"checking for va_copy... $ECHO_C\" >&6\n if test \"${cf_cv_have_va_copy+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n \n cat >conftest.$ac_ext <<_ACEOF\n-#line 21748 \"configure\"\n+#line 21749 \"configure\"\n #include \"confdefs.h\"\n \n #include <stdarg.h>\n@@ -21762,16 +21763,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:21765: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:21766: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21768: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21769: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:21771: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:21772: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21774: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21775: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_have_va_copy=yes\n else\n@@ -21781,7 +21782,7 @@ cf_cv_have_va_copy=no\n fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n fi\n-echo \"$as_me:21784: result: $cf_cv_have_va_copy\" >&5\n+echo \"$as_me:21785: result: $cf_cv_have_va_copy\" >&5\n echo \"${ECHO_T}$cf_cv_have_va_copy\" >&6\n \n if test \"$cf_cv_have_va_copy\" = yes;\n@@ -21793,14 +21794,14 @@ EOF\n \n else # !cf_cv_have_va_copy\n \n-echo \"$as_me:21796: checking for __va_copy\" >&5\n+echo \"$as_me:21797: checking for __va_copy\" >&5\n echo $ECHO_N \"checking for __va_copy... $ECHO_C\" >&6\n if test \"${cf_cv_have___va_copy+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n \n cat >conftest.$ac_ext <<_ACEOF\n-#line 21803 \"configure\"\n+#line 21804 \"configure\"\n #include \"confdefs.h\"\n \n #include <stdarg.h>\n@@ -21817,16 +21818,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:21820: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:21821: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21823: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21824: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:21826: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:21827: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21829: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21830: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_have___va_copy=yes\n else\n@@ -21836,7 +21837,7 @@ cf_cv_have___va_copy=no\n fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n fi\n-echo \"$as_me:21839: result: $cf_cv_have___va_copy\" >&5\n+echo \"$as_me:21840: result: $cf_cv_have___va_copy\" >&5\n echo \"${ECHO_T}$cf_cv_have___va_copy\" >&6\n \n if test \"$cf_cv_have___va_copy\" = yes\n@@ -21848,14 +21849,14 @@ EOF\n \n else # !cf_cv_have___va_copy\n \n-echo \"$as_me:21851: checking for __builtin_va_copy\" >&5\n+echo \"$as_me:21852: checking for __builtin_va_copy\" >&5\n echo $ECHO_N \"checking for __builtin_va_copy... $ECHO_C\" >&6\n if test \"${cf_cv_have___builtin_va_copy+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n \n cat >conftest.$ac_ext <<_ACEOF\n-#line 21858 \"configure\"\n+#line 21859 \"configure\"\n #include \"confdefs.h\"\n \n #include <stdarg.h>\n@@ -21872,16 +21873,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:21875: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:21876: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21878: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21879: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:21881: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:21882: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21884: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21885: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_have___builtin_va_copy=yes\n else\n@@ -21891,7 +21892,7 @@ cf_cv_have___builtin_va_copy=no\n fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n fi\n-echo \"$as_me:21894: result: $cf_cv_have___builtin_va_copy\" >&5\n+echo \"$as_me:21895: result: $cf_cv_have___builtin_va_copy\" >&5\n echo \"${ECHO_T}$cf_cv_have___builtin_va_copy\" >&6\n \n test \"$cf_cv_have___builtin_va_copy\" = yes &&\n@@ -21909,14 +21910,14 @@ case \"${cf_cv_have_va_copy}${cf_cv_have___va_copy}${cf_cv_have___builtin_va_copy\n \t;;\n \n (*)\n-\techo \"$as_me:21912: checking if we can simply copy va_list\" >&5\n+\techo \"$as_me:21913: checking if we can simply copy va_list\" >&5\n echo $ECHO_N \"checking if we can simply copy va_list... $ECHO_C\" >&6\n if test \"${cf_cv_pointer_va_list+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n \n cat >conftest.$ac_ext <<_ACEOF\n-#line 21919 \"configure\"\n+#line 21920 \"configure\"\n #include \"confdefs.h\"\n \n #include <stdarg.h>\n@@ -21933,16 +21934,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:21936: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:21937: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21939: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21940: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:21942: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:21943: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21945: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21946: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_pointer_va_list=yes\n else\n@@ -21952,19 +21953,19 @@ cf_cv_pointer_va_list=no\n fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n fi\n-echo \"$as_me:21955: result: $cf_cv_pointer_va_list\" >&5\n+echo \"$as_me:21956: result: $cf_cv_pointer_va_list\" >&5\n echo \"${ECHO_T}$cf_cv_pointer_va_list\" >&6\n \n \tif test \"$cf_cv_pointer_va_list\" = no\n \tthen\n-\t\techo \"$as_me:21960: checking if we can copy va_list indirectly\" >&5\n+\t\techo \"$as_me:21961: checking if we can copy va_list indirectly\" >&5\n echo $ECHO_N \"checking if we can copy va_list indirectly... $ECHO_C\" >&6\n if test \"${cf_cv_array_va_list+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n \n cat >conftest.$ac_ext <<_ACEOF\n-#line 21967 \"configure\"\n+#line 21968 \"configure\"\n #include \"confdefs.h\"\n \n #include <stdarg.h>\n@@ -21981,16 +21982,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:21984: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:21985: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21987: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21988: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:21990: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:21991: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21993: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21994: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_array_va_list=yes\n else\n@@ -22000,7 +22001,7 @@ cf_cv_array_va_list=no\n fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n fi\n-echo \"$as_me:22003: result: $cf_cv_array_va_list\" >&5\n+echo \"$as_me:22004: result: $cf_cv_array_va_list\" >&5\n echo \"${ECHO_T}$cf_cv_array_va_list\" >&6\n \t\ttest \"$cf_cv_array_va_list\" = yes &&\n cat >>confdefs.h <<\\EOF\n@@ -22011,13 +22012,13 @@ EOF\n \t;;\n esac\n \n-echo \"$as_me:22014: checking for pid_t\" >&5\n+echo \"$as_me:22015: checking for pid_t\" >&5\n echo $ECHO_N \"checking for pid_t... $ECHO_C\" >&6\n if test \"${ac_cv_type_pid_t+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 22020 \"configure\"\n+#line 22021 \"configure\"\n #include \"confdefs.h\"\n $ac_includes_default\n int\n@@ -22032,16 +22033,16 @@ if (sizeof (pid_t))\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:22035: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:22036: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:22038: \\$? = $ac_status\" >&5\n+  echo \"$as_me:22039: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:22041: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:22042: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:22044: \\$? = $ac_status\" >&5\n+  echo \"$as_me:22045: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   ac_cv_type_pid_t=yes\n else\n@@ -22051,7 +22052,7 @@ ac_cv_type_pid_t=no\n fi\n rm -f conftest.$ac_objext conftest.$ac_ext\n fi\n-echo \"$as_me:22054: result: $ac_cv_type_pid_t\" >&5\n+echo \"$as_me:22055: result: $ac_cv_type_pid_t\" >&5\n echo \"${ECHO_T}$ac_cv_type_pid_t\" >&6\n if test $ac_cv_type_pid_t = yes; then\n   :\n@@ -22066,23 +22067,23 @@ fi\n for ac_header in unistd.h vfork.h\n do\n as_ac_Header=`echo \"ac_cv_header_$ac_header\" | $as_tr_sh`\n-echo \"$as_me:22069: checking for $ac_header\" >&5\n+echo \"$as_me:22070: checking for $ac_header\" >&5\n echo $ECHO_N \"checking for $ac_header... $ECHO_C\" >&6\n if eval \"test \\\"\\${$as_ac_Header+set}\\\" = set\"; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 22075 \"configure\"\n+#line 22076 \"configure\"\n #include \"confdefs.h\"\n #include <$ac_header>\n _ACEOF\n-if { (eval echo \"$as_me:22079: \\\"$ac_cpp conftest.$ac_ext\\\"\") >&5\n+if { (eval echo \"$as_me:22080: \\\"$ac_cpp conftest.$ac_ext\\\"\") >&5\n   (eval $ac_cpp conftest.$ac_ext) 2>conftest.er1\n   ac_status=$?\n   egrep -v '^ *\\+' conftest.er1 >conftest.err\n   rm -f conftest.er1\n   cat conftest.err >&5\n-  echo \"$as_me:22085: \\$? = $ac_status\" >&5\n+  echo \"$as_me:22086: \\$? = $ac_status\" >&5\n   (exit $ac_status); } >/dev/null; then\n   if test -s conftest.err; then\n     ac_cpp_err=$ac_c_preproc_warn_flag\n@@ -22101,7 +22102,7 @@ else\n fi\n rm -f conftest.err conftest.$ac_ext\n fi\n-echo \"$as_me:22104: result: `eval echo '${'$as_ac_Header'}'`\" >&5\n+echo \"$as_me:22105: result: `eval echo '${'$as_ac_Header'}'`\" >&5\n echo \"${ECHO_T}`eval echo '${'$as_ac_Header'}'`\" >&6\n if test `eval echo '${'$as_ac_Header'}'` = yes; then\n   cat >>confdefs.h <<EOF\n@@ -22114,13 +22115,13 @@ done\n for ac_func in fork vfork\n do\n as_ac_var=`echo \"ac_cv_func_$ac_func\" | $as_tr_sh`\n-echo \"$as_me:22117: checking for $ac_func\" >&5\n+echo \"$as_me:22118: checking for $ac_func\" >&5\n echo $ECHO_N \"checking for $ac_func... $ECHO_C\" >&6\n if eval \"test \\\"\\${$as_ac_var+set}\\\" = set\"; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 22123 \"configure\"\n+#line 22124 \"configure\"\n #include \"confdefs.h\"\n #define $ac_func autoconf_temporary\n #include <limits.h>\t/* least-intrusive standard header which defines gcc2 __stub macros */\n@@ -22151,16 +22152,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:22154: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:22155: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:22157: \\$? = $ac_status\" >&5\n+  echo \"$as_me:22158: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:22160: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:22161: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:22163: \\$? = $ac_status\" >&5\n+  echo \"$as_me:22164: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   eval \"$as_ac_var=yes\"\n else\n@@ -22170,7 +22171,7 @@ eval \"$as_ac_var=no\"\n fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n fi\n-echo \"$as_me:22173: result: `eval echo '${'$as_ac_var'}'`\" >&5\n+echo \"$as_me:22174: result: `eval echo '${'$as_ac_var'}'`\" >&5\n echo \"${ECHO_T}`eval echo '${'$as_ac_var'}'`\" >&6\n if test `eval echo '${'$as_ac_var'}'` = yes; then\n   cat >>confdefs.h <<EOF\n@@ -22182,7 +22183,7 @@ done\n \n ac_cv_func_fork_works=$ac_cv_func_fork\n if test \"x$ac_cv_func_fork\" = xyes; then\n-  echo \"$as_me:22185: checking for working fork\" >&5\n+  echo \"$as_me:22186: checking for working fork\" >&5\n echo $ECHO_N \"checking for working fork... $ECHO_C\" >&6\n if test \"${ac_cv_func_fork_works+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -22205,15 +22206,15 @@ else\n       }\n _ACEOF\n rm -f conftest$ac_exeext\n-if { (eval echo \"$as_me:22208: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:22209: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:22211: \\$? = $ac_status\" >&5\n+  echo \"$as_me:22212: \\$? = $ac_status\" >&5\n   (exit $ac_status); } && { ac_try='./conftest$ac_exeext'\n-  { (eval echo \"$as_me:22213: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:22214: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:22216: \\$? = $ac_status\" >&5\n+  echo \"$as_me:22217: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   ac_cv_func_fork_works=yes\n else\n@@ -22225,7 +22226,7 @@ fi\n rm -f core core.* *.core conftest$ac_exeext conftest.$ac_objext conftest.$ac_ext\n fi\n fi\n-echo \"$as_me:22228: result: $ac_cv_func_fork_works\" >&5\n+echo \"$as_me:22229: result: $ac_cv_func_fork_works\" >&5\n echo \"${ECHO_T}$ac_cv_func_fork_works\" >&6\n \n fi\n@@ -22239,12 +22240,12 @@ if test \"x$ac_cv_func_fork_works\" = xcross; then\n       ac_cv_func_fork_works=yes\n       ;;\n   esac\n-  { echo \"$as_me:22242: WARNING: CROSS: Result $ac_cv_func_fork_works guessed due to cross-compiling.\" >&5\n+  { echo \"$as_me:22243: WARNING: CROSS: Result $ac_cv_func_fork_works guessed due to cross-compiling.\" >&5\n echo \"$as_me: WARNING: CROSS: Result $ac_cv_func_fork_works guessed due to cross-compiling.\" >&2;}\n fi\n ac_cv_func_vfork_works=$ac_cv_func_vfork\n if test \"x$ac_cv_func_vfork\" = xyes; then\n-  echo \"$as_me:22247: checking for working vfork\" >&5\n+  echo \"$as_me:22248: checking for working vfork\" >&5\n echo $ECHO_N \"checking for working vfork... $ECHO_C\" >&6\n if test \"${ac_cv_func_vfork_works+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -22253,7 +22254,7 @@ else\n   ac_cv_func_vfork_works=cross\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 22256 \"configure\"\n+#line 22257 \"configure\"\n #include \"confdefs.h\"\n /* Thanks to Paul Eggert for this test.  */\n #include <stdio.h>\n@@ -22350,15 +22351,15 @@ main (void)\n }\n _ACEOF\n rm -f conftest$ac_exeext\n-if { (eval echo \"$as_me:22353: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:22354: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:22356: \\$? = $ac_status\" >&5\n+  echo \"$as_me:22357: \\$? = $ac_status\" >&5\n   (exit $ac_status); } && { ac_try='./conftest$ac_exeext'\n-  { (eval echo \"$as_me:22358: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:22359: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:22361: \\$? = $ac_status\" >&5\n+  echo \"$as_me:22362: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   ac_cv_func_vfork_works=yes\n else\n@@ -22370,13 +22371,13 @@ fi\n rm -f core core.* *.core conftest$ac_exeext conftest.$ac_objext conftest.$ac_ext\n fi\n fi\n-echo \"$as_me:22373: result: $ac_cv_func_vfork_works\" >&5\n+echo \"$as_me:22374: result: $ac_cv_func_vfork_works\" >&5\n echo \"${ECHO_T}$ac_cv_func_vfork_works\" >&6\n \n fi;\n if test \"x$ac_cv_func_fork_works\" = xcross; then\n   ac_cv_func_vfork_works=ac_cv_func_vfork\n-  { echo \"$as_me:22379: WARNING: CROSS: Result $ac_cv_func_vfork_works guessed due to cross-compiling.\" >&5\n+  { echo \"$as_me:22380: WARNING: CROSS: Result $ac_cv_func_vfork_works guessed due to cross-compiling.\" >&5\n echo \"$as_me: WARNING: CROSS: Result $ac_cv_func_vfork_works guessed due to cross-compiling.\" >&2;}\n fi\n \n@@ -22401,7 +22402,7 @@ EOF\n \n fi\n \n-echo \"$as_me:22404: checking if fopen accepts explicit binary mode\" >&5\n+echo \"$as_me:22405: checking if fopen accepts explicit binary mode\" >&5\n echo $ECHO_N \"checking if fopen accepts explicit binary mode... $ECHO_C\" >&6\n if test \"${cf_cv_fopen_bin_r+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -22411,7 +22412,7 @@ else\n   cf_cv_fopen_bin_r=unknown\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 22414 \"configure\"\n+#line 22415 \"configure\"\n #include \"confdefs.h\"\n \n #include <stdio.h>\n@@ -22444,15 +22445,15 @@ int main(void) {\n \n _ACEOF\n rm -f conftest$ac_exeext\n-if { (eval echo \"$as_me:22447: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:22448: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:22450: \\$? = $ac_status\" >&5\n+  echo \"$as_me:22451: \\$? = $ac_status\" >&5\n   (exit $ac_status); } && { ac_try='./conftest$ac_exeext'\n-  { (eval echo \"$as_me:22452: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:22453: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:22455: \\$? = $ac_status\" >&5\n+  echo \"$as_me:22456: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_fopen_bin_r=yes\n else\n@@ -22465,7 +22466,7 @@ rm -f core core.* *.core conftest$ac_exeext conftest.$ac_objext conftest.$ac_ext\n fi\n \n fi\n-echo \"$as_me:22468: result: $cf_cv_fopen_bin_r\" >&5\n+echo \"$as_me:22469: result: $cf_cv_fopen_bin_r\" >&5\n echo \"${ECHO_T}$cf_cv_fopen_bin_r\" >&6\n test \"x$cf_cv_fopen_bin_r\" != xno &&\n cat >>confdefs.h <<\\EOF\n@@ -22474,7 +22475,7 @@ EOF\n \n # special check for test/ditto.c\n \n-echo \"$as_me:22477: checking for openpty in -lutil\" >&5\n+echo \"$as_me:22478: checking for openpty in -lutil\" >&5\n echo $ECHO_N \"checking for openpty in -lutil... $ECHO_C\" >&6\n if test \"${ac_cv_lib_util_openpty+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -22482,7 +22483,7 @@ else\n   ac_check_lib_save_LIBS=$LIBS\n LIBS=\"-lutil  $LIBS\"\n cat >conftest.$ac_ext <<_ACEOF\n-#line 22485 \"configure\"\n+#line 22486 \"configure\"\n #include \"confdefs.h\"\n \n /* Override any gcc2 internal prototype to avoid an error.  */\n@@ -22501,16 +22502,16 @@ openpty ();\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:22504: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:22505: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:22507: \\$? = $ac_status\" >&5\n+  echo \"$as_me:22508: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:22510: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:22511: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:22513: \\$? = $ac_status\" >&5\n+  echo \"$as_me:22514: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   ac_cv_lib_util_openpty=yes\n else\n@@ -22521,7 +22522,7 @@ fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n LIBS=$ac_check_lib_save_LIBS\n fi\n-echo \"$as_me:22524: result: $ac_cv_lib_util_openpty\" >&5\n+echo \"$as_me:22525: result: $ac_cv_lib_util_openpty\" >&5\n echo \"${ECHO_T}$ac_cv_lib_util_openpty\" >&6\n if test $ac_cv_lib_util_openpty = yes; then\n   cf_cv_lib_util=yes\n@@ -22529,7 +22530,7 @@ else\n   cf_cv_lib_util=no\n fi\n \n-echo \"$as_me:22532: checking for openpty header\" >&5\n+echo \"$as_me:22533: checking for openpty header\" >&5\n echo $ECHO_N \"checking for openpty header... $ECHO_C\" >&6\n if test \"${cf_cv_func_openpty+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -22556,7 +22557,7 @@ LIBS=\"$cf_add_libs\"\n \tfor cf_header in pty.h libutil.h util.h\n \tdo\n \tcat >conftest.$ac_ext <<_ACEOF\n-#line 22559 \"configure\"\n+#line 22560 \"configure\"\n #include \"confdefs.h\"\n \n #include <$cf_header>\n@@ -22573,16 +22574,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:22576: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:22577: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:22579: \\$? = $ac_status\" >&5\n+  echo \"$as_me:22580: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:22582: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:22583: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:22585: \\$? = $ac_status\" >&5\n+  echo \"$as_me:22586: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n \n \t\tcf_cv_func_openpty=$cf_header\n@@ -22600,7 +22601,7 @@ rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n \tLIBS=\"$cf_save_LIBS\"\n \n fi\n-echo \"$as_me:22603: result: $cf_cv_func_openpty\" >&5\n+echo \"$as_me:22604: result: $cf_cv_func_openpty\" >&5\n echo \"${ECHO_T}$cf_cv_func_openpty\" >&6\n \n if test \"$cf_cv_func_openpty\" != no ; then\n@@ -22673,7 +22674,7 @@ if test -n \"$with_hashed_db/include\" ; then\n \tCPPFLAGS=\"${CPPFLAGS}-I$cf_add_incdir\"\n \n \t\t\t  cat >conftest.$ac_ext <<_ACEOF\n-#line 22676 \"configure\"\n+#line 22677 \"configure\"\n #include \"confdefs.h\"\n #include <stdio.h>\n int\n@@ -22685,16 +22686,16 @@ printf(\"Hello\")\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:22688: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:22689: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:22691: \\$? = $ac_status\" >&5\n+  echo \"$as_me:22692: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:22694: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:22695: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:22697: \\$? = $ac_status\" >&5\n+  echo \"$as_me:22698: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   :\n else\n@@ -22711,7 +22712,7 @@ rm -f conftest.$ac_objext conftest.$ac_ext\n \t\tif test \"$cf_have_incdir\" = no ; then\n \t\t  test -n \"$verbose\" && echo \"\tadding $cf_add_incdir to include-path\" 1>&6\n \n-echo \"${as_me:-configure}:22714: testing adding $cf_add_incdir to include-path ...\" 1>&5\n+echo \"${as_me:-configure}:22715: testing adding $cf_add_incdir to include-path ...\" 1>&5\n \n \t\t  CPPFLAGS=\"$CPPFLAGS -I$cf_add_incdir\"\n \n@@ -22747,7 +22748,7 @@ if test -n \"$with_hashed_db/lib\" ; then\n \t\t\tif test \"$cf_have_libdir\" = no ; then\n \t\t\t\ttest -n \"$verbose\" && echo \"\tadding $cf_add_libdir to library-path\" 1>&6\n \n-echo \"${as_me:-configure}:22750: testing adding $cf_add_libdir to library-path ...\" 1>&5\n+echo \"${as_me:-configure}:22751: testing adding $cf_add_libdir to library-path ...\" 1>&5\n \n \t\t\t\tLDFLAGS=\"-L$cf_add_libdir $LDFLAGS\"\n \t\t\tfi\n@@ -22758,7 +22759,7 @@ fi\n \telse\n \t\tcase \"$with_hashed_db\" in\n \t\t(./*|../*|/*)\n-\t\t\t{ echo \"$as_me:22761: WARNING: no such directory $with_hashed_db\" >&5\n+\t\t\t{ echo \"$as_me:22762: WARNING: no such directory $with_hashed_db\" >&5\n echo \"$as_me: WARNING: no such directory $with_hashed_db\" >&2;}\n \t\t\t;;\n \t\t(*)\n@@ -22830,7 +22831,7 @@ if test -n \"$cf_item\" ; then\n \tCPPFLAGS=\"${CPPFLAGS}-I$cf_add_incdir\"\n \n \t\t\t  cat >conftest.$ac_ext <<_ACEOF\n-#line 22833 \"configure\"\n+#line 22834 \"configure\"\n #include \"confdefs.h\"\n #include <stdio.h>\n int\n@@ -22842,16 +22843,16 @@ printf(\"Hello\")\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:22845: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:22846: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:22848: \\$? = $ac_status\" >&5\n+  echo \"$as_me:22849: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:22851: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:22852: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:22854: \\$? = $ac_status\" >&5\n+  echo \"$as_me:22855: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   :\n else\n@@ -22868,7 +22869,7 @@ rm -f conftest.$ac_objext conftest.$ac_ext\n \t\tif test \"$cf_have_incdir\" = no ; then\n \t\t  test -n \"$verbose\" && echo \"\tadding $cf_add_incdir to include-path\" 1>&6\n \n-echo \"${as_me:-configure}:22871: testing adding $cf_add_incdir to include-path ...\" 1>&5\n+echo \"${as_me:-configure}:22872: testing adding $cf_add_incdir to include-path ...\" 1>&5\n \n \t\t  CPPFLAGS=\"$CPPFLAGS -I$cf_add_incdir\"\n \n@@ -22948,7 +22949,7 @@ if test -n \"$cf_item\" ; then\n \t\t\tif test \"$cf_have_libdir\" = no ; then\n \t\t\t\ttest -n \"$verbose\" && echo \"\tadding $cf_add_libdir to library-path\" 1>&6\n \n-echo \"${as_me:-configure}:22951: testing adding $cf_add_libdir to library-path ...\" 1>&5\n+echo \"${as_me:-configure}:22952: testing adding $cf_add_libdir to library-path ...\" 1>&5\n \n \t\t\t\tLDFLAGS=\"-L$cf_add_libdir $LDFLAGS\"\n \t\t\tfi\n@@ -22965,23 +22966,23 @@ fi\n \tfi\n esac\n \n-echo \"$as_me:22968: checking for db.h\" >&5\n+echo \"$as_me:22969: checking for db.h\" >&5\n echo $ECHO_N \"checking for db.h... $ECHO_C\" >&6\n if test \"${ac_cv_header_db_h+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 22974 \"configure\"\n+#line 22975 \"configure\"\n #include \"confdefs.h\"\n #include <db.h>\n _ACEOF\n-if { (eval echo \"$as_me:22978: \\\"$ac_cpp conftest.$ac_ext\\\"\") >&5\n+if { (eval echo \"$as_me:22979: \\\"$ac_cpp conftest.$ac_ext\\\"\") >&5\n   (eval $ac_cpp conftest.$ac_ext) 2>conftest.er1\n   ac_status=$?\n   egrep -v '^ *\\+' conftest.er1 >conftest.err\n   rm -f conftest.er1\n   cat conftest.err >&5\n-  echo \"$as_me:22984: \\$? = $ac_status\" >&5\n+  echo \"$as_me:22985: \\$? = $ac_status\" >&5\n   (exit $ac_status); } >/dev/null; then\n   if test -s conftest.err; then\n     ac_cpp_err=$ac_c_preproc_warn_flag\n@@ -23000,11 +23001,11 @@ else\n fi\n rm -f conftest.err conftest.$ac_ext\n fi\n-echo \"$as_me:23003: result: $ac_cv_header_db_h\" >&5\n+echo \"$as_me:23004: result: $ac_cv_header_db_h\" >&5\n echo \"${ECHO_T}$ac_cv_header_db_h\" >&6\n if test $ac_cv_header_db_h = yes; then\n \n-echo \"$as_me:23007: checking for version of db\" >&5\n+echo \"$as_me:23008: checking for version of db\" >&5\n echo $ECHO_N \"checking for version of db... $ECHO_C\" >&6\n if test \"${cf_cv_hashed_db_version+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -23015,10 +23016,10 @@ cf_cv_hashed_db_version=unknown\n for cf_db_version in 1 2 3 4 5 6\n do\n \n-echo \"${as_me:-configure}:23018: testing checking for db version $cf_db_version ...\" 1>&5\n+echo \"${as_me:-configure}:23019: testing checking for db version $cf_db_version ...\" 1>&5\n \n \tcat >conftest.$ac_ext <<_ACEOF\n-#line 23021 \"configure\"\n+#line 23022 \"configure\"\n #include \"confdefs.h\"\n \n $ac_includes_default\n@@ -23048,16 +23049,16 @@ DBT *foo = 0\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:23051: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:23052: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:23054: \\$? = $ac_status\" >&5\n+  echo \"$as_me:23055: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:23057: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:23058: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:23060: \\$? = $ac_status\" >&5\n+  echo \"$as_me:23061: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n \n \tcf_cv_hashed_db_version=$cf_db_version\n@@ -23071,16 +23072,16 @@ rm -f conftest.$ac_objext conftest.$ac_ext\n done\n \n fi\n-echo \"$as_me:23074: result: $cf_cv_hashed_db_version\" >&5\n+echo \"$as_me:23075: result: $cf_cv_hashed_db_version\" >&5\n echo \"${ECHO_T}$cf_cv_hashed_db_version\" >&6\n \n if test \"$cf_cv_hashed_db_version\" = unknown ; then\n-\t{ { echo \"$as_me:23078: error: Cannot determine version of db\" >&5\n+\t{ { echo \"$as_me:23079: error: Cannot determine version of db\" >&5\n echo \"$as_me: error: Cannot determine version of db\" >&2;}\n    { (exit 1); exit 1; }; }\n else\n \n-echo \"$as_me:23083: checking for db libraries\" >&5\n+echo \"$as_me:23084: checking for db libraries\" >&5\n echo $ECHO_N \"checking for db libraries... $ECHO_C\" >&6\n if test \"${cf_cv_hashed_db_libs+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -23110,10 +23111,10 @@ LIBS=\"$cf_add_libs\"\n \n \tfi\n \n-echo \"${as_me:-configure}:23113: testing checking for library \"$cf_db_libs\" ...\" 1>&5\n+echo \"${as_me:-configure}:23114: testing checking for library \"$cf_db_libs\" ...\" 1>&5\n \n \tcat >conftest.$ac_ext <<_ACEOF\n-#line 23116 \"configure\"\n+#line 23117 \"configure\"\n #include \"confdefs.h\"\n \n $ac_includes_default\n@@ -23168,16 +23169,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:23171: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:23172: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:23174: \\$? = $ac_status\" >&5\n+  echo \"$as_me:23175: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:23177: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:23178: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:23180: \\$? = $ac_status\" >&5\n+  echo \"$as_me:23181: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n \n \tif test -n \"$cf_db_libs\" ; then\n@@ -23197,11 +23198,11 @@ rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n done\n \n fi\n-echo \"$as_me:23200: result: $cf_cv_hashed_db_libs\" >&5\n+echo \"$as_me:23201: result: $cf_cv_hashed_db_libs\" >&5\n echo \"${ECHO_T}$cf_cv_hashed_db_libs\" >&6\n \n \tif test \"$cf_cv_hashed_db_libs\" = unknown ; then\n-\t\t{ { echo \"$as_me:23204: error: Cannot determine library for db\" >&5\n+\t\t{ { echo \"$as_me:23205: error: Cannot determine library for db\" >&5\n echo \"$as_me: error: Cannot determine library for db\" >&2;}\n    { (exit 1); exit 1; }; }\n \telif test \"$cf_cv_hashed_db_libs\" != default ; then\n@@ -23227,7 +23228,7 @@ fi\n \n else\n \n-\t{ { echo \"$as_me:23230: error: Cannot find db.h\" >&5\n+\t{ { echo \"$as_me:23231: error: Cannot find db.h\" >&5\n echo \"$as_me: error: Cannot find db.h\" >&2;}\n    { (exit 1); exit 1; }; }\n \n@@ -23242,7 +23243,7 @@ fi\n \n # Just in case, check if the C compiler has a bool type.\n \n-echo \"$as_me:23245: checking if we should include stdbool.h\" >&5\n+echo \"$as_me:23246: checking if we should include stdbool.h\" >&5\n echo $ECHO_N \"checking if we should include stdbool.h... $ECHO_C\" >&6\n \n if test \"${cf_cv_header_stdbool_h+set}\" = set; then\n@@ -23250,7 +23251,7 @@ if test \"${cf_cv_header_stdbool_h+set}\" = set; then\n else\n \n \tcat >conftest.$ac_ext <<_ACEOF\n-#line 23253 \"configure\"\n+#line 23254 \"configure\"\n #include \"confdefs.h\"\n \n int\n@@ -23262,23 +23263,23 @@ bool foo = false\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:23265: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:23266: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:23268: \\$? = $ac_status\" >&5\n+  echo \"$as_me:23269: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:23271: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:23272: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:23274: \\$? = $ac_status\" >&5\n+  echo \"$as_me:23275: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_header_stdbool_h=0\n else\n   echo \"$as_me: failed program was:\" >&5\n cat conftest.$ac_ext >&5\n cat >conftest.$ac_ext <<_ACEOF\n-#line 23281 \"configure\"\n+#line 23282 \"configure\"\n #include \"confdefs.h\"\n \n #ifndef __BEOS__\n@@ -23294,16 +23295,16 @@ bool foo = false\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:23297: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:23298: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:23300: \\$? = $ac_status\" >&5\n+  echo \"$as_me:23301: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:23303: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:23304: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:23306: \\$? = $ac_status\" >&5\n+  echo \"$as_me:23307: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_header_stdbool_h=1\n else\n@@ -23317,13 +23318,13 @@ rm -f conftest.$ac_objext conftest.$ac_ext\n fi\n \n if test \"$cf_cv_header_stdbool_h\" = 1\n-then\techo \"$as_me:23320: result: yes\" >&5\n+then\techo \"$as_me:23321: result: yes\" >&5\n echo \"${ECHO_T}yes\" >&6\n-else\techo \"$as_me:23322: result: no\" >&5\n+else\techo \"$as_me:23323: result: no\" >&5\n echo \"${ECHO_T}no\" >&6\n fi\n \n-echo \"$as_me:23326: checking for builtin bool type\" >&5\n+echo \"$as_me:23327: checking for builtin bool type\" >&5\n echo $ECHO_N \"checking for builtin bool type... $ECHO_C\" >&6\n \n if test \"${cf_cv_cc_bool_type+set}\" = set; then\n@@ -23331,7 +23332,7 @@ if test \"${cf_cv_cc_bool_type+set}\" = set; then\n else\n \n \tcat >conftest.$ac_ext <<_ACEOF\n-#line 23334 \"configure\"\n+#line 23335 \"configure\"\n #include \"confdefs.h\"\n \n #include <stdio.h>\n@@ -23346,16 +23347,16 @@ bool x = false\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:23349: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:23350: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:23352: \\$? = $ac_status\" >&5\n+  echo \"$as_me:23353: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:23355: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:23356: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:23358: \\$? = $ac_status\" >&5\n+  echo \"$as_me:23359: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_cc_bool_type=1\n else\n@@ -23368,9 +23369,9 @@ rm -f conftest.$ac_objext conftest.$ac_ext\n fi\n \n if test \"$cf_cv_cc_bool_type\" = 1\n-then\techo \"$as_me:23371: result: yes\" >&5\n+then\techo \"$as_me:23372: result: yes\" >&5\n echo \"${ECHO_T}yes\" >&6\n-else\techo \"$as_me:23373: result: no\" >&5\n+else\techo \"$as_me:23374: result: no\" >&5\n echo \"${ECHO_T}no\" >&6\n fi\n \n@@ -23387,10 +23388,10 @@ if test -n \"$GXX\" ; then\n \n \tcf_save=\"$LIBS\"\n \tLIBS=\"$LIBS $CXXLIBS\"\n-\techo \"$as_me:23390: checking if we already have C++ library\" >&5\n+\techo \"$as_me:23391: checking if we already have C++ library\" >&5\n echo $ECHO_N \"checking if we already have C++ library... $ECHO_C\" >&6\n \tcat >conftest.$ac_ext <<_ACEOF\n-#line 23393 \"configure\"\n+#line 23394 \"configure\"\n #include \"confdefs.h\"\n \n \t\t\t#include <iostream>\n@@ -23404,16 +23405,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:23407: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:23408: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:23410: \\$? = $ac_status\" >&5\n+  echo \"$as_me:23411: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:23413: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:23414: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:23416: \\$? = $ac_status\" >&5\n+  echo \"$as_me:23417: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_have_libstdcpp=yes\n else\n@@ -23422,7 +23423,7 @@ cat conftest.$ac_ext >&5\n cf_have_libstdcpp=no\n fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n-\techo \"$as_me:23425: result: $cf_have_libstdcpp\" >&5\n+\techo \"$as_me:23426: result: $cf_have_libstdcpp\" >&5\n echo \"${ECHO_T}$cf_have_libstdcpp\" >&6\n \tLIBS=\"$cf_save\"\n \n@@ -23441,7 +23442,7 @@ echo \"${ECHO_T}$cf_have_libstdcpp\" >&6\n \t\t\t;;\n \t\tesac\n \n-\t\techo \"$as_me:23444: checking for library $cf_stdcpp_libname\" >&5\n+\t\techo \"$as_me:23445: checking for library $cf_stdcpp_libname\" >&5\n echo $ECHO_N \"checking for library $cf_stdcpp_libname... $ECHO_C\" >&6\n if test \"${cf_cv_libstdcpp+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -23467,7 +23468,7 @@ done\n LIBS=\"$cf_add_libs\"\n \n \t\tcat >conftest.$ac_ext <<_ACEOF\n-#line 23470 \"configure\"\n+#line 23471 \"configure\"\n #include \"confdefs.h\"\n \n \t\t\t\t#include <iostream>\n@@ -23481,16 +23482,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:23484: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:23485: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:23487: \\$? = $ac_status\" >&5\n+  echo \"$as_me:23488: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:23490: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:23491: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:23493: \\$? = $ac_status\" >&5\n+  echo \"$as_me:23494: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_libstdcpp=yes\n else\n@@ -23502,7 +23503,7 @@ rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n \t\t\tLIBS=\"$cf_save\"\n \n fi\n-echo \"$as_me:23505: result: $cf_cv_libstdcpp\" >&5\n+echo \"$as_me:23506: result: $cf_cv_libstdcpp\" >&5\n echo \"${ECHO_T}$cf_cv_libstdcpp\" >&6\n \t\ttest \"$cf_cv_libstdcpp\" = yes && {\n cf_add_libs=\"$CXXLIBS\"\n@@ -23524,7 +23525,7 @@ CXXLIBS=\"$cf_add_libs\"\n \tfi\n fi\n \n-\techo \"$as_me:23527: checking whether $CXX understands -c and -o together\" >&5\n+\techo \"$as_me:23528: checking whether $CXX understands -c and -o together\" >&5\n echo $ECHO_N \"checking whether $CXX understands -c and -o together... $ECHO_C\" >&6\n if test \"${cf_cv_prog_CXX_c_o+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -23539,15 +23540,15 @@ CF_EOF\n # We do the test twice because some compilers refuse to overwrite an\n # existing .o file with -o, though they will create one.\n ac_try='$CXX $CXXFLAGS $CPPFLAGS -c conftest.$ac_ext -o conftest2.$ac_objext >&5'\n-if { (eval echo \"$as_me:23542: \\\"$ac_try\\\"\") >&5\n+if { (eval echo \"$as_me:23543: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:23545: \\$? = $ac_status\" >&5\n+  echo \"$as_me:23546: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n-  test -f conftest2.$ac_objext && { (eval echo \"$as_me:23547: \\\"$ac_try\\\"\") >&5\n+  test -f conftest2.$ac_objext && { (eval echo \"$as_me:23548: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:23550: \\$? = $ac_status\" >&5\n+  echo \"$as_me:23551: \\$? = $ac_status\" >&5\n   (exit $ac_status); };\n then\n   eval cf_cv_prog_CXX_c_o=yes\n@@ -23558,15 +23559,15 @@ rm -rf conftest*\n \n fi\n if test $cf_cv_prog_CXX_c_o = yes; then\n-  echo \"$as_me:23561: result: yes\" >&5\n+  echo \"$as_me:23562: result: yes\" >&5\n echo \"${ECHO_T}yes\" >&6\n else\n-  echo \"$as_me:23564: result: no\" >&5\n+  echo \"$as_me:23565: result: no\" >&5\n echo \"${ECHO_T}no\" >&6\n fi\n \n \tcase $GXX_VERSION in\n-\t(1*|2.0-6*)\n+\t(1.*|2.[0-6]*|[1-9][0-9].*)\n \t\tcf_cxx_library=yes\n \t\t;;\n \t(*-2.7*|2.7*)\n@@ -23581,7 +23582,7 @@ case $cf_cv_system_name in\n \t;;\n esac\n if test \"$GXX\" = yes; then\n-\techo \"$as_me:23584: checking for lib$cf_gpp_libname\" >&5\n+\techo \"$as_me:23585: checking for lib$cf_gpp_libname\" >&5\n echo $ECHO_N \"checking for lib$cf_gpp_libname... $ECHO_C\" >&6\n \tcf_save=\"$LIBS\"\n \n@@ -23602,7 +23603,7 @@ done\n LIBS=\"$cf_add_libs\"\n \n \tcat >conftest.$ac_ext <<_ACEOF\n-#line 23605 \"configure\"\n+#line 23606 \"configure\"\n #include \"confdefs.h\"\n \n #include <$cf_gpp_libname/builtin.h>\n@@ -23616,16 +23617,16 @@ two_arg_error_handler_t foo2 = lib_error_handler\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:23619: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:23620: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:23622: \\$? = $ac_status\" >&5\n+  echo \"$as_me:23623: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:23625: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:23626: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:23628: \\$? = $ac_status\" >&5\n+  echo \"$as_me:23629: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cxx_library=yes\n \n@@ -23662,7 +23663,7 @@ else\n   echo \"$as_me: failed program was:\" >&5\n cat conftest.$ac_ext >&5\n cat >conftest.$ac_ext <<_ACEOF\n-#line 23665 \"configure\"\n+#line 23666 \"configure\"\n #include \"confdefs.h\"\n \n #include <builtin.h>\n@@ -23676,16 +23677,16 @@ two_arg_error_handler_t foo2 = lib_error_handler\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:23679: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:23680: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:23682: \\$? = $ac_status\" >&5\n+  echo \"$as_me:23683: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:23685: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:23686: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:23688: \\$? = $ac_status\" >&5\n+  echo \"$as_me:23689: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cxx_library=yes\n \n@@ -23718,7 +23719,7 @@ rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n \tLIBS=\"$cf_save\"\n-\techo \"$as_me:23721: result: $cf_cxx_library\" >&5\n+\techo \"$as_me:23722: result: $cf_cxx_library\" >&5\n echo \"${ECHO_T}$cf_cxx_library\" >&6\n fi\n \n@@ -23734,7 +23735,7 @@ ac_compile='$CXX -c $CXXFLAGS $CPPFLAGS conftest.$ac_ext >&5'\n ac_link='$CXX -o conftest$ac_exeext $CXXFLAGS $CPPFLAGS $LDFLAGS conftest.$ac_ext $LIBS >&5'\n ac_compiler_gnu=$ac_cv_cxx_compiler_gnu\n ac_main_return=return\n-echo \"$as_me:23737: checking how to run the C++ preprocessor\" >&5\n+echo \"$as_me:23738: checking how to run the C++ preprocessor\" >&5\n echo $ECHO_N \"checking how to run the C++ preprocessor... $ECHO_C\" >&6\n if test -z \"$CXXCPP\"; then\n   if test \"${ac_cv_prog_CXXCPP+set}\" = set; then\n@@ -23751,18 +23752,18 @@ do\n   # On the NeXT, cc -E runs the code through the compiler's parser,\n   # not just through cpp. \"Syntax error\" is here to catch this case.\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 23754 \"configure\"\n+#line 23755 \"configure\"\n #include \"confdefs.h\"\n #include <assert.h>\n                      Syntax error\n _ACEOF\n-if { (eval echo \"$as_me:23759: \\\"$ac_cpp conftest.$ac_ext\\\"\") >&5\n+if { (eval echo \"$as_me:23760: \\\"$ac_cpp conftest.$ac_ext\\\"\") >&5\n   (eval $ac_cpp conftest.$ac_ext) 2>conftest.er1\n   ac_status=$?\n   egrep -v '^ *\\+' conftest.er1 >conftest.err\n   rm -f conftest.er1\n   cat conftest.err >&5\n-  echo \"$as_me:23765: \\$? = $ac_status\" >&5\n+  echo \"$as_me:23766: \\$? = $ac_status\" >&5\n   (exit $ac_status); } >/dev/null; then\n   if test -s conftest.err; then\n     ac_cpp_err=$ac_cxx_preproc_warn_flag\n@@ -23785,17 +23786,17 @@ rm -f conftest.err conftest.$ac_ext\n   # OK, works on sane cases.  Now check whether non-existent headers\n   # can be detected and how.\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 23788 \"configure\"\n+#line 23789 \"configure\"\n #include \"confdefs.h\"\n #include <ac_nonexistent.h>\n _ACEOF\n-if { (eval echo \"$as_me:23792: \\\"$ac_cpp conftest.$ac_ext\\\"\") >&5\n+if { (eval echo \"$as_me:23793: \\\"$ac_cpp conftest.$ac_ext\\\"\") >&5\n   (eval $ac_cpp conftest.$ac_ext) 2>conftest.er1\n   ac_status=$?\n   egrep -v '^ *\\+' conftest.er1 >conftest.err\n   rm -f conftest.er1\n   cat conftest.err >&5\n-  echo \"$as_me:23798: \\$? = $ac_status\" >&5\n+  echo \"$as_me:23799: \\$? = $ac_status\" >&5\n   (exit $ac_status); } >/dev/null; then\n   if test -s conftest.err; then\n     ac_cpp_err=$ac_cxx_preproc_warn_flag\n@@ -23832,7 +23833,7 @@ fi\n else\n   ac_cv_prog_CXXCPP=$CXXCPP\n fi\n-echo \"$as_me:23835: result: $CXXCPP\" >&5\n+echo \"$as_me:23836: result: $CXXCPP\" >&5\n echo \"${ECHO_T}$CXXCPP\" >&6\n ac_preproc_ok=false\n for ac_cxx_preproc_warn_flag in '' yes\n@@ -23842,18 +23843,18 @@ do\n   # On the NeXT, cc -E runs the code through the compiler's parser,\n   # not just through cpp. \"Syntax error\" is here to catch this case.\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 23845 \"configure\"\n+#line 23846 \"configure\"\n #include \"confdefs.h\"\n #include <assert.h>\n                      Syntax error\n _ACEOF\n-if { (eval echo \"$as_me:23850: \\\"$ac_cpp conftest.$ac_ext\\\"\") >&5\n+if { (eval echo \"$as_me:23851: \\\"$ac_cpp conftest.$ac_ext\\\"\") >&5\n   (eval $ac_cpp conftest.$ac_ext) 2>conftest.er1\n   ac_status=$?\n   egrep -v '^ *\\+' conftest.er1 >conftest.err\n   rm -f conftest.er1\n   cat conftest.err >&5\n-  echo \"$as_me:23856: \\$? = $ac_status\" >&5\n+  echo \"$as_me:23857: \\$? = $ac_status\" >&5\n   (exit $ac_status); } >/dev/null; then\n   if test -s conftest.err; then\n     ac_cpp_err=$ac_cxx_preproc_warn_flag\n@@ -23876,17 +23877,17 @@ rm -f conftest.err conftest.$ac_ext\n   # OK, works on sane cases.  Now check whether non-existent headers\n   # can be detected and how.\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 23879 \"configure\"\n+#line 23880 \"configure\"\n #include \"confdefs.h\"\n #include <ac_nonexistent.h>\n _ACEOF\n-if { (eval echo \"$as_me:23883: \\\"$ac_cpp conftest.$ac_ext\\\"\") >&5\n+if { (eval echo \"$as_me:23884: \\\"$ac_cpp conftest.$ac_ext\\\"\") >&5\n   (eval $ac_cpp conftest.$ac_ext) 2>conftest.er1\n   ac_status=$?\n   egrep -v '^ *\\+' conftest.er1 >conftest.err\n   rm -f conftest.er1\n   cat conftest.err >&5\n-  echo \"$as_me:23889: \\$? = $ac_status\" >&5\n+  echo \"$as_me:23890: \\$? = $ac_status\" >&5\n   (exit $ac_status); } >/dev/null; then\n   if test -s conftest.err; then\n     ac_cpp_err=$ac_cxx_preproc_warn_flag\n@@ -23914,7 +23915,7 @@ rm -f conftest.err conftest.$ac_ext\n if $ac_preproc_ok; then\n   :\n else\n-  { { echo \"$as_me:23917: error: C++ preprocessor \\\"$CXXCPP\\\" fails sanity check\" >&5\n+  { { echo \"$as_me:23918: error: C++ preprocessor \\\"$CXXCPP\\\" fails sanity check\" >&5\n echo \"$as_me: error: C++ preprocessor \\\"$CXXCPP\\\" fails sanity check\" >&2;}\n    { (exit 1); exit 1; }; }\n fi\n@@ -23929,23 +23930,23 @@ ac_main_return=return\n for ac_header in typeinfo\n do\n as_ac_Header=`echo \"ac_cv_header_$ac_header\" | $as_tr_sh`\n-echo \"$as_me:23932: checking for $ac_header\" >&5\n+echo \"$as_me:23933: checking for $ac_header\" >&5\n echo $ECHO_N \"checking for $ac_header... $ECHO_C\" >&6\n if eval \"test \\\"\\${$as_ac_Header+set}\\\" = set\"; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 23938 \"configure\"\n+#line 23939 \"configure\"\n #include \"confdefs.h\"\n #include <$ac_header>\n _ACEOF\n-if { (eval echo \"$as_me:23942: \\\"$ac_cpp conftest.$ac_ext\\\"\") >&5\n+if { (eval echo \"$as_me:23943: \\\"$ac_cpp conftest.$ac_ext\\\"\") >&5\n   (eval $ac_cpp conftest.$ac_ext) 2>conftest.er1\n   ac_status=$?\n   egrep -v '^ *\\+' conftest.er1 >conftest.err\n   rm -f conftest.er1\n   cat conftest.err >&5\n-  echo \"$as_me:23948: \\$? = $ac_status\" >&5\n+  echo \"$as_me:23949: \\$? = $ac_status\" >&5\n   (exit $ac_status); } >/dev/null; then\n   if test -s conftest.err; then\n     ac_cpp_err=$ac_cxx_preproc_warn_flag\n@@ -23964,7 +23965,7 @@ else\n fi\n rm -f conftest.err conftest.$ac_ext\n fi\n-echo \"$as_me:23967: result: `eval echo '${'$as_ac_Header'}'`\" >&5\n+echo \"$as_me:23968: result: `eval echo '${'$as_ac_Header'}'`\" >&5\n echo \"${ECHO_T}`eval echo '${'$as_ac_Header'}'`\" >&6\n if test `eval echo '${'$as_ac_Header'}'` = yes; then\n   cat >>confdefs.h <<EOF\n@@ -23977,23 +23978,23 @@ done\n for ac_header in iostream\n do\n as_ac_Header=`echo \"ac_cv_header_$ac_header\" | $as_tr_sh`\n-echo \"$as_me:23980: checking for $ac_header\" >&5\n+echo \"$as_me:23981: checking for $ac_header\" >&5\n echo $ECHO_N \"checking for $ac_header... $ECHO_C\" >&6\n if eval \"test \\\"\\${$as_ac_Header+set}\\\" = set\"; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 23986 \"configure\"\n+#line 23987 \"configure\"\n #include \"confdefs.h\"\n #include <$ac_header>\n _ACEOF\n-if { (eval echo \"$as_me:23990: \\\"$ac_cpp conftest.$ac_ext\\\"\") >&5\n+if { (eval echo \"$as_me:23991: \\\"$ac_cpp conftest.$ac_ext\\\"\") >&5\n   (eval $ac_cpp conftest.$ac_ext) 2>conftest.er1\n   ac_status=$?\n   egrep -v '^ *\\+' conftest.er1 >conftest.err\n   rm -f conftest.er1\n   cat conftest.err >&5\n-  echo \"$as_me:23996: \\$? = $ac_status\" >&5\n+  echo \"$as_me:23997: \\$? = $ac_status\" >&5\n   (exit $ac_status); } >/dev/null; then\n   if test -s conftest.err; then\n     ac_cpp_err=$ac_cxx_preproc_warn_flag\n@@ -24012,7 +24013,7 @@ else\n fi\n rm -f conftest.err conftest.$ac_ext\n fi\n-echo \"$as_me:24015: result: `eval echo '${'$as_ac_Header'}'`\" >&5\n+echo \"$as_me:24016: result: `eval echo '${'$as_ac_Header'}'`\" >&5\n echo \"${ECHO_T}`eval echo '${'$as_ac_Header'}'`\" >&6\n if test `eval echo '${'$as_ac_Header'}'` = yes; then\n   cat >>confdefs.h <<EOF\n@@ -24023,10 +24024,10 @@ fi\n done\n \n if test x\"$ac_cv_header_iostream\" = xyes ; then\n-\techo \"$as_me:24026: checking if iostream uses std-namespace\" >&5\n+\techo \"$as_me:24027: checking if iostream uses std-namespace\" >&5\n echo $ECHO_N \"checking if iostream uses std-namespace... $ECHO_C\" >&6\n \tcat >conftest.$ac_ext <<_ACEOF\n-#line 24029 \"configure\"\n+#line 24030 \"configure\"\n #include \"confdefs.h\"\n \n #include <iostream>\n@@ -24043,16 +24044,16 @@ cerr << \"testing\" << endl;\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:24046: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:24047: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:24049: \\$? = $ac_status\" >&5\n+  echo \"$as_me:24050: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:24052: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:24053: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:24055: \\$? = $ac_status\" >&5\n+  echo \"$as_me:24056: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_iostream_namespace=yes\n else\n@@ -24061,7 +24062,7 @@ cat conftest.$ac_ext >&5\n cf_iostream_namespace=no\n fi\n rm -f conftest.$ac_objext conftest.$ac_ext\n-\techo \"$as_me:24064: result: $cf_iostream_namespace\" >&5\n+\techo \"$as_me:24065: result: $cf_iostream_namespace\" >&5\n echo \"${ECHO_T}$cf_iostream_namespace\" >&6\n \tif test \"$cf_iostream_namespace\" = yes ; then\n \n@@ -24072,7 +24073,7 @@ EOF\n \tfi\n fi\n \n-echo \"$as_me:24075: checking if we should include stdbool.h\" >&5\n+echo \"$as_me:24076: checking if we should include stdbool.h\" >&5\n echo $ECHO_N \"checking if we should include stdbool.h... $ECHO_C\" >&6\n \n if test \"${cf_cv_header_stdbool_h+set}\" = set; then\n@@ -24080,7 +24081,7 @@ if test \"${cf_cv_header_stdbool_h+set}\" = set; then\n else\n \n \tcat >conftest.$ac_ext <<_ACEOF\n-#line 24083 \"configure\"\n+#line 24084 \"configure\"\n #include \"confdefs.h\"\n \n int\n@@ -24092,23 +24093,23 @@ bool foo = false\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:24095: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:24096: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:24098: \\$? = $ac_status\" >&5\n+  echo \"$as_me:24099: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:24101: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:24102: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:24104: \\$? = $ac_status\" >&5\n+  echo \"$as_me:24105: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_header_stdbool_h=0\n else\n   echo \"$as_me: failed program was:\" >&5\n cat conftest.$ac_ext >&5\n cat >conftest.$ac_ext <<_ACEOF\n-#line 24111 \"configure\"\n+#line 24112 \"configure\"\n #include \"confdefs.h\"\n \n #ifndef __BEOS__\n@@ -24124,16 +24125,16 @@ bool foo = false\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:24127: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:24128: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:24130: \\$? = $ac_status\" >&5\n+  echo \"$as_me:24131: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:24133: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:24134: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:24136: \\$? = $ac_status\" >&5\n+  echo \"$as_me:24137: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_header_stdbool_h=1\n else\n@@ -24147,13 +24148,13 @@ rm -f conftest.$ac_objext conftest.$ac_ext\n fi\n \n if test \"$cf_cv_header_stdbool_h\" = 1\n-then\techo \"$as_me:24150: result: yes\" >&5\n+then\techo \"$as_me:24151: result: yes\" >&5\n echo \"${ECHO_T}yes\" >&6\n-else\techo \"$as_me:24152: result: no\" >&5\n+else\techo \"$as_me:24153: result: no\" >&5\n echo \"${ECHO_T}no\" >&6\n fi\n \n-echo \"$as_me:24156: checking for builtin bool type\" >&5\n+echo \"$as_me:24157: checking for builtin bool type\" >&5\n echo $ECHO_N \"checking for builtin bool type... $ECHO_C\" >&6\n \n if test \"${cf_cv_builtin_bool+set}\" = set; then\n@@ -24161,7 +24162,7 @@ if test \"${cf_cv_builtin_bool+set}\" = set; then\n else\n \n \tcat >conftest.$ac_ext <<_ACEOF\n-#line 24164 \"configure\"\n+#line 24165 \"configure\"\n #include \"confdefs.h\"\n \n #include <stdio.h>\n@@ -24176,16 +24177,16 @@ bool x = false\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:24179: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:24180: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:24182: \\$? = $ac_status\" >&5\n+  echo \"$as_me:24183: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:24185: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:24186: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:24188: \\$? = $ac_status\" >&5\n+  echo \"$as_me:24189: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_builtin_bool=1\n else\n@@ -24198,13 +24199,13 @@ rm -f conftest.$ac_objext conftest.$ac_ext\n fi\n \n if test \"$cf_cv_builtin_bool\" = 1\n-then\techo \"$as_me:24201: result: yes\" >&5\n+then\techo \"$as_me:24202: result: yes\" >&5\n echo \"${ECHO_T}yes\" >&6\n-else\techo \"$as_me:24203: result: no\" >&5\n+else\techo \"$as_me:24204: result: no\" >&5\n echo \"${ECHO_T}no\" >&6\n fi\n \n-echo \"$as_me:24207: checking for size of bool\" >&5\n+echo \"$as_me:24208: checking for size of bool\" >&5\n echo $ECHO_N \"checking for size of bool... $ECHO_C\" >&6\n if test \"${cf_cv_type_of_bool+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -24215,7 +24216,7 @@ else\n   cf_cv_type_of_bool=unknown\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 24218 \"configure\"\n+#line 24219 \"configure\"\n #include \"confdefs.h\"\n \n #include <stdlib.h>\n@@ -24257,15 +24258,15 @@ int main(void)\n \n _ACEOF\n rm -f conftest$ac_exeext\n-if { (eval echo \"$as_me:24260: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:24261: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:24263: \\$? = $ac_status\" >&5\n+  echo \"$as_me:24264: \\$? = $ac_status\" >&5\n   (exit $ac_status); } && { ac_try='./conftest$ac_exeext'\n-  { (eval echo \"$as_me:24265: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:24266: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:24268: \\$? = $ac_status\" >&5\n+  echo \"$as_me:24269: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_type_of_bool=`cat cf_test.out`\n \t\t if test -z \"$cf_cv_type_of_bool\"; then\n@@ -24283,18 +24284,18 @@ fi\n fi\n \n \trm -f cf_test.out\n-echo \"$as_me:24286: result: $cf_cv_type_of_bool\" >&5\n+echo \"$as_me:24287: result: $cf_cv_type_of_bool\" >&5\n echo \"${ECHO_T}$cf_cv_type_of_bool\" >&6\n if test \"$cf_cv_type_of_bool\" = unknown ; then\n \tcase .$NCURSES_BOOL in\n \t(.auto|.) NCURSES_BOOL=unsigned;;\n \tesac\n-\t{ echo \"$as_me:24292: WARNING: Assuming $NCURSES_BOOL for type of bool\" >&5\n+\t{ echo \"$as_me:24293: WARNING: Assuming $NCURSES_BOOL for type of bool\" >&5\n echo \"$as_me: WARNING: Assuming $NCURSES_BOOL for type of bool\" >&2;}\n \tcf_cv_type_of_bool=$NCURSES_BOOL\n fi\n \n-echo \"$as_me:24297: checking for special defines needed for etip.h\" >&5\n+echo \"$as_me:24298: checking for special defines needed for etip.h\" >&5\n echo $ECHO_N \"checking for special defines needed for etip.h... $ECHO_C\" >&6\n cf_save_CXXFLAGS=\"$CXXFLAGS\"\n cf_result=\"none\"\n@@ -24312,7 +24313,7 @@ do\n \ttest -n \"$cf_math\" && CXXFLAGS=\"$CXXFLAGS -DETIP_NEEDS_${cf_math}\"\n \ttest -n \"$cf_excp\" && CXXFLAGS=\"$CXXFLAGS -DETIP_NEEDS_${cf_excp}\"\n cat >conftest.$ac_ext <<_ACEOF\n-#line 24315 \"configure\"\n+#line 24316 \"configure\"\n #include \"confdefs.h\"\n \n #include <etip.h.in>\n@@ -24326,16 +24327,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:24329: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:24330: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:24332: \\$? = $ac_status\" >&5\n+  echo \"$as_me:24333: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:24335: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:24336: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:24338: \\$? = $ac_status\" >&5\n+  echo \"$as_me:24339: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n \n \ttest -n \"$cf_math\" && cat >>confdefs.h <<EOF\n@@ -24356,12 +24357,12 @@ fi\n rm -f conftest.$ac_objext conftest.$ac_ext\n done\n done\n-echo \"$as_me:24359: result: $cf_result\" >&5\n+echo \"$as_me:24360: result: $cf_result\" >&5\n echo \"${ECHO_T}$cf_result\" >&6\n CXXFLAGS=\"$cf_save_CXXFLAGS\"\n \n if test -n \"$CXX\"; then\n-echo \"$as_me:24364: checking if $CXX accepts parameter initialization\" >&5\n+echo \"$as_me:24365: checking if $CXX accepts parameter initialization\" >&5\n echo $ECHO_N \"checking if $CXX accepts parameter initialization... $ECHO_C\" >&6\n if test \"${cf_cv_cpp_param_init+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -24378,7 +24379,7 @@ ac_main_return=return\n   cf_cv_cpp_param_init=unknown\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 24381 \"configure\"\n+#line 24382 \"configure\"\n #include \"confdefs.h\"\n \n class TEST {\n@@ -24397,15 +24398,15 @@ int main(void) { }\n \n _ACEOF\n rm -f conftest$ac_exeext\n-if { (eval echo \"$as_me:24400: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:24401: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:24403: \\$? = $ac_status\" >&5\n+  echo \"$as_me:24404: \\$? = $ac_status\" >&5\n   (exit $ac_status); } && { ac_try='./conftest$ac_exeext'\n-  { (eval echo \"$as_me:24405: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:24406: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:24408: \\$? = $ac_status\" >&5\n+  echo \"$as_me:24409: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_cpp_param_init=yes\n else\n@@ -24424,7 +24425,7 @@ ac_compiler_gnu=$ac_cv_cxx_compiler_gnu\n ac_main_return=return\n \n fi\n-echo \"$as_me:24427: result: $cf_cv_cpp_param_init\" >&5\n+echo \"$as_me:24428: result: $cf_cv_cpp_param_init\" >&5\n echo \"${ECHO_T}$cf_cv_cpp_param_init\" >&6\n fi\n test \"$cf_cv_cpp_param_init\" = yes &&\n@@ -24434,7 +24435,7 @@ EOF\n \n if test -n \"$CXX\"; then\n \n-echo \"$as_me:24437: checking if $CXX accepts static_cast\" >&5\n+echo \"$as_me:24438: checking if $CXX accepts static_cast\" >&5\n echo $ECHO_N \"checking if $CXX accepts static_cast... $ECHO_C\" >&6\n if test \"${cf_cv_cpp_static_cast+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -24448,7 +24449,7 @@ ac_compiler_gnu=$ac_cv_cxx_compiler_gnu\n ac_main_return=return\n \n \tcat >conftest.$ac_ext <<_ACEOF\n-#line 24451 \"configure\"\n+#line 24452 \"configure\"\n #include \"confdefs.h\"\n \n class NCursesPanel\n@@ -24492,16 +24493,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:24495: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:24496: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:24498: \\$? = $ac_status\" >&5\n+  echo \"$as_me:24499: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:24501: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:24502: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:24504: \\$? = $ac_status\" >&5\n+  echo \"$as_me:24505: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_cpp_static_cast=yes\n else\n@@ -24519,7 +24520,7 @@ ac_compiler_gnu=$ac_cv_cxx_compiler_gnu\n ac_main_return=return\n \n fi\n-echo \"$as_me:24522: result: $cf_cv_cpp_static_cast\" >&5\n+echo \"$as_me:24523: result: $cf_cv_cpp_static_cast\" >&5\n echo \"${ECHO_T}$cf_cv_cpp_static_cast\" >&6\n \n fi\n@@ -24568,7 +24569,7 @@ else\n \telse\n \t\tif test \"$cf_cv_header_stdbool_h\" = 1 ; then\n \n-echo \"$as_me:24571: checking for size of bool\" >&5\n+echo \"$as_me:24572: checking for size of bool\" >&5\n echo $ECHO_N \"checking for size of bool... $ECHO_C\" >&6\n if test \"${cf_cv_type_of_bool+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -24579,7 +24580,7 @@ else\n   cf_cv_type_of_bool=unknown\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 24582 \"configure\"\n+#line 24583 \"configure\"\n #include \"confdefs.h\"\n \n #include <stdlib.h>\n@@ -24621,15 +24622,15 @@ int main(void)\n \n _ACEOF\n rm -f conftest$ac_exeext\n-if { (eval echo \"$as_me:24624: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:24625: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:24627: \\$? = $ac_status\" >&5\n+  echo \"$as_me:24628: \\$? = $ac_status\" >&5\n   (exit $ac_status); } && { ac_try='./conftest$ac_exeext'\n-  { (eval echo \"$as_me:24629: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:24630: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:24632: \\$? = $ac_status\" >&5\n+  echo \"$as_me:24633: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_type_of_bool=`cat cf_test.out`\n \t\t if test -z \"$cf_cv_type_of_bool\"; then\n@@ -24647,25 +24648,25 @@ fi\n fi\n \n \trm -f cf_test.out\n-echo \"$as_me:24650: result: $cf_cv_type_of_bool\" >&5\n+echo \"$as_me:24651: result: $cf_cv_type_of_bool\" >&5\n echo \"${ECHO_T}$cf_cv_type_of_bool\" >&6\n if test \"$cf_cv_type_of_bool\" = unknown ; then\n \tcase .$NCURSES_BOOL in\n \t(.auto|.) NCURSES_BOOL=unsigned;;\n \tesac\n-\t{ echo \"$as_me:24656: WARNING: Assuming $NCURSES_BOOL for type of bool\" >&5\n+\t{ echo \"$as_me:24657: WARNING: Assuming $NCURSES_BOOL for type of bool\" >&5\n echo \"$as_me: WARNING: Assuming $NCURSES_BOOL for type of bool\" >&2;}\n \tcf_cv_type_of_bool=$NCURSES_BOOL\n fi\n \n \t\telse\n-\t\t\techo \"$as_me:24662: checking for fallback type of bool\" >&5\n+\t\t\techo \"$as_me:24663: checking for fallback type of bool\" >&5\n echo $ECHO_N \"checking for fallback type of bool... $ECHO_C\" >&6\n \t\t\tcase \"$host_cpu\" in\n \t\t\t(i?86)\tcf_cv_type_of_bool=char\t;;\n \t\t\t(*)\tcf_cv_type_of_bool=int\t;;\n \t\t\tesac\n-\t\t\techo \"$as_me:24668: result: $cf_cv_type_of_bool\" >&5\n+\t\t\techo \"$as_me:24669: result: $cf_cv_type_of_bool\" >&5\n echo \"${ECHO_T}$cf_cv_type_of_bool\" >&6\n \t\tfi\n \tfi\n@@ -24694,7 +24695,7 @@ if test -f \"${srcdir}/Ada95/Makefile.in\" ; then\n \n \tif test \"$cf_with_ada\" != \"no\" ; then\n \t\tif test \"$with_libtool\" != \"no\"; then\n-\t\t\t{ echo \"$as_me:24697: WARNING: libtool does not support Ada - disabling feature\" >&5\n+\t\t\t{ echo \"$as_me:24698: WARNING: libtool does not support Ada - disabling feature\" >&5\n echo \"$as_me: WARNING: libtool does not support Ada - disabling feature\" >&2;}\n \t\t\tcf_with_ada=no\n \t\tfi\n@@ -24711,7 +24712,7 @@ cf_upper_prog_gnat=`echo \"${cf_prog_gnat}\" | sed y%abcdefghijklmnopqrstuvwxyz./-\n \tunset cf_TEMP_gnat\n \t# Extract the first word of \"$cf_prog_gnat\", so it can be a program name with args.\n set dummy $cf_prog_gnat; ac_word=$2\n-echo \"$as_me:24714: checking for $ac_word\" >&5\n+echo \"$as_me:24715: checking for $ac_word\" >&5\n echo $ECHO_N \"checking for $ac_word... $ECHO_C\" >&6\n if test \"${ac_cv_path_cf_TEMP_gnat+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -24728,7 +24729,7 @@ for ac_dir in $ac_dummy; do\n   test -z \"$ac_dir\" && ac_dir=.\n   if $as_executable_p \"$ac_dir/$ac_word\"; then\n    ac_cv_path_cf_TEMP_gnat=\"$ac_dir/$ac_word\"\n-   echo \"$as_me:24731: found $ac_dir/$ac_word\" >&5\n+   echo \"$as_me:24732: found $ac_dir/$ac_word\" >&5\n    break\n fi\n done\n@@ -24740,10 +24741,10 @@ fi\n cf_TEMP_gnat=$ac_cv_path_cf_TEMP_gnat\n \n if test -n \"$cf_TEMP_gnat\"; then\n-  echo \"$as_me:24743: result: $cf_TEMP_gnat\" >&5\n+  echo \"$as_me:24744: result: $cf_TEMP_gnat\" >&5\n echo \"${ECHO_T}$cf_TEMP_gnat\" >&6\n else\n-  echo \"$as_me:24746: result: no\" >&5\n+  echo \"$as_me:24747: result: no\" >&5\n echo \"${ECHO_T}no\" >&6\n fi\n \n@@ -24753,7 +24754,7 @@ fi\n \t\tunset cf_cv_gnat_version\n \t\tunset cf_TEMP_gnat\n \n-echo \"$as_me:24756: checking for $cf_prog_gnat version\" >&5\n+echo \"$as_me:24757: checking for $cf_prog_gnat version\" >&5\n echo $ECHO_N \"checking for $cf_prog_gnat version... $ECHO_C\" >&6\n if test \"${cf_cv_gnat_version+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -24764,7 +24765,7 @@ cf_cv_gnat_version=`$cf_prog_gnat --version 2>&1 | \\\n \tsed -e '2,$d' -e 's/[^0-9 \\.]//g' -e 's/^[ ]*//' -e 's/ .*//'`\n \n fi\n-echo \"$as_me:24767: result: $cf_cv_gnat_version\" >&5\n+echo \"$as_me:24768: result: $cf_cv_gnat_version\" >&5\n echo \"${ECHO_T}$cf_cv_gnat_version\" >&6\n test -z \"$cf_cv_gnat_version\" && cf_cv_gnat_version=no\n eval cf_TEMP_gnat=$cf_cv_gnat_version; unset cf_cv_gnat_version\n@@ -24793,7 +24794,7 @@ else\n \t\t\tcd conftest.src\n \t\t\tfor cf_gprconfig in Ada C\n \t\t\tdo\n-\t\t\t\techo \"$as_me:24796: checking for gprconfig name for $cf_gprconfig\" >&5\n+\t\t\t\techo \"$as_me:24797: checking for gprconfig name for $cf_gprconfig\" >&5\n echo $ECHO_N \"checking for gprconfig name for $cf_gprconfig... $ECHO_C\" >&6\n \t\t\t\tif test $cf_gprconfig = C\n \t\t\t\tthen\n@@ -24812,10 +24813,10 @@ echo $ECHO_N \"checking for gprconfig name for $cf_gprconfig... $ECHO_C\" >&6\n \t\t\t\tif test -n \"$cf_gprconfig_value\"\n \t\t\t\tthen\n \t\t\t\t\teval cf_ada_config_$cf_gprconfig=$cf_gprconfig_value\n-\t\t\t\t\techo \"$as_me:24815: result: $cf_gprconfig_value\" >&5\n+\t\t\t\t\techo \"$as_me:24816: result: $cf_gprconfig_value\" >&5\n echo \"${ECHO_T}$cf_gprconfig_value\" >&6\n \t\t\t\telse\n-\t\t\t\t\techo \"$as_me:24818: result: missing\" >&5\n+\t\t\t\t\techo \"$as_me:24819: result: missing\" >&5\n echo \"${ECHO_T}missing\" >&6\n \t\t\t\t\tcf_ada_config=\"#\"\n \t\t\t\t\tbreak\n@@ -24828,7 +24829,7 @@ echo \"${ECHO_T}missing\" >&6\n \tif test \"x$cf_ada_config\" != \"x#\"\n \tthen\n \n-echo \"$as_me:24831: checking for gnat version\" >&5\n+echo \"$as_me:24832: checking for gnat version\" >&5\n echo $ECHO_N \"checking for gnat version... $ECHO_C\" >&6\n if test \"${cf_cv_gnat_version+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -24839,7 +24840,7 @@ cf_cv_gnat_version=`${cf_ada_make:-gnatmake} --version 2>&1 | \\\n \tsed -e '2,$d' -e 's/[^0-9 \\.]//g' -e 's/^[ ]*//' -e 's/ .*//'`\n \n fi\n-echo \"$as_me:24842: result: $cf_cv_gnat_version\" >&5\n+echo \"$as_me:24843: result: $cf_cv_gnat_version\" >&5\n echo \"${ECHO_T}$cf_cv_gnat_version\" >&6\n test -z \"$cf_cv_gnat_version\" && cf_cv_gnat_version=no\n \n@@ -24848,7 +24849,7 @@ case $cf_cv_gnat_version in\n \tcf_cv_prog_gnat_correct=yes\n \t;;\n (*)\n-\t{ echo \"$as_me:24851: WARNING: Unsupported GNAT version $cf_cv_gnat_version. We require 3.11 or better. Disabling Ada95 binding.\" >&5\n+\t{ echo \"$as_me:24852: WARNING: Unsupported GNAT version $cf_cv_gnat_version. We require 3.11 or better. Disabling Ada95 binding.\" >&5\n echo \"$as_me: WARNING: Unsupported GNAT version $cf_cv_gnat_version. We require 3.11 or better. Disabling Ada95 binding.\" >&2;}\n \tcf_cv_prog_gnat_correct=no\n \t;;\n@@ -24856,7 +24857,7 @@ esac\n \n \t\t# Extract the first word of \"m4\", so it can be a program name with args.\n set dummy m4; ac_word=$2\n-echo \"$as_me:24859: checking for $ac_word\" >&5\n+echo \"$as_me:24860: checking for $ac_word\" >&5\n echo $ECHO_N \"checking for $ac_word... $ECHO_C\" >&6\n if test \"${ac_cv_prog_M4_exists+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -24871,7 +24872,7 @@ for ac_dir in $ac_dummy; do\n   test -z \"$ac_dir\" && ac_dir=.\n   $as_executable_p \"$ac_dir/$ac_word\" || continue\n ac_cv_prog_M4_exists=\"yes\"\n-echo \"$as_me:24874: found $ac_dir/$ac_word\" >&5\n+echo \"$as_me:24875: found $ac_dir/$ac_word\" >&5\n break\n done\n \n@@ -24880,20 +24881,20 @@ fi\n fi\n M4_exists=$ac_cv_prog_M4_exists\n if test -n \"$M4_exists\"; then\n-  echo \"$as_me:24883: result: $M4_exists\" >&5\n+  echo \"$as_me:24884: result: $M4_exists\" >&5\n echo \"${ECHO_T}$M4_exists\" >&6\n else\n-  echo \"$as_me:24886: result: no\" >&5\n+  echo \"$as_me:24887: result: no\" >&5\n echo \"${ECHO_T}no\" >&6\n fi\n \n \t\tif test \"$ac_cv_prog_M4_exists\" = no; then\n \t\t\tcf_cv_prog_gnat_correct=no\n-\t\t\t{ echo \"$as_me:24892: WARNING: Ada95 binding required program m4 not found. Ada95 binding disabled\" >&5\n+\t\t\t{ echo \"$as_me:24893: WARNING: Ada95 binding required program m4 not found. Ada95 binding disabled\" >&5\n echo \"$as_me: WARNING: Ada95 binding required program m4 not found. Ada95 binding disabled\" >&2;}\n \t\tfi\n \t\tif test \"$cf_cv_prog_gnat_correct\" = yes; then\n-\t\t\techo \"$as_me:24896: checking if GNAT works\" >&5\n+\t\t\techo \"$as_me:24897: checking if GNAT works\" >&5\n echo $ECHO_N \"checking if GNAT works... $ECHO_C\" >&6\n \n rm -rf conftest* *~conftest*\n@@ -24921,7 +24922,7 @@ else\n fi\n rm -rf conftest* *~conftest*\n \n-\t\t\techo \"$as_me:24924: result: $cf_cv_prog_gnat_correct\" >&5\n+\t\t\techo \"$as_me:24925: result: $cf_cv_prog_gnat_correct\" >&5\n echo \"${ECHO_T}$cf_cv_prog_gnat_correct\" >&6\n \t\tfi\n \telse\n@@ -24933,7 +24934,7 @@ fi\n \n  \tADAFLAGS=\"$ADAFLAGS -gnatpn\"\n \n-\techo \"$as_me:24936: checking optimization options for ADAFLAGS\" >&5\n+\techo \"$as_me:24937: checking optimization options for ADAFLAGS\" >&5\n echo $ECHO_N \"checking optimization options for ADAFLAGS... $ECHO_C\" >&6\n \tcase \"$CFLAGS\" in\n \t(*-g*)\n@@ -24950,10 +24951,10 @@ echo $ECHO_N \"checking optimization options for ADAFLAGS... $ECHO_C\" >&6\n \n \t\t;;\n \tesac\n-\techo \"$as_me:24953: result: $ADAFLAGS\" >&5\n+\techo \"$as_me:24954: result: $ADAFLAGS\" >&5\n echo \"${ECHO_T}$ADAFLAGS\" >&6\n \n-echo \"$as_me:24956: checking if GNATPREP supports -T option\" >&5\n+echo \"$as_me:24957: checking if GNATPREP supports -T option\" >&5\n echo $ECHO_N \"checking if GNATPREP supports -T option... $ECHO_C\" >&6\n if test \"${cf_cv_gnatprep_opt_t+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -24963,21 +24964,21 @@ cf_cv_gnatprep_opt_t=no\n gnatprep -T 2>/dev/null >/dev/null && cf_cv_gnatprep_opt_t=yes\n \n fi\n-echo \"$as_me:24966: result: $cf_cv_gnatprep_opt_t\" >&5\n+echo \"$as_me:24967: result: $cf_cv_gnatprep_opt_t\" >&5\n echo \"${ECHO_T}$cf_cv_gnatprep_opt_t\" >&6\n test \"$cf_cv_gnatprep_opt_t\" = yes && GNATPREP_OPTS=\"-T $GNATPREP_OPTS\"\n \n-echo \"$as_me:24970: checking if GNAT supports generics\" >&5\n+echo \"$as_me:24971: checking if GNAT supports generics\" >&5\n echo $ECHO_N \"checking if GNAT supports generics... $ECHO_C\" >&6\n case $cf_cv_gnat_version in\n-(3.[1-9]*|[4-9].*)\n+(3.[1-9]*|[4-9].*|[1-9][0-9].*)\n \tcf_gnat_generics=yes\n \t;;\n (*)\n \tcf_gnat_generics=no\n \t;;\n esac\n-echo \"$as_me:24980: result: $cf_gnat_generics\" >&5\n+echo \"$as_me:24981: result: $cf_gnat_generics\" >&5\n echo \"${ECHO_T}$cf_gnat_generics\" >&6\n \n if test \"$cf_gnat_generics\" = yes\n@@ -24989,7 +24990,7 @@ else\n \tcf_generic_objects=\n fi\n \n-echo \"$as_me:24992: checking if GNAT supports SIGINT\" >&5\n+echo \"$as_me:24993: checking if GNAT supports SIGINT\" >&5\n echo $ECHO_N \"checking if GNAT supports SIGINT... $ECHO_C\" >&6\n if test \"${cf_cv_gnat_sigint+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -25037,7 +25038,7 @@ fi\n rm -rf conftest* *~conftest*\n \n fi\n-echo \"$as_me:25040: result: $cf_cv_gnat_sigint\" >&5\n+echo \"$as_me:25041: result: $cf_cv_gnat_sigint\" >&5\n echo \"${ECHO_T}$cf_cv_gnat_sigint\" >&6\n \n if test $cf_cv_gnat_sigint = yes ; then\n@@ -25050,7 +25051,7 @@ cf_gnat_libraries=no\n cf_gnat_projects=no\n \n if test \"$enable_gnat_projects\" != no ; then\n-echo \"$as_me:25053: checking if GNAT supports project files\" >&5\n+echo \"$as_me:25054: checking if GNAT supports project files\" >&5\n echo $ECHO_N \"checking if GNAT supports project files... $ECHO_C\" >&6\n case $cf_cv_gnat_version in\n (3.[0-9]*)\n@@ -25113,15 +25114,15 @@ CF_EOF\n \tesac\n \t;;\n esac\n-echo \"$as_me:25116: result: $cf_gnat_projects\" >&5\n+echo \"$as_me:25117: result: $cf_gnat_projects\" >&5\n echo \"${ECHO_T}$cf_gnat_projects\" >&6\n fi # enable_gnat_projects\n \n if test $cf_gnat_projects = yes\n then\n-\techo \"$as_me:25122: checking if GNAT supports libraries\" >&5\n+\techo \"$as_me:25123: checking if GNAT supports libraries\" >&5\n echo $ECHO_N \"checking if GNAT supports libraries... $ECHO_C\" >&6\n-\techo \"$as_me:25124: result: $cf_gnat_libraries\" >&5\n+\techo \"$as_me:25125: result: $cf_gnat_libraries\" >&5\n echo \"${ECHO_T}$cf_gnat_libraries\" >&6\n fi\n \n@@ -25141,7 +25142,7 @@ else\n \tUSE_GNAT_LIBRARIES=\"#\"\n fi\n \n-echo \"$as_me:25144: checking for ada-compiler\" >&5\n+echo \"$as_me:25145: checking for ada-compiler\" >&5\n echo $ECHO_N \"checking for ada-compiler... $ECHO_C\" >&6\n \n # Check whether --with-ada-compiler or --without-ada-compiler was given.\n@@ -25152,12 +25153,12 @@ else\n   cf_ada_compiler=gnatmake\n fi;\n \n-echo \"$as_me:25155: result: $cf_ada_compiler\" >&5\n+echo \"$as_me:25156: result: $cf_ada_compiler\" >&5\n echo \"${ECHO_T}$cf_ada_compiler\" >&6\n \n \t\t\tcf_ada_package=terminal_interface\n \n-echo \"$as_me:25160: checking for ada-include\" >&5\n+echo \"$as_me:25161: checking for ada-include\" >&5\n echo $ECHO_N \"checking for ada-include... $ECHO_C\" >&6\n \n # Check whether --with-ada-include or --without-ada-include was given.\n@@ -25193,7 +25194,7 @@ case \".$withval\" in\n \twithval=`echo $withval | sed -e s%NONE%$cf_path_syntax%`\n \t;;\n (*)\n-\t{ { echo \"$as_me:25196: error: expected a pathname, not \\\"$withval\\\"\" >&5\n+\t{ { echo \"$as_me:25197: error: expected a pathname, not \\\"$withval\\\"\" >&5\n echo \"$as_me: error: expected a pathname, not \\\"$withval\\\"\" >&2;}\n    { (exit 1); exit 1; }; }\n \t;;\n@@ -25202,10 +25203,10 @@ esac\n fi\n eval ADA_INCLUDE=\"$withval\"\n \n-echo \"$as_me:25205: result: $ADA_INCLUDE\" >&5\n+echo \"$as_me:25206: result: $ADA_INCLUDE\" >&5\n echo \"${ECHO_T}$ADA_INCLUDE\" >&6\n \n-echo \"$as_me:25208: checking for ada-objects\" >&5\n+echo \"$as_me:25209: checking for ada-objects\" >&5\n echo $ECHO_N \"checking for ada-objects... $ECHO_C\" >&6\n \n # Check whether --with-ada-objects or --without-ada-objects was given.\n@@ -25241,7 +25242,7 @@ case \".$withval\" in\n \twithval=`echo $withval | sed -e s%NONE%$cf_path_syntax%`\n \t;;\n (*)\n-\t{ { echo \"$as_me:25244: error: expected a pathname, not \\\"$withval\\\"\" >&5\n+\t{ { echo \"$as_me:25245: error: expected a pathname, not \\\"$withval\\\"\" >&5\n echo \"$as_me: error: expected a pathname, not \\\"$withval\\\"\" >&2;}\n    { (exit 1); exit 1; }; }\n \t;;\n@@ -25250,10 +25251,10 @@ esac\n fi\n eval ADA_OBJECTS=\"$withval\"\n \n-echo \"$as_me:25253: result: $ADA_OBJECTS\" >&5\n+echo \"$as_me:25254: result: $ADA_OBJECTS\" >&5\n echo \"${ECHO_T}$ADA_OBJECTS\" >&6\n \n-echo \"$as_me:25256: checking if an Ada95 shared-library should be built\" >&5\n+echo \"$as_me:25257: checking if an Ada95 shared-library should be built\" >&5\n echo $ECHO_N \"checking if an Ada95 shared-library should be built... $ECHO_C\" >&6\n \n # Check whether --with-ada-sharedlib or --without-ada-sharedlib was given.\n@@ -25263,14 +25264,14 @@ if test \"${with_ada_sharedlib+set}\" = set; then\n else\n   with_ada_sharedlib=no\n fi;\n-echo \"$as_me:25266: result: $with_ada_sharedlib\" >&5\n+echo \"$as_me:25267: result: $with_ada_sharedlib\" >&5\n echo \"${ECHO_T}$with_ada_sharedlib\" >&6\n \n if test \"x$with_ada_sharedlib\" != xno\n then\n \tif test \"x$cf_gnat_projects\" != xyes\n \tthen\n-\t\t{ echo \"$as_me:25273: WARNING: disabling shared-library since GNAT projects are not supported\" >&5\n+\t\t{ echo \"$as_me:25274: WARNING: disabling shared-library since GNAT projects are not supported\" >&5\n echo \"$as_me: WARNING: disabling shared-library since GNAT projects are not supported\" >&2;}\n \t\twith_ada_sharedlib=no\n \tfi\n@@ -25290,7 +25291,7 @@ fi\n \n \t\t\t# allow the Ada binding to be renamed\n \n-echo \"$as_me:25293: checking for ada-libname\" >&5\n+echo \"$as_me:25294: checking for ada-libname\" >&5\n echo $ECHO_N \"checking for ada-libname... $ECHO_C\" >&6\n \n # Check whether --with-ada-libname or --without-ada-libname was given.\n@@ -25306,7 +25307,7 @@ case \"x$ADA_LIBNAME\" in\n \t;;\n esac\n \n-echo \"$as_me:25309: result: $ADA_LIBNAME\" >&5\n+echo \"$as_me:25310: result: $ADA_LIBNAME\" >&5\n echo \"${ECHO_T}$ADA_LIBNAME\" >&6\n \n \t\tfi\n@@ -25317,13 +25318,13 @@ fi\n \n # do this \"late\" to avoid conflict with header-checks\n if test \"x$with_widec\" = xyes ; then\n-\techo \"$as_me:25320: checking for wchar_t\" >&5\n+\techo \"$as_me:25321: checking for wchar_t\" >&5\n echo $ECHO_N \"checking for wchar_t... $ECHO_C\" >&6\n if test \"${ac_cv_type_wchar_t+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 25326 \"configure\"\n+#line 25327 \"configure\"\n #include \"confdefs.h\"\n $ac_includes_default\n int\n@@ -25338,16 +25339,16 @@ if (sizeof (wchar_t))\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:25341: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:25342: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:25344: \\$? = $ac_status\" >&5\n+  echo \"$as_me:25345: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:25347: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:25348: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:25350: \\$? = $ac_status\" >&5\n+  echo \"$as_me:25351: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   ac_cv_type_wchar_t=yes\n else\n@@ -25357,10 +25358,10 @@ ac_cv_type_wchar_t=no\n fi\n rm -f conftest.$ac_objext conftest.$ac_ext\n fi\n-echo \"$as_me:25360: result: $ac_cv_type_wchar_t\" >&5\n+echo \"$as_me:25361: result: $ac_cv_type_wchar_t\" >&5\n echo \"${ECHO_T}$ac_cv_type_wchar_t\" >&6\n \n-echo \"$as_me:25363: checking size of wchar_t\" >&5\n+echo \"$as_me:25364: checking size of wchar_t\" >&5\n echo $ECHO_N \"checking size of wchar_t... $ECHO_C\" >&6\n if test \"${ac_cv_sizeof_wchar_t+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -25369,7 +25370,7 @@ else\n   if test \"$cross_compiling\" = yes; then\n   # Depending upon the size, compute the lo and hi bounds.\n cat >conftest.$ac_ext <<_ACEOF\n-#line 25372 \"configure\"\n+#line 25373 \"configure\"\n #include \"confdefs.h\"\n $ac_includes_default\n int\n@@ -25381,21 +25382,21 @@ int _array_ [1 - 2 * !((sizeof (wchar_t)) >= 0)]\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:25384: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:25385: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:25387: \\$? = $ac_status\" >&5\n+  echo \"$as_me:25388: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:25390: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:25391: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:25393: \\$? = $ac_status\" >&5\n+  echo \"$as_me:25394: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   ac_lo=0 ac_mid=0\n   while :; do\n     cat >conftest.$ac_ext <<_ACEOF\n-#line 25398 \"configure\"\n+#line 25399 \"configure\"\n #include \"confdefs.h\"\n $ac_includes_default\n int\n@@ -25407,16 +25408,16 @@ int _array_ [1 - 2 * !((sizeof (wchar_t)) <= $ac_mid)]\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:25410: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:25411: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:25413: \\$? = $ac_status\" >&5\n+  echo \"$as_me:25414: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:25416: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:25417: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:25419: \\$? = $ac_status\" >&5\n+  echo \"$as_me:25420: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   ac_hi=$ac_mid; break\n else\n@@ -25432,7 +25433,7 @@ cat conftest.$ac_ext >&5\n ac_hi=-1 ac_mid=-1\n   while :; do\n     cat >conftest.$ac_ext <<_ACEOF\n-#line 25435 \"configure\"\n+#line 25436 \"configure\"\n #include \"confdefs.h\"\n $ac_includes_default\n int\n@@ -25444,16 +25445,16 @@ int _array_ [1 - 2 * !((sizeof (wchar_t)) >= $ac_mid)]\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:25447: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:25448: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:25450: \\$? = $ac_status\" >&5\n+  echo \"$as_me:25451: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:25453: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:25454: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:25456: \\$? = $ac_status\" >&5\n+  echo \"$as_me:25457: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   ac_lo=$ac_mid; break\n else\n@@ -25469,7 +25470,7 @@ rm -f conftest.$ac_objext conftest.$ac_ext\n while test \"x$ac_lo\" != \"x$ac_hi\"; do\n   ac_mid=`expr '(' $ac_hi - $ac_lo ')' / 2 + $ac_lo`\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 25472 \"configure\"\n+#line 25473 \"configure\"\n #include \"confdefs.h\"\n $ac_includes_default\n int\n@@ -25481,16 +25482,16 @@ int _array_ [1 - 2 * !((sizeof (wchar_t)) <= $ac_mid)]\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:25484: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:25485: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:25487: \\$? = $ac_status\" >&5\n+  echo \"$as_me:25488: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:25490: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:25491: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:25493: \\$? = $ac_status\" >&5\n+  echo \"$as_me:25494: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   ac_hi=$ac_mid\n else\n@@ -25503,12 +25504,12 @@ done\n ac_cv_sizeof_wchar_t=$ac_lo\n else\n   if test \"$cross_compiling\" = yes; then\n-  { { echo \"$as_me:25506: error: cannot run test program while cross compiling\" >&5\n+  { { echo \"$as_me:25507: error: cannot run test program while cross compiling\" >&5\n echo \"$as_me: error: cannot run test program while cross compiling\" >&2;}\n    { (exit 1); exit 1; }; }\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 25511 \"configure\"\n+#line 25512 \"configure\"\n #include \"confdefs.h\"\n $ac_includes_default\n int\n@@ -25524,15 +25525,15 @@ fclose (f);\n }\n _ACEOF\n rm -f conftest$ac_exeext\n-if { (eval echo \"$as_me:25527: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:25528: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:25530: \\$? = $ac_status\" >&5\n+  echo \"$as_me:25531: \\$? = $ac_status\" >&5\n   (exit $ac_status); } && { ac_try='./conftest$ac_exeext'\n-  { (eval echo \"$as_me:25532: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:25533: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:25535: \\$? = $ac_status\" >&5\n+  echo \"$as_me:25536: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   ac_cv_sizeof_wchar_t=`cat conftest.val`\n else\n@@ -25548,7 +25549,7 @@ else\n   ac_cv_sizeof_wchar_t=0\n fi\n fi\n-echo \"$as_me:25551: result: $ac_cv_sizeof_wchar_t\" >&5\n+echo \"$as_me:25552: result: $ac_cv_sizeof_wchar_t\" >&5\n echo \"${ECHO_T}$ac_cv_sizeof_wchar_t\" >&6\n cat >>confdefs.h <<EOF\n #define SIZEOF_WCHAR_T $ac_cv_sizeof_wchar_t\n@@ -25561,7 +25562,7 @@ EOF\n \tthen\n \t\ttest -n \"$verbose\" && echo \"\ttest failed (assume 2)\" 1>&6\n \n-echo \"${as_me:-configure}:25564: testing test failed (assume 2) ...\" 1>&5\n+echo \"${as_me:-configure}:25565: testing test failed (assume 2) ...\" 1>&5\n \n \t\tsed /SIZEOF_WCHAR_T/d confdefs.h >confdefs.tmp\n \t\tmv confdefs.tmp confdefs.h\n@@ -25579,7 +25580,7 @@ fi\n ### chooses to split module lists into libraries.\n ###\n ### (see CF_LIB_RULES).\n-echo \"$as_me:25582: checking for library subsets\" >&5\n+echo \"$as_me:25583: checking for library subsets\" >&5\n echo $ECHO_N \"checking for library subsets... $ECHO_C\" >&6\n LIB_SUBSETS=\n \n@@ -25621,7 +25622,7 @@ fi\n test \"x$with_widec\"     = xyes && LIB_SUBSETS=\"${LIB_SUBSETS}+widechar\"\n test \"x$with_ext_funcs\" = xyes && LIB_SUBSETS=\"${LIB_SUBSETS}+ext_funcs\"\n \n-echo \"$as_me:25624: result: $LIB_SUBSETS\" >&5\n+echo \"$as_me:25625: result: $LIB_SUBSETS\" >&5\n echo \"${ECHO_T}$LIB_SUBSETS\" >&6\n \n ### Construct the list of include-directories to be generated\n@@ -25652,7 +25653,7 @@ elif test \"$includedir\" != \"/usr/include\"; then\n fi\n \n ### Build up pieces for makefile rules\n-echo \"$as_me:25655: checking default library suffix\" >&5\n+echo \"$as_me:25656: checking default library suffix\" >&5\n echo $ECHO_N \"checking default library suffix... $ECHO_C\" >&6\n \n \tcase $DFT_LWR_MODEL in\n@@ -25663,10 +25664,10 @@ echo $ECHO_N \"checking default library suffix... $ECHO_C\" >&6\n \t(shared)  DFT_ARG_SUFFIX=''   ;;\n \tesac\n \ttest -n \"$LIB_SUFFIX\" && DFT_ARG_SUFFIX=\"${LIB_SUFFIX}${DFT_ARG_SUFFIX}\"\n-echo \"$as_me:25666: result: $DFT_ARG_SUFFIX\" >&5\n+echo \"$as_me:25667: result: $DFT_ARG_SUFFIX\" >&5\n echo \"${ECHO_T}$DFT_ARG_SUFFIX\" >&6\n \n-echo \"$as_me:25669: checking default library-dependency suffix\" >&5\n+echo \"$as_me:25670: checking default library-dependency suffix\" >&5\n echo $ECHO_N \"checking default library-dependency suffix... $ECHO_C\" >&6\n \n \tcase X$DFT_LWR_MODEL in\n@@ -25749,10 +25750,10 @@ echo $ECHO_N \"checking default library-dependency suffix... $ECHO_C\" >&6\n \t\tDFT_LIB_SUFFIX=\"${LIB_SUFFIX}${EXTRA_SUFFIX}${DFT_LIB_SUFFIX}\"\n \t\tDFT_DEP_SUFFIX=\"${LIB_SUFFIX}${EXTRA_SUFFIX}${DFT_DEP_SUFFIX}\"\n \tfi\n-echo \"$as_me:25752: result: $DFT_DEP_SUFFIX\" >&5\n+echo \"$as_me:25753: result: $DFT_DEP_SUFFIX\" >&5\n echo \"${ECHO_T}$DFT_DEP_SUFFIX\" >&6\n \n-echo \"$as_me:25755: checking default object directory\" >&5\n+echo \"$as_me:25756: checking default object directory\" >&5\n echo $ECHO_N \"checking default object directory... $ECHO_C\" >&6\n \n \tcase $DFT_LWR_MODEL in\n@@ -25768,11 +25769,11 @@ echo $ECHO_N \"checking default object directory... $ECHO_C\" >&6\n \t\t\tDFT_OBJ_SUBDIR='obj_s' ;;\n \t\tesac\n \tesac\n-echo \"$as_me:25771: result: $DFT_OBJ_SUBDIR\" >&5\n+echo \"$as_me:25772: result: $DFT_OBJ_SUBDIR\" >&5\n echo \"${ECHO_T}$DFT_OBJ_SUBDIR\" >&6\n \n if test \"x$cf_with_cxx\" = xyes ; then\n-echo \"$as_me:25775: checking c++ library-dependency suffix\" >&5\n+echo \"$as_me:25776: checking c++ library-dependency suffix\" >&5\n echo $ECHO_N \"checking c++ library-dependency suffix... $ECHO_C\" >&6\n if test \"$with_libtool\" != \"no\"; then\n \t# libtool thinks it can make c++ shared libraries (perhaps only g++)\n@@ -25865,7 +25866,7 @@ else\n \tfi\n \n fi\n-echo \"$as_me:25868: result: $CXX_LIB_SUFFIX\" >&5\n+echo \"$as_me:25869: result: $CXX_LIB_SUFFIX\" >&5\n echo \"${ECHO_T}$CXX_LIB_SUFFIX\" >&6\n \n fi\n@@ -26041,19 +26042,19 @@ fi\n \n if test -n \"$LDFLAGS_STATIC\" && test -n \"$LDFLAGS_SHARED\"\n then\n-\techo \"$as_me:26044: checking if linker supports switching between static/dynamic\" >&5\n+\techo \"$as_me:26045: checking if linker supports switching between static/dynamic\" >&5\n echo $ECHO_N \"checking if linker supports switching between static/dynamic... $ECHO_C\" >&6\n \n \trm -f libconftest.a\n \tcat >conftest.$ac_ext <<EOF\n-#line 26049 \"configure\"\n+#line 26050 \"configure\"\n #include <stdio.h>\n int cf_ldflags_static(FILE *fp) { return fflush(fp); }\n EOF\n-\tif { (eval echo \"$as_me:26053: \\\"$ac_compile\\\"\") >&5\n+\tif { (eval echo \"$as_me:26054: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:26056: \\$? = $ac_status\" >&5\n+  echo \"$as_me:26057: \\$? = $ac_status\" >&5\n   (exit $ac_status); } ; then\n \t\t( $AR $ARFLAGS libconftest.a conftest.o ) 2>&5 1>/dev/null\n \t\t( eval $RANLIB libconftest.a ) 2>&5 >/dev/null\n@@ -26064,10 +26065,10 @@ EOF\n \n \tLIBS=\"$LDFLAGS_STATIC -L`pwd` -lconftest $LDFLAGS_DYNAMIC $LIBS\"\n \tcat >conftest.$ac_ext <<_ACEOF\n-#line 26067 \"configure\"\n+#line 26068 \"configure\"\n #include \"confdefs.h\"\n \n-#line 26070 \"configure\"\n+#line 26071 \"configure\"\n #include <stdio.h>\n int cf_ldflags_static(FILE *fp);\n \n@@ -26082,16 +26083,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:26085: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:26086: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:26088: \\$? = $ac_status\" >&5\n+  echo \"$as_me:26089: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:26091: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:26092: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:26094: \\$? = $ac_status\" >&5\n+  echo \"$as_me:26095: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n \n \t# some linkers simply ignore the -dynamic\n@@ -26114,7 +26115,7 @@ rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n \trm -f libconftest.*\n \tLIBS=\"$cf_save_LIBS\"\n \n-\techo \"$as_me:26117: result: $cf_ldflags_static\" >&5\n+\techo \"$as_me:26118: result: $cf_ldflags_static\" >&5\n echo \"${ECHO_T}$cf_ldflags_static\" >&6\n \n \tif test $cf_ldflags_static != yes\n@@ -26130,7 +26131,7 @@ fi\n \t;;\n esac\n \n-echo \"$as_me:26133: checking where we will install curses.h\" >&5\n+echo \"$as_me:26134: checking where we will install curses.h\" >&5\n echo $ECHO_N \"checking where we will install curses.h... $ECHO_C\" >&6\n \n includesubdir=\n@@ -26140,7 +26141,7 @@ if test \"$with_overwrite\" = no && \\\n then\n \tincludesubdir=\"/ncurses${USE_LIB_SUFFIX}\"\n fi\n-echo \"$as_me:26143: result: ${includedir}${includesubdir}\" >&5\n+echo \"$as_me:26144: result: ${includedir}${includesubdir}\" >&5\n echo \"${ECHO_T}${includedir}${includesubdir}\" >&6\n \n ### Resolve a conflict between normal and wide-curses by forcing applications\n@@ -26148,7 +26149,7 @@ echo \"${ECHO_T}${includedir}${includesubdir}\" >&6\n if test \"$with_overwrite\" != no ; then\n if test \"$NCURSES_LIBUTF8\" = 1 ; then\n \tNCURSES_LIBUTF8='defined(HAVE_LIBUTF8_H)'\n-\t{ echo \"$as_me:26151: WARNING: Wide-character applications must define HAVE_LIBUTF8_H to include curses.h\" >&5\n+\t{ echo \"$as_me:26152: WARNING: Wide-character applications must define HAVE_LIBUTF8_H to include curses.h\" >&5\n echo \"$as_me: WARNING: Wide-character applications must define HAVE_LIBUTF8_H to include curses.h\" >&2;}\n fi\n fi\n@@ -26165,7 +26166,7 @@ EOF\n \n # pkgsrc uses these\n \n-echo \"$as_me:26168: checking for desired basename for form library\" >&5\n+echo \"$as_me:26169: checking for desired basename for form library\" >&5\n echo $ECHO_N \"checking for desired basename for form library... $ECHO_C\" >&6\n \n # Check whether --with-form-libname or --without-form-libname was given.\n@@ -26185,10 +26186,10 @@ case \"x$FORM_NAME\" in\n \t;;\n esac\n \n-echo \"$as_me:26188: result: $FORM_NAME\" >&5\n+echo \"$as_me:26189: result: $FORM_NAME\" >&5\n echo \"${ECHO_T}$FORM_NAME\" >&6\n \n-echo \"$as_me:26191: checking for desired basename for menu library\" >&5\n+echo \"$as_me:26192: checking for desired basename for menu library\" >&5\n echo $ECHO_N \"checking for desired basename for menu library... $ECHO_C\" >&6\n \n # Check whether --with-menu-libname or --without-menu-libname was given.\n@@ -26208,10 +26209,10 @@ case \"x$MENU_NAME\" in\n \t;;\n esac\n \n-echo \"$as_me:26211: result: $MENU_NAME\" >&5\n+echo \"$as_me:26212: result: $MENU_NAME\" >&5\n echo \"${ECHO_T}$MENU_NAME\" >&6\n \n-echo \"$as_me:26214: checking for desired basename for panel library\" >&5\n+echo \"$as_me:26215: checking for desired basename for panel library\" >&5\n echo $ECHO_N \"checking for desired basename for panel library... $ECHO_C\" >&6\n \n # Check whether --with-panel-libname or --without-panel-libname was given.\n@@ -26231,10 +26232,10 @@ case \"x$PANEL_NAME\" in\n \t;;\n esac\n \n-echo \"$as_me:26234: result: $PANEL_NAME\" >&5\n+echo \"$as_me:26235: result: $PANEL_NAME\" >&5\n echo \"${ECHO_T}$PANEL_NAME\" >&6\n \n-echo \"$as_me:26237: checking for desired basename for cxx library\" >&5\n+echo \"$as_me:26238: checking for desired basename for cxx library\" >&5\n echo $ECHO_N \"checking for desired basename for cxx library... $ECHO_C\" >&6\n \n # Check whether --with-cxx-libname or --without-cxx-libname was given.\n@@ -26254,13 +26255,13 @@ case \"x$CXX_NAME\" in\n \t;;\n esac\n \n-echo \"$as_me:26257: result: $CXX_NAME\" >&5\n+echo \"$as_me:26258: result: $CXX_NAME\" >&5\n echo \"${ECHO_T}$CXX_NAME\" >&6\n \n ### Construct the list of subdirectories for which we'll customize makefiles\n ### with the appropriate compile-rules.\n \n-echo \"$as_me:26263: checking for src modules\" >&5\n+echo \"$as_me:26264: checking for src modules\" >&5\n echo $ECHO_N \"checking for src modules... $ECHO_C\" >&6\n \n # dependencies and linker-arguments for test-programs\n@@ -26329,7 +26330,7 @@ eval TEST_ROOT=\\$${cf_map_lib_basename}_NAME\n \t\tfi\n \tfi\n done\n-echo \"$as_me:26332: result: $cf_cv_src_modules\" >&5\n+echo \"$as_me:26333: result: $cf_cv_src_modules\" >&5\n echo \"${ECHO_T}$cf_cv_src_modules\" >&6\n \n TEST_ARGS=\"-L${LIB_DIR} $TEST_ARGS\"\n@@ -26590,7 +26591,7 @@ case $cf_cv_system_name in\n \t(*-D_XOPEN_SOURCE_EXTENDED*)\n \t\ttest -n \"$verbose\" && echo \"\tmoving _XOPEN_SOURCE_EXTENDED to work around g++ problem\" 1>&6\n \n-echo \"${as_me:-configure}:26593: testing moving _XOPEN_SOURCE_EXTENDED to work around g++ problem ...\" 1>&5\n+echo \"${as_me:-configure}:26594: testing moving _XOPEN_SOURCE_EXTENDED to work around g++ problem ...\" 1>&5\n \n \t\tCFLAGS=\"$CFLAGS -D_XOPEN_SOURCE_EXTENDED\"\n \t\tCPPFLAGS=`echo \"x$CPPFLAGS\" | sed -e  's/^.//' -e 's/-D_XOPEN_SOURCE_EXTENDED//'`\n@@ -26601,7 +26602,7 @@ esac\n \n # Help to automatically enable the extended curses features when using either\n # the *-config or the \".pc\" files by adding defines.\n-echo \"$as_me:26604: checking for defines to add to ncurses${USE_CFG_SUFFIX}-config script\" >&5\n+echo \"$as_me:26605: checking for defines to add to ncurses${USE_CFG_SUFFIX}-config script\" >&5\n echo $ECHO_N \"checking for defines to add to ncurses${USE_CFG_SUFFIX}-config script... $ECHO_C\" >&6\n PKG_CFLAGS=\n for cf_loop1 in $CPPFLAGS_after_XOPEN\n@@ -26617,7 +26618,7 @@ do\n \tdone\n \ttest \"$cf_found\" = no && PKG_CFLAGS=\"$PKG_CFLAGS $cf_loop1\"\n done\n-echo \"$as_me:26620: result: $PKG_CFLAGS\" >&5\n+echo \"$as_me:26621: result: $PKG_CFLAGS\" >&5\n echo \"${ECHO_T}$PKG_CFLAGS\" >&6\n \n # AC_CHECK_SIZEOF demands a literal parameter, no variables.  So we do this.\n@@ -26678,7 +26679,7 @@ then\n \tcf_filter_syms=$cf_dft_filter_syms\n \ttest -n \"$verbose\" && echo \"\twill map symbols to ABI=$cf_cv_abi_version\" 1>&6\n \n-echo \"${as_me:-configure}:26681: testing will map symbols to ABI=$cf_cv_abi_version ...\" 1>&5\n+echo \"${as_me:-configure}:26682: testing will map symbols to ABI=$cf_cv_abi_version ...\" 1>&5\n \n fi\n \n@@ -26705,7 +26706,7 @@ fi\n \n # This is used for the *-config script and *.pc data files.\n \n-echo \"$as_me:26708: checking for linker search path\" >&5\n+echo \"$as_me:26709: checking for linker search path\" >&5\n echo $ECHO_N \"checking for linker search path... $ECHO_C\" >&6\n if test \"${cf_cv_ld_searchpath+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -26769,7 +26770,7 @@ done\n test -z \"$cf_cv_ld_searchpath\" && cf_cv_ld_searchpath=/usr/lib\n \n fi\n-echo \"$as_me:26772: result: $cf_cv_ld_searchpath\" >&5\n+echo \"$as_me:26773: result: $cf_cv_ld_searchpath\" >&5\n echo \"${ECHO_T}$cf_cv_ld_searchpath\" >&6\n \n LD_SEARCHPATH=`echo \"$cf_cv_ld_searchpath\"|sed -e 's/ /|/g'`\n@@ -26859,7 +26860,7 @@ DEFS=-DHAVE_CONFIG_H\n : ${CONFIG_STATUS=./config.status}\n ac_clean_files_save=$ac_clean_files\n ac_clean_files=\"$ac_clean_files $CONFIG_STATUS\"\n-{ echo \"$as_me:26862: creating $CONFIG_STATUS\" >&5\n+{ echo \"$as_me:26863: creating $CONFIG_STATUS\" >&5\n echo \"$as_me: creating $CONFIG_STATUS\" >&6;}\n cat >$CONFIG_STATUS <<_ACEOF\n #! $SHELL\n@@ -27035,7 +27036,7 @@ cat >>$CONFIG_STATUS <<\\EOF\n     echo \"$ac_cs_version\"; exit 0 ;;\n   --he | --h)\n     # Conflict between --help and --header\n-    { { echo \"$as_me:27038: error: ambiguous option: $1\n+    { { echo \"$as_me:27039: error: ambiguous option: $1\n Try \\`$0 --help' for more information.\" >&5\n echo \"$as_me: error: ambiguous option: $1\n Try \\`$0 --help' for more information.\" >&2;}\n@@ -27054,7 +27055,7 @@ Try \\`$0 --help' for more information.\" >&2;}\n     ac_need_defaults=false;;\n \n   # This is an error.\n-  -*) { { echo \"$as_me:27057: error: unrecognized option: $1\n+  -*) { { echo \"$as_me:27058: error: unrecognized option: $1\n Try \\`$0 --help' for more information.\" >&5\n echo \"$as_me: error: unrecognized option: $1\n Try \\`$0 --help' for more information.\" >&2;}\n@@ -27177,7 +27178,7 @@ do\n   \"Makefile\" ) CONFIG_FILES=\"$CONFIG_FILES Makefile\" ;;\n   \"default\" ) CONFIG_COMMANDS=\"$CONFIG_COMMANDS default\" ;;\n   \"include/ncurses_cfg.h\" ) CONFIG_HEADERS=\"$CONFIG_HEADERS include/ncurses_cfg.h:include/ncurses_cfg.hin\" ;;\n-  *) { { echo \"$as_me:27180: error: invalid argument: $ac_config_target\" >&5\n+  *) { { echo \"$as_me:27181: error: invalid argument: $ac_config_target\" >&5\n echo \"$as_me: error: invalid argument: $ac_config_target\" >&2;}\n    { (exit 1); exit 1; }; };;\n   esac\n@@ -27676,7 +27677,7 @@ done; }\n   esac\n \n   if test x\"$ac_file\" != x-; then\n-    { echo \"$as_me:27679: creating $ac_file\" >&5\n+    { echo \"$as_me:27680: creating $ac_file\" >&5\n echo \"$as_me: creating $ac_file\" >&6;}\n     rm -f \"$ac_file\"\n   fi\n@@ -27694,7 +27695,7 @@ echo \"$as_me: creating $ac_file\" >&6;}\n       -) echo $tmp/stdin ;;\n       [\\\\/$]*)\n          # Absolute (can't be DOS-style, as IFS=:)\n-         test -f \"$f\" || { { echo \"$as_me:27697: error: cannot find input file: $f\" >&5\n+         test -f \"$f\" || { { echo \"$as_me:27698: error: cannot find input file: $f\" >&5\n echo \"$as_me: error: cannot find input file: $f\" >&2;}\n    { (exit 1); exit 1; }; }\n          echo $f;;\n@@ -27707,7 +27708,7 @@ echo \"$as_me: error: cannot find input file: $f\" >&2;}\n            echo $srcdir/$f\n          else\n            # /dev/null tree\n-           { { echo \"$as_me:27710: error: cannot find input file: $f\" >&5\n+           { { echo \"$as_me:27711: error: cannot find input file: $f\" >&5\n echo \"$as_me: error: cannot find input file: $f\" >&2;}\n    { (exit 1); exit 1; }; }\n          fi;;\n@@ -27723,7 +27724,7 @@ cat >>$CONFIG_STATUS <<\\EOF\n       if test -n \"$ac_seen\"; then\n         ac_used=`grep '@datarootdir@' $ac_item`\n         if test -z \"$ac_used\"; then\n-          { echo \"$as_me:27726: WARNING: datarootdir was used implicitly but not set:\n+          { echo \"$as_me:27727: WARNING: datarootdir was used implicitly but not set:\n $ac_seen\" >&5\n echo \"$as_me: WARNING: datarootdir was used implicitly but not set:\n $ac_seen\" >&2;}\n@@ -27732,7 +27733,7 @@ $ac_seen\" >&2;}\n       fi\n       ac_seen=`grep '${datarootdir}' $ac_item`\n       if test -n \"$ac_seen\"; then\n-        { echo \"$as_me:27735: WARNING: datarootdir was used explicitly but not set:\n+        { echo \"$as_me:27736: WARNING: datarootdir was used explicitly but not set:\n $ac_seen\" >&5\n echo \"$as_me: WARNING: datarootdir was used explicitly but not set:\n $ac_seen\" >&2;}\n@@ -27769,7 +27770,7 @@ s,@INSTALL@,$ac_INSTALL,;t t\n             ac_init=`egrep '[ \t]*'$ac_name'[ \t]*=' $ac_file`\n             if test -z \"$ac_init\"; then\n               ac_seen=`echo \"$ac_seen\" |sed -e 's,^,'$ac_file':,'`\n-              { echo \"$as_me:27772: WARNING: Variable $ac_name is used but was not set:\n+              { echo \"$as_me:27773: WARNING: Variable $ac_name is used but was not set:\n $ac_seen\" >&5\n echo \"$as_me: WARNING: Variable $ac_name is used but was not set:\n $ac_seen\" >&2;}\n@@ -27780,7 +27781,7 @@ $ac_seen\" >&2;}\n     egrep -n '@[A-Z_][A-Z_0-9]+@' $ac_file >>$tmp/out\n     if test -s $tmp/out; then\n       ac_seen=`sed -e 's,^,'$ac_file':,' < $tmp/out`\n-      { echo \"$as_me:27783: WARNING: Some variables may not be substituted:\n+      { echo \"$as_me:27784: WARNING: Some variables may not be substituted:\n $ac_seen\" >&5\n echo \"$as_me: WARNING: Some variables may not be substituted:\n $ac_seen\" >&2;}\n@@ -27829,7 +27830,7 @@ for ac_file in : $CONFIG_HEADERS; do test \"x$ac_file\" = x: && continue\n   * )   ac_file_in=$ac_file.in ;;\n   esac\n \n-  test x\"$ac_file\" != x- && { echo \"$as_me:27832: creating $ac_file\" >&5\n+  test x\"$ac_file\" != x- && { echo \"$as_me:27833: creating $ac_file\" >&5\n echo \"$as_me: creating $ac_file\" >&6;}\n \n   # First look for the input files in the build tree, otherwise in the\n@@ -27840,7 +27841,7 @@ echo \"$as_me: creating $ac_file\" >&6;}\n       -) echo $tmp/stdin ;;\n       [\\\\/$]*)\n          # Absolute (can't be DOS-style, as IFS=:)\n-         test -f \"$f\" || { { echo \"$as_me:27843: error: cannot find input file: $f\" >&5\n+         test -f \"$f\" || { { echo \"$as_me:27844: error: cannot find input file: $f\" >&5\n echo \"$as_me: error: cannot find input file: $f\" >&2;}\n    { (exit 1); exit 1; }; }\n          echo $f;;\n@@ -27853,7 +27854,7 @@ echo \"$as_me: error: cannot find input file: $f\" >&2;}\n            echo $srcdir/$f\n          else\n            # /dev/null tree\n-           { { echo \"$as_me:27856: error: cannot find input file: $f\" >&5\n+           { { echo \"$as_me:27857: error: cannot find input file: $f\" >&5\n echo \"$as_me: error: cannot find input file: $f\" >&2;}\n    { (exit 1); exit 1; }; }\n          fi;;\n@@ -27911,7 +27912,7 @@ cat >>$CONFIG_STATUS <<\\EOF\n   rm -f $tmp/in\n   if test x\"$ac_file\" != x-; then\n     if cmp -s $ac_file $tmp/config.h 2>/dev/null; then\n-      { echo \"$as_me:27914: $ac_file is unchanged\" >&5\n+      { echo \"$as_me:27915: $ac_file is unchanged\" >&5\n echo \"$as_me: $ac_file is unchanged\" >&6;}\n     else\n       ac_dir=`$as_expr X\"$ac_file\" : 'X\\(.*[^/]\\)//*[^/][^/]*/*$' \\| \\\n@@ -28298,7 +28299,7 @@ cf_ITEM=`echo \"$cf_item\" | sed y%abcdefghijklmnopqrstuvwxyz./-%ABCDEFGHIJKLMNOPQ\n \t\t\t\t(cygdll|msysdll|mingw|msvcdll)\n \t\t\t\t\ttest \"x$with_shared_cxx\" = xno && test -n \"$verbose\" && echo \"\toverriding CXX_MODEL to SHARED\" 1>&6\n \n-echo \"${as_me:-configure}:28301: testing overriding CXX_MODEL to SHARED ...\" 1>&5\n+echo \"${as_me:-configure}:28302: testing overriding CXX_MODEL to SHARED ...\" 1>&5\n \n \t\t\t\t\twith_shared_cxx=yes\n \t\t\t\t\t;;\ndiff --git a/configure.in b/configure.in\nindex 10857b8de..7454c9aea 100644\n--- a/configure.in\n+++ b/configure.in\n@@ -29,7 +29,7 @@ dnl***************************************************************************\n dnl\n dnl Author: Thomas E. Dickey 1995-on\n dnl\n-dnl $Id: configure.in,v 1.707 2020/05/23 18:16:07 tom Exp $\n+dnl $Id: configure.in,v 1.709 2020/05/31 20:04:09 tom Exp $\n dnl Process this file with autoconf to produce a configure script.\n dnl\n dnl For additional information, see\n@@ -38,7 +38,7 @@ dnl     https://invisible-island.net/autoconf/my-autoconf.html\n dnl\n dnl ---------------------------------------------------------------------------\n AC_PREREQ(2.52.20200111)\n-AC_REVISION($Revision: 1.707 $)\n+AC_REVISION($Revision: 1.709 $)\n AC_INIT(ncurses/base/lib_initscr.c)\n AC_CONFIG_HEADER(include/ncurses_cfg.h:include/ncurses_cfg.hin)\n \n@@ -145,9 +145,9 @@ fi\n \n CF_GXX_VERSION\n case $GXX_VERSION in\n-(1*|2.[[0-6]]*)\n-\t# GXX=\"\"; CXX=\"\"; ac_cv_prog_gxx=no\n-\t# cf_cxx_library=no\n+([[1-9]][[0-9]].*)\n+\t;;\n+(1.*|2.[[0-6]]*)\n \tAC_MSG_WARN(templates do not work)\n \t;;\n esac\n@@ -1761,6 +1761,7 @@ setenv \\\n setvbuf \\\n sigaction \\\n sigvec \\\n+snprintf \\\n strdup \\\n strstr \\\n sysconf \\\n@@ -1848,7 +1849,7 @@ if test -n \"$CXX\" ; then\n \tCF_PROG_CC_C_O(CXX,[$CXXFLAGS $CPPFLAGS])\n \n \tcase $GXX_VERSION in\n-\t(1*|2.[0-6]*)\n+\t(1.*|2.[[0-6]]*|[[1-9]][[0-9]].*)\n \t\tcf_cxx_library=yes\n \t\t;;\n \t(*-2.7*|2.7*)\ndiff --git a/convert_configure.pl b/convert_configure.pl\ndeleted file mode 100644\nindex f35d154ff..000000000\n--- a/convert_configure.pl\n+++ /dev/null\n@@ -1,120 +0,0 @@\n-extproc perl -S -w\n-\n-# $Id: convert_configure.pl,v 1.4 2020/02/02 23:34:34 tom Exp $\n-##############################################################################\n-# Copyright 2020 Thomas E. Dickey                                            #\n-# Copyright 1998-2000,2006 Free Software Foundation, Inc.                    #\n-#                                                                            #\n-# Permission is hereby granted, free of charge, to any person obtaining a    #\n-# copy of this software and associated documentation files (the \"Software\"), #\n-# to deal in the Software without restriction, including without limitation  #\n-# the rights to use, copy, modify, merge, publish, distribute, distribute    #\n-# with modifications, sublicense, and/or sell copies of the Software, and to #\n-# permit persons to whom the Software is furnished to do so, subject to the  #\n-# following conditions:                                                      #\n-#                                                                            #\n-# The above copyright notice and this permission notice shall be included in #\n-# all copies or substantial portions of the Software.                        #\n-#                                                                            #\n-# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR #\n-# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,   #\n-# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL    #\n-# THE ABOVE COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER      #\n-# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING    #\n-# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER        #\n-# DEALINGS IN THE SOFTWARE.                                                  #\n-#                                                                            #\n-# Except as contained in this notice, the name(s) of the above copyright     #\n-# holders shall not be used in advertising or otherwise to promote the sale, #\n-# use or other dealings in this Software without prior written               #\n-# authorization.                                                             #\n-##############################################################################\n-\n-# The converted script is written to stdout, so run this script as\n-#    convert_configure configure > configure.cmd\n-#\n-# When the converted script runs, it expects that /tmp dir is\n-# available (so we create it).\n-#\n-# run the result like this:\n-#    .\\configure\n-\n-# Some frequent manual intervention:\n-# a) Some makefiles hardwire SHELL = /bin/sh ==> change to: sh\n-# b) Some makefiles recognize that exe files terminate on .exe\n-#    You need to give this script -no-zexe option...\n-\n-shift, $no_zexe = 1 if @ARGV and $ARGV[0] eq '-no-zexe';\n-\n-mkdir '/tmp', 0777 unless -d '/tmp';\n-\n-print <<EOF;\n-extproc sh\n-\n-EOF\n-\n-print <<EOF unless $no_zexe;\n-# Make sensible defaults:\n-CC=\"gcc -Zexe -Zmt\"\n-export CC\n-CXX=\"gcc -Zexe -Zmt\"\n-export CXX\n-#GCCOPT=\"$GCCOPT -Zexe\"\n-#export GCCOPT\n-EOF\n-\n-print <<EOF;\n-CONFIG_SHELL=sh\n-export CONFIG_SHELL\n-\n-# Optimization (GNU make 3.74 cannot be loaded :-():\n-emxload -m 30 sh.exe ls.exe tr.exe id.exe sed.exe # make.exe \n-emxload -m 30 grep.exe egrep.exe fgrep.exe cat.exe rm.exe mv.exe cp.exe\n-emxload -m 30 uniq.exe basename.exe sort.exe awk.exe echo.exe\n-\n-\n-EOF\n-\n-$checking_path = 0;\n-\n-while (<>) {\n-  if (/for\\s+(\\w+)\\s+in\\s*\\$(PATH|ac_dummy)\\s*;/) {\n-    $checking_path = 1;\n-    $varname = $1;\n-    $subst= <<EOS\n-$varname=\"`echo -E \\\\\"\\$$varname\\\\\" | tr \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ / `\"\n-EOS\n-  } \n-  if (/if\\s+test\\s+-z\\s+\\\"\\$INSTALL\\\"/) {\n-    $checking_install = 1;\n-  } \n-  $checking_install = $checking_path = 0 if /^\\s*done\\s*$/;\n-  # We want to create an extra line like this one:\n-#   ac_dir=\"`echo -E \\\"$ac_dir\\\" | tr \\\\\\\\\\\\\\\\ / `\"\n-  s{^((\\s*)if\\s+test)\\s*-f\\s*(\\$$varname/\\S+)\\s*;}\n-   {$2$subst$1 -f $3 -o -f $3.exe ;}\n-      if $checking_path;\t# Checking for executables\n-  # change |/usr/sbin/*| to |/usr/sbin/*|?:[\\\\/]os2[\\\\/]install[\\\\/]*|\n-  # in the list of things to skip (with both cases)\n-  s{\\Q|/usr/sbin/*|}\n-   {|/usr/sbin/*|?:[\\\\\\\\/]os2[\\\\\\\\/]install[\\\\\\\\/]*|?:[\\\\\\\\/]OS2[\\\\\\\\/]INSTALL[\\\\\\\\/]*|}\n-      if $checking_install;\t# Do not accept d:/os2/install/install.exe\n-  s/^(host|build)=NONE$/$1=x86-emx-os2/;\t# Make default host/build\n-  s/\"\\$\\{IFS}:\"$/\"\\${IFS};\"/;\t# Fix IFS line\n-  s/\\bIFS=\\\":\\\"$/IFS=\";\"/;\t# Fix another IFS line\n-  s/\\btest\\s+-s\\s+conftest\\b/test -f conftest/g; # Fix exe test\n-  # This one is needed for curses:\n-  s/^\\s*host=`.*\\$ac_config_sub \\$host_alias`/$&\\nif test -z \"\\$host\"; then host=\\$host_alias; fi/;\n-  s,/bin/sh(?![/\\w]),sh,g;\n-  s,^(\\s*/usr/sbin/sendmail\\s*)\\\\$,$1 \"`whence sendmail | tr '\\\\\\\\\\\\\\\\' / `\" \\\\,;\n-  print;\n-}\n-\n-__END__\n-\n-Changes:\t98/11 : support check for executables in ncurses.\n-\t\t99/2  : support INSTALL, \n-\t\t\tnew IFS=':' style\n-\t\t99/11 : find sendmail\n-\t\t00/01 : export CONFIG_SHELL\n-\t\t00/10 : new syntax for host=`...` line\ndiff --git a/dist.mk b/dist.mk\nindex 4e711ef8f..6bfdbd5ec 100644\n--- a/dist.mk\n+++ b/dist.mk\n@@ -26,7 +26,7 @@\n # use or other dealings in this Software without prior written               #\n # authorization.                                                             #\n ##############################################################################\n-# $Id: dist.mk,v 1.1351 2020/05/23 09:35:39 tom Exp $\n+# $Id: dist.mk,v 1.1354 2020/05/31 18:56:59 tom Exp $\n # Makefile for creating ncurses distributions.\n #\n # This only needs to be used directly as a makefile by developers, but\n@@ -38,7 +38,7 @@ SHELL = /bin/sh\n # These define the major/minor/patch versions of ncurses.\n NCURSES_MAJOR = 6\n NCURSES_MINOR = 2\n-NCURSES_PATCH = 20200523\n+NCURSES_PATCH = 20200531\n \n # We don't append the patch to the version, since this only applies to releases\n VERSION = $(NCURSES_MAJOR).$(NCURSES_MINOR)\ndiff --git a/include/MKterm.h.awk.in b/include/MKterm.h.awk.in\nindex ee4e2b48d..3c7eb72c1 100644\n--- a/include/MKterm.h.awk.in\n+++ b/include/MKterm.h.awk.in\n@@ -60,7 +60,7 @@ BEGIN {\n \tprint  \"/*    and: Thomas E. Dickey                        1995-on                  */\"\n \tprint  \"/****************************************************************************/\"\n \tprint  \"\"\n-\tprint  \"/* $Id: MKterm.h.awk.in,v 1.74 2020/02/02 23:34:34 tom Exp $ */\"\n+\tprint  \"/* $Id: MKterm.h.awk.in,v 1.76 2020/05/30 19:24:03 tom Exp $ */\"\n \tprint  \"\"\n \tprint  \"/*\"\n \tprint  \"**\tterm.h -- Definition of struct term\"\n@@ -298,6 +298,7 @@ END {\n \tprint  \"extern NCURSES_EXPORT(int) _nc_read_termtype (TERMTYPE2 *, char *, int);\"\n \tprint  \"extern NCURSES_EXPORT(char *) _nc_first_name (const char *const);\"\n \tprint  \"extern NCURSES_EXPORT(int) _nc_name_match (const char *const, const char *const, const char *const);\"\n+\tprint  \"extern NCURSES_EXPORT(char *) _nc_tiparm(int, const char *, ...);\"\n \tprint  \"\"\n \tprint  \"#endif /* NCURSES_INTERNALS */\"\n \tprint  \"\"\n@@ -330,7 +331,6 @@ END {\n \tprint  \"extern NCURSES_EXPORT(char *) tparm (const char *, ...);\t/* special */\"\n \tprint  \"#else\"\n \tprint  \"extern NCURSES_EXPORT(char *) tparm (const char *, long,long,long,long,long,long,long,long,long);\t/* special */\"\n-\tprint  \"extern NCURSES_EXPORT(char *) tparm_varargs (const char *, ...);\t/* special */\"\n \tprint  \"#endif\"\n \tprint  \"\"\n \tprint  \"extern NCURSES_EXPORT(char *) tiparm (const char *, ...);\t\t/* special */\"\n@@ -361,7 +361,6 @@ END {\n \tprint  \"extern NCURSES_EXPORT(char *)  NCURSES_SP_NAME(tparm) (SCREEN*, const char *, ...);\t/* special */\"\n \tprint  \"#else\"\n \tprint  \"extern NCURSES_EXPORT(char *)  NCURSES_SP_NAME(tparm) (SCREEN*, const char *, long,long,long,long,long,long,long,long,long);\t/* special */\"\n-\tprint  \"extern NCURSES_EXPORT(char *)  NCURSES_SP_NAME(tparm_varargs) (SCREEN*, const char *, ...);\t/* special */\"\n \tprint  \"#endif\"\n \tprint  \"\"\n \tprint  \"/* termcap database emulation (XPG4 uses const only for 2nd param of tgetent) */\"\ndiff --git a/include/curses.h.in b/include/curses.h.in\nindex 2cb3224b3..db07cb53d 100644\n--- a/include/curses.h.in\n+++ b/include/curses.h.in\n@@ -33,7 +33,7 @@\n  *     and: Thomas E. Dickey                        1996-on                 *\n  ****************************************************************************/\n \n-/* $Id: curses.h.in,v 1.266 2020/02/08 10:51:53 tom Exp $ */\n+/* $Id: curses.h.in,v 1.267 2020/05/30 19:23:28 tom Exp $ */\n \n #ifndef __NCURSES_H\n #define __NCURSES_H\n@@ -895,7 +895,6 @@ extern NCURSES_EXPORT(int) putp (const char *);\t\t\t\t/* implemented */\n extern NCURSES_EXPORT(char *) tparm (const char *, ...);\t\t/* special */\n #else\n extern NCURSES_EXPORT(char *) tparm (const char *, NCURSES_TPARM_ARG,NCURSES_TPARM_ARG,NCURSES_TPARM_ARG,NCURSES_TPARM_ARG,NCURSES_TPARM_ARG,NCURSES_TPARM_ARG,NCURSES_TPARM_ARG,NCURSES_TPARM_ARG,NCURSES_TPARM_ARG);\t/* special */\n-extern NCURSES_EXPORT(char *) tparm_varargs (const char *, ...);\t/* special */\n #endif\n \n extern NCURSES_EXPORT(char *) tiparm (const char *, ...);\t\t/* special */\ndiff --git a/include/nc_tparm.h b/include/nc_tparm.h\nindex 61570959c..943d94760 100644\n--- a/include/nc_tparm.h\n+++ b/include/nc_tparm.h\n@@ -31,7 +31,7 @@\n  *  Author: Thomas E. Dickey                        2006                    *\n  ****************************************************************************/\n \n-/* $Id: nc_tparm.h,v 1.10 2020/02/02 23:34:34 tom Exp $ */\n+/* $Id: nc_tparm.h,v 1.11 2020/05/27 23:33:31 tom Exp $ */\n \n #ifndef NC_TPARM_included\n #define NC_TPARM_included 1\n@@ -77,4 +77,16 @@\n #define TPARM_0(a) TPARM_1(a,0)\n #endif\n \n+#ifdef NCURSES_INTERNALS\n+#define TIPARM_1(s,a) _nc_tiparm(1,s,a)\n+#define TIPARM_2(s,a,b) _nc_tiparm(2,s,a,b)\n+#define TIPARM_3(s,a,b,c) _nc_tiparm(3,s,a,b,c)\n+#define TIPARM_4(s,a,b,c,d) _nc_tiparm(4,s,a,b,c,d)\n+#define TIPARM_5(s,a,b,c,d,e) _nc_tiparm(5,s,a,b,c,d,e)\n+#define TIPARM_6(s,a,b,c,d,e,f) _nc_tiparm(6,s,a,b,c,d,e,f)\n+#define TIPARM_7(s,a,b,c,d,e,f,g) _nc_tiparm(7,s,a,b,c,d,e,f,g)\n+#define TIPARM_8(s,a,b,c,d,e,f,g,h) _nc_tiparm(8,s,a,b,c,d,e,f,g,h)\n+#define TIPARM_9(s,a,b,c,d,e,f,g,h,i) _nc_tiparm(9,s,a,b,c,d,e,f,g,h,i)\n+#endif\n+\n #endif /* NC_TPARM_included */\ndiff --git a/misc/terminfo.src b/misc/terminfo.src\nindex a68de86ea..21fdd2e91 100644\n--- a/misc/terminfo.src\n+++ b/misc/terminfo.src\n@@ -6,8 +6,8 @@\n # Report bugs and new terminal descriptions to\n #\tbug-ncurses@gnu.org\n #\n-#\t$Revision: 1.800 $\n-#\t$Date: 2020/05/16 16:59:20 $\n+#\t$Revision: 1.802 $\n+#\t$Date: 2020/05/30 21:37:01 $\n #\n # The original header is preserved below for reference.  It is noted that there\n # is a \"newer\" version which differs in some cosmetic details (but actually\n@@ -4447,7 +4447,7 @@ xterm-old|antique xterm version,\n # initially part of the xterm sources (in XFree86).  But \"xterm\" continued to\n # grow, while \"xterm-mono\" had none of the newer features.  Additionally,\n # inheriting from \"xtermm\" runs into several problems, including different\n-# function keys as well as the fact that the mouse support is not compatible. \n+# function keys as well as the fact that the mouse support is not compatible.\n # This entry restores the original intent, intentionally not an alias to\n # simplify maintenance -TD\n xterm-mono|monochrome xterm,\n@@ -5781,10 +5781,13 @@ kvt|KDE terminal,\n #    (also overline, which is too rarely used to provide as an extension)\n #\n # Updated for konsole 17.12.0 (late 2017):\n+#\n+# Re-enable \"bel\", since it is latent in the source-code even though KDE config\n+# often hides the feature (2020/5/30)\n konsole-base|KDE console window,\n \tbce, km@, npc, XT,\n \tncv@,\n-\tbel@, blink=\\E[5m, civis=\\E[?25l, cnorm=\\E[?25h, dim=\\E[2m,\n+\tblink=\\E[5m, civis=\\E[?25l, cnorm=\\E[?25h, dim=\\E[2m,\n \tech=\\E[%p1%dX, flash=\\E[?5h$<100/>\\E[?5l,\n \thpa=\\E[%i%p1%dG, invis=\\E[8m, kbs=^?, kdch1=\\E[3~,\n \tkend=\\E[4~, kf1@, kf10@, kf11@, kf12@, kf13@, kf14@, kf15@, kf16@,\n@@ -20911,6 +20914,17 @@ linux-m2|Linux Minitel 2 \"like\" Couleurs (Vert/Blanc/Noir+Bleu),\n \t       \\E]PFFFFFFF\\E[;37m,\n \tuse=linux-m1,\n \n+# From: Alexandre Montaron, 27 May 2020\n+linux-s|Linux Console with added status line at bottom,\n+\ths,\n+\tclear=\\E[255;255H\\E[A\\E[1J\\E[H, csr@,\n+\tdsl=\\E7\\E[255H\\E[K\\E8, ed@, fsl=\\E8,\n+\tiprog=\\sbash\\s-c\\s'echo\\s-ne\\s\"\\E[?6l\\E[255H\\E[A\\E[6n\"\\s;\n+\t      \\sread\\s-d\\sR\\sTMP\\s;\\sLINES=`echo\\s$TMP\\s|\\scut\\s-f1\n+\t      \\s-d\\s\";\"\\s|\\scut\\s-f2\\s-d\\s\"[\"`\\s;\\sstty\\srows\\s$LINE\n+\t      S\\s;\\secho\\s-ne\\s\"\\E[;\"$LINES\"r\\E[J\"',\n+\trs1=\\E]R, tsl=\\E7\\E[255;%p1%dH, .rc@, .sc@, use=linux,\n+\n # Screen entries counterpart :\n \n screen.linux-m1|Linux m1 specific for screen,\n@@ -26557,4 +26571,8 @@ v3220|LANPAR Vision II model 3220/3221/3222,\n # 2020-05-16\n #\t+ update notes on vscode / xterm.js -TD\n #\n+# 2020-05-30\n+#\t+ re-enable \"bel\" in konsole-base (report by Nia Huang)\n+#\t+ add linux-s entry (patch by Alexandre Montaron).\n+#\n ######## SHANTIH!  SHANTIH!  SHANTIH!\ndiff --git a/ncurses/base/lib_color.c b/ncurses/base/lib_color.c\nindex 376ad4f60..2343219e0 100644\n--- a/ncurses/base/lib_color.c\n+++ b/ncurses/base/lib_color.c\n@@ -49,7 +49,7 @@\n #define CUR SP_TERMTYPE\n #endif\n \n-MODULE_ID(\"$Id: lib_color.c,v 1.143 2020/02/02 23:34:34 tom Exp $\")\n+MODULE_ID(\"$Id: lib_color.c,v 1.145 2020/05/27 23:55:32 tom Exp $\")\n \n #ifdef USE_TERM_DRIVER\n #define CanChange      InfoOf(SP_PARM).canchange\n@@ -140,7 +140,6 @@ NCURSES_EXPORT_VAR(const color_t*) _nc_hls_palette = hls_palette;\n #endif\n \n /* *INDENT-ON* */\n-\n #if NCURSES_EXT_FUNCS\n /*\n  * These are called from _nc_do_color(), which in turn is called from\n@@ -190,12 +189,12 @@ set_background_color(NCURSES_SP_DCLx int bg, NCURSES_SP_OUTC outc)\n     if (set_a_background) {\n \tTPUTS_TRACE(\"set_a_background\");\n \tNCURSES_SP_NAME(tputs) (NCURSES_SP_ARGx\n-\t\t\t\tTPARM_1(set_a_background, bg),\n+\t\t\t\tTIPARM_1(set_a_background, bg),\n \t\t\t\t1, outc);\n     } else {\n \tTPUTS_TRACE(\"set_background\");\n \tNCURSES_SP_NAME(tputs) (NCURSES_SP_ARGx\n-\t\t\t\tTPARM_1(set_background, toggled_colors(bg)),\n+\t\t\t\tTIPARM_1(set_background, toggled_colors(bg)),\n \t\t\t\t1, outc);\n     }\n #endif\n@@ -210,12 +209,12 @@ set_foreground_color(NCURSES_SP_DCLx int fg, NCURSES_SP_OUTC outc)\n     if (set_a_foreground) {\n \tTPUTS_TRACE(\"set_a_foreground\");\n \tNCURSES_SP_NAME(tputs) (NCURSES_SP_ARGx\n-\t\t\t\tTPARM_1(set_a_foreground, fg),\n+\t\t\t\tTIPARM_1(set_a_foreground, fg),\n \t\t\t\t1, outc);\n     } else {\n \tTPUTS_TRACE(\"set_foreground\");\n \tNCURSES_SP_NAME(tputs) (NCURSES_SP_ARGx\n-\t\t\t\tTPARM_1(set_foreground, toggled_colors(fg)),\n+\t\t\t\tTIPARM_1(set_foreground, toggled_colors(fg)),\n \t\t\t\t1, outc);\n     }\n #endif\n@@ -672,14 +671,14 @@ _nc_init_pair(SCREEN *sp, int pair, int f, int b)\n \t    (int) tp[b].red, (int) tp[b].green, (int) tp[b].blue));\n \n \tNCURSES_PUTP2(\"initialize_pair\",\n-\t\t      TPARM_7(initialize_pair,\n-\t\t\t      pair,\n-\t\t\t      (int) tp[f].red,\n-\t\t\t      (int) tp[f].green,\n-\t\t\t      (int) tp[f].blue,\n-\t\t\t      (int) tp[b].red,\n-\t\t\t      (int) tp[b].green,\n-\t\t\t      (int) tp[b].blue));\n+\t\t      TIPARM_7(initialize_pair,\n+\t\t\t       pair,\n+\t\t\t       (int) tp[f].red,\n+\t\t\t       (int) tp[f].green,\n+\t\t\t       (int) tp[f].blue,\n+\t\t\t       (int) tp[b].red,\n+\t\t\t       (int) tp[b].green,\n+\t\t\t       (int) tp[b].blue));\n     }\n #endif\n \n@@ -746,7 +745,7 @@ _nc_init_color(SCREEN *sp, int color, int r, int g, int b)\n \tCallDriver_4(sp, td_initcolor, color, r, g, b);\n #else\n \tNCURSES_PUTP2(\"initialize_color\",\n-\t\t      TPARM_4(initialize_color, color, r, g, b));\n+\t\t      TIPARM_4(initialize_color, color, r, g, b));\n #endif\n \tsp->_color_defs = max(color + 1, sp->_color_defs);\n \n@@ -1004,7 +1003,7 @@ NCURSES_SP_NAME(_nc_do_color) (NCURSES_SP_DCLx\n \tif (set_color_pair) {\n \t    TPUTS_TRACE(\"set_color_pair\");\n \t    NCURSES_SP_NAME(tputs) (NCURSES_SP_ARGx\n-\t\t\t\t    TPARM_1(set_color_pair, pair),\n+\t\t\t\t    TIPARM_1(set_color_pair, pair),\n \t\t\t\t    1, outc);\n \t    return;\n \t} else if (SP_PARM != 0) {\ndiff --git a/ncurses/base/lib_mouse.c b/ncurses/base/lib_mouse.c\nindex 887f1ab5c..6422b52e0 100644\n--- a/ncurses/base/lib_mouse.c\n+++ b/ncurses/base/lib_mouse.c\n@@ -85,7 +85,7 @@\n #define CUR SP_TERMTYPE\n #endif\n \n-MODULE_ID(\"$Id: lib_mouse.c,v 1.188 2020/05/23 23:35:35 tom Exp $\")\n+MODULE_ID(\"$Id: lib_mouse.c,v 1.190 2020/05/27 23:55:32 tom Exp $\")\n \n #include <tic.h>\n \n@@ -436,7 +436,7 @@ enable_xterm_mouse(SCREEN *sp, int enable)\n #if USE_EMX_MOUSE\n     sp->_emxmouse_activated = enable;\n #else\n-    NCURSES_PUTP2(\"xterm-mouse\", TPARM_1(sp->_mouse_xtermcap, enable));\n+    NCURSES_PUTP2(\"xterm-mouse\", TIPARM_1(sp->_mouse_xtermcap, enable));\n #endif\n     sp->_mouse_active = enable;\n }\ndiff --git a/ncurses/base/lib_screen.c b/ncurses/base/lib_screen.c\nindex d306e1e86..6afba6611 100644\n--- a/ncurses/base/lib_screen.c\n+++ b/ncurses/base/lib_screen.c\n@@ -42,7 +42,7 @@\n #define CUR SP_TERMTYPE\n #endif\n \n-MODULE_ID(\"$Id: lib_screen.c,v 1.99 2020/05/23 19:12:01 tom Exp $\")\n+MODULE_ID(\"$Id: lib_screen.c,v 1.100 2020/05/25 22:48:41 tom Exp $\")\n \n #define MAX_SIZE 0x3fff\t\t/* 16k is big enough for a window or pad */\n \n@@ -58,7 +58,7 @@ MODULE_ID(\"$Id: lib_screen.c,v 1.99 2020/05/23 19:12:01 tom Exp $\")\n #define ARG_SLIMIT(name)\t/* nothing */\n #endif\n \n-#define CUR_SLIMIT _nc_SLIMIT(limit - (target - base))\n+#define CUR_SLIMIT _nc_SLIMIT(limit - (size_t) (target - base))\n #define TOP_SLIMIT _nc_SLIMIT(sizeof(buffer))\n \n /*\ndiff --git a/ncurses/tinfo/captoinfo.c b/ncurses/tinfo/captoinfo.c\nindex 8b3b83d18..9362105ab 100644\n--- a/ncurses/tinfo/captoinfo.c\n+++ b/ncurses/tinfo/captoinfo.c\n@@ -98,7 +98,7 @@\n #include <ctype.h>\n #include <tic.h>\n \n-MODULE_ID(\"$Id: captoinfo.c,v 1.98 2020/02/02 23:34:34 tom Exp $\")\n+MODULE_ID(\"$Id: captoinfo.c,v 1.99 2020/05/25 21:28:29 tom Exp $\")\n \n #if 0\n #define DEBUG_THIS(p) DEBUG(9, p)\n@@ -216,12 +216,15 @@ cvtchar(register const char *sp)\n \t}\n \tbreak;\n     case '^':\n+\tlen = 2;\n \tc = UChar(*++sp);\n-\tif (c == '?')\n+\tif (c == '?') {\n \t    c = 127;\n-\telse\n+\t} else if (c == '\\0') {\n+\t    len = 1;\n+\t} else {\n \t    c &= 0x1f;\n-\tlen = 2;\n+\t}\n \tbreak;\n     default:\n \tc = UChar(*sp);\ndiff --git a/ncurses/tinfo/lib_print.c b/ncurses/tinfo/lib_print.c\nindex eb9214925..25e45170b 100644\n--- a/ncurses/tinfo/lib_print.c\n+++ b/ncurses/tinfo/lib_print.c\n@@ -40,7 +40,7 @@\n #define CUR SP_TERMTYPE\n #endif\n \n-MODULE_ID(\"$Id: lib_print.c,v 1.25 2020/02/02 23:34:34 tom Exp $\")\n+MODULE_ID(\"$Id: lib_print.c,v 1.27 2020/05/27 23:55:56 tom Exp $\")\n \n NCURSES_EXPORT(int)\n NCURSES_SP_NAME(mcprint) (NCURSES_SP_DCLx char *data, int len)\n@@ -60,7 +60,7 @@ NCURSES_SP_NAME(mcprint) (NCURSES_SP_DCLx char *data, int len)\n     }\n \n     if (prtr_non) {\n-\tswitchon = TPARM_1(prtr_non, len);\n+\tswitchon = TIPARM_1(prtr_non, len);\n \tonsize = strlen(switchon);\n \toffsize = 0;\n     } else {\ndiff --git a/ncurses/tinfo/lib_tgoto.c b/ncurses/tinfo/lib_tgoto.c\nindex 8e240856f..9cf5e100c 100644\n--- a/ncurses/tinfo/lib_tgoto.c\n+++ b/ncurses/tinfo/lib_tgoto.c\n@@ -36,7 +36,7 @@\n #include <ctype.h>\n #include <termcap.h>\n \n-MODULE_ID(\"$Id: lib_tgoto.c,v 1.19 2020/02/02 23:34:34 tom Exp $\")\n+MODULE_ID(\"$Id: lib_tgoto.c,v 1.21 2020/05/27 23:55:56 tom Exp $\")\n \n #if !PURE_TERMINFO\n static bool\n@@ -207,6 +207,6 @@ tgoto(const char *string, int x, int y)\n \tresult = tgoto_internal(string, x, y);\n     else\n #endif\n-\tresult = TPARM_2(string, y, x);\n+\tresult = TIPARM_2(string, y, x);\n     returnPtr(result);\n }\ndiff --git a/ncurses/tinfo/lib_tparm.c b/ncurses/tinfo/lib_tparm.c\nindex 400cd3199..00380151f 100644\n--- a/ncurses/tinfo/lib_tparm.c\n+++ b/ncurses/tinfo/lib_tparm.c\n@@ -38,12 +38,22 @@\n  *\n  */\n \n+#define entry _ncu_entry\n+#define ENTRY _ncu_ENTRY\n+\n #include <curses.priv.h>\n \n+#undef entry\n+#undef ENTRY\n+\n+#if HAVE_TSEARCH\n+#include <search.h>\n+#endif\n+\n #include <ctype.h>\n #include <tic.h>\n \n-MODULE_ID(\"$Id: lib_tparm.c,v 1.108 2020/02/02 23:34:34 tom Exp $\")\n+MODULE_ID(\"$Id: lib_tparm.c,v 1.126 2020/05/31 00:02:03 tom Exp $\")\n \n /*\n  *\tchar *\n@@ -110,17 +120,81 @@ NCURSES_EXPORT_VAR(int) _nc_tparm_err = 0;\n #define TPS(var) _nc_prescreen.tparm_state.var\n #define popcount _nc_popcount\t/* workaround for NetBSD 6.0 defect */\n \n+#define isUPPER(c) ((c) >= 'A' && (c) <= 'Z')\n+#define isLOWER(c) ((c) >= 'a' && (c) <= 'z')\n+#define tc_BUMP()  if (level < 0 && number < 2) number++\n+\n+typedef struct {\n+    const char *format;\t\t/* format-string can be used as cache-key */\n+    int tparm_type;\t\t/* bit-set for each string-parameter */\n+    int num_actual;\n+    int num_parsed;\n+    int num_popped;\n+    TPARM_ARG param[NUM_PARM];\n+    char *p_is_s[NUM_PARM];\n+} TPARM_DATA;\n+\n+#if HAVE_TSEARCH\n+static void *cached_tparm;\n+static int count_tparm;\n+#if NO_LEAKS\n+static int which_tparm;\n+static TPARM_DATA **delete_tparm;\n+#endif\n+#endif /* HAVE_TSEARCH */\n+\n+static char dummy[] = \"\";\t/* avoid const-cast */\n+\n+#if HAVE_TSEARCH\n+static int\n+cmp_format(const void *p, const void *q)\n+{\n+    const char *a = *(char *const *) p;\n+    const char *b = *(char *const *) q;\n+    return strcmp(a, b);\n+}\n+#endif\n+\n #if NO_LEAKS\n+#if HAVE_TSEARCH\n+static void\n+visit_nodes(const void *nodep, const VISIT which, const int depth)\n+{\n+    (void) depth;\n+    if (which == preorder || which == leaf) {\n+\tdelete_tparm[which_tparm] = *(TPARM_DATA **) nodep;\n+\twhich_tparm++;\n+    }\n+}\n+#endif\n+\n NCURSES_EXPORT(void)\n _nc_free_tparm(void)\n {\n-    if (TPS(out_buff) != 0) {\n-\tFreeAndNull(TPS(out_buff));\n-\tTPS(out_size) = 0;\n-\tTPS(out_used) = 0;\n-\tFreeAndNull(TPS(fmt_buff));\n-\tTPS(fmt_size) = 0;\n+#if HAVE_TSEARCH\n+    if (count_tparm != 0) {\n+\tdelete_tparm = typeMalloc(TPARM_DATA *, count_tparm);\n+\twhich_tparm = 0;\n+\ttwalk(cached_tparm, visit_nodes);\n+\tfor (which_tparm = 0; which_tparm < count_tparm; ++which_tparm) {\n+\t    TPARM_DATA *ptr = delete_tparm[which_tparm];\n+\t    tdelete(ptr, &cached_tparm, cmp_format);\n+\t    free((char *) ptr->format);\n+\t    free(ptr);\n+\t}\n+\twhich_tparm = 0;\n+\ttwalk(cached_tparm, visit_nodes);\n+\tFreeAndNull(delete_tparm);\n+\tcount_tparm = 0;\n+\twhich_tparm = 0;\n     }\n+#endif\n+    FreeAndNull(TPS(out_buff));\n+    TPS(out_size) = 0;\n+    TPS(out_used) = 0;\n+\n+    FreeAndNull(TPS(fmt_buff));\n+    TPS(fmt_size) = 0;\n }\n #endif\n \n@@ -137,10 +211,7 @@ get_space(size_t need)\n static NCURSES_INLINE void\n save_text(const char *fmt, const char *s, int len)\n {\n-    size_t s_len = strlen(s);\n-    if (len > (int) s_len)\n-\ts_len = (size_t) len;\n-\n+    size_t s_len = (size_t) len + strlen(s) + strlen(fmt);\n     get_space(s_len + 1);\n \n     _nc_SPRINTF(TPS(out_buff) + TPS(out_used),\n@@ -152,10 +223,8 @@ save_text(const char *fmt, const char *s, int len)\n static NCURSES_INLINE void\n save_number(const char *fmt, int number, int len)\n {\n-    if (len < 30)\n-\tlen = 30;\t\t/* actually log10(MAX_INT)+1 */\n-\n-    get_space((size_t) len + 1);\n+    size_t s_len = (size_t) len + 30 + strlen(fmt);\n+    get_space(s_len + 1);\n \n     _nc_SPRINTF(TPS(out_buff) + TPS(out_used),\n \t\t_nc_SLIMIT(TPS(out_size) - TPS(out_used))\n@@ -216,7 +285,6 @@ spush(char *x)\n static NCURSES_INLINE char *\n spop(void)\n {\n-    static char dummy[] = \"\";\t/* avoid const-cast */\n     char *result = dummy;\n     if (TPS(stack_ptr) > 0) {\n \tTPS(stack_ptr)--;\n@@ -325,10 +393,6 @@ parse_format(const char *s, char *format, int *len)\n     return s;\n }\n \n-#define isUPPER(c) ((c) >= 'A' && (c) <= 'Z')\n-#define isLOWER(c) ((c) >= 'a' && (c) <= 'z')\n-#define tc_BUMP()  if (level < 0 && number < 2) number++\n-\n /*\n  * Analyze the string to see how many parameters we need from the varargs list,\n  * and what their types are.  We will only accept string parameters if they\n@@ -350,7 +414,6 @@ _nc_tparm_analyze(const char *string, char *p_is_s[NUM_PARM], int *popcount)\n     int number = 0;\n     int level = -1;\n     const char *cp = string;\n-    static char dummy[] = \"\";\n \n     if (cp == 0)\n \treturn 0;\n@@ -469,106 +532,179 @@ _nc_tparm_analyze(const char *string, char *p_is_s[NUM_PARM], int *popcount)\n     return number;\n }\n \n-static NCURSES_INLINE char *\n-tparam_internal(int use_TPARM_ARG, const char *string, va_list ap)\n+/*\n+ * Analyze the capability string, finding the number of parameters and their\n+ * types.\n+ *\n+ * TODO: cache the result so that this is done once per capability per term.\n+ */\n+static int\n+tparm_setup(const char *string, TPARM_DATA * result)\n {\n-    char *p_is_s[NUM_PARM];\n-    TPARM_ARG param[NUM_PARM];\n-    int popcount = 0;\n-    int number;\n-    int num_args;\n-    int len;\n-    int level;\n-    int x, y;\n-    int i;\n-    const char *cp = string;\n-    size_t len2;\n-    bool termcap_hack;\n-    bool incremented_two;\n+    int rc = OK;\n+\n+    TPS(out_used) = 0;\n+    memset(result, 0, sizeof(*result));\n \n-    if (cp == NULL) {\n+    if (string == NULL) {\n \tTR(TRACE_CALLS, (\"%s: format is null\", TPS(tname)));\n-\treturn NULL;\n-    }\n+\trc = ERR;\n+    } else {\n+#if HAVE_TSEARCH\n+\tTPARM_DATA *fs;\n+\tvoid *ft;\n+\n+\tresult->format = string;\n+\tif ((ft = tfind(result, &cached_tparm, cmp_format)) != 0) {\n+\t    fs = *(TPARM_DATA **) ft;\n+\t    *result = *fs;\n+\t} else\n+#endif\n+\t{\n+\t    /*\n+\t     * Find the highest parameter-number referred to in the format\n+\t     * string.  Use this value to limit the number of arguments copied\n+\t     * from the variable-length argument list.\n+\t     */\n+\t    result->num_parsed = _nc_tparm_analyze(string,\n+\t\t\t\t\t\t   result->p_is_s,\n+\t\t\t\t\t\t   &(result->num_popped));\n+\t    if (TPS(fmt_buff) == 0) {\n+\t\tTR(TRACE_CALLS, (\"%s: error in analysis\", TPS(tname)));\n+\t\trc = ERR;\n+\t    } else {\n+\t\tint n;\n \n-    TPS(out_used) = 0;\n-    len2 = strlen(cp);\n-\n-    /*\n-     * Find the highest parameter-number referred to in the format string.\n-     * Use this value to limit the number of arguments copied from the\n-     * variable-length argument list.\n-     */\n-    number = _nc_tparm_analyze(cp, p_is_s, &popcount);\n-    if (TPS(fmt_buff) == 0) {\n-\tTR(TRACE_CALLS, (\"%s: error in analysis\", TPS(tname)));\n-\treturn NULL;\n+\t\tif (result->num_parsed > NUM_PARM)\n+\t\t    result->num_parsed = NUM_PARM;\n+\t\tif (result->num_popped > NUM_PARM)\n+\t\t    result->num_popped = NUM_PARM;\n+\t\tresult->num_actual = max(result->num_popped, result->num_parsed);\n+\n+\t\tfor (n = 0; n < result->num_actual; ++n) {\n+\t\t    if (result->p_is_s[n])\n+\t\t\tresult->tparm_type |= (1 << n);\n+\t\t}\n+#if HAVE_TSEARCH\n+\t\tif ((fs = typeCalloc(TPARM_DATA, 1)) != 0) {\n+\t\t    *fs = *result;\n+\t\t    if ((fs->format = strdup(string)) != 0) {\n+\t\t\tif ((ft = tsearch(fs, &cached_tparm, cmp_format)) != 0) {\n+\t\t\t    ++count_tparm;\n+\t\t\t} else {\n+\t\t\t    rc = ERR;\n+\t\t\t}\n+\t\t    } else {\n+\t\t\trc = ERR;\n+\t\t    }\n+\t\t} else {\n+\t\t    rc = ERR;\n+\t\t}\n+#endif\n+\t    }\n+\t}\n     }\n \n-    incremented_two = FALSE;\n+    return rc;\n+}\n \n-    if (number > NUM_PARM)\n-\tnumber = NUM_PARM;\n-    if (popcount > NUM_PARM)\n-\tpopcount = NUM_PARM;\n-    num_args = max(popcount, number);\n+/*\n+ * A few caps (such as plab_norm) have string-valued parms.  We'll have to\n+ * assume that the caller knows the difference, since a char* and an int may\n+ * not be the same size on the stack.  The normal prototype for tparm uses 9\n+ * long's, which is consistent with our va_arg() usage.\n+ */\n+static void\n+tparm_copy_valist(TPARM_DATA * data, int use_TPARM_ARG, va_list ap)\n+{\n+    int i;\n \n-    for (i = 0; i < num_args; i++) {\n-\t/*\n-\t * A few caps (such as plab_norm) have string-valued parms.\n-\t * We'll have to assume that the caller knows the difference, since\n-\t * a char* and an int may not be the same size on the stack.  The\n-\t * normal prototype for this uses 9 long's, which is consistent with\n-\t * our va_arg() usage.\n-\t */\n-\tif (p_is_s[i] != 0) {\n-\t    p_is_s[i] = va_arg(ap, char *);\n-\t    param[i] = 0;\n+    for (i = 0; i < data->num_actual; i++) {\n+\tif (data->p_is_s[i] != 0) {\n+\t    char *value = va_arg(ap, char *);\n+\t    if (value == 0)\n+\t\tvalue = dummy;\n+\t    data->p_is_s[i] = value;\n+\t    data->param[i] = 0;\n \t} else if (use_TPARM_ARG) {\n-\t    param[i] = va_arg(ap, TPARM_ARG);\n+\t    data->param[i] = va_arg(ap, TPARM_ARG);\n \t} else {\n-\t    param[i] = (TPARM_ARG) va_arg(ap, int);\n+\t    data->param[i] = (TPARM_ARG) va_arg(ap, int);\n \t}\n     }\n+}\n+\n+/*\n+ * This is a termcap compatibility hack.  If there are no explicit pop\n+ * operations in the string, load the stack in such a way that successive pops\n+ * will grab successive parameters.  That will make the expansion of (for\n+ * example) \\E[%d;%dH work correctly in termcap style, which means tparam()\n+ * will expand termcap strings OK.\n+ */\n+static bool\n+tparm_tc_compat(TPARM_DATA * data)\n+{\n+    bool termcap_hack = FALSE;\n \n-    /*\n-     * This is a termcap compatibility hack.  If there are no explicit pop\n-     * operations in the string, load the stack in such a way that\n-     * successive pops will grab successive parameters.  That will make\n-     * the expansion of (for example) \\E[%d;%dH work correctly in termcap\n-     * style, which means tparam() will expand termcap strings OK.\n-     */\n     TPS(stack_ptr) = 0;\n-    termcap_hack = FALSE;\n-    if (popcount == 0) {\n+\n+    if (data->num_popped == 0) {\n+\tint i;\n+\n \ttermcap_hack = TRUE;\n-\tfor (i = number - 1; i >= 0; i--) {\n-\t    if (p_is_s[i])\n-\t\tspush(p_is_s[i]);\n+\tfor (i = data->num_parsed - 1; i >= 0; i--) {\n+\t    if (data->p_is_s[i])\n+\t\tspush(data->p_is_s[i]);\n \t    else\n-\t\tnpush((int) param[i]);\n+\t\tnpush((int) data->param[i]);\n \t}\n     }\n+    return termcap_hack;\n+}\n+\n #ifdef TRACE\n+static void\n+tparm_trace_call(const char *string, TPARM_DATA * data)\n+{\n     if (USE_TRACEF(TRACE_CALLS)) {\n-\tfor (i = 0; i < num_args; i++) {\n-\t    if (p_is_s[i] != 0) {\n-\t\tsave_text(\", %s\", _nc_visbuf(p_is_s[i]), 0);\n-\t    } else if ((long) param[i] > MAX_OF_TYPE(NCURSES_INT2) ||\n-\t\t       (long) param[i] < 0) {\n+\tint i;\n+\tfor (i = 0; i < data->num_actual; i++) {\n+\t    if (data->p_is_s[i] != 0) {\n+\t\tsave_text(\", %s\", _nc_visbuf(data->p_is_s[i]), 0);\n+\t    } else if ((long) data->param[i] > MAX_OF_TYPE(NCURSES_INT2) ||\n+\t\t       (long) data->param[i] < 0) {\n \t\t_tracef(\"BUG: problem with tparm parameter #%d of %d\",\n-\t\t\ti + 1, num_args);\n+\t\t\ti + 1, data->num_actual);\n \t\tbreak;\n \t    } else {\n-\t\tsave_number(\", %d\", (int) param[i], 0);\n+\t\tsave_number(\", %d\", (int) data->param[i], 0);\n \t    }\n \t}\n-\t_tracef(T_CALLED(\"%s(%s%s)\"), TPS(tname), _nc_visbuf(cp), TPS(out_buff));\n+\t_tracef(T_CALLED(\"%s(%s%s)\"), TPS(tname), _nc_visbuf(string), TPS(out_buff));\n \tTPS(out_used) = 0;\n \t_nc_unlock_global(tracef);\n     }\n+}\n+\n+#else\n+#define tparm_trace_call(string, data)\t/* nothing */\n #endif /* TRACE */\n \n+static NCURSES_INLINE char *\n+tparam_internal(const char *string, TPARM_DATA * data)\n+{\n+    int number;\n+    int len;\n+    int level;\n+    int x, y;\n+    int i;\n+    const char *cp = string;\n+    size_t len2 = strlen(cp);\n+    bool incremented_two = FALSE;\n+    bool termcap_hack = tparm_tc_compat(data);\n+\n+    tparm_trace_call(string, data);\n+\n     while ((cp - string) < (int) len2) {\n \tif (*cp != '%') {\n \t    save_char(UChar(*cp));\n@@ -619,10 +755,10 @@ tparam_internal(int use_TPARM_ARG, const char *string, va_list ap)\n \t\tcp++;\n \t\ti = (UChar(*cp) - '1');\n \t\tif (i >= 0 && i < NUM_PARM) {\n-\t\t    if (p_is_s[i]) {\n-\t\t\tspush(p_is_s[i]);\n+\t\t    if (data->p_is_s[i]) {\n+\t\t\tspush(data->p_is_s[i]);\n \t\t    } else {\n-\t\t\tnpush((int) param[i]);\n+\t\t\tnpush((int) data->param[i]);\n \t\t    }\n \t\t}\n \t\tbreak;\n@@ -751,15 +887,15 @@ tparam_internal(int use_TPARM_ARG, const char *string, va_list ap)\n \t\t */\n \t\tif (!incremented_two) {\n \t\t    incremented_two = TRUE;\n-\t\t    if (p_is_s[0] == 0) {\n-\t\t\tparam[0]++;\n+\t\t    if (data->p_is_s[0] == 0) {\n+\t\t\tdata->param[0]++;\n \t\t\tif (termcap_hack)\n-\t\t\t    TPS(stack)[0].data.num = (int) param[0];\n+\t\t\t    TPS(stack)[0].data.num = (int) data->param[0];\n \t\t    }\n-\t\t    if (p_is_s[1] == 0) {\n-\t\t\tparam[1]++;\n+\t\t    if (data->p_is_s[1] == 0) {\n+\t\t\tdata->param[1]++;\n \t\t\tif (termcap_hack)\n-\t\t\t    TPS(stack)[1].data.num = (int) param[1];\n+\t\t\t    TPS(stack)[1].data.num = (int) data->param[1];\n \t\t    }\n \t\t}\n \t\tbreak;\n@@ -835,56 +971,118 @@ tparam_internal(int use_TPARM_ARG, const char *string, va_list ap)\n }\n \n #if NCURSES_TPARM_VARARGS\n-#define tparm_varargs tparm\n-#else\n-#define tparm_proto tparm\n-#endif\n \n NCURSES_EXPORT(char *)\n-tparm_varargs(const char *string, ...)\n+tparm(const char *string, ...)\n {\n+    TPARM_DATA myData;\n     va_list ap;\n-    char *result;\n+    char *result = NULL;\n \n     _nc_tparm_err = 0;\n-    va_start(ap, string);\n #ifdef TRACE\n     TPS(tname) = \"tparm\";\n #endif /* TRACE */\n-    result = tparam_internal(TRUE, string, ap);\n-    va_end(ap);\n+\n+    if (tparm_setup(string, &myData) == OK) {\n+\n+\tva_start(ap, string);\n+\ttparm_copy_valist(&myData, TRUE, ap);\n+\tva_end(ap);\n+\n+\tresult = tparam_internal(string, &myData);\n+    }\n     return result;\n }\n \n-#if !NCURSES_TPARM_VARARGS\n+#else /* !NCURSES_TPARM_VARARGS */\n+\n NCURSES_EXPORT(char *)\n-tparm_proto(const char *string,\n-\t    TPARM_ARG a1,\n-\t    TPARM_ARG a2,\n-\t    TPARM_ARG a3,\n-\t    TPARM_ARG a4,\n-\t    TPARM_ARG a5,\n-\t    TPARM_ARG a6,\n-\t    TPARM_ARG a7,\n-\t    TPARM_ARG a8,\n-\t    TPARM_ARG a9)\n+tparm(const char *string,\n+      TPARM_ARG a1,\n+      TPARM_ARG a2,\n+      TPARM_ARG a3,\n+      TPARM_ARG a4,\n+      TPARM_ARG a5,\n+      TPARM_ARG a6,\n+      TPARM_ARG a7,\n+      TPARM_ARG a8,\n+      TPARM_ARG a9)\n {\n-    return tparm_varargs(string, a1, a2, a3, a4, a5, a6, a7, a8, a9);\n+    TPARM_DATA myData;\n+    char *result = NULL;\n+\n+    _nc_tparm_err = 0;\n+#ifdef TRACE\n+    TPS(tname) = \"tparm\";\n+#endif /* TRACE */\n+\n+    if (tparm_setup(string, &myData) == OK) {\n+\n+\tmyData.param[0] = a1;\n+\tmyData.param[1] = a2;\n+\tmyData.param[2] = a3;\n+\tmyData.param[3] = a4;\n+\tmyData.param[4] = a5;\n+\tmyData.param[5] = a6;\n+\tmyData.param[6] = a7;\n+\tmyData.param[7] = a8;\n+\tmyData.param[8] = a9;\n+\n+\tresult = tparam_internal(string, &myData);\n+    }\n+    return result;\n }\n+\n #endif /* NCURSES_TPARM_VARARGS */\n \n NCURSES_EXPORT(char *)\n tiparm(const char *string, ...)\n {\n+    TPARM_DATA myData;\n     va_list ap;\n-    char *result;\n+    char *result = NULL;\n \n     _nc_tparm_err = 0;\n-    va_start(ap, string);\n #ifdef TRACE\n     TPS(tname) = \"tiparm\";\n #endif /* TRACE */\n-    result = tparam_internal(FALSE, string, ap);\n-    va_end(ap);\n+\n+    if (tparm_setup(string, &myData) == OK) {\n+\n+\tva_start(ap, string);\n+\ttparm_copy_valist(&myData, FALSE, ap);\n+\tva_end(ap);\n+\n+\tresult = tparam_internal(string, &myData);\n+    }\n+    return result;\n+}\n+\n+/*\n+ * The internal-use flavor ensures that the parameters are numbers, not strings\n+ */\n+NCURSES_EXPORT(char *)\n+_nc_tiparm(int expected, const char *string, ...)\n+{\n+    TPARM_DATA myData;\n+    va_list ap;\n+    char *result = NULL;\n+\n+    _nc_tparm_err = 0;\n+#ifdef TRACE\n+    TPS(tname) = \"_nc_tiparm\";\n+#endif /* TRACE */\n+\n+    if (tparm_setup(string, &myData) == OK\n+\t&& myData.num_actual <= expected\n+\t&& myData.tparm_type == 0) {\n+\n+\tva_start(ap, string);\n+\ttparm_copy_valist(&myData, FALSE, ap);\n+\tva_end(ap);\n+\n+\tresult = tparam_internal(string, &myData);\n+    }\n     return result;\n }\ndiff --git a/ncurses/tinfo/tinfo_driver.c b/ncurses/tinfo/tinfo_driver.c\nindex 7919a9b09..3089cf0aa 100644\n--- a/ncurses/tinfo/tinfo_driver.c\n+++ b/ncurses/tinfo/tinfo_driver.c\n@@ -52,7 +52,7 @@\n # endif\n #endif\n \n-MODULE_ID(\"$Id: tinfo_driver.c,v 1.67 2020/02/02 23:34:34 tom Exp $\")\n+MODULE_ID(\"$Id: tinfo_driver.c,v 1.69 2020/05/27 23:55:56 tom Exp $\")\n \n /*\n  * SCO defines TIOCGSIZE and the corresponding struct.  Other systems (SunOS,\n@@ -356,23 +356,23 @@ drv_setcolor(TERMINAL_CONTROL_BLOCK * TCB,\n \tif (set_a_foreground) {\n \t    TPUTS_TRACE(\"set_a_foreground\");\n \t    NCURSES_SP_NAME(tputs) (NCURSES_SP_ARGx\n-\t\t\t\t    TPARM_1(set_a_foreground, color), 1, outc);\n+\t\t\t\t    TIPARM_1(set_a_foreground, color), 1, outc);\n \t} else {\n \t    TPUTS_TRACE(\"set_foreground\");\n \t    NCURSES_SP_NAME(tputs) (NCURSES_SP_ARGx\n-\t\t\t\t    TPARM_1(set_foreground,\n-\t\t\t\t\t    toggled_colors(color)), 1, outc);\n+\t\t\t\t    TIPARM_1(set_foreground,\n+\t\t\t\t\t     toggled_colors(color)), 1, outc);\n \t}\n     } else {\n \tif (set_a_background) {\n \t    TPUTS_TRACE(\"set_a_background\");\n \t    NCURSES_SP_NAME(tputs) (NCURSES_SP_ARGx\n-\t\t\t\t    TPARM_1(set_a_background, color), 1, outc);\n+\t\t\t\t    TIPARM_1(set_a_background, color), 1, outc);\n \t} else {\n \t    TPUTS_TRACE(\"set_background\");\n \t    NCURSES_SP_NAME(tputs) (NCURSES_SP_ARGx\n-\t\t\t\t    TPARM_1(set_background,\n-\t\t\t\t\t    toggled_colors(color)), 1, outc);\n+\t\t\t\t    TIPARM_1(set_background,\n+\t\t\t\t\t     toggled_colors(color)), 1, outc);\n \t}\n     }\n }\n@@ -764,10 +764,10 @@ drv_initpair(TERMINAL_CONTROL_BLOCK * TCB, int pair, int f, int b)\n \t    tp[b].red, tp[b].green, tp[b].blue));\n \n \tNCURSES_PUTP2(\"initialize_pair\",\n-\t\t      TPARM_7(initialize_pair,\n-\t\t\t      pair,\n-\t\t\t      tp[f].red, tp[f].green, tp[f].blue,\n-\t\t\t      tp[b].red, tp[b].green, tp[b].blue));\n+\t\t      TIPARM_7(initialize_pair,\n+\t\t\t       pair,\n+\t\t\t       tp[f].red, tp[f].green, tp[f].blue,\n+\t\t\t       tp[b].red, tp[b].green, tp[b].blue));\n     }\n }\n \n@@ -800,7 +800,7 @@ drv_initcolor(TERMINAL_CONTROL_BLOCK * TCB,\n     AssertTCB();\n     if (initialize_color != NULL) {\n \tNCURSES_PUTP2(\"initialize_color\",\n-\t\t      TPARM_4(initialize_color, color, r, g, b));\n+\t\t      TIPARM_4(initialize_color, color, r, g, b));\n     }\n }\n \n@@ -826,7 +826,7 @@ drv_do_color(TERMINAL_CONTROL_BLOCK * TCB,\n \tif (set_color_pair) {\n \t    TPUTS_TRACE(\"set_color_pair\");\n \t    NCURSES_SP_NAME(tputs) (NCURSES_SP_ARGx\n-\t\t\t\t    TPARM_1(set_color_pair, pair), 1, outc);\n+\t\t\t\t    TIPARM_1(set_color_pair, pair), 1, outc);\n \t    return;\n \t} else if (sp != 0) {\n \t    _nc_pair_content(SP_PARM, pair, &fg, &bg);\ndiff --git a/ncurses/tinfo/trim_sgr0.c b/ncurses/tinfo/trim_sgr0.c\nindex 4d10529c0..30c8f75c1 100644\n--- a/ncurses/tinfo/trim_sgr0.c\n+++ b/ncurses/tinfo/trim_sgr0.c\n@@ -37,7 +37,7 @@\n \n #include <tic.h>\n \n-MODULE_ID(\"$Id: trim_sgr0.c,v 1.18 2020/02/02 23:34:34 tom Exp $\")\n+MODULE_ID(\"$Id: trim_sgr0.c,v 1.20 2020/05/27 23:54:31 tom Exp $\")\n \n #undef CUR\n #define CUR tp->\n@@ -52,7 +52,7 @@ set_attribute_9(TERMTYPE2 *tp, int flag)\n     const char *value;\n     char *result;\n \n-    value = tparm(set_attributes, 0, 0, 0, 0, 0, 0, 0, 0, flag);\n+    value = TIPARM_9(set_attributes, 0, 0, 0, 0, 0, 0, 0, 0, flag);\n     if (PRESENT(value))\n \tresult = strdup(value);\n     else\ndiff --git a/ncurses/trace/lib_trace.c b/ncurses/trace/lib_trace.c\nindex 2c10b51d0..28ce5196f 100644\n--- a/ncurses/trace/lib_trace.c\n+++ b/ncurses/trace/lib_trace.c\n@@ -48,7 +48,7 @@\n \n #include <ctype.h>\n \n-MODULE_ID(\"$Id: lib_trace.c,v 1.95 2020/02/02 23:34:34 tom Exp $\")\n+MODULE_ID(\"$Id: lib_trace.c,v 1.96 2020/05/25 22:48:18 tom Exp $\")\n \n NCURSES_EXPORT_VAR(unsigned) _nc_tracing = 0; /* always define this */\n \n@@ -349,7 +349,7 @@ _nc_fmt_funcptr(char *target, const char *source, size_t size)\n \tif (ch != 0 || (n + 1) >= size)\n \t    leading = FALSE;\n \tif (!leading) {\n-\t    _nc_SPRINTF(dst, _nc_SLIMIT(TR_FUNC_LEN - (dst - target))\n+\t    _nc_SPRINTF(dst, _nc_SLIMIT(TR_FUNC_LEN - (size_t) (dst - target))\n \t\t\t\"%02x\", ch & 0xff);\n \t    dst += 2;\n \t}\ndiff --git a/ncurses/tty/hashmap.c b/ncurses/tty/hashmap.c\nindex 9d1e482b0..3f124c96c 100644\n--- a/ncurses/tty/hashmap.c\n+++ b/ncurses/tty/hashmap.c\n@@ -74,7 +74,7 @@ AUTHOR\n #define CUR SP_TERMTYPE\n #endif\n \n-MODULE_ID(\"$Id: hashmap.c,v 1.68 2020/02/02 23:34:34 tom Exp $\")\n+MODULE_ID(\"$Id: hashmap.c,v 1.69 2020/05/31 17:50:48 tom Exp $\")\n \n #ifdef HASHDEBUG\n \n@@ -88,7 +88,7 @@ MODULE_ID(\"$Id: hashmap.c,v 1.68 2020/02/02 23:34:34 tom Exp $\")\n # undef screen_lines\n # define screen_lines(sp) MAXLINES\n # define TEXTWIDTH(sp)\t1\n-int oldnums[MAXLINES], reallines[MAXLINES];\n+static int oldnums[MAXLINES], reallines[MAXLINES];\n static NCURSES_CH_T oldtext[MAXLINES][TEXTWIDTH(sp)];\n static NCURSES_CH_T newtext[MAXLINES][TEXTWIDTH(sp)];\n # define OLDNUM(sp,n)\toldnums[n]\ndiff --git a/ncurses/tty/lib_mvcur.c b/ncurses/tty/lib_mvcur.c\nindex 5382b3bfe..86e2fb183 100644\n--- a/ncurses/tty/lib_mvcur.c\n+++ b/ncurses/tty/lib_mvcur.c\n@@ -160,7 +160,7 @@\n #define CUR SP_TERMTYPE\n #endif\n \n-MODULE_ID(\"$Id: lib_mvcur.c,v 1.151 2020/02/02 23:34:34 tom Exp $\")\n+MODULE_ID(\"$Id: lib_mvcur.c,v 1.153 2020/05/27 23:56:32 tom Exp $\")\n \n #define WANT_CHAR(sp, y, x) NewScreen(sp)->_line[y].text[x]\t/* desired state */\n \n@@ -279,8 +279,8 @@ reset_scroll_region(NCURSES_SP_DCL0)\n {\n     if (change_scroll_region) {\n \tNCURSES_PUTP2(\"change_scroll_region\",\n-\t\t      TPARM_2(change_scroll_region,\n-\t\t\t      0, screen_lines(SP_PARM) - 1));\n+\t\t      TIPARM_2(change_scroll_region,\n+\t\t\t       0, screen_lines(SP_PARM) - 1));\n     }\n }\n \n@@ -399,13 +399,13 @@ NCURSES_SP_NAME(_nc_mvcur_init) (NCURSES_SP_DCL0)\n      * All these averages depend on the assumption that all parameter values\n      * are equally probable.\n      */\n-    SP_PARM->_cup_cost = CostOf(TPARM_2(SP_PARM->_address_cursor, 23, 23), 1);\n-    SP_PARM->_cub_cost = CostOf(TPARM_1(parm_left_cursor, 23), 1);\n-    SP_PARM->_cuf_cost = CostOf(TPARM_1(parm_right_cursor, 23), 1);\n-    SP_PARM->_cud_cost = CostOf(TPARM_1(parm_down_cursor, 23), 1);\n-    SP_PARM->_cuu_cost = CostOf(TPARM_1(parm_up_cursor, 23), 1);\n-    SP_PARM->_hpa_cost = CostOf(TPARM_1(column_address, 23), 1);\n-    SP_PARM->_vpa_cost = CostOf(TPARM_1(row_address, 23), 1);\n+    SP_PARM->_cup_cost = CostOf(TIPARM_2(SP_PARM->_address_cursor, 23, 23), 1);\n+    SP_PARM->_cub_cost = CostOf(TIPARM_1(parm_left_cursor, 23), 1);\n+    SP_PARM->_cuf_cost = CostOf(TIPARM_1(parm_right_cursor, 23), 1);\n+    SP_PARM->_cud_cost = CostOf(TIPARM_1(parm_down_cursor, 23), 1);\n+    SP_PARM->_cuu_cost = CostOf(TIPARM_1(parm_up_cursor, 23), 1);\n+    SP_PARM->_hpa_cost = CostOf(TIPARM_1(column_address, 23), 1);\n+    SP_PARM->_vpa_cost = CostOf(TIPARM_1(row_address, 23), 1);\n \n     /* non-parameterized screen-update strings */\n     SP_PARM->_ed_cost = NormalizedCost(clr_eos, 1);\n@@ -422,17 +422,16 @@ NCURSES_SP_NAME(_nc_mvcur_init) (NCURSES_SP_DCL0)\n \tSP_PARM->_el_cost = 0;\n \n     /* parameterized screen-update strings */\n-    SP_PARM->_dch_cost = NormalizedCost(TPARM_1(parm_dch, 23), 1);\n-    SP_PARM->_ich_cost = NormalizedCost(TPARM_1(parm_ich, 23), 1);\n-    SP_PARM->_ech_cost = NormalizedCost(TPARM_1(erase_chars, 23), 1);\n-    SP_PARM->_rep_cost = NormalizedCost(TPARM_2(repeat_char, ' ', 23), 1);\n-\n-    SP_PARM->_cup_ch_cost = NormalizedCost(\n-\t\t\t\t\t      TPARM_2(SP_PARM->_address_cursor,\n-\t\t\t\t\t\t      23, 23),\n-\t\t\t\t\t      1);\n-    SP_PARM->_hpa_ch_cost = NormalizedCost(TPARM_1(column_address, 23), 1);\n-    SP_PARM->_cuf_ch_cost = NormalizedCost(TPARM_1(parm_right_cursor, 23), 1);\n+    SP_PARM->_dch_cost = NormalizedCost(TIPARM_1(parm_dch, 23), 1);\n+    SP_PARM->_ich_cost = NormalizedCost(TIPARM_1(parm_ich, 23), 1);\n+    SP_PARM->_ech_cost = NormalizedCost(TIPARM_1(erase_chars, 23), 1);\n+    SP_PARM->_rep_cost = NormalizedCost(TIPARM_2(repeat_char, ' ', 23), 1);\n+\n+    SP_PARM->_cup_ch_cost = NormalizedCost(TIPARM_2(SP_PARM->_address_cursor,\n+\t\t\t\t\t\t    23, 23),\n+\t\t\t\t\t   1);\n+    SP_PARM->_hpa_ch_cost = NormalizedCost(TIPARM_1(column_address, 23), 1);\n+    SP_PARM->_cuf_ch_cost = NormalizedCost(TIPARM_1(parm_right_cursor, 23), 1);\n     SP_PARM->_inline_cost = min(SP_PARM->_cup_ch_cost,\n \t\t\t\tmin(SP_PARM->_hpa_ch_cost,\n \t\t\t\t    SP_PARM->_cuf_ch_cost));\n@@ -563,7 +562,7 @@ relative_move(NCURSES_SP_DCLx\n \tvcost = INFINITY;\n \n \tif (row_address != 0\n-\t    && _nc_safe_strcat(target, TPARM_1(row_address, to_y))) {\n+\t    && _nc_safe_strcat(target, TIPARM_1(row_address, to_y))) {\n \t    vcost = SP_PARM->_vpa_cost;\n \t}\n \n@@ -573,7 +572,7 @@ relative_move(NCURSES_SP_DCLx\n \t    if (parm_down_cursor\n \t\t&& SP_PARM->_cud_cost < vcost\n \t\t&& _nc_safe_strcat(_nc_str_copy(target, &save),\n-\t\t\t\t   TPARM_1(parm_down_cursor, n))) {\n+\t\t\t\t   TIPARM_1(parm_down_cursor, n))) {\n \t\tvcost = SP_PARM->_cud_cost;\n \t    }\n \n@@ -589,7 +588,7 @@ relative_move(NCURSES_SP_DCLx\n \t    if (parm_up_cursor\n \t\t&& SP_PARM->_cuu_cost < vcost\n \t\t&& _nc_safe_strcat(_nc_str_copy(target, &save),\n-\t\t\t\t   TPARM_1(parm_up_cursor, n))) {\n+\t\t\t\t   TIPARM_1(parm_up_cursor, n))) {\n \t\tvcost = SP_PARM->_cuu_cost;\n \t    }\n \n@@ -613,7 +612,7 @@ relative_move(NCURSES_SP_DCLx\n \n \tif (column_address\n \t    && _nc_safe_strcat(_nc_str_copy(target, &save),\n-\t\t\t       TPARM_1(column_address, to_x))) {\n+\t\t\t       TIPARM_1(column_address, to_x))) {\n \t    hcost = SP_PARM->_hpa_cost;\n \t}\n \n@@ -623,7 +622,7 @@ relative_move(NCURSES_SP_DCLx\n \t    if (parm_right_cursor\n \t\t&& SP_PARM->_cuf_cost < hcost\n \t\t&& _nc_safe_strcat(_nc_str_copy(target, &save),\n-\t\t\t\t   TPARM_1(parm_right_cursor, n))) {\n+\t\t\t\t   TIPARM_1(parm_right_cursor, n))) {\n \t\thcost = SP_PARM->_cuf_cost;\n \t    }\n \n@@ -716,7 +715,7 @@ relative_move(NCURSES_SP_DCLx\n \t    if (parm_left_cursor\n \t\t&& SP_PARM->_cub_cost < hcost\n \t\t&& _nc_safe_strcat(_nc_str_copy(target, &save),\n-\t\t\t\t   TPARM_1(parm_left_cursor, n))) {\n+\t\t\t\t   TIPARM_1(parm_left_cursor, n))) {\n \t\thcost = SP_PARM->_cub_cost;\n \t    }\n \n@@ -793,7 +792,8 @@ onscreen_mvcur(NCURSES_SP_DCLx\n #define InitResult _nc_str_init(&result, buffer, sizeof(buffer))\n \n     /* tactic #0: use direct cursor addressing */\n-    if (_nc_safe_strcpy(InitResult, TPARM_2(SP_PARM->_address_cursor, ynew, xnew))) {\n+    if (_nc_safe_strcpy(InitResult, TIPARM_2(SP_PARM->_address_cursor,\n+\t\t\t\t\t     ynew, xnew))) {\n \ttactic = 0;\n \tusecost = SP_PARM->_cup_cost;\n \ndiff --git a/ncurses/tty/lib_vidattr.c b/ncurses/tty/lib_vidattr.c\nindex c752919bf..15e7397d5 100644\n--- a/ncurses/tty/lib_vidattr.c\n+++ b/ncurses/tty/lib_vidattr.c\n@@ -70,7 +70,7 @@\n #define CUR SP_TERMTYPE\n #endif\n \n-MODULE_ID(\"$Id: lib_vidattr.c,v 1.76 2020/02/02 23:34:34 tom Exp $\")\n+MODULE_ID(\"$Id: lib_vidattr.c,v 1.78 2020/05/27 23:56:32 tom Exp $\")\n \n #define doPut(mode) \\\n \tTPUTS_TRACE(#mode); \\\n@@ -258,16 +258,16 @@ NCURSES_SP_NAME(vidputs) (NCURSES_SP_DCLx\n \tif (turn_on || turn_off) {\n \t    TPUTS_TRACE(\"set_attributes\");\n \t    NCURSES_SP_NAME(tputs) (NCURSES_SP_ARGx\n-\t\t\t\t    tparm(set_attributes,\n-\t\t\t\t\t  (newmode & A_STANDOUT) != 0,\n-\t\t\t\t\t  (newmode & A_UNDERLINE) != 0,\n-\t\t\t\t\t  (newmode & A_REVERSE) != 0,\n-\t\t\t\t\t  (newmode & A_BLINK) != 0,\n-\t\t\t\t\t  (newmode & A_DIM) != 0,\n-\t\t\t\t\t  (newmode & A_BOLD) != 0,\n-\t\t\t\t\t  (newmode & A_INVIS) != 0,\n-\t\t\t\t\t  (newmode & A_PROTECT) != 0,\n-\t\t\t\t\t  (newmode & A_ALTCHARSET) != 0),\n+\t\t\t\t    TIPARM_9(set_attributes,\n+\t\t\t\t\t     (newmode & A_STANDOUT) != 0,\n+\t\t\t\t\t     (newmode & A_UNDERLINE) != 0,\n+\t\t\t\t\t     (newmode & A_REVERSE) != 0,\n+\t\t\t\t\t     (newmode & A_BLINK) != 0,\n+\t\t\t\t\t     (newmode & A_DIM) != 0,\n+\t\t\t\t\t     (newmode & A_BOLD) != 0,\n+\t\t\t\t\t     (newmode & A_INVIS) != 0,\n+\t\t\t\t\t     (newmode & A_PROTECT) != 0,\n+\t\t\t\t\t     (newmode & A_ALTCHARSET) != 0),\n \t\t\t\t    1, outc);\n \t    PreviousAttr &= ALL_BUT_COLOR;\n \t}\ndiff --git a/ncurses/tty/tty_update.c b/ncurses/tty/tty_update.c\nindex d57f23f10..9691f8996 100644\n--- a/ncurses/tty/tty_update.c\n+++ b/ncurses/tty/tty_update.c\n@@ -85,7 +85,7 @@\n \n #include <ctype.h>\n \n-MODULE_ID(\"$Id: tty_update.c,v 1.307 2020/05/23 19:10:35 tom Exp $\")\n+MODULE_ID(\"$Id: tty_update.c,v 1.309 2020/05/27 23:56:32 tom Exp $\")\n \n /*\n  * This define controls the line-breakout optimization.  Every once in a\n@@ -170,9 +170,9 @@ position_check(NCURSES_SP_DCLx int expected_y, int expected_x, char *legend)\n \tif (y - 1 != expected_y || x - 1 != expected_x) {\n \t    NCURSES_SP_NAME(beep) (NCURSES_SP_ARG);\n \t    NCURSES_SP_NAME(tputs) (NCURSES_SP_ARGx\n-\t\t\t\t    tparm(\"\\033[%d;%dH\",\n-\t\t\t\t\t  expected_y + 1,\n-\t\t\t\t\t  expected_x + 1),\n+\t\t\t\t    TIPARM_2(\"\\033[%d;%dH\",\n+\t\t\t\t\t     expected_y + 1,\n+\t\t\t\t\t     expected_x + 1),\n \t\t\t\t    1, NCURSES_SP_NAME(_nc_outch));\n \t    _tracef(\"position seen (%d, %d) doesn't match expected one (%d, %d) in %s\",\n \t\t    y - 1, x - 1, expected_y, expected_x, legend);\n@@ -605,7 +605,7 @@ EmitRange(NCURSES_SP_DCLx const NCURSES_CH_T *ntext, int num)\n \t\t&& runcount > SP_PARM->_ech_cost + SP_PARM->_cup_ch_cost\n \t\t&& can_clear_with(NCURSES_SP_ARGx CHREF(ntext0))) {\n \t\tUpdateAttrs(SP_PARM, ntext0);\n-\t\tNCURSES_PUTP2(\"erase_chars\", TPARM_1(erase_chars, runcount));\n+\t\tNCURSES_PUTP2(\"erase_chars\", TIPARM_1(erase_chars, runcount));\n \n \t\t/*\n \t\t * If this is the last part of the given interval,\n@@ -648,9 +648,9 @@ EmitRange(NCURSES_SP_DCLx const NCURSES_CH_T *ntext, int num)\n \t\t\t    AttrOf(ntext0) | A_ALTCHARSET);\n \t\t}\n \t\tNCURSES_SP_NAME(tputs) (NCURSES_SP_ARGx\n-\t\t\t\t\tTPARM_2(repeat_char,\n-\t\t\t\t\t\tCharOf(temp),\n-\t\t\t\t\t\trep_count),\n+\t\t\t\t\tTIPARM_2(repeat_char,\n+\t\t\t\t\t\t CharOf(temp),\n+\t\t\t\t\t\t rep_count),\n \t\t\t\t\t1,\n \t\t\t\t\tNCURSES_SP_NAME(_nc_outch));\n \t\tSP_PARM->_curscol += rep_count;\n@@ -1716,7 +1716,7 @@ InsStr(NCURSES_SP_DCLx NCURSES_CH_T *line, int count)\n     if (parm_ich) {\n \tTPUTS_TRACE(\"parm_ich\");\n \tNCURSES_SP_NAME(tputs) (NCURSES_SP_ARGx\n-\t\t\t\tTPARM_1(parm_ich, count),\n+\t\t\t\tTIPARM_1(parm_ich, count),\n \t\t\t\t1,\n \t\t\t\tNCURSES_SP_NAME(_nc_outch));\n \twhile (count > 0) {\n@@ -1769,7 +1769,7 @@ DelChar(NCURSES_SP_DCLx int count)\n     if (parm_dch) {\n \tTPUTS_TRACE(\"parm_dch\");\n \tNCURSES_SP_NAME(tputs) (NCURSES_SP_ARGx\n-\t\t\t\tTPARM_1(parm_dch, count),\n+\t\t\t\tTIPARM_1(parm_dch, count),\n \t\t\t\t1,\n \t\t\t\tNCURSES_SP_NAME(_nc_outch));\n     } else {\n@@ -1838,7 +1838,7 @@ scroll_csr_forward(NCURSES_SP_DCLx\n \tUpdateAttrs(SP_PARM, blank);\n \tTPUTS_TRACE(\"parm_index\");\n \tNCURSES_SP_NAME(tputs) (NCURSES_SP_ARGx\n-\t\t\t\tTPARM_2(parm_index, n, 0),\n+\t\t\t\tTIPARM_1(parm_index, n),\n \t\t\t\tn,\n \t\t\t\tNCURSES_SP_NAME(_nc_outch));\n     } else if (parm_delete_line && bot == maxy) {\n@@ -1846,7 +1846,7 @@ scroll_csr_forward(NCURSES_SP_DCLx\n \tUpdateAttrs(SP_PARM, blank);\n \tTPUTS_TRACE(\"parm_delete_line\");\n \tNCURSES_SP_NAME(tputs) (NCURSES_SP_ARGx\n-\t\t\t\tTPARM_2(parm_delete_line, n, 0),\n+\t\t\t\tTIPARM_1(parm_delete_line, n),\n \t\t\t\tn,\n \t\t\t\tNCURSES_SP_NAME(_nc_outch));\n     } else if (scroll_forward && top == miny && bot == maxy) {\n@@ -1903,7 +1903,7 @@ scroll_csr_backward(NCURSES_SP_DCLx\n \tUpdateAttrs(SP_PARM, blank);\n \tTPUTS_TRACE(\"parm_rindex\");\n \tNCURSES_SP_NAME(tputs) (NCURSES_SP_ARGx\n-\t\t\t\tTPARM_2(parm_rindex, n, 0),\n+\t\t\t\tTIPARM_1(parm_rindex, n),\n \t\t\t\tn,\n \t\t\t\tNCURSES_SP_NAME(_nc_outch));\n     } else if (parm_insert_line && bot == maxy) {\n@@ -1911,7 +1911,7 @@ scroll_csr_backward(NCURSES_SP_DCLx\n \tUpdateAttrs(SP_PARM, blank);\n \tTPUTS_TRACE(\"parm_insert_line\");\n \tNCURSES_SP_NAME(tputs) (NCURSES_SP_ARGx\n-\t\t\t\tTPARM_2(parm_insert_line, n, 0),\n+\t\t\t\tTIPARM_1(parm_insert_line, n),\n \t\t\t\tn,\n \t\t\t\tNCURSES_SP_NAME(_nc_outch));\n     } else if (scroll_reverse && top == miny && bot == maxy) {\n@@ -1959,7 +1959,7 @@ scroll_idl(NCURSES_SP_DCLx int n, int del, int ins, NCURSES_CH_T blank)\n     } else if (parm_delete_line) {\n \tTPUTS_TRACE(\"parm_delete_line\");\n \tNCURSES_SP_NAME(tputs) (NCURSES_SP_ARGx\n-\t\t\t\tTPARM_2(parm_delete_line, n, 0),\n+\t\t\t\tTIPARM_1(parm_delete_line, n),\n \t\t\t\tn,\n \t\t\t\tNCURSES_SP_NAME(_nc_outch));\n     } else {\t\t\t/* if (delete_line) */\n@@ -1975,7 +1975,7 @@ scroll_idl(NCURSES_SP_DCLx int n, int del, int ins, NCURSES_CH_T blank)\n     } else if (parm_insert_line) {\n \tTPUTS_TRACE(\"parm_insert_line\");\n \tNCURSES_SP_NAME(tputs) (NCURSES_SP_ARGx\n-\t\t\t\tTPARM_2(parm_insert_line, n, 0),\n+\t\t\t\tTIPARM_1(parm_insert_line, n),\n \t\t\t\tn,\n \t\t\t\tNCURSES_SP_NAME(_nc_outch));\n     } else {\t\t\t/* if (insert_line) */\n@@ -2040,7 +2040,7 @@ NCURSES_SP_NAME(_nc_scrolln) (NCURSES_SP_DCLx\n \t\tNCURSES_PUTP2(\"save_cursor\", save_cursor);\n \t    }\n \t    NCURSES_PUTP2(\"change_scroll_region\",\n-\t\t\t  TPARM_2(change_scroll_region, top, bot));\n+\t\t\t  TIPARM_2(change_scroll_region, top, bot));\n \t    if (cursor_saved) {\n \t\tNCURSES_PUTP2(\"restore_cursor\", restore_cursor);\n \t    } else {\n@@ -2050,7 +2050,7 @@ NCURSES_SP_NAME(_nc_scrolln) (NCURSES_SP_DCLx\n \t    res = scroll_csr_forward(NCURSES_SP_ARGx n, top, bot, top, bot, blank);\n \n \t    NCURSES_PUTP2(\"change_scroll_region\",\n-\t\t\t  TPARM_2(change_scroll_region, 0, maxy));\n+\t\t\t  TIPARM_2(change_scroll_region, 0, maxy));\n \t    SP_PARM->_cursrow = SP_PARM->_curscol = -1;\n \t}\n \n@@ -2086,7 +2086,7 @@ NCURSES_SP_NAME(_nc_scrolln) (NCURSES_SP_DCLx\n \t\tNCURSES_PUTP2(\"save_cursor\", save_cursor);\n \t    }\n \t    NCURSES_PUTP2(\"change_scroll_region\",\n-\t\t\t  TPARM_2(change_scroll_region, top, bot));\n+\t\t\t  TIPARM_2(change_scroll_region, top, bot));\n \t    if (cursor_saved) {\n \t\tNCURSES_PUTP2(\"restore_cursor\", restore_cursor);\n \t    } else {\n@@ -2097,7 +2097,7 @@ NCURSES_SP_NAME(_nc_scrolln) (NCURSES_SP_DCLx\n \t\t\t\t      -n, top, bot, top, bot, blank);\n \n \t    NCURSES_PUTP2(\"change_scroll_region\",\n-\t\t\t  TPARM_2(change_scroll_region, 0, maxy));\n+\t\t\t  TIPARM_2(change_scroll_region, 0, maxy));\n \t    SP_PARM->_cursrow = SP_PARM->_curscol = -1;\n \t}\n \ndiff --git a/ncurses/widechar/lib_vid_attr.c b/ncurses/widechar/lib_vid_attr.c\nindex e167bebee..2d9531f1b 100644\n--- a/ncurses/widechar/lib_vid_attr.c\n+++ b/ncurses/widechar/lib_vid_attr.c\n@@ -37,7 +37,7 @@\n #define CUR SP_TERMTYPE\n #endif\n \n-MODULE_ID(\"$Id: lib_vid_attr.c,v 1.28 2020/02/02 23:34:34 tom Exp $\")\n+MODULE_ID(\"$Id: lib_vid_attr.c,v 1.30 2020/05/27 23:54:31 tom Exp $\")\n \n #define doPut(mode) \\\n \tTPUTS_TRACE(#mode); \\\n@@ -191,16 +191,16 @@ NCURSES_SP_NAME(vid_puts) (NCURSES_SP_DCLx\n \tif (turn_on || turn_off) {\n \t    TPUTS_TRACE(\"set_attributes\");\n \t    NCURSES_SP_NAME(tputs) (NCURSES_SP_ARGx\n-\t\t\t\t    TPARM_9(set_attributes,\n-\t\t\t\t\t    (newmode & A_STANDOUT) != 0,\n-\t\t\t\t\t    (newmode & A_UNDERLINE) != 0,\n-\t\t\t\t\t    (newmode & A_REVERSE) != 0,\n-\t\t\t\t\t    (newmode & A_BLINK) != 0,\n-\t\t\t\t\t    (newmode & A_DIM) != 0,\n-\t\t\t\t\t    (newmode & A_BOLD) != 0,\n-\t\t\t\t\t    (newmode & A_INVIS) != 0,\n-\t\t\t\t\t    (newmode & A_PROTECT) != 0,\n-\t\t\t\t\t    (newmode & A_ALTCHARSET) != 0),\n+\t\t\t\t    TIPARM_9(set_attributes,\n+\t\t\t\t\t       (newmode & A_STANDOUT) != 0,\n+\t\t\t\t\t       (newmode & A_UNDERLINE) != 0,\n+\t\t\t\t\t       (newmode & A_REVERSE) != 0,\n+\t\t\t\t\t       (newmode & A_BLINK) != 0,\n+\t\t\t\t\t       (newmode & A_DIM) != 0,\n+\t\t\t\t\t       (newmode & A_BOLD) != 0,\n+\t\t\t\t\t       (newmode & A_INVIS) != 0,\n+\t\t\t\t\t       (newmode & A_PROTECT) != 0,\n+\t\t\t\t\t       (newmode & A_ALTCHARSET) != 0),\n \t\t\t\t    1, outc);\n \t    previous_attr &= ALL_BUT_COLOR;\n \t    previous_pair = 0;\n@@ -264,7 +264,6 @@ NCURSES_SP_NAME(vid_puts) (NCURSES_SP_DCLx\n \tTurnOn(A_VERTICAL,\tenter_vertical_hl_mode);\n #endif\n \t/* *INDENT-ON* */\n-\n     }\n \n     if (reverse)\ndiff --git a/package/debian-mingw/changelog b/package/debian-mingw/changelog\nindex 9e844799b..7a9d961d9 100644\n--- a/package/debian-mingw/changelog\n+++ b/package/debian-mingw/changelog\n@@ -1,8 +1,8 @@\n-ncurses6 (6.2+20200523) unstable; urgency=low\n+ncurses6 (6.2+20200531) unstable; urgency=low\n \n   * latest weekly patch\n \n- -- Thomas E. Dickey <dickey@invisible-island.net>  Sat, 23 May 2020 05:35:39 -0400\n+ -- Thomas E. Dickey <dickey@invisible-island.net>  Sun, 31 May 2020 14:56:59 -0400\n \n ncurses6 (5.9-20131005) unstable; urgency=low\n \ndiff --git a/package/debian-mingw64/changelog b/package/debian-mingw64/changelog\nindex 9e844799b..7a9d961d9 100644\n--- a/package/debian-mingw64/changelog\n+++ b/package/debian-mingw64/changelog\n@@ -1,8 +1,8 @@\n-ncurses6 (6.2+20200523) unstable; urgency=low\n+ncurses6 (6.2+20200531) unstable; urgency=low\n \n   * latest weekly patch\n \n- -- Thomas E. Dickey <dickey@invisible-island.net>  Sat, 23 May 2020 05:35:39 -0400\n+ -- Thomas E. Dickey <dickey@invisible-island.net>  Sun, 31 May 2020 14:56:59 -0400\n \n ncurses6 (5.9-20131005) unstable; urgency=low\n \ndiff --git a/package/debian/changelog b/package/debian/changelog\nindex 47a55f774..843c49b86 100644\n--- a/package/debian/changelog\n+++ b/package/debian/changelog\n@@ -1,8 +1,8 @@\n-ncurses6 (6.2+20200523) unstable; urgency=low\n+ncurses6 (6.2+20200531) unstable; urgency=low\n \n   * latest weekly patch\n \n- -- Thomas E. Dickey <dickey@invisible-island.net>  Sat, 23 May 2020 05:35:39 -0400\n+ -- Thomas E. Dickey <dickey@invisible-island.net>  Sun, 31 May 2020 14:56:59 -0400\n \n ncurses6 (5.9-20120608) unstable; urgency=low\n \ndiff --git a/package/mingw-ncurses.nsi b/package/mingw-ncurses.nsi\nindex 634b0df5e..ce1de07ce 100644\n--- a/package/mingw-ncurses.nsi\n+++ b/package/mingw-ncurses.nsi\n@@ -1,4 +1,4 @@\n-; $Id: mingw-ncurses.nsi,v 1.395 2020/05/23 09:35:39 tom Exp $\r\n+; $Id: mingw-ncurses.nsi,v 1.398 2020/05/31 18:56:59 tom Exp $\r\n \r\n ; TODO add examples\r\n ; TODO bump ABI to 6\r\n@@ -10,7 +10,7 @@\n !define VERSION_MAJOR \"6\"\r\n !define VERSION_MINOR \"2\"\r\n !define VERSION_YYYY  \"2020\"\r\n-!define VERSION_MMDD  \"0523\"\r\n+!define VERSION_MMDD  \"0531\"\r\n !define VERSION_PATCH ${VERSION_YYYY}${VERSION_MMDD}\r\n \r\n !define MY_ABI   \"5\"\r\ndiff --git a/package/mingw-ncurses.spec b/package/mingw-ncurses.spec\nindex 40522dd5a..cefaa9b4d 100644\n--- a/package/mingw-ncurses.spec\n+++ b/package/mingw-ncurses.spec\n@@ -3,7 +3,7 @@\n Summary: shared libraries for terminal handling\n Name: mingw32-ncurses6\n Version: 6.2\n-Release: 20200523\n+Release: 20200531\n License: X11\n Group: Development/Libraries\n Source: ncurses-%{version}-%{release}.tgz\ndiff --git a/package/ncurses.map b/package/ncurses.map\nindex 1c400dee5..0b2a1ab2c 100644\n--- a/package/ncurses.map\n+++ b/package/ncurses.map\n@@ -1,4 +1,4 @@\n-# $Id: ncurses.map,v 1.51 2020/02/04 11:44:12 tom Exp $\n+# $Id: ncurses.map,v 1.52 2020/05/27 19:26:59 tom Exp $\n # script for shared library symbol-versioning using ld\n #\n # This file was generated by ncu-mapsyms\n@@ -1206,6 +1206,11 @@ NCURSES_TINFO_6.2.20200212 {\n \t\t_nc_wacs_width;\n \t\tcurses_trace;\n \t\texit_terminfo;\n+} NCURSES_TINFO_6.1.20171230;\n+\n+NCURSES_TINFO_6.2.current {\n+\tglobal:\n+\t\t_nc_tiparm;\n \tlocal:\n \t\t_*;\n-} NCURSES_TINFO_6.1.20171230;\n+} NCURSES_TINFO_6.2.20200212;\ndiff --git a/package/ncurses.spec b/package/ncurses.spec\nindex 9aaac6c71..32bc053c5 100644\n--- a/package/ncurses.spec\n+++ b/package/ncurses.spec\n@@ -1,7 +1,7 @@\n Summary: shared libraries for terminal handling\n Name: ncurses6\n Version: 6.2\n-Release: 20200523\n+Release: 20200531\n License: X11\n Group: Development/Libraries\n Source: ncurses-%{version}-%{release}.tgz\ndiff --git a/package/ncursest.map b/package/ncursest.map\nindex 643dc8e11..ed8f4e191 100644\n--- a/package/ncursest.map\n+++ b/package/ncursest.map\n@@ -1,4 +1,4 @@\n-# $Id: ncursest.map,v 1.49 2020/02/04 11:44:12 tom Exp $\n+# $Id: ncursest.map,v 1.50 2020/05/27 19:29:10 tom Exp $\n # script for shared library symbol-versioning using ld\n #\n # This file was generated by ncu-mapsyms\n@@ -485,9 +485,14 @@ NCURSES_TINFO_6.2.20200212 {\n \t\t_nc_wacs_width;\n \t\tcurses_trace;\n \t\texit_terminfo;\n+} NCURSES_TINFO_6.1.20171230;\n+\n+NCURSES_TINFO_6.2.current {\n+\tglobal:\n+\t\t_nc_tiparm;\n \tlocal:\n \t\t_*;\n-} NCURSES_TINFO_6.1.20171230;\n+} NCURSES_TINFO_6.2.20200212;\n \n NCURSEST_5.7.20081102 {\n \tglobal:\ndiff --git a/package/ncursest.spec b/package/ncursest.spec\nindex 710d6e5ba..b3c4bff12 100644\n--- a/package/ncursest.spec\n+++ b/package/ncursest.spec\n@@ -1,7 +1,7 @@\n Summary: Curses library with POSIX thread support.\n Name: ncursest6\n Version: 6.2\n-Release: 20200523\n+Release: 20200531\n License: X11\n Group: Development/Libraries\n Source: ncurses-%{version}-%{release}.tgz\ndiff --git a/package/ncursestw.map b/package/ncursestw.map\nindex 0c932b934..ff857389e 100644\n--- a/package/ncursestw.map\n+++ b/package/ncursestw.map\n@@ -1,4 +1,4 @@\n-# $Id: ncursestw.map,v 1.51 2020/02/04 11:44:12 tom Exp $\n+# $Id: ncursestw.map,v 1.52 2020/05/27 19:29:32 tom Exp $\n # script for shared library symbol-versioning using ld\n #\n # This file was generated by ncu-mapsyms\n@@ -491,9 +491,14 @@ NCURSES_TINFO_6.2.20200212 {\n \t\t_nc_wacs_width;\n \t\tcurses_trace;\n \t\texit_terminfo;\n+} NCURSES_TINFO_6.1.20171230;\n+\n+NCURSES_TINFO_6.2.current {\n+\tglobal:\n+\t\t_nc_tiparm;\n \tlocal:\n \t\t_*;\n-} NCURSES_TINFO_6.1.20171230;\n+} NCURSES_TINFO_6.2.20200212;\n \n NCURSESTW_5.7.20081102 {\n \tglobal:\ndiff --git a/package/ncursesw.map b/package/ncursesw.map\nindex da68b73c1..021cd5776 100644\n--- a/package/ncursesw.map\n+++ b/package/ncursesw.map\n@@ -1,4 +1,4 @@\n-# $Id: ncursesw.map,v 1.54 2020/02/04 11:44:12 tom Exp $\n+# $Id: ncursesw.map,v 1.55 2020/05/27 19:27:45 tom Exp $\n # script for shared library symbol-versioning using ld\n #\n # This file was generated by ncu-mapsyms\n@@ -485,9 +485,14 @@ NCURSES_TINFO_6.2.20200212 {\n \t\t_nc_wacs_width;\n \t\tcurses_trace;\n \t\texit_terminfo;\n+} NCURSES_TINFO_6.1.20171230;\n+\n+NCURSES_TINFO_6.2.current {\n+\tglobal:\n+\t\t_nc_tiparm;\n \tlocal:\n \t\t_*;\n-} NCURSES_TINFO_6.1.20171230;\n+} NCURSES_TINFO_6.2.20200212;\n \n NCURSESW_5.1.20000708 {\n \tglobal:\ndiff --git a/progs/reset_cmd.c b/progs/reset_cmd.c\nindex 9d23cd05e..2e118ae58 100644\n--- a/progs/reset_cmd.c\n+++ b/progs/reset_cmd.c\n@@ -53,7 +53,7 @@\n #include <sys/ptem.h>\n #endif\n \n-MODULE_ID(\"$Id: reset_cmd.c,v 1.19 2020/02/02 23:34:34 tom Exp $\")\n+MODULE_ID(\"$Id: reset_cmd.c,v 1.21 2020/05/27 23:46:20 tom Exp $\")\n \n /*\n  * SCO defines TIOCGSIZE and the corresponding struct.  Other systems (SunOS,\n@@ -501,16 +501,15 @@ send_init_strings(int fd GCC_UNUSED, TTY * old_settings)\n \t} else\n #if defined(set_lr_margin)\n \tif (VALID_STRING(set_lr_margin)) {\n-\t    need_flush |= sent_string(TPARM_2(set_lr_margin, 0,\n-\t\t\t\t\t      columns - 1));\n+\t    need_flush |= sent_string(TIPARM_2(set_lr_margin, 0, columns - 1));\n \t} else\n #endif\n #if defined(set_left_margin_parm) && defined(set_right_margin_parm)\n \t    if (VALID_STRING(set_left_margin_parm)\n \t\t&& VALID_STRING(set_right_margin_parm)) {\n-\t    need_flush |= sent_string(TPARM_1(set_left_margin_parm, 0));\n-\t    need_flush |= sent_string(TPARM_1(set_right_margin_parm,\n-\t\t\t\t\t      columns - 1));\n+\t    need_flush |= sent_string(TIPARM_1(set_left_margin_parm, 0));\n+\t    need_flush |= sent_string(TIPARM_1(set_right_margin_parm,\n+\t\t\t\t\t       columns - 1));\n \t} else\n #endif\n \t    if (VALID_STRING(set_left_margin)\n@@ -518,8 +517,8 @@ send_init_strings(int fd GCC_UNUSED, TTY * old_settings)\n \t    need_flush |= to_left_margin();\n \t    need_flush |= sent_string(set_left_margin);\n \t    if (VALID_STRING(parm_right_cursor)) {\n-\t\tneed_flush |= sent_string(TPARM_1(parm_right_cursor,\n-\t\t\t\t\t\t  columns - 1));\n+\t\tneed_flush |= sent_string(TIPARM_1(parm_right_cursor,\n+\t\t\t\t\t\t   columns - 1));\n \t    } else {\n \t\tfor (i = 0; i < columns - 1; i++) {\n \t\t    out_char(' ');\ndiff --git a/progs/tabs.c b/progs/tabs.c\nindex 8a3bc108f..0539e8565 100644\n--- a/progs/tabs.c\n+++ b/progs/tabs.c\n@@ -39,7 +39,7 @@\n #include <progs.priv.h>\n #include <tty_settings.h>\n \n-MODULE_ID(\"$Id: tabs.c,v 1.42 2020/02/02 23:34:34 tom Exp $\")\n+MODULE_ID(\"$Id: tabs.c,v 1.45 2020/05/27 23:47:22 tom Exp $\")\n \n static void usage(void) GCC_NORETURN;\n \n@@ -75,7 +75,7 @@ do_tabs(int *tab_list)\n \t    }\n \t}\n \tif (stop <= max_cols) {\n-\t    tputs(tparm(set_tab, stop), 1, putch);\n+\t    tputs(TIPARM_1(set_tab, stop), 1, putch);\n \t    last = stop;\n \t} else {\n \t    break;\ndiff --git a/progs/tic.c b/progs/tic.c\nindex 328bcd6b2..ae172ece9 100644\n--- a/progs/tic.c\n+++ b/progs/tic.c\n@@ -49,7 +49,7 @@\n #include <parametrized.h>\n #include <transform.h>\n \n-MODULE_ID(\"$Id: tic.c,v 1.282 2020/02/02 23:34:34 tom Exp $\")\n+MODULE_ID(\"$Id: tic.c,v 1.286 2020/05/31 21:05:44 tom Exp $\")\n \n #define STDIN_NAME \"<stdin>\"\n \n@@ -1179,6 +1179,14 @@ check_acs(TERMTYPE2 *tp)\n     }\n }\n \n+static char *\n+safe_strdup(const char *value)\n+{\n+    if (value == NULL)\n+\tvalue = \"\";\n+    return strdup(value);\n+}\n+\n static bool\n same_color(NCURSES_CONST char *oldcap, NCURSES_CONST char *newcap, int limit)\n {\n@@ -1189,8 +1197,8 @@ same_color(NCURSES_CONST char *oldcap, NCURSES_CONST char *newcap, int limit)\n \tint n;\n \tint same;\n \tfor (n = same = 0; n < limit; ++n) {\n-\t    char *oldvalue = strdup(TPARM_1(oldcap, n));\n-\t    char *newvalue = strdup(TPARM_1(newcap, n));\n+\t    char *oldvalue = safe_strdup(TIPARM_1(oldcap, n));\n+\t    char *newvalue = safe_strdup(TIPARM_1(newcap, n));\n \t    same += !strcmp(oldvalue, newvalue);\n \t    free(oldvalue);\n \t    free(newvalue);\n@@ -1835,7 +1843,6 @@ expected_params(const char *name)\n \tDATA( \"wingo\",\t\t1 ),\n     };\n     /* *INDENT-ON* */\n-\n #undef DATA\n \n     unsigned n;\n@@ -1910,7 +1917,7 @@ check_params(TERMTYPE2 *tp, const char *name, char *value, int extended)\n     int expected = expected_params(name);\n     int actual = 0;\n     int n;\n-    bool params[NUM_PARM];\n+    bool params[1 + NUM_PARM];\n     char *s = value;\n \n #ifdef set_top_margin_parm\n@@ -1919,7 +1926,7 @@ check_params(TERMTYPE2 *tp, const char *name, char *value, int extended)\n \texpected = 2;\n #endif\n \n-    for (n = 0; n < NUM_PARM; n++)\n+    for (n = 0; n <= NUM_PARM; n++)\n \tparams[n] = FALSE;\n \n     while (*s != 0) {\n@@ -2192,6 +2199,19 @@ check_1_infotocap(const char *name, NCURSES_CONST char *value, int count)\n \tresult = TPARM_3(value, numbers[1], strings[2], strings[3]);\n \tbreak;\n     case Numbers:\n+#define myParam(n) numbers[n]\n+\tresult = TIPARM_9(value,\n+\t\t\t  myParam(1),\n+\t\t\t  myParam(2),\n+\t\t\t  myParam(3),\n+\t\t\t  myParam(4),\n+\t\t\t  myParam(5),\n+\t\t\t  myParam(6),\n+\t\t\t  myParam(7),\n+\t\t\t  myParam(8),\n+\t\t\t  myParam(9));\n+#undef myParam\n+\tbreak;\n     default:\n \t(void) _nc_tparm_analyze(value, p_is_s, &ignored);\n #define myParam(n) (p_is_s[n - 1] != 0 ? ((TPARM_ARG) strings[n]) : numbers[n])\n@@ -2205,6 +2225,7 @@ check_1_infotocap(const char *name, NCURSES_CONST char *value, int count)\n \t\t\t myParam(7),\n \t\t\t myParam(8),\n \t\t\t myParam(9));\n+#undef myParam\n \tbreak;\n     }\n     return strdup(result);\n@@ -2515,16 +2536,16 @@ check_sgr(TERMTYPE2 *tp, char *zero, int num, char *cap, const char *name)\n     char *test;\n \n     _nc_tparm_err = 0;\n-    test = TPARM_9(set_attributes,\n-\t\t   num == 1,\n-\t\t   num == 2,\n-\t\t   num == 3,\n-\t\t   num == 4,\n-\t\t   num == 5,\n-\t\t   num == 6,\n-\t\t   num == 7,\n-\t\t   num == 8,\n-\t\t   num == 9);\n+    test = TIPARM_9(set_attributes,\n+\t\t    num == 1,\n+\t\t    num == 2,\n+\t\t    num == 3,\n+\t\t    num == 4,\n+\t\t    num == 5,\n+\t\t    num == 6,\n+\t\t    num == 7,\n+\t\t    num == 8,\n+\t\t    num == 9);\n     if (test != 0) {\n \tif (PRESENT(cap)) {\n \t    if (!similar_sgr(num, test, cap)) {\n@@ -2695,7 +2716,6 @@ check_conflict(TERMTYPE2 *tp)\n \t\t{ NULL,   NULL },\n \t    };\n \t    /* *INDENT-ON* */\n-\n \t    /*\n \t     * SVr4 curses defines the \"xcurses\" names listed above except for\n \t     * the special cases in the \"shifted\" column.  When using these\n@@ -2973,7 +2993,7 @@ check_termtype(TERMTYPE2 *tp, bool literal)\n \tif (PRESENT(exit_attribute_mode)) {\n \t    zero = strdup(CHECK_SGR(0, exit_attribute_mode));\n \t} else {\n-\t    zero = strdup(TPARM_9(set_attributes, 0, 0, 0, 0, 0, 0, 0, 0, 0));\n+\t    zero = strdup(TIPARM_9(set_attributes, 0, 0, 0, 0, 0, 0, 0, 0, 0));\n \t}\n \tif (_nc_tparm_err)\n \t    _nc_warning(\"stack error in sgr(0) string\");\ndiff --git a/progs/tput.c b/progs/tput.c\nindex 295b83fb8..4bb771478 100644\n--- a/progs/tput.c\n+++ b/progs/tput.c\n@@ -51,7 +51,7 @@\n #include <transform.h>\n #include <tty_settings.h>\n \n-MODULE_ID(\"$Id: tput.c,v 1.81 2020/02/02 23:34:34 tom Exp $\")\n+MODULE_ID(\"$Id: tput.c,v 1.83 2020/05/27 23:47:51 tom Exp $\")\n \n #define PUTS(s)\t\tfputs(s, stdout)\n \n@@ -63,7 +63,7 @@ static bool is_reset = FALSE;\n static bool is_clear = FALSE;\n \n static void\n-quit(int status, const char *fmt,...)\n+quit(int status, const char *fmt, ...)\n {\n     va_list argp;\n \n@@ -251,6 +251,19 @@ tput_cmd(int fd, TTY * saved_settings, bool opt_x, int argc, char *argv[])\n \t\ts = TPARM_3(s, numbers[1], strings[2], strings[3]);\n \t\tbreak;\n \t    case Numbers:\n+#define myParam(n) numbers[n]\n+\t\ts = TIPARM_9(s,\n+\t\t\t     myParam(1),\n+\t\t\t     myParam(2),\n+\t\t\t     myParam(3),\n+\t\t\t     myParam(4),\n+\t\t\t     myParam(5),\n+\t\t\t     myParam(6),\n+\t\t\t     myParam(7),\n+\t\t\t     myParam(8),\n+\t\t\t     myParam(9));\n+#undef myParam\n+\t\tbreak;\n \t    default:\n \t\t(void) _nc_tparm_analyze(s, p_is_s, &ignored);\n #define myParam(n) (p_is_s[n - 1] != 0 ? ((TPARM_ARG) strings[n]) : numbers[n])\n@@ -264,6 +277,7 @@ tput_cmd(int fd, TTY * saved_settings, bool opt_x, int argc, char *argv[])\n \t\t\t    myParam(7),\n \t\t\t    myParam(8),\n \t\t\t    myParam(9));\n+#undef myParam\n \t\tbreak;\n \t    }\n \t}\ndiff --git a/test/configure b/test/configure\nindex 6a19a63bd..41cd8efd1 100755\n--- a/test/configure\n+++ b/test/configure\n@@ -17576,18 +17576,19 @@ fi\n for ac_func in \\\n getopt \\\n gettimeofday \\\n+snprintf \\\n strstr \\\n tsearch \\\n \n do\n as_ac_var=`echo \"ac_cv_func_$ac_func\" | $as_tr_sh`\n-echo \"$as_me:17584: checking for $ac_func\" >&5\n+echo \"$as_me:17585: checking for $ac_func\" >&5\n echo $ECHO_N \"checking for $ac_func... $ECHO_C\" >&6\n if eval \"test \\\"\\${$as_ac_var+set}\\\" = set\"; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 17590 \"configure\"\n+#line 17591 \"configure\"\n #include \"confdefs.h\"\n #define $ac_func autoconf_temporary\n #include <limits.h>\t/* least-intrusive standard header which defines gcc2 __stub macros */\n@@ -17618,16 +17619,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:17621: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:17622: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:17624: \\$? = $ac_status\" >&5\n+  echo \"$as_me:17625: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:17627: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:17628: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:17630: \\$? = $ac_status\" >&5\n+  echo \"$as_me:17631: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   eval \"$as_ac_var=yes\"\n else\n@@ -17637,7 +17638,7 @@ eval \"$as_ac_var=no\"\n fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n fi\n-echo \"$as_me:17640: result: `eval echo '${'$as_ac_var'}'`\" >&5\n+echo \"$as_me:17641: result: `eval echo '${'$as_ac_var'}'`\" >&5\n echo \"${ECHO_T}`eval echo '${'$as_ac_var'}'`\" >&6\n if test `eval echo '${'$as_ac_var'}'` = yes; then\n   cat >>confdefs.h <<EOF\n@@ -17648,14 +17649,14 @@ fi\n done\n \n # use a compile-check to work with ncurses*-config and subdirectory includes\n-echo \"$as_me:17651: checking if we can use termcap.h\" >&5\n+echo \"$as_me:17652: checking if we can use termcap.h\" >&5\n echo $ECHO_N \"checking if we can use termcap.h... $ECHO_C\" >&6\n if test \"${cf_cv_have_termcap_h+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n \n \tcat >conftest.$ac_ext <<_ACEOF\n-#line 17658 \"configure\"\n+#line 17659 \"configure\"\n #include \"confdefs.h\"\n \n #include <curses.h>\n@@ -17676,16 +17677,16 @@ return 0;\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:17679: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:17680: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:17682: \\$? = $ac_status\" >&5\n+  echo \"$as_me:17683: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:17685: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:17686: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:17688: \\$? = $ac_status\" >&5\n+  echo \"$as_me:17689: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_have_termcap_h=yes\n else\n@@ -17695,7 +17696,7 @@ cf_cv_have_termcap_h=no\n fi\n rm -f conftest.$ac_objext conftest.$ac_ext\n fi\n-echo \"$as_me:17698: result: $cf_cv_have_termcap_h\" >&5\n+echo \"$as_me:17699: result: $cf_cv_have_termcap_h\" >&5\n echo \"${ECHO_T}$cf_cv_have_termcap_h\" >&6\n if test \"x$cf_cv_have_termcap_h\" = xyes\n then\n@@ -17705,14 +17706,14 @@ cat >>confdefs.h <<\\EOF\n EOF\n \n else\n-echo \"$as_me:17708: checking if we can use ncurses/termcap.h\" >&5\n+echo \"$as_me:17709: checking if we can use ncurses/termcap.h\" >&5\n echo $ECHO_N \"checking if we can use ncurses/termcap.h... $ECHO_C\" >&6\n if test \"${cf_cv_have_ncurses_termcap_h+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n \n \tcat >conftest.$ac_ext <<_ACEOF\n-#line 17715 \"configure\"\n+#line 17716 \"configure\"\n #include \"confdefs.h\"\n \n #include <ncurses/curses.h>\n@@ -17733,16 +17734,16 @@ return 0;\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:17736: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:17737: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:17739: \\$? = $ac_status\" >&5\n+  echo \"$as_me:17740: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:17742: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:17743: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:17745: \\$? = $ac_status\" >&5\n+  echo \"$as_me:17746: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_have_ncurses_termcap_h=yes\n else\n@@ -17752,7 +17753,7 @@ cf_cv_have_ncurses_termcap_h=no\n fi\n rm -f conftest.$ac_objext conftest.$ac_ext\n fi\n-echo \"$as_me:17755: result: $cf_cv_have_ncurses_termcap_h\" >&5\n+echo \"$as_me:17756: result: $cf_cv_have_ncurses_termcap_h\" >&5\n echo \"${ECHO_T}$cf_cv_have_ncurses_termcap_h\" >&6\n test \"x$cf_cv_have_ncurses_termcap_h\" = xyes &&\n cat >>confdefs.h <<\\EOF\n@@ -17762,7 +17763,7 @@ EOF\n fi\n \n if test \"x$ac_cv_func_getopt\" = xno; then\n-\t{ { echo \"$as_me:17765: error: getopt is required for building programs\" >&5\n+\t{ { echo \"$as_me:17766: error: getopt is required for building programs\" >&5\n echo \"$as_me: error: getopt is required for building programs\" >&2;}\n    { (exit 1); exit 1; }; }\n fi\n@@ -17781,13 +17782,13 @@ wcstombs \\\n \n do\n as_ac_var=`echo \"ac_cv_func_$ac_func\" | $as_tr_sh`\n-echo \"$as_me:17784: checking for $ac_func\" >&5\n+echo \"$as_me:17785: checking for $ac_func\" >&5\n echo $ECHO_N \"checking for $ac_func... $ECHO_C\" >&6\n if eval \"test \\\"\\${$as_ac_var+set}\\\" = set\"; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 17790 \"configure\"\n+#line 17791 \"configure\"\n #include \"confdefs.h\"\n #define $ac_func autoconf_temporary\n #include <limits.h>\t/* least-intrusive standard header which defines gcc2 __stub macros */\n@@ -17818,16 +17819,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:17821: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:17822: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:17824: \\$? = $ac_status\" >&5\n+  echo \"$as_me:17825: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:17827: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:17828: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:17830: \\$? = $ac_status\" >&5\n+  echo \"$as_me:17831: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   eval \"$as_ac_var=yes\"\n else\n@@ -17837,7 +17838,7 @@ eval \"$as_ac_var=no\"\n fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n fi\n-echo \"$as_me:17840: result: `eval echo '${'$as_ac_var'}'`\" >&5\n+echo \"$as_me:17841: result: `eval echo '${'$as_ac_var'}'`\" >&5\n echo \"${ECHO_T}`eval echo '${'$as_ac_var'}'`\" >&6\n if test `eval echo '${'$as_ac_var'}'` = yes; then\n   cat >>confdefs.h <<EOF\n@@ -17849,7 +17850,7 @@ done\n \n fi\n \n-echo \"$as_me:17852: checking definition to turn on extended curses functions\" >&5\n+echo \"$as_me:17853: checking definition to turn on extended curses functions\" >&5\n echo $ECHO_N \"checking definition to turn on extended curses functions... $ECHO_C\" >&6\n if test \"${cf_cv_need_xopen_extension+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -17857,7 +17858,7 @@ else\n \n cf_cv_need_xopen_extension=unknown\n cat >conftest.$ac_ext <<_ACEOF\n-#line 17860 \"configure\"\n+#line 17861 \"configure\"\n #include \"confdefs.h\"\n \n #include <stdlib.h>\n@@ -17890,16 +17891,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:17893: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:17894: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:17896: \\$? = $ac_status\" >&5\n+  echo \"$as_me:17897: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:17899: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:17900: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:17902: \\$? = $ac_status\" >&5\n+  echo \"$as_me:17903: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_need_xopen_extension=none\n else\n@@ -17909,7 +17910,7 @@ cat conftest.$ac_ext >&5\n \tfor cf_try_xopen_extension in _XOPEN_SOURCE_EXTENDED NCURSES_WIDECHAR\n \tdo\n \t\tcat >conftest.$ac_ext <<_ACEOF\n-#line 17912 \"configure\"\n+#line 17913 \"configure\"\n #include \"confdefs.h\"\n \n #define $cf_try_xopen_extension 1\n@@ -17938,16 +17939,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:17941: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:17942: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:17944: \\$? = $ac_status\" >&5\n+  echo \"$as_me:17945: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:17947: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:17948: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:17950: \\$? = $ac_status\" >&5\n+  echo \"$as_me:17951: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_need_xopen_extension=$cf_try_xopen_extension; break\n else\n@@ -17961,7 +17962,7 @@ fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n \n fi\n-echo \"$as_me:17964: result: $cf_cv_need_xopen_extension\" >&5\n+echo \"$as_me:17965: result: $cf_cv_need_xopen_extension\" >&5\n echo \"${ECHO_T}$cf_cv_need_xopen_extension\" >&6\n \n case $cf_cv_need_xopen_extension in\n@@ -17973,7 +17974,7 @@ case $cf_cv_need_xopen_extension in\n \t;;\n esac\n \n-echo \"$as_me:17976: checking for term.h\" >&5\n+echo \"$as_me:17977: checking for term.h\" >&5\n echo $ECHO_N \"checking for term.h... $ECHO_C\" >&6\n if test \"${cf_cv_term_header+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -17994,7 +17995,7 @@ esac\n for cf_header in $cf_header_list\n do\n \tcat >conftest.$ac_ext <<_ACEOF\n-#line 17997 \"configure\"\n+#line 17998 \"configure\"\n #include \"confdefs.h\"\n \n #include <${cf_cv_ncurses_header:-curses.h}>\n@@ -18008,16 +18009,16 @@ WINDOW *x; (void)x\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:18011: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:18012: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18014: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18015: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:18017: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:18018: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18020: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18021: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_term_header=$cf_header\n \t break\n@@ -18036,7 +18037,7 @@ case $cf_cv_term_header in\n \tfor cf_header in ncurses/term.h ncursesw/term.h\n \tdo\n \t\tcat >conftest.$ac_ext <<_ACEOF\n-#line 18039 \"configure\"\n+#line 18040 \"configure\"\n #include \"confdefs.h\"\n \n #include <${cf_cv_ncurses_header:-curses.h}>\n@@ -18054,16 +18055,16 @@ WINDOW *x; (void)x\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:18057: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:18058: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18060: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18061: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:18063: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:18064: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18066: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18067: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_term_header=$cf_header\n \t\t\t break\n@@ -18078,7 +18079,7 @@ rm -f conftest.$ac_objext conftest.$ac_ext\n esac\n \n fi\n-echo \"$as_me:18081: result: $cf_cv_term_header\" >&5\n+echo \"$as_me:18082: result: $cf_cv_term_header\" >&5\n echo \"${ECHO_T}$cf_cv_term_header\" >&6\n \n case $cf_cv_term_header in\n@@ -18105,7 +18106,7 @@ EOF\n \t;;\n esac\n \n-echo \"$as_me:18108: checking for unctrl.h\" >&5\n+echo \"$as_me:18109: checking for unctrl.h\" >&5\n echo $ECHO_N \"checking for unctrl.h... $ECHO_C\" >&6\n if test \"${cf_cv_unctrl_header+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -18126,7 +18127,7 @@ esac\n for cf_header in $cf_header_list\n do\n \tcat >conftest.$ac_ext <<_ACEOF\n-#line 18129 \"configure\"\n+#line 18130 \"configure\"\n #include \"confdefs.h\"\n \n #include <${cf_cv_ncurses_header:-curses.h}>\n@@ -18140,16 +18141,16 @@ WINDOW *x; (void)x\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:18143: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:18144: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18146: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18147: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:18149: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:18150: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18152: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18153: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_unctrl_header=$cf_header\n \t break\n@@ -18162,12 +18163,12 @@ rm -f conftest.$ac_objext conftest.$ac_ext\n done\n \n fi\n-echo \"$as_me:18165: result: $cf_cv_unctrl_header\" >&5\n+echo \"$as_me:18166: result: $cf_cv_unctrl_header\" >&5\n echo \"${ECHO_T}$cf_cv_unctrl_header\" >&6\n \n case $cf_cv_unctrl_header in\n (no)\n-\t{ echo \"$as_me:18170: WARNING: unctrl.h header not found\" >&5\n+\t{ echo \"$as_me:18171: WARNING: unctrl.h header not found\" >&5\n echo \"$as_me: WARNING: unctrl.h header not found\" >&2;}\n \t;;\n esac\n@@ -18256,10 +18257,10 @@ do\n \n cf_tr_func=`echo \"$cf_func\" | sed y%abcdefghijklmnopqrstuvwxyz./-%ABCDEFGHIJKLMNOPQRSTUVWXYZ___%`\n \n-\techo \"$as_me:18259: checking for ${cf_func}\" >&5\n+\techo \"$as_me:18260: checking for ${cf_func}\" >&5\n echo $ECHO_N \"checking for ${cf_func}... $ECHO_C\" >&6\n \n-echo \"${as_me:-configure}:18262: testing ${cf_func} ...\" 1>&5\n+echo \"${as_me:-configure}:18263: testing ${cf_func} ...\" 1>&5\n \n \tif eval \"test \\\"\\${cf_cv_func_$cf_func+set}\\\" = set\"; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -18268,7 +18269,7 @@ else\n \t\teval cf_result='$ac_cv_func_'$cf_func\n \t\tif test \".$cf_result\" != \".no\"; then\n \t\t\tcat >conftest.$ac_ext <<_ACEOF\n-#line 18271 \"configure\"\n+#line 18272 \"configure\"\n #include \"confdefs.h\"\n \n #ifdef HAVE_XCURSES\n@@ -18301,16 +18302,16 @@ if (foo + 1234L > 5678L)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:18304: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:18305: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18307: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18308: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:18310: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:18311: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18313: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18314: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_result=yes\n else\n@@ -18326,7 +18327,7 @@ fi\n \n \t# use the computed/retrieved cache-value:\n \teval 'cf_result=$cf_cv_func_'$cf_func\n-\techo \"$as_me:18329: result: $cf_result\" >&5\n+\techo \"$as_me:18330: result: $cf_result\" >&5\n echo \"${ECHO_T}$cf_result\" >&6\n \tif test $cf_result != no; then\n \t\tcat >>confdefs.h <<EOF\n@@ -18341,10 +18342,10 @@ do\n \n cf_tr_func=`echo \"$cf_func\" | sed y%abcdefghijklmnopqrstuvwxyz./-%ABCDEFGHIJKLMNOPQRSTUVWXYZ___%`\n \n-\techo \"$as_me:18344: checking for ${cf_func}\" >&5\n+\techo \"$as_me:18345: checking for ${cf_func}\" >&5\n echo $ECHO_N \"checking for ${cf_func}... $ECHO_C\" >&6\n \n-echo \"${as_me:-configure}:18347: testing ${cf_func} ...\" 1>&5\n+echo \"${as_me:-configure}:18348: testing ${cf_func} ...\" 1>&5\n \n \tif eval \"test \\\"\\${cf_cv_func_$cf_func+set}\\\" = set\"; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -18353,7 +18354,7 @@ else\n \t\teval cf_result='$ac_cv_func_'$cf_func\n \t\tif test \".$cf_result\" != \".no\"; then\n \t\t\tcat >conftest.$ac_ext <<_ACEOF\n-#line 18356 \"configure\"\n+#line 18357 \"configure\"\n #include \"confdefs.h\"\n \n #ifdef HAVE_XCURSES\n@@ -18386,16 +18387,16 @@ if (foo + 1234L > 5678L)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:18389: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:18390: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18392: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18393: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:18395: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:18396: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18398: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18399: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_result=yes\n else\n@@ -18411,7 +18412,7 @@ fi\n \n \t# use the computed/retrieved cache-value:\n \teval 'cf_result=$cf_cv_func_'$cf_func\n-\techo \"$as_me:18414: result: $cf_result\" >&5\n+\techo \"$as_me:18415: result: $cf_result\" >&5\n echo \"${ECHO_T}$cf_result\" >&6\n \tif test $cf_result != no; then\n \t\tcat >>confdefs.h <<EOF\n@@ -18435,7 +18436,7 @@ then\n \t\t\t\tcf_return=\"return value\"\n \t\t\tfi\n \t\t\tcat >conftest.$ac_ext <<_ACEOF\n-#line 18438 \"configure\"\n+#line 18439 \"configure\"\n #include \"confdefs.h\"\n \n #include <${cf_cv_ncurses_header:-curses.h}>\n@@ -18455,21 +18456,21 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:18458: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:18459: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18461: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18462: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:18464: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:18465: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18467: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18468: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n \n \t\ttest -n \"$verbose\" && echo \"\tprototype $cf_ret func($cf_arg value)\" 1>&6\n \n-echo \"${as_me:-configure}:18472: testing prototype $cf_ret func($cf_arg value) ...\" 1>&5\n+echo \"${as_me:-configure}:18473: testing prototype $cf_ret func($cf_arg value) ...\" 1>&5\n \n \t\tcat >>confdefs.h <<EOF\n #define TPUTS_ARG               $cf_arg\n@@ -18489,14 +18490,14 @@ rm -f conftest.$ac_objext conftest.$ac_ext\n \tdone\n fi\n \n-echo \"$as_me:18492: checking for ncurses extended functions\" >&5\n+echo \"$as_me:18493: checking for ncurses extended functions\" >&5\n echo $ECHO_N \"checking for ncurses extended functions... $ECHO_C\" >&6\n if test \"${cf_cv_ncurses_ext_funcs+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n \n cat >conftest.$ac_ext <<_ACEOF\n-#line 18499 \"configure\"\n+#line 18500 \"configure\"\n #include \"confdefs.h\"\n \n #include <${cf_cv_ncurses_header:-curses.h}>\n@@ -18511,16 +18512,16 @@ int x = NCURSES_EXT_FUNCS\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:18514: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:18515: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18517: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18518: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:18520: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:18521: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18523: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18524: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_ncurses_ext_funcs=defined\n else\n@@ -18528,7 +18529,7 @@ else\n cat conftest.$ac_ext >&5\n \n cat >conftest.$ac_ext <<_ACEOF\n-#line 18531 \"configure\"\n+#line 18532 \"configure\"\n #include \"confdefs.h\"\n \n #include <${cf_cv_ncurses_header:-curses.h}>\n@@ -18553,16 +18554,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:18556: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:18557: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18559: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18560: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:18562: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:18563: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18565: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18566: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_ncurses_ext_funcs=yes\n else\n@@ -18576,7 +18577,7 @@ fi\n rm -f conftest.$ac_objext conftest.$ac_ext\n \n fi\n-echo \"$as_me:18579: result: $cf_cv_ncurses_ext_funcs\" >&5\n+echo \"$as_me:18580: result: $cf_cv_ncurses_ext_funcs\" >&5\n echo \"${ECHO_T}$cf_cv_ncurses_ext_funcs\" >&6\n test \"$cf_cv_ncurses_ext_funcs\" = yes &&\n cat >>confdefs.h <<\\EOF\n@@ -18590,11 +18591,11 @@ then\n \tif test -n \"$cf_cv_ncurses_version\" && test \"x$cf_cv_ncurses_version\" != xno\n \tthen\n \t\tcf_define_xpg5=no\n-\t\techo \"$as_me:18593: checking if _XPG5 should be defined to enable wide-characters\" >&5\n+\t\techo \"$as_me:18594: checking if _XPG5 should be defined to enable wide-characters\" >&5\n echo $ECHO_N \"checking if _XPG5 should be defined to enable wide-characters... $ECHO_C\" >&6\n \n \t\tcat >conftest.$ac_ext <<_ACEOF\n-#line 18597 \"configure\"\n+#line 18598 \"configure\"\n #include \"confdefs.h\"\n \n #include <${cf_cv_ncurses_header:-curses.h}>\n@@ -18607,16 +18608,16 @@ int x = _XPG5\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:18610: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:18611: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18613: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18614: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:18616: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:18617: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18619: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18620: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   :\n else\n@@ -18625,7 +18626,7 @@ cat conftest.$ac_ext >&5\n cf_save_cppflags=\"$CPPFLAGS\"\n \t\t\t CPPFLAGS=\"$CPPFLAGS -D_XPG5\"\n \t\t\t cat >conftest.$ac_ext <<_ACEOF\n-#line 18628 \"configure\"\n+#line 18629 \"configure\"\n #include \"confdefs.h\"\n \n #include <${cf_cv_ncurses_header:-curses.h}>\n@@ -18638,16 +18639,16 @@ int x = _XPG5\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:18641: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:18642: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18644: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18645: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:18647: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:18648: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18650: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18651: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_define_xpg5=yes\n else\n@@ -18658,7 +18659,7 @@ rm -f conftest.$ac_objext conftest.$ac_ext\n \t\t\t CPPFLAGS=\"$cf_save_cppflags\"\n fi\n rm -f conftest.$ac_objext conftest.$ac_ext\n-\t\techo \"$as_me:18661: result: $cf_define_xpg5\" >&5\n+\t\techo \"$as_me:18662: result: $cf_define_xpg5\" >&5\n echo \"${ECHO_T}$cf_define_xpg5\" >&6\n \n \t\tif test \"$cf_define_xpg5\" = yes\n@@ -18667,14 +18668,14 @@ echo \"${ECHO_T}$cf_define_xpg5\" >&6\n \t\tfi\n \tfi\n \n-\techo \"$as_me:18670: checking for wide-character functions\" >&5\n+\techo \"$as_me:18671: checking for wide-character functions\" >&5\n echo $ECHO_N \"checking for wide-character functions... $ECHO_C\" >&6\n if test \"${cf_cv_widechar_funcs+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n \n \tcat >conftest.$ac_ext <<_ACEOF\n-#line 18677 \"configure\"\n+#line 18678 \"configure\"\n #include \"confdefs.h\"\n \n #include <${cf_cv_ncurses_header:-curses.h}>\n@@ -18691,16 +18692,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:18694: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:18695: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18697: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18698: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:18700: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:18701: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18703: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18704: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_widechar_funcs=yes\n else\n@@ -18711,7 +18712,7 @@ fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n \n fi\n-echo \"$as_me:18714: result: $cf_cv_widechar_funcs\" >&5\n+echo \"$as_me:18715: result: $cf_cv_widechar_funcs\" >&5\n echo \"${ECHO_T}$cf_cv_widechar_funcs\" >&6\n \tif test \"$cf_cv_widechar_funcs\" != no ; then\n \n@@ -18732,14 +18733,14 @@ EOF\n \n fi\n \n-echo \"$as_me:18735: checking if $cf_cv_screen library uses pthreads\" >&5\n+echo \"$as_me:18736: checking if $cf_cv_screen library uses pthreads\" >&5\n echo $ECHO_N \"checking if $cf_cv_screen library uses pthreads... $ECHO_C\" >&6\n if test \"${cf_cv_use_pthreads+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n \n cat >conftest.$ac_ext <<_ACEOF\n-#line 18742 \"configure\"\n+#line 18743 \"configure\"\n #include \"confdefs.h\"\n \n #include <${cf_cv_ncurses_header:-curses.h}>\n@@ -18757,16 +18758,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:18760: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:18761: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18763: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18764: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:18766: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:18767: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18769: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18770: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_use_pthreads=yes\n else\n@@ -18777,21 +18778,21 @@ fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n \n fi\n-echo \"$as_me:18780: result: $cf_cv_use_pthreads\" >&5\n+echo \"$as_me:18781: result: $cf_cv_use_pthreads\" >&5\n echo \"${ECHO_T}$cf_cv_use_pthreads\" >&6\n test $cf_cv_use_pthreads = yes &&\n cat >>confdefs.h <<\\EOF\n #define USE_PTHREADS 1\n EOF\n \n-echo \"$as_me:18787: checking if sys/time.h works with sys/select.h\" >&5\n+echo \"$as_me:18788: checking if sys/time.h works with sys/select.h\" >&5\n echo $ECHO_N \"checking if sys/time.h works with sys/select.h... $ECHO_C\" >&6\n if test \"${cf_cv_sys_time_select+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n \n cat >conftest.$ac_ext <<_ACEOF\n-#line 18794 \"configure\"\n+#line 18795 \"configure\"\n #include \"confdefs.h\"\n \n #include <sys/types.h>\n@@ -18811,16 +18812,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:18814: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:18815: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18817: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18818: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:18820: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:18821: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18823: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18824: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_sys_time_select=yes\n else\n@@ -18832,7 +18833,7 @@ rm -f conftest.$ac_objext conftest.$ac_ext\n \n fi\n \n-echo \"$as_me:18835: result: $cf_cv_sys_time_select\" >&5\n+echo \"$as_me:18836: result: $cf_cv_sys_time_select\" >&5\n echo \"${ECHO_T}$cf_cv_sys_time_select\" >&6\n test \"$cf_cv_sys_time_select\" = yes &&\n cat >>confdefs.h <<\\EOF\n@@ -18841,7 +18842,7 @@ EOF\n \n # special check for test/ditto.c\n \n-echo \"$as_me:18844: checking for openpty in -lutil\" >&5\n+echo \"$as_me:18845: checking for openpty in -lutil\" >&5\n echo $ECHO_N \"checking for openpty in -lutil... $ECHO_C\" >&6\n if test \"${ac_cv_lib_util_openpty+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -18849,7 +18850,7 @@ else\n   ac_check_lib_save_LIBS=$LIBS\n LIBS=\"-lutil  $LIBS\"\n cat >conftest.$ac_ext <<_ACEOF\n-#line 18852 \"configure\"\n+#line 18853 \"configure\"\n #include \"confdefs.h\"\n \n /* Override any gcc2 internal prototype to avoid an error.  */\n@@ -18868,16 +18869,16 @@ openpty ();\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:18871: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:18872: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18874: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18875: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:18877: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:18878: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18880: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18881: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   ac_cv_lib_util_openpty=yes\n else\n@@ -18888,7 +18889,7 @@ fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n LIBS=$ac_check_lib_save_LIBS\n fi\n-echo \"$as_me:18891: result: $ac_cv_lib_util_openpty\" >&5\n+echo \"$as_me:18892: result: $ac_cv_lib_util_openpty\" >&5\n echo \"${ECHO_T}$ac_cv_lib_util_openpty\" >&6\n if test $ac_cv_lib_util_openpty = yes; then\n   cf_cv_lib_util=yes\n@@ -18896,7 +18897,7 @@ else\n   cf_cv_lib_util=no\n fi\n \n-echo \"$as_me:18899: checking for openpty header\" >&5\n+echo \"$as_me:18900: checking for openpty header\" >&5\n echo $ECHO_N \"checking for openpty header... $ECHO_C\" >&6\n if test \"${cf_cv_func_openpty+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -18923,7 +18924,7 @@ LIBS=\"$cf_add_libs\"\n \tfor cf_header in pty.h libutil.h util.h\n \tdo\n \tcat >conftest.$ac_ext <<_ACEOF\n-#line 18926 \"configure\"\n+#line 18927 \"configure\"\n #include \"confdefs.h\"\n \n #include <$cf_header>\n@@ -18940,16 +18941,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:18943: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:18944: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18946: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18947: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:18949: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:18950: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:18952: \\$? = $ac_status\" >&5\n+  echo \"$as_me:18953: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n \n \t\tcf_cv_func_openpty=$cf_header\n@@ -18967,7 +18968,7 @@ rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n \tLIBS=\"$cf_save_LIBS\"\n \n fi\n-echo \"$as_me:18970: result: $cf_cv_func_openpty\" >&5\n+echo \"$as_me:18971: result: $cf_cv_func_openpty\" >&5\n echo \"${ECHO_T}$cf_cv_func_openpty\" >&6\n \n if test \"$cf_cv_func_openpty\" != no ; then\n@@ -19001,7 +19002,7 @@ TEST_LIBS=\"$cf_add_libs\"\n \tfi\n fi\n \n-echo \"$as_me:19004: checking for function curses_version\" >&5\n+echo \"$as_me:19005: checking for function curses_version\" >&5\n echo $ECHO_N \"checking for function curses_version... $ECHO_C\" >&6\n if test \"${cf_cv_func_curses_version+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -19011,7 +19012,7 @@ if test \"$cross_compiling\" = yes; then\n   cf_cv_func_curses_version=unknown\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 19014 \"configure\"\n+#line 19015 \"configure\"\n #include \"confdefs.h\"\n \n #include <${cf_cv_ncurses_header:-curses.h}>\n@@ -19024,15 +19025,15 @@ int main(void)\n \n _ACEOF\n rm -f conftest$ac_exeext\n-if { (eval echo \"$as_me:19027: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:19028: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19030: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19031: \\$? = $ac_status\" >&5\n   (exit $ac_status); } && { ac_try='./conftest$ac_exeext'\n-  { (eval echo \"$as_me:19032: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:19033: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19035: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19036: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_func_curses_version=yes\n \n@@ -19047,14 +19048,14 @@ rm -f core core.* *.core conftest$ac_exeext conftest.$ac_objext conftest.$ac_ext\n fi\n rm -f core\n fi\n-echo \"$as_me:19050: result: $cf_cv_func_curses_version\" >&5\n+echo \"$as_me:19051: result: $cf_cv_func_curses_version\" >&5\n echo \"${ECHO_T}$cf_cv_func_curses_version\" >&6\n test \"$cf_cv_func_curses_version\" = yes &&\n cat >>confdefs.h <<\\EOF\n #define HAVE_CURSES_VERSION 1\n EOF\n \n-echo \"$as_me:19057: checking for alternate character set array\" >&5\n+echo \"$as_me:19058: checking for alternate character set array\" >&5\n echo $ECHO_N \"checking for alternate character set array... $ECHO_C\" >&6\n if test \"${cf_cv_curses_acs_map+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -19064,7 +19065,7 @@ cf_cv_curses_acs_map=unknown\n for name in acs_map _acs_map __acs_map ${NCURSES_WRAP_PREFIX}acs_map\n do\n cat >conftest.$ac_ext <<_ACEOF\n-#line 19067 \"configure\"\n+#line 19068 \"configure\"\n #include \"confdefs.h\"\n \n #include <${cf_cv_ncurses_header:-curses.h}>\n@@ -19080,16 +19081,16 @@ $name['k'] = ACS_PLUS\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:19083: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:19084: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19086: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19087: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:19089: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:19090: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19092: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19093: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_curses_acs_map=$name; break\n else\n@@ -19100,7 +19101,7 @@ rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n done\n \n fi\n-echo \"$as_me:19103: result: $cf_cv_curses_acs_map\" >&5\n+echo \"$as_me:19104: result: $cf_cv_curses_acs_map\" >&5\n echo \"${ECHO_T}$cf_cv_curses_acs_map\" >&6\n \n test \"$cf_cv_curses_acs_map\" != unknown &&\n@@ -19110,7 +19111,7 @@ EOF\n \n if test \"$cf_enable_widec\" = yes; then\n \n-echo \"$as_me:19113: checking for wide alternate character set array\" >&5\n+echo \"$as_me:19114: checking for wide alternate character set array\" >&5\n echo $ECHO_N \"checking for wide alternate character set array... $ECHO_C\" >&6\n if test \"${cf_cv_curses_wacs_map+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -19120,7 +19121,7 @@ else\n \tfor name in wacs_map _wacs_map __wacs_map _nc_wacs _wacs_char\n \tdo\n \tcat >conftest.$ac_ext <<_ACEOF\n-#line 19123 \"configure\"\n+#line 19124 \"configure\"\n #include \"confdefs.h\"\n \n #ifndef _XOPEN_SOURCE_EXTENDED\n@@ -19136,16 +19137,16 @@ void *foo = &($name['k']); (void)foo\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:19139: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:19140: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19142: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19143: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:19145: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:19146: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19148: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19149: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_curses_wacs_map=$name\n \t break\n@@ -19156,7 +19157,7 @@ fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n \tdone\n fi\n-echo \"$as_me:19159: result: $cf_cv_curses_wacs_map\" >&5\n+echo \"$as_me:19160: result: $cf_cv_curses_wacs_map\" >&5\n echo \"${ECHO_T}$cf_cv_curses_wacs_map\" >&6\n \n test \"$cf_cv_curses_wacs_map\" != unknown &&\n@@ -19164,7 +19165,7 @@ cat >>confdefs.h <<EOF\n #define CURSES_WACS_ARRAY $cf_cv_curses_wacs_map\n EOF\n \n-echo \"$as_me:19167: checking for wide alternate character constants\" >&5\n+echo \"$as_me:19168: checking for wide alternate character constants\" >&5\n echo $ECHO_N \"checking for wide alternate character constants... $ECHO_C\" >&6\n if test \"${cf_cv_curses_wacs_symbols+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -19174,7 +19175,7 @@ cf_cv_curses_wacs_symbols=no\n if test \"$cf_cv_curses_wacs_map\" != unknown\n then\n \tcat >conftest.$ac_ext <<_ACEOF\n-#line 19177 \"configure\"\n+#line 19178 \"configure\"\n #include \"confdefs.h\"\n \n #ifndef _XOPEN_SOURCE_EXTENDED\n@@ -19191,16 +19192,16 @@ cchar_t *foo = WACS_PLUS;\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:19194: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:19195: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19197: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19198: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:19200: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:19201: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19203: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19204: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_curses_wacs_symbols=yes\n else\n@@ -19210,7 +19211,7 @@ fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n else\n \tcat >conftest.$ac_ext <<_ACEOF\n-#line 19213 \"configure\"\n+#line 19214 \"configure\"\n #include \"confdefs.h\"\n \n #ifndef _XOPEN_SOURCE_EXTENDED\n@@ -19226,16 +19227,16 @@ cchar_t *foo = WACS_PLUS; (void)foo\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:19229: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:19230: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19232: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19233: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:19235: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:19236: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19238: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19239: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_curses_wacs_symbols=yes\n else\n@@ -19246,7 +19247,7 @@ rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n fi\n \n fi\n-echo \"$as_me:19249: result: $cf_cv_curses_wacs_symbols\" >&5\n+echo \"$as_me:19250: result: $cf_cv_curses_wacs_symbols\" >&5\n echo \"${ECHO_T}$cf_cv_curses_wacs_symbols\" >&6\n \n test \"$cf_cv_curses_wacs_symbols\" != no &&\n@@ -19256,10 +19257,10 @@ EOF\n \n fi\n \n-echo \"$as_me:19259: checking for type attr_t in ${cf_cv_ncurses_header:-curses.h}\" >&5\n+echo \"$as_me:19260: checking for type attr_t in ${cf_cv_ncurses_header:-curses.h}\" >&5\n echo $ECHO_N \"checking for type attr_t in ${cf_cv_ncurses_header:-curses.h}... $ECHO_C\" >&6\n cat >conftest.$ac_ext <<_ACEOF\n-#line 19262 \"configure\"\n+#line 19263 \"configure\"\n #include \"confdefs.h\"\n \n #ifndef _XOPEN_SOURCE_EXTENDED\n@@ -19277,16 +19278,16 @@ attr_t foo\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:19280: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:19281: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19283: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19284: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:19286: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:19287: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19289: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19290: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_result=yes\n else\n@@ -19295,7 +19296,7 @@ cat conftest.$ac_ext >&5\n cf_result=no\n fi\n rm -f conftest.$ac_objext conftest.$ac_ext\n-echo \"$as_me:19298: result: $cf_result\" >&5\n+echo \"$as_me:19299: result: $cf_result\" >&5\n echo \"${ECHO_T}$cf_result\" >&6\n if test $cf_result = yes ; then\n \n@@ -19316,14 +19317,14 @@ fi\n if test \"$cf_enable_widec\" = yes; then\n \n # This is needed on Tru64 5.0 to declare mbstate_t\n-echo \"$as_me:19319: checking if we must include wchar.h to declare mbstate_t\" >&5\n+echo \"$as_me:19320: checking if we must include wchar.h to declare mbstate_t\" >&5\n echo $ECHO_N \"checking if we must include wchar.h to declare mbstate_t... $ECHO_C\" >&6\n if test \"${cf_cv_mbstate_t+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n \n cat >conftest.$ac_ext <<_ACEOF\n-#line 19326 \"configure\"\n+#line 19327 \"configure\"\n #include \"confdefs.h\"\n \n #include <stdlib.h>\n@@ -19341,23 +19342,23 @@ mbstate_t state\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:19344: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:19345: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19347: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19348: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:19350: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:19351: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19353: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19354: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_mbstate_t=no\n else\n   echo \"$as_me: failed program was:\" >&5\n cat conftest.$ac_ext >&5\n cat >conftest.$ac_ext <<_ACEOF\n-#line 19360 \"configure\"\n+#line 19361 \"configure\"\n #include \"confdefs.h\"\n \n #include <stdlib.h>\n@@ -19376,16 +19377,16 @@ mbstate_t value\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:19379: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:19380: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19382: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19383: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:19385: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:19386: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19388: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19389: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_mbstate_t=yes\n else\n@@ -19397,7 +19398,7 @@ rm -f conftest.$ac_objext conftest.$ac_ext\n fi\n rm -f conftest.$ac_objext conftest.$ac_ext\n fi\n-echo \"$as_me:19400: result: $cf_cv_mbstate_t\" >&5\n+echo \"$as_me:19401: result: $cf_cv_mbstate_t\" >&5\n echo \"${ECHO_T}$cf_cv_mbstate_t\" >&6\n \n if test \"$cf_cv_mbstate_t\" = yes ; then\n@@ -19420,14 +19421,14 @@ if test \"$cf_cv_mbstate_t\" != unknown ; then\n fi\n \n # This is needed on Tru64 5.0 to declare wchar_t\n-echo \"$as_me:19423: checking if we must include wchar.h to declare wchar_t\" >&5\n+echo \"$as_me:19424: checking if we must include wchar.h to declare wchar_t\" >&5\n echo $ECHO_N \"checking if we must include wchar.h to declare wchar_t... $ECHO_C\" >&6\n if test \"${cf_cv_wchar_t+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n \n cat >conftest.$ac_ext <<_ACEOF\n-#line 19430 \"configure\"\n+#line 19431 \"configure\"\n #include \"confdefs.h\"\n \n #include <stdlib.h>\n@@ -19445,23 +19446,23 @@ wchar_t state\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:19448: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:19449: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19451: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19452: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:19454: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:19455: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19457: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19458: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_wchar_t=no\n else\n   echo \"$as_me: failed program was:\" >&5\n cat conftest.$ac_ext >&5\n cat >conftest.$ac_ext <<_ACEOF\n-#line 19464 \"configure\"\n+#line 19465 \"configure\"\n #include \"confdefs.h\"\n \n #include <stdlib.h>\n@@ -19480,16 +19481,16 @@ wchar_t value\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:19483: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:19484: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19486: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19487: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:19489: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:19490: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19492: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19493: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_wchar_t=yes\n else\n@@ -19501,7 +19502,7 @@ rm -f conftest.$ac_objext conftest.$ac_ext\n fi\n rm -f conftest.$ac_objext conftest.$ac_ext\n fi\n-echo \"$as_me:19504: result: $cf_cv_wchar_t\" >&5\n+echo \"$as_me:19505: result: $cf_cv_wchar_t\" >&5\n echo \"${ECHO_T}$cf_cv_wchar_t\" >&6\n \n if test \"$cf_cv_wchar_t\" = yes ; then\n@@ -19524,14 +19525,14 @@ if test \"$cf_cv_wchar_t\" != unknown ; then\n fi\n \n # This is needed on Tru64 5.0 to declare wint_t\n-echo \"$as_me:19527: checking if we must include wchar.h to declare wint_t\" >&5\n+echo \"$as_me:19528: checking if we must include wchar.h to declare wint_t\" >&5\n echo $ECHO_N \"checking if we must include wchar.h to declare wint_t... $ECHO_C\" >&6\n if test \"${cf_cv_wint_t+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n \n cat >conftest.$ac_ext <<_ACEOF\n-#line 19534 \"configure\"\n+#line 19535 \"configure\"\n #include \"confdefs.h\"\n \n #include <stdlib.h>\n@@ -19549,23 +19550,23 @@ wint_t state\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:19552: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:19553: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19555: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19556: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:19558: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:19559: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19561: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19562: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_wint_t=no\n else\n   echo \"$as_me: failed program was:\" >&5\n cat conftest.$ac_ext >&5\n cat >conftest.$ac_ext <<_ACEOF\n-#line 19568 \"configure\"\n+#line 19569 \"configure\"\n #include \"confdefs.h\"\n \n #include <stdlib.h>\n@@ -19584,16 +19585,16 @@ wint_t value\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:19587: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:19588: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19590: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19591: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:19593: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:19594: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19596: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19597: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_cv_wint_t=yes\n else\n@@ -19605,7 +19606,7 @@ rm -f conftest.$ac_objext conftest.$ac_ext\n fi\n rm -f conftest.$ac_objext conftest.$ac_ext\n fi\n-echo \"$as_me:19608: result: $cf_cv_wint_t\" >&5\n+echo \"$as_me:19609: result: $cf_cv_wint_t\" >&5\n echo \"${ECHO_T}$cf_cv_wint_t\" >&6\n \n if test \"$cf_cv_wint_t\" = yes ; then\n@@ -19629,10 +19630,10 @@ fi\n \n \tif test \"$NCURSES_OK_MBSTATE_T\" = 0 ; then\n \n-echo \"$as_me:19632: checking for type mbstate_t in ${cf_cv_ncurses_header:-curses.h}\" >&5\n+echo \"$as_me:19633: checking for type mbstate_t in ${cf_cv_ncurses_header:-curses.h}\" >&5\n echo $ECHO_N \"checking for type mbstate_t in ${cf_cv_ncurses_header:-curses.h}... $ECHO_C\" >&6\n cat >conftest.$ac_ext <<_ACEOF\n-#line 19635 \"configure\"\n+#line 19636 \"configure\"\n #include \"confdefs.h\"\n \n #ifndef _XOPEN_SOURCE_EXTENDED\n@@ -19650,16 +19651,16 @@ mbstate_t foo\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:19653: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:19654: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19656: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19657: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:19659: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:19660: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19662: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19663: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_result=yes\n else\n@@ -19668,7 +19669,7 @@ cat conftest.$ac_ext >&5\n cf_result=no\n fi\n rm -f conftest.$ac_objext conftest.$ac_ext\n-echo \"$as_me:19671: result: $cf_result\" >&5\n+echo \"$as_me:19672: result: $cf_result\" >&5\n echo \"${ECHO_T}$cf_result\" >&6\n if test $cf_result = yes ; then\n \n@@ -19690,10 +19691,10 @@ fi\n \n \tif test \"$NCURSES_OK_WCHAR_T\" = 0 ; then\n \n-echo \"$as_me:19693: checking for type wchar_t in ${cf_cv_ncurses_header:-curses.h}\" >&5\n+echo \"$as_me:19694: checking for type wchar_t in ${cf_cv_ncurses_header:-curses.h}\" >&5\n echo $ECHO_N \"checking for type wchar_t in ${cf_cv_ncurses_header:-curses.h}... $ECHO_C\" >&6\n cat >conftest.$ac_ext <<_ACEOF\n-#line 19696 \"configure\"\n+#line 19697 \"configure\"\n #include \"confdefs.h\"\n \n #ifndef _XOPEN_SOURCE_EXTENDED\n@@ -19711,16 +19712,16 @@ wchar_t foo\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:19714: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:19715: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19717: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19718: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:19720: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:19721: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19723: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19724: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_result=yes\n else\n@@ -19729,7 +19730,7 @@ cat conftest.$ac_ext >&5\n cf_result=no\n fi\n rm -f conftest.$ac_objext conftest.$ac_ext\n-echo \"$as_me:19732: result: $cf_result\" >&5\n+echo \"$as_me:19733: result: $cf_result\" >&5\n echo \"${ECHO_T}$cf_result\" >&6\n if test $cf_result = yes ; then\n \n@@ -19751,10 +19752,10 @@ fi\n \n \tif test \"$NCURSES_OK_WINT_T\" = 0 ; then\n \n-echo \"$as_me:19754: checking for type wint_t in ${cf_cv_ncurses_header:-curses.h}\" >&5\n+echo \"$as_me:19755: checking for type wint_t in ${cf_cv_ncurses_header:-curses.h}\" >&5\n echo $ECHO_N \"checking for type wint_t in ${cf_cv_ncurses_header:-curses.h}... $ECHO_C\" >&6\n cat >conftest.$ac_ext <<_ACEOF\n-#line 19757 \"configure\"\n+#line 19758 \"configure\"\n #include \"confdefs.h\"\n \n #ifndef _XOPEN_SOURCE_EXTENDED\n@@ -19772,16 +19773,16 @@ wint_t foo\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:19775: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:19776: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19778: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19779: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:19781: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:19782: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19784: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19785: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_result=yes\n else\n@@ -19790,7 +19791,7 @@ cat conftest.$ac_ext >&5\n cf_result=no\n fi\n rm -f conftest.$ac_objext conftest.$ac_ext\n-echo \"$as_me:19793: result: $cf_result\" >&5\n+echo \"$as_me:19794: result: $cf_result\" >&5\n echo \"${ECHO_T}$cf_result\" >&6\n if test $cf_result = yes ; then\n \n@@ -19819,11 +19820,11 @@ boolnames \\\n boolfnames \\\n ttytype\n do\n-echo \"$as_me:19822: checking for data $cf_data declaration in ${cf_cv_ncurses_header:-curses.h}\" >&5\n+echo \"$as_me:19823: checking for data $cf_data declaration in ${cf_cv_ncurses_header:-curses.h}\" >&5\n echo $ECHO_N \"checking for data $cf_data declaration in ${cf_cv_ncurses_header:-curses.h}... $ECHO_C\" >&6\n \n cat >conftest.$ac_ext <<_ACEOF\n-#line 19826 \"configure\"\n+#line 19827 \"configure\"\n #include \"confdefs.h\"\n \n #ifdef HAVE_XCURSES\n@@ -19856,16 +19857,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:19859: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:19860: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19862: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19863: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:19865: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:19866: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19868: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19869: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_result=yes\n \n@@ -19875,7 +19876,7 @@ cat conftest.$ac_ext >&5\n cf_result=no\n fi\n rm -f conftest.$ac_objext conftest.$ac_ext\n-echo \"$as_me:19878: result: $cf_result\" >&5\n+echo \"$as_me:19879: result: $cf_result\" >&5\n echo \"${ECHO_T}$cf_result\" >&6\n \n if test $cf_result = yes ; then\n@@ -19887,14 +19888,14 @@ cf_result=`echo \"have_curses_data_$cf_data\" | sed y%abcdefghijklmnopqrstuvwxyz./\n EOF\n \n else\n-\techo \"$as_me:19890: checking for data $cf_data in library\" >&5\n+\techo \"$as_me:19891: checking for data $cf_data in library\" >&5\n echo $ECHO_N \"checking for data $cf_data in library... $ECHO_C\" >&6\n \t# BSD linkers insist on making weak linkage, but resolve at runtime.\n \tif test \"$cross_compiling\" = yes; then\n \n \t# cross-compiling\n \tcat >conftest.$ac_ext <<_ACEOF\n-#line 19897 \"configure\"\n+#line 19898 \"configure\"\n #include \"confdefs.h\"\n \n #ifdef HAVE_XCURSES\n@@ -19933,16 +19934,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:19936: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:19937: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19939: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19940: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:19942: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:19943: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19945: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19946: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_result=yes\n else\n@@ -19954,7 +19955,7 @@ rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n \n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 19957 \"configure\"\n+#line 19958 \"configure\"\n #include \"confdefs.h\"\n \n #ifdef HAVE_XCURSES\n@@ -19986,15 +19987,15 @@ int main(void)\n }\n _ACEOF\n rm -f conftest$ac_exeext\n-if { (eval echo \"$as_me:19989: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:19990: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19992: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19993: \\$? = $ac_status\" >&5\n   (exit $ac_status); } && { ac_try='./conftest$ac_exeext'\n-  { (eval echo \"$as_me:19994: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:19995: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:19997: \\$? = $ac_status\" >&5\n+  echo \"$as_me:19998: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_result=yes\n \n@@ -20006,7 +20007,7 @@ cf_result=no\n fi\n rm -f core core.* *.core conftest$ac_exeext conftest.$ac_objext conftest.$ac_ext\n fi\n-\techo \"$as_me:20009: result: $cf_result\" >&5\n+\techo \"$as_me:20010: result: $cf_result\" >&5\n echo \"${ECHO_T}$cf_result\" >&6\n \tif test $cf_result = yes ; then\n \n@@ -20023,7 +20024,7 @@ done\n \n if ( test \"$GCC\" = yes || test \"$GXX\" = yes )\n then\n-echo \"$as_me:20026: checking if you want to turn on gcc warnings\" >&5\n+echo \"$as_me:20027: checking if you want to turn on gcc warnings\" >&5\n echo $ECHO_N \"checking if you want to turn on gcc warnings... $ECHO_C\" >&6\n \n # Check whether --enable-warnings or --disable-warnings was given.\n@@ -20040,7 +20041,7 @@ else\n \twith_warnings=no\n \n fi;\n-echo \"$as_me:20043: result: $with_warnings\" >&5\n+echo \"$as_me:20044: result: $with_warnings\" >&5\n echo \"${ECHO_T}$with_warnings\" >&6\n if test \"$with_warnings\" = \"yes\"\n then\n@@ -20063,10 +20064,10 @@ cat > conftest.i <<EOF\n EOF\n if test \"$GCC\" = yes\n then\n-\t{ echo \"$as_me:20066: checking for $CC __attribute__ directives...\" >&5\n+\t{ echo \"$as_me:20067: checking for $CC __attribute__ directives...\" >&5\n echo \"$as_me: checking for $CC __attribute__ directives...\" >&6;}\n cat > conftest.$ac_ext <<EOF\n-#line 20069 \"${as_me:-configure}\"\n+#line 20070 \"${as_me:-configure}\"\n #include \"confdefs.h\"\n #include \"conftest.h\"\n #include \"conftest.i\"\n@@ -20115,12 +20116,12 @@ EOF\n \t\t\t;;\n \t\tesac\n \n-\t\tif { (eval echo \"$as_me:20118: \\\"$ac_compile\\\"\") >&5\n+\t\tif { (eval echo \"$as_me:20119: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20121: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20122: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; then\n-\t\t\ttest -n \"$verbose\" && echo \"$as_me:20123: result: ... $cf_attribute\" >&5\n+\t\t\ttest -n \"$verbose\" && echo \"$as_me:20124: result: ... $cf_attribute\" >&5\n echo \"${ECHO_T}... $cf_attribute\" >&6\n \t\t\tcat conftest.h >>confdefs.h\n \t\t\tcase $cf_attribute in\n@@ -20198,7 +20199,7 @@ do\n done\n \n cat >conftest.$ac_ext <<_ACEOF\n-#line 20201 \"configure\"\n+#line 20202 \"configure\"\n #include \"confdefs.h\"\n \n #include <stdlib.h>\n@@ -20213,26 +20214,26 @@ String foo = malloc(1); (void)foo\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:20216: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:20217: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20219: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20220: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:20222: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:20223: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20225: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20226: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n \n-echo \"$as_me:20228: checking for X11/Xt const-feature\" >&5\n+echo \"$as_me:20229: checking for X11/Xt const-feature\" >&5\n echo $ECHO_N \"checking for X11/Xt const-feature... $ECHO_C\" >&6\n if test \"${cf_cv_const_x_string+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n \n \tcat >conftest.$ac_ext <<_ACEOF\n-#line 20235 \"configure\"\n+#line 20236 \"configure\"\n #include \"confdefs.h\"\n \n #define _CONST_X_STRING\t/* X11R7.8 (perhaps) */\n@@ -20249,16 +20250,16 @@ String foo = malloc(1); *foo = 0\n }\n _ACEOF\n rm -f conftest.$ac_objext\n-if { (eval echo \"$as_me:20252: \\\"$ac_compile\\\"\") >&5\n+if { (eval echo \"$as_me:20253: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20255: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20256: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest.$ac_objext'\n-  { (eval echo \"$as_me:20258: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:20259: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20261: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20262: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n \n \t\t\tcf_cv_const_x_string=no\n@@ -20273,7 +20274,7 @@ fi\n rm -f conftest.$ac_objext conftest.$ac_ext\n \n fi\n-echo \"$as_me:20276: result: $cf_cv_const_x_string\" >&5\n+echo \"$as_me:20277: result: $cf_cv_const_x_string\" >&5\n echo \"${ECHO_T}$cf_cv_const_x_string\" >&6\n \n LIBS=\"$cf_save_LIBS_CF_CONST_X_STRING\"\n@@ -20302,7 +20303,7 @@ fi\n rm -f conftest.$ac_objext conftest.$ac_ext\n  fi\n cat > conftest.$ac_ext <<EOF\n-#line 20305 \"${as_me:-configure}\"\n+#line 20306 \"${as_me:-configure}\"\n int main(int argc, char *argv[]) { return (argv[argc-1] == 0) ; }\n EOF\n if test \"$INTEL_COMPILER\" = yes\n@@ -20318,7 +20319,7 @@ then\n # remark #981: operands are evaluated in unspecified order\n # warning #279: controlling expression is constant\n \n-\t{ echo \"$as_me:20321: checking for $CC warning options...\" >&5\n+\t{ echo \"$as_me:20322: checking for $CC warning options...\" >&5\n echo \"$as_me: checking for $CC warning options...\" >&6;}\n \tcf_save_CFLAGS=\"$CFLAGS\"\n \tEXTRA_CFLAGS=\"-Wall\"\n@@ -20334,12 +20335,12 @@ echo \"$as_me: checking for $CC warning options...\" >&6;}\n \t\twd981\n \tdo\n \t\tCFLAGS=\"$cf_save_CFLAGS $EXTRA_CFLAGS -$cf_opt\"\n-\t\tif { (eval echo \"$as_me:20337: \\\"$ac_compile\\\"\") >&5\n+\t\tif { (eval echo \"$as_me:20338: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20340: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20341: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; then\n-\t\t\ttest -n \"$verbose\" && echo \"$as_me:20342: result: ... -$cf_opt\" >&5\n+\t\t\ttest -n \"$verbose\" && echo \"$as_me:20343: result: ... -$cf_opt\" >&5\n echo \"${ECHO_T}... -$cf_opt\" >&6\n \t\t\tEXTRA_CFLAGS=\"$EXTRA_CFLAGS -$cf_opt\"\n \t\tfi\n@@ -20347,7 +20348,7 @@ echo \"${ECHO_T}... -$cf_opt\" >&6\n \tCFLAGS=\"$cf_save_CFLAGS\"\n elif test \"$GCC\" = yes && test \"$GCC_VERSION\" != \"unknown\"\n then\n-\t{ echo \"$as_me:20350: checking for $CC warning options...\" >&5\n+\t{ echo \"$as_me:20351: checking for $CC warning options...\" >&5\n echo \"$as_me: checking for $CC warning options...\" >&6;}\n \tcf_save_CFLAGS=\"$CFLAGS\"\n \tEXTRA_CFLAGS=\n@@ -20371,12 +20372,12 @@ echo \"$as_me: checking for $CC warning options...\" >&6;}\n \t\tWundef Wno-inline $cf_gcc_warnings $cf_warn_CONST Wno-unknown-pragmas\n \tdo\n \t\tCFLAGS=\"$cf_save_CFLAGS $EXTRA_CFLAGS -$cf_opt\"\n-\t\tif { (eval echo \"$as_me:20374: \\\"$ac_compile\\\"\") >&5\n+\t\tif { (eval echo \"$as_me:20375: \\\"$ac_compile\\\"\") >&5\n   (eval $ac_compile) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20377: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20378: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; then\n-\t\t\ttest -n \"$verbose\" && echo \"$as_me:20379: result: ... -$cf_opt\" >&5\n+\t\t\ttest -n \"$verbose\" && echo \"$as_me:20380: result: ... -$cf_opt\" >&5\n echo \"${ECHO_T}... -$cf_opt\" >&6\n \t\t\tcase $cf_opt in\n \t\t\t(Winline)\n@@ -20384,7 +20385,7 @@ echo \"${ECHO_T}... -$cf_opt\" >&6\n \t\t\t\t([34].*)\n \t\t\t\t\ttest -n \"$verbose\" && echo \"\tfeature is broken in gcc $GCC_VERSION\" 1>&6\n \n-echo \"${as_me:-configure}:20387: testing feature is broken in gcc $GCC_VERSION ...\" 1>&5\n+echo \"${as_me:-configure}:20388: testing feature is broken in gcc $GCC_VERSION ...\" 1>&5\n \n \t\t\t\t\tcontinue;;\n \t\t\t\tesac\n@@ -20394,7 +20395,7 @@ echo \"${as_me:-configure}:20387: testing feature is broken in gcc $GCC_VERSION .\n \t\t\t\t([12].*)\n \t\t\t\t\ttest -n \"$verbose\" && echo \"\tfeature is broken in gcc $GCC_VERSION\" 1>&6\n \n-echo \"${as_me:-configure}:20397: testing feature is broken in gcc $GCC_VERSION ...\" 1>&5\n+echo \"${as_me:-configure}:20398: testing feature is broken in gcc $GCC_VERSION ...\" 1>&5\n \n \t\t\t\t\tcontinue;;\n \t\t\t\tesac\n@@ -20410,7 +20411,7 @@ rm -rf conftest*\n fi\n fi\n \n-echo \"$as_me:20413: checking if you want to use dmalloc for testing\" >&5\n+echo \"$as_me:20414: checking if you want to use dmalloc for testing\" >&5\n echo $ECHO_N \"checking if you want to use dmalloc for testing... $ECHO_C\" >&6\n \n # Check whether --with-dmalloc or --without-dmalloc was given.\n@@ -20427,7 +20428,7 @@ EOF\n else\n   with_dmalloc=\n fi;\n-echo \"$as_me:20430: result: ${with_dmalloc:-no}\" >&5\n+echo \"$as_me:20431: result: ${with_dmalloc:-no}\" >&5\n echo \"${ECHO_T}${with_dmalloc:-no}\" >&6\n \n case .$with_cflags in\n@@ -20541,23 +20542,23 @@ fi\n esac\n \n if test \"$with_dmalloc\" = yes ; then\n-\techo \"$as_me:20544: checking for dmalloc.h\" >&5\n+\techo \"$as_me:20545: checking for dmalloc.h\" >&5\n echo $ECHO_N \"checking for dmalloc.h... $ECHO_C\" >&6\n if test \"${ac_cv_header_dmalloc_h+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 20550 \"configure\"\n+#line 20551 \"configure\"\n #include \"confdefs.h\"\n #include <dmalloc.h>\n _ACEOF\n-if { (eval echo \"$as_me:20554: \\\"$ac_cpp conftest.$ac_ext\\\"\") >&5\n+if { (eval echo \"$as_me:20555: \\\"$ac_cpp conftest.$ac_ext\\\"\") >&5\n   (eval $ac_cpp conftest.$ac_ext) 2>conftest.er1\n   ac_status=$?\n   egrep -v '^ *\\+' conftest.er1 >conftest.err\n   rm -f conftest.er1\n   cat conftest.err >&5\n-  echo \"$as_me:20560: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20561: \\$? = $ac_status\" >&5\n   (exit $ac_status); } >/dev/null; then\n   if test -s conftest.err; then\n     ac_cpp_err=$ac_c_preproc_warn_flag\n@@ -20576,11 +20577,11 @@ else\n fi\n rm -f conftest.err conftest.$ac_ext\n fi\n-echo \"$as_me:20579: result: $ac_cv_header_dmalloc_h\" >&5\n+echo \"$as_me:20580: result: $ac_cv_header_dmalloc_h\" >&5\n echo \"${ECHO_T}$ac_cv_header_dmalloc_h\" >&6\n if test $ac_cv_header_dmalloc_h = yes; then\n \n-echo \"$as_me:20583: checking for dmalloc_debug in -ldmalloc\" >&5\n+echo \"$as_me:20584: checking for dmalloc_debug in -ldmalloc\" >&5\n echo $ECHO_N \"checking for dmalloc_debug in -ldmalloc... $ECHO_C\" >&6\n if test \"${ac_cv_lib_dmalloc_dmalloc_debug+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -20588,7 +20589,7 @@ else\n   ac_check_lib_save_LIBS=$LIBS\n LIBS=\"-ldmalloc  $LIBS\"\n cat >conftest.$ac_ext <<_ACEOF\n-#line 20591 \"configure\"\n+#line 20592 \"configure\"\n #include \"confdefs.h\"\n \n /* Override any gcc2 internal prototype to avoid an error.  */\n@@ -20607,16 +20608,16 @@ dmalloc_debug ();\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:20610: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:20611: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20613: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20614: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:20616: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:20617: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20619: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20620: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   ac_cv_lib_dmalloc_dmalloc_debug=yes\n else\n@@ -20627,7 +20628,7 @@ fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n LIBS=$ac_check_lib_save_LIBS\n fi\n-echo \"$as_me:20630: result: $ac_cv_lib_dmalloc_dmalloc_debug\" >&5\n+echo \"$as_me:20631: result: $ac_cv_lib_dmalloc_dmalloc_debug\" >&5\n echo \"${ECHO_T}$ac_cv_lib_dmalloc_dmalloc_debug\" >&6\n if test $ac_cv_lib_dmalloc_dmalloc_debug = yes; then\n   cat >>confdefs.h <<EOF\n@@ -20642,7 +20643,7 @@ fi\n \n fi\n \n-echo \"$as_me:20645: checking if you want to use dbmalloc for testing\" >&5\n+echo \"$as_me:20646: checking if you want to use dbmalloc for testing\" >&5\n echo $ECHO_N \"checking if you want to use dbmalloc for testing... $ECHO_C\" >&6\n \n # Check whether --with-dbmalloc or --without-dbmalloc was given.\n@@ -20659,7 +20660,7 @@ EOF\n else\n   with_dbmalloc=\n fi;\n-echo \"$as_me:20662: result: ${with_dbmalloc:-no}\" >&5\n+echo \"$as_me:20663: result: ${with_dbmalloc:-no}\" >&5\n echo \"${ECHO_T}${with_dbmalloc:-no}\" >&6\n \n case .$with_cflags in\n@@ -20773,23 +20774,23 @@ fi\n esac\n \n if test \"$with_dbmalloc\" = yes ; then\n-\techo \"$as_me:20776: checking for dbmalloc.h\" >&5\n+\techo \"$as_me:20777: checking for dbmalloc.h\" >&5\n echo $ECHO_N \"checking for dbmalloc.h... $ECHO_C\" >&6\n if test \"${ac_cv_header_dbmalloc_h+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n else\n   cat >conftest.$ac_ext <<_ACEOF\n-#line 20782 \"configure\"\n+#line 20783 \"configure\"\n #include \"confdefs.h\"\n #include <dbmalloc.h>\n _ACEOF\n-if { (eval echo \"$as_me:20786: \\\"$ac_cpp conftest.$ac_ext\\\"\") >&5\n+if { (eval echo \"$as_me:20787: \\\"$ac_cpp conftest.$ac_ext\\\"\") >&5\n   (eval $ac_cpp conftest.$ac_ext) 2>conftest.er1\n   ac_status=$?\n   egrep -v '^ *\\+' conftest.er1 >conftest.err\n   rm -f conftest.er1\n   cat conftest.err >&5\n-  echo \"$as_me:20792: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20793: \\$? = $ac_status\" >&5\n   (exit $ac_status); } >/dev/null; then\n   if test -s conftest.err; then\n     ac_cpp_err=$ac_c_preproc_warn_flag\n@@ -20808,11 +20809,11 @@ else\n fi\n rm -f conftest.err conftest.$ac_ext\n fi\n-echo \"$as_me:20811: result: $ac_cv_header_dbmalloc_h\" >&5\n+echo \"$as_me:20812: result: $ac_cv_header_dbmalloc_h\" >&5\n echo \"${ECHO_T}$ac_cv_header_dbmalloc_h\" >&6\n if test $ac_cv_header_dbmalloc_h = yes; then\n \n-echo \"$as_me:20815: checking for debug_malloc in -ldbmalloc\" >&5\n+echo \"$as_me:20816: checking for debug_malloc in -ldbmalloc\" >&5\n echo $ECHO_N \"checking for debug_malloc in -ldbmalloc... $ECHO_C\" >&6\n if test \"${ac_cv_lib_dbmalloc_debug_malloc+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -20820,7 +20821,7 @@ else\n   ac_check_lib_save_LIBS=$LIBS\n LIBS=\"-ldbmalloc  $LIBS\"\n cat >conftest.$ac_ext <<_ACEOF\n-#line 20823 \"configure\"\n+#line 20824 \"configure\"\n #include \"confdefs.h\"\n \n /* Override any gcc2 internal prototype to avoid an error.  */\n@@ -20839,16 +20840,16 @@ debug_malloc ();\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:20842: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:20843: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20845: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20846: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:20848: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:20849: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:20851: \\$? = $ac_status\" >&5\n+  echo \"$as_me:20852: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   ac_cv_lib_dbmalloc_debug_malloc=yes\n else\n@@ -20859,7 +20860,7 @@ fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n LIBS=$ac_check_lib_save_LIBS\n fi\n-echo \"$as_me:20862: result: $ac_cv_lib_dbmalloc_debug_malloc\" >&5\n+echo \"$as_me:20863: result: $ac_cv_lib_dbmalloc_debug_malloc\" >&5\n echo \"${ECHO_T}$ac_cv_lib_dbmalloc_debug_malloc\" >&6\n if test $ac_cv_lib_dbmalloc_debug_malloc = yes; then\n   cat >>confdefs.h <<EOF\n@@ -20874,7 +20875,7 @@ fi\n \n fi\n \n-echo \"$as_me:20877: checking if you want to use valgrind for testing\" >&5\n+echo \"$as_me:20878: checking if you want to use valgrind for testing\" >&5\n echo $ECHO_N \"checking if you want to use valgrind for testing... $ECHO_C\" >&6\n \n # Check whether --with-valgrind or --without-valgrind was given.\n@@ -20891,7 +20892,7 @@ EOF\n else\n   with_valgrind=\n fi;\n-echo \"$as_me:20894: result: ${with_valgrind:-no}\" >&5\n+echo \"$as_me:20895: result: ${with_valgrind:-no}\" >&5\n echo \"${ECHO_T}${with_valgrind:-no}\" >&6\n \n case .$with_cflags in\n@@ -21004,7 +21005,7 @@ fi\n \t;;\n esac\n \n-echo \"$as_me:21007: checking if you want to perform memory-leak testing\" >&5\n+echo \"$as_me:21008: checking if you want to perform memory-leak testing\" >&5\n echo $ECHO_N \"checking if you want to perform memory-leak testing... $ECHO_C\" >&6\n \n # Check whether --enable-leaks or --disable-leaks was given.\n@@ -21014,7 +21015,7 @@ if test \"${enable_leaks+set}\" = set; then\n else\n   : ${with_no_leaks:=no}\n fi;\n-echo \"$as_me:21017: result: $with_no_leaks\" >&5\n+echo \"$as_me:21018: result: $with_no_leaks\" >&5\n echo \"${ECHO_T}$with_no_leaks\" >&6\n \n if test \"$with_no_leaks\" = yes ; then\n@@ -21032,7 +21033,7 @@ fi\n LD_RPATH_OPT=\n if test \"x$cf_cv_enable_rpath\" != xno\n then\n-\techo \"$as_me:21035: checking for an rpath option\" >&5\n+\techo \"$as_me:21036: checking for an rpath option\" >&5\n echo $ECHO_N \"checking for an rpath option... $ECHO_C\" >&6\n \tcase $cf_cv_system_name in\n \t(irix*)\n@@ -21063,12 +21064,12 @@ echo $ECHO_N \"checking for an rpath option... $ECHO_C\" >&6\n \t(*)\n \t\t;;\n \tesac\n-\techo \"$as_me:21066: result: $LD_RPATH_OPT\" >&5\n+\techo \"$as_me:21067: result: $LD_RPATH_OPT\" >&5\n echo \"${ECHO_T}$LD_RPATH_OPT\" >&6\n \n \tcase \"x$LD_RPATH_OPT\" in\n \t(x-R*)\n-\t\techo \"$as_me:21071: checking if we need a space after rpath option\" >&5\n+\t\techo \"$as_me:21072: checking if we need a space after rpath option\" >&5\n echo $ECHO_N \"checking if we need a space after rpath option... $ECHO_C\" >&6\n \t\tcf_save_LIBS=\"$LIBS\"\n \n@@ -21089,7 +21090,7 @@ done\n LIBS=\"$cf_add_libs\"\n \n \t\tcat >conftest.$ac_ext <<_ACEOF\n-#line 21092 \"configure\"\n+#line 21093 \"configure\"\n #include \"confdefs.h\"\n \n int\n@@ -21101,16 +21102,16 @@ main (void)\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:21104: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:21105: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21107: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21108: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:21110: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:21111: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21113: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21114: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_rpath_space=no\n else\n@@ -21120,14 +21121,14 @@ cf_rpath_space=yes\n fi\n rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n \t\tLIBS=\"$cf_save_LIBS\"\n-\t\techo \"$as_me:21123: result: $cf_rpath_space\" >&5\n+\t\techo \"$as_me:21124: result: $cf_rpath_space\" >&5\n echo \"${ECHO_T}$cf_rpath_space\" >&6\n \t\ttest \"$cf_rpath_space\" = yes && LD_RPATH_OPT=\"$LD_RPATH_OPT \"\n \t\t;;\n \tesac\n fi\n \n-echo \"$as_me:21130: checking if rpath-hack should be disabled\" >&5\n+echo \"$as_me:21131: checking if rpath-hack should be disabled\" >&5\n echo $ECHO_N \"checking if rpath-hack should be disabled... $ECHO_C\" >&6\n \n # Check whether --enable-rpath-hack or --disable-rpath-hack was given.\n@@ -21144,21 +21145,21 @@ else\n \tcf_disable_rpath_hack=no\n \n fi;\n-echo \"$as_me:21147: result: $cf_disable_rpath_hack\" >&5\n+echo \"$as_me:21148: result: $cf_disable_rpath_hack\" >&5\n echo \"${ECHO_T}$cf_disable_rpath_hack\" >&6\n if test \"$cf_disable_rpath_hack\" = no ; then\n \n-echo \"$as_me:21151: checking for updated LDFLAGS\" >&5\n+echo \"$as_me:21152: checking for updated LDFLAGS\" >&5\n echo $ECHO_N \"checking for updated LDFLAGS... $ECHO_C\" >&6\n if test -n \"$LD_RPATH_OPT\" ; then\n-\techo \"$as_me:21154: result: maybe\" >&5\n+\techo \"$as_me:21155: result: maybe\" >&5\n echo \"${ECHO_T}maybe\" >&6\n \n \tfor ac_prog in ldd\n do\n   # Extract the first word of \"$ac_prog\", so it can be a program name with args.\n set dummy $ac_prog; ac_word=$2\n-echo \"$as_me:21161: checking for $ac_word\" >&5\n+echo \"$as_me:21162: checking for $ac_word\" >&5\n echo $ECHO_N \"checking for $ac_word... $ECHO_C\" >&6\n if test \"${ac_cv_prog_cf_ldd_prog+set}\" = set; then\n   echo $ECHO_N \"(cached) $ECHO_C\" >&6\n@@ -21173,7 +21174,7 @@ for ac_dir in $ac_dummy; do\n   test -z \"$ac_dir\" && ac_dir=.\n   $as_executable_p \"$ac_dir/$ac_word\" || continue\n ac_cv_prog_cf_ldd_prog=\"$ac_prog\"\n-echo \"$as_me:21176: found $ac_dir/$ac_word\" >&5\n+echo \"$as_me:21177: found $ac_dir/$ac_word\" >&5\n break\n done\n \n@@ -21181,10 +21182,10 @@ fi\n fi\n cf_ldd_prog=$ac_cv_prog_cf_ldd_prog\n if test -n \"$cf_ldd_prog\"; then\n-  echo \"$as_me:21184: result: $cf_ldd_prog\" >&5\n+  echo \"$as_me:21185: result: $cf_ldd_prog\" >&5\n echo \"${ECHO_T}$cf_ldd_prog\" >&6\n else\n-  echo \"$as_me:21187: result: no\" >&5\n+  echo \"$as_me:21188: result: no\" >&5\n echo \"${ECHO_T}no\" >&6\n fi\n \n@@ -21198,7 +21199,7 @@ test -n \"$cf_ldd_prog\" || cf_ldd_prog=\"no\"\n \t\tcf_rpath_oops=\n \n cat >conftest.$ac_ext <<_ACEOF\n-#line 21201 \"configure\"\n+#line 21202 \"configure\"\n #include \"confdefs.h\"\n #include <stdio.h>\n int\n@@ -21210,16 +21211,16 @@ printf(\"Hello\");\n }\n _ACEOF\n rm -f conftest.$ac_objext conftest$ac_exeext\n-if { (eval echo \"$as_me:21213: \\\"$ac_link\\\"\") >&5\n+if { (eval echo \"$as_me:21214: \\\"$ac_link\\\"\") >&5\n   (eval $ac_link) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21216: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21217: \\$? = $ac_status\" >&5\n   (exit $ac_status); } &&\n          { ac_try='test -s conftest$ac_exeext'\n-  { (eval echo \"$as_me:21219: \\\"$ac_try\\\"\") >&5\n+  { (eval echo \"$as_me:21220: \\\"$ac_try\\\"\") >&5\n   (eval $ac_try) 2>&5\n   ac_status=$?\n-  echo \"$as_me:21222: \\$? = $ac_status\" >&5\n+  echo \"$as_me:21223: \\$? = $ac_status\" >&5\n   (exit $ac_status); }; }; then\n   cf_rpath_oops=`$cf_ldd_prog conftest$ac_exeext | fgrep ' not found' | sed -e 's% =>.*$%%' |sort | uniq`\n \t\t cf_rpath_list=`$cf_ldd_prog conftest$ac_exeext | fgrep / | sed -e 's%^.*[ \t]/%/%' -e 's%/[^/][^/]*$%%' |sort | uniq`\n@@ -21247,7 +21248,7 @@ rm -f conftest.$ac_objext conftest$ac_exeext conftest.$ac_ext\n \t\t\t\t\tthen\n \t\t\t\t\t\ttest -n \"$verbose\" && echo \"\t...adding -L$cf_rpath_dir/lib to LDFLAGS for $cf_rpath_src\" 1>&6\n \n-echo \"${as_me:-configure}:21250: testing ...adding -L$cf_rpath_dir/lib to LDFLAGS for $cf_rpath_src ...\" 1>&5\n+echo \"${as_me:-configure}:21251: testing ...adding -L$cf_rpath_dir/lib to LDFLAGS for $cf_rpath_src ...\" 1>&5\n \n \t\t\t\t\t\tLDFLAGS=\"$LDFLAGS -L$cf_rpath_dir/lib\"\n \t\t\t\t\t\tbreak\n@@ -21259,11 +21260,11 @@ echo \"${as_me:-configure}:21250: testing ...adding -L$cf_rpath_dir/lib to LDFLAG\n \n \ttest -n \"$verbose\" && echo \"\t...checking EXTRA_LDFLAGS $EXTRA_LDFLAGS\" 1>&6\n \n-echo \"${as_me:-configure}:21262: testing ...checking EXTRA_LDFLAGS $EXTRA_LDFLAGS ...\" 1>&5\n+echo \"${as_me:-configure}:21263: testing ...checking EXTRA_LDFLAGS $EXTRA_LDFLAGS ...\" 1>&5\n \n test -n \"$verbose\" && echo \"\t...checking LDFLAGS $LDFLAGS\" 1>&6\n \n-echo \"${as_me:-configure}:21266: testing ...checking LDFLAGS $LDFLAGS ...\" 1>&5\n+echo \"${as_me:-configure}:21267: testing ...checking LDFLAGS $LDFLAGS ...\" 1>&5\n \n cf_rpath_dst=\n for cf_rpath_src in $LDFLAGS\n@@ -21300,7 +21301,7 @@ do\n \t\t\tthen\n \t\t\t\ttest -n \"$verbose\" && echo \"\t...Filter $cf_rpath_src ->$cf_rpath_tmp\" 1>&6\n \n-echo \"${as_me:-configure}:21303: testing ...Filter $cf_rpath_src ->$cf_rpath_tmp ...\" 1>&5\n+echo \"${as_me:-configure}:21304: testing ...Filter $cf_rpath_src ->$cf_rpath_tmp ...\" 1>&5\n \n \t\t\t\tEXTRA_LDFLAGS=\"$cf_rpath_tmp $EXTRA_LDFLAGS\"\n \t\t\tfi\n@@ -21313,11 +21314,11 @@ LDFLAGS=$cf_rpath_dst\n \n test -n \"$verbose\" && echo \"\t...checked LDFLAGS $LDFLAGS\" 1>&6\n \n-echo \"${as_me:-configure}:21316: testing ...checked LDFLAGS $LDFLAGS ...\" 1>&5\n+echo \"${as_me:-configure}:21317: testing ...checked LDFLAGS $LDFLAGS ...\" 1>&5\n \n test -n \"$verbose\" && echo \"\t...checking LIBS $LIBS\" 1>&6\n \n-echo \"${as_me:-configure}:21320: testing ...checking LIBS $LIBS ...\" 1>&5\n+echo \"${as_me:-configure}:21321: testing ...checking LIBS $LIBS ...\" 1>&5\n \n cf_rpath_dst=\n for cf_rpath_src in $LIBS\n@@ -21354,7 +21355,7 @@ do\n \t\t\tthen\n \t\t\t\ttest -n \"$verbose\" && echo \"\t...Filter $cf_rpath_src ->$cf_rpath_tmp\" 1>&6\n \n-echo \"${as_me:-configure}:21357: testing ...Filter $cf_rpath_src ->$cf_rpath_tmp ...\" 1>&5\n+echo \"${as_me:-configure}:21358: testing ...Filter $cf_rpath_src ->$cf_rpath_tmp ...\" 1>&5\n \n \t\t\t\tEXTRA_LDFLAGS=\"$cf_rpath_tmp $EXTRA_LDFLAGS\"\n \t\t\tfi\n@@ -21367,14 +21368,14 @@ LIBS=$cf_rpath_dst\n \n test -n \"$verbose\" && echo \"\t...checked LIBS $LIBS\" 1>&6\n \n-echo \"${as_me:-configure}:21370: testing ...checked LIBS $LIBS ...\" 1>&5\n+echo \"${as_me:-configure}:21371: testing ...checked LIBS $LIBS ...\" 1>&5\n \n \ttest -n \"$verbose\" && echo \"\t...checked EXTRA_LDFLAGS $EXTRA_LDFLAGS\" 1>&6\n \n-echo \"${as_me:-configure}:21374: testing ...checked EXTRA_LDFLAGS $EXTRA_LDFLAGS ...\" 1>&5\n+echo \"${as_me:-configure}:21375: testing ...checked EXTRA_LDFLAGS $EXTRA_LDFLAGS ...\" 1>&5\n \n else\n-\techo \"$as_me:21377: result: no\" >&5\n+\techo \"$as_me:21378: result: no\" >&5\n echo \"${ECHO_T}no\" >&6\n fi\n \n@@ -21464,7 +21465,7 @@ DEFS=-DHAVE_CONFIG_H\n : ${CONFIG_STATUS=./config.status}\n ac_clean_files_save=$ac_clean_files\n ac_clean_files=\"$ac_clean_files $CONFIG_STATUS\"\n-{ echo \"$as_me:21467: creating $CONFIG_STATUS\" >&5\n+{ echo \"$as_me:21468: creating $CONFIG_STATUS\" >&5\n echo \"$as_me: creating $CONFIG_STATUS\" >&6;}\n cat >$CONFIG_STATUS <<_ACEOF\n #! $SHELL\n@@ -21640,7 +21641,7 @@ cat >>$CONFIG_STATUS <<\\EOF\n     echo \"$ac_cs_version\"; exit 0 ;;\n   --he | --h)\n     # Conflict between --help and --header\n-    { { echo \"$as_me:21643: error: ambiguous option: $1\n+    { { echo \"$as_me:21644: error: ambiguous option: $1\n Try \\`$0 --help' for more information.\" >&5\n echo \"$as_me: error: ambiguous option: $1\n Try \\`$0 --help' for more information.\" >&2;}\n@@ -21659,7 +21660,7 @@ Try \\`$0 --help' for more information.\" >&2;}\n     ac_need_defaults=false;;\n \n   # This is an error.\n-  -*) { { echo \"$as_me:21662: error: unrecognized option: $1\n+  -*) { { echo \"$as_me:21663: error: unrecognized option: $1\n Try \\`$0 --help' for more information.\" >&5\n echo \"$as_me: error: unrecognized option: $1\n Try \\`$0 --help' for more information.\" >&2;}\n@@ -21709,7 +21710,7 @@ do\n   \"Makefile\" ) CONFIG_FILES=\"$CONFIG_FILES Makefile\" ;;\n   \"default\" ) CONFIG_COMMANDS=\"$CONFIG_COMMANDS default\" ;;\n   \"ncurses_cfg.h\" ) CONFIG_HEADERS=\"$CONFIG_HEADERS ncurses_cfg.h:ncurses_tst.hin\" ;;\n-  *) { { echo \"$as_me:21712: error: invalid argument: $ac_config_target\" >&5\n+  *) { { echo \"$as_me:21713: error: invalid argument: $ac_config_target\" >&5\n echo \"$as_me: error: invalid argument: $ac_config_target\" >&2;}\n    { (exit 1); exit 1; }; };;\n   esac\n@@ -22008,7 +22009,7 @@ done; }\n   esac\n \n   if test x\"$ac_file\" != x-; then\n-    { echo \"$as_me:22011: creating $ac_file\" >&5\n+    { echo \"$as_me:22012: creating $ac_file\" >&5\n echo \"$as_me: creating $ac_file\" >&6;}\n     rm -f \"$ac_file\"\n   fi\n@@ -22026,7 +22027,7 @@ echo \"$as_me: creating $ac_file\" >&6;}\n       -) echo $tmp/stdin ;;\n       [\\\\/$]*)\n          # Absolute (can't be DOS-style, as IFS=:)\n-         test -f \"$f\" || { { echo \"$as_me:22029: error: cannot find input file: $f\" >&5\n+         test -f \"$f\" || { { echo \"$as_me:22030: error: cannot find input file: $f\" >&5\n echo \"$as_me: error: cannot find input file: $f\" >&2;}\n    { (exit 1); exit 1; }; }\n          echo $f;;\n@@ -22039,7 +22040,7 @@ echo \"$as_me: error: cannot find input file: $f\" >&2;}\n            echo $srcdir/$f\n          else\n            # /dev/null tree\n-           { { echo \"$as_me:22042: error: cannot find input file: $f\" >&5\n+           { { echo \"$as_me:22043: error: cannot find input file: $f\" >&5\n echo \"$as_me: error: cannot find input file: $f\" >&2;}\n    { (exit 1); exit 1; }; }\n          fi;;\n@@ -22055,7 +22056,7 @@ cat >>$CONFIG_STATUS <<\\EOF\n       if test -n \"$ac_seen\"; then\n         ac_used=`grep '@datarootdir@' $ac_item`\n         if test -z \"$ac_used\"; then\n-          { echo \"$as_me:22058: WARNING: datarootdir was used implicitly but not set:\n+          { echo \"$as_me:22059: WARNING: datarootdir was used implicitly but not set:\n $ac_seen\" >&5\n echo \"$as_me: WARNING: datarootdir was used implicitly but not set:\n $ac_seen\" >&2;}\n@@ -22064,7 +22065,7 @@ $ac_seen\" >&2;}\n       fi\n       ac_seen=`grep '${datarootdir}' $ac_item`\n       if test -n \"$ac_seen\"; then\n-        { echo \"$as_me:22067: WARNING: datarootdir was used explicitly but not set:\n+        { echo \"$as_me:22068: WARNING: datarootdir was used explicitly but not set:\n $ac_seen\" >&5\n echo \"$as_me: WARNING: datarootdir was used explicitly but not set:\n $ac_seen\" >&2;}\n@@ -22101,7 +22102,7 @@ s,@INSTALL@,$ac_INSTALL,;t t\n             ac_init=`egrep '[ \t]*'$ac_name'[ \t]*=' $ac_file`\n             if test -z \"$ac_init\"; then\n               ac_seen=`echo \"$ac_seen\" |sed -e 's,^,'$ac_file':,'`\n-              { echo \"$as_me:22104: WARNING: Variable $ac_name is used but was not set:\n+              { echo \"$as_me:22105: WARNING: Variable $ac_name is used but was not set:\n $ac_seen\" >&5\n echo \"$as_me: WARNING: Variable $ac_name is used but was not set:\n $ac_seen\" >&2;}\n@@ -22112,7 +22113,7 @@ $ac_seen\" >&2;}\n     egrep -n '@[A-Z_][A-Z_0-9]+@' $ac_file >>$tmp/out\n     if test -s $tmp/out; then\n       ac_seen=`sed -e 's,^,'$ac_file':,' < $tmp/out`\n-      { echo \"$as_me:22115: WARNING: Some variables may not be substituted:\n+      { echo \"$as_me:22116: WARNING: Some variables may not be substituted:\n $ac_seen\" >&5\n echo \"$as_me: WARNING: Some variables may not be substituted:\n $ac_seen\" >&2;}\n@@ -22161,7 +22162,7 @@ for ac_file in : $CONFIG_HEADERS; do test \"x$ac_file\" = x: && continue\n   * )   ac_file_in=$ac_file.in ;;\n   esac\n \n-  test x\"$ac_file\" != x- && { echo \"$as_me:22164: creating $ac_file\" >&5\n+  test x\"$ac_file\" != x- && { echo \"$as_me:22165: creating $ac_file\" >&5\n echo \"$as_me: creating $ac_file\" >&6;}\n \n   # First look for the input files in the build tree, otherwise in the\n@@ -22172,7 +22173,7 @@ echo \"$as_me: creating $ac_file\" >&6;}\n       -) echo $tmp/stdin ;;\n       [\\\\/$]*)\n          # Absolute (can't be DOS-style, as IFS=:)\n-         test -f \"$f\" || { { echo \"$as_me:22175: error: cannot find input file: $f\" >&5\n+         test -f \"$f\" || { { echo \"$as_me:22176: error: cannot find input file: $f\" >&5\n echo \"$as_me: error: cannot find input file: $f\" >&2;}\n    { (exit 1); exit 1; }; }\n          echo $f;;\n@@ -22185,7 +22186,7 @@ echo \"$as_me: error: cannot find input file: $f\" >&2;}\n            echo $srcdir/$f\n          else\n            # /dev/null tree\n-           { { echo \"$as_me:22188: error: cannot find input file: $f\" >&5\n+           { { echo \"$as_me:22189: error: cannot find input file: $f\" >&5\n echo \"$as_me: error: cannot find input file: $f\" >&2;}\n    { (exit 1); exit 1; }; }\n          fi;;\n@@ -22243,7 +22244,7 @@ cat >>$CONFIG_STATUS <<\\EOF\n   rm -f $tmp/in\n   if test x\"$ac_file\" != x-; then\n     if cmp -s $ac_file $tmp/config.h 2>/dev/null; then\n-      { echo \"$as_me:22246: $ac_file is unchanged\" >&5\n+      { echo \"$as_me:22247: $ac_file is unchanged\" >&5\n echo \"$as_me: $ac_file is unchanged\" >&6;}\n     else\n       ac_dir=`$as_expr X\"$ac_file\" : 'X\\(.*[^/]\\)//*[^/][^/]*/*$' \\| \\\ndiff --git a/test/configure.in b/test/configure.in\nindex 87757d041..59ff30fe5 100644\n--- a/test/configure.in\n+++ b/test/configure.in\n@@ -29,7 +29,7 @@ dnl***************************************************************************\n dnl\n dnl Author: Thomas E. Dickey 1996-on\n dnl\n-dnl $Id: configure.in,v 1.158 2020/03/08 14:12:23 tom Exp $\n+dnl $Id: configure.in,v 1.159 2020/05/30 00:13:37 tom Exp $\n dnl This is a simple configuration-script for the ncurses test programs that\n dnl allows the test-directory to be separately configured against a reference\n dnl system (i.e., sysvr4 curses)\n@@ -256,6 +256,7 @@ CF_GETOPT_HEADER\n AC_CHECK_FUNCS( \\\n getopt \\\n gettimeofday \\\n+snprintf \\\n strstr \\\n tsearch \\\n )\ndiff --git a/test/dots.c b/test/dots.c\nindex 11fc1cfef..94d90a13f 100644\n--- a/test/dots.c\n+++ b/test/dots.c\n@@ -30,7 +30,7 @@\n /*\n  * Author: Thomas E. Dickey <dickey@clark.net> 1999\n  *\n- * $Id: dots.c,v 1.39 2020/05/10 00:31:03 tom Exp $\n+ * $Id: dots.c,v 1.40 2020/05/29 23:04:02 tom Exp $\n  *\n  * A simple demo of the terminfo interface.\n  */\n@@ -214,7 +214,8 @@ main(int argc,\n \t\ttputs(tparm2(set_a_foreground, z), 1, outc);\n \t    } else {\n \t\ttputs(tparm2(set_a_background, z), 1, outc);\n-\t\tnapms(s_option);\n+\t\tif (s_option)\n+\t\t    napms(s_option);\n \t    }\n \t} else if (VALID_STRING(exit_attribute_mode)\n \t\t   && VALID_STRING(enter_reverse_mode)) {\n@@ -222,7 +223,8 @@ main(int argc,\n \t\touts((ranf() > 0.6)\n \t\t     ? enter_reverse_mode\n \t\t     : exit_attribute_mode);\n-\t\tnapms(s_option);\n+\t\tif (s_option)\n+\t\t    napms(s_option);\n \t    }\n \t}\n \toutc(p);\ndiff --git a/test/dots_curses.c b/test/dots_curses.c\nindex 4754e98ab..e30a24ae3 100644\n--- a/test/dots_curses.c\n+++ b/test/dots_curses.c\n@@ -30,7 +30,7 @@\n /*\n  * Author: Thomas E. Dickey\n  *\n- * $Id: dots_curses.c,v 1.19 2020/05/10 00:31:59 tom Exp $\n+ * $Id: dots_curses.c,v 1.20 2020/05/29 23:04:02 tom Exp $\n  *\n  * A simple demo of the curses interface used for comparison with termcap.\n  */\n@@ -206,7 +206,8 @@ main(int argc, char *argv[])\n \t\tattron(COLOR_PAIR(mypair(fg, bg)));\n \t    } else {\n \t\tset_colors(fg, bg = z);\n-\t\tnapms(s_option);\n+\t\tif (s_option)\n+\t\t    napms(s_option);\n \t    }\n \t} else {\n \t    if (ranf() <= 0.01) {\n@@ -215,7 +216,8 @@ main(int argc, char *argv[])\n \t\t} else {\n \t\t    attroff(A_REVERSE);\n \t\t}\n-\t\tnapms(s_option);\n+\t\tif (s_option)\n+\t\t    napms(s_option);\n \t    }\n \t}\n \tAddCh(p);\ndiff --git a/test/dots_mvcur.c b/test/dots_mvcur.c\nindex 76176642d..a032124c1 100644\n--- a/test/dots_mvcur.c\n+++ b/test/dots_mvcur.c\n@@ -30,7 +30,7 @@\n /*\n  * Author: Thomas E. Dickey - 2007\n  *\n- * $Id: dots_mvcur.c,v 1.25 2020/05/10 00:32:11 tom Exp $\n+ * $Id: dots_mvcur.c,v 1.26 2020/05/29 23:04:02 tom Exp $\n  *\n  * A simple demo of the terminfo interface, and mvcur.\n  */\n@@ -228,7 +228,8 @@ main(int argc GCC_UNUSED,\n \t\ttputs(tparm2(set_a_foreground, z), 1, outc);\n \t    } else {\n \t\ttputs(tparm2(set_a_background, z), 1, outc);\n-\t\tnapms(s_option);\n+\t\tif (s_option)\n+\t\t    napms(s_option);\n \t    }\n \t} else if (VALID_STRING(exit_attribute_mode)\n \t\t   && VALID_STRING(enter_reverse_mode)) {\n@@ -236,7 +237,8 @@ main(int argc GCC_UNUSED,\n \t\touts((ranf() > 0.6)\n \t\t     ? enter_reverse_mode\n \t\t     : exit_attribute_mode);\n-\t\tnapms(s_option);\n+\t\tif (s_option)\n+\t\t    napms(s_option);\n \t    }\n \t}\n \toutc(p);\ndiff --git a/test/dots_termcap.c b/test/dots_termcap.c\nindex 0fc1a89e1..52749c754 100644\n--- a/test/dots_termcap.c\n+++ b/test/dots_termcap.c\n@@ -30,7 +30,7 @@\n /*\n  * Author: Thomas E. Dickey\n  *\n- * $Id: dots_termcap.c,v 1.23 2020/05/10 00:32:22 tom Exp $\n+ * $Id: dots_termcap.c,v 1.24 2020/05/29 23:04:02 tom Exp $\n  *\n  * A simple demo of the termcap interface.\n  */\n@@ -297,7 +297,8 @@ main(int argc, char *argv[])\n \t\ttputs(tgoto(t_AF, 0, z), 1, outc);\n \t    } else {\n \t\ttputs(tgoto(t_AB, 0, z), 1, outc);\n-\t\tmy_napms(s_option);\n+\t\tif (s_option)\n+\t\t    my_napms(s_option);\n \t    }\n \t} else if (VALID_STRING(t_me)\n \t\t   && VALID_STRING(t_mr)) {\n@@ -305,7 +306,8 @@ main(int argc, char *argv[])\n \t\touts((ranf() > 0.6)\n \t\t     ? t_mr\n \t\t     : t_me);\n-\t\tmy_napms(s_option);\n+\t\tif (s_option)\n+\t\t    my_napms(s_option);\n \t    }\n \t}\n \toutc(p);\ndiff --git a/test/dots_xcurses.c b/test/dots_xcurses.c\nindex a2aa8b926..d8fe80319 100644\n--- a/test/dots_xcurses.c\n+++ b/test/dots_xcurses.c\n@@ -30,7 +30,7 @@\n /*\n  * Author: Thomas E. Dickey\n  *\n- * $Id: dots_xcurses.c,v 1.22 2020/05/10 00:32:33 tom Exp $\n+ * $Id: dots_xcurses.c,v 1.23 2020/05/29 23:04:02 tom Exp $\n  *\n  * A simple demo of the wide-curses interface used for comparison with termcap.\n  */\n@@ -244,7 +244,8 @@ main(int argc, char *argv[])\n \t\tset_colors(fg = z, bg);\n \t    } else {\n \t\tset_colors(fg, bg = z);\n-\t\tnapms(s_option);\n+\t\tif (s_option)\n+\t\t    napms(s_option);\n \t    }\n \t} else {\n \t    if (ranf() <= 0.01) {\n@@ -253,7 +254,8 @@ main(int argc, char *argv[])\n \t\t} else {\n \t\t    attr_off(WA_REVERSE, NULL);\n \t\t}\n-\t\tnapms(s_option);\n+\t\tif (s_option)\n+\t\t    napms(s_option);\n \t    }\n \t}\n \twch[0] = (wchar_t) p;\ndiff --git a/test/modules b/test/modules\nindex 7fb9b1794..524a60004 100644\n--- a/test/modules\n+++ b/test/modules\n@@ -1,4 +1,4 @@\n-# $Id: modules,v 1.72 2020/03/21 16:09:48 tom Exp $\n+# $Id: modules,v 1.73 2020/05/29 23:27:44 tom Exp $\n ##############################################################################\n # Copyright 2018-2019,2020 Thomas E. Dickey                                  #\n # Copyright 1998-2016,2017 Free Software Foundation, Inc.                    #\n@@ -107,6 +107,7 @@ test_opaque\tprogs\t\t$(srcdir)\t$(HEADER_DEPS)\n test_setupterm\tprogs\t\t$(srcdir)\t$(HEADER_DEPS)\n test_sgr\tprogs\t\t$(srcdir)\t$(HEADER_DEPS)\n test_termattrs\tprogs\t\t$(srcdir)\t$(HEADER_DEPS)\n+test_tparm\tprogs\t\t$(srcdir)\t$(HEADER_DEPS)\n test_vid_puts\tprogs\t\t$(srcdir)\t$(HEADER_DEPS)\n test_vidputs\tprogs\t\t$(srcdir)\t$(HEADER_DEPS)\n testaddch\tprogs\t\t$(srcdir)\t$(HEADER_DEPS)\ndiff --git a/test/programs b/test/programs\nindex f6a48f3a6..b9faf99de 100644\n--- a/test/programs\n+++ b/test/programs\n@@ -1,4 +1,4 @@\n-# $Id: programs,v 1.46 2020/03/21 15:55:22 tom Exp $\n+# $Id: programs,v 1.47 2020/05/29 23:27:58 tom Exp $\n ##############################################################################\n # Copyright 2018-2019,2020 Thomas E. Dickey                                  #\n # Copyright 2006-2016,2017 Free Software Foundation, Inc.                    #\n@@ -102,6 +102,7 @@ test_opaque\t$(LDFLAGS_CURSES)\t$(LOCAL_LIBS)\ttest_opaque\n test_setupterm\t$(LDFLAGS_CURSES)\t$(LOCAL_LIBS)\ttest_setupterm\n test_sgr\t$(LDFLAGS_TINFO)\t$(LOCAL_LIBS)\ttest_sgr\n test_termattrs\t$(LDFLAGS_CURSES)\t$(LOCAL_LIBS)\ttest_termattrs\n+test_tparm\t$(LDFLAGS_TINFO)\t$(LOCAL_LIBS)\ttest_tparm\n test_vid_puts\t$(LDFLAGS_CURSES)\t$(LOCAL_LIBS)\ttest_vid_puts\n test_vidputs\t$(LDFLAGS_CURSES)\t$(LOCAL_LIBS)\ttest_vidputs\n testaddch\t$(LDFLAGS_CURSES)\t$(LOCAL_LIBS)\ttestaddch\ndiff --git a/test/test_tparm.c b/test/test_tparm.c\nnew file mode 100644\nindex 000000000..40ffc4fb1\n--- /dev/null\n+++ b/test/test_tparm.c\n@@ -0,0 +1,388 @@\n+/****************************************************************************\n+ * Copyright 2020 Thomas E. Dickey                                          *\n+ *                                                                          *\n+ * Permission is hereby granted, free of charge, to any person obtaining a  *\n+ * copy of this software and associated documentation files (the            *\n+ * \"Software\"), to deal in the Software without restriction, including      *\n+ * without limitation the rights to use, copy, modify, merge, publish,      *\n+ * distribute, distribute with modifications, sublicense, and/or sell       *\n+ * copies of the Software, and to permit persons to whom the Software is    *\n+ * furnished to do so, subject to the following conditions:                 *\n+ *                                                                          *\n+ * The above copyright notice and this permission notice shall be included  *\n+ * in all copies or substantial portions of the Software.                   *\n+ *                                                                          *\n+ * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS  *\n+ * OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF               *\n+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.   *\n+ * IN NO EVENT SHALL THE ABOVE COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,   *\n+ * DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR    *\n+ * OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR    *\n+ * THE USE OR OTHER DEALINGS IN THE SOFTWARE.                               *\n+ *                                                                          *\n+ * Except as contained in this notice, the name(s) of the above copyright   *\n+ * holders shall not be used in advertising or otherwise to promote the     *\n+ * sale, use or other dealings in this Software without prior written       *\n+ * authorization.                                                           *\n+ ****************************************************************************/\n+\n+/*\n+ * Author: Thomas E. Dickey\n+ *\n+ * $Id: test_tparm.c,v 1.4 2020/05/31 00:51:32 tom Exp $\n+ *\n+ * Exercise tparm, either for all possible capabilities with fixed parameters,\n+ * or one capability with all possible parameters.\n+ *\n+ * TODO: incorporate tic.h and _nc_tparm_analyze\n+ * TODO: optionally test tiparm\n+ * TODO: add checks/logic to handle \"%s\" in tparm\n+ */\n+#define USE_TINFO\n+#include <test.priv.h>\n+\n+static void failed(const char *) GCC_NORETURN;\n+\n+static void\n+failed(const char *msg)\n+{\n+    fprintf(stderr, \"%s\\n\", msg);\n+    ExitProgram(EXIT_FAILURE);\n+}\n+\n+#if HAVE_TIGETSTR\n+\n+static int a_opt;\n+static int v_opt;\n+\n+static int\n+isNumeric(char *source)\n+{\n+    char *next = 0;\n+    long value = strtol(source, &next, 0);\n+    int result = (next == 0 || next == source || *next != '\\0') ? 0 : 1;\n+    (void) value;\n+    return result;\n+}\n+\n+static char *\n+validate(const char *name)\n+{\n+    char *value = tigetstr(name);\n+    if (!VALID_STRING(value)) {\n+\tif (v_opt > 1) {\n+\t    printf(\"? %s %s\\n\",\n+\t\t   (value == ABSENT_STRING)\n+\t\t   ? \"absent\"\n+\t\t   : \"cancel\",\n+\t\t   name);\n+\t}\n+\tvalue = 0;\n+    }\n+    return value;\n+}\n+\n+static int\n+increment(int *all_parms, int *num_parms, int len_parms, int end_parms)\n+{\n+    int rc = 0;\n+    int n;\n+\n+    if (len_parms > 9)\n+\tlen_parms = 9;\n+\n+    if (end_parms < len_parms) {\n+\tif (all_parms[end_parms]++ >= num_parms[end_parms]) {\n+\t    all_parms[end_parms] = 0;\n+\t    increment(all_parms, num_parms, len_parms, end_parms + 1);\n+\t}\n+    }\n+    for (n = 0; n < len_parms; ++n) {\n+\tif (all_parms[n] != 0) {\n+\t    rc = 1;\n+\t    break;\n+\t}\n+    }\n+    /* return 1 until the vector resets to all 0's */\n+    return rc;\n+}\n+\n+static void\n+test_tparm(const char *name, int *number)\n+{\n+    char *format = tigetstr(name);\n+    if ((format = validate(name)) != 0) {\n+\tchar *result = tparm(format,\n+\t\t\t     number[0],\n+\t\t\t     number[1],\n+\t\t\t     number[2],\n+\t\t\t     number[3],\n+\t\t\t     number[4],\n+\t\t\t     number[5],\n+\t\t\t     number[6],\n+\t\t\t     number[7],\n+\t\t\t     number[8]);\n+\tif (v_opt > 1)\n+\t    printf(\".. %2d = %2d %2d %2d %2d %2d %2d %2d %2d %2d %s\\n\",\n+\t\t   result != 0 ? (int) strlen(result) : -1,\n+\t\t   number[0],\n+\t\t   number[1],\n+\t\t   number[2],\n+\t\t   number[3],\n+\t\t   number[4],\n+\t\t   number[5],\n+\t\t   number[6],\n+\t\t   number[7],\n+\t\t   number[8],\n+\t\t   name);\n+    }\n+}\n+\n+static void\n+usage(void)\n+{\n+    static const char *msg[] =\n+    {\n+\t\"Usage: test_tparm [options] [capability] [value1 [value2 [...]]]\",\n+\t\"\",\n+\t\"Print all distinct combinations of given capability.\",\n+\t\"\",\n+\t\"Options:\",\n+\t\" -T TERM  override $TERM; this may be a comma-separated list or \\\"-\\\"\",\n+\t\"          to read a list from standard-input\",\n+\t\" -a       if capability is given, test all combinations of values\",\n+\t\" -r NUM   repeat tests NUM times\",\n+\t\" -v       show values and results\",\n+    };\n+    unsigned n;\n+    for (n = 0; n < SIZEOF(msg); ++n) {\n+\tfprintf(stderr, \"%s\\n\", msg[n]);\n+    }\n+    ExitProgram(EXIT_FAILURE);\n+}\n+\n+#define PLURAL(n) n, (n != 1) ? \"s\" : \"\"\n+#define COLONS(n) (n >= 1) ? \":\" : \"\"\n+\n+int\n+main(int argc, char *argv[])\n+{\n+    int n;\n+    int r_run, t_run, n_run;\n+    char *old_term = getenv(\"TERM\");\n+    int r_opt = 1;\n+    char *t_opt = 0;\n+    int len_names = 0;\t\t/* cur # of items in all_names[] */\n+    int use_names = 10;\t\t/* max # of items in all_names[] */\n+    char **all_names = typeCalloc(char *, use_names);\n+    int all_parms[10];\t\t/* workspace for \"-a\" option */\n+    int len_terms = 0;\t\t/* cur # of items in all_terms[] */\n+    int use_terms = 10;\t\t/* max # of items in all_terms[] */\n+    char **all_terms = typeCalloc(char *, use_terms);\n+    int len_parms = 0;\t\t/* cur # of items in num_parms[], str_parms[] */\n+    int use_parms = argc + 10;\t/* max # of items in num_parms[], str_parms[] */\n+    int *num_parms = typeCalloc(int, use_parms);\n+    char **str_parms = typeCalloc(char *, use_parms);\n+\n+    if (all_names == 0 || all_terms == 0 || num_parms == 0 || str_parms == 0)\n+\tfailed(\"no memory\");\n+\n+    while ((n = getopt(argc, argv, \"T:ar:v\")) != -1) {\n+\tswitch (n) {\n+\tcase 'T':\n+\t    t_opt = optarg;\n+\t    break;\n+\tcase 'a':\n+\t    ++a_opt;\n+\t    break;\n+\tcase 'r':\n+\t    r_opt = atoi(optarg);\n+\t    break;\n+\tcase 'v':\n+\t    ++v_opt;\n+\t    break;\n+\tdefault:\n+\t    usage();\n+\t    break;\n+\t}\n+    }\n+\n+    /*\n+     * If there is a nonnumeric parameter after the options, use that as the\n+     * capability name.\n+     */\n+    if (optind < argc) {\n+\tif (!isNumeric(argv[optind])) {\n+\t    all_names[len_names++] = strdup(argv[optind++]);\n+\t}\n+    }\n+\n+    /*\n+     * Any remaining arguments must be possible parameter values.  If numeric,\n+     * and \"-a\" is not set, use those as the maximum values within which the\n+     * test parameters should vary.\n+     */\n+    while (optind < argc) {\n+\tif (isNumeric(argv[optind])) {\n+\t    char *dummy = 0;\n+\t    long value = strtol(argv[optind], &dummy, 0);\n+\t    num_parms[len_parms] = (int) value;\n+\t}\n+\tstr_parms[len_parms] = argv[optind];\n+\t++optind;\n+\t++len_parms;\n+    }\n+    for (n = len_parms; n < use_parms; ++n) {\n+\tstatic char dummy[1];\n+\tstr_parms[n] = dummy;\n+    }\n+    if (v_opt) {\n+\tprintf(\"%d parameter%s%s\\n\", PLURAL(len_parms), COLONS(len_parms));\n+\tfor (n = 0; n < len_parms; ++n) {\n+\t    printf(\" %d: %d (%s)\\n\", n + 1, num_parms[n], str_parms[n]);\n+\t}\n+    }\n+\n+    /*\n+     * Make a list of values for $TERM.  Accept \"-\" for standard input to\n+     * simplify scripting a check of the whole database.\n+     */\n+    old_term = strdup((old_term == 0) ? \"unknown\" : old_term);\n+    if (t_opt != 0) {\n+\tif (!strcmp(t_opt, \"-\")) {\n+\t    char buffer[BUFSIZ];\n+\t    while (fgets(buffer, sizeof(buffer) - 1, stdin) != 0) {\n+\t\tchar *s = buffer;\n+\t\tchar *t;\n+\t\twhile (isspace(UChar(s[0])))\n+\t\t    ++s;\n+\t\tt = s + strlen(s);\n+\t\twhile (t != s && isspace(UChar(t[-1])))\n+\t\t    *--t = '\\0';\n+\t\ts = strdup(s);\n+\t\tif (len_terms + 2 >= use_terms) {\n+\t\t    use_terms *= 2;\n+\t\t    all_terms = typeRealloc(char *, use_terms, all_terms);\n+\t\t    if (all_terms == 0)\n+\t\t\tfailed(\"no memory: all_terms\");\n+\t\t}\n+\t\tall_terms[len_terms++] = s;\n+\t    }\n+\t} else {\n+\t    char *s = t_opt;\n+\t    char *t;\n+\t    while ((t = strtok(s, \",\")) != 0) {\n+\t\ts = 0;\n+\t\tif (len_terms + 2 >= use_terms) {\n+\t\t    use_terms *= 2;\n+\t\t    all_terms = typeRealloc(char *, use_terms, all_terms);\n+\t\t    if (all_terms == 0)\n+\t\t\tfailed(\"no memory: all_terms\");\n+\t\t}\n+\t\tall_terms[len_terms++] = strdup(t);\n+\t    }\n+\t}\n+    } else {\n+\tall_terms[len_terms++] = strdup(old_term);\n+    }\n+    all_terms[len_terms] = 0;\n+    if (v_opt) {\n+\tprintf(\"%d term%s:\\n\", PLURAL(len_terms));\n+\tfor (n = 0; n < len_terms; ++n) {\n+\t    printf(\" %d: %s\\n\", n + 1, all_terms[n]);\n+\t}\n+    }\n+\n+    /*\n+     * If no capability name was selected, use the predefined list of string\n+     * capabilities.\n+     *\n+     * TODO: To address the \"other\" systems which do not follow SVr4,\n+     * just use the output from infocmp on $TERM.\n+     */\n+    if (len_names == 0) {\n+#if defined(HAVE_CURSES_DATA_BOOLNAMES) || defined(DECL_CURSES_DATA_BOOLNAMES)\n+\tfor (n = 0; strnames[n] != 0; ++n) {\n+\t    if (len_names + 2 >= use_names) {\n+\t\tuse_names *= 2;\n+\t\tall_names = typeRealloc(char *, use_names, all_names);\n+\t\tif (all_names == 0) {\n+\t\t    failed(\"no memory: all_names\");\n+\t\t}\n+\t    }\n+\t    all_names[len_names++] = strdup(strnames[n]);\n+\t}\n+#else\n+\tall_names[len_names++] = strdup(\"cup\");\n+\tall_names[len_names++] = strdup(\"sgr\");\n+#endif\n+    }\n+    all_names[len_names] = 0;\n+    if (v_opt) {\n+\tprintf(\"%d name%s%s\\n\", PLURAL(len_names), COLONS(len_names));\n+\tfor (n = 0; n < len_names; ++n) {\n+\t    printf(\" %d: %s\\n\", n + 1, all_names[n]);\n+\t}\n+    }\n+\n+    if (r_opt <= 0)\n+\tr_opt = 1;\n+\n+    for (r_run = 0; r_run < r_opt; ++r_run) {\n+\tfor (t_run = 0; t_run < len_terms; ++t_run) {\n+\t    int errs;\n+\n+\t    if (setupterm(all_terms[t_run], fileno(stdout), &errs) != OK) {\n+\t\tprintf(\"** skipping %s (errs:%d)\\n\", all_terms[t_run], errs);\n+\t    }\n+\n+\t    if (v_opt)\n+\t\tprintf(\"** testing %s\\n\", all_terms[t_run]);\n+\t    if (len_names == 1) {\n+\t\tif (a_opt) {\n+\t\t    /* for each combination of values */\n+\t\t    memset(all_parms, 0, sizeof(all_parms));\n+\t\t    do {\n+\t\t\ttest_tparm(all_names[0], all_parms);\n+\t\t    }\n+\t\t    while (increment(all_parms, num_parms, len_parms, 0));\n+\t\t} else {\n+\t\t    /* for the given values */\n+\t\t    test_tparm(all_names[0], num_parms);\n+\t\t}\n+\t    } else {\n+\t\tfor (n_run = 0; n_run < len_names; ++n_run) {\n+\t\t    test_tparm(all_names[n_run], num_parms);\n+\t\t}\n+\t    }\n+\t    if (cur_term != 0) {\n+\t\tdel_curterm(cur_term);\n+\t    } else {\n+\t\tprintf(\"? no cur_term\\n\");\n+\t    }\n+\t}\n+    }\n+#if NO_LEAKS\n+    for (n = 0; n < len_names; ++n) {\n+\tfree(all_names[n]);\n+    }\n+    free(all_names);\n+    free(old_term);\n+    for (n = 0; n < len_terms; ++n) {\n+\tfree(all_terms[n]);\n+    }\n+    free(all_terms);\n+    free(num_parms);\n+    free(str_parms);\n+#endif\n+\n+    ExitProgram(EXIT_SUCCESS);\n+}\n+\n+#else /* !HAVE_TIGETSTR */\n+int\n+main(int argc GCC_UNUSED, char *argv[]GCC_UNUSED)\n+{\n+    failed(\"This program requires the terminfo functions such as tigetstr\");\n+}\n+#endif /* HAVE_TIGETSTR */\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "00fffbc1a15e2696a89c721d0c94dc333ff419ef",
        "repo": "torproject/tor",
        "msg": "Don't give the Guard flag to relays without the CVE-2011-2768 fixTor before 0.2.2.34, when configured as a client or bridge, sends a TLS certificate chain as part of an outgoing OR connection, which allows remote relays to bypass intended anonymity properties by reading this chain and then determining the set of entry guards that the client or bridge had selected.",
        "filename": "dirserv.c",
        "diff": "diff --git a/changes/issue-2011-10-19L b/changes/issue-2011-10-19L\nindex 1fefd7267e8..b879c9d401d 100644\n--- a/changes/issue-2011-10-19L\n+++ b/changes/issue-2011-10-19L\n@@ -19,3 +19,10 @@\n       client is connected to a patched relay.  Bugfix on FIXME; found\n       by frosty_un.\n \n+    - Don't assign the Guard flag to relays running a version of Tor\n+      which would use an OR connection on which it has received a\n+      CREATE_FAST cell to satisfy an EXTEND request.  Mitigates\n+      CVE-2011-2768, by ensuring that clients will not connect\n+      directly to any relay which an attacker could probe for an\n+      unpatched client's connections.\n+\ndiff --git a/src/or/dirserv.c b/src/or/dirserv.c\nindex 66079018abe..fa7f693afe4 100644\n--- a/src/or/dirserv.c\n+++ b/src/or/dirserv.c\n@@ -2251,6 +2251,74 @@ get_possible_sybil_list(const smartlist_t *routers)\n   return omit_as_sybil;\n }\n \n+/** Return non-zero iff a relay running the Tor version specified in\n+ * <b>platform</b> is suitable for use as a potential entry guard. */\n+static int\n+is_router_version_good_for_possible_guard(const char *platform)\n+{\n+  static int parsed_versions_initialized = 0;\n+  static tor_version_t first_good_0_2_1_guard_version;\n+  static tor_version_t first_good_0_2_2_guard_version;\n+  static tor_version_t first_good_later_guard_version;\n+\n+  tor_version_t router_version;\n+\n+  /* XXX023 This block should be extracted into its own function. */\n+  /* XXXX Begin code copied from tor_version_as_new_as (in routerparse.c) */\n+  {\n+    char *s, *s2, *start;\n+    char tmp[128];\n+\n+    tor_assert(platform);\n+\n+    if (strcmpstart(platform,\"Tor \")) /* nonstandard Tor; be safe and say yes */\n+      return 1;\n+\n+    start = (char *)eat_whitespace(platform+3);\n+    if (!*start) return 0;\n+    s = (char *)find_whitespace(start); /* also finds '\\0', which is fine */\n+    s2 = (char*)eat_whitespace(s);\n+    if (!strcmpstart(s2, \"(r\") || !strcmpstart(s2, \"(git-\"))\n+      s = (char*)find_whitespace(s2);\n+\n+    if ((size_t)(s-start+1) >= sizeof(tmp)) /* too big, no */\n+      return 0;\n+    strlcpy(tmp, start, s-start+1);\n+\n+    if (tor_version_parse(tmp, &router_version)<0) {\n+      log_info(LD_DIR,\"Router version '%s' unparseable.\",tmp);\n+      return 1; /* be safe and say yes */\n+    }\n+  }\n+  /* XXXX End code copied from tor_version_as_new_as (in routerparse.c) */\n+\n+  if (!parsed_versions_initialized) {\n+    /* CVE-2011-2769 was fixed on the relay side in Tor versions\n+     * 0.2.1.31, 0.2.2.34, and 0.2.3.6-alpha. */\n+    tor_assert(tor_version_parse(\"0.2.1.31\",\n+                                 &first_good_0_2_1_guard_version)>=0);\n+    tor_assert(tor_version_parse(\"0.2.2.34\",\n+                                 &first_good_0_2_2_guard_version)>=0);\n+    tor_assert(tor_version_parse(\"0.2.3.6-alpha\",\n+                                 &first_good_later_guard_version)>=0);\n+\n+    /* Don't parse these constant version strings once for every relay\n+     * for every vote. */\n+    parsed_versions_initialized = 1;\n+  }\n+\n+  return ((tor_version_same_series(&first_good_0_2_1_guard_version,\n+                                   &router_version) &&\n+           tor_version_compare(&first_good_0_2_1_guard_version,\n+                               &router_version) <= 0) ||\n+          (tor_version_same_series(&first_good_0_2_2_guard_version,\n+                                   &router_version) &&\n+           tor_version_compare(&first_good_0_2_2_guard_version,\n+                               &router_version) <= 0) ||\n+          (tor_version_compare(&first_good_later_guard_version,\n+                               &router_version) <= 0));\n+}\n+\n /** Extract status information from <b>ri</b> and from other authority\n  * functions and store it in <b>rs</b>>.  If <b>naming</b>, consider setting\n  * the named flag in <b>rs</b>.\n@@ -2294,7 +2362,8 @@ set_routerstatus_from_routerinfo(routerstatus_t *rs,\n       (router_get_advertised_bandwidth(ri) >= BANDWIDTH_TO_GUARANTEE_GUARD ||\n        router_get_advertised_bandwidth(ri) >=\n                               MIN(guard_bandwidth_including_exits,\n-                                  guard_bandwidth_excluding_exits))) {\n+                                  guard_bandwidth_excluding_exits)) &&\n+      is_router_version_good_for_possible_guard(ri->platform)) {\n     long tk = rep_hist_get_weighted_time_known(\n                                       ri->cache_info.identity_digest, now);\n     double wfu = rep_hist_get_weighted_fractional_uptime(\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "d6c67629ed05aae436164eec474832daf8ba7420",
        "repo": "vim/vim",
        "msg": "patch 9.0.0260: using freed memory when using 'quickfixtextfunc' recursively\n\nProblem:    Using freed memory when using 'quickfixtextfunc' recursively.\nSolution:   Do not allow for recursion.Use After Free in GitHub repository vim/vim prior to 9.0.0260.",
        "filename": "None",
        "diff": "diff --git a/src/quickfix.c b/src/quickfix.c\nindex 54ae07df53d4f..6af62e8dfe56d 100644\n--- a/src/quickfix.c\n+++ b/src/quickfix.c\n@@ -4674,6 +4674,11 @@ call_qftf_func(qf_list_T *qfl, int qf_winid, long start_idx, long end_idx)\n {\n     callback_T\t*cb = &qftf_cb;\n     list_T\t*qftf_list = NULL;\n+    static int\trecursive = FALSE;\n+\n+    if (recursive)\n+\treturn NULL;  // this doesn't work properly recursively\n+    recursive = TRUE;\n \n     // If 'quickfixtextfunc' is set, then use the user-supplied function to get\n     // the text to display. Use the local value of 'quickfixtextfunc' if it is\n@@ -4688,7 +4693,10 @@ call_qftf_func(qf_list_T *qfl, int qf_winid, long start_idx, long end_idx)\n \n \t// create the dict argument\n \tif ((d = dict_alloc_lock(VAR_FIXED)) == NULL)\n+\t{\n+\t    recursive = FALSE;\n \t    return NULL;\n+\t}\n \tdict_add_number(d, \"quickfix\", (long)IS_QF_LIST(qfl));\n \tdict_add_number(d, \"winid\", (long)qf_winid);\n \tdict_add_number(d, \"id\", (long)qfl->qf_id);\n@@ -4711,6 +4719,7 @@ call_qftf_func(qf_list_T *qfl, int qf_winid, long start_idx, long end_idx)\n \tdict_unref(d);\n     }\n \n+    recursive = FALSE;\n     return qftf_list;\n }\n \ndiff --git a/src/testdir/test_quickfix.vim b/src/testdir/test_quickfix.vim\nindex 94651af819423..762fa8d8d0e3c 100644\n--- a/src/testdir/test_quickfix.vim\n+++ b/src/testdir/test_quickfix.vim\n@@ -6351,4 +6351,17 @@ func Test_qflist_statusmsg()\n   %bw!\n endfunc\n \n+func Test_quickfixtextfunc_recursive()\n+  func s:QFTfunc(o)\n+    cgete '0'\n+  endfunc\n+  copen\n+  let &quickfixtextfunc = 's:QFTfunc'\n+  cex \"\"\n+\n+  let &quickfixtextfunc = ''\n+  cclose\n+endfunc\n+\n+\n \" vim: shiftwidth=2 sts=2 expandtab\ndiff --git a/src/version.c b/src/version.c\nindex b1943bb161571..02c20f03f6026 100644\n--- a/src/version.c\n+++ b/src/version.c\n@@ -731,6 +731,8 @@ static char *(features[]) =\n \n static int included_patches[] =\n {   /* Add new patch number below this line */\n+/**/\n+    260,\n /**/\n     259,\n /**/\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "524de6cc35d3b222f0e940bb0fd027f5482572c5",
        "repo": "libvirt/libvirt",
        "msg": "virstoragetest: testBackingParse: Use VIR_DOMAIN_DEF_FORMAT_SECURE when formatting xml\n\nWe want to format even the secure information in tests.\n\nSigned-off-by: Peter Krempa <pkrempa@redhat.com>\nReviewed-by: Erik Skultety <eskultet@redhat.com>An information disclosure vulnerability was found in libvirt in versions before 6.3.0. HTTP cookies used to access network-based disks were saved in the XML dump of the guest domain. This flaw allows an attacker to access potentially sensitive information in the domain configuration via the `dumpxml` command.",
        "filename": "virstoragetest.c",
        "diff": "diff --git a/tests/virstoragetest.c b/tests/virstoragetest.c\nindex 6e8ebeba134..6d2b21c25f3 100644\n--- a/tests/virstoragetest.c\n+++ b/tests/virstoragetest.c\n@@ -594,6 +594,7 @@ testBackingParse(const void *args)\n     g_autoptr(virStorageSource) src = NULL;\n     int rc;\n     int erc = data->rv;\n+    unsigned int xmlformatflags = VIR_DOMAIN_DEF_FORMAT_SECURE;\n \n     /* expect failure return code with NULL expected data */\n     if (!data->expect)\n@@ -613,7 +614,7 @@ testBackingParse(const void *args)\n         return -1;\n     }\n \n-    if (virDomainDiskSourceFormat(&buf, src, \"source\", 0, false, 0, true, NULL) < 0 ||\n+    if (virDomainDiskSourceFormat(&buf, src, \"source\", 0, false, xmlformatflags, true, NULL) < 0 ||\n         !(xml = virBufferContentAndReset(&buf))) {\n         fprintf(stderr, \"failed to format disk source xml\\n\");\n         return -1;\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "395bd1f6d3edc9f7edb5d1f2d7deaf5a9e3ab93c",
        "repo": "vim/vim",
        "msg": "patch 8.2.4956: reading past end of line with \"gf\" in Visual block mode\n\nProblem:    Reading past end of line with \"gf\" in Visual block mode.\nSolution:   Do not include the NUL in the length.Buffer Over-read in function grab_file_name in GitHub repository vim/vim prior to 8.2.4956. This vulnerability is capable of crashing the software, memory modification, and possible remote execution.",
        "filename": "normal.c",
        "diff": "diff --git a/src/normal.c b/src/normal.c\nindex 1baf68a1453ae..bc3e29e1abaa1 100644\n--- a/src/normal.c\n+++ b/src/normal.c\n@@ -3671,9 +3671,16 @@ get_visual_text(\n \t}\n \tif (**pp == NUL)\n \t    *lenp = 0;\n-\tif (has_mbyte && *lenp > 0)\n-\t    // Correct the length to include all bytes of the last character.\n-\t    *lenp += (*mb_ptr2len)(*pp + (*lenp - 1)) - 1;\n+\tif (*lenp > 0)\n+\t{\n+\t    if (has_mbyte)\n+\t\t// Correct the length to include all bytes of the last\n+\t\t// character.\n+\t\t*lenp += (*mb_ptr2len)(*pp + (*lenp - 1)) - 1;\n+\t    else if ((*pp)[*lenp - 1] == NUL)\n+\t\t// Do not include a trailing NUL.\n+\t\t*lenp -= 1;\n+\t}\n     }\n     reset_VIsual_and_resel();\n     return OK;\ndiff --git a/src/testdir/test_gf.vim b/src/testdir/test_gf.vim\nindex 3602ba010e8c4..1b3b139810eca 100644\n--- a/src/testdir/test_gf.vim\n+++ b/src/testdir/test_gf.vim\n@@ -138,6 +138,21 @@ func Test_gf_visual()\n   call assert_equal('Xtest_gf_visual', bufname('%'))\n   call assert_equal(3, getcurpos()[1])\n \n+  \" do not include the NUL at the end \n+  call writefile(['x'], 'X')\n+  let save_enc = &enc\n+  for enc in ['latin1', 'utf-8']\n+    exe \"set enc=\" .. enc\n+    new\n+    call setline(1, 'X')\n+    set nomodified\n+    exe \"normal \\<C-V>$gf\"\n+    call assert_equal('X', bufname())\n+    bwipe!\n+  endfor\n+  let &enc = save_enc\n+  call delete('X')\n+\n   \" line number in visual area is used for file name\n   if has('unix')\n     bwipe!\ndiff --git a/src/version.c b/src/version.c\nindex 62e2b0af69411..821f3680e2fb5 100644\n--- a/src/version.c\n+++ b/src/version.c\n@@ -746,6 +746,8 @@ static char *(features[]) =\n \n static int included_patches[] =\n {   /* Add new patch number below this line */\n+/**/\n+    4956,\n /**/\n     4955,\n /**/\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "2a8859f373b0a86f0ece8ec8312607eacf12485d",
        "repo": "torvalds/linux",
        "msg": "KVM: x86/mmu: do compare-and-exchange of gPTE via the user address\n\nFNAME(cmpxchg_gpte) is an inefficient mess.  It is at least decent if it\ncan go through get_user_pages_fast(), but if it cannot then it tries to\nuse memremap(); that is not just terribly slow, it is also wrong because\nit assumes that the VM_PFNMAP VMA is contiguous.\n\nThe right way to do it would be to do the same thing as\nhva_to_pfn_remapped() does since commit add6a0cd1c5b (\"KVM: MMU: try to\nfix up page faults before giving up\", 2016-07-05), using follow_pte()\nand fixup_user_fault() to determine the correct address to use for\nmemremap().  To do this, one could for example extract hva_to_pfn()\nfor use outside virt/kvm/kvm_main.c.  But really there is no reason to\ndo that either, because there is already a perfectly valid address to\ndo the cmpxchg() on, only it is a userspace address.  That means doing\nuser_access_begin()/user_access_end() and writing the code in assembly\nto handle exceptions correctly.  Worse, the guest PTE can be 8-byte\neven on i686 so there is the extra complication of using cmpxchg8b to\naccount for.  But at least it is an efficient mess.\n\n(Thanks to Linus for suggesting improvement on the inline assembly).\n\nReported-by: Qiuhao Li <qiuhao@sysec.org>\nReported-by: Gaoning Pan <pgn@zju.edu.cn>\nReported-by: Yongkang Jia <kangel@zju.edu.cn>\nReported-by: syzbot+6cde2282daa792c49ab8@syzkaller.appspotmail.com\nDebugged-by: Tadeusz Struk <tadeusz.struk@linaro.org>\nTested-by: Maxim Levitsky <mlevitsk@redhat.com>\nCc: stable@vger.kernel.org\nFixes: bd53cb35a3e9 (\"X86/KVM: Handle PFNs outside of kernel reach when touching GPTEs\")\nSigned-off-by: Paolo Bonzini <pbonzini@redhat.com>A flaw was found in KVM. When updating a guest's page table entry, vm_pgoff was improperly used as the offset to get the page's pfn. As vaddr and vm_pgoff are controllable by user-mode processes, this flaw allows unprivileged local users on the host to write outside the userspace region and potentially corrupt the kernel, resulting in a denial of service condition.",
        "filename": "paging_tmpl.h",
        "diff": "diff --git a/arch/x86/kvm/mmu/paging_tmpl.h b/arch/x86/kvm/mmu/paging_tmpl.h\nindex 8621188b46df5a..01fee5f67ac370 100644\n--- a/arch/x86/kvm/mmu/paging_tmpl.h\n+++ b/arch/x86/kvm/mmu/paging_tmpl.h\n@@ -34,9 +34,8 @@\n \t#define PT_HAVE_ACCESSED_DIRTY(mmu) true\n \t#ifdef CONFIG_X86_64\n \t#define PT_MAX_FULL_LEVELS PT64_ROOT_MAX_LEVEL\n-\t#define CMPXCHG cmpxchg\n+\t#define CMPXCHG \"cmpxchgq\"\n \t#else\n-\t#define CMPXCHG cmpxchg64\n \t#define PT_MAX_FULL_LEVELS 2\n \t#endif\n #elif PTTYPE == 32\n@@ -52,7 +51,7 @@\n \t#define PT_GUEST_DIRTY_SHIFT PT_DIRTY_SHIFT\n \t#define PT_GUEST_ACCESSED_SHIFT PT_ACCESSED_SHIFT\n \t#define PT_HAVE_ACCESSED_DIRTY(mmu) true\n-\t#define CMPXCHG cmpxchg\n+\t#define CMPXCHG \"cmpxchgl\"\n #elif PTTYPE == PTTYPE_EPT\n \t#define pt_element_t u64\n \t#define guest_walker guest_walkerEPT\n@@ -65,7 +64,9 @@\n \t#define PT_GUEST_DIRTY_SHIFT 9\n \t#define PT_GUEST_ACCESSED_SHIFT 8\n \t#define PT_HAVE_ACCESSED_DIRTY(mmu) ((mmu)->ept_ad)\n-\t#define CMPXCHG cmpxchg64\n+\t#ifdef CONFIG_X86_64\n+\t#define CMPXCHG \"cmpxchgq\"\n+\t#endif\n \t#define PT_MAX_FULL_LEVELS PT64_ROOT_MAX_LEVEL\n #else\n \t#error Invalid PTTYPE value\n@@ -147,43 +148,36 @@ static int FNAME(cmpxchg_gpte)(struct kvm_vcpu *vcpu, struct kvm_mmu *mmu,\n \t\t\t       pt_element_t __user *ptep_user, unsigned index,\n \t\t\t       pt_element_t orig_pte, pt_element_t new_pte)\n {\n-\tint npages;\n-\tpt_element_t ret;\n-\tpt_element_t *table;\n-\tstruct page *page;\n-\n-\tnpages = get_user_pages_fast((unsigned long)ptep_user, 1, FOLL_WRITE, &page);\n-\tif (likely(npages == 1)) {\n-\t\ttable = kmap_atomic(page);\n-\t\tret = CMPXCHG(&table[index], orig_pte, new_pte);\n-\t\tkunmap_atomic(table);\n-\n-\t\tkvm_release_page_dirty(page);\n-\t} else {\n-\t\tstruct vm_area_struct *vma;\n-\t\tunsigned long vaddr = (unsigned long)ptep_user & PAGE_MASK;\n-\t\tunsigned long pfn;\n-\t\tunsigned long paddr;\n-\n-\t\tmmap_read_lock(current->mm);\n-\t\tvma = find_vma_intersection(current->mm, vaddr, vaddr + PAGE_SIZE);\n-\t\tif (!vma || !(vma->vm_flags & VM_PFNMAP)) {\n-\t\t\tmmap_read_unlock(current->mm);\n-\t\t\treturn -EFAULT;\n-\t\t}\n-\t\tpfn = ((vaddr - vma->vm_start) >> PAGE_SHIFT) + vma->vm_pgoff;\n-\t\tpaddr = pfn << PAGE_SHIFT;\n-\t\ttable = memremap(paddr, PAGE_SIZE, MEMREMAP_WB);\n-\t\tif (!table) {\n-\t\t\tmmap_read_unlock(current->mm);\n-\t\t\treturn -EFAULT;\n-\t\t}\n-\t\tret = CMPXCHG(&table[index], orig_pte, new_pte);\n-\t\tmemunmap(table);\n-\t\tmmap_read_unlock(current->mm);\n-\t}\n+\tsigned char r;\n \n-\treturn (ret != orig_pte);\n+\tif (!user_access_begin(ptep_user, sizeof(pt_element_t)))\n+\t\treturn -EFAULT;\n+\n+#ifdef CMPXCHG\n+\tasm volatile(\"1:\" LOCK_PREFIX CMPXCHG \" %[new], %[ptr]\\n\"\n+\t\t     \"setnz %b[r]\\n\"\n+\t\t     \"2:\"\n+\t\t     _ASM_EXTABLE_TYPE_REG(1b, 2b, EX_TYPE_EFAULT_REG, %k[r])\n+\t\t     : [ptr] \"+m\" (*ptep_user),\n+\t\t       [old] \"+a\" (orig_pte),\n+\t\t       [r] \"=q\" (r)\n+\t\t     : [new] \"r\" (new_pte)\n+\t\t     : \"memory\");\n+#else\n+\tasm volatile(\"1:\" LOCK_PREFIX \"cmpxchg8b %[ptr]\\n\"\n+\t\t     \"setnz %b[r]\\n\"\n+\t\t     \"2:\"\n+\t\t     _ASM_EXTABLE_TYPE_REG(1b, 2b, EX_TYPE_EFAULT_REG, %k[r])\n+\t\t     : [ptr] \"+m\" (*ptep_user),\n+\t\t       [old] \"+A\" (orig_pte),\n+\t\t       [r] \"=q\" (r)\n+\t\t     : [new_lo] \"b\" ((u32)new_pte),\n+\t\t       [new_hi] \"c\" ((u32)(new_pte >> 32))\n+\t\t     : \"memory\");\n+#endif\n+\n+\tuser_access_end();\n+\treturn r;\n }\n \n static bool FNAME(prefetch_invalid_gpte)(struct kvm_vcpu *vcpu,\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "560a1346f87aabe126509bb24930106dea292b00",
        "repo": "pjsip/pjproject",
        "msg": "Merge pull request from GHSA-f5qg-pqcg-765mPJSIP is a free and open source multimedia communication library written in C. Versions 2.12 and prior contain a stack buffer overflow vulnerability that affects PJSUA2 users or users that call the API `pjmedia_sdp_print(), pjmedia_sdp_media_print()`. Applications that do not use PJSUA2 and do not directly call `pjmedia_sdp_print()` or `pjmedia_sdp_media_print()` should not be affected. A patch is available on the `master` branch of the `pjsip/pjproject` GitHub repository. There are currently no known workarounds.",
        "filename": "sdp.c",
        "diff": "diff --git a/pjmedia/src/pjmedia/sdp.c b/pjmedia/src/pjmedia/sdp.c\nindex 31446b5424..3905c2f525 100644\n--- a/pjmedia/src/pjmedia/sdp.c\n+++ b/pjmedia/src/pjmedia/sdp.c\n@@ -733,12 +733,21 @@ static int print_media_desc(const pjmedia_sdp_media *m, char *buf, pj_size_t len\n     pj_memcpy(p, m->desc.transport.ptr, m->desc.transport.slen);\n     p += m->desc.transport.slen;\n     for (i=0; i<m->desc.fmt_count; ++i) {\n-\t*p++ = ' ';\n-\tpj_memcpy(p, m->desc.fmt[i].ptr, m->desc.fmt[i].slen);\n-\tp += m->desc.fmt[i].slen;\n+\tif (end-p > m->desc.fmt[i].slen) {\n+\t    *p++ = ' ';\n+\t    pj_memcpy(p, m->desc.fmt[i].ptr, m->desc.fmt[i].slen);\n+\t    p += m->desc.fmt[i].slen;\n+\t} else {\n+\t    return -1;\n+\t}\n+    }\n+\n+    if (end-p >= 2) {\n+\t*p++ = '\\r';\n+\t*p++ = '\\n';\n+    } else {\n+\treturn -1;\n     }\n-    *p++ = '\\r';\n-    *p++ = '\\n';\n \n     /* print connection info, if present. */\n     if (m->conn) {\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "a3727a8bac0a9e77c70820655fd8715523ba3db7",
        "repo": "torvalds/linux",
        "msg": "selinux,smack: fix subjective/objective credential use mixups\n\nJann Horn reported a problem with commit eb1231f73c4d (\"selinux:\nclarify task subjective and objective credentials\") where some LSM\nhooks were attempting to access the subjective credentials of a task\nother than the current task.  Generally speaking, it is not safe to\naccess another task's subjective credentials and doing so can cause\na number of problems.\n\nFurther, while looking into the problem, I realized that Smack was\nsuffering from a similar problem brought about by a similar commit\n1fb057dcde11 (\"smack: differentiate between subjective and objective\ntask credentials\").\n\nThis patch addresses this problem by restoring the use of the task's\nobjective credentials in those cases where the task is other than the\ncurrent executing task.  Not only does this resolve the problem\nreported by Jann, it is arguably the correct thing to do in these\ncases.\n\nCc: stable@vger.kernel.org\nFixes: eb1231f73c4d (\"selinux: clarify task subjective and objective credentials\")\nFixes: 1fb057dcde11 (\"smack: differentiate between subjective and objective task credentials\")\nReported-by: Jann Horn <jannh@google.com>\nAcked-by: Eric W. Biederman <ebiederm@xmission.com>\nAcked-by: Casey Schaufler <casey@schaufler-ca.com>\nSigned-off-by: Paul Moore <paul@paul-moore.com>An issue was discovered in the Linux kernel before 5.14.8. A use-after-free in selinux_ptrace_traceme (aka the SELinux handler for PTRACE_TRACEME) could be used by local attackers to cause memory corruption and escalate privileges, aka CID-a3727a8bac0a. This occurs because of an attempt to access the subjective credentials of another task.",
        "filename": "None",
        "diff": "diff --git a/security/selinux/hooks.c b/security/selinux/hooks.c\nindex 6517f221d52cd2..e7ebd45ca34573 100644\n--- a/security/selinux/hooks.c\n+++ b/security/selinux/hooks.c\n@@ -2157,7 +2157,7 @@ static int selinux_ptrace_access_check(struct task_struct *child,\n static int selinux_ptrace_traceme(struct task_struct *parent)\n {\n \treturn avc_has_perm(&selinux_state,\n-\t\t\t    task_sid_subj(parent), task_sid_obj(current),\n+\t\t\t    task_sid_obj(parent), task_sid_obj(current),\n \t\t\t    SECCLASS_PROCESS, PROCESS__PTRACE, NULL);\n }\n \n@@ -6222,7 +6222,7 @@ static int selinux_msg_queue_msgrcv(struct kern_ipc_perm *msq, struct msg_msg *m\n \tstruct ipc_security_struct *isec;\n \tstruct msg_security_struct *msec;\n \tstruct common_audit_data ad;\n-\tu32 sid = task_sid_subj(target);\n+\tu32 sid = task_sid_obj(target);\n \tint rc;\n \n \tisec = selinux_ipc(msq);\ndiff --git a/security/smack/smack_lsm.c b/security/smack/smack_lsm.c\nindex cacbe751851943..21a0e7c3b8dee5 100644\n--- a/security/smack/smack_lsm.c\n+++ b/security/smack/smack_lsm.c\n@@ -2016,7 +2016,7 @@ static int smk_curacc_on_task(struct task_struct *p, int access,\n \t\t\t\tconst char *caller)\n {\n \tstruct smk_audit_info ad;\n-\tstruct smack_known *skp = smk_of_task_struct_subj(p);\n+\tstruct smack_known *skp = smk_of_task_struct_obj(p);\n \tint rc;\n \n \tsmk_ad_init(&ad, caller, LSM_AUDIT_DATA_TASK);\n@@ -3480,7 +3480,7 @@ static void smack_d_instantiate(struct dentry *opt_dentry, struct inode *inode)\n  */\n static int smack_getprocattr(struct task_struct *p, char *name, char **value)\n {\n-\tstruct smack_known *skp = smk_of_task_struct_subj(p);\n+\tstruct smack_known *skp = smk_of_task_struct_obj(p);\n \tchar *cp;\n \tint slen;\n \n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "8b51dc7291473093c821195c4b6af85fadedbc2f",
        "repo": "torvalds/linux",
        "msg": "rsi: fix a double free bug in rsi_91x_deinit()\n\n`dev` (struct rsi_91x_usbdev *) field of adapter\n(struct rsi_91x_usbdev *) is allocated  and initialized in\n`rsi_init_usb_interface`. If any error is detected in information\nread from the device side,  `rsi_init_usb_interface` will be\nfreed. However, in the higher level error handling code in\n`rsi_probe`, if error is detected, `rsi_91x_deinit` is called\nagain, in which `dev` will be freed again, resulting double free.\n\nThis patch fixes the double free by removing the free operation on\n`dev` in `rsi_init_usb_interface`, because `rsi_91x_deinit` is also\nused in `rsi_disconnect`, in that code path, the `dev` field is not\n (and thus needs to be) freed.\n\nThis bug was found in v4.19, but is also present in the latest version\nof kernel. Fixes CVE-2019-15504.\n\nReported-by: Hui Peng <benquike@gmail.com>\nReported-by: Mathias Payer <mathias.payer@nebelwelt.net>\nSigned-off-by: Hui Peng <benquike@gmail.com>\nReviewed-by: Guenter Roeck <linux@roeck-us.net>\nSigned-off-by: Kalle Valo <kvalo@codeaurora.org>drivers/net/wireless/rsi/rsi_91x_usb.c in the Linux kernel through 5.2.9 has a Double Free via crafted USB device traffic (which may be remote via usbip or usbredir).",
        "filename": "rsi_91x_usb.c",
        "diff": "diff --git a/drivers/net/wireless/rsi/rsi_91x_usb.c b/drivers/net/wireless/rsi/rsi_91x_usb.c\nindex f5048d4b8cb6d3..760eaffeebd64a 100644\n--- a/drivers/net/wireless/rsi/rsi_91x_usb.c\n+++ b/drivers/net/wireless/rsi/rsi_91x_usb.c\n@@ -645,7 +645,6 @@ static int rsi_init_usb_interface(struct rsi_hw *adapter,\n \tkfree(rsi_dev->tx_buffer);\n \n fail_eps:\n-\tkfree(rsi_dev);\n \n \treturn status;\n }\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "672214abb47a802fc000125996e6e0a46c623a4e",
        "repo": "gerbv/gerbv",
        "msg": "Add test to demonstrate buffer overrunAn out-of-bounds write vulnerability exists in the drill format T-code tool number functionality of Gerbv 2.7.0, dev (commit b5f1eacd), and the forked version of Gerbv (commit 71493260). A specially-crafted drill file can lead to code execution. An attacker can provide a malicious file to trigger this vulnerability.",
        "filename": "drill.c",
        "diff": "diff --git a/src/drill.c b/src/drill.c\nindex c571b3b5..7e1e24f6 100644\n--- a/src/drill.c\n+++ b/src/drill.c\n@@ -1116,6 +1116,7 @@ drill_parse_T_code(gerb_file_t *fd, drill_state_t *state,\n \t\t_(\"Out of bounds drill number %d \"\n \t\t    \"at line %ld in file \\\"%s\\\"\"),\n \t\ttool_num, file_line, fd->filename);\n+\treturn -1;\n     }\n \n     /* Set the current tool to the correct one */\ndiff --git a/test/golden/out-of-bounds-drill-tool.png b/test/golden/out-of-bounds-drill-tool.png\nnew file mode 100644\nindex 00000000..9015ba79\nBinary files /dev/null and b/test/golden/out-of-bounds-drill-tool.png differ\ndiff --git a/test/inputs/test-out-of-bounds-drill-tool.exc b/test/inputs/test-out-of-bounds-drill-tool.exc\nnew file mode 100644\nindex 00000000..2ec8bcca\n--- /dev/null\n+++ b/test/inputs/test-out-of-bounds-drill-tool.exc\n@@ -0,0 +1,10 @@\n+G90\r\n+M72\r\n+M48\r\n+T10950C0.12345\r\n+%\r\n+G90\r\n+M72\r\n+M48\r\n+%\r\n+M30\r\ndiff --git a/test/run_valgrind_tests.sh b/test/run_valgrind_tests.sh\nindex ba522078..f805849f 100755\n--- a/test/run_valgrind_tests.sh\n+++ b/test/run_valgrind_tests.sh\n@@ -1,2 +1,2 @@\n #!/bin/sh\n-./run_tests.sh --valgrind example_cslk\n+./run_tests.sh --valgrind example_cslk out-of-bounds-drill-tool\ndiff --git a/test/tests.list b/test/tests.list\nindex 787444de..031a98e6 100644\n--- a/test/tests.list\n+++ b/test/tests.list\n@@ -194,3 +194,6 @@ test-drill-trailing-zero-suppression | test-drill-trailing-zero-suppression.exc\n \n # Test \"G85\" drilled slot\n test-drill-slot-drilled-g85 | test-drill-slot-drilled-g85.exc\n+\n+# Out of bounds drill tool\n+out-of-bounds-drill-tool | test-out-of-bounds-drill-tool.exc\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "34f8117dec685ace52cd9e578e2729db278163fc",
        "repo": "vim/vim",
        "msg": "patch 8.2.4397: crash when using many composing characters in error message\n\nProblem:    Crash when using many composing characters in error message.\nSolution:   Use mb_cptr2char_adv() instead of mb_ptr2char_adv().Stack-based Buffer Overflow in GitHub repository vim/vim prior to 8.2.",
        "filename": "None",
        "diff": "diff --git a/src/testdir/test_assert.vim b/src/testdir/test_assert.vim\nindex 8987f3f8dfcd3..27b2d73fbfc80 100644\n--- a/src/testdir/test_assert.vim\n+++ b/src/testdir/test_assert.vim\n@@ -53,6 +53,14 @@ func Test_assert_equal()\n   call assert_equal(\"\\b\\e\\f\\n\\t\\r\\\\\\x01\\x7f\", 'x')\n   call assert_match('Expected ''\\\\b\\\\e\\\\f\\\\n\\\\t\\\\r\\\\\\\\\\\\x01\\\\x7f'' but got ''x''', v:errors[0])\n   call remove(v:errors, 0)\n+\n+  \" many composing characters are handled properly\n+  call setline(1, ' ')\n+  norm 100gr\u0740\n+  call assert_equal(1, getline(1))\n+  call assert_match(\"Expected 1 but got '.* occurs 100 times]'\", v:errors[0])\n+  call remove(v:errors, 0)\n+  bwipe!\n endfunc\n \n func Test_assert_equal_dict()\ndiff --git a/src/testing.c b/src/testing.c\nindex 448c01c1e9648..48ba14d2cafd5 100644\n--- a/src/testing.c\n+++ b/src/testing.c\n@@ -101,7 +101,7 @@ ga_concat_shorten_esc(garray_T *gap, char_u *str)\n     {\n \tsame_len = 1;\n \ts = p;\n-\tc = mb_ptr2char_adv(&s);\n+\tc = mb_cptr2char_adv(&s);\n \tclen = s - p;\n \twhile (*s != NUL && c == mb_ptr2char(s))\n \t{\ndiff --git a/src/version.c b/src/version.c\nindex fb1b8476e1a6c..b4983661cadcc 100644\n--- a/src/version.c\n+++ b/src/version.c\n@@ -750,6 +750,8 @@ static char *(features[]) =\n \n static int included_patches[] =\n {   /* Add new patch number below this line */\n+/**/\n+    4397,\n /**/\n     4396,\n /**/\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "e6ea5876e0228165ee3abc6e959aa174cee06680",
        "repo": "ImageMagick/ImageMagick6",
        "msg": "https://github.com/ImageMagick/ImageMagick/issues/4988ImageMagick 7.1.0-27 is vulnerable to Buffer Overflow.",
        "filename": "cin.c",
        "diff": "diff --git a/coders/cin.c b/coders/cin.c\nindex 854b59758a..13e3cfe75b 100644\n--- a/coders/cin.c\n+++ b/coders/cin.c\n@@ -451,6 +451,8 @@ static Image *ReadCINImage(const ImageInfo *image_info,ExceptionInfo *exception)\n   image->endian=(magick[0] == 0x80) && (magick[1] == 0x2a) &&\n     (magick[2] == 0x5f) && (magick[3] == 0xd7) ? MSBEndian : LSBEndian;\n   cin.file.image_offset=ReadBlobLong(image);\n+  if (cin.file.image_offset < 712)\n+    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n   offset+=4;\n   cin.file.generic_length=ReadBlobLong(image);\n   offset+=4;\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "96daa4036a425ff3f23a7dfcba57bfb0f942bec6",
        "repo": "Ardour/ardour",
        "msg": "fix apparent free-ordering issue reported in #7926Ardour v5.12 contains a use-after-free vulnerability in the component ardour/libs/pbd/xml++.cc when using xmlFreeDoc and xmlXPathFreeContext.",
        "filename": "None",
        "diff": "diff --git a/libs/pbd/xml++.cc b/libs/pbd/xml++.cc\nindex 598a7684b3e..e09af7602be 100644\n--- a/libs/pbd/xml++.cc\n+++ b/libs/pbd/xml++.cc\n@@ -770,16 +770,16 @@ static XMLSharedNodeList* find_impl(xmlXPathContext* ctxt, const string& xpath)\n \txmlXPathObject* result = xmlXPathEval((const xmlChar*)xpath.c_str(), ctxt);\n \n \tif (!result) {\n-\t\txmlXPathFreeContext(ctxt);\n \t\txmlFreeDoc(ctxt->doc);\n+\t\txmlXPathFreeContext(ctxt);\n \n \t\tthrow XMLException(\"Invalid XPath: \" + xpath);\n \t}\n \n \tif (result->type != XPATH_NODESET) {\n \t\txmlXPathFreeObject(result);\n-\t\txmlXPathFreeContext(ctxt);\n \t\txmlFreeDoc(ctxt->doc);\n+\t\txmlXPathFreeContext(ctxt);\n \n \t\tthrow XMLException(\"Only nodeset result types are supported.\");\n \t}\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "858da537bde4de9d8c92466d5a866505310bc328",
        "repo": "pcmacdon/jsish",
        "msg": "Release \"3.0.8\": Address Array alloc sizing issues from issue \"integer overflow and buffer overflow #5\".\n\nFossilOrigin-Name: 8c46a1d465b358110dcfb271721d35fe843a1b52f2fa24ccc10094eb8aaf6fe4Integer overflow vulnerability in function Jsi_ObjArraySizer in jsish before 3.0.8, allows remote attackers to execute arbitrary code.",
        "filename": "None",
        "diff": "diff --git a/md/Reference.md b/md/Reference.md\nindex f8313ea..a99d36c 100644\n--- a/md/Reference.md\n+++ b/md/Reference.md\n@@ -600,7 +600,7 @@ Otherwise waits until the sub-interp is idle, to make call and return result.</t\n <tr><td>lockTimeout</td><td><i>INT</i></td><td>Thread time-out for mutex lock acquires (milliseconds).</td><td><i></i></td></tr>\n <tr><td>logOpts</td><td><i><a href='#logOptsOptions'>options</a></i></td><td>Options for log output to add file/line/time.</td><td><i></i></td></tr>\n <tr><td>maxDepth</td><td><i>INT</i></td><td>Depth limit of recursive function calls (1000).</td><td><i></i></td></tr>\n-<tr><td>maxArrayList</td><td><i>INT</i></td><td>Maximum array convertable to list (100000).</td><td><i></i></td></tr>\n+<tr><td>maxArrayList</td><td><i>UINT</i></td><td>Maximum array convertable to list (100000).</td><td><i></i></td></tr>\n <tr><td>maxIncDepth</td><td><i>INT</i></td><td>Maximum allowed source/require nesting depth (50).</td><td><i></i></td></tr>\n <tr><td>maxInterpDepth</td><td><i>INT</i></td><td>Maximum nested subinterp create depth (10).</td><td><i></i></td></tr>\n <tr><td>maxUserObjs</td><td><i>INT</i></td><td>Maximum number of 'new' object calls, eg. File, RegExp, etc.</td><td><i></i></td></tr>\ndiff --git a/src/jsi.h b/src/jsi.h\nindex ba55da4..8a0b178 100644\n--- a/src/jsi.h\n+++ b/src/jsi.h\n@@ -4,7 +4,7 @@\n \n #define JSI_VERSION_MAJOR   3\n #define JSI_VERSION_MINOR   0\n-#define JSI_VERSION_RELEASE 7\n+#define JSI_VERSION_RELEASE 8\n \n #define JSI_VERSION (JSI_VERSION_MAJOR + ((Jsi_Number)JSI_VERSION_MINOR/100.0) + ((Jsi_Number)JSI_VERSION_RELEASE/10000.0))\n \ndiff --git a/src/jsiArray.c b/src/jsiArray.c\nindex 298ec75..64f9555 100644\n--- a/src/jsiArray.c\n+++ b/src/jsiArray.c\n@@ -267,7 +267,7 @@ static Jsi_RC jsi_ArrayFlatSub(Jsi_Interp *interp, Jsi_Obj* nobj, Jsi_Value *arr\n             rc = jsi_ArrayFlatSub(interp, nobj, t , depth-1);\n         else if (!Jsi_ValueIsUndef(interp, t))\n             Jsi_ObjArrayAdd(interp, nobj, t);\n-        if ((++n + clen)>interp->maxArrayList)\n+        if ((uint)(++n + clen)>interp->maxArrayList)\n             return Jsi_LogError(\"array size exceeded\");\n     }\n     return rc;\ndiff --git a/src/jsiCData.c b/src/jsiCData.c\nindex 4dbc91e..0bb82d9 100644\n--- a/src/jsiCData.c\n+++ b/src/jsiCData.c\n@@ -1276,8 +1276,8 @@ static Jsi_RC CDataStructDefineCmd(Jsi_Interp *interp, Jsi_Value *args, Jsi_Valu\n             sf->flags |= JSI_OPT_BITSET_ENUM;\n         }\n         if (sf->arrSize) {\n-            if (sf->arrSize>MAX_ARRAY_LIST) {\n-                rc = Jsi_LogError(\"array size too big: %d >= %d\", sf->arrSize, MAX_ARRAY_LIST);\n+            if (sf->arrSize>interp->maxArrayList) {\n+                rc = Jsi_LogError(\"array size too big: %d >= %d\", sf->arrSize, interp->maxArrayList);\n                 goto bail;\n             }\n             if (sf->bits || isEnum) {\ndiff --git a/src/jsiInt.h b/src/jsiInt.h\nindex 03fa347..87cb6eb 100644\n--- a/src/jsiInt.h\n+++ b/src/jsiInt.h\n@@ -1259,7 +1259,7 @@ struct Jsi_Interp {\n     Jsi_Value *Top_object;\n     Jsi_ScopeStrs *scopes[JSI_MAX_SCOPE];\n     int cur_scope;\n-    int maxArrayList;\n+    uint maxArrayList;\n     int delRBCnt;\n     Jsi_Func *activeFunc;  // Currently active function call.\n     Jsi_Func *prevActiveFunc;  // Prev active function call.\ndiff --git a/src/jsiInterp.c b/src/jsiInterp.c\nindex 508f62f..133a74e 100644\n--- a/src/jsiInterp.c\n+++ b/src/jsiInterp.c\n@@ -100,7 +100,7 @@ static Jsi_OptionSpec InterpOptions[] = {\n     JSI_OPT(INT,   Jsi_Interp, lockTimeout, .help=\"Thread time-out for mutex lock acquires (milliseconds)\" ),\n     JSI_OPT(CUSTOM,Jsi_Interp, logOpts,     .help=\"Options for log output to add file/line/time\", .flags=0, .custom=Jsi_Opt_SwitchSuboption, .data=jsi_InterpLogOptions),\n     JSI_OPT(INT,   Jsi_Interp, maxDepth,    .help=\"Depth limit of recursive function calls (1000)\", .flags=JSI_OPT_LOCKSAFE),\n-    JSI_OPT(INT,   Jsi_Interp, maxArrayList,.help=\"Maximum array convertable to list (100000)\", .flags=JSI_OPT_LOCKSAFE),\n+    JSI_OPT(UINT,  Jsi_Interp, maxArrayList,.help=\"Maximum array convertable to list (100000)\", .flags=JSI_OPT_LOCKSAFE),\n     JSI_OPT(INT,   Jsi_Interp, maxIncDepth, .help=\"Maximum allowed source/require nesting depth (50)\", .flags=JSI_OPT_LOCKSAFE),\n     JSI_OPT(INT,   Jsi_Interp, maxInterpDepth,.help=\"Maximum nested subinterp create depth (10)\", .flags=JSI_OPT_LOCKSAFE),\n     JSI_OPT(INT,   Jsi_Interp, maxUserObjs, .help=\"Maximum number of 'new' object calls, eg. File, RegExp, etc\", .flags=JSI_OPT_LOCKSAFE ),\n@@ -1146,6 +1146,7 @@ static Jsi_Interp* jsi_InterpNew(Jsi_Interp *parent, Jsi_Value *opts, Jsi_Interp\n     }\n     interp->maxDepth = JSI_MAX_EVAL_DEPTH;\n     interp->maxIncDepth = JSI_MAX_INCLUDE_DEPTH;\n+    interp->maxArrayList = MAX_ARRAY_LIST;\n     interp->typeWarnMax = 50;\n     interp->subOpts.dblPrec = __DBL_DECIMAL_DIG__-1;\n     interp->subOpts.prompt = \"$ \";\n@@ -1482,7 +1483,6 @@ static Jsi_Interp* jsi_InterpNew(Jsi_Interp *parent, Jsi_Value *opts, Jsi_Interp\n #endif\n     if (interp->typeCheck.all|interp->typeCheck.parse|interp->typeCheck.funcsig)\n         interp->staticFuncsTbl = Jsi_HashNew(interp, JSI_KEYS_STRING, NULL);\n-    interp->maxArrayList = MAX_ARRAY_LIST;\n     if (!jsiIntData.isInit) {\n         jsiIntData.isInit = 1;\n         jsi_InitValue(interp, 0);\ndiff --git a/src/jsiObj.c b/src/jsiObj.c\nindex eae81de..7a11f49 100644\n--- a/src/jsiObj.c\n+++ b/src/jsiObj.c\n@@ -76,7 +76,7 @@ static Jsi_RC ObjListifyCallback(Jsi_Tree *tree, Jsi_TreeEntry *hPtr, void *data\n         if (!cp || !isdigit(*cp))\n             return JSI_OK;\n         n = (int)strtol(cp, &ep, 0);\n-        if (n<0 || n >= interp->maxArrayList)\n+        if (n<0 || (uint)n >= interp->maxArrayList)\n             return JSI_OK;\n         hPtr->f.bits.isarrlist = 1;\n         if (Jsi_ObjArraySizer(interp, obj, n) <= 0) \n@@ -414,12 +414,12 @@ int Jsi_ObjDecrRefCount(Jsi_Interp *interp, Jsi_Obj *obj)  {\n \n int Jsi_ObjArraySizer(Jsi_Interp *interp, Jsi_Obj *obj, uint len)\n {\n-    int nsiz = len + 1, mod = ALLOC_MOD_SIZE;\n+    uint nsiz = len + 1, mod = ALLOC_MOD_SIZE;\n     assert(obj->isarrlist);\n     if (mod>1)\n         nsiz = nsiz + ((mod-1) - (nsiz + mod - 1)%mod);\n-    if (nsiz > MAX_ARRAY_LIST) {\n-        Jsi_LogError(\"array size too large\");\n+    if (len >= interp->maxArrayList || nsiz > interp->maxArrayList) {\n+        Jsi_LogError(\"array size too big: %u >= %u\", len, interp->maxArrayList);\n         return 0;\n     }\n     if (len >= obj->arrMaxSize) {\ndiff --git a/src/jsiValue.c b/src/jsiValue.c\nindex a9fa8a2..c520084 100644\n--- a/src/jsiValue.c\n+++ b/src/jsiValue.c\n@@ -1036,7 +1036,7 @@ Jsi_Value *jsi_ValueObjKeyAssign(Jsi_Interp *interp, Jsi_Value *target, Jsi_Valu\n     }\n     /* TODO: array[\"1\"] also extern the length of array */\n     \n-    if (arrayindex >= 0 && arrayindex < MAX_ARRAY_LIST &&\n+    if (arrayindex >= 0 && (uint)arrayindex < interp->maxArrayList &&\n         target->vt == JSI_VT_OBJECT && target->d.obj->arr) {\n         return jsi_ObjArraySetDup(interp, target->d.obj, value, arrayindex);\n     }\n@@ -1373,7 +1373,7 @@ Jsi_RC Jsi_ValueInsertArray(Jsi_Interp *interp, Jsi_Value *target, int key, Jsi_\n     Jsi_Obj *obj = target->d.obj;\n     \n     if (obj->isarrlist) {\n-        if (key >= 0 && key < interp->maxArrayList) {\n+        if (key >= 0 && (uint)key < interp->maxArrayList) {\n             Jsi_ObjArraySet(interp, obj, val, key);\n             return JSI_OK;\n         }\ndiff --git a/tools/protos.jsi b/tools/protos.jsi\nindex 76d21d1..f2c4608 100755\n--- a/tools/protos.jsi\n+++ b/tools/protos.jsi\n@@ -1,4 +1,4 @@\n-//JSI Command Prototypes: version 3.0.6\n+//JSI Command Prototypes: version 3.0.8\n throw(\"NOT EXECUTABLE: USE FILE IN GEANY EDITOR FOR CMD LINE COMPLETION + GOTO TAG\");\n \n var Array = function(cmd,args) {};\ndiff --git a/www/reference.wiki b/www/reference.wiki\nindex 2b11595..51f6cdb 100644\n--- a/www/reference.wiki\n+++ b/www/reference.wiki\n@@ -633,7 +633,7 @@ Otherwise waits until the sub-interp is idle, to make call and return result.</t\n <tr><td>lockTimeout</td><td><i>INT</i></td><td>Thread time-out for mutex lock acquires (milliseconds).</td><td><i></i></td></tr>\n <tr><td>logOpts</td><td><i><a href='#logOptsOptions'>options</a></i></td><td>Options for log output to add file/line/time.</td><td><i></i></td></tr>\n <tr><td>maxDepth</td><td><i>INT</i></td><td>Depth limit of recursive function calls (1000).</td><td><i></i></td></tr>\n-<tr><td>maxArrayList</td><td><i>INT</i></td><td>Maximum array convertable to list (100000).</td><td><i></i></td></tr>\n+<tr><td>maxArrayList</td><td><i>UINT</i></td><td>Maximum array convertable to list (100000).</td><td><i></i></td></tr>\n <tr><td>maxIncDepth</td><td><i>INT</i></td><td>Maximum allowed source/require nesting depth (50).</td><td><i></i></td></tr>\n <tr><td>maxInterpDepth</td><td><i>INT</i></td><td>Maximum nested subinterp create depth (10).</td><td><i></i></td></tr>\n <tr><td>maxUserObjs</td><td><i>INT</i></td><td>Maximum number of 'new' object calls, eg. File, RegExp, etc.</td><td><i></i></td></tr>\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "a06f9efca373e25328b1c53639a48decd0854570",
        "repo": "stnoonan/spnego-http-auth-nginx-module",
        "msg": "Check basic auth result against != NGX_OK rather than == NGX_DECLINED\n\nThis corrects the error handling case when ngx_http_auth_spnego_basic is called with a bad configuration or bad username. These cases return NGX_ERROR, which allowed basic auth to proceed.\n\nThanks to Prakapovich Pavel aka Flyguy.by for pointing this out.In the SPNEGO HTTP Authentication Module for nginx (spnego-http-auth-nginx-module) before version 1.1.1 basic Authentication can be bypassed using a malformed username. This affects users of spnego-http-auth-nginx-module that have enabled basic authentication. This is fixed in version 1.1.1 of spnego-http-auth-nginx-module. As a workaround, one may disable basic authentication.",
        "filename": "None",
        "diff": "diff --git a/ngx_http_auth_spnego_module.c b/ngx_http_auth_spnego_module.c\nindex 97c0b44..25683f2 100644\n--- a/ngx_http_auth_spnego_module.c\n+++ b/ngx_http_auth_spnego_module.c\n@@ -1043,7 +1043,7 @@ ngx_http_auth_spnego_handler(\n             /* If basic auth is enabled and basic creds are supplied\n              * attempt basic auth.  If we attempt basic auth, we do\n              * not fall through to real SPNEGO */\n-            if (NGX_DECLINED == ngx_http_auth_spnego_basic(r, ctx, alcf)) {\n+            if (NGX_OK != ngx_http_auth_spnego_basic(r, ctx, alcf)) {\n                 spnego_debug0(\"Basic auth failed\");\n                 if (NGX_ERROR == ngx_http_auth_spnego_headers_basic_only(r, ctx, alcf)) {\n                     spnego_debug0(\"Error setting headers\");\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "5be38b672c1410e2f10acd3ad2eecfdc81d5daf7",
        "repo": "open-power/skiboot",
        "msg": "secvar: fix endian conversion\n\nunpack_timestamp() calls le32_to_cpu() for endian conversion of\nuint16_t \"year\" value. This patch fixes the code to use le16_to_cpu().\n\nSigned-off-by: Nayna Jain <nayna@linux.ibm.com>\nReviewed-by: Daniel Axtens <dja@axtens.net>\nSigned-off-by: Vasant Hegde <hegdevasant@linux.vnet.ibm.com>An issue was discovered in OpenPOWER 2.6 firmware. unpack_timestamp() calls le32_to_cpu() for endian conversion of a uint16_t \"year\" value, resulting in a type mismatch that can truncate a higher integer value to a smaller one, and bypass a timestamp check. The fix is to use the right endian conversion function.",
        "filename": "None",
        "diff": "diff --git a/libstb/secvar/backend/edk2-compat-process.c b/libstb/secvar/backend/edk2-compat-process.c\nindex 244f23403fe0..037c1b492734 100644\n--- a/libstb/secvar/backend/edk2-compat-process.c\n+++ b/libstb/secvar/backend/edk2-compat-process.c\n@@ -370,7 +370,7 @@ int update_timestamp(const char *key, const struct efi_time *timestamp, char *la\n static uint64_t unpack_timestamp(const struct efi_time *timestamp)\n {\n \tuint64_t val = 0;\n-\tuint16_t year = le32_to_cpu(timestamp->year);\n+\tuint16_t year = le16_to_cpu(timestamp->year);\n \n \t/* pad1, nanosecond, timezone, daylight and pad2 are meant to be zero */\n \tval |= ((uint64_t) timestamp->pad1 & 0xFF) << 0;\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "dc070da861a015d3c97488fdcca6063b44d47a7b",
        "repo": "ImageMagick/ImageMagick6",
        "msg": "https://github.com/ImageMagick/ImageMagick/pull/5034In ImageMagick, there is load of misaligned address for type 'double', which requires 8 byte alignment and for type 'float', which requires 4 byte alignment at MagickCore/property.c. Whenever crafted or untrusted input is processed by ImageMagick, this causes a negative impact to application availability or other problems related to undefined behavior.",
        "filename": "property.c",
        "diff": "diff --git a/magick/property.c b/magick/property.c\nindex 2d80493dd2..bfc689466d 100644\n--- a/magick/property.c\n+++ b/magick/property.c\n@@ -1526,12 +1526,14 @@ static MagickBooleanType GetEXIFProperty(const Image *image,\n             }\n             case EXIF_FMT_SINGLE:\n             {\n-              EXIFMultipleValues(4,\"%f\",(double) *(float *) p1);\n+              EXIFMultipleValues(4,\"%.20g\",(double)\n+                ReadPropertySignedLong(endian,p1));\n               break;\n             }\n             case EXIF_FMT_DOUBLE:\n             {\n-              EXIFMultipleValues(8,\"%f\",*(double *) p1);\n+              EXIFMultipleValues(8,\"%.20g\",(double)\n+                ReadPropertySignedLong(endian,p1));\n               break;\n             }\n             case EXIF_FMT_STRING:\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "450949ed017f009b399c937cf362f0058eacc5fa",
        "repo": "ImageMagick/ImageMagick6",
        "msg": "Pull request: https://github.com/ImageMagick/ImageMagick/pull/4963A vulnerability was found in ImageMagick, causing an outside the range of representable values of type 'unsigned char' at coders/psd.c, when crafted or untrusted input is processed. This leads to a negative impact to application availability or other problems related to undefined behavior.",
        "filename": "psd.c",
        "diff": "diff --git a/coders/emf.c b/coders/emf.c\nindex 39c0ac726b..efc92c303f 100644\n--- a/coders/emf.c\n+++ b/coders/emf.c\n@@ -411,7 +411,8 @@ static HENHMETAFILE ReadEnhMetaFile(const char *path,ssize_t *width,\n     }\n   ReadFile(hFile,pBits,dwSize,&dwSize,NULL);\n   CloseHandle(hFile);\n-  if (((PAPMHEADER) pBits)->dwKey != 0x9ac6cdd7l)\n+  if (((PAPMHEADER) pBits)->dwKey != 0x9ac6cdd7l ||\n+      (((PAPMHEADER) pBits)->wInch == 0))\n     {\n       pBits=(BYTE *) DestroyString((char *) pBits);\n       return((HENHMETAFILE) NULL);\ndiff --git a/coders/psd.c b/coders/psd.c\nindex 19d36f0a0e..eedcf3782d 100644\n--- a/coders/psd.c\n+++ b/coders/psd.c\n@@ -1048,8 +1048,9 @@ static MagickBooleanType ReadPSDChannelPixels(Image *image,\n           number_bits=8;\n         for (bit=0; bit < number_bits; bit++)\n         {\n-          SetPSDPixel(image,channels,type,packet_size,(((unsigned char) pixel)\n-            & (0x01 << (7-bit))) != 0 ? 0 : QuantumRange,q++,indexes,x++);\n+          SetPSDPixel(image,channels,type,packet_size,\n+            (((unsigned char) ((ssize_t) pixel)) & (0x01 << (7-bit))) != 0 ? 0 :\n+            QuantumRange,q++,indexes,x++);\n         }\n         if (x != (ssize_t) image->columns)\n           x--;\ndiff --git a/magick/widget.c b/magick/widget.c\nindex 96fb7cd8df..dea54667d5 100644\n--- a/magick/widget.c\n+++ b/magick/widget.c\n@@ -7861,6 +7861,8 @@ MagickExport int XMenuWidget(Display *display,XWindows *windows,\n             break;\n           }\n         state&=(~InactiveWidgetState);\n+        if (selection_info.height == 0)\n+          break;\n         id=(event.xbutton.y-top_offset)/(int) selection_info.height;\n         selection_info.id=id;\n         if ((id < 0) || (id >= (int) number_selections))\n@@ -7914,6 +7916,8 @@ MagickExport int XMenuWidget(Display *display,XWindows *windows,\n         if (event.xcrossing.state == 0)\n           break;\n         state&=(~InactiveWidgetState);\n+        if (selection_info.height == 0)\n+          break;\n         id=((event.xcrossing.y-top_offset)/(int) selection_info.height);\n         if ((selection_info.id >= 0) &&\n             (selection_info.id < (int) number_selections))\n@@ -8000,6 +8004,8 @@ MagickExport int XMenuWidget(Display *display,XWindows *windows,\n           break;\n         if (state & InactiveWidgetState)\n           break;\n+        if (selection_info.height == 0)\n+          break;\n         id=(event.xmotion.y-top_offset)/(int) selection_info.height;\n         if ((selection_info.id >= 0) &&\n             (selection_info.id < (int) number_selections))\ndiff --git a/wand/animate.c b/wand/animate.c\nindex 0f70436108..adc84d8679 100644\n--- a/wand/animate.c\n+++ b/wand/animate.c\n@@ -1143,7 +1143,10 @@ WandExport MagickBooleanType AnimateImageCommand(ImageInfo *image_info,\n             if (i == (ssize_t) argc)\n               ThrowAnimateException(OptionError,\"MissingArgument\",option);\n             if (XRemoteCommand(display,resource_info.window_id,argv[i]) != 0)\n-              return(MagickFalse);\n+              {\n+                DestroyAnimate();\n+                return(MagickFalse);\n+              }\n             i--;\n             break;\n           }\ndiff --git a/wand/display.c b/wand/display.c\nindex b7b9ed932d..27abafa1b5 100644\n--- a/wand/display.c\n+++ b/wand/display.c\n@@ -1491,7 +1491,10 @@ WandExport MagickBooleanType DisplayImageCommand(ImageInfo *image_info,\n             if (i == (ssize_t) argc)\n               ThrowDisplayException(OptionError,\"MissingArgument\",option);\n             if (XRemoteCommand(display,resource_info.window_id,argv[i]) != 0)\n-              return(MagickFalse);\n+              {\n+                DestroyDisplay();\n+                return(MagickFalse);\n+              }\n             i--;\n             break;\n           }\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "c79ccba517dbb1a0ccb9b01ee3bd2a63748b60dd",
        "repo": "tensorflow/tensorflow",
        "msg": "Fix memory leak when a graph node is invalid.\n\nIf a graph node is invalid but a kernel is created then we set the kernel back to `nullptr` but we forget to delete it. Hence, we get a memory leak.\n\nPiperOrigin-RevId: 408968108\nChange-Id: I1d8a9d0d8988ed5e08be8b9f2004ce1b4cd11b7cTensorflow is an Open Source Machine Learning Framework. If a graph node is invalid, TensorFlow can leak memory in the implementation of `ImmutableExecutorState::Initialize`. Here, we set `item->kernel` to `nullptr` but it is a simple `OpKernel*` pointer so the memory that was previously allocated to it would leak. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "filename": "immutable_executor_state.cc",
        "diff": "diff --git a/tensorflow/core/common_runtime/immutable_executor_state.cc b/tensorflow/core/common_runtime/immutable_executor_state.cc\nindex 1f728334e2b7ee..25822540f024ae 100644\n--- a/tensorflow/core/common_runtime/immutable_executor_state.cc\n+++ b/tensorflow/core/common_runtime/immutable_executor_state.cc\n@@ -131,6 +131,7 @@ Status ImmutableExecutorState::Initialize(const Graph& graph) {\n \n     Status s = params_.create_kernel(n->properties(), &item->kernel);\n     if (!s.ok()) {\n+      params_.delete_kernel(item->kernel);\n       item->kernel = nullptr;\n       s = AttachDef(s, *n);\n       return s;\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "4f38b1ac8e42727e18a2f0bde06d3bee8e77b250",
        "repo": "tensorflow/tensorflow",
        "msg": "Prevent null dereference read in `GetInitOp`.\n\nWe have a map of maps. We test that the key exists in the first map but then we don't have any validation that this also means the second map has the needed key. In the scenarios where this is not the case, we'll dereference a nullptr, if we don't have this check\n\nPiperOrigin-RevId: 408739325\nChange-Id: If9bb7ed759aba1f3b56a34913f209508dbaf65ceTensorflow is an Open Source Machine Learning Framework. The implementation of `GetInitOp` is vulnerable to a crash caused by dereferencing a null pointer. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "filename": "loader_util.cc",
        "diff": "diff --git a/tensorflow/cc/saved_model/loader_util.cc b/tensorflow/cc/saved_model/loader_util.cc\nindex 100cae2291333f..411dc41fd44837 100644\n--- a/tensorflow/cc/saved_model/loader_util.cc\n+++ b/tensorflow/cc/saved_model/loader_util.cc\n@@ -34,9 +34,14 @@ Status GetInitOp(const string& export_dir, const MetaGraphDef& meta_graph_def,\n   const auto& init_op_sig_it =\n       meta_graph_def.signature_def().find(kSavedModelInitOpSignatureKey);\n   if (init_op_sig_it != sig_def_map.end()) {\n-    *init_op_name = init_op_sig_it->second.outputs()\n-                        .find(kSavedModelInitOpSignatureKey)\n-                        ->second.name();\n+    const auto& sig_def_outputs = init_op_sig_it->second.outputs();\n+    const auto& sig_def_outputs_it =\n+        sig_def_outputs.find(kSavedModelInitOpSignatureKey);\n+    if (sig_def_outputs_it == sig_def_outputs.end()) {\n+      return errors::FailedPrecondition(\"Could not find output \",\n+                                        kSavedModelInitOpSignatureKey);\n+    }\n+    *init_op_name = sig_def_outputs_it->second.name();\n     return Status::OK();\n   }\n \n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "240655511cd3e701155f944a972db71b6c0b1bb6",
        "repo": "tensorflow/tensorflow",
        "msg": "Eliminate `CHECK`-fails from `IsSimplifiableReshape` via `MakeShape(<invalid shape>)`\n\nPiperOrigin-RevId: 409166738\nChange-Id: I7f0a3590b8acae3f3e3e2fe636e1f5ef285693cfTensorflow is an Open Source Machine Learning Framework. The Grappler optimizer in TensorFlow can be used to cause a denial of service by altering a `SavedModel` such that `IsSimplifiableReshape` would trigger `CHECK` failures. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "filename": "constant_folding.cc",
        "diff": "diff --git a/tensorflow/core/grappler/optimizers/constant_folding.cc b/tensorflow/core/grappler/optimizers/constant_folding.cc\nindex a2050899f60726..d5fadb311a75cc 100644\n--- a/tensorflow/core/grappler/optimizers/constant_folding.cc\n+++ b/tensorflow/core/grappler/optimizers/constant_folding.cc\n@@ -1741,14 +1741,16 @@ Status ConstantFolding::IsSimplifiableReshape(\n       int32_t dim = outputs[0]->flat<int32>()(i);\n       shp.push_back(dim);\n     }\n-    TF_CHECK_OK(TensorShapeUtils::MakeShape(shp, &new_dims));\n+    s = TensorShapeUtils::MakeShape(shp, &new_dims);\n+    if (!s.ok()) return s;\n   } else {\n     std::vector<int64_t> shp;\n     for (int i = 0; i < outputs[0]->NumElements(); ++i) {\n       int64_t dim = outputs[0]->flat<int64_t>()(i);\n       shp.push_back(dim);\n     }\n-    TF_CHECK_OK(TensorShapeUtils::MakeShape(shp, &new_dims));\n+    s = TensorShapeUtils::MakeShape(shp, &new_dims);\n+    if (!s.ok()) return s;\n   }\n \n   if (!shape.IsCompatibleWith(new_dims)) {\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "ad18ece95fa064efc0995c4ab2c985f77fb166ec",
        "repo": "gpac/gpac",
        "msg": "fixed #1904The binary MP4Box in Gpac 1.0.1 has a null pointer dereference vulnerability in the gf_isom_get_payt_count function in hint_track.c, which allows attackers to cause a denial of service.",
        "filename": "hint_track.c",
        "diff": "diff --git a/src/isomedia/hint_track.c b/src/isomedia/hint_track.c\nindex 304aa2cd8c..385e746257 100644\n--- a/src/isomedia/hint_track.c\n+++ b/src/isomedia/hint_track.c\n@@ -43,7 +43,7 @@ Bool IsHintTrack(GF_TrackBox *trak)\n u32 GetHintFormat(GF_TrackBox *trak)\n {\n \tGF_HintMediaHeaderBox *hmhd = (GF_HintMediaHeaderBox *)trak->Media->information->InfoHeader;\n-\tif (hmhd->type != GF_ISOM_BOX_TYPE_HMHD)\n+\tif (!hmhd || (hmhd->type != GF_ISOM_BOX_TYPE_HMHD))\n \t\treturn 0;\n \t\t\n \tif (!hmhd || !hmhd->subType) {\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "6b5adc0877de832b2a7c189532dbbbc64622eeb6",
        "repo": "tensorflow/tensorflow",
        "msg": "Prevent `CHECK`-fail when building reference tensor.\n\nThe tensor constructor does not allow reference dtypes, as these should not show up explicitly. However, when passed these invalid types instead of building an invalid object the constructor crashes via a `CHECK`-fail. We have a static builder that properly handles this case but is not applicable given current usage.\n\nInstead, before calling the constructor, we can check that the dtype is not a reference type and return an error otherwise, given that the dtype is user controlled so malicious users can trigger denial of service.\n\nPiperOrigin-RevId: 409662503\nChange-Id: I5892f831fde7f276cd7ab34519cf6b8061c71a59Tensorflow is an Open Source Machine Learning Framework. A malicious user can cause a denial of service by altering a `SavedModel` such that Grappler optimizer would attempt to build a tensor using a reference `dtype`. This would result in a crash due to a `CHECK`-fail in the `Tensor` constructor as reference types are not allowed. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "filename": "constant_folding.cc",
        "diff": "diff --git a/tensorflow/core/grappler/optimizers/constant_folding.cc b/tensorflow/core/grappler/optimizers/constant_folding.cc\nindex d5fadb311a75cc..281806be20259f 100644\n--- a/tensorflow/core/grappler/optimizers/constant_folding.cc\n+++ b/tensorflow/core/grappler/optimizers/constant_folding.cc\n@@ -1363,6 +1363,11 @@ Status ConstantFolding::EvaluateOneFoldable(const NodeDef& node,\n                           input_tensor.ToString(),\n                           \" has a dtype of DT_INVALID.\"));\n     }\n+    if (IsRefType(raw_val.dtype())) {\n+      return errors::InvalidArgument(\n+          \"Not allowed to construct a tensor with reference dtype, got \",\n+          DataTypeString(raw_val.dtype()));\n+    }\n     Tensor* value = new Tensor(raw_val.dtype(), raw_val.tensor_shape());\n     if (!value->FromProto(raw_val)) {\n       delete (value);\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "125281f1c0d4b6a8b49f7e55a757205a2ef01fbe",
        "repo": "babelouest/glewlwyd",
        "msg": "Fix update session when auth failGlewlwyd 2.0.0, fixed in 2.6.1 is affected by an incorrect access control vulnerability. One user can attempt to log in as another user without its password.",
        "filename": "webservice.c",
        "diff": "diff --git a/src/webservice.c b/src/webservice.c\nindex 15ab937be..58e0a3ab0 100644\n--- a/src/webservice.c\n+++ b/src/webservice.c\n@@ -278,10 +278,6 @@ int callback_glewlwyd_user_auth (const struct _u_request * request, struct _u_re\n             if (check_result_value(j_result, G_ERROR_UNAUTHORIZED)) {\n               y_log_message(Y_LOG_LEVEL_WARNING, \"Security - Authorization invalid for username %s at IP Address %s\", json_string_value(json_object_get(j_param, \"username\")), ip_source);\n             }\n-            if ((session_uid = get_session_id(config, request)) != NULL && user_session_update(config, session_uid, u_map_get_case(request->map_header, \"user-agent\"), issued_for, json_string_value(json_object_get(j_param, \"username\")), NULL, 1) != G_OK) {\n-              y_log_message(Y_LOG_LEVEL_ERROR, \"callback_glewlwyd_user_auth - Error user_session_update (2)\");\n-            }\n-            o_free(session_uid);\n             response->status = 401;\n             glewlwyd_metrics_increment_counter_va(config, GLWD_METRICS_AUTH_USER_INVALID, 1, NULL);\n             glewlwyd_metrics_increment_counter_va(config, GLWD_METRICS_AUTH_USER_INVALID_SCHEME, 1, \"scheme_type\", \"password\", NULL);\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "a68f68061e263a88321c104a6c911fe5598050a8",
        "repo": "tensorflow/tensorflow",
        "msg": "Replace faulty overflow check with a builder for `TensorShape`.\n\nPrevents an integer overflow that was not caught before.\n\nPiperOrigin-RevId: 415381595\nChange-Id: I76585ddedc912bd9f4a390aeafa8e2ced1a28863Tensorflow is an Open Source Machine Learning Framework. The implementation of `AddManySparseToTensorsMap` is vulnerable to an integer overflow which results in a `CHECK`-fail when building new `TensorShape` objects (so, an assert failure based denial of service). We are missing some validation on the shapes of the input tensors as well as directly constructing a large `TensorShape` with user-provided dimensions. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "filename": "sparse_tensors_map_ops.cc",
        "diff": "diff --git a/tensorflow/core/kernels/sparse_tensors_map_ops.cc b/tensorflow/core/kernels/sparse_tensors_map_ops.cc\nindex 5fa690743b05c1..b486a2b4dc3c92 100644\n--- a/tensorflow/core/kernels/sparse_tensors_map_ops.cc\n+++ b/tensorflow/core/kernels/sparse_tensors_map_ops.cc\n@@ -263,22 +263,10 @@ class AddManySparseToTensorsMapOp : public SparseTensorAccessingOp {\n             \"Rank of input SparseTensor should be > 1, but saw rank: \", rank));\n \n     auto input_shape_vec = input_shape->vec<int64_t>();\n-    int new_num_elements = 1;\n-    bool overflow_ocurred = false;\n-    for (int i = 0; i < input_shape_vec.size(); i++) {\n-      new_num_elements =\n-          MultiplyWithoutOverflow(new_num_elements, input_shape_vec(i));\n-      if (new_num_elements < 0) {\n-        overflow_ocurred = true;\n-        break;\n-      }\n-    }\n-\n-    OP_REQUIRES(\n-        context, !overflow_ocurred,\n-        errors::Internal(\"Encountered overflow from large input shape.\"));\n \n-    TensorShape tensor_input_shape(input_shape_vec);\n+    TensorShape tensor_input_shape;\n+    OP_REQUIRES_OK(context, TensorShape::BuildTensorShape(input_shape_vec,\n+                                                          &tensor_input_shape));\n     gtl::InlinedVector<int64_t, 8> std_order(rank);\n     std::iota(std_order.begin(), std_order.end(), 0);\n     SparseTensor input_st;\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "ab0fc21bc7105b54bafd85bd8b82742f9e68898a",
        "repo": "torvalds/linux",
        "msg": "Revert \"NFSv4: Handle the special Linux file open access mode\"\n\nThis reverts commit 44942b4e457beda00981f616402a1a791e8c616e.\n\nAfter secondly opening a file with O_ACCMODE|O_DIRECT flags,\nnfs4_valid_open_stateid() will dereference NULL nfs4_state when lseek().\n\nReproducer:\n  1. mount -t nfs -o vers=4.2 $server_ip:/ /mnt/\n  2. fd = open(\"/mnt/file\", O_ACCMODE|O_DIRECT|O_CREAT)\n  3. close(fd)\n  4. fd = open(\"/mnt/file\", O_ACCMODE|O_DIRECT)\n  5. lseek(fd)\n\nReported-by: Lyu Tao <tao.lyu@epfl.ch>\nSigned-off-by: ChenXiaoSong <chenxiaosong2@huawei.com>\nSigned-off-by: Trond Myklebust <trond.myklebust@hammerspace.com>An issue was discovered in fs/nfs/dir.c in the Linux kernel before 5.16.5. If an application sets the O_DIRECTORY flag, and tries to open a regular file, nfs_atomic_open() performs a regular lookup. If a regular file is found, ENOTDIR should occur, but the server instead returns uninitialized data in the file descriptor.",
        "filename": "nfs4file.c",
        "diff": "diff --git a/fs/nfs/inode.c b/fs/nfs/inode.c\nindex e51d86707fcace..e72900c059ee58 100644\n--- a/fs/nfs/inode.c\n+++ b/fs/nfs/inode.c\n@@ -1180,7 +1180,6 @@ int nfs_open(struct inode *inode, struct file *filp)\n \tnfs_fscache_open_file(inode, filp);\n \treturn 0;\n }\n-EXPORT_SYMBOL_GPL(nfs_open);\n \n /*\n  * This function is called whenever some part of NFS notices that\ndiff --git a/fs/nfs/nfs4file.c b/fs/nfs/nfs4file.c\nindex d258933cf8c881..f336d0a4190e5c 100644\n--- a/fs/nfs/nfs4file.c\n+++ b/fs/nfs/nfs4file.c\n@@ -51,7 +51,7 @@ nfs4_file_open(struct inode *inode, struct file *filp)\n \t\treturn err;\n \n \tif ((openflags & O_ACCMODE) == 3)\n-\t\treturn nfs_open(inode, filp);\n+\t\topenflags--;\n \n \t/* We can't create new files here */\n \topenflags &= ~(O_CREAT|O_EXCL);\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "ab51e5b813573dc9f51efa335aebcf2994125ee9",
        "repo": "tensorflow/tensorflow",
        "msg": "Prevent memory leak in decoding PNG images.\n\nPiperOrigin-RevId: 409300653\nChange-Id: I6182124c545989cef80cefd439b659095920763bTensorflow is an Open Source Machine Learning Framework. When decoding PNG images TensorFlow can produce a memory leak if the image is invalid. After calling `png::CommonInitDecode(..., &decode)`, the `decode` value contains allocated buffers which can only be freed by calling `png::CommonFreeDecode(&decode)`. However, several error case in the function implementation invoke the `OP_REQUIRES` macro which immediately terminates the execution of the function, without allowing for the memory free to occur. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "filename": "decode_image_op.cc",
        "diff": "diff --git a/tensorflow/core/kernels/image/decode_image_op.cc b/tensorflow/core/kernels/image/decode_image_op.cc\nindex eef98dd2d83400..ee0ae957203b37 100644\n--- a/tensorflow/core/kernels/image/decode_image_op.cc\n+++ b/tensorflow/core/kernels/image/decode_image_op.cc\n@@ -18,6 +18,8 @@ limitations under the License.\n #include <cstdint>\n #include <memory>\n \n+#include \"tensorflow/core/lib/gtl/cleanup.h\"\n+\n #define EIGEN_USE_THREADS\n \n #include \"absl/strings/escaping.h\"\n@@ -326,6 +328,16 @@ class DecodeImageV2Op : public OpKernel {\n         context, png::CommonInitDecode(input, channels_, channel_bits, &decode),\n         errors::InvalidArgument(\"Invalid PNG. Failed to initialize decoder.\"));\n \n+    // If we reach this point, then there is data in `decode` which must be\n+    // freed by the time we end execution in this function. We cannot call\n+    // `png::CommonFreeDecode()` before an `OP_REQUIRES` because if\n+    // `OP_REQUIRES` constraint is satisfied then the data would be freed\n+    // prematurely. Instead, let's use a `Cleanup` object.\n+    auto cleanup = gtl::MakeCleanup([&decode]() {\n+      std::cerr << \"Cleanup called...\\n\";\n+      png::CommonFreeDecode(&decode);\n+    });\n+\n     // Verify that width and height are not too large:\n     // - verify width and height don't overflow int.\n     // - width can later be multiplied by channels_ and sizeof(uint16), so\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "c99d98cd189839dcf51aee94e7437b54b31f8abd",
        "repo": "tensorflow/tensorflow",
        "msg": "Handle invalid inputs instead of crashing.\n\nPiperOrigin-RevId: 409549744\nChange-Id: I7f5935b34b53f7e426a5462fcc027bdbf5dcda24Tensorflow is an Open Source Machine Learning Framework. TensorFlow's type inference can cause a heap out of bounds read as the bounds checking is done in a `DCHECK` (which is a no-op during production). An attacker can control the `input_idx` variable such that `ix` would be larger than the number of values in `node_t.args`. The fix will be included in TensorFlow 2.8.0. This is the only affected version.",
        "filename": "graph.cc",
        "diff": "diff --git a/tensorflow/core/graph/graph.cc b/tensorflow/core/graph/graph.cc\nindex 2e3703b66030f4..4af258a203813d 100644\n--- a/tensorflow/core/graph/graph.cc\n+++ b/tensorflow/core/graph/graph.cc\n@@ -222,10 +222,16 @@ void Node::RunForwardTypeInference() {\n       const auto& node_t = node->def().experimental_type();\n       if (node_t.type_id() != TFT_UNSET) {\n         int ix = input_idx[i];\n-        DCHECK(ix < node_t.args_size())\n-            << \"input \" << i << \" should have an output \" << ix\n-            << \" but instead only has \" << node_t.args_size()\n-            << \" outputs: \" << node_t.DebugString();\n+        if (ix >= node_t.args_size()) {\n+          LOG(WARNING) << name() << \" has bad type information: input \" << i\n+                       << \" should have an output \" << ix\n+                       << \" but instead only has \" << node_t.args_size()\n+                       << \" outputs: \" << node_t.DebugString()\n+                       << \"\\nThis indicates either \"\n+                          \"a bug in op registration or a corrupted graph.\";\n+          ClearTypeInfo();\n+          return;\n+        }\n         input_types.emplace_back(node_t.args(ix));\n       } else {\n         input_types.emplace_back(*no_type);\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "b51b82fe65ebace4475e3c54eb089c18a4403f1c",
        "repo": "tensorflow/tensorflow",
        "msg": "Add missing validation to `AddManySparseToTensorsMap`.\n\nSparse tensors have a set of requirements for the 3 components and not all of them were checked.\n\nPiperOrigin-RevId: 415358027\nChange-Id: I96cbb672999cd1da772c22fabbd15507e32e12dcTensorflow is an Open Source Machine Learning Framework. The implementation of `AddManySparseToTensorsMap` is vulnerable to an integer overflow which results in a `CHECK`-fail when building new `TensorShape` objects (so, an assert failure based denial of service). We are missing some validation on the shapes of the input tensors as well as directly constructing a large `TensorShape` with user-provided dimensions. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "filename": "sparse_tensors_map_ops.cc",
        "diff": "diff --git a/tensorflow/core/kernels/sparse_tensors_map_ops.cc b/tensorflow/core/kernels/sparse_tensors_map_ops.cc\nindex 04efed5fd90c75..5fa690743b05c1 100644\n--- a/tensorflow/core/kernels/sparse_tensors_map_ops.cc\n+++ b/tensorflow/core/kernels/sparse_tensors_map_ops.cc\n@@ -231,16 +231,29 @@ class AddManySparseToTensorsMapOp : public SparseTensorAccessingOp {\n                 errors::InvalidArgument(\n                     \"Input indices should be a matrix but received shape \",\n                     input_indices->shape().DebugString()));\n-\n     OP_REQUIRES(context, TensorShapeUtils::IsVector(input_values->shape()),\n                 errors::InvalidArgument(\n                     \"Input values should be a vector but received shape \",\n                     input_values->shape().DebugString()));\n-\n     OP_REQUIRES(context, TensorShapeUtils::IsVector(input_shape->shape()),\n                 errors::InvalidArgument(\n                     \"Input shape should be a vector but received shape \",\n                     input_shape->shape().DebugString()));\n+    OP_REQUIRES(\n+        context,\n+        input_values->shape().dim_size(0) == input_indices->shape().dim_size(0),\n+        errors::InvalidArgument(\n+            \"Number of values must match first dimension of indices. \", \"Got \",\n+            input_values->shape().dim_size(0),\n+            \" values, indices shape: \", input_indices->shape().DebugString()));\n+    OP_REQUIRES(\n+        context,\n+        input_shape->shape().dim_size(0) == input_indices->shape().dim_size(1),\n+        errors::InvalidArgument(\n+            \"Number of dimensions must match second dimension of indices. \",\n+            \"Got \", input_shape->shape().dim_size(0),\n+            \" dimensions, indices shape: \",\n+            input_indices->shape().DebugString()));\n \n     int rank = input_shape->NumElements();\n \n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "27d1e0132a0804581dca28df042e7047fd27eaa8",
        "repo": "mruby/mruby",
        "msg": "array.c: fix `mrb_ary_shift_m` initialization bug.\n\nThe `ARY_PTR` and `ARY_LEN` may be modified in `mrb_get_args`.mruby is vulnerable to NULL Pointer Dereference",
        "filename": "array.c",
        "diff": "diff --git a/src/array.c b/src/array.c\nindex c100591ebe..1a95b75c93 100644\n--- a/src/array.c\n+++ b/src/array.c\n@@ -581,14 +581,16 @@ mrb_ary_shift(mrb_state *mrb, mrb_value self)\n static mrb_value\n mrb_ary_shift_m(mrb_state *mrb, mrb_value self)\n {\n-  struct RArray *a = mrb_ary_ptr(self);\n-  mrb_int len = ARY_LEN(a);\n   mrb_int n;\n-  mrb_value val;\n \n   if (mrb_get_args(mrb, \"|i\", &n) == 0) {\n     return mrb_ary_shift(mrb, self);\n-  };\n+  }\n+\n+  struct RArray *a = mrb_ary_ptr(self);\n+  mrb_int len = ARY_LEN(a);\n+  mrb_value val;\n+\n   ary_modify_check(mrb, a);\n   if (len == 0 || n == 0) return mrb_ary_new(mrb);\n   if (n < 0) mrb_raise(mrb, E_ARGUMENT_ERROR, \"negative array shift\");\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "e7f497570abb6b4ae5af4970620cd880e4c0c904",
        "repo": "tensorflow/tensorflow",
        "msg": "Fix segfault on OOM in Conv2D.\n\nPiperOrigin-RevId: 404655317\nChange-Id: I33588dbd3f5d0fef980e3c908bf5515a9ee09ce7TensorFlow is an open source platform for machine learning. In affected versions several TensorFlow operations are missing validation for the shapes of the tensor arguments involved in the call. Depending on the API, this can result in undefined behavior and segfault or `CHECK`-fail related crashes but in some scenarios writes and reads from heap populated arrays are also possible. We have discovered these issues internally via tooling while working on improving/testing GPU op determinism. As such, we don't have reproducers and there will be multiple fixes for these issues. These fixes will be included in TensorFlow 2.7.0. We will also cherrypick these commits on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.",
        "filename": "conv_ops.cc",
        "diff": "diff --git a/tensorflow/core/kernels/conv_ops.cc b/tensorflow/core/kernels/conv_ops.cc\nindex 94926358675fb2..67418151a1cf2d 100644\n--- a/tensorflow/core/kernels/conv_ops.cc\n+++ b/tensorflow/core/kernels/conv_ops.cc\n@@ -183,12 +183,18 @@ struct LaunchGrouped {\n     auto on_shuffled = [&]() { shuffles_completed.DecrementCount(); };\n \n     // Shuffle input into temporary tensor.\n-    Tensor input_shuffled(input.dtype(), TensorShape(post_shuffle(input)));\n+    Tensor input_shuffled;\n+    OP_REQUIRES_OK(\n+        ctx, ctx->allocate_temp(input.dtype(), TensorShape(post_shuffle(input)),\n+                                &input_shuffled));\n     input_shuffled.tensor<T, 5>().device(device, on_shuffled) =\n         input.shaped<T, 5>(pre_shuffle(input)).shuffle(shuffle);\n \n     // Shuffle filter into temporary tensor.\n-    Tensor filter_shuffled(filter.dtype(), TensorShape(post_shuffle(filter)));\n+    Tensor filter_shuffled;\n+    OP_REQUIRES_OK(ctx, ctx->allocate_temp(filter.dtype(),\n+                                           TensorShape(post_shuffle(filter)),\n+                                           &filter_shuffled));\n     filter_shuffled.tensor<T, 5>().device(device, on_shuffled) =\n         filter.shaped<T, 5>(pre_shuffle(filter)).shuffle(shuffle);\n \n@@ -196,7 +202,10 @@ struct LaunchGrouped {\n     shuffles_completed.Wait();\n \n     // Write group convolution results into temporary output tensor.\n-    Tensor output_shuffled(output->dtype(), TensorShape(post_shuffle(*output)));\n+    Tensor output_shuffled;\n+    OP_REQUIRES_OK(ctx, ctx->allocate_temp(output->dtype(),\n+                                           TensorShape(post_shuffle(*output)),\n+                                           &output_shuffled));\n \n     for (int64_t i = 0; i < num_groups; ++i) {\n       // TODO(ezhulenev): Run this loop using `parallelFor` (regular parallelFor\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "e21af685e1828f7ca65038307df5cc06de4479e8",
        "repo": "tensorflow/tensorflow",
        "msg": "Fix Null-pointer dereference in BuildXlaCompilationCache\n\nIf ConfigProto is not used, then use the default settings which is to allow all devices.\n\nPiperOrigin-RevId: 420391800\nChange-Id: I88161ad7042990aef678e77b597a2fb2c8f815beTensorflow is an Open Source Machine Learning Framework. When building an XLA compilation cache, if default settings are used, TensorFlow triggers a null pointer dereference. In the default scenario, all devices are allowed, so `flr->config_proto` is `nullptr`. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "filename": "xla_platform_info.cc",
        "diff": "diff --git a/tensorflow/compiler/jit/xla_platform_info.cc b/tensorflow/compiler/jit/xla_platform_info.cc\nindex 8b20c9169c3e90..96d6e27d36a7ee 100644\n--- a/tensorflow/compiler/jit/xla_platform_info.cc\n+++ b/tensorflow/compiler/jit/xla_platform_info.cc\n@@ -82,11 +82,13 @@ Status BuildXlaCompilationCache(DeviceBase* device, FunctionLibraryRuntime* flr,\n   client_options.set_intra_op_parallelism_threads(\n       device->tensorflow_cpu_worker_threads()->num_threads);\n \n-  string allowed_gpus =\n-      flr->config_proto()->gpu_options().visible_device_list();\n-  TF_ASSIGN_OR_RETURN(absl::optional<std::set<int>> gpu_ids,\n-                      ParseVisibleDeviceList(allowed_gpus));\n-  client_options.set_allowed_devices(gpu_ids);\n+  if (flr->config_proto()) {\n+    string allowed_gpus =\n+        flr->config_proto()->gpu_options().visible_device_list();\n+    TF_ASSIGN_OR_RETURN(absl::optional<std::set<int>> gpu_ids,\n+                        ParseVisibleDeviceList(allowed_gpus));\n+    client_options.set_allowed_devices(gpu_ids);\n+  }\n \n   auto client = xla::ClientLibrary::GetOrCreateLocalClient(client_options);\n   if (!client.ok()) {\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "2b7100d6cdff36aa21010a82269bc05a6d1cc74a",
        "repo": "tensorflow/tensorflow",
        "msg": "Cleanup and remove duplicate validation in `SparseCount`.\n\nWe have valdiation that is duplicated, checking different conditions, in different formats and failing to capture all cases. This should fix all the previous bugs.\n\nPiperOrigin-RevId: 414886981\nChange-Id: Ibf0bba0beb057b76d505324bb9487565daf95f01Tensorflow is an Open Source Machine Learning Framework. The implementation of `SparseCountSparseOutput` is vulnerable to a heap overflow. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "filename": "count_ops.cc",
        "diff": "diff --git a/tensorflow/core/kernels/count_ops.cc b/tensorflow/core/kernels/count_ops.cc\nindex 5330c36361e5e6..1f99e0783e26f6 100644\n--- a/tensorflow/core/kernels/count_ops.cc\n+++ b/tensorflow/core/kernels/count_ops.cc\n@@ -185,6 +185,27 @@ class SparseCount : public OpKernel {\n                 errors::InvalidArgument(\n                     \"Input indices must be a 2-dimensional tensor. Got: \",\n                     indices.shape().DebugString()));\n+    OP_REQUIRES(context, TensorShapeUtils::IsVector(values.shape()),\n+                errors::InvalidArgument(\"Input values must be a vector. Got: \",\n+                                        values.shape().DebugString()));\n+    OP_REQUIRES(context, TensorShapeUtils::IsVector(shape.shape()),\n+                errors::InvalidArgument(\"Input shape must be a vector. Got: \",\n+                                        shape.shape().DebugString()));\n+    OP_REQUIRES(context,\n+                values.shape().dim_size(0) == indices.shape().dim_size(0),\n+                errors::InvalidArgument(\n+                    \"Number of values must match first dimension of indices.\",\n+                    \"Got \", values.shape().dim_size(0),\n+                    \" values, indices shape: \", indices.shape().DebugString()));\n+    OP_REQUIRES(\n+        context, shape.shape().dim_size(0) == indices.shape().dim_size(1),\n+        errors::InvalidArgument(\n+            \"Number of dimensions must match second dimension of indices.\",\n+            \"Got \", shape.shape().dim_size(0),\n+            \" dimensions, indices shape: \", indices.shape().DebugString()));\n+    OP_REQUIRES(context, shape.NumElements() > 0,\n+                errors::InvalidArgument(\n+                    \"The shape argument requires at least one element.\"));\n \n     if (use_weights) {\n       OP_REQUIRES(\n@@ -195,28 +216,11 @@ class SparseCount : public OpKernel {\n               \"; values shape: \", values.shape().DebugString()));\n     }\n \n-    OP_REQUIRES(context, shape.NumElements() != 0,\n-                errors::InvalidArgument(\n-                    \"The shape argument requires at least one element.\"));\n-\n     bool is_1d = shape.NumElements() == 1;\n     auto shape_vector = shape.flat<int64_t>();\n     int num_batches = is_1d ? 1 : shape_vector(0);\n     int num_values = values.NumElements();\n \n-    for (int b = 0; b < shape_vector.size(); b++) {\n-      OP_REQUIRES(context, shape_vector(b) >= 0,\n-                  errors::InvalidArgument(\n-                      \"Elements in dense_shape must be >= 0. Instead got:\",\n-                      shape.DebugString()));\n-    }\n-\n-    OP_REQUIRES(context, num_values == indices.shape().dim_size(0),\n-                errors::InvalidArgument(\n-                    \"Number of values must match first dimension of indices.\",\n-                    \"Got \", num_values,\n-                    \" values, indices shape: \", indices.shape().DebugString()));\n-\n     const auto indices_values = indices.matrix<int64_t>();\n     const auto values_values = values.flat<T>();\n     const auto weight_values = weights.flat<W>();\n@@ -225,16 +229,6 @@ class SparseCount : public OpKernel {\n \n     T max_value = 0;\n \n-    OP_REQUIRES(context, num_values <= indices.shape().dim_size(0),\n-                errors::InvalidArgument(\n-                    \"The first dimension of indices must be equal to or \"\n-                    \"greather than number of values. ( \",\n-                    indices.shape().dim_size(0), \" vs. \", num_values, \" )\"));\n-    OP_REQUIRES(context, indices.shape().dim_size(1) > 0,\n-                errors::InvalidArgument(\"The second dimension of indices must \"\n-                                        \"be greater than 0. Received: \",\n-                                        indices.shape().dim_size(1)));\n-\n     for (int idx = 0; idx < num_values; ++idx) {\n       int batch = is_1d ? 0 : indices_values(idx, 0);\n       if (batch >= num_batches) {\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "8c6f391a2282684a25cbfec7687bd5d35261a209",
        "repo": "tensorflow/tensorflow",
        "msg": "[lite] Add check for bias_size is zero to avoid division by zero. This shouldn't happen for properly converted models. Just safety check\n\nPiperOrigin-RevId: 416383645\nChange-Id: If8e508bf696ae8ecfb927e69c139a8ccf7fe60cbTensorflow is an Open Source Machine Learning Framework. An attacker can craft a TFLite model that would trigger a division by zero in `BiasAndClamp` implementation. There is no check that the `bias_size` is non zero. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "filename": "common.h",
        "diff": "diff --git a/tensorflow/lite/kernels/internal/common.h b/tensorflow/lite/kernels/internal/common.h\nindex 38fa9167fd9da0..5e8778f183ec33 100644\n--- a/tensorflow/lite/kernels/internal/common.h\n+++ b/tensorflow/lite/kernels/internal/common.h\n@@ -75,6 +75,7 @@ float ActivationFunction(float x) {\n inline void BiasAndClamp(float clamp_min, float clamp_max, int bias_size,\n                          const float* bias_data, int array_size,\n                          float* array_data) {\n+  if (bias_size == 0) return;\n   // Note: see b/132215220: in May 2019 we thought it would be OK to replace\n   // this with the Eigen one-liner:\n   //   return (array.colwise() + bias).cwiseMin(clamp_max).cwiseMin(clamp_max).\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "92dba16749fae36c246bec3f9ba474d9ddeb7662",
        "repo": "tensorflow/tensorflow",
        "msg": "Prevent a null-pointer dereference / `CHECK`-fail in grappler.\n\nPiperOrigin-RevId: 409187354\nChange-Id: I369c249cca32e6c56ec193f0ebbf2f2768fc7d43Tensorflow is an Open Source Machine Learning Framework. The Grappler optimizer in TensorFlow can be used to cause a denial of service by altering a `SavedModel` such that `SafeToRemoveIdentity` would trigger `CHECK` failures. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "filename": "dependency_optimizer.cc",
        "diff": "diff --git a/tensorflow/core/grappler/optimizers/dependency_optimizer.cc b/tensorflow/core/grappler/optimizers/dependency_optimizer.cc\nindex aadea833a4fc48..bfd98a58a77718 100644\n--- a/tensorflow/core/grappler/optimizers/dependency_optimizer.cc\n+++ b/tensorflow/core/grappler/optimizers/dependency_optimizer.cc\n@@ -75,8 +75,10 @@ bool DependencyOptimizer::SafeToRemoveIdentity(const NodeDef& node) const {\n   }\n \n   const NodeDef* input = node_map_->GetNode(NodeName(node.input(0)));\n-  CHECK(input != nullptr) << \"node = \" << node.name()\n-                          << \" input = \" << node.input(0);\n+  if (input == nullptr) {\n+    VLOG(1) << \"node = \" << node.name() << \" input = \" << node.input(0);\n+    return false;\n+  }\n   // Don't remove Identity nodes corresponding to Variable reads or following\n   // Recv.\n   if (IsVariable(*input) || IsRecv(*input)) {\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "33441d90a506d5f3ae9388f2752901227e430553",
        "repo": "LibVNC/libvncserver",
        "msg": "libvncclient/tls_openssl: do not deref a NULL pointer\n\nHappens in anonTLS mode where cred is NULL.\n\nre #347An issue was discovered in LibVNCServer before 0.9.13. libvncclient/tls_openssl.c has a NULL pointer dereference.",
        "filename": "tls_openssl.c",
        "diff": "diff --git a/libvncclient/tls_openssl.c b/libvncclient/tls_openssl.c\nindex c9b2647c5..fcef1bc3e 100644\n--- a/libvncclient/tls_openssl.c\n+++ b/libvncclient/tls_openssl.c\n@@ -268,7 +268,7 @@ open_ssl_connection (rfbClient *client, int sockfd, rfbBool anonTLS, rfbCredenti\n   SSL *ssl = NULL;\n   int n, finished = 0;\n   X509_VERIFY_PARAM *param;\n-  uint8_t verify_crls = cred->x509Credential.x509CrlVerifyMode;\n+  uint8_t verify_crls;\n \n   if (!(ssl_ctx = SSL_CTX_new(SSLv23_client_method())))\n   {\n@@ -281,6 +281,7 @@ open_ssl_connection (rfbClient *client, int sockfd, rfbBool anonTLS, rfbCredenti\n   /* Setup verification if not anonymous */\n   if (!anonTLS)\n   {\n+    verify_crls = cred->x509Credential.x509CrlVerifyMode;\n     if (cred->x509Credential.x509CACertFile)\n     {\n       if (!SSL_CTX_load_verify_locations(ssl_ctx, cred->x509Credential.x509CACertFile, NULL))\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "5f2c2a16d30229b6241f02fa28e3d6b810d64858",
        "repo": "gpac/gpac",
        "msg": "fixed #1905The binary MP4Box in Gpac 1.0.1 has a null pointer dereference vulnerability in the mpgviddmx_process function in reframe_mpgvid.c, which allows attackers to cause a denial of service. This vulnerability is possibly due to an incomplete fix for CVE-2021-40566.",
        "filename": "reframe_mpgvid.c",
        "diff": "diff --git a/src/filters/reframe_mpgvid.c b/src/filters/reframe_mpgvid.c\nindex 328db28551..85d4faa4cb 100644\n--- a/src/filters/reframe_mpgvid.c\n+++ b/src/filters/reframe_mpgvid.c\n@@ -784,8 +784,14 @@ GF_Err mpgviddmx_process(GF_Filter *filter)\n \t\t\tmpgviddmx_enqueue_or_dispatch(ctx, dst_pck, GF_FALSE, GF_FALSE);\n \t\t}\n \n-\t\t//parse headers\n+\t\t//not enough bytes to parse start code\n+\t\tif (remain<5) {\n+\t\t\tmemcpy(ctx->hdr_store, start, remain);\n+\t\t\tctx->bytes_in_header = remain;\n+\t\t\tbreak;\n+\t\t}\n \n+\t\t//parse headers\n \t\t//we have a start code loaded, eg the data packet does not have a full start code at the beginning\n \t\tif (sc_type_forced) {\n \t\t\tgf_bs_reassign_buffer(ctx->bs, start + hdr_offset, remain - hdr_offset);\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "839085f8026afd6f6920a0c31ad2a9d880d97932",
        "repo": "weihongbin1/graphviz",
        "msg": "attempted fix for null pointer deference on malformed inputThe agroot() function in cgraph\\obj.c in libcgraph.a in Graphviz 2.39.20160612.1140 has a NULL pointer dereference, as demonstrated by graphml2gv.",
        "filename": "None",
        "diff": "diff --git a/cmd/tools/graphml2gv.c b/cmd/tools/graphml2gv.c\nindex f4798089e..b9fc9730c 100644\n--- a/cmd/tools/graphml2gv.c\n+++ b/cmd/tools/graphml2gv.c\n@@ -468,8 +468,10 @@ startElementHandler(void *userData, const char *name, const char **atts)\n \tif (pos > 0) {\n \t    const char *attrname;\n \t    attrname = atts[pos];\n-\n-\t    bind_node(attrname);\n+            if (G == 0)\n+                fprintf(stderr,\"node %s outside graph, ignored\\n\",attrname);\n+\t    else\n+                bind_node(attrname);\n \n \t    pushString(&ud->elements, attrname);\n \t}\n@@ -495,21 +497,25 @@ startElementHandler(void *userData, const char *name, const char **atts)\n \tif (tname)\n \t    head = tname;\n \n-\tbind_edge(tail, head);\n+        if (G == 0)\n+            fprintf(stderr,\"edge source %s target %s outside graph, ignored\\n\",(char*)tail,(char*)head);\n+        else {\n+            bind_edge(tail, head);\n \n-\tt = AGTAIL(E);\n-\ttname = agnameof(t);\n+            t = AGTAIL(E);\n+\t    tname = agnameof(t);\n \n-\tif (strcmp(tname, tail) == 0) {\n-\t    ud->edgeinverted = FALSE;\n-\t} else if (strcmp(tname, head) == 0) {\n-\t    ud->edgeinverted = TRUE;\n-\t}\n+\t    if (strcmp(tname, tail) == 0) {\n+\t        ud->edgeinverted = FALSE;\n+\t    } else if (strcmp(tname, head) == 0) {\n+\t        ud->edgeinverted = TRUE;\n+\t    }\n \n-\tpos = get_xml_attr(\"id\", atts);\n-\tif (pos > 0) {\n-\t    setEdgeAttr(E, GRAPHML_ID, (char *) atts[pos], ud);\n-\t}\n+\t    pos = get_xml_attr(\"id\", atts);\n+\t    if (pos > 0) {\n+\t        setEdgeAttr(E, GRAPHML_ID, (char *) atts[pos], ud);\n+\t    }\n+        }\n     } else {\n \t/* must be some extension */\n \tfprintf(stderr,\n@@ -530,7 +536,7 @@ static void endElementHandler(void *userData, const char *name)\n \tchar *ele_name = topString(ud->elements);\n \tif (ud->closedElementType == TAG_GRAPH) {\n \t    Agnode_t *node = agnode(root, ele_name, 0);\n-\t    agdelete(root, node);\n+\t    if (node) agdelete(root, node);\n \t}\n \tpopString(&ud->elements);\n \tCurrent_class = TAG_GRAPH;\ndiff --git a/lib/cgraph/grammar.y b/lib/cgraph/grammar.y\nindex 90aa27387..127a7241a 100644\n--- a/lib/cgraph/grammar.y\n+++ b/lib/cgraph/grammar.y\n@@ -22,6 +22,7 @@ extern void yyerror(char *);\t/* gets mapped to aagerror, see below */\n #endif\n \n static char Key[] = \"key\";\n+static int SubgraphDepth = 0;\n \n typedef union s {\t\t\t\t\t/* possible items in generic list */\n \t\tAgnode_t\t\t*n;\n@@ -542,6 +543,7 @@ static void startgraph(char *name, int directed, int strict)\n \tstatic Agdesc_t\treq;\t/* get rid of warnings */\n \n \tif (G == NILgraph) {\n+    SubgraphDepth = 0;\n \t\treq.directed = directed;\n \t\treq.strict = strict;\n \t\treq.maingraph = TRUE;\n@@ -562,6 +564,11 @@ static void endgraph()\n \n static void opensubg(char *name)\n {\n+  if (++SubgraphDepth >= YYMAXDEPTH/2) {\n+    char buf[128];\n+    sprintf(buf,\"subgraphs nested more than %d deep\",YYMAXDEPTH);\n+    agerr(AGERR,buf);\n+  }\n \tS = push(S,agsubg(S->g,name,TRUE));\n \tagstrfree(G,name);\n }\n@@ -569,6 +576,7 @@ static void opensubg(char *name)\n static void closesubg()\n {\n \tAgraph_t *subg = S->g;\n+  --SubgraphDepth;\n \tS = pop(S);\n \tS->subg = subg;\n \tassert(subg);\ndiff --git a/lib/cgraph/obj.c b/lib/cgraph/obj.c\nindex 7b1c8c101..709774e3d 100644\n--- a/lib/cgraph/obj.c\n+++ b/lib/cgraph/obj.c\n@@ -168,6 +168,8 @@ void agdelcb(Agraph_t * g, void *obj, Agcbstack_t * cbstack)\n \n Agraph_t *agroot(void* obj)\n {\n+    // fixes CVE-2019-11023 by moving the problem to the caller :-)\n+    if (obj == 0) return NILgraph; \n     switch (AGTYPE(obj)) {\n     case AGINEDGE:\n     case AGOUTEDGE:\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "052cbd17c3cbbc602ee080b2617d32a8417d7563",
        "repo": "gnuplot/gnuplot",
        "msg": "successive failures of \"set print <foo>\" could cause double-free\nBug #2312gnuplot 5.5 is affected by double free when executing print_set_output. This may result in context-dependent arbitrary code execution.",
        "filename": "None",
        "diff": "diff --git a/src/command.c b/src/command.c\nindex c6a923b5a..9701de995 100644\n--- a/src/command.c\n+++ b/src/command.c\n@@ -1914,6 +1914,7 @@ print_set_output(char *name, TBOOLEAN datablock, TBOOLEAN append_p)\n #endif\n \t    if (0 > fclose(print_out))\n \t\tperror(print_out_name);\n+\tprint_out = stderr;\n     }\n \n     free(print_out_name);\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "fb246611e62ad8c5a95b0ca180a63f17aa34b0d8",
        "repo": "LibreOffice/core",
        "msg": "lib-ntlm: Check buffer length on responses\n\nAdd missing check for buffer length.\n\nIf this is not checked, it is possible to send message which\ncauses read past buffer bug.\n\nBroken in c7480644202e5451fbed448508ea29a25cffc99cIn Dovecot before 2.3.11.3, sending a specially formatted NTLM request will crash the auth service because of an out-of-bounds read.",
        "filename": "None",
        "diff": "diff --git a/src/lib-ntlm/ntlm-message.c b/src/lib-ntlm/ntlm-message.c\nindex 160b9f918c..a29413b47e 100644\n--- a/src/lib-ntlm/ntlm-message.c\n+++ b/src/lib-ntlm/ntlm-message.c\n@@ -184,6 +184,11 @@ static bool ntlmssp_check_buffer(const struct ntlmssp_buffer *buffer,\n \tif (length == 0 && space == 0)\n \t\treturn TRUE;\n \n+\tif (length > data_size) {\n+\t\t*error = \"buffer length out of bounds\";\n+\t\treturn FALSE;\n+\t}\n+\n \tif (offset >= data_size) {\n \t\t*error = \"buffer offset out of bounds\";\n \t\treturn FALSE;\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "af09d8b96a8aacdd7d738fec81b695c1c58368f7",
        "repo": "php/php-src",
        "msg": "Fixed Bug #66815 imagecrop(): insufficient fix for NULL defer CVE-2013-7327\n\nThis amends commit 8f4a537, which aimed to correct NULL dereference because of\nmissing check of gdImageCreateTrueColor() / gdImageCreate() return value.  That\ncommit checks for negative crop rectangle width and height, but\ngdImageCreate*() can also return NULL when width * height overflows.  Hence\nNULL deref is still possible, as gdImageSaveAlpha() and gdImagePaletteCopy()\nis called before dst == NULL check.\n\nThis moves NULL check to happen right after gdImageCreate*().  It also removes\nwidth and height check before gdImageCreate*(), as the same check is done by\nimage create functions (with an extra warning).\n\nFrom thoger redhat comInteger overflow in the gdImageCrop function in ext/gd/gd.c in PHP 5.5.x before 5.5.9 allows remote attackers to cause a denial of service (application crash) or possibly have unspecified other impact via an imagecrop function call with a large x dimension value, leading to a heap-based buffer overflow.",
        "filename": "None",
        "diff": "diff --git a/ext/gd/libgd/gd_crop.c b/ext/gd/libgd/gd_crop.c\nindex bba425d0e3fcc..84edb5d1f7f8f 100644\n--- a/ext/gd/libgd/gd_crop.c\n+++ b/ext/gd/libgd/gd_crop.c\n@@ -45,22 +45,20 @@ gdImagePtr gdImageCrop(gdImagePtr src, const gdRectPtr crop)\n \tgdImagePtr dst;\n \tint y;\n \n-\t/* check size */\n-\tif (crop->width<=0 || crop->height<=0) {\n-\t\treturn NULL;\n-\t}\n-\n \t/* allocate the requested size (could be only partially filled) */\n \tif (src->trueColor) {\n \t\tdst = gdImageCreateTrueColor(crop->width, crop->height);\n+\t\tif (dst == NULL) {\n+\t\t\treturn NULL;\n+\t\t}\n \t\tgdImageSaveAlpha(dst, 1);\n \t} else {\n \t\tdst = gdImageCreate(crop->width, crop->height);\n+\t\tif (dst == NULL) {\n+\t\t\treturn NULL;\n+\t\t}\n \t\tgdImagePaletteCopy(dst, src);\n \t}\n-\tif (dst == NULL) {\n-\t\treturn NULL;\n-\t}\n \tdst->transparent = src->transparent;\n \n \t/* check position in the src image */\ndiff --git a/ext/gd/tests/bug66356.phpt b/ext/gd/tests/bug66356.phpt\nindex 2da91d61a9f3e..583d74942c8cc 100644\n--- a/ext/gd/tests/bug66356.phpt\n+++ b/ext/gd/tests/bug66356.phpt\n@@ -24,6 +24,8 @@ var_dump(imagecrop($img, array(\"x\" => -20, \"y\" => -20, \"width\" => 10, \"height\" =\n // POC #4\n var_dump(imagecrop($img, array(\"x\" => 0x7fffff00, \"y\" => 0, \"width\" => 10, \"height\" => 10)));\n \n+// bug 66815\n+var_dump(imagecrop($img, array(\"x\" => 0, \"y\" => 0, \"width\" => 65535, \"height\" => 65535)));\n ?>\n --EXPECTF--\n resource(%d) of type (gd)\n@@ -35,6 +37,13 @@ Array\n     [width] => 10\n     [height] => 10\n )\n+\n+Warning: imagecrop(): gd warning: one parameter to a memory allocation multiplication is negative or zero, failing operation gracefully\n+ in %sbug66356.php on line %d\n bool(false)\n resource(%d) of type (gd)\n-resource(%d) of type (gd)\n\\ No newline at end of file\n+resource(%d) of type (gd)\n+\n+Warning: imagecrop(): gd warning: product of memory allocation multiplication would exceed INT_MAX, failing operation gracefully\n+ in %sbug66356.php on line %d\n+bool(false)\n\\ No newline at end of file\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "052cbd17c3cbbc602ee080b2617d32a8417d7563",
        "repo": "gnuplot/gnuplot",
        "msg": "successive failures of \"set print <foo>\" could cause double-free\nBug #2312gnuplot 5.5 is affected by double free when executing print_set_output. This may result in context-dependent arbitrary code execution.",
        "filename": "None",
        "diff": "diff --git a/src/command.c b/src/command.c\nindex c6a923b5a..9701de995 100644\n--- a/src/command.c\n+++ b/src/command.c\n@@ -1914,6 +1914,7 @@ print_set_output(char *name, TBOOLEAN datablock, TBOOLEAN append_p)\n #endif\n \t    if (0 > fclose(print_out))\n \t\tperror(print_out_name);\n+\tprint_out = stderr;\n     }\n \n     free(print_out_name);\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "963c7df3e0c5266efff260d0dff757dfe03d3632",
        "repo": "gnuplot/gnuplot",
        "msg": "Better error handling for faulty font syntax\n\nA missing close-quote in an enhanced text font specification could\ncause a segfault.\nBug #2303com_line() in command.c in gnuplot 5.4 leads to an out-of-bounds-write from strncpy() that may lead to arbitrary code execution.",
        "filename": "None",
        "diff": "diff --git a/src/term.c b/src/term.c\nindex fb99a9a6f..7fd46fa04 100644\n--- a/src/term.c\n+++ b/src/term.c\n@@ -2175,7 +2175,7 @@ enhanced_recursion(\n \t\t\t    ++p;\n \t\t\tif (*p != *start_of_fontname) {\n \t\t\t    int_warn(NO_CARET, \"cannot interpret font name %s\", start_of_fontname);\n-\t\t\t    p = start_of_fontname;\n+\t\t\t    p = start_of_fontname + 1;\n \t\t\t}\n \t\t\tstart_of_fontname++;\n \t\t\tend_of_fontname = p++;\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "2e7891080667c59ac80f788eef4d59d447595772",
        "repo": "MariaDB/server",
        "msg": "MDEV-25635 Assertion failure when pushing from HAVING into WHERE of view\n\nThis bug could manifest itself after pushing a where condition over a\nmergeable derived table / view / CTE DT into a grouping view / derived\ntable / CTE V whose item list contained set functions with constant\narguments such as MIN(2), SUM(1) etc. In such cases the field references\nused in the condition pushed into the view V that correspond set functions\nare wrapped into Item_direct_view_ref wrappers. Due to a wrong implementation\nof the virtual method const_item() for the class Item_direct_view_ref the\nwrapped set functions with constant arguments could be erroneously taken\nfor constant items. This could lead to a wrong result set returned by the\nmain select query in 10.2. In 10.4 where a possibility of pushing condition\nfrom HAVING into WHERE had been added this could cause a crash.\n\nApproved by Sergey Petrunya <sergey.petrunya@mariadb.com>MariaDB before 10.6.2 allows an application crash because of mishandling of a pushdown from a HAVING clause to a WHERE clause.",
        "filename": "None",
        "diff": "diff --git a/mysql-test/r/derived_cond_pushdown.result b/mysql-test/r/derived_cond_pushdown.result\nindex 25237aa11a98d..28532ae88a437 100644\n--- a/mysql-test/r/derived_cond_pushdown.result\n+++ b/mysql-test/r/derived_cond_pushdown.result\n@@ -10634,4 +10634,43 @@ m\n 7\n drop view v1;\n drop table t1;\n+#\n+# MDEV-25635: pushdown into grouping view using aggregate functions\n+#             with constant arguments via a mergeable derived table\n+#\n+create table t1 (a int);\n+insert into t1 values (3), (7), (1), (3), (7), (7), (3);\n+create view v1 as select a, sum(1) as f, sum(1) as g from t1 group by a;\n+select * from v1;\n+a\tf\tg\n+1\t1\t1\n+3\t3\t3\n+7\t3\t3\n+select * from (select * from v1) as dt where a=f and a=g;\n+a\tf\tg\n+1\t1\t1\n+3\t3\t3\n+explain extended select * from (select * from v1) as dt where a=f and a=g;\n+id\tselect_type\ttable\ttype\tpossible_keys\tkey\tkey_len\tref\trows\tfiltered\tExtra\n+1\tPRIMARY\t<derived3>\tALL\tNULL\tNULL\tNULL\tNULL\t7\t100.00\tUsing where\n+3\tDERIVED\tt1\tALL\tNULL\tNULL\tNULL\tNULL\t7\t100.00\tUsing temporary; Using filesort\n+Warnings:\n+Note\t1003\tselect `v1`.`a` AS `a`,`v1`.`f` AS `f`,`v1`.`g` AS `g` from `test`.`v1` where `v1`.`a` = `v1`.`f` and `v1`.`a` = `v1`.`g`\n+create view v2 as select a, min(1) as f, min(1) as g from t1 group by a;\n+select * from v2;\n+a\tf\tg\n+1\t1\t1\n+3\t1\t1\n+7\t1\t1\n+select * from (select * from v2) as dt where a=f and a=g;\n+a\tf\tg\n+1\t1\t1\n+explain extended select * from (select * from v2) as dt where a=f and a=g;\n+id\tselect_type\ttable\ttype\tpossible_keys\tkey\tkey_len\tref\trows\tfiltered\tExtra\n+1\tPRIMARY\t<derived3>\tALL\tNULL\tNULL\tNULL\tNULL\t7\t100.00\tUsing where\n+3\tDERIVED\tt1\tALL\tNULL\tNULL\tNULL\tNULL\t7\t100.00\tUsing temporary; Using filesort\n+Warnings:\n+Note\t1003\tselect `v2`.`a` AS `a`,`v2`.`f` AS `f`,`v2`.`g` AS `g` from `test`.`v2` where `v2`.`f` = `v2`.`a` and `v2`.`g` = `v2`.`a`\n+drop view v1,v2;\n+drop table t1;\n # End of 10.2 tests\ndiff --git a/mysql-test/t/derived_cond_pushdown.test b/mysql-test/t/derived_cond_pushdown.test\nindex 31b49047bf1b8..58f38ac1e5aa9 100644\n--- a/mysql-test/t/derived_cond_pushdown.test\n+++ b/mysql-test/t/derived_cond_pushdown.test\n@@ -2212,4 +2212,29 @@ select * from v1 where m > 0;\n drop view v1;\n drop table t1;\n \n+--echo #\n+--echo # MDEV-25635: pushdown into grouping view using aggregate functions\n+--echo #             with constant arguments via a mergeable derived table\n+--echo #\n+\n+create table t1 (a int);\n+insert into t1 values (3), (7), (1), (3), (7), (7), (3);\n+\n+create view v1 as select a, sum(1) as f, sum(1) as g from t1 group by a;\n+select * from v1;\n+let $q1=\n+select * from (select * from v1) as dt where a=f and a=g;\n+eval $q1;\n+eval explain extended $q1;\n+\n+create view v2 as select a, min(1) as f, min(1) as g from t1 group by a;\n+select * from v2;\n+let $q2=\n+select * from (select * from v2) as dt where a=f and a=g;\n+eval $q2;\n+eval explain extended $q2;\n+\n+drop view v1,v2;\n+drop table t1;\n+\n --echo # End of 10.2 tests\ndiff --git a/sql/item.h b/sql/item.h\nindex c94709c733e3b..76be66d2a7c6c 100644\n--- a/sql/item.h\n+++ b/sql/item.h\n@@ -4952,7 +4952,10 @@ class Item_direct_view_ref :public Item_direct_ref\n   table_map used_tables() const;\n   void update_used_tables();\n   table_map not_null_tables() const;\n-  bool const_item() const { return used_tables() == 0; }\n+  bool const_item() const\n+  {\n+    return (*ref)->const_item() && (null_ref_table == NO_NULL_TABLE);\n+  }\n   TABLE *get_null_ref_table() const { return null_ref_table; }\n   bool walk(Item_processor processor, bool walk_subquery, void *arg)\n   { \n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "0beed9b5e933f0ff79b3bb346524f7a451d14e38",
        "repo": "MariaDB/server",
        "msg": "MDEV-28097 use-after-free when WHERE has subquery with an outer reference in HAVING\n\nwhen resolving WHERE and ON clauses, do not look in\nSELECT list/aliases.MariaDB Server v10.6.3 and below was discovered to contain an use-after-free in the component my_wildcmp_8bit_impl at /strings/ctype-simple.c.",
        "filename": "None",
        "diff": "diff --git a/mysql-test/main/having.result b/mysql-test/main/having.result\nindex 8800402dc356f..b4ca607ec8483 100644\n--- a/mysql-test/main/having.result\n+++ b/mysql-test/main/having.result\n@@ -279,11 +279,7 @@ select t1.col1 as tmp_col from t1\n where t1.col2 in \n (select t2.col2 from t2 \n group by t2.col1, t2.col2 having tmp_col <= 10);\n-tmp_col\n-10\n-10\n-10\n-10\n+ERROR 42S22: Unknown column 'tmp_col' in 'having clause'\n select t1.col1 from t1\n where t1.col2 in \n (select t2.col2 from t2 \ndiff --git a/mysql-test/main/having.test b/mysql-test/main/having.test\nindex b3b128684a34b..3f4e8a8e71009 100644\n--- a/mysql-test/main/having.test\n+++ b/mysql-test/main/having.test\n@@ -249,7 +249,8 @@ where t1.col2 in\n        group by t2.col1, t2.col2 having t1.col1 <= 10);\n \n # the having column is resolved in the SELECT clause of the outer query -\n-# error in ANSI, works with MySQL extension\n+# error in ANSI\n+--error ER_BAD_FIELD_ERROR\n select t1.col1 as tmp_col from t1\n where t1.col2 in \n       (select t2.col2 from t2 \ndiff --git a/mysql-test/main/subselect_innodb.result b/mysql-test/main/subselect_innodb.result\nindex ae22329f62a83..467ed218198b9 100644\n--- a/mysql-test/main/subselect_innodb.result\n+++ b/mysql-test/main/subselect_innodb.result\n@@ -667,5 +667,17 @@ execute stmt;\n a\tb\n drop table t1,t2;\n #\n+# MDEV-28097 use-after-free when WHERE has subquery with an outer reference in HAVING\n+#\n+create table t1 (a text(60) not null) engine=innodb;\n+insert into t1 values ('1'),('0');\n+select distinct a from t1 where '' in (select 'x' like a having a like a);\n+a\n+1\n+0\n+Warnings:\n+Warning\t1292\tTruncated incorrect DOUBLE value: ''\n+drop table t1;\n+#\n # End of 10.4 tests\n #\ndiff --git a/mysql-test/main/subselect_innodb.test b/mysql-test/main/subselect_innodb.test\nindex e767891c8db76..8ff3a5acf7d18 100644\n--- a/mysql-test/main/subselect_innodb.test\n+++ b/mysql-test/main/subselect_innodb.test\n@@ -658,6 +658,14 @@ execute stmt;\n \n drop table t1,t2;\n \n+--echo #\n+--echo # MDEV-28097 use-after-free when WHERE has subquery with an outer reference in HAVING\n+--echo #\n+create table t1 (a text(60) not null) engine=innodb;\n+insert into t1 values ('1'),('0');\n+select distinct a from t1 where '' in (select 'x' like a having a like a);\n+drop table t1;\n+\n --echo #\n --echo # End of 10.4 tests\n --echo #\ndiff --git a/sql/sql_base.cc b/sql/sql_base.cc\nindex 14b97b4366098..ef7a075e30401 100644\n--- a/sql/sql_base.cc\n+++ b/sql/sql_base.cc\n@@ -8398,9 +8398,11 @@ int setup_conds(THD *thd, TABLE_LIST *tables, List<TABLE_LIST> &leaves,\n     thd->lex->which_check_option_applicable();\n   bool save_is_item_list_lookup= select_lex->is_item_list_lookup;\n   TABLE_LIST *derived= select_lex->master_unit()->derived;\n+  bool save_resolve_in_select_list= select_lex->context.resolve_in_select_list;\n   DBUG_ENTER(\"setup_conds\");\n \n   select_lex->is_item_list_lookup= 0;\n+  select_lex->context.resolve_in_select_list= false;\n \n   thd->column_usage= MARK_COLUMNS_READ;\n   DBUG_PRINT(\"info\", (\"thd->column_usage: %d\", thd->column_usage));\n@@ -8453,6 +8455,7 @@ int setup_conds(THD *thd, TABLE_LIST *tables, List<TABLE_LIST> &leaves,\n     select_lex->where= *conds;\n   }\n   thd->lex->current_select->is_item_list_lookup= save_is_item_list_lookup;\n+  select_lex->context.resolve_in_select_list= save_resolve_in_select_list;\n   DBUG_RETURN(thd->is_error());\n \n err_no_arena:\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "418ade7849ce7641c0f7333718caf5091a02fd4c",
        "repo": "bonzini/qemu",
        "msg": "softmmu: Always initialize xlat in address_space_translate_for_iotlb\n\nThe bug is an uninitialized memory read, along the translate_fail\npath, which results in garbage being read from iotlb_to_section,\nwhich can lead to a crash in io_readx/io_writex.\n\nThe bug may be fixed by writing any value with zero\nin ~TARGET_PAGE_MASK, so that the call to iotlb_to_section using\nthe xlat'ed address returns io_mem_unassigned, as desired by the\ntranslate_fail path.\n\nIt is most useful to record the original physical page address,\nwhich will eventually be logged by memory_region_access_valid\nwhen the access is rejected by unassigned_mem_accepts.\n\nResolves: https://gitlab.com/qemu-project/qemu/-/issues/1065\nSigned-off-by: Richard Henderson <richard.henderson@linaro.org>\nReviewed-by: Peter Maydell <peter.maydell@linaro.org>\nMessage-Id: <20220621153829.366423-1-richard.henderson@linaro.org>softmmu/physmem.c in QEMU through 7.0.0 can perform an uninitialized read on the translate_fail path, leading to an io_readx or io_writex crash. NOTE: a third party states that the Non-virtualization Use Case in the qemu.org reference applies here, i.e., \"Bugs affecting the non-virtualization use case are not considered security bugs at this time.",
        "filename": "None",
        "diff": "diff --git a/softmmu/physmem.c b/softmmu/physmem.c\nindex fb16be57a6c6..dc3c3e5f2e70 100644\n--- a/softmmu/physmem.c\n+++ b/softmmu/physmem.c\n@@ -669,7 +669,7 @@ void tcg_iommu_init_notifier_list(CPUState *cpu)\n \n /* Called from RCU critical section */\n MemoryRegionSection *\n-address_space_translate_for_iotlb(CPUState *cpu, int asidx, hwaddr addr,\n+address_space_translate_for_iotlb(CPUState *cpu, int asidx, hwaddr orig_addr,\n                                   hwaddr *xlat, hwaddr *plen,\n                                   MemTxAttrs attrs, int *prot)\n {\n@@ -678,6 +678,7 @@ address_space_translate_for_iotlb(CPUState *cpu, int asidx, hwaddr addr,\n     IOMMUMemoryRegionClass *imrc;\n     IOMMUTLBEntry iotlb;\n     int iommu_idx;\n+    hwaddr addr = orig_addr;\n     AddressSpaceDispatch *d =\n         qatomic_rcu_read(&cpu->cpu_ases[asidx].memory_dispatch);\n \n@@ -722,6 +723,16 @@ address_space_translate_for_iotlb(CPUState *cpu, int asidx, hwaddr addr,\n     return section;\n \n translate_fail:\n+    /*\n+     * We should be given a page-aligned address -- certainly\n+     * tlb_set_page_with_attrs() does so.  The page offset of xlat\n+     * is used to index sections[], and PHYS_SECTION_UNASSIGNED = 0.\n+     * The page portion of xlat will be logged by memory_region_access_valid()\n+     * when this memory access is rejected, so use the original untranslated\n+     * physical address.\n+     */\n+    assert((orig_addr & ~TARGET_PAGE_MASK) == 0);\n+    *xlat = orig_addr;\n     return &d->map.sections[PHYS_SECTION_UNASSIGNED];\n }\n \n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "e809ea80e3527e32c40756eddd8b2ae44bc3af1a",
        "repo": "bittorrent/bootstrap-dht",
        "msg": "Check for out-of-bounds bencoded lengths before advancing buffer pointerThe lazy_bdecode function in BitTorrent DHT bootstrap server (bootstrap-dht ) allows remote attackers to execute arbitrary code via a crafted packet, related to \"improper indexing.\"",
        "filename": "None",
        "diff": "diff --git a/lazy_bdecode.cpp b/lazy_bdecode.cpp\nindex 0f7b292..fe6cb67 100644\n--- a/lazy_bdecode.cpp\n+++ b/lazy_bdecode.cpp\n@@ -150,7 +150,9 @@ namespace libtorrent\n \t\t\t\t\tif (e)\n \t\t\t\t\t\tTORRENT_FAIL_BDECODE(e);\n \n-\t\t\t\t\tif (start + len + 1 > end)\n+\t\t\t\t\t// remaining buffer size excluding ':'\n+\t\t\t\t\tconst ptrdiff_t buff_size = end - start - 1;\n+\t\t\t\t\tif (len > buff_size)\n \t\t\t\t\t\tTORRENT_FAIL_BDECODE(bdecode_errors::unexpected_eof);\n \n \t\t\t\t\tif (len < 0)\n@@ -216,12 +218,16 @@ namespace libtorrent\n \t\t\t\t\tstart = parse_int(start, end, ':', len, e);\n \t\t\t\t\tif (e)\n \t\t\t\t\t\tTORRENT_FAIL_BDECODE(e);\n-\t\t\t\t\tif (start + len + 1 > end)\n+\n+\t\t\t\t\t// remaining buffer size excluding ':'\n+\t\t\t\t\tconst ptrdiff_t buff_size = end - start - 1;\n+\t\t\t\t\tif (len > buff_size)\n \t\t\t\t\t\tTORRENT_FAIL_BDECODE(bdecode_errors::unexpected_eof);\n \t\t\t\t\tif (len < 0)\n \t\t\t\t\t\tTORRENT_FAIL_BDECODE(bdecode_errors::overflow);\n \n \t\t\t\t\t++start;\n+\t\t\t\t\tif (start == end) TORRENT_FAIL_BDECODE(bdecode_errors::unexpected_eof);\n \t\t\t\t\ttop->construct_string(start, int(len));\n \t\t\t\t\tstack.pop_back();\n \t\t\t\t\tstart += len;\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "47eb44b2e90ca88a08dca9f9a1aa9041e9587f43",
        "repo": "imazen/gd-libgd",
        "msg": "Fix possible buffer read overflow\ndetected by -fsanitize=address, thanks to Jan BeeThe GetCode_ function in gd_gif_in.c in GD 2.1.1 and earlier, as used in PHP before 5.5.21 and 5.6.x before 5.6.5, allows remote attackers to cause a denial of service (buffer over-read and application crash) via a crafted GIF image that is improperly handled by the gdImageCreateFromGif function.",
        "filename": "None",
        "diff": "diff --git a/src/gd_gif_in.c b/src/gd_gif_in.c\nindex b3b4ca3..13a663c 100644\n--- a/src/gd_gif_in.c\n+++ b/src/gd_gif_in.c\n@@ -75,8 +75,10 @@ static struct {\n \n #define STACK_SIZE ((1<<(MAX_LWZ_BITS))*2)\n \n+#define CSD_BUF_SIZE 280\n+\n typedef struct {\n-\tunsigned char buf[280];\n+\tunsigned char buf[CSD_BUF_SIZE];\n \tint curbit;\n \tint lastbit;\n \tint done;\n@@ -468,7 +470,12 @@ GetCode_(gdIOCtx *fd, CODE_STATIC_DATA *scd, int code_size, int flag, int *ZeroD\n \n \tret = 0;\n \tfor (i = scd->curbit, j = 0; j < code_size; ++i, ++j) {\n-\t\tret |= ((scd->buf[i / 8] & (1 << (i % 8))) != 0) << j;\n+\t\tif (i < CSD_BUF_SIZE * 8) {\n+\t\t\tret |= ((scd->buf[i / 8] & (1 << (i % 8))) != 0) << j;\n+\t\t} else {\n+\t\t\tret = -1;\n+\t\t\tbreak;\n+\t\t}\n \t}\n \n \tscd->curbit += code_size;\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "5ddda15d89f5ac82f4416208c5319ace4aecdc36",
        "repo": "ucbrise/opaque",
        "msg": "Check that ecall [user_check] pointers and ocall_malloc result pointer are outside enclave (#67)\n\nThis should reduce the enclave's attack surface by preventing an attacker from invoking ecalls on or triggering unexpected writes to arbitrary enclave memory, which could potentially leak information about that memory or lead to incorrect results.\n\nFixes #36. Fixes #66.An issue was discovered in UC Berkeley RISE Opaque before 2018-12-01. There is no boundary check on ocall_malloc. The return value could be a pointer to enclave memory. It could cause an arbitrary enclave memory write.",
        "filename": "None",
        "diff": "diff --git a/src/enclave/App/App.cpp b/src/enclave/App/App.cpp\nindex 66dcbbd49b..5d680c2ddd 100644\n--- a/src/enclave/App/App.cpp\n+++ b/src/enclave/App/App.cpp\n@@ -357,7 +357,7 @@ void ocall_print_string(const char *str)\n   fflush(stdout);\n }\n \n-void ocall_malloc(size_t size, uint8_t **ret) {\n+void unsafe_ocall_malloc(size_t size, uint8_t **ret) {\n   *ret = static_cast<uint8_t *>(malloc(size));\n }\n \ndiff --git a/src/enclave/Enclave/Enclave.cpp b/src/enclave/Enclave/Enclave.cpp\nindex bca6918e47..b78a2645fe 100644\n--- a/src/enclave/Enclave/Enclave.cpp\n+++ b/src/enclave/Enclave/Enclave.cpp\n@@ -10,6 +10,7 @@\n #include \"Project.h\"\n #include \"Sort.h\"\n #include \"isv_enclave.h\"\n+#include \"sgx_lfence.h\"\n #include \"util.h\"\n \n // This file contains definitions of the ecalls declared in Enclave.edl. Errors originating within\n@@ -19,6 +20,11 @@\n \n void ecall_encrypt(uint8_t *plaintext, uint32_t plaintext_length,\n                    uint8_t *ciphertext, uint32_t cipher_length) {\n+  // Guard against encrypting or overwriting enclave memory\n+  assert(sgx_is_outside_enclave(plaintext, plaintext_length) == 1);\n+  assert(sgx_is_outside_enclave(ciphertext, cipher_length) == 1);\n+  sgx_lfence();\n+\n   try {\n     // IV (12 bytes) + ciphertext + mac (16 bytes)\n     assert(cipher_length >= plaintext_length + SGX_AESGCM_IV_SIZE + SGX_AESGCM_MAC_SIZE);\n@@ -33,6 +39,10 @@ void ecall_encrypt(uint8_t *plaintext, uint32_t plaintext_length,\n void ecall_project(uint8_t *condition, size_t condition_length,\n                    uint8_t *input_rows, size_t input_rows_length,\n                    uint8_t **output_rows, size_t *output_rows_length) {\n+  // Guard against operating on arbitrary enclave memory\n+  assert(sgx_is_outside_enclave(input_rows, input_rows_length) == 1);\n+  sgx_lfence();\n+\n   try {\n     project(condition, condition_length,\n             input_rows, input_rows_length,\n@@ -45,6 +55,10 @@ void ecall_project(uint8_t *condition, size_t condition_length,\n void ecall_filter(uint8_t *condition, size_t condition_length,\n                   uint8_t *input_rows, size_t input_rows_length,\n                   uint8_t **output_rows, size_t *output_rows_length) {\n+  // Guard against operating on arbitrary enclave memory\n+  assert(sgx_is_outside_enclave(input_rows, input_rows_length) == 1);\n+  sgx_lfence();\n+\n   try {\n     filter(condition, condition_length,\n            input_rows, input_rows_length,\n@@ -56,6 +70,10 @@ void ecall_filter(uint8_t *condition, size_t condition_length,\n \n void ecall_sample(uint8_t *input_rows, size_t input_rows_length,\n                   uint8_t **output_rows, size_t *output_rows_length) {\n+  // Guard against operating on arbitrary enclave memory\n+  assert(sgx_is_outside_enclave(input_rows, input_rows_length) == 1);\n+  sgx_lfence();\n+\n   try {\n     sample(input_rows, input_rows_length,\n            output_rows, output_rows_length);\n@@ -68,6 +86,10 @@ void ecall_find_range_bounds(uint8_t *sort_order, size_t sort_order_length,\n                              uint32_t num_partitions,\n                              uint8_t *input_rows, size_t input_rows_length,\n                              uint8_t **output_rows, size_t *output_rows_length) {\n+  // Guard against operating on arbitrary enclave memory\n+  assert(sgx_is_outside_enclave(input_rows, input_rows_length) == 1);\n+  sgx_lfence();\n+\n   try {\n     find_range_bounds(sort_order, sort_order_length,\n                       num_partitions,\n@@ -83,6 +105,11 @@ void ecall_partition_for_sort(uint8_t *sort_order, size_t sort_order_length,\n                               uint8_t *input_rows, size_t input_rows_length,\n                               uint8_t *boundary_rows, size_t boundary_rows_length,\n                               uint8_t **output_partitions, size_t *output_partition_lengths) {\n+  // Guard against operating on arbitrary enclave memory\n+  assert(sgx_is_outside_enclave(input_rows, input_rows_length) == 1);\n+  assert(sgx_is_outside_enclave(boundary_rows, boundary_rows_length) == 1);\n+  sgx_lfence();\n+\n   try {\n     partition_for_sort(sort_order, sort_order_length,\n                        num_partitions,\n@@ -97,6 +124,10 @@ void ecall_partition_for_sort(uint8_t *sort_order, size_t sort_order_length,\n void ecall_external_sort(uint8_t *sort_order, size_t sort_order_length,\n                          uint8_t *input_rows, size_t input_rows_length,\n                          uint8_t **output_rows, size_t *output_rows_length) {\n+  // Guard against operating on arbitrary enclave memory\n+  assert(sgx_is_outside_enclave(input_rows, input_rows_length) == 1);\n+  sgx_lfence();\n+\n   try {\n     external_sort(sort_order, sort_order_length,\n                   input_rows, input_rows_length,\n@@ -109,6 +140,10 @@ void ecall_external_sort(uint8_t *sort_order, size_t sort_order_length,\n void ecall_scan_collect_last_primary(uint8_t *join_expr, size_t join_expr_length,\n                                      uint8_t *input_rows, size_t input_rows_length,\n                                      uint8_t **output_rows, size_t *output_rows_length) {\n+  // Guard against operating on arbitrary enclave memory\n+  assert(sgx_is_outside_enclave(input_rows, input_rows_length) == 1);\n+  sgx_lfence();\n+\n   try {\n     scan_collect_last_primary(join_expr, join_expr_length,\n                               input_rows, input_rows_length,\n@@ -122,6 +157,11 @@ void ecall_non_oblivious_sort_merge_join(uint8_t *join_expr, size_t join_expr_le\n                                          uint8_t *input_rows, size_t input_rows_length,\n                                          uint8_t *join_row, size_t join_row_length,\n                                          uint8_t **output_rows, size_t *output_rows_length) {\n+  // Guard against operating on arbitrary enclave memory\n+  assert(sgx_is_outside_enclave(input_rows, input_rows_length) == 1);\n+  assert(sgx_is_outside_enclave(join_row, join_row_length) == 1);\n+  sgx_lfence();\n+\n   try {\n     non_oblivious_sort_merge_join(join_expr, join_expr_length,\n                                   input_rows, input_rows_length,\n@@ -138,6 +178,10 @@ void ecall_non_oblivious_aggregate_step1(\n   uint8_t **first_row, size_t *first_row_length,\n   uint8_t **last_group, size_t *last_group_length,\n   uint8_t **last_row, size_t *last_row_length) {\n+  // Guard against operating on arbitrary enclave memory\n+  assert(sgx_is_outside_enclave(input_rows, input_rows_length) == 1);\n+  sgx_lfence();\n+\n   try {\n     non_oblivious_aggregate_step1(\n       agg_op, agg_op_length,\n@@ -157,6 +201,13 @@ void ecall_non_oblivious_aggregate_step2(\n   uint8_t *prev_partition_last_group, size_t prev_partition_last_group_length,\n   uint8_t *prev_partition_last_row, size_t prev_partition_last_row_length,\n   uint8_t **output_rows, size_t *output_rows_length) {\n+  // Guard against operating on arbitrary enclave memory\n+  assert(sgx_is_outside_enclave(input_rows, input_rows_length) == 1);\n+  assert(sgx_is_outside_enclave(next_partition_first_row, next_partition_first_row_length) == 1);\n+  assert(sgx_is_outside_enclave(prev_partition_last_group, prev_partition_last_group_length) == 1);\n+  assert(sgx_is_outside_enclave(prev_partition_last_row, prev_partition_last_row_length) == 1);\n+  sgx_lfence();\n+\n   try {\n     non_oblivious_aggregate_step2(\n       agg_op, agg_op_length,\ndiff --git a/src/enclave/Enclave/Enclave.edl b/src/enclave/Enclave/Enclave.edl\nindex abd2d7f183..d8acfc796b 100644\n--- a/src/enclave/Enclave/Enclave.edl\n+++ b/src/enclave/Enclave/Enclave.edl\n@@ -88,7 +88,18 @@ enclave {\n \n   untrusted {\n     void ocall_print_string([in, string] const char *str);\n-    void ocall_malloc(size_t size, [out] uint8_t **ret);\n+\n+    /**\n+     * Allocate memory outside of the enclave and return the pointer in `ret`.\n+     *\n+     * Before dereferencing the resulting pointer, the caller must check whether it is actually\n+     * outside the enclave using `sgx_is_outside_enclave()`. Otherwise, an attacker could cause the\n+     * enclave to perform unexpected operations on its own memory. The function `ocall_malloc()`\n+     * wraps this function with such a bounds check and most callers should use that function\n+     * instead.\n+     */\n+    void unsafe_ocall_malloc(size_t size, [out] uint8_t **ret);\n+\n     void ocall_free([user_check] uint8_t *buf);\n     void ocall_exit(int exit_code);\n     void ocall_throw([in, string] const char *message);\ndiff --git a/src/enclave/Enclave/util.cpp b/src/enclave/Enclave/util.cpp\nindex 3f514e9d32..ed86392873 100644\n--- a/src/enclave/Enclave/util.cpp\n+++ b/src/enclave/Enclave/util.cpp\n@@ -4,6 +4,7 @@\n #include <cstdio>\n \n #include \"Enclave_t.h\"\n+#include \"sgx_lfence.h\"\n \n int printf(const char *fmt, ...) {\n   char buf[BUFSIZ] = {'\\0'};\n@@ -38,6 +39,14 @@ void exit(int exit_code) {\n   ocall_exit(exit_code);\n }\n \n+void ocall_malloc(size_t size, uint8_t **ret) {\n+  unsafe_ocall_malloc(size, ret);\n+\n+  // Guard against overwriting enclave memory\n+  assert(sgx_is_outside_enclave(*ret, size) == 1);\n+  sgx_lfence();\n+}\n+\n void print_bytes(uint8_t *ptr, uint32_t len) {\n   for (uint32_t i = 0; i < len; i++) {\n     printf(\"%u\", *(ptr + i));\ndiff --git a/src/enclave/Enclave/util.h b/src/enclave/Enclave/util.h\nindex 22bf0f4371..b4e0b52327 100644\n--- a/src/enclave/Enclave/util.h\n+++ b/src/enclave/Enclave/util.h\n@@ -18,6 +18,14 @@ namespace std {\n     using ::exit;\n }\n \n+/**\n+ * Allocate memory outside of the enclave and return the pointer in `ret`.\n+ *\n+ * This is a checked wrapper around `unsafe_ocall_malloc`. The resulting pointer is safe to write\n+ * to.\n+ */\n+void ocall_malloc(size_t size, uint8_t **ret);\n+\n std::string string_format(const std::string &fmt, ...);\n \n void print_bytes(uint8_t *ptr, uint32_t len);\n",
        "label": 0,
        "partition": "train"
    },
    {
        "commit_id": "a28053045bd2e778c50ed1acaf4e52e1e34f6e34",
        "repo": "univention/univention-corporate-server",
        "msg": "Bug #48427 UDN: Forbid vulnerable GET_DN for VERSION >= 3\n\nUDL using PROTOCOL_3 must no longer use GET_DN but WAIT_DN - if it is\nstill used this is a protocol violation. UDL simply will not get an\nanswer.\n\nWhen UCRV 'notifier/protocol/version is set to 3, any old client still\nusing PROTOCOL_2 will get rejected while negotiating the protocol\nversion, so it is asserted that \"version >= network_procotol_version\".Univention Corporate Server univention-directory-notifier 12.0.1-3 and earlier is affected by: CWE-213: Intentional Information Exposure. The impact is: Loss of Confidentiality. The component is: function data_on_connection() in src/callback.c. The attack vector is: network connectivity. The fixed version is: 12.0.1-4 and later.",
        "filename": "None",
        "diff": "diff --git a/management/univention-directory-notifier/debian/changelog b/management/univention-directory-notifier/debian/changelog\nindex 80faf0fff8b..963a9b34b41 100644\n--- a/management/univention-directory-notifier/debian/changelog\n+++ b/management/univention-directory-notifier/debian/changelog\n@@ -1,3 +1,9 @@\n+univention-directory-notifier (12.0.1-11) unstable; urgency=low\n+\n+  * Bug #48427: Forbid vulnerable GET_DN for VERSION >= 3\n+\n+ -- Philipp Hahn <hahn@univention.de>  Wed, 13 Feb 2019 10:23:12 +0100\n+\n univention-directory-notifier (12.0.1-10) unstable; urgency=low\n \n   * Bug #48427: Change import limits\ndiff --git a/management/univention-directory-notifier/src/callback.c b/management/univention-directory-notifier/src/callback.c\nindex 151e50e7ce6..9c6e80401a9 100644\n--- a/management/univention-directory-notifier/src/callback.c\n+++ b/management/univention-directory-notifier/src/callback.c\n@@ -199,7 +199,7 @@ int data_on_connection(int fd, callback_remove_handler remove)\n \t\t\tp+=strlen(network_line);\n \n \n-\t\t} else if ( !strncmp(network_line, \"GET_DN \", strlen(\"GET_DN \")) && msg_id != UINT32_MAX && network_client_get_version(fd) > 0) {\n+\t\t} else if ( !strncmp(network_line, \"GET_DN \", strlen(\"GET_DN \")) && msg_id != UINT32_MAX && version > PROTOCOL_UNKNOWN && version < PROTOCOL_3) {\n \n \t\t\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_ALL, \"RECV: GET_DN\");\n \n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "48fbf6a88d4822a1e5470cf08f29464511bd72c1",
        "repo": "SerenityOS/serenity",
        "msg": "LibCrypto: Don't copy the prime test candidates\n\nThis was copying a bunch of bigints for no reason.SerenityOS Unspecified is affected by: Buffer Overflow. The impact is: obtain sensitive information (context-dependent). The component is: /Userland/Libraries/LibCrypto/ASN1/DER.h Crypto::der_decode_sequence() function. The attack vector is: Parsing RSA Key ASN.1.",
        "filename": "None",
        "diff": "diff --git a/Userland/Libraries/LibCrypto/NumberTheory/ModularFunctions.cpp b/Userland/Libraries/LibCrypto/NumberTheory/ModularFunctions.cpp\nindex 2bc7445701d7b4..ecccd2c60e8847 100644\n--- a/Userland/Libraries/LibCrypto/NumberTheory/ModularFunctions.cpp\n+++ b/Userland/Libraries/LibCrypto/NumberTheory/ModularFunctions.cpp\n@@ -258,7 +258,7 @@ static bool MR_primality_test(UnsignedBigInteger n, const Vector<UnsignedBigInte\n         return n == 2;\n     }\n \n-    for (auto a : tests) {\n+    for (auto& a : tests) {\n         // Technically: ASSERT(2 <= a && a <= n - 2)\n         ASSERT(a < n);\n         auto x = ModularPower(a, d, n);\n",
        "label": 1,
        "partition": "train"
    },
    {
        "commit_id": "c9f25bca048443e317f1994ba9b106f2386688c3",
        "repo": "SerenityOS/serenity",
        "msg": "LibTextCodec: Make UTF16BEDecoder read only up to an even offset\n\nReading up to the end of the input string of odd length results in\nan out-of-bounds readSerenityOS fixed as of c9f25bca048443e317f1994ba9b106f2386688c3 contains a buffer overflow vulnerability in LibTextCode through opening a crafted file.",
        "filename": "None",
        "diff": "diff --git a/Userland/Libraries/LibTextCodec/Decoder.cpp b/Userland/Libraries/LibTextCodec/Decoder.cpp\nindex 26fced65244cc0..b075a818704727 100644\n--- a/Userland/Libraries/LibTextCodec/Decoder.cpp\n+++ b/Userland/Libraries/LibTextCodec/Decoder.cpp\n@@ -183,7 +183,8 @@ String UTF8Decoder::to_utf8(const StringView& input)\n String UTF16BEDecoder::to_utf8(const StringView& input)\n {\n     StringBuilder builder(input.length() / 2);\n-    for (size_t i = 0; i < input.length(); i += 2) {\n+    size_t utf16_length = input.length() - (input.length() % 2);\n+    for (size_t i = 0; i < utf16_length; i += 2) {\n         u16 code_point = (input[i] << 8) | input[i + 1];\n         builder.append_code_point(code_point);\n     }\n",
        "label": 0,
        "partition": "test"
    },
    {
        "commit_id": "4317db7498eaa5a37068052bb0310fbc6a5f78e4",
        "repo": "SerenityOS/serenity",
        "msg": "LibArchive: Make bounds checks stricter in the Zip parser\n\nWe now also check we have enough space in the incoming buffer for the\nvarious signatures and optional (length specified) fields. This helps\nprevents a possible heap overflow read.SerenityOS 2021-03-27 contains a buffer overflow vulnerability in the EndOfCentralDirectory::read() function.",
        "filename": "None",
        "diff": "diff --git a/Userland/Libraries/LibArchive/Zip.h b/Userland/Libraries/LibArchive/Zip.h\nindex ac835b8bfae64b..66a25acf726ef8 100644\n--- a/Userland/Libraries/LibArchive/Zip.h\n+++ b/Userland/Libraries/LibArchive/Zip.h\n@@ -52,11 +52,13 @@ struct [[gnu::packed]] EndOfCentralDirectory {\n     bool read(ReadonlyBytes buffer)\n     {\n         auto fields_size = sizeof(EndOfCentralDirectory) - sizeof(u8*);\n-        if (buffer.size() < fields_size)\n+        if (buffer.size() < sizeof(end_of_central_directory_signature) + fields_size)\n             return false;\n         if (memcmp(buffer.data(), end_of_central_directory_signature, sizeof(end_of_central_directory_signature)) != 0)\n             return false;\n         memcpy(reinterpret_cast<void*>(&disk_number), buffer.data() + sizeof(end_of_central_directory_signature), fields_size);\n+        if (buffer.size() < sizeof(end_of_central_directory_signature) + fields_size + comment_length)\n+            return false;\n         comment = buffer.data() + sizeof(end_of_central_directory_signature) + fields_size;\n         return true;\n     }\n@@ -101,11 +103,13 @@ struct [[gnu::packed]] CentralDirectoryRecord {\n     bool read(ReadonlyBytes buffer)\n     {\n         auto fields_size = sizeof(CentralDirectoryRecord) - (sizeof(u8*) * 3);\n-        if (buffer.size() < fields_size)\n+        if (buffer.size() < sizeof(central_directory_record_signature) + fields_size)\n             return false;\n         if (memcmp(buffer.data(), central_directory_record_signature, sizeof(central_directory_record_signature)) != 0)\n             return false;\n         memcpy(reinterpret_cast<void*>(&made_by_version), buffer.data() + sizeof(central_directory_record_signature), fields_size);\n+        if (buffer.size() < sizeof(end_of_central_directory_signature) + fields_size + comment_length + name_length + extra_data_length)\n+            return false;\n         name = buffer.data() + sizeof(central_directory_record_signature) + fields_size;\n         extra_data = name + name_length;\n         comment = extra_data + extra_data_length;\n@@ -165,11 +169,13 @@ struct [[gnu::packed]] LocalFileHeader {\n     bool read(ReadonlyBytes buffer)\n     {\n         auto fields_size = sizeof(LocalFileHeader) - (sizeof(u8*) * 3);\n-        if (buffer.size() < fields_size)\n+        if (buffer.size() < sizeof(local_file_header_signature) + fields_size)\n             return false;\n         if (memcmp(buffer.data(), local_file_header_signature, sizeof(local_file_header_signature)) != 0)\n             return false;\n         memcpy(reinterpret_cast<void*>(&minimum_version), buffer.data() + sizeof(local_file_header_signature), fields_size);\n+        if (buffer.size() < sizeof(end_of_central_directory_signature) + fields_size + name_length + extra_data_length + compressed_size)\n+            return false;\n         name = buffer.data() + sizeof(local_file_header_signature) + fields_size;\n         extra_data = name + name_length;\n         compressed_data = extra_data + extra_data_length;\n",
        "label": 1,
        "partition": "test"
    },
    {
        "commit_id": "4317db7498eaa5a37068052bb0310fbc6a5f78e4",
        "repo": "SerenityOS/serenity",
        "msg": "LibArchive: Make bounds checks stricter in the Zip parser\n\nWe now also check we have enough space in the incoming buffer for the\nvarious signatures and optional (length specified) fields. This helps\nprevents a possible heap overflow read.SerenityOS 2021-03-27 contains a buffer overflow vulnerability in the EndOfCentralDirectory::read() function.",
        "filename": "None",
        "diff": "diff --git a/Userland/Libraries/LibArchive/Zip.h b/Userland/Libraries/LibArchive/Zip.h\nindex ac835b8bfae64b..66a25acf726ef8 100644\n--- a/Userland/Libraries/LibArchive/Zip.h\n+++ b/Userland/Libraries/LibArchive/Zip.h\n@@ -52,11 +52,13 @@ struct [[gnu::packed]] EndOfCentralDirectory {\n     bool read(ReadonlyBytes buffer)\n     {\n         auto fields_size = sizeof(EndOfCentralDirectory) - sizeof(u8*);\n-        if (buffer.size() < fields_size)\n+        if (buffer.size() < sizeof(end_of_central_directory_signature) + fields_size)\n             return false;\n         if (memcmp(buffer.data(), end_of_central_directory_signature, sizeof(end_of_central_directory_signature)) != 0)\n             return false;\n         memcpy(reinterpret_cast<void*>(&disk_number), buffer.data() + sizeof(end_of_central_directory_signature), fields_size);\n+        if (buffer.size() < sizeof(end_of_central_directory_signature) + fields_size + comment_length)\n+            return false;\n         comment = buffer.data() + sizeof(end_of_central_directory_signature) + fields_size;\n         return true;\n     }\n@@ -101,11 +103,13 @@ struct [[gnu::packed]] CentralDirectoryRecord {\n     bool read(ReadonlyBytes buffer)\n     {\n         auto fields_size = sizeof(CentralDirectoryRecord) - (sizeof(u8*) * 3);\n-        if (buffer.size() < fields_size)\n+        if (buffer.size() < sizeof(central_directory_record_signature) + fields_size)\n             return false;\n         if (memcmp(buffer.data(), central_directory_record_signature, sizeof(central_directory_record_signature)) != 0)\n             return false;\n         memcpy(reinterpret_cast<void*>(&made_by_version), buffer.data() + sizeof(central_directory_record_signature), fields_size);\n+        if (buffer.size() < sizeof(end_of_central_directory_signature) + fields_size + comment_length + name_length + extra_data_length)\n+            return false;\n         name = buffer.data() + sizeof(central_directory_record_signature) + fields_size;\n         extra_data = name + name_length;\n         comment = extra_data + extra_data_length;\n@@ -165,11 +169,13 @@ struct [[gnu::packed]] LocalFileHeader {\n     bool read(ReadonlyBytes buffer)\n     {\n         auto fields_size = sizeof(LocalFileHeader) - (sizeof(u8*) * 3);\n-        if (buffer.size() < fields_size)\n+        if (buffer.size() < sizeof(local_file_header_signature) + fields_size)\n             return false;\n         if (memcmp(buffer.data(), local_file_header_signature, sizeof(local_file_header_signature)) != 0)\n             return false;\n         memcpy(reinterpret_cast<void*>(&minimum_version), buffer.data() + sizeof(local_file_header_signature), fields_size);\n+        if (buffer.size() < sizeof(end_of_central_directory_signature) + fields_size + name_length + extra_data_length + compressed_size)\n+            return false;\n         name = buffer.data() + sizeof(local_file_header_signature) + fields_size;\n         extra_data = name + name_length;\n         compressed_data = extra_data + extra_data_length;\n",
        "label": 1,
        "partition": "test"
    },
    {
        "commit_id": "4317db7498eaa5a37068052bb0310fbc6a5f78e4",
        "repo": "SerenityOS/serenity",
        "msg": "LibArchive: Make bounds checks stricter in the Zip parser\n\nWe now also check we have enough space in the incoming buffer for the\nvarious signatures and optional (length specified) fields. This helps\nprevents a possible heap overflow read.SerenityOS 2021-03-27 contains a buffer overflow vulnerability in the EndOfCentralDirectory::read() function.",
        "filename": "None",
        "diff": "diff --git a/Userland/Libraries/LibArchive/Zip.h b/Userland/Libraries/LibArchive/Zip.h\nindex ac835b8bfae64b..66a25acf726ef8 100644\n--- a/Userland/Libraries/LibArchive/Zip.h\n+++ b/Userland/Libraries/LibArchive/Zip.h\n@@ -52,11 +52,13 @@ struct [[gnu::packed]] EndOfCentralDirectory {\n     bool read(ReadonlyBytes buffer)\n     {\n         auto fields_size = sizeof(EndOfCentralDirectory) - sizeof(u8*);\n-        if (buffer.size() < fields_size)\n+        if (buffer.size() < sizeof(end_of_central_directory_signature) + fields_size)\n             return false;\n         if (memcmp(buffer.data(), end_of_central_directory_signature, sizeof(end_of_central_directory_signature)) != 0)\n             return false;\n         memcpy(reinterpret_cast<void*>(&disk_number), buffer.data() + sizeof(end_of_central_directory_signature), fields_size);\n+        if (buffer.size() < sizeof(end_of_central_directory_signature) + fields_size + comment_length)\n+            return false;\n         comment = buffer.data() + sizeof(end_of_central_directory_signature) + fields_size;\n         return true;\n     }\n@@ -101,11 +103,13 @@ struct [[gnu::packed]] CentralDirectoryRecord {\n     bool read(ReadonlyBytes buffer)\n     {\n         auto fields_size = sizeof(CentralDirectoryRecord) - (sizeof(u8*) * 3);\n-        if (buffer.size() < fields_size)\n+        if (buffer.size() < sizeof(central_directory_record_signature) + fields_size)\n             return false;\n         if (memcmp(buffer.data(), central_directory_record_signature, sizeof(central_directory_record_signature)) != 0)\n             return false;\n         memcpy(reinterpret_cast<void*>(&made_by_version), buffer.data() + sizeof(central_directory_record_signature), fields_size);\n+        if (buffer.size() < sizeof(end_of_central_directory_signature) + fields_size + comment_length + name_length + extra_data_length)\n+            return false;\n         name = buffer.data() + sizeof(central_directory_record_signature) + fields_size;\n         extra_data = name + name_length;\n         comment = extra_data + extra_data_length;\n@@ -165,11 +169,13 @@ struct [[gnu::packed]] LocalFileHeader {\n     bool read(ReadonlyBytes buffer)\n     {\n         auto fields_size = sizeof(LocalFileHeader) - (sizeof(u8*) * 3);\n-        if (buffer.size() < fields_size)\n+        if (buffer.size() < sizeof(local_file_header_signature) + fields_size)\n             return false;\n         if (memcmp(buffer.data(), local_file_header_signature, sizeof(local_file_header_signature)) != 0)\n             return false;\n         memcpy(reinterpret_cast<void*>(&minimum_version), buffer.data() + sizeof(local_file_header_signature), fields_size);\n+        if (buffer.size() < sizeof(end_of_central_directory_signature) + fields_size + name_length + extra_data_length + compressed_size)\n+            return false;\n         name = buffer.data() + sizeof(local_file_header_signature) + fields_size;\n         extra_data = name + name_length;\n         compressed_data = extra_data + extra_data_length;\n",
        "label": 1,
        "partition": "test"
    },
    {
        "commit_id": "4647a68e364401e81dbd370728127d844f221d93",
        "repo": "mjurczak/mbed-coap",
        "msg": "Implemented measures to prevent memory leaks in sn_coap_parser_options_parse().\n\nAdded a helper uint16_t addition function with overflow detection. The function is used when calculating the extended length and option delta. The overlow detection is needed to avoid wrap-around of option number or length.\nAdditional checks in options using sn_coap_parser_options_parse_multiple_options() have been implemented to avoid overwriting of pointers pointing to previously allocated memory.Memory leaks were discovered in the CoAP library in Arm Mbed OS 5.15.3 when using the Arm mbed-coap library 5.1.5. The CoAP parser is responsible for parsing received CoAP packets. The function sn_coap_parser_options_parse() parses the CoAP option number field of all options present in the input packet. Each option number is calculated as a sum of the previous option number and a delta of the current option. The delta and the previous option number are expressed as unsigned 16-bit integers. Due to lack of overflow detection, it is possible to craft a packet that wraps the option number around and results in the same option number being processed again in a single packet. Certain options allocate memory by calling a memory allocation function. In the cases of COAP_OPTION_URI_QUERY, COAP_OPTION_URI_PATH, COAP_OPTION_LOCATION_QUERY, and COAP_OPTION_ETAG, there is no check on whether memory has already been allocated, which in conjunction with the option number integer overflow may lead to multiple assignments of allocated memory to a single pointer. This has been demonstrated to lead to memory leak by buffer orphaning. As a result, the memory is never freed.",
        "filename": "None",
        "diff": "diff --git a/source/sn_coap_parser.c b/source/sn_coap_parser.c\nindex d222de4e..a2577cd8 100644\n--- a/source/sn_coap_parser.c\n+++ b/source/sn_coap_parser.c\n@@ -260,6 +260,29 @@ static uint32_t sn_coap_parser_options_parse_uint(uint8_t **packet_data_pptr, ui\n     return value;\n }\n \n+/**\n+ * \\brief Add u16 integers with overflow detection\n+ *\n+ * \\param a            first term of addition\n+ * \\param b            second term of addion\n+ * \\param result       pointer to the result variable\n+ *\n+ * \\return Return 0 if there was no overflow, -1 otherwise\n+ */\n+static int8_t sn_coap_parser_add_u16_limit(uint16_t a, uint16_t b, uint16_t *result)\n+{\n+    uint16_t c;\n+\n+    c = a + b;\n+    if (c < a || c < b)\n+    {\n+        return -1;\n+    }\n+\n+    *result = c;\n+\n+    return 0;\n+}\n \n /**\n  * \\brief Performs data packet pointer boundary check\n@@ -397,11 +420,15 @@ static int8_t parse_ext_option(uint16_t *dst, uint8_t **packet_data_pptr, uint8_\n             return -1;\n         }\n         else {\n-                option_number += option_ext;\n-                *message_left = sn_coap_parser_move_packet_ptr(packet_data_pptr,\n-                                                               packet_data_start_ptr,\n-                                                               packet_len,\n-                                                               1);\n+            if(sn_coap_parser_add_u16_limit(option_number, option_ext, &option_number) != 0)\n+            {\n+                return -1;\n+            }\n+\n+            *message_left = sn_coap_parser_move_packet_ptr(packet_data_pptr,\n+                                                            packet_data_start_ptr,\n+                                                            packet_len,\n+                                                            1);\n         }\n     } else if (option_number == 14) {\n             int8_t read_result = sn_coap_parser_read_packet_u16(&option_number,\n@@ -414,11 +441,15 @@ static int8_t parse_ext_option(uint16_t *dst, uint8_t **packet_data_pptr, uint8_\n                 return -1;\n             }\n             else {\n-            option_number += 269;\n-            *message_left = sn_coap_parser_move_packet_ptr(packet_data_pptr,\n-                                                           packet_data_start_ptr,\n-                                                           packet_len,\n-                                                           2);\n+                if(sn_coap_parser_add_u16_limit(option_number, 269, &option_number) != 0)\n+                {\n+                    return -1;\n+                }\n+\n+                *message_left = sn_coap_parser_move_packet_ptr(packet_data_pptr,\n+                                                            packet_data_start_ptr,\n+                                                            packet_len,\n+                                                            2);\n             }\n     }\n     /* Option number 15 reserved for payload marker. This is handled as a error! */\n@@ -499,7 +530,10 @@ static int8_t sn_coap_parser_options_parse(struct coap_s *handle, uint8_t **pack\n             return -1;\n         }\n         /* Add previous option to option delta and get option number */\n-        option_number += previous_option_number;\n+        if(sn_coap_parser_add_u16_limit(option_number, previous_option_number, &option_number) != 0)\n+        {\n+            return -1;\n+        }\n \n         /* Add possible option length extension to resolve full length of the option */\n         option_parse_result = parse_ext_option(&option_len,\n@@ -577,6 +611,11 @@ static int8_t sn_coap_parser_options_parse(struct coap_s *handle, uint8_t **pack\n                 break;\n \n             case COAP_OPTION_ETAG:\n+                if (dst_coap_msg_ptr->options_list_ptr->etag_ptr)\n+                {\n+                    tr_error(\"sn_coap_parser_options_parse - COAP_OPTION_ETAG exists!\");\n+                    return -1;\n+                }\n                 /* This is managed independently because User gives this option in one character table */\n                 ret_status = sn_coap_parser_options_parse_multiple_options(handle, packet_data_pptr,\n                              message_left,\n@@ -628,6 +667,11 @@ static int8_t sn_coap_parser_options_parse(struct coap_s *handle, uint8_t **pack\n                 break;\n \n             case COAP_OPTION_LOCATION_QUERY:\n+                if (dst_coap_msg_ptr->options_list_ptr->location_query_ptr)\n+                {\n+                    tr_error(\"sn_coap_parser_options_parse - COAP_OPTION_LOCATION_QUERY exists!\");\n+                    return -1;\n+                }\n                 ret_status = sn_coap_parser_options_parse_multiple_options(handle, packet_data_pptr, message_left,\n                              &dst_coap_msg_ptr->options_list_ptr->location_query_ptr, &dst_coap_msg_ptr->options_list_ptr->location_query_len,\n                              COAP_OPTION_LOCATION_QUERY, option_len);\n@@ -639,6 +683,11 @@ static int8_t sn_coap_parser_options_parse(struct coap_s *handle, uint8_t **pack\n                 break;\n \n             case COAP_OPTION_URI_PATH:\n+                if (dst_coap_msg_ptr->uri_path_ptr)\n+                {\n+                    tr_error(\"sn_coap_parser_options_parse - COAP_OPTION_URI_PATH exists!\");\n+                    return -1;\n+                }\n                 ret_status = sn_coap_parser_options_parse_multiple_options(handle, packet_data_pptr, message_left,\n                              &dst_coap_msg_ptr->uri_path_ptr, &dst_coap_msg_ptr->uri_path_len,\n                              COAP_OPTION_URI_PATH, option_len);\n",
        "label": 0,
        "partition": "test"
    },
    {
        "commit_id": "b265455a2518ece7c004b43c144199ec980fc620",
        "repo": "openbmc/phosphor-host-ipmid",
        "msg": "Use more restrictive permissions on /etc/ipmi-pass\n\nThis forces the permissions on /etc/ipmi-pass to be 0600 or RW only by\nowner. This is to prevent non-owners from reading the file, even though\nit is obfuscated to make it harder for ipmi passwords to leak.\n\nTested: change ipmi passwords and see that the /etc/ipmi-pass file has\n        0600 permissions.\n\nChange-Id: I4be0b8a65f98ced031493f7767879eb054e1ee84\nSigned-off-by: Vernon Mauery <vernon.mauery@linux.intel.com>user_channel/passwd_mgr.cpp in OpenBMC phosphor-host-ipmid before 2020-04-03 does not ensure that /etc/ipmi-pass has strong file permissions.",
        "filename": "None",
        "diff": "diff --git a/user_channel/passwd_mgr.cpp b/user_channel/passwd_mgr.cpp\nindex 66bdef0d8..5e0b30da6 100644\n--- a/user_channel/passwd_mgr.cpp\n+++ b/user_channel/passwd_mgr.cpp\n@@ -444,8 +444,8 @@ int PasswdMgr::updatePasswdSpecialFile(const std::string& userName,\n         return -EIO;\n     }\n \n-    // Set the file mode as of actual ipmi-pass file.\n-    if (fchmod(fileno((temp)()), st.st_mode) < 0)\n+    // Set the file mode as read-write for owner only\n+    if (fchmod(fileno((temp)()), S_IRUSR | S_IWUSR) < 0)\n     {\n         log<level::DEBUG>(\"Error setting fchmod for temp file\");\n         return -EIO;\n",
        "label": 1,
        "partition": "test"
    },
    {
        "commit_id": "49a4cee2feef7deaf9d89e5e793a8824930284d7",
        "repo": "ilanschnell/bsdiff4",
        "msg": "apply patch from Robert Scott to fix - shifting some bounds checkingA buffer overflow in the patching routine of bsdiff4 before 1.2.0 allows an attacker to write to heap memory (beyond allocated bounds) via a crafted patch file.",
        "filename": "None",
        "diff": "diff --git a/bsdiff4/core.c b/bsdiff4/core.c\nindex 91be7f8..11b6806 100644\n--- a/bsdiff4/core.c\n+++ b/bsdiff4/core.c\n@@ -431,8 +431,7 @@ static PyObject* patch(PyObject* self, PyObject* args)\n         y = PyLong_AsLong(PyTuple_GET_ITEM(tuple, 1));\n         z = PyLong_AsLong(PyTuple_GET_ITEM(tuple, 2));\n         if (newpos + x > newDataLength ||\n-                diffPtr + x > diffBlock + diffBlockLength ||\n-                extraPtr + y > extraBlock + extraBlockLength) {\n+                diffPtr + x > diffBlock + diffBlockLength) {\n             PyMem_Free(newData);\n             PyErr_SetString(PyExc_ValueError, \"corrupt patch (overflow)\");\n             return NULL;\n@@ -444,6 +443,12 @@ static PyObject* patch(PyObject* self, PyObject* args)\n                 newData[newpos + j] += origData[oldpos + j];\n         newpos += x;\n         oldpos += x;\n+        if (newpos + y > newDataLength ||\n+                extraPtr + y > extraBlock + extraBlockLength) {\n+            PyMem_Free(newData);\n+            PyErr_SetString(PyExc_ValueError, \"corrupt patch (overflow)\");\n+            return NULL;\n+        }\n         memcpy(newData + newpos, extraPtr, y);\n         extraPtr += y;\n         newpos += y;\n",
        "label": 0,
        "partition": "test"
    },
    {
        "commit_id": "803969389ca9c06237075a7f8eeb1a19e6651759",
        "repo": "trgil/gilcc",
        "msg": "Fix parser tmp-buffer overflow issueBuffer overflow vulnerability in function src_parser_trans_stage_1_2_3 trgil gilcc before commit 803969389ca9c06237075a7f8eeb1a19e6651759, allows attackers to cause a denial of service.",
        "filename": "None",
        "diff": "diff --git a/src/src_parser.c b/src/src_parser.c\nindex 321c336..262ae5d 100644\n--- a/src/src_parser.c\n+++ b/src/src_parser.c\n@@ -171,7 +171,7 @@ static int src_parser_trans_stage_1_2_3(const int tmp_fd, const char *src, const\n                             (PBUF_TMP_PREV_CHAR(pbuf) == ' ' || PBUF_TMP_PREV_CHAR(pbuf) == '\\t' ||\n                              PBUF_TMP_PREV_CHAR(pbuf) == '\\n')) {\n                         pbuf.f_indx++;\n-                    } else if (pbuf.tmp_indx && \n+                    } else if (pbuf.tmp_indx &&\n                             (PBUF_TMP_PREV_CHAR(pbuf) == '\\\\')) {\n                         pbuf.tmp_indx--;\n                         pbuf.f_indx++;\n@@ -182,10 +182,12 @@ static int src_parser_trans_stage_1_2_3(const int tmp_fd, const char *src, const\n                     continue;\n \n                 case '\\\\':\n+                    p_buf_write_tmp(&pbuf, tmp_fd);\n                     p_buf_push_tmp_char(&pbuf, '\\\\');\n                     continue;\n \n                 case '/':\n+                    p_buf_write_tmp(&pbuf, tmp_fd);\n                     p_buf_push_tmp_char(&pbuf, '/');\n                     continue;\n \n",
        "label": 1,
        "partition": "test"
    },
    {
        "commit_id": "8a513cec4bec15961fbfdedcaa5376522980455c",
        "repo": "tensorflow/tensorflow",
        "msg": "Prevent null dereference read in `SpecializeType()`\n\nFor some adversarial protos, the attribute for a key might not exist.\n\nPiperOrigin-RevId: 408382090\nChange-Id: Ie7eabe532c9ff280fce5dce1f6cdb93c76c2e040Tensorflow is an Open Source Machine Learning Framework. When decoding a tensor from protobuf, TensorFlow might do a null-dereference if attributes of some mutable arguments to some operations are missing from the proto. This is guarded by a `DCHECK`. However, `DCHECK` is a no-op in production builds and an assertion failure in debug builds. In the first case execution proceeds to the dereferencing of the null pointer, whereas in the second case it results in a crash due to the assertion failure. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, and TensorFlow 2.6.3, as these are also affected and still in supported range.",
        "filename": "full_type_util.cc",
        "diff": "diff --git a/tensorflow/core/framework/full_type_util.cc b/tensorflow/core/framework/full_type_util.cc\nindex 5d2b33c3099341..e0d8ca0721c850 100644\n--- a/tensorflow/core/framework/full_type_util.cc\n+++ b/tensorflow/core/framework/full_type_util.cc\n@@ -22,6 +22,7 @@ limitations under the License.\n #include \"tensorflow/core/framework/op_def.pb.h\"\n #include \"tensorflow/core/framework/types.h\"\n #include \"tensorflow/core/platform/statusor.h\"\n+#include \"tensorflow/core/protobuf/error_codes.pb.h\"\n \n namespace tensorflow {\n \n@@ -102,7 +103,11 @@ StatusOr<FullTypeDef> SpecializeType(const AttrSlice& attrs,\n       auto* arg = t->mutable_args(i);\n       if (arg->type_id() == TFT_VAR) {\n         const auto* attr = attrs.Find(arg->s());\n-        DCHECK(attr != nullptr);\n+        if (attr == nullptr) {\n+          return Status(\n+              error::INVALID_ARGUMENT,\n+              absl::StrCat(\"Could not find an attribute for key \", arg->s()));\n+        }\n         if (attr->value_case() == AttrValue::kList) {\n           const auto& attr_list = attr->list();\n           arg->set_type_id(TFT_PRODUCT);\n",
        "label": 1,
        "partition": "test"
    },
    {
        "commit_id": "f1ae01d745200a258cdf62622f71754c37cb6c30",
        "repo": "gpac/gpac",
        "msg": "fixed #1900A buffer overflow vulnerability exists in Gpac through 1.0.1 via a malformed MP4 file in the svc_parse_slice function in av_parsers.c, which allows attackers to cause a denial of service, even code execution and escalation of privileges.",
        "filename": "av_parsers.c",
        "diff": "diff --git a/src/media_tools/av_parsers.c b/src/media_tools/av_parsers.c\nindex 2a819da12c..96d2797420 100644\n--- a/src/media_tools/av_parsers.c\n+++ b/src/media_tools/av_parsers.c\n@@ -4690,20 +4690,23 @@ u32 gf_bs_read_ue_log_idx3(GF_BitStream *bs, const char *fname, s32 idx1, s32 id\n \tu32 bits = 0;\n \tfor (code=0; !code; nb_lead++) {\n \t\tif (nb_lead>=32) {\n-\t\t\t//gf_bs_read_int keeps returning 0 on EOS, so if no more bits available, rbsp was truncated otherwise code is broken in rbsp)\n-\t\t\t//we only test once nb_lead>=32 to avoid testing at each bit read\n-\t\t\tif (!gf_bs_available(bs)) {\n-\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CODING, (\"[Core] exp-golomb read failed, not enough bits in bitstream !\\n\"));\n-\t\t\t} else {\n-\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CODING, (\"[Core] corrupted exp-golomb code, %d leading zeros, max 31 allowed !\\n\", nb_lead));\n-\t\t\t}\n-\t\t\treturn 0;\n+\t\t\tbreak;\n \t\t}\n-\n \t\tcode = gf_bs_read_int(bs, 1);\n \t\tbits++;\n \t}\n \n+\tif (nb_lead>=32) {\n+\t\t//gf_bs_read_int keeps returning 0 on EOS, so if no more bits available, rbsp was truncated otherwise code is broken in rbsp)\n+\t\t//we only test once nb_lead>=32 to avoid testing at each bit read\n+\t\tif (!gf_bs_available(bs)) {\n+\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CODING, (\"[Core] exp-golomb read failed, not enough bits in bitstream !\\n\"));\n+\t\t} else {\n+\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CODING, (\"[Core] corrupted exp-golomb code, %d leading zeros, max 31 allowed !\\n\", nb_lead));\n+\t\t}\n+\t\treturn 0;\n+\t}\n+\n \tif (nb_lead) {\n \t\tu32 leads=1;\n \t\tval = gf_bs_read_int(bs, nb_lead);\n@@ -5785,7 +5788,7 @@ static s32 svc_parse_slice(GF_BitStream *bs, AVCState *avc, AVCSliceInfo *si)\n \tif (si->slice_type > 9) return -1;\n \n \tpps_id = gf_bs_read_ue_log(bs, \"pps_id\");\n-\tif (pps_id > 255)\n+\tif ((pps_id<0) || (pps_id > 255))\n \t\treturn -1;\n \tsi->pps = &avc->pps[pps_id];\n \tsi->pps->id = pps_id;\n",
        "label": 1,
        "partition": "test"
    },
    {
        "commit_id": "e746adbfcfee15e9cfdb391ff746c765b99bdf9b",
        "repo": "tensorflow/tensorflow",
        "msg": "Prevent use after free in `DecodePng` kernel.\n\nWe are cleaning up the memory in `decode` and then we are using an `OP_REQUIRES` to check an invariant on the `decode` data.\n\nPiperOrigin-RevId: 409299145\nChange-Id: I4eb93aaca52483eb202e89b78df07fbb2f6cb254Tensorflow is an Open Source Machine Learning Framework. A malicious user can cause a use after free behavior when decoding PNG images. After `png::CommonFreeDecode(&decode)` gets called, the values of `decode.width` and `decode.height` are in an unspecified state. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "filename": "decode_image_op.cc",
        "diff": "diff --git a/tensorflow/core/kernels/image/decode_image_op.cc b/tensorflow/core/kernels/image/decode_image_op.cc\nindex 4573b4db0f46ca..a0345b7e0b79b0 100644\n--- a/tensorflow/core/kernels/image/decode_image_op.cc\n+++ b/tensorflow/core/kernels/image/decode_image_op.cc\n@@ -339,7 +339,6 @@ class DecodeImageV2Op : public OpKernel {\n     if (width != static_cast<int64_t>(decode.width) || width <= 0 ||\n         width >= (1LL << 27) || height != static_cast<int64_t>(decode.height) ||\n         height <= 0 || height >= (1LL << 27) || total_size >= (1LL << 29)) {\n-      png::CommonFreeDecode(&decode);\n       OP_REQUIRES(context, false,\n                   errors::InvalidArgument(\"PNG size too large for int: \",\n                                           decode.width, \" by \", decode.height));\n",
        "label": 1,
        "partition": "test"
    },
    {
        "commit_id": "a69b567b8c95c72f9560c873c5ab348be058f340",
        "repo": "gpac/gpac",
        "msg": "fixed #1895The binary MP4Box in Gpac 1.0.1 has a double-free vulnerability in the ilst_box_read function in box_code_apple.c, which allows attackers to cause a denial of service, even code execution and escalation of privileges.",
        "filename": "descriptors.c",
        "diff": "diff --git a/src/odf/descriptors.c b/src/odf/descriptors.c\nindex afc623729e..c1970e820b 100644\n--- a/src/odf/descriptors.c\n+++ b/src/odf/descriptors.c\n@@ -1613,6 +1613,7 @@ GF_AV1Config *gf_odf_av1_cfg_read_bs_size(GF_BitStream *bs, u32 size)\n \t\tsize -= (u32) obu_size;\n \t}\n \tgf_av1_reset_state(& state, GF_TRUE);\n+\tgf_bs_align(bs);\n \treturn cfg;\n #else\n \treturn NULL;\n",
        "label": 1,
        "partition": "test"
    },
    {
        "commit_id": "c7dfa4009965a9b2d7b329ee970eb8da0d32f0bc",
        "repo": "torvalds/linux",
        "msg": "KVM: nSVM: always intercept VMLOAD/VMSAVE when nested (CVE-2021-3656)\n\nIf L1 disables VMLOAD/VMSAVE intercepts, and doesn't enable\nVirtual VMLOAD/VMSAVE (currently not supported for the nested hypervisor),\nthen VMLOAD/VMSAVE must operate on the L1 physical memory, which is only\npossible by making L0 intercept these instructions.\n\nFailure to do so allowed the nested guest to run VMLOAD/VMSAVE unintercepted,\nand thus read/write portions of the host physical memory.\n\nFixes: 89c8a4984fc9 (\"KVM: SVM: Enable Virtual VMLOAD VMSAVE feature\")\n\nSuggested-by: Paolo Bonzini <pbonzini@redhat.com>\nSigned-off-by: Maxim Levitsky <mlevitsk@redhat.com>\nSigned-off-by: Paolo Bonzini <pbonzini@redhat.com>A flaw was found in the KVM's AMD code for supporting SVM nested virtualization. The flaw occurs when processing the VMCB (virtual machine control block) provided by the L1 guest to spawn/handle a nested guest (L2). Due to improper validation of the \"virt_ext\" field, this issue could allow a malicious L1 to disable both VMLOAD/VMSAVE intercepts and VLS (Virtual VMLOAD/VMSAVE) for the L2 guest. As a result, the L2 guest would be allowed to read/write physical pages of the host, resulting in a crash of the entire system, leak of sensitive data or potential guest-to-host escape.",
        "filename": "None",
        "diff": "diff --git a/arch/x86/kvm/svm/nested.c b/arch/x86/kvm/svm/nested.c\nindex 28381ca5221c00..e5515477c30a61 100644\n--- a/arch/x86/kvm/svm/nested.c\n+++ b/arch/x86/kvm/svm/nested.c\n@@ -158,6 +158,9 @@ void recalc_intercepts(struct vcpu_svm *svm)\n \t/* If SMI is not intercepted, ignore guest SMI intercept as well  */\n \tif (!intercept_smi)\n \t\tvmcb_clr_intercept(c, INTERCEPT_SMI);\n+\n+\tvmcb_set_intercept(c, INTERCEPT_VMLOAD);\n+\tvmcb_set_intercept(c, INTERCEPT_VMSAVE);\n }\n \n static void copy_vmcb_control_area(struct vmcb_control_area *dst,\n",
        "label": 1,
        "partition": "test"
    },
    {
        "commit_id": "5b491cd5e41ad63735161cec9c2a568172c8b6a3",
        "repo": "tensorflow/tensorflow",
        "msg": "Validate `proto.dtype()` before calling `set_dtype()`.\n\nThis prevents a `DCHECK`-fail when the proto contains an invalid dtype for a tensor shape with 0 elements or for an incomplete tensor shape.\n\nPiperOrigin-RevId: 408369083\nChange-Id: Ia21a3e3d62a90d642a4561f08f3b543e5ad00c46Tensorflow is an Open Source Machine Learning Framework. When decoding a tensor from protobuf, a TensorFlow process can encounter cases where a `CHECK` assertion is invalidated based on user controlled arguments, if the tensors have an invalid `dtype` and 0 elements or an invalid shape. This allows attackers to cause denial of services in TensorFlow processes. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "filename": "tensor.cc",
        "diff": "diff --git a/tensorflow/core/framework/tensor.cc b/tensorflow/core/framework/tensor.cc\nindex 8ae9fd0051652c..c7a08ee0808043 100644\n--- a/tensorflow/core/framework/tensor.cc\n+++ b/tensorflow/core/framework/tensor.cc\n@@ -983,6 +983,15 @@ bool Tensor::FromProto(Allocator* a, const TensorProto& proto) {\n                          dtype_error = true, dtype_error = true);\n     }\n     if (dtype_error || p == nullptr) return false;\n+  } else {\n+    // Handle the case of empty tensors (N = 0) or tensors with incomplete shape\n+    // (N = -1). All other values of `shape.num_elements()` should be invalid by\n+    // construction.\n+    // Here, we just need to validate that the `proto.dtype()` value is valid.\n+    bool dtype_error = false;\n+    CASES_WITH_DEFAULT(proto.dtype(), break, dtype_error = true,\n+                       dtype_error = true);\n+    if (dtype_error) return false;\n   }\n   shape_ = shape;\n   set_dtype(proto.dtype());\n",
        "label": 1,
        "partition": "test"
    },
    {
        "commit_id": "89ae9fe74c6d445bb1b3a40e568d77cf5de47e48",
        "repo": "flatpak/flatpak",
        "msg": "run: Add cross-references for some other seccomp syscall filters\n\nSigned-off-by: Simon McVittie <smcv@collabora.com>Flatpak is a system for building, distributing, and running sandboxed desktop applications on Linux. In versions prior to 1.10.4 and 1.12.0, Flatpak apps with direct access to AF_UNIX sockets such as those used by Wayland, Pipewire or pipewire-pulse can trick portals and other host-OS services into treating the Flatpak app as though it was an ordinary, non-sandboxed host-OS process. They can do this by manipulating the VFS using recent mount-related syscalls that are not blocked by Flatpak's denylist seccomp filter, in order to substitute a crafted `/.flatpak-info` or make that file disappear entirely. Flatpak apps that act as clients for AF_UNIX sockets such as those used by Wayland, Pipewire or pipewire-pulse can escalate the privileges that the corresponding services will believe the Flatpak app has. Note that protocols that operate entirely over the D-Bus session bus (user bus), system bus or accessibility bus are not affected by this. This is due to the use of a proxy process `xdg-dbus-proxy`, whose VFS cannot be manipulated by the Flatpak app, when interacting with these buses. Patches exist for versions 1.10.4 and 1.12.0, and as of time of publication, a patch for version 1.8.2 is being planned. There are no workarounds aside from upgrading to a patched version.",
        "filename": "flatpak-run.c",
        "diff": "diff --git a/common/flatpak-run.c b/common/flatpak-run.c\nindex 7817ff94f0..ff6403d393 100644\n--- a/common/flatpak-run.c\n+++ b/common/flatpak-run.c\n@@ -2892,6 +2892,10 @@ setup_seccomp (FlatpakBwrap   *bwrap,\n    *  https://git.gnome.org/browse/linux-user-chroot\n    *    in src/setup-seccomp.c\n    *\n+   * Other useful resources:\n+   * https://github.com/systemd/systemd/blob/HEAD/src/shared/seccomp-util.c\n+   * https://github.com/moby/moby/blob/HEAD/profiles/seccomp/default.json\n+   *\n    **** END NOTE ON CODE SHARING\n    */\n   struct\n",
        "label": 1,
        "partition": "test"
    },
    {
        "commit_id": "35f0fabb4c178253a964d7aabdbb15c6a398b69a",
        "repo": "tensorflow/tensorflow",
        "msg": "Avoid Segfault for scalar shapes.\n\nCalling tensor::FromElementsOp with an empty vector of elements and no type\ncauses a segfault. We need to let the FromElementsOp know which scalar type it\nshould have.\nAlso add back the DynamicBroadcastInDimOp canonicalization patterns, which\npreviously prevented this bug from happening.\nAdd a regression test that demonstrates the bug.\n\nPiperOrigin-RevId: 417561444\nChange-Id: I6d1d6cfb71aabbad6102422625a00bbe253ac95aTensorflow is an Open Source Machine Learning Framework. The `simplifyBroadcast` function in the MLIR-TFRT infrastructure in TensorFlow is vulnerable to a segfault (hence, denial of service), if called with scalar shapes. If all shapes are scalar, then `maxRank` is 0, so we build an empty `SmallVector`. The fix will be included in TensorFlow 2.8.0. This is the only affected version.",
        "filename": "tf_cpurt_symbolic_shape_optimization.cc",
        "diff": "diff --git a/tensorflow/compiler/mlir/tfrt/jit/transforms/tf_cpurt_symbolic_shape_optimization.cc b/tensorflow/compiler/mlir/tfrt/jit/transforms/tf_cpurt_symbolic_shape_optimization.cc\nindex 628141a6cd4615..0a8fc42e80a7cd 100644\n--- a/tensorflow/compiler/mlir/tfrt/jit/transforms/tf_cpurt_symbolic_shape_optimization.cc\n+++ b/tensorflow/compiler/mlir/tfrt/jit/transforms/tf_cpurt_symbolic_shape_optimization.cc\n@@ -157,6 +157,10 @@ llvm::Optional<Value> simplifyBroadcast(ShapeComponentAnalysis& analysis,\n     shapes_found.push_back(*found_shape);\n     maxRank = std::max(maxRank, found_shape->size());\n   }\n+  if (maxRank == 0) {\n+    return Value(builder->create<tensor::FromElementsOp>(\n+        loc, shapes[0].getType(), SmallVector<Value>()));\n+  }\n \n   SmallVector<const ShapeComponentAnalysis::SymbolicExpr*> joined_dimensions(\n       maxRank);\ndiff --git a/tensorflow/compiler/mlir/tfrt/python_tests/regression_tests/scalar_broadcast.mlir b/tensorflow/compiler/mlir/tfrt/python_tests/regression_tests/scalar_broadcast.mlir\nnew file mode 100644\nindex 00000000000000..33b785ee6fb19d\n--- /dev/null\n+++ b/tensorflow/compiler/mlir/tfrt/python_tests/regression_tests/scalar_broadcast.mlir\n@@ -0,0 +1,11 @@\n+builtin.func @test(%V__0 : tensor<i1> { python_test_attrs.static_type = tensor<i1> }, %V__1 : tensor<f32> { python_test_attrs.static_type = tensor<f32> }, %V__2 : tensor<f32> { python_test_attrs.static_type = tensor<f32> }) -> tensor<f32> {\n+  %0 = \"tf.Cast\"(%V__0) : (tensor<i1>) -> tensor<i1>\n+  %1 = \"tf.Selu\"(%V__2) : (tensor<f32>) -> tensor<f32>\n+  %2 = \"tf.NextAfter\"(%1, %V__2) : (tensor<f32>, tensor<f32>) -> tensor<f32>\n+  %3 = \"tf.Elu\"(%2) : (tensor<f32>) -> tensor<f32>\n+  %4 = \"tf.Cosh\"(%3) : (tensor<f32>) -> tensor<f32>\n+  %5 = \"tf.Elu\"(%4) : (tensor<f32>) -> tensor<f32>\n+  %6 = \"tf.Div\"(%V__1, %5) : (tensor<f32>, tensor<f32>) -> tensor<f32>\n+  %7 = \"tf.Select\"(%0, %6, %V__1) : (tensor<i1>, tensor<f32>, tensor<f32>) -> tensor<f32>\n+  return %7 : tensor<f32>\n+}\n\\ No newline at end of file\n",
        "label": 1,
        "partition": "test"
    },
    {
        "commit_id": "55e1b2343f4deb1a1b5726cfe1e23b2068217ff2",
        "repo": "facebook/hermes",
        "msg": "Handle typeof applied to empty in InstSimplify\n\nSummary:\nDo not simplify `typeof` if it is applied to an invalid type. This\nhandles a case like the one in the added test, where `typeof` is called\non a literal empty in unreachable code.\n\nReviewed By: kodafb\n\nDifferential Revision: D31000173\n\nfbshipit-source-id: 2d7f69cbcc9c1bb0a916585c07171089444c85dcA type confusion vulnerability could be triggered when resolving the \"typeof\" unary operator in Facebook Hermes prior to v0.10.0. Note that this is only exploitable if the application using Hermes permits evaluation of untrusted JavaScript. Hence, most React Native applications are not affected.",
        "filename": "IREval.cpp",
        "diff": "diff --git a/lib/IR/IREval.cpp b/lib/IR/IREval.cpp\nindex a07efd66dcb..3ddb40d74b0 100644\n--- a/lib/IR/IREval.cpp\n+++ b/lib/IR/IREval.cpp\n@@ -107,7 +107,7 @@ Literal *hermes::evalUnaryOperator(\n         case ValueKind::LiteralStringKind:\n           return builder.getLiteralString(\"string\");\n         default:\n-          llvm_unreachable(\"Invalid literal kind.\");\n+          break;\n       }\n       break;\n \ndiff --git a/test/hermes/tdz-check.js b/test/hermes/tdz-check.js\nindex 0533c1c49d7..fa82b26e8fb 100644\n--- a/test/hermes/tdz-check.js\n+++ b/test/hermes/tdz-check.js\n@@ -45,3 +45,8 @@ test(() => {\n     return x;\n });\n //CHECK-NEXT: caught ReferenceError: accessing an uninitialized variable\n+\n+test(() => {\n+    const foo = print(foo, typeof foo)\n+});\n+//CHECK-NEXT: caught ReferenceError: accessing an uninitialized variable\n",
        "label": 1,
        "partition": "test"
    },
    {
        "commit_id": "eae46a7e2a57103aadca903c4a24cca94dc502a2",
        "repo": "e2guardian/e2guardian",
        "msg": "Fix bug #707 cert hostnames not being checked\n- only happened when openssl v1.1 is usede2guardian v5.4.x <= v5.4.3r is affected by missing SSL certificate validation in the SSL MITM engine. In standalone mode (i.e., acting as a proxy or a transparent proxy), with SSL MITM enabled, e2guardian, if built with OpenSSL v1.1.x, did not validate hostnames in certificates of the web servers that it connected to, and thus was itself vulnerable to MITM attacks.",
        "filename": "Socket.cpp",
        "diff": "diff --git a/src/Socket.cpp b/src/Socket.cpp\nindex 6ef9619c..2b687ef5 100644\n--- a/src/Socket.cpp\n+++ b/src/Socket.cpp\n@@ -377,6 +377,10 @@ int Socket::startSslClient(const std::string &certificate_path, String hostname)\n     //fcntl(this->getFD() ,F_SETFL, O_NONBLOCK); // blocking mode used currently\n     SSL_set_fd(ssl, this->getFD());\n     SSL_set_tlsext_host_name(ssl, hostname.c_str());\n+#if OPENSSL_VERSION_NUMBER < 0x10100000L\n+#else\n+  X509_VERIFY_PARAM_set1_host(SSL_get0_param(ssl),hostname.c_str(),0);\n+#endif\n \n     //make io non blocking as select wont tell us if we can do a read without blocking\n     //BIO_set_nbio(SSL_get_rbio(ssl),1l);  // blocking mode used currently\n",
        "label": 0,
        "partition": "test"
    },
    {
        "commit_id": "3d89911481ba6ebe8c88c1c0b595412121e6c645",
        "repo": "tensorflow/tensorflow",
        "msg": "Eliminate `CHECK`-fail from `function.cc`.\n\nPiperOrigin-RevId: 409414744\nChange-Id: Ic854e12ab2edb88b165d32e2d632c4ee654d71adTensorflow is an Open Source Machine Learning Framework. A malicious user can cause a denial of service by altering a `SavedModel` such that assertions in `function.cc` would be falsified and crash the Python interpreter. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "filename": "function.cc",
        "diff": "diff --git a/tensorflow/core/framework/function.cc b/tensorflow/core/framework/function.cc\nindex 41b8d446149694..492d9d54fe60eb 100644\n--- a/tensorflow/core/framework/function.cc\n+++ b/tensorflow/core/framework/function.cc\n@@ -181,7 +181,9 @@ class FunctionInstantiationHelper {\n     DataTypeVector dtypes;\n     TF_RETURN_IF_ERROR(\n         ArgNumType(attr_values, arg_def, &is_type_list, &dtypes));\n-    CHECK_GE(dtypes.size(), size_t{1});\n+    if (dtypes.size() < size_t{1}) {\n+      return errors::Internal(\"Expected a list of at least one dtype\");\n+    }\n     int arg_index = result_.nodes.size();\n     TF_RETURN_IF_ERROR(\n         AddItem(arg_def.name(), {true, arg_index, 0, is_type_list, dtypes}));\n",
        "label": 1,
        "partition": "test"
    },
    {
        "commit_id": "0849a2885f81cfd82134992c06df3ccd59052ac7",
        "repo": "mruby/mruby",
        "msg": "codegen.c: stack position may be wrong on assignments.\n\nWhen `[]=` access includes keyword arguments.Out-of-bounds Read in Homebrew mruby prior to 3.2.",
        "filename": "codegen.c",
        "diff": "diff --git a/mrbgems/mruby-compiler/core/codegen.c b/mrbgems/mruby-compiler/core/codegen.c\nindex 4a9fb9aeb0..86f88b6e64 100644\n--- a/mrbgems/mruby-compiler/core/codegen.c\n+++ b/mrbgems/mruby-compiler/core/codegen.c\n@@ -1865,15 +1865,21 @@ gen_assignment(codegen_scope *s, node *tree, node *rhs, int sp, int val)\n           }\n         }\n         if (tree->cdr->car) {       /* keyword arguments */\n+          if (n == 14) {\n+            pop_n(n);\n+            genop_2(s, OP_ARRAY, cursp(), n);\n+            push();\n+            n = 15;\n+          }\n           gen_hash(s, tree->cdr->car->cdr, VAL, 0);\n           if (n < 14) {\n             n++;\n-            push();\n           }\n           else {\n-            pop();\n+            pop_n(2);\n             genop_2(s, OP_ARYPUSH, cursp(), 1);\n           }\n+          push();\n         }\n       }\n       if (rhs) {\n",
        "label": 1,
        "partition": "test"
    },
    {
        "commit_id": "1c020d1f5ca462f5b150b46a027aaa1bbe3c9596",
        "repo": "tmate-io/tmate-ssh-server",
        "msg": "Harden /tmp/tmate directory\n\nSuggested by Matthias GerstnerWorld-writable permissions on the /tmp/tmate/sessions directory in tmate-ssh-server 2.3.0 allow a local attacker to compromise the integrity of session handling, or obtain the read-write session ID from a read-only session symlink in this directory.",
        "filename": "tmate-main.c",
        "diff": "diff --git a/tmate-main.c b/tmate-main.c\nindex 86560ecb..69f33209 100644\n--- a/tmate-main.c\n+++ b/tmate-main.c\n@@ -98,6 +98,24 @@ static void setup_locale(void)\n \ttzset();\n }\n \n+static int check_owned_directory_mode(const char *path, mode_t expected_mode)\n+{\n+\tstruct stat stat;\n+\tif (lstat(path, &stat))\n+\t\treturn -1;\n+\n+\tif (!S_ISDIR(stat.st_mode))\n+\t\treturn -1;\n+\n+\tif (stat.st_uid != getuid())\n+\t\treturn -1;\n+\n+\tif ((stat.st_mode & 07777) != expected_mode)\n+\t\treturn -1;\n+\n+\treturn 0;\n+}\n+\n int main(int argc, char **argv, char **envp)\n {\n \tint opt;\n@@ -151,17 +169,22 @@ int main(int argc, char **argv, char **envp)\n \ttmate_catch_sigsegv();\n \ttmate_init_rand();\n \n-\tif ((mkdir(TMATE_WORKDIR, 0701)             < 0 && errno != EEXIST) ||\n-\t    (mkdir(TMATE_WORKDIR \"/sessions\", 0703) < 0 && errno != EEXIST) ||\n+\tif ((mkdir(TMATE_WORKDIR, 0700)             < 0 && errno != EEXIST) ||\n+\t    (mkdir(TMATE_WORKDIR \"/sessions\", 0700) < 0 && errno != EEXIST) ||\n \t    (mkdir(TMATE_WORKDIR \"/jail\", 0700)     < 0 && errno != EEXIST))\n \t\ttmate_fatal(\"Cannot prepare session in \" TMATE_WORKDIR);\n \n-\t/* The websocket server needs to access the /session dir to rename sockets */\n-\tif ((chmod(TMATE_WORKDIR, 0701)             < 0) ||\n-\t    (chmod(TMATE_WORKDIR \"/sessions\", 0703) < 0) ||\n+\tif ((chmod(TMATE_WORKDIR, 0700)             < 0) ||\n+\t    (chmod(TMATE_WORKDIR \"/sessions\", 0700) < 0) ||\n \t    (chmod(TMATE_WORKDIR \"/jail\", 0700)     < 0))\n \t\ttmate_fatal(\"Cannot prepare session in \" TMATE_WORKDIR);\n \n+\tif (check_owned_directory_mode(TMATE_WORKDIR, 0700) ||\n+\t    check_owned_directory_mode(TMATE_WORKDIR \"/sessions\", 0700) ||\n+\t    check_owned_directory_mode(TMATE_WORKDIR \"/jail\", 0700))\n+\t\ttmate_fatal(TMATE_WORKDIR \" and subdirectories has incorrect ownership/mode. \"\n+\t\t\t    \"Try deleting \" TMATE_WORKDIR \" and try again\");\n+\n \ttmate_ssh_server_main(tmate_session,\n \t\t\t      tmate_settings->keys_dir, tmate_settings->bind_addr, tmate_settings->ssh_port);\n \treturn 0;\n",
        "label": 1,
        "partition": "test"
    },
    {
        "commit_id": "f74c1fc22b760d2a24369aa72c74c4a9ab985859",
        "repo": "pjsip/pjproject",
        "msg": "Merge pull request from GHSA-r374-qrwv-86hhPJSIP is a free and open source multimedia communication library. In version 2.11.1 and prior, if incoming RTCP XR message contain block, the data field is not checked against the received packet size, potentially resulting in an out-of-bound read access. This affects all users that use PJMEDIA and RTCP XR. A malicious actor can send a RTCP XR message with an invalid packet size.",
        "filename": "rtcp_xr.c",
        "diff": "diff --git a/pjmedia/src/pjmedia/rtcp_xr.c b/pjmedia/src/pjmedia/rtcp_xr.c\nindex 44927063b1..f554698a20 100644\n--- a/pjmedia/src/pjmedia/rtcp_xr.c\n+++ b/pjmedia/src/pjmedia/rtcp_xr.c\n@@ -436,16 +436,32 @@ void pjmedia_rtcp_xr_rx_rtcp_xr( pjmedia_rtcp_xr_session *sess,\n \tif (rb_len) {\n \t    switch (rb_hdr->bt) {\n \t\tcase BT_RR_TIME:\n-\t\t    rb_rr_time = (pjmedia_rtcp_xr_rb_rr_time*) rb_hdr;\n+\t\t    if ((char*)rb_hdr + sizeof(*rb_rr_time) <=\n+\t\t\t(char*)pkt + size) \n+\t\t    {\n+\t\t\trb_rr_time = (pjmedia_rtcp_xr_rb_rr_time*)rb_hdr;\n+\t\t    }\n \t\t    break;\n \t\tcase BT_DLRR:\n-\t\t    rb_dlrr = (pjmedia_rtcp_xr_rb_dlrr*) rb_hdr;\n+\t\t    if ((char*)rb_hdr + sizeof(*rb_dlrr) <=\n+\t\t\t(char*)pkt + size)\n+\t\t    {\n+\t\t\trb_dlrr = (pjmedia_rtcp_xr_rb_dlrr*)rb_hdr;\n+\t\t    }\n \t\t    break;\n \t\tcase BT_STATS:\n-\t\t    rb_stats = (pjmedia_rtcp_xr_rb_stats*) rb_hdr;\n+\t\t    if ((char*)rb_hdr + sizeof(*rb_stats) <=\n+\t\t\t(char*)pkt + size)\n+\t\t    {\n+\t\t\trb_stats = (pjmedia_rtcp_xr_rb_stats*)rb_hdr;\n+\t\t    }\n \t\t    break;\n \t\tcase BT_VOIP_METRICS:\n-\t\t    rb_voip_mtc = (pjmedia_rtcp_xr_rb_voip_mtc*) rb_hdr;\n+\t\t    if ((char*)rb_hdr + sizeof(*rb_voip_mtc) <=\n+\t\t\t(char*)pkt + size)\n+\t\t    {\n+\t\t\trb_voip_mtc = (pjmedia_rtcp_xr_rb_voip_mtc*)rb_hdr;\n+\t\t    }\n \t\t    break;\n \t\tdefault:\n \t\t    break;\n",
        "label": 0,
        "partition": "test"
    },
    {
        "commit_id": "893fb99b606eebfae46cde151846a980e689039b",
        "repo": "gpac/gpac",
        "msg": "fixed #1902A Segmentation fault caused by a null pointer dereference vulnerability exists in Gpac through 1.0.1 via the gf_avc_parse_nalu function in av_parsers.c when using mp4box, which causes a denial of service.",
        "filename": "av_parsers.c",
        "diff": "diff --git a/src/media_tools/av_parsers.c b/src/media_tools/av_parsers.c\nindex 96d2797420..1ab1a5373f 100644\n--- a/src/media_tools/av_parsers.c\n+++ b/src/media_tools/av_parsers.c\n@@ -6113,7 +6113,8 @@ s32 gf_avc_parse_nalu(GF_BitStream *bs, AVCState *avc)\n \t\t\tret = 1;\n \t\t\tbreak;\n \t\t}\n-\t\tassert(avc->s_info.sps);\n+\t\tif (!avc->s_info.sps)\n+\t\t\treturn -1;\n \n \t\tif (avc->s_info.sps->poc_type == n_state.sps->poc_type) {\n \t\t\tif (!avc->s_info.sps->poc_type) {\n",
        "label": 0,
        "partition": "test"
    },
    {
        "commit_id": "97282c6d0d34476b6ba033f961590b783fa184cd",
        "repo": "tensorflow/tensorflow",
        "msg": "Prevent a crash due to heap OOB write in grappler.\n\nPiperOrigin-RevId: 408318417\nChange-Id: If095feb8c001e3a8ac4a85b7387b81e8309df47dTensorflow is an Open Source Machine Learning Framework. TensorFlow is vulnerable to a heap OOB write in `Grappler`. The `set_output` function writes to an array at the specified index. Hence, this gives a malicious user a write primitive. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "filename": "graph_properties.cc",
        "diff": "diff --git a/tensorflow/core/grappler/costs/graph_properties.cc b/tensorflow/core/grappler/costs/graph_properties.cc\nindex 51a2cd080c5445..3cc12173ba10c5 100644\n--- a/tensorflow/core/grappler/costs/graph_properties.cc\n+++ b/tensorflow/core/grappler/costs/graph_properties.cc\n@@ -1134,7 +1134,12 @@ class SymbolicShapeRefiner {\n         GetUnknownOutputShape(node, output_port);\n     InferenceContext* ctx = GetContext(node);\n     if (ctx == nullptr) {\n-      return errors::InvalidArgument(\"Missing context\");\n+      return errors::InvalidArgument(\"SetUnknownShape: Missing context\");\n+    }\n+    if (output_port < 0 || output_port >= ctx->num_outputs()) {\n+      return errors::InvalidArgument(\n+          \"SetUnknownShape: output_port must be in [0, \", ctx->num_outputs(),\n+          \") but was \", output_port);\n     }\n     ctx->set_output(output_port, shape);\n     return Status::OK();\n",
        "label": 1,
        "partition": "test"
    },
    {
        "commit_id": "dcc21c7bc972b10b6fb95c2fb0f4ab5a59680ec2",
        "repo": "tensorflow/tensorflow",
        "msg": "Eliminate debug `CHECK`-fail from `function.cc`\n\nPiperOrigin-RevId: 409416119\nChange-Id: I8376ee464d434e9b970ff0ad49edfdaa2a273cfeTensorflow is an Open Source Machine Learning Framework. A malicious user can cause a denial of service by altering a `SavedModel` such that assertions in `function.cc` would be falsified and crash the Python interpreter. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "filename": "function.cc",
        "diff": "diff --git a/tensorflow/core/framework/function.cc b/tensorflow/core/framework/function.cc\nindex 492d9d54fe60eb..b8318ef346ae08 100644\n--- a/tensorflow/core/framework/function.cc\n+++ b/tensorflow/core/framework/function.cc\n@@ -191,7 +191,11 @@ class FunctionInstantiationHelper {\n     for (size_t i = 0; i < dtypes.size(); ++i) {\n       TF_RETURN_IF_ERROR(AddItem(strings::StrCat(arg_def.name(), \":\", i),\n                                  {true, arg_index, 0, false, {dtypes[i]}}));\n-      DCHECK_EQ(arg_index, result_.nodes.size());\n+      if (arg_index != result_.nodes.size()) {\n+        return errors::Internal(\n+            \"Expected arg_index to be equal to the number of nodes in result.\",\n+            \" Got \", arg_index, \" and \", result_.nodes.size());\n+      }\n       string name = arg_def.name();\n       if (dtypes.size() > 1) {\n         strings::StrAppend(&name, \"_\", i);\n",
        "label": 1,
        "partition": "test"
    },
    {
        "commit_id": "f221ea0fa3171f0f4fdf74ac9d81b203b9534c23",
        "repo": "ImageMagick/ImageMagick",
        "msg": "Fixes #4985: 4e+26 is outside the range of representable values of type 'unsigned long' at coders/pcl.c:299 (#4986)\n\n* fix Division by zero in XMenuWidget() of MagickCore/widget.c\n\n* Fix memory leak in AnimateImageCommand() of MagickWand/animate.c and DisplayImageCommand() of MagickWand/display.c\n\n* fix Division by zero in ReadEnhMetaFile() of coders/emf.c\n\n* Resolve conflicts\n\n* fix issue: outside the range of representable values of type 'unsigned char' at coders/psd.c:1025\n\n* fix error: 4e+26 is outside the range of representable values of type 'unsigned long' at coders/pcl.c:299\n\nCo-authored-by: zhailiangliang <zhailiangliang@loongson.cn>A vulnerability was found in ImageMagick, causing an outside the range of representable values of type 'unsigned long' at coders/pcl.c, when crafted or untrusted input is processed. This leads to a negative impact to application availability or other problems related to undefined behavior.",
        "filename": "pcl.c",
        "diff": "diff --git a/coders/pcl.c b/coders/pcl.c\nindex c0cc213ed5a..70d2b4b9994 100644\n--- a/coders/pcl.c\n+++ b/coders/pcl.c\n@@ -295,8 +295,8 @@ static Image *ReadPCLImage(const ImageInfo *image_info,ExceptionInfo *exception)\n     /*\n       Set PCL render geometry.\n     */\n-    width=(size_t) floor(bounds.x2-bounds.x1+0.5);\n-    height=(size_t) floor(bounds.y2-bounds.y1+0.5);\n+    width=(size_t)CastDoubleToLong(floor(bounds.x2-bounds.x1+0.5));\n+    height=(size_t)CastDoubleToLong(floor(bounds.y2-bounds.y1+0.5));\n     if (width > page.width)\n       page.width=width;\n     if (height > page.height)\n",
        "label": 0,
        "partition": "test"
    },
    {
        "commit_id": "e26ac7586c392b5eb35ff4609fe232c52523b2cf",
        "repo": "flatpak/flatpak",
        "msg": "run: Add an errno value to seccomp filters\n\nAt the moment, if we block a syscall we always make it fail with EPERM,\nbut this is risky: user-space libraries can start to use new replacements\nfor old syscalls at any time, and will often treat EPERM as a fatal error.\nFor new syscalls, we should make the syscall fail with ENOSYS, which is\nindistinguishable from running on an older kernel and will cause fallback\nto an older implementation, for example clone3() to clone().\n\nIn future we should probably move from EPERM to ENOSYS for some of the\nsyscalls we already block, but for now keep the status quo.\n\nThis is a prerequisite for fixing the vulnerability tracked as\nGHSA-67h7-w3jq-vh4q.\n\nSigned-off-by: Simon McVittie <smcv@collabora.com>Flatpak is a system for building, distributing, and running sandboxed desktop applications on Linux. In versions prior to 1.10.4 and 1.12.0, Flatpak apps with direct access to AF_UNIX sockets such as those used by Wayland, Pipewire or pipewire-pulse can trick portals and other host-OS services into treating the Flatpak app as though it was an ordinary, non-sandboxed host-OS process. They can do this by manipulating the VFS using recent mount-related syscalls that are not blocked by Flatpak's denylist seccomp filter, in order to substitute a crafted `/.flatpak-info` or make that file disappear entirely. Flatpak apps that act as clients for AF_UNIX sockets such as those used by Wayland, Pipewire or pipewire-pulse can escalate the privileges that the corresponding services will believe the Flatpak app has. Note that protocols that operate entirely over the D-Bus session bus (user bus), system bus or accessibility bus are not affected by this. This is due to the use of a proxy process `xdg-dbus-proxy`, whose VFS cannot be manipulated by the Flatpak app, when interacting with these buses. Patches exist for versions 1.10.4 and 1.12.0, and as of time of publication, a patch for version 1.8.2 is being planned. There are no workarounds aside from upgrading to a patched version.",
        "filename": "flatpak-run.c",
        "diff": "diff --git a/common/flatpak-run.c b/common/flatpak-run.c\nindex e93b3d63b0..7817ff94f0 100644\n--- a/common/flatpak-run.c\n+++ b/common/flatpak-run.c\n@@ -2897,61 +2897,63 @@ setup_seccomp (FlatpakBwrap   *bwrap,\n   struct\n   {\n     int                  scall;\n+    int                  errnum;\n     struct scmp_arg_cmp *arg;\n   } syscall_blocklist[] = {\n     /* Block dmesg */\n-    {SCMP_SYS (syslog)},\n+    {SCMP_SYS (syslog), EPERM},\n     /* Useless old syscall */\n-    {SCMP_SYS (uselib)},\n+    {SCMP_SYS (uselib), EPERM},\n     /* Don't allow disabling accounting */\n-    {SCMP_SYS (acct)},\n+    {SCMP_SYS (acct), EPERM},\n     /* 16-bit code is unnecessary in the sandbox, and modify_ldt is a\n        historic source of interesting information leaks. */\n-    {SCMP_SYS (modify_ldt)},\n+    {SCMP_SYS (modify_ldt), EPERM},\n     /* Don't allow reading current quota use */\n-    {SCMP_SYS (quotactl)},\n+    {SCMP_SYS (quotactl), EPERM},\n \n     /* Don't allow access to the kernel keyring */\n-    {SCMP_SYS (add_key)},\n-    {SCMP_SYS (keyctl)},\n-    {SCMP_SYS (request_key)},\n+    {SCMP_SYS (add_key), EPERM},\n+    {SCMP_SYS (keyctl), EPERM},\n+    {SCMP_SYS (request_key), EPERM},\n \n     /* Scary VM/NUMA ops */\n-    {SCMP_SYS (move_pages)},\n-    {SCMP_SYS (mbind)},\n-    {SCMP_SYS (get_mempolicy)},\n-    {SCMP_SYS (set_mempolicy)},\n-    {SCMP_SYS (migrate_pages)},\n+    {SCMP_SYS (move_pages), EPERM},\n+    {SCMP_SYS (mbind), EPERM},\n+    {SCMP_SYS (get_mempolicy), EPERM},\n+    {SCMP_SYS (set_mempolicy), EPERM},\n+    {SCMP_SYS (migrate_pages), EPERM},\n \n     /* Don't allow subnamespace setups: */\n-    {SCMP_SYS (unshare)},\n-    {SCMP_SYS (mount)},\n-    {SCMP_SYS (pivot_root)},\n+    {SCMP_SYS (unshare), EPERM},\n+    {SCMP_SYS (mount), EPERM},\n+    {SCMP_SYS (pivot_root), EPERM},\n #if defined(__s390__) || defined(__s390x__) || defined(__CRIS__)\n     /* Architectures with CONFIG_CLONE_BACKWARDS2: the child stack\n      * and flags arguments are reversed so the flags come second */\n-    {SCMP_SYS (clone), &SCMP_A1 (SCMP_CMP_MASKED_EQ, CLONE_NEWUSER, CLONE_NEWUSER)},\n+    {SCMP_SYS (clone), EPERM, &SCMP_A1 (SCMP_CMP_MASKED_EQ, CLONE_NEWUSER, CLONE_NEWUSER)},\n #else\n     /* Normally the flags come first */\n-    {SCMP_SYS (clone), &SCMP_A0 (SCMP_CMP_MASKED_EQ, CLONE_NEWUSER, CLONE_NEWUSER)},\n+    {SCMP_SYS (clone), EPERM, &SCMP_A0 (SCMP_CMP_MASKED_EQ, CLONE_NEWUSER, CLONE_NEWUSER)},\n #endif\n \n     /* Don't allow faking input to the controlling tty (CVE-2017-5226) */\n-    {SCMP_SYS (ioctl), &SCMP_A1 (SCMP_CMP_MASKED_EQ, 0xFFFFFFFFu, (int) TIOCSTI)},\n+    {SCMP_SYS (ioctl), EPERM, &SCMP_A1 (SCMP_CMP_MASKED_EQ, 0xFFFFFFFFu, (int) TIOCSTI)},\n   };\n \n   struct\n   {\n     int                  scall;\n+    int                  errnum;\n     struct scmp_arg_cmp *arg;\n   } syscall_nondevel_blocklist[] = {\n     /* Profiling operations; we expect these to be done by tools from outside\n      * the sandbox.  In particular perf has been the source of many CVEs.\n      */\n-    {SCMP_SYS (perf_event_open)},\n+    {SCMP_SYS (perf_event_open), EPERM},\n     /* Don't allow you to switch to bsd emulation or whatnot */\n-    {SCMP_SYS (personality), &SCMP_A0 (SCMP_CMP_NE, allowed_personality)},\n-    {SCMP_SYS (ptrace)}\n+    {SCMP_SYS (personality), EPERM, &SCMP_A0 (SCMP_CMP_NE, allowed_personality)},\n+    {SCMP_SYS (ptrace), EPERM}\n   };\n   /* Blocklist all but unix, inet, inet6 and netlink */\n   struct\n@@ -3035,10 +3037,14 @@ setup_seccomp (FlatpakBwrap   *bwrap,\n   for (i = 0; i < G_N_ELEMENTS (syscall_blocklist); i++)\n     {\n       int scall = syscall_blocklist[i].scall;\n+      int errnum = syscall_blocklist[i].errnum;\n+\n+      g_return_val_if_fail (errnum == EPERM || errnum == ENOSYS, FALSE);\n+\n       if (syscall_blocklist[i].arg)\n-        r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (EPERM), scall, 1, *syscall_blocklist[i].arg);\n+        r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (errnum), scall, 1, *syscall_blocklist[i].arg);\n       else\n-        r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (EPERM), scall, 0);\n+        r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (errnum), scall, 0);\n       if (r < 0 && r == -EFAULT /* unknown syscall */)\n         return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to block syscall %d\"), scall);\n     }\n@@ -3048,10 +3054,14 @@ setup_seccomp (FlatpakBwrap   *bwrap,\n       for (i = 0; i < G_N_ELEMENTS (syscall_nondevel_blocklist); i++)\n         {\n           int scall = syscall_nondevel_blocklist[i].scall;\n+          int errnum = syscall_nondevel_blocklist[i].errnum;\n+\n+          g_return_val_if_fail (errnum == EPERM || errnum == ENOSYS, FALSE);\n+\n           if (syscall_nondevel_blocklist[i].arg)\n-            r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (EPERM), scall, 1, *syscall_nondevel_blocklist[i].arg);\n+            r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (errnum), scall, 1, *syscall_nondevel_blocklist[i].arg);\n           else\n-            r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (EPERM), scall, 0);\n+            r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (errnum), scall, 0);\n \n           if (r < 0 && r == -EFAULT /* unknown syscall */)\n             return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to block syscall %d\"), scall);\n",
        "label": 1,
        "partition": "test"
    },
    {
        "commit_id": "1b54cadd19391b60b6fcccd8d076426f7221d5e8",
        "repo": "tensorflow/tensorflow",
        "msg": "Add missing validation to sparse dense cwise ops.\n\nPiperOrigin-RevId: 415543133\nChange-Id: I5baf3284e919338afb96178c468ad3d3cb0d956cTensorflow is an Open Source Machine Learning Framework. The implementations of `Sparse*Cwise*` ops are vulnerable to integer overflows. These can be used to trigger large allocations (so, OOM based denial of service) or `CHECK`-fails when building new `TensorShape` objects (so, assert failures based denial of service). We are missing some validation on the shapes of the input tensors as well as directly constructing a large `TensorShape` with user-provided dimensions. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "filename": "sparse_dense_binary_op_shared.cc",
        "diff": "diff --git a/tensorflow/core/kernels/sparse_dense_binary_op_shared.cc b/tensorflow/core/kernels/sparse_dense_binary_op_shared.cc\nindex b8a391b560f3c1..db27abfda7e537 100644\n--- a/tensorflow/core/kernels/sparse_dense_binary_op_shared.cc\n+++ b/tensorflow/core/kernels/sparse_dense_binary_op_shared.cc\n@@ -78,11 +78,24 @@ class SparseDenseBinaryOpShared : public OpKernel {\n                     \"but received shapes: \",\n                     values_t->shape().DebugString(), \" and \",\n                     shape_t->shape().DebugString()));\n+    OP_REQUIRES(\n+        ctx, TensorShapeUtils::IsVector(shape_t->shape()),\n+        errors::InvalidArgument(\"Input sp_shape must be a vector. Got: \",\n+                                shape_t->shape().DebugString()));\n     OP_REQUIRES(\n         ctx, values_t->dim_size(0) == indices_t->dim_size(0),\n         errors::InvalidArgument(\n             \"The first dimension of values and indices should match. (\",\n             values_t->dim_size(0), \" vs. \", indices_t->dim_size(0), \")\"));\n+    OP_REQUIRES(\n+        ctx, shape_t->shape().dim_size(0) == indices_t->shape().dim_size(1),\n+        errors::InvalidArgument(\n+            \"Number of dimensions must match second dimension of indices. \",\n+            \"Got \", shape_t->shape().dim_size(0),\n+            \" dimensions, indices shape: \", indices_t->shape().DebugString()));\n+    OP_REQUIRES(ctx, shape_t->NumElements() > 0,\n+                errors::InvalidArgument(\n+                    \"The shape argument requires at least one element.\"));\n \n     const auto indices_mat = indices_t->matrix<int64_t>();\n     const auto shape_vec = shape_t->vec<int64_t>();\n",
        "label": 1,
        "partition": "test"
    },
    {
        "commit_id": "4923de56ec94fff7770df259ab7f2288a74feb41",
        "repo": "tensorflow/tensorflow",
        "msg": "Don't do any work when reshaping 0 elements sparse tensor.\n\nIf reshaping to 0 elements tensor, check that input has no elements.\nIf reshaping no elements input, check that output has no elements.\n\nPiperOrigin-RevId: 388296986\nChange-Id: Iadc9fe7252e14313ca987e69bf0d7042fd10232aTensorFlow is an end-to-end open source platform for machine learning. In affected versions the implementation of `tf.raw_ops.SparseReshape` can be made to trigger an integral division by 0 exception. The [implementation](https://github.com/tensorflow/tensorflow/blob/8d72537c6abf5a44103b57b9c2e22c14f5f49698/tensorflow/core/kernels/reshape_util.cc#L176-L181) calls the reshaping functor whenever there is at least an index in the input but does not check that shape of the input or the target shape have both a non-zero number of elements. The [reshape functor](https://github.com/tensorflow/tensorflow/blob/8d72537c6abf5a44103b57b9c2e22c14f5f49698/tensorflow/core/kernels/reshape_util.cc#L40-L78) blindly divides by the dimensions of the target shape. Hence, if this is not checked, code will result in a division by 0. We have patched the issue in GitHub commit 4923de56ec94fff7770df259ab7f2288a74feb41. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1 as this is the other affected version.",
        "filename": "reshape_util.cc",
        "diff": "diff --git a/tensorflow/core/kernels/reshape_util.cc b/tensorflow/core/kernels/reshape_util.cc\nindex 6d6c6b3fcf193b..5db8944cebf06b 100644\n--- a/tensorflow/core/kernels/reshape_util.cc\n+++ b/tensorflow/core/kernels/reshape_util.cc\n@@ -174,6 +174,12 @@ void ReshapeSparseTensor(OpKernelContext *context,\n                                           TensorShape({nnz, output_rank}),\n                                           &result_indices));\n   if (nnz > 0) {\n+    OP_REQUIRES(\n+        context, dense_size > 0 && product > 0,\n+        errors::InvalidArgument(\n+            \"Input tensor has \", nnz, \" non zero elements but input shape (\",\n+            input_shape.DebugString(), \") or output shape (\",\n+            output_shape.DebugString(), \") is empty\"));\n     OP_REQUIRES_OK(context, functor::ReshapeSparseTensorFunctor<Device>()(\n                                 context, input_shape, output_shape,\n                                 input_indices_in.matrix<int64>(),\n",
        "label": 1,
        "partition": "test"
    },
    {
        "commit_id": "246d8ae0cef27377e5dfe9ee3ad87e864d6b6266",
        "repo": "owntone/owntone-server",
        "msg": "[misc] Fix use-after-free in net_bind()\n\nThanks to Ba Jinsheng for reporting this bugOwnTone (aka owntone-server) through 28.1 has a use-after-free in net_bind() in misc.c.",
        "filename": "misc.c",
        "diff": "diff --git a/src/misc.c b/src/misc.c\nindex 4062525719..73266c91a8 100644\n--- a/src/misc.c\n+++ b/src/misc.c\n@@ -251,6 +251,8 @@ net_bind(short unsigned *port, int type, const char *log_service_name)\n   struct addrinfo hints = { 0 };\n   struct addrinfo *servinfo;\n   struct addrinfo *ptr;\n+  union net_sockaddr naddr = { 0 };\n+  socklen_t naddr_len = sizeof(naddr);\n   const char *cfgaddr;\n   char addr[INET6_ADDRSTRLEN];\n   char strport[8];\n@@ -314,16 +316,22 @@ net_bind(short unsigned *port, int type, const char *log_service_name)\n       goto error;\n     }\n \n-  // Get the port that was assigned\n-  ret = getsockname(fd, ptr->ai_addr, &ptr->ai_addrlen);\n+  // Get our address (as string) and the port that was assigned (necessary when\n+  // caller didn't specify a port)\n+  ret = getsockname(fd, &naddr.sa, &naddr_len);\n   if (ret < 0)\n     {\n-      DPRINTF(E_LOG, L_MISC, \"Could not find address of service '%s': %s\\n\", log_service_name, strerror(errno));\n+      DPRINTF(E_LOG, L_MISC, \"Error finding address of service '%s': %s\\n\", log_service_name, strerror(errno));\n+      goto error;\n+    }\n+  else if (naddr_len > sizeof(naddr))\n+    {\n+      DPRINTF(E_LOG, L_MISC, \"Unexpected address length of service '%s'\\n\", log_service_name);\n       goto error;\n     }\n \n-  net_port_get(port, (union net_sockaddr *)ptr->ai_addr);\n-  net_address_get(addr, sizeof(addr), (union net_sockaddr *)ptr->ai_addr);\n+  net_port_get(port, &naddr);\n+  net_address_get(addr, sizeof(addr), &naddr);\n \n   DPRINTF(E_DBG, L_MISC, \"Service '%s' bound to %s, port %hu, socket %d\\n\", log_service_name, addr, *port, fd);\n \n",
        "label": 1,
        "partition": "test"
    },
    {
        "commit_id": "803404044ae7a1efac48ba82d74111fce1ddb09a",
        "repo": "tensorflow/tensorflow",
        "msg": "Fix security vulnerability with LSTMBlockCellOp\n\nPiperOrigin-RevId: 446028341TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, the implementation of `tf.raw_ops.LSTMBlockCell` does not fully validate the input arguments. This results in a `CHECK`-failure which can be used to trigger a denial of service attack. The code does not validate the ranks of any of the arguments to this API call. This results in `CHECK`-failures when the elements of the tensor are accessed. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.",
        "filename": "lstm_ops.cc",
        "diff": "diff --git a/tensorflow/core/kernels/rnn/lstm_ops.cc b/tensorflow/core/kernels/rnn/lstm_ops.cc\nindex 711fc8f08275d8..ab4b9c695a5699 100644\n--- a/tensorflow/core/kernels/rnn/lstm_ops.cc\n+++ b/tensorflow/core/kernels/rnn/lstm_ops.cc\n@@ -416,6 +416,65 @@ class LSTMBlockCellOp : public OpKernel {\n \n     const Device& device = ctx->eigen_device<Device>();\n \n+    // Sanity check that each of the tensors have the required NDIMS.\n+    OP_REQUIRES(ctx, x_tensor->dims() == 2,\n+                errors::InvalidArgument(\"x_tensor must be rank 2 but is rank \",\n+                                        x_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, cs_prev_tensor->dims() == 2,\n+        errors::InvalidArgument(\"cs_prev_tensor must be rank 2 but is rank \",\n+                                cs_prev_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, h_prev_tensor->dims() == 2,\n+        errors::InvalidArgument(\"h_prev_tensor must be rank 2 but is rank \",\n+                                h_prev_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, w_tensor->dims() == 2,\n+                errors::InvalidArgument(\"w_tensor must be rank 2 but is rank \",\n+                                        w_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, wci_tensor->dims() == 1,\n+        errors::InvalidArgument(\"wci_tensor must be rank 1 but is rank \",\n+                                wci_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, wcf_tensor->dims() == 1,\n+        errors::InvalidArgument(\"wcf_tensor must be rank 1 but is rank \",\n+                                wci_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, wco_tensor->dims() == 1,\n+        errors::InvalidArgument(\"wco_tensor must be rank 1 but is rank \",\n+                                wco_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, b_tensor->dims() == 1,\n+                errors::InvalidArgument(\"b_tensor must be rank 1 but is rank \",\n+                                        b_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, xh_tensor.dims() == 2,\n+                errors::InvalidArgument(\"xh_tensor must be rank 2 but is rank \",\n+                                        xh_tensor.dims(), \".\"));\n+    OP_REQUIRES(ctx, i_tensor->dims() == 2,\n+                errors::InvalidArgument(\"i_tensor must be rank 2 but is rank \",\n+                                        i_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, cs_tensor->dims() == 2,\n+                errors::InvalidArgument(\"cs_tensor must be rank 2 but is rank \",\n+                                        cs_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, f_tensor->dims() == 2,\n+                errors::InvalidArgument(\"f_tensor must be rank 2 but is rank \",\n+                                        f_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, o_tensor->dims() == 2,\n+                errors::InvalidArgument(\"o_tensor must be rank 2 but is rank \",\n+                                        o_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, ci_tensor->dims() == 2,\n+                errors::InvalidArgument(\"ci_tensor must be rank 2 but is rank \",\n+                                        ci_tensor->dims(), \".\"));\n+    OP_REQUIRES(ctx, co_tensor->dims() == 2,\n+                errors::InvalidArgument(\"co_tensor must be rank 2 but is rank \",\n+                                        co_tensor->dims(), \".\"));\n+    OP_REQUIRES(\n+        ctx, gates_tensor.dims() == 2,\n+        errors::InvalidArgument(\"gates_tensor must be rank 2 but is rank \",\n+                                gates_tensor.dims(), \".\"));\n+    OP_REQUIRES(ctx, h_tensor->dims() == 2,\n+                errors::InvalidArgument(\"h_tensor must be rank 2 but is rank \",\n+                                        h_tensor->dims(), \".\"));\n+\n     functor::LSTMBlockCellFprop<Device, T, USE_CUBLAS, gate_layout>(\n         batch_size, input_size, cell_size)(\n         ctx, device, forget_bias_, cell_clip_, use_peephole_,\ndiff --git a/tensorflow/python/kernel_tests/nn_ops/rnn_cell_test.py b/tensorflow/python/kernel_tests/nn_ops/rnn_cell_test.py\nindex 438211f0cb71fa..bed3cbfd8aa2a9 100644\n--- a/tensorflow/python/kernel_tests/nn_ops/rnn_cell_test.py\n+++ b/tensorflow/python/kernel_tests/nn_ops/rnn_cell_test.py\n@@ -33,6 +33,7 @@\n from tensorflow.python.framework import test_util\n from tensorflow.python.ops import   array_ops\n from tensorflow.python.ops import control_flow_ops\n+from tensorflow.python.ops import gen_rnn_ops\n from tensorflow.python.ops import gradients_impl\n from tensorflow.python.ops import init_ops\n from tensorflow.python.ops import math_ops\n@@ -1323,6 +1324,36 @@ def testDynamicEquivalentToStaticRNN(self):\n   def testDynamicEquivalentToStaticRNNWithSequenceLength(self):\n     self._testDynamicEquivalentToStaticRNN(use_sequence_length=True)\n \n+  @test_util.run_in_graph_and_eager_modes\n+  def testLSTMBlockCellErrorHandling(self):\n+    forget_bias = 1\n+    cell_clip = 0\n+    use_peephole = False\n+    x = constant_op.constant(0.837607, shape=[28, 29], dtype=dtypes.float32)\n+    cs_prev = constant_op.constant(0, shape=[28, 17], dtype=dtypes.float32)\n+    h_prev = constant_op.constant(\n+        0.592631638, shape=[28, 17], dtype=dtypes.float32)\n+    w = constant_op.constant(0.887386262, shape=[46, 68], dtype=dtypes.float32)\n+    wci = constant_op.constant(0, shape=[], dtype=dtypes.float32)\n+    wcf = constant_op.constant(0, shape=[17], dtype=dtypes.float32)\n+    wco = constant_op.constant(\n+        0.592631638, shape=[28, 17], dtype=dtypes.float32)\n+    b = constant_op.constant(0.75259006, shape=[68], dtype=dtypes.float32)\n+    with self.assertRaises(errors_impl.InvalidArgumentError):\n+      self.evaluate(\n+          gen_rnn_ops.lstm_block_cell(\n+              x=x,\n+              cs_prev=cs_prev,\n+              h_prev=h_prev,\n+              w=w,\n+              wci=wci,\n+              wcf=wcf,\n+              wco=wco,\n+              b=b,\n+              forget_bias=forget_bias,\n+              cell_clip=cell_clip,\n+              use_peephole=use_peephole))\n+\n \n class BidirectionalRNNTest(test.TestCase):\n \n",
        "label": 1,
        "partition": "test"
    },
    {
        "commit_id": "0fb2c031ce0ace07cc19cd2cb2143c4b5a63c9dd",
        "repo": "troglobit/uftpd",
        "msg": "FTP: Fix buffer overflow in PORT parser, reported by Aaron Esau\n\nSigned-off-by: Joachim Nilsson <troglobit@gmail.com>An unauthenticated stack-based buffer overflow vulnerability in common.c's handle_PORT in uftpd FTP server versions 2.10 and earlier can be abused to cause a crash and could potentially lead to remote code execution.",
        "filename": "ftpcmd.c",
        "diff": "diff --git a/src/ftpcmd.c b/src/ftpcmd.c\nindex b318711..34686a4 100644\n--- a/src/ftpcmd.c\n+++ b/src/ftpcmd.c\n@@ -441,7 +441,7 @@ static void handle_PORT(ctrl_t *ctrl, char *str)\n \n \t/* Convert PORT command's argument to IP address + port */\n \tsscanf(str, \"%d,%d,%d,%d,%d,%d\", &a, &b, &c, &d, &e, &f);\n-\tsprintf(addr, \"%d.%d.%d.%d\", a, b, c, d);\n+\tsnprintf(addr, sizeof(addr), \"%d.%d.%d.%d\", a, b, c, d);\n \n \t/* Check IPv4 address using inet_aton(), throw away converted result */\n \tif (!inet_aton(addr, &(sin.sin_addr))) {\n",
        "label": 0,
        "partition": "test"
    },
    {
        "commit_id": "3cf291f72224715942beaf8553e42ba8891ab3c6",
        "repo": "mruby/mruby",
        "msg": "vm.c: create break object before clearing GC arena.\n\nOtherwise it possibly cause use-after-free.Use-After-Free in str_escape in mruby/mruby in GitHub repository mruby/mruby prior to 3.2. Possible arbitrary code execution if being exploited.",
        "filename": "vm.c",
        "diff": "diff --git a/src/vm.c b/src/vm.c\nindex 3796f41738..6d61386b31 100644\n--- a/src/vm.c\n+++ b/src/vm.c\n@@ -2268,9 +2268,9 @@ mrb_vm_exec(mrb_state *mrb, const struct RProc *proc, const mrb_code *pc)\n           }\n           if (ci->cci > CINFO_NONE) {\n             ci = cipop(mrb);\n+            mrb->exc = (struct RObject*)break_new(mrb, RBREAK_TAG_BREAK, proc, v);\n             mrb_gc_arena_restore(mrb, ai);\n             mrb->c->vmexec = FALSE;\n-            mrb->exc = (struct RObject*)break_new(mrb, RBREAK_TAG_BREAK, proc, v);\n             mrb->jmp = prev_jmp;\n             MRB_THROW(prev_jmp);\n           }\n",
        "label": 1,
        "partition": "test"
    },
    {
        "commit_id": "450baca94f475345542c6953832650c390889202",
        "repo": "pjsip/pjproject",
        "msg": "Merge pull request from GHSA-26j7-ww69-c4qjPJSIP is a free and open source multimedia communication library written in C language implementing standard based protocols such as SIP, SDP, RTP, STUN, TURN, and ICE. In versions prior to and including 2.12.1 a stack buffer overflow vulnerability affects PJSIP users that use STUN in their applications, either by: setting a STUN server in their account/media config in PJSUA/PJSUA2 level, or directly using `pjlib-util/stun_simple` API. A patch is available in commit 450baca which should be included in the next release. There are no known workarounds for this issue.",
        "filename": "stun_simple.c",
        "diff": "diff --git a/pjlib-util/src/pjlib-util/stun_simple.c b/pjlib-util/src/pjlib-util/stun_simple.c\nindex 7225195846..d0549176dd 100644\n--- a/pjlib-util/src/pjlib-util/stun_simple.c\n+++ b/pjlib-util/src/pjlib-util/stun_simple.c\n@@ -54,6 +54,7 @@ PJ_DEF(pj_status_t) pjstun_parse_msg( void *buf, pj_size_t buf_len,\n {\n     pj_uint16_t msg_type, msg_len;\n     char *p_attr;\n+    int attr_max_cnt = PJ_ARRAY_SIZE(msg->attr);\n \n     PJ_CHECK_STACK();\n \n@@ -83,7 +84,7 @@ PJ_DEF(pj_status_t) pjstun_parse_msg( void *buf, pj_size_t buf_len,\n     msg->attr_count = 0;\n     p_attr = (char*)buf + sizeof(pjstun_msg_hdr);\n \n-    while (msg_len > 0) {\n+    while (msg_len > 0 && msg->attr_count < attr_max_cnt) {\n \tpjstun_attr_hdr **attr = &msg->attr[msg->attr_count];\n \tpj_uint32_t len;\n \tpj_uint16_t attr_type;\n@@ -111,6 +112,10 @@ PJ_DEF(pj_status_t) pjstun_parse_msg( void *buf, pj_size_t buf_len,\n \tp_attr += len;\n \t++msg->attr_count;\n     }\n+    if (msg->attr_count == attr_max_cnt) {\n+\tPJ_LOG(4, (THIS_FILE, \"Warning: max number attribute %d reached.\",\n+\t\t   attr_max_cnt));\n+    }\n \n     return PJ_SUCCESS;\n }\n",
        "label": 1,
        "partition": "test"
    },
    {
        "commit_id": "a989426ee1346693cc015792f11d715f6944f2b8",
        "repo": "tensorflow/tensorflow",
        "msg": "Improve to cover scale value greater than one\n\nPiperOrigin-RevId: 433050921TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, certain TFLite models that were created using TFLite model converter would crash when loaded in the TFLite interpreter. The culprit is that during quantization the scale of values could be greater than 1 but code was always assuming sub-unit scaling. Thus, since code was calling `QuantizeMultiplierSmallerThanOneExp`, the `TFLITE_CHECK_LT` assertion would trigger and abort the process. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.",
        "filename": "comparisons.cc",
        "diff": "diff --git a/tensorflow/lite/kernels/comparisons.cc b/tensorflow/lite/kernels/comparisons.cc\nindex d0a1876c5c654f..c3824c1db01706 100644\n--- a/tensorflow/lite/kernels/comparisons.cc\n+++ b/tensorflow/lite/kernels/comparisons.cc\n@@ -81,6 +81,17 @@ TfLiteStatus ComparisonPrepareStringAllowed(TfLiteContext* context,\n   return ComparisonPrepareCommon(context, node, true);\n }\n \n+void QuantizeMultiplier(double double_multiplier, int32_t* quantized_multiplier,\n+                        int* left_shift) {\n+  if (double_multiplier < 1.0) {\n+    QuantizeMultiplierSmallerThanOneExp(double_multiplier, quantized_multiplier,\n+                                        left_shift);\n+  } else {\n+    QuantizeMultiplierGreaterThanOne(double_multiplier, quantized_multiplier,\n+                                     left_shift);\n+  }\n+}\n+\n template <typename input_dtype, reference_ops::ComparisonFn<int32> opname>\n void ComparisonQuantized(const TfLiteTensor* input1, const TfLiteTensor* input2,\n                          TfLiteTensor* output, bool requires_broadcast) {\n@@ -90,13 +101,11 @@ void ComparisonQuantized(const TfLiteTensor* input1, const TfLiteTensor* input2,\n     const int left_shift = 8;\n \n     int32 input1_multiplier;\n-    int input1_shift;\n-    QuantizeMultiplierSmallerThanOneExp(input1->params.scale,\n-                                        &input1_multiplier, &input1_shift);\n     int32 input2_multiplier;\n+    int input1_shift;\n     int input2_shift;\n-    QuantizeMultiplierSmallerThanOneExp(input2->params.scale,\n-                                        &input2_multiplier, &input2_shift);\n+    QuantizeMultiplier(input1->params.scale, &input1_multiplier, &input1_shift);\n+    QuantizeMultiplier(input2->params.scale, &input2_multiplier, &input2_shift);\n \n     ComparisonParams op_params;\n     op_params.left_shift = left_shift;\ndiff --git a/tensorflow/lite/kernels/comparisons_test.cc b/tensorflow/lite/kernels/comparisons_test.cc\nindex f8cf6dee74c4bf..074d0f1f61513a 100644\n--- a/tensorflow/lite/kernels/comparisons_test.cc\n+++ b/tensorflow/lite/kernels/comparisons_test.cc\n@@ -653,6 +653,26 @@ TEST(ComparisonsTest, QuantizedInt8GreaterWithBroadcast) {\n   }\n }\n \n+TEST(ComparisonsTest,\n+     QuantizedInt8GreaterWithBroadcastMultiplierGreaterThanOne) {\n+  const float kMin = -127.f;\n+  const float kMax = 127.f;\n+  std::vector<std::vector<int>> test_shapes = {\n+      {6}, {2, 3}, {2, 1, 3}, {1, 3, 1, 2}};\n+  for (int i = 0; i < test_shapes.size(); ++i) {\n+    ComparisonOpModel model({TensorType_INT8, test_shapes[i], kMin, kMax},\n+                            {TensorType_INT8, {}, kMin, kMax}, TensorType_INT8,\n+                            BuiltinOperator_GREATER);\n+    model.QuantizeAndPopulate<int8_t>(model.input1(),\n+                                      {572, -2, -71, 8, 11, 20});\n+    model.QuantizeAndPopulate<int8_t>(model.input2(), {8});\n+    model.Invoke();\n+    EXPECT_THAT(model.GetOutput(),\n+                ElementsAre(true, false, false, false, true, true))\n+        << \"With shape number \" << i;\n+  }\n+}\n+\n TEST(ComparisonsTest, QuantizedUInt8GreaterEqualWithBroadcast) {\n   const float kMin = -1.f;\n   const float kMax = 128.f;\n",
        "label": 1,
        "partition": "test"
    },
    {
        "commit_id": "6a07c2156a07ef307b6dcf3c2ca8571a5f1af7a6",
        "repo": "nginx/njs",
        "msg": "Fixed recursive async function calls.\n\nPreviously, PromiseCapability record was stored (function->context)\ndirectly in function object during a function invocation.  This is\nnot correct, because PromiseCapability record should be linked to\ncurrent execution context.  As a result, function->context is\noverwritten with consecutive recursive calls which results in\nuse-after-free.\n\nThis closes #451 issue on Github.njs through 0.7.0, used in NGINX, was discovered to contain a heap use-after-free in njs_await_fulfilled.",
        "filename": "njs_async.c",
        "diff": "diff --git a/src/njs_async.c b/src/njs_async.c\nindex 7bc6c37e7..e4dd74863 100644\n--- a/src/njs_async.c\n+++ b/src/njs_async.c\n@@ -29,9 +29,7 @@ njs_async_function_frame_invoke(njs_vm_t *vm, njs_value_t *retval)\n         return NJS_ERROR;\n     }\n \n-    frame->function->context = capability;\n-\n-    ret = njs_function_lambda_call(vm);\n+    ret = njs_function_lambda_call(vm, capability, NULL);\n \n     if (ret == NJS_OK) {\n         ret = njs_function_call(vm, njs_function(&capability->resolve),\n@@ -63,7 +61,6 @@ njs_await_fulfilled(njs_vm_t *vm, njs_value_t *args, njs_uint_t nargs,\n     njs_int_t           ret;\n     njs_value_t         **cur_local, **cur_closures, **cur_temp, *value;\n     njs_frame_t         *frame, *async_frame;\n-    njs_function_t      *function;\n     njs_async_ctx_t     *ctx;\n     njs_native_frame_t  *top, *async;\n \n@@ -78,8 +75,6 @@ njs_await_fulfilled(njs_vm_t *vm, njs_value_t *args, njs_uint_t nargs,\n     async = &async_frame->native;\n     async->previous = vm->top_frame;\n \n-    function = async->function;\n-\n     cur_local = vm->levels[NJS_LEVEL_LOCAL];\n     cur_closures = vm->levels[NJS_LEVEL_CLOSURE];\n     cur_temp = vm->levels[NJS_LEVEL_TEMP];\n@@ -98,13 +93,7 @@ njs_await_fulfilled(njs_vm_t *vm, njs_value_t *args, njs_uint_t nargs,\n \n     vm->top_frame->retval = &vm->retval;\n \n-    function->context = ctx->capability;\n-    function->await = ctx;\n-\n-    ret = njs_vmcode_interpreter(vm, ctx->pc);\n-\n-    function->context = NULL;\n-    function->await = NULL;\n+    ret = njs_vmcode_interpreter(vm, ctx->pc, ctx->capability, ctx);\n \n     vm->levels[NJS_LEVEL_LOCAL] = cur_local;\n     vm->levels[NJS_LEVEL_CLOSURE] = cur_closures;\ndiff --git a/src/njs_function.c b/src/njs_function.c\nindex ae0fa11ff..5f07ddd9c 100644\n--- a/src/njs_function.c\n+++ b/src/njs_function.c\n@@ -608,7 +608,7 @@ njs_function_call2(njs_vm_t *vm, njs_function_t *function,\n \n \n njs_int_t\n-njs_function_lambda_call(njs_vm_t *vm)\n+njs_function_lambda_call(njs_vm_t *vm, void *promise_cap, void *async_ctx)\n {\n     uint32_t               n;\n     njs_int_t              ret;\n@@ -622,6 +622,8 @@ njs_function_lambda_call(njs_vm_t *vm)\n     frame = (njs_frame_t *) vm->top_frame;\n     function = frame->native.function;\n \n+    njs_assert(function->context == NULL);\n+\n     if (function->global && !function->closure_copied) {\n         ret = njs_function_capture_global_closures(vm, function);\n         if (njs_slow_path(ret != NJS_OK)) {\n@@ -698,7 +700,7 @@ njs_function_lambda_call(njs_vm_t *vm)\n         }\n     }\n \n-    ret = njs_vmcode_interpreter(vm, lambda->start);\n+    ret = njs_vmcode_interpreter(vm, lambda->start, promise_cap, async_ctx);\n \n     /* Restore current level. */\n     vm->levels[NJS_LEVEL_LOCAL] = cur_local;\n@@ -775,7 +777,7 @@ njs_function_frame_invoke(njs_vm_t *vm, njs_value_t *retval)\n         return njs_function_native_call(vm);\n \n     } else {\n-        return njs_function_lambda_call(vm);\n+        return njs_function_lambda_call(vm, NULL, NULL);\n     }\n }\n \ndiff --git a/src/njs_function.h b/src/njs_function.h\nindex b47e7dc6a..59150fdd5 100644\n--- a/src/njs_function.h\n+++ b/src/njs_function.h\n@@ -112,7 +112,8 @@ njs_int_t njs_function_lambda_frame(njs_vm_t *vm, njs_function_t *function,\n njs_int_t njs_function_call2(njs_vm_t *vm, njs_function_t *function,\n     const njs_value_t *this, const njs_value_t *args,\n     njs_uint_t nargs, njs_value_t *retval, njs_bool_t ctor);\n-njs_int_t njs_function_lambda_call(njs_vm_t *vm);\n+njs_int_t njs_function_lambda_call(njs_vm_t *vm, void *promise_cap,\n+    void *async_ctx);\n njs_int_t njs_function_native_call(njs_vm_t *vm);\n njs_native_frame_t *njs_function_frame_alloc(njs_vm_t *vm, size_t size);\n void njs_function_frame_free(njs_vm_t *vm, njs_native_frame_t *frame);\ndiff --git a/src/njs_value.h b/src/njs_value.h\nindex 12448eacd..7297df395 100644\n--- a/src/njs_value.h\n+++ b/src/njs_value.h\n@@ -270,7 +270,6 @@ struct njs_function_s {\n     } u;\n \n     void                              *context;\n-    void                              *await;\n \n     njs_value_t                       *bound;\n };\ndiff --git a/src/njs_vm.c b/src/njs_vm.c\nindex b46f88c62..0c75fff71 100644\n--- a/src/njs_vm.c\n+++ b/src/njs_vm.c\n@@ -490,7 +490,7 @@ njs_vm_start(njs_vm_t *vm)\n         return ret;\n     }\n \n-    ret = njs_vmcode_interpreter(vm, vm->start);\n+    ret = njs_vmcode_interpreter(vm, vm->start, NULL, NULL);\n \n     return (ret == NJS_ERROR) ? NJS_ERROR : NJS_OK;\n }\ndiff --git a/src/njs_vmcode.c b/src/njs_vmcode.c\nindex b371c3748..3039642cb 100644\n--- a/src/njs_vmcode.c\n+++ b/src/njs_vmcode.c\n@@ -42,7 +42,8 @@ static njs_jump_off_t njs_vmcode_debugger(njs_vm_t *vm);\n static njs_jump_off_t njs_vmcode_return(njs_vm_t *vm, njs_value_t *invld,\n     njs_value_t *retval);\n \n-static njs_jump_off_t njs_vmcode_await(njs_vm_t *vm, njs_vmcode_await_t *await);\n+static njs_jump_off_t njs_vmcode_await(njs_vm_t *vm, njs_vmcode_await_t *await,\n+    njs_promise_capability_t *pcap, njs_async_ctx_t *actx);\n \n static njs_jump_off_t njs_vmcode_try_start(njs_vm_t *vm, njs_value_t *value,\n     njs_value_t *offset, u_char *pc);\n@@ -77,7 +78,8 @@ static njs_jump_off_t njs_function_frame_create(njs_vm_t *vm,\n \n \n njs_int_t\n-njs_vmcode_interpreter(njs_vm_t *vm, u_char *pc)\n+njs_vmcode_interpreter(njs_vm_t *vm, u_char *pc, void *promise_cap,\n+    void *async_ctx)\n {\n     u_char                       *catch;\n     double                       num, exponent;\n@@ -826,7 +828,7 @@ njs_vmcode_interpreter(njs_vm_t *vm, u_char *pc)\n \n             case NJS_VMCODE_AWAIT:\n                 await = (njs_vmcode_await_t *) pc;\n-                return njs_vmcode_await(vm, await);\n+                return njs_vmcode_await(vm, await, promise_cap, async_ctx);\n \n             case NJS_VMCODE_TRY_START:\n                 ret = njs_vmcode_try_start(vm, value1, value2, pc);\n@@ -1812,7 +1814,8 @@ njs_vmcode_return(njs_vm_t *vm, njs_value_t *invld, njs_value_t *retval)\n \n \n static njs_jump_off_t\n-njs_vmcode_await(njs_vm_t *vm, njs_vmcode_await_t *await)\n+njs_vmcode_await(njs_vm_t *vm, njs_vmcode_await_t *await,\n+    njs_promise_capability_t *pcap, njs_async_ctx_t *ctx)\n {\n     size_t              size;\n     njs_int_t           ret;\n@@ -1820,7 +1823,6 @@ njs_vmcode_await(njs_vm_t *vm, njs_vmcode_await_t *await)\n     njs_value_t         ctor, val, on_fulfilled, on_rejected, *value;\n     njs_promise_t       *promise;\n     njs_function_t      *fulfilled, *rejected;\n-    njs_async_ctx_t     *ctx;\n     njs_native_frame_t  *active;\n \n     active = &vm->active_frame->native;\n@@ -1837,8 +1839,6 @@ njs_vmcode_await(njs_vm_t *vm, njs_vmcode_await_t *await)\n         return NJS_ERROR;\n     }\n \n-    ctx = active->function->await;\n-\n     if (ctx == NULL) {\n         ctx = njs_mp_alloc(vm->mem_pool, sizeof(njs_async_ctx_t));\n         if (njs_slow_path(ctx == NULL)) {\n@@ -1854,9 +1854,7 @@ njs_vmcode_await(njs_vm_t *vm, njs_vmcode_await_t *await)\n         }\n \n         ctx->await = fulfilled->context;\n-        ctx->capability = active->function->context;\n-\n-        active->function->context = NULL;\n+        ctx->capability = pcap;\n \n         ret = njs_function_frame_save(vm, ctx->await, NULL);\n         if (njs_slow_path(ret != NJS_OK)) {\ndiff --git a/src/njs_vmcode.h b/src/njs_vmcode.h\nindex c15a4bd9e..6b8f65582 100644\n--- a/src/njs_vmcode.h\n+++ b/src/njs_vmcode.h\n@@ -437,7 +437,8 @@ typedef struct {\n } njs_vmcode_await_t;\n \n \n-njs_int_t njs_vmcode_interpreter(njs_vm_t *vm, u_char *pc);\n+njs_int_t njs_vmcode_interpreter(njs_vm_t *vm, u_char *pc,\n+    void *promise_cap, void *async_ctx);\n \n njs_object_t *njs_function_new_object(njs_vm_t *vm, njs_value_t *constructor);\n \ndiff --git a/test/js/async_recursive_last.t.js b/test/js/async_recursive_last.t.js\nnew file mode 100644\nindex 000000000..84f1b5792\n--- /dev/null\n+++ b/test/js/async_recursive_last.t.js\n@@ -0,0 +1,26 @@\n+/*---\n+includes: [compareArray.js]\n+flags: [async]\n+---*/\n+\n+let stages = [];\n+\n+async function f(v) {\n+    if (v == 3) {\n+        return;\n+    }\n+\n+    stages.push(`f>${v}`);\n+\n+    f(v + 1);\n+\n+    stages.push(`f<${v}`);\n+\n+    await \"X\";\n+}\n+\n+f(0)\n+.then(v => {\n+    assert.compareArray(stages, ['f>0', 'f>1', 'f>2', 'f<2', 'f<1', 'f<0']);\n+})\n+.then($DONE, $DONE);\ndiff --git a/test/js/async_recursive_mid.t.js b/test/js/async_recursive_mid.t.js\nnew file mode 100644\nindex 000000000..4d3a9fd19\n--- /dev/null\n+++ b/test/js/async_recursive_mid.t.js\n@@ -0,0 +1,26 @@\n+/*---\n+includes: [compareArray.js]\n+flags: [async]\n+---*/\n+\n+let stages = [];\n+\n+async function f(v) {\n+    if (v == 3) {\n+        return;\n+    }\n+\n+    stages.push(`f>${v}`);\n+\n+    await \"X\";\n+\n+    f(v + 1);\n+\n+    stages.push(`f<${v}`);\n+}\n+\n+f(0)\n+.then(v => {\n+    assert.compareArray(stages, ['f>0','f>1','f<0','f>2','f<1']);\n+})\n+.then($DONE, $DONE);\n",
        "label": 1,
        "partition": "test"
    },
    {
        "commit_id": "1b5f5cea5145c96dd8791b9b2c41424fc74c2172",
        "repo": "kmackay/micro-ecc",
        "msg": "Fix for #168The ECDSA operation of the micro-ecc library 1.0 is vulnerable to simple power analysis attacks which allows an adversary to extract the private ECC key.",
        "filename": "uECC.c",
        "diff": "diff --git a/uECC.c b/uECC.c\nindex c08b7ac..17c0f6f 100644\n--- a/uECC.c\n+++ b/uECC.c\n@@ -1210,7 +1210,7 @@ static void bits2int(uECC_word_t *native,\n     bcopy((uint8_t *) native, bits, bits_size);\n #else\n     uECC_vli_bytesToNative(native, bits, bits_size);\n-#endif    \n+#endif\n     if (bits_size * 8 <= (unsigned)curve->num_n_bits) {\n         return;\n     }\n@@ -1239,6 +1239,7 @@ static int uECC_sign_with_k(const uint8_t *private_key,\n     uECC_word_t tmp[uECC_MAX_WORDS];\n     uECC_word_t s[uECC_MAX_WORDS];\n     uECC_word_t *k2[2] = {tmp, s};\n+    uECC_word_t *initial_Z = 0;\n #if uECC_VLI_NATIVE_LITTLE_ENDIAN\n     uECC_word_t *p = (uECC_word_t *)signature;\n #else\n@@ -1255,7 +1256,15 @@ static int uECC_sign_with_k(const uint8_t *private_key,\n     }\n \n     carry = regularize_k(k, tmp, s, curve);\n-    EccPoint_mult(p, curve->G, k2[!carry], 0, num_n_bits + 1, curve);\n+    /* If an RNG function was specified, try to get a random initial Z value to improve\n+       protection against side-channel attacks. */\n+    if (g_rng_function) {\n+        if (!uECC_generate_random_int(k2[carry], curve->p, num_words)) {\n+            return 0;\n+        }\n+        initial_Z = k2[carry];\n+    }\n+    EccPoint_mult(p, curve->G, k2[!carry], initial_Z, num_n_bits + 1, curve);\n     if (uECC_vli_isZero(p, num_words)) {\n         return 0;\n     }\n@@ -1299,7 +1308,7 @@ static int uECC_sign_with_k(const uint8_t *private_key,\n     bcopy((uint8_t *) signature + curve->num_bytes, (uint8_t *) s, curve->num_bytes);\n #else\n     uECC_vli_nativeToBytes(signature + curve->num_bytes, curve->num_bytes, s);\n-#endif    \n+#endif\n     return 1;\n }\n \n@@ -1472,7 +1481,7 @@ int uECC_verify(const uint8_t *public_key,\n     uECC_word_t *_public = (uECC_word_t *)public_key;\n #else\n     uECC_word_t _public[uECC_MAX_WORDS * 2];\n-#endif    \n+#endif\n     uECC_word_t r[uECC_MAX_WORDS], s[uECC_MAX_WORDS];\n     wordcount_t num_words = curve->num_words;\n     wordcount_t num_n_words = BITS_TO_WORDS(curve->num_n_bits);\n",
        "label": 1,
        "partition": "test"
    },
    {
        "commit_id": "00acae117da1b45b318dc36531a7b0021b8097ae",
        "repo": "mruby/mruby",
        "msg": "vm.c: target class may be NULL.NULL Pointer Dereference in mrb_vm_exec with super in GitHub repository mruby/mruby prior to 3.2. This vulnerability is capable of making the mruby interpreter crash, thus affecting the availability of the system.",
        "filename": "vm.c",
        "diff": "diff --git a/src/vm.c b/src/vm.c\nindex 77edbb38fc..3bb9510ec1 100644\n--- a/src/vm.c\n+++ b/src/vm.c\n@@ -1749,7 +1749,7 @@ mrb_vm_exec(mrb_state *mrb, const struct RProc *proc, const mrb_code *pc)\n       }\n       else if (target_class->tt == MRB_TT_MODULE) {\n         target_class = mrb_vm_ci_target_class(ci);\n-        if (target_class->tt != MRB_TT_ICLASS) {\n+        if (!target_class || target_class->tt != MRB_TT_ICLASS) {\n           goto super_typeerror;\n         }\n       }\n",
        "label": 0,
        "partition": "test"
    },
    {
        "commit_id": "5ecec9c6fbdbc6be03295685190a45e7eee726ab",
        "repo": "tensorflow/tensorflow",
        "msg": "Prevent use after free.\n\nA very old version of the code used `result` as a simple pointer to a resource. Two years later, the pointer got changed to a `unique_ptr` but author forgot to remove the call to `Unref`. Three years after that, we finally uncover the UAF.\n\nPiperOrigin-RevId: 387924872\nChange-Id: I70fb6f199164de49fac20c168132a07b84903f9bTensorFlow is an end-to-end open source platform for machine learning. In affected versions the implementation for `tf.raw_ops.BoostedTreesCreateEnsemble` can result in a use after free error if an attacker supplies specially crafted arguments. The [implementation](https://github.com/tensorflow/tensorflow/blob/f24faa153ad31a4b51578f8181d3aaab77a1ddeb/tensorflow/core/kernels/boosted_trees/resource_ops.cc#L55) uses a reference counted resource and decrements the refcount if the initialization fails, as it should. However, when the code was written, the resource was represented as a naked pointer but later refactoring has changed it to be a smart pointer. Thus, when the pointer leaves the scope, a subsequent `free`-ing of the resource occurs, but this fails to take into account that the refcount has already reached 0, thus the resource has been already freed. During this double-free process, members of the resource object are accessed for cleanup but they are invalid as the entire resource has been freed. We have patched the issue in GitHub commit 5ecec9c6fbdbc6be03295685190a45e7eee726ab. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "filename": "resource_ops.cc",
        "diff": "diff --git a/tensorflow/core/kernels/boosted_trees/resource_ops.cc b/tensorflow/core/kernels/boosted_trees/resource_ops.cc\nindex d50885fa3f5113..f2c60b9b4511de 100644\n--- a/tensorflow/core/kernels/boosted_trees/resource_ops.cc\n+++ b/tensorflow/core/kernels/boosted_trees/resource_ops.cc\n@@ -53,6 +53,7 @@ class BoostedTreesCreateEnsembleOp : public OpKernel {\n     if (!result->InitFromSerialized(\n             tree_ensemble_serialized_t->scalar<tstring>()(), stamp_token)) {\n       result->Unref();\n+      result.release();  // Needed due to the `->Unref` above, to prevent UAF\n       OP_REQUIRES(\n           context, false,\n           errors::InvalidArgument(\"Unable to parse tree ensemble proto.\"));\n",
        "label": 1,
        "partition": "test"
    },
    {
        "commit_id": "8f8c04bf1ebbd2f72f1643e7ad9617dafa6e5409",
        "repo": "u-boot/u-boot",
        "msg": "i2c: fix stack buffer overflow vulnerability in i2c md command\n\nWhen running \"i2c md 0 0 80000100\", the function do_i2c_md parses the\nlength into an unsigned int variable named length. The value is then\nmoved to a signed variable:\n\n    int nbytes = length;\n    #define DISP_LINE_LEN 16\n    int linebytes = (nbytes > DISP_LINE_LEN) ? DISP_LINE_LEN : nbytes;\n    ret = dm_i2c_read(dev, addr, linebuf, linebytes);\n\nOn systems where integers are 32 bits wide, 0x80000100 is a negative\nvalue to \"nbytes > DISP_LINE_LEN\" is false and linebytes gets assigned\n0x80000100 instead of 16.\n\nThe consequence is that the function which reads from the i2c device\n(dm_i2c_read or i2c_read) is called with a 16-byte stack buffer to fill\nbut with a size parameter which is too large. In some cases, this could\ntrigger a crash. But with some i2c drivers, such as drivers/i2c/nx_i2c.c\n(used with \"nexell,s5pxx18-i2c\" bus), the size is actually truncated to\na 16-bit integer. This is because function i2c_transfer expects an\nunsigned short length. In such a case, an attacker who can control the\nresponse of an i2c device can overwrite the return address of a function\nand execute arbitrary code through Return-Oriented Programming.\n\nFix this issue by using unsigned integers types in do_i2c_md. While at\nit, make also alen unsigned, as signed sizes can cause vulnerabilities\nwhen people forgot to check that they can be negative.\n\nSigned-off-by: Nicolas Iooss <nicolas.iooss+uboot@ledger.fr>\nReviewed-by: Heiko Schocher <hs@denx.de>In Das U-Boot through 2022.07-rc5, an integer signedness error and resultant stack-based buffer overflow in the \"i2c md\" command enables the corruption of the return address pointer of the do_i2c_md function.",
        "filename": "i2c.c",
        "diff": "diff --git a/cmd/i2c.c b/cmd/i2c.c\nindex 9050b2b8d27a..bd04b14024be 100644\n--- a/cmd/i2c.c\n+++ b/cmd/i2c.c\n@@ -200,10 +200,10 @@ void i2c_init_board(void)\n  *\n  * Returns the address length.\n  */\n-static uint get_alen(char *arg, int default_len)\n+static uint get_alen(char *arg, uint default_len)\n {\n-\tint\tj;\n-\tint\talen;\n+\tuint\tj;\n+\tuint\talen;\n \n \talen = default_len;\n \tfor (j = 0; j < 8; j++) {\n@@ -247,7 +247,7 @@ static int do_i2c_read(struct cmd_tbl *cmdtp, int flag, int argc,\n {\n \tuint\tchip;\n \tuint\tdevaddr, length;\n-\tint alen;\n+\tuint\talen;\n \tu_char  *memaddr;\n \tint ret;\n #if CONFIG_IS_ENABLED(DM_I2C)\n@@ -301,7 +301,7 @@ static int do_i2c_write(struct cmd_tbl *cmdtp, int flag, int argc,\n {\n \tuint\tchip;\n \tuint\tdevaddr, length;\n-\tint alen;\n+\tuint\talen;\n \tu_char  *memaddr;\n \tint ret;\n #if CONFIG_IS_ENABLED(DM_I2C)\n@@ -469,8 +469,8 @@ static int do_i2c_md(struct cmd_tbl *cmdtp, int flag, int argc,\n {\n \tuint\tchip;\n \tuint\taddr, length;\n-\tint alen;\n-\tint\tj, nbytes, linebytes;\n+\tuint\talen;\n+\tuint\tj, nbytes, linebytes;\n \tint ret;\n #if CONFIG_IS_ENABLED(DM_I2C)\n \tstruct udevice *dev;\n@@ -589,9 +589,9 @@ static int do_i2c_mw(struct cmd_tbl *cmdtp, int flag, int argc,\n {\n \tuint\tchip;\n \tulong\taddr;\n-\tint\talen;\n+\tuint\talen;\n \tuchar\tbyte;\n-\tint\tcount;\n+\tuint\tcount;\n \tint ret;\n #if CONFIG_IS_ENABLED(DM_I2C)\n \tstruct udevice *dev;\n@@ -676,8 +676,8 @@ static int do_i2c_crc(struct cmd_tbl *cmdtp, int flag, int argc,\n {\n \tuint\tchip;\n \tulong\taddr;\n-\tint\talen;\n-\tint\tcount;\n+\tuint\talen;\n+\tuint\tcount;\n \tuchar\tbyte;\n \tulong\tcrc;\n \tulong\terr;\n@@ -985,7 +985,7 @@ static int do_i2c_loop(struct cmd_tbl *cmdtp, int flag, int argc,\n \t\t       char *const argv[])\n {\n \tuint\tchip;\n-\tint alen;\n+\tuint\talen;\n \tuint\taddr;\n \tuint\tlength;\n \tu_char\tbytes[16];\n",
        "label": 1,
        "partition": "test"
    },
    {
        "commit_id": "7df766124f87768b43b9e8947c5a01e17545772c",
        "repo": "gost-engine/engine",
        "msg": "Fix buffer overrun in creating key transport blob according to RFC 9189, 4.2.4.2\n\nResolves: CVE-2022-29242GOST engine is a reference implementation of the Russian GOST crypto algorithms for OpenSSL. TLS clients using GOST engine when ciphersuite `TLS_GOSTR341112_256_WITH_KUZNYECHIK_CTR_OMAC` is agreed and the server uses 512 bit GOST secret keys are vulnerable to buffer overflow. GOST engine version 3.0.1 contains a patch for this issue. Disabling ciphersuite `TLS_GOSTR341112_256_WITH_KUZNYECHIK_CTR_OMAC` is a possible workaround.",
        "filename": "gost_ec_keyx.c",
        "diff": "diff --git a/gost_ec_keyx.c b/gost_ec_keyx.c\nindex 5e677dc2..192b8922 100644\n--- a/gost_ec_keyx.c\n+++ b/gost_ec_keyx.c\n@@ -292,6 +292,8 @@ static int pkey_GOST_ECcp_encrypt(EVP_PKEY_CTX *pctx, unsigned char *out,\n     int key_is_ephemeral = 1;\n     gost_ctx cctx;\n     EVP_PKEY *sec_key = EVP_PKEY_CTX_get0_peerkey(pctx);\n+    int res_len = 0;\n+\n     if (data->shared_ukm_size) {\n         memcpy(ukm, data->shared_ukm, 8);\n     } else {\n@@ -373,8 +375,26 @@ static int pkey_GOST_ECcp_encrypt(EVP_PKEY_CTX *pctx, unsigned char *out,\n             goto err;\n         }\n     }\n-    if ((*out_len = i2d_GOST_KEY_TRANSPORT(gkt, out ? &out : NULL)) > 0)\n+    res_len = i2d_GOST_KEY_TRANSPORT(gkt, NULL);\n+    if (res_len <= 0) {\n+        GOSTerr(GOST_F_PKEY_GOST_ECCP_ENCRYPT, ERR_R_ASN1_LIB);\n+        goto err;\n+    }\n+\n+    if (out == NULL) {\n+        *out_len = res_len;\n         ret = 1;\n+    } else {\n+        if ((size_t)res_len > *out_len) {\n+            GOSTerr(GOST_F_PKEY_GOST_ECCP_ENCRYPT, GOST_R_INVALID_BUFFER_SIZE);\n+            goto err;\n+        }\n+        if ((*out_len = i2d_GOST_KEY_TRANSPORT(gkt, &out)) > 0)\n+            ret = 1;\n+        else\n+            GOSTerr(GOST_F_PKEY_GOST_ECCP_ENCRYPT, ERR_R_ASN1_LIB);\n+    }\n+\n     OPENSSL_cleanse(shared_key, sizeof(shared_key));\n     GOST_KEY_TRANSPORT_free(gkt);\n     return ret;\n",
        "label": 1,
        "partition": "test"
    },
    {
        "commit_id": "da48e7dbb20024c198493b8724adae1b842083aa",
        "repo": "mruby/mruby",
        "msg": "fiber.c: should pack 15+ arguments in an array.NULL Pointer Dereference in GitHub repository mruby/mruby prior to 3.2.",
        "filename": "fiber.c",
        "diff": "diff --git a/mrbgems/mruby-fiber/src/fiber.c b/mrbgems/mruby-fiber/src/fiber.c\nindex 0d85bedadc..322ed36ea8 100644\n--- a/mrbgems/mruby-fiber/src/fiber.c\n+++ b/mrbgems/mruby-fiber/src/fiber.c\n@@ -208,15 +208,22 @@ fiber_switch(mrb_state *mrb, mrb_value self, mrb_int len, const mrb_value *a, mr\n     if (!c->ci->proc) {\n       mrb_raise(mrb, E_FIBER_ERROR, \"double resume (current)\");\n     }\n-    mrb_stack_extend(mrb, len+2); /* for receiver and (optional) block */\n-    b = c->stbase+1;\n-    e = b + len;\n-    while (b<e) {\n-      *b++ = *a++;\n-    }\n     if (vmexec) {\n       c->ci--;                    /* pop dummy callinfo */\n     }\n+    if (len >= 15) {\n+      mrb_stack_extend(mrb, 3);   /* for receiver, args and (optional) block */\n+      c->stbase[1] = mrb_ary_new_from_values(mrb, len, a);\n+      len = 15;\n+    }\n+    else {\n+      mrb_stack_extend(mrb, len+2); /* for receiver and (optional) block */\n+      b = c->stbase+1;\n+      e = b + len;\n+      while (b<e) {\n+        *b++ = *a++;\n+      }\n+    }\n     c->cibase->n = len;\n     value = c->stbase[0] = MRB_PROC_ENV(c->cibase->proc)->stack[0];\n   }\n",
        "label": 1,
        "partition": "test"
    },
    {
        "commit_id": "a28053045bd2e778c50ed1acaf4e52e1e34f6e34",
        "repo": "univention/univention-corporate-server",
        "msg": "Bug #48427 UDN: Forbid vulnerable GET_DN for VERSION >= 3\n\nUDL using PROTOCOL_3 must no longer use GET_DN but WAIT_DN - if it is\nstill used this is a protocol violation. UDL simply will not get an\nanswer.\n\nWhen UCRV 'notifier/protocol/version is set to 3, any old client still\nusing PROTOCOL_2 will get rejected while negotiating the protocol\nversion, so it is asserted that \"version >= network_procotol_version\".Univention Corporate Server univention-directory-notifier 12.0.1-3 and earlier is affected by: CWE-213: Intentional Information Exposure. The impact is: Loss of Confidentiality. The component is: function data_on_connection() in src/callback.c. The attack vector is: network connectivity. The fixed version is: 12.0.1-4 and later.",
        "filename": "None",
        "diff": "diff --git a/management/univention-directory-notifier/debian/changelog b/management/univention-directory-notifier/debian/changelog\nindex 80faf0fff8b..963a9b34b41 100644\n--- a/management/univention-directory-notifier/debian/changelog\n+++ b/management/univention-directory-notifier/debian/changelog\n@@ -1,3 +1,9 @@\n+univention-directory-notifier (12.0.1-11) unstable; urgency=low\n+\n+  * Bug #48427: Forbid vulnerable GET_DN for VERSION >= 3\n+\n+ -- Philipp Hahn <hahn@univention.de>  Wed, 13 Feb 2019 10:23:12 +0100\n+\n univention-directory-notifier (12.0.1-10) unstable; urgency=low\n \n   * Bug #48427: Change import limits\ndiff --git a/management/univention-directory-notifier/src/callback.c b/management/univention-directory-notifier/src/callback.c\nindex 151e50e7ce6..9c6e80401a9 100644\n--- a/management/univention-directory-notifier/src/callback.c\n+++ b/management/univention-directory-notifier/src/callback.c\n@@ -199,7 +199,7 @@ int data_on_connection(int fd, callback_remove_handler remove)\n \t\t\tp+=strlen(network_line);\n \n \n-\t\t} else if ( !strncmp(network_line, \"GET_DN \", strlen(\"GET_DN \")) && msg_id != UINT32_MAX && network_client_get_version(fd) > 0) {\n+\t\t} else if ( !strncmp(network_line, \"GET_DN \", strlen(\"GET_DN \")) && msg_id != UINT32_MAX && version > PROTOCOL_UNKNOWN && version < PROTOCOL_3) {\n \n \t\t\tunivention_debug(UV_DEBUG_TRANSFILE, UV_DEBUG_ALL, \"RECV: GET_DN\");\n \n",
        "label": 1,
        "partition": "test"
    },
    {
        "commit_id": "963c7df3e0c5266efff260d0dff757dfe03d3632",
        "repo": "gnuplot/gnuplot",
        "msg": "Better error handling for faulty font syntax\n\nA missing close-quote in an enhanced text font specification could\ncause a segfault.\nBug #2303com_line() in command.c in gnuplot 5.4 leads to an out-of-bounds-write from strncpy() that may lead to arbitrary code execution.",
        "filename": "None",
        "diff": "diff --git a/src/term.c b/src/term.c\nindex fb99a9a6f..7fd46fa04 100644\n--- a/src/term.c\n+++ b/src/term.c\n@@ -2175,7 +2175,7 @@ enhanced_recursion(\n \t\t\t    ++p;\n \t\t\tif (*p != *start_of_fontname) {\n \t\t\t    int_warn(NO_CARET, \"cannot interpret font name %s\", start_of_fontname);\n-\t\t\t    p = start_of_fontname;\n+\t\t\t    p = start_of_fontname + 1;\n \t\t\t}\n \t\t\tstart_of_fontname++;\n \t\t\tend_of_fontname = p++;\n",
        "label": 1,
        "partition": "test"
    },
    {
        "commit_id": "4647a68e364401e81dbd370728127d844f221d93",
        "repo": "mjurczak/mbed-coap",
        "msg": "Implemented measures to prevent memory leaks in sn_coap_parser_options_parse().\n\nAdded a helper uint16_t addition function with overflow detection. The function is used when calculating the extended length and option delta. The overlow detection is needed to avoid wrap-around of option number or length.\nAdditional checks in options using sn_coap_parser_options_parse_multiple_options() have been implemented to avoid overwriting of pointers pointing to previously allocated memory.Memory leaks were discovered in the CoAP library in Arm Mbed OS 5.15.3 when using the Arm mbed-coap library 5.1.5. The CoAP parser is responsible for parsing received CoAP packets. The function sn_coap_parser_options_parse() parses the CoAP option number field of all options present in the input packet. Each option number is calculated as a sum of the previous option number and a delta of the current option. The delta and the previous option number are expressed as unsigned 16-bit integers. Due to lack of overflow detection, it is possible to craft a packet that wraps the option number around and results in the same option number being processed again in a single packet. Certain options allocate memory by calling a memory allocation function. In the cases of COAP_OPTION_URI_QUERY, COAP_OPTION_URI_PATH, COAP_OPTION_LOCATION_QUERY, and COAP_OPTION_ETAG, there is no check on whether memory has already been allocated, which in conjunction with the option number integer overflow may lead to multiple assignments of allocated memory to a single pointer. This has been demonstrated to lead to memory leak by buffer orphaning. As a result, the memory is never freed.",
        "filename": "None",
        "diff": "diff --git a/source/sn_coap_parser.c b/source/sn_coap_parser.c\nindex d222de4e..a2577cd8 100644\n--- a/source/sn_coap_parser.c\n+++ b/source/sn_coap_parser.c\n@@ -260,6 +260,29 @@ static uint32_t sn_coap_parser_options_parse_uint(uint8_t **packet_data_pptr, ui\n     return value;\n }\n \n+/**\n+ * \\brief Add u16 integers with overflow detection\n+ *\n+ * \\param a            first term of addition\n+ * \\param b            second term of addion\n+ * \\param result       pointer to the result variable\n+ *\n+ * \\return Return 0 if there was no overflow, -1 otherwise\n+ */\n+static int8_t sn_coap_parser_add_u16_limit(uint16_t a, uint16_t b, uint16_t *result)\n+{\n+    uint16_t c;\n+\n+    c = a + b;\n+    if (c < a || c < b)\n+    {\n+        return -1;\n+    }\n+\n+    *result = c;\n+\n+    return 0;\n+}\n \n /**\n  * \\brief Performs data packet pointer boundary check\n@@ -397,11 +420,15 @@ static int8_t parse_ext_option(uint16_t *dst, uint8_t **packet_data_pptr, uint8_\n             return -1;\n         }\n         else {\n-                option_number += option_ext;\n-                *message_left = sn_coap_parser_move_packet_ptr(packet_data_pptr,\n-                                                               packet_data_start_ptr,\n-                                                               packet_len,\n-                                                               1);\n+            if(sn_coap_parser_add_u16_limit(option_number, option_ext, &option_number) != 0)\n+            {\n+                return -1;\n+            }\n+\n+            *message_left = sn_coap_parser_move_packet_ptr(packet_data_pptr,\n+                                                            packet_data_start_ptr,\n+                                                            packet_len,\n+                                                            1);\n         }\n     } else if (option_number == 14) {\n             int8_t read_result = sn_coap_parser_read_packet_u16(&option_number,\n@@ -414,11 +441,15 @@ static int8_t parse_ext_option(uint16_t *dst, uint8_t **packet_data_pptr, uint8_\n                 return -1;\n             }\n             else {\n-            option_number += 269;\n-            *message_left = sn_coap_parser_move_packet_ptr(packet_data_pptr,\n-                                                           packet_data_start_ptr,\n-                                                           packet_len,\n-                                                           2);\n+                if(sn_coap_parser_add_u16_limit(option_number, 269, &option_number) != 0)\n+                {\n+                    return -1;\n+                }\n+\n+                *message_left = sn_coap_parser_move_packet_ptr(packet_data_pptr,\n+                                                            packet_data_start_ptr,\n+                                                            packet_len,\n+                                                            2);\n             }\n     }\n     /* Option number 15 reserved for payload marker. This is handled as a error! */\n@@ -499,7 +530,10 @@ static int8_t sn_coap_parser_options_parse(struct coap_s *handle, uint8_t **pack\n             return -1;\n         }\n         /* Add previous option to option delta and get option number */\n-        option_number += previous_option_number;\n+        if(sn_coap_parser_add_u16_limit(option_number, previous_option_number, &option_number) != 0)\n+        {\n+            return -1;\n+        }\n \n         /* Add possible option length extension to resolve full length of the option */\n         option_parse_result = parse_ext_option(&option_len,\n@@ -577,6 +611,11 @@ static int8_t sn_coap_parser_options_parse(struct coap_s *handle, uint8_t **pack\n                 break;\n \n             case COAP_OPTION_ETAG:\n+                if (dst_coap_msg_ptr->options_list_ptr->etag_ptr)\n+                {\n+                    tr_error(\"sn_coap_parser_options_parse - COAP_OPTION_ETAG exists!\");\n+                    return -1;\n+                }\n                 /* This is managed independently because User gives this option in one character table */\n                 ret_status = sn_coap_parser_options_parse_multiple_options(handle, packet_data_pptr,\n                              message_left,\n@@ -628,6 +667,11 @@ static int8_t sn_coap_parser_options_parse(struct coap_s *handle, uint8_t **pack\n                 break;\n \n             case COAP_OPTION_LOCATION_QUERY:\n+                if (dst_coap_msg_ptr->options_list_ptr->location_query_ptr)\n+                {\n+                    tr_error(\"sn_coap_parser_options_parse - COAP_OPTION_LOCATION_QUERY exists!\");\n+                    return -1;\n+                }\n                 ret_status = sn_coap_parser_options_parse_multiple_options(handle, packet_data_pptr, message_left,\n                              &dst_coap_msg_ptr->options_list_ptr->location_query_ptr, &dst_coap_msg_ptr->options_list_ptr->location_query_len,\n                              COAP_OPTION_LOCATION_QUERY, option_len);\n@@ -639,6 +683,11 @@ static int8_t sn_coap_parser_options_parse(struct coap_s *handle, uint8_t **pack\n                 break;\n \n             case COAP_OPTION_URI_PATH:\n+                if (dst_coap_msg_ptr->uri_path_ptr)\n+                {\n+                    tr_error(\"sn_coap_parser_options_parse - COAP_OPTION_URI_PATH exists!\");\n+                    return -1;\n+                }\n                 ret_status = sn_coap_parser_options_parse_multiple_options(handle, packet_data_pptr, message_left,\n                              &dst_coap_msg_ptr->uri_path_ptr, &dst_coap_msg_ptr->uri_path_len,\n                              COAP_OPTION_URI_PATH, option_len);\n",
        "label": 0,
        "partition": "test"
    },
    {
        "commit_id": "eafc415bc6067e72577f70d6dd5acbf057ce6e6f",
        "repo": "bfabiszewski/libmobi",
        "msg": "Fix wrong boundary checks in inflections parser resulting in stack buffer over-read with corrupt inputBuffer Over-read in GitHub repository bfabiszewski/libmobi prior to 0.11. This vulnerability is capable of arbitrary code execution.",
        "filename": "index.c",
        "diff": "diff --git a/ChangeLog b/ChangeLog\nindex 8171034..b431347 100644\n--- a/ChangeLog\n+++ b/ChangeLog\n@@ -1,3 +1,4 @@\n+2022-04-27: Fix wrong boundary checks in inflections parser resulting in stack buffer over-read with corrupt input\n 2022-04-26: Fix text formatting\n 2022-04-26: Fix array boundary check when parsing inflections which could result in buffer over-read with corrupt input\n 2022-04-23: Fix formatting\ndiff --git a/src/index.c b/src/index.c\nindex 7e4f3b7..ca83675 100644\n--- a/src/index.c\n+++ b/src/index.c\n@@ -961,17 +961,13 @@ MOBI_RET mobi_decode_infl(unsigned char *decoded, int *decoded_size, const unsig\n             }\n             pos -= c - 10;\n             dir = 0;\n-            if (pos < 0 || pos > *decoded_size) {\n-                debug_print(\"Position setting failed (%s)\\n\", decoded);\n-                return MOBI_DATA_CORRUPT;\n-            }\n         }\n         else {\n             if (mod == 'i') {\n                 const unsigned char *s = decoded + pos;\n                 unsigned char *d = decoded + pos + 1;\n                 const int l = *decoded_size - pos;\n-                if (l < 0 || d + l > decoded + INDX_INFLBUF_SIZEMAX) {\n+                if (pos < 0 || l < 0 || d + l > decoded + INDX_INFLBUF_SIZEMAX) {\n                     debug_print(\"Out of buffer in %s at pos: %i\\n\", decoded, pos);\n                     return MOBI_DATA_CORRUPT;\n                 }\n@@ -984,7 +980,7 @@ MOBI_RET mobi_decode_infl(unsigned char *decoded, int *decoded_size, const unsig\n                 const unsigned char *s = decoded + pos + 1;\n                 unsigned char *d = decoded + pos;\n                 const int l = *decoded_size - pos;\n-                if (l < 0 || d + l > decoded + INDX_INFLBUF_SIZEMAX) {\n+                if (pos < 0 || l < 0 || s + l > decoded + INDX_INFLBUF_SIZEMAX) {\n                     debug_print(\"Out of buffer in %s at pos: %i\\n\", decoded, pos);\n                     return MOBI_DATA_CORRUPT;\n                 }\n",
        "label": 0,
        "partition": "test"
    },
    {
        "commit_id": "0e8e938d497260dd57be67b4966cb27a5f72376f",
        "repo": "vim/vim",
        "msg": "patch 8.2.5122: lisp indenting my run over the end of the line\n\nProblem:    Lisp indenting my run over the end of the line.\nSolution:   Check for NUL earlier.Heap-based Buffer Overflow in GitHub repository vim/vim prior to 8.2.",
        "filename": "indent.c",
        "diff": "diff --git a/src/indent.c b/src/indent.c\nindex 794fa2c3430bc..fa177bcf2c791 100644\n--- a/src/indent.c\n+++ b/src/indent.c\n@@ -2029,6 +2029,8 @@ get_lisp_indent(void)\n \t\t\t    }\n \t\t\t}\n \t\t    }\n+\t\t    if (*that == NUL)\n+\t\t\tbreak;\n \t\t}\n \t\tif (*that == '(' || *that == '[')\n \t\t    ++parencount;\ndiff --git a/src/testdir/test_indent.vim b/src/testdir/test_indent.vim\nindex be55227bd20cb..3b5b643177b4e 100644\n--- a/src/testdir/test_indent.vim\n+++ b/src/testdir/test_indent.vim\n@@ -144,6 +144,16 @@ func Test_lisp_indent()\n   close!\n endfunc\n \n+func Test_lisp_indent_quoted()\n+  \" This was going past the end of the line\n+  new\n+  setlocal lisp autoindent\n+  call setline(1, ['\"[', '='])\n+  normal Gvk=\n+\n+  bwipe!\n+endfunc\n+\n \" Test for setting the 'indentexpr' from a modeline\n func Test_modeline_indent_expr()\n   let modeline = &modeline\ndiff --git a/src/version.c b/src/version.c\nindex 89e1fa1b7aff8..5411e1c189f3e 100644\n--- a/src/version.c\n+++ b/src/version.c\n@@ -734,6 +734,8 @@ static char *(features[]) =\n \n static int included_patches[] =\n {   /* Add new patch number below this line */\n+/**/\n+    5122,\n /**/\n     5121,\n /**/\n",
        "label": 1,
        "partition": "test"
    },
    {
        "commit_id": "dc5490e2cbc8c16022a23b449b48c1bd0083f366",
        "repo": "vim/vim",
        "msg": "patch 8.2.4215: illegal memory access when copying lines in Visual mode\n\nProblem:    Illegal memory access when copying lines in Visual mode.\nSolution:   Adjust the Visual position after copying lines.Heap-based Buffer Overflow in GitHub repository vim/vim prior to 8.2.",
        "filename": "ex_cmds.c",
        "diff": "diff --git a/src/ex_cmds.c b/src/ex_cmds.c\nindex 95209985e190a..f5d93e664531e 100644\n--- a/src/ex_cmds.c\n+++ b/src/ex_cmds.c\n@@ -866,6 +866,8 @@ ex_copy(linenr_T line1, linenr_T line2, linenr_T n)\n     }\n \n     appended_lines_mark(n, count);\n+    if (VIsual_active)\n+\tcheck_pos(curbuf, &VIsual);\n \n     msgmore((long)count);\n }\ndiff --git a/src/testdir/test_visual.vim b/src/testdir/test_visual.vim\nindex 72f5388b934df..9b322fd211b38 100644\n--- a/src/testdir/test_visual.vim\n+++ b/src/testdir/test_visual.vim\n@@ -1328,5 +1328,16 @@ func Test_visual_exchange_windows()\n   bwipe!\n endfunc\n \n+\" this was leaving the end of the Visual area beyond the end of a line\n+func Test_visual_ex_copy_line()\n+  new\n+  call setline(1, [\"aaa\", \"bbbbbbbbbxbb\"])\n+  /x\n+  exe \"normal ggvjfxO\"\n+  t0\n+  normal gNU\n+  bwipe!\n+endfunc\n+\n \n \" vim: shiftwidth=2 sts=2 expandtab\ndiff --git a/src/version.c b/src/version.c\nindex 5d7eccb19109b..ddc34d864be98 100644\n--- a/src/version.c\n+++ b/src/version.c\n@@ -750,6 +750,8 @@ static char *(features[]) =\n \n static int included_patches[] =\n {   /* Add new patch number below this line */\n+/**/\n+    4215,\n /**/\n     4214,\n /**/\n",
        "label": 1,
        "partition": "test"
    },
    {
        "commit_id": "7bab09631c2a303f87a7eb7e3d69e888673b9b7e",
        "repo": "torvalds/linux",
        "msg": "xfrm: policy: check policy direction value\n\nThe 'dir' parameter in xfrm_migrate() is a user-controlled byte which is used\nas an array index. This can lead to an out-of-bound access, kernel lockup and\nDoS. Add a check for the 'dir' value.\n\nThis fixes CVE-2017-11600.\n\nReferences: https://bugzilla.redhat.com/show_bug.cgi?id=1474928\nFixes: 80c9abaabf42 (\"[XFRM]: Extension for dynamic update of endpoint address(es)\")\nCc: <stable@vger.kernel.org> # v2.6.21-rc1\nReported-by: \"bo Zhang\" <zhangbo5891001@gmail.com>\nSigned-off-by: Vladis Dronov <vdronov@redhat.com>\nSigned-off-by: Steffen Klassert <steffen.klassert@secunet.com>net/xfrm/xfrm_policy.c in the Linux kernel through 4.12.3, when CONFIG_XFRM_MIGRATE is enabled, does not ensure that the dir value of xfrm_userpolicy_id is XFRM_POLICY_MAX or less, which allows local users to cause a denial of service (out-of-bounds access) or possibly have unspecified other impact via an XFRM_MSG_MIGRATE xfrm Netlink message.",
        "filename": "xfrm_policy.c",
        "diff": "diff --git a/net/xfrm/xfrm_policy.c b/net/xfrm/xfrm_policy.c\nindex ff61d85579292d..6f5a0dad502f6e 100644\n--- a/net/xfrm/xfrm_policy.c\n+++ b/net/xfrm/xfrm_policy.c\n@@ -3308,9 +3308,15 @@ int xfrm_migrate(const struct xfrm_selector *sel, u8 dir, u8 type,\n \tstruct xfrm_state *x_new[XFRM_MAX_DEPTH];\n \tstruct xfrm_migrate *mp;\n \n+\t/* Stage 0 - sanity checks */\n \tif ((err = xfrm_migrate_check(m, num_migrate)) < 0)\n \t\tgoto out;\n \n+\tif (dir >= XFRM_POLICY_MAX) {\n+\t\terr = -EINVAL;\n+\t\tgoto out;\n+\t}\n+\n \t/* Stage 1 - find policy */\n \tif ((pol = xfrm_migrate_policy_find(sel, dir, type, net)) == NULL) {\n \t\terr = -ENOENT;\n",
        "label": 1,
        "partition": "test"
    },
    {
        "commit_id": "fd607a3439fcdd0992e5efded3c16fc79c804e34",
        "repo": "milkytracker/MilkyTracker",
        "msg": "Fix #184: Heap overflow in S3M loaderXMFile::read in XMFile.cpp in milkyplay in MilkyTracker 1.02.00 has a heap-based buffer overflow.",
        "filename": "LoaderS3M.cpp",
        "diff": "diff --git a/src/milkyplay/LoaderS3M.cpp b/src/milkyplay/LoaderS3M.cpp\nindex 5abf211c..edf0fd54 100644\n--- a/src/milkyplay/LoaderS3M.cpp\n+++ b/src/milkyplay/LoaderS3M.cpp\n@@ -340,7 +340,11 @@ mp_sint32 LoaderS3M::load(XMFileBase& f, XModule* module)\n \t\treturn MP_OUT_OF_MEMORY;\n \t\n \theader->insnum = f.readWord(); // number of instruments\n-\theader->patnum = f.readWord(); // number of patterns\t\n+\tif (header->insnum > MP_MAXINS)\n+\t\treturn MP_LOADER_FAILED;\n+\theader->patnum = f.readWord(); // number of patterns\n+\tif (header->patnum > 256)\n+\t\treturn MP_LOADER_FAILED;\n \t\n \tmp_sint32 flags = f.readWord(); // st3 flags\t\n \n",
        "label": 0,
        "partition": "test"
    },
    {
        "commit_id": "4606c28f494a750892c5c1ac7903e62dd1c6fdb5",
        "repo": "LibRaw/LibRaw",
        "msg": "0.16.1: fix for dcraw ljpeg_start() vulnerabilityInteger overflow in the ljpeg_start function in dcraw 7.00 and earlier allows remote attackers to cause a denial of service (crash) via a crafted image, which triggers a buffer overflow, related to the len variable.",
        "filename": "dcraw.c",
        "diff": "diff --git a/Changelog.rus b/Changelog.rus\nindex 4813ffe6..75be4962 100644\n--- a/Changelog.rus\n+++ b/Changelog.rus\n@@ -1,4 +1,8 @@\n-\ufeff2014-01-17 Alex Tutubalin <lexa@lexa.ru>\n+\ufeff2015-05-11 Alex Tutubalin <lexa@lexa.ru>\n+  * \u0418\u0441\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u0430 \u0443\u044f\u0437\u0432\u0438\u043c\u043e\u0441\u0442\u044c \u0432 dcraw:ljpeg_start()\n+  * LibRaw 0.16.1\n+\n+2014-01-17 Alex Tutubalin <lexa@lexa.ru>\n   * \u041f\u043e\u0434\u0434\u0435\u0440\u0436\u043a\u0430 \u043a\u0430\u043c\u0435\u0440\n     \u0414\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u044b: Fujifilm X-E2,XQ1\n     \u041e\u0431\u043d\u043e\u0432\u043b\u0435\u043d\u044b \u0446\u0432\u0435\u0442\u043e\u0432\u044b\u0435 \u0434\u0430\u043d\u043d\u044b\u0435: Nikon D4, 1 AW1/J3; Fuji X-M2\n@@ -13,7 +17,7 @@\n   * \u0418\u0441\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u044b \u043e\u0448\u0438\u0431\u043a\u0438 \u043a\u043e\u043c\u043f\u0438\u043b\u044f\u0446\u0438\u0438 \u043f\u0440\u0438 \u0441\u0431\u043e\u0440\u043a\u0435 VS2012 \u0441 \u0432\u043a\u043b\u044e\u0447\u0435\u043d\u043d\u044b\u043c\n     OpenMP\n   * \u0418\u0441\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u0430 \u043e\u043f\u0435\u0447\u0430\u0442\u043a\u0430, \u043d\u0435 \u0434\u0430\u0432\u0430\u0432\u0448\u0430\u044f \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c Demosaic Pack GPL2\n-  * LibRaw 0.16.0-Beta1\n+  * LibRaw 0.16.0\n \n 2013-11-12 Alex Tutubalin <lexa@lexa.ru>\n   * \u041f\u043e\u0434\u0434\u0435\u0440\u0436\u043a\u0430 \u043d\u043e\u0432\u044b\u0445 \u043a\u0430\u043c\u0435\u0440\ndiff --git a/Changelog.txt b/Changelog.txt\nindex 9e675fda..546e532e 100644\n--- a/Changelog.txt\n+++ b/Changelog.txt\n@@ -1,3 +1,7 @@\n+2015-05-11 Alex Tutubalin <lexa@lexa.ru>\n+  * Fix for dcraw ljpeg_start() vulnerability\n+  * LibRaw 0.16.1-Release\n+\n 2014-01-17 Alex Tutubalin <lexa@lexa.ru>\n   * Camera support:\n      Added: Fujifilm XE2, XQ1\ndiff --git a/dcraw/dcraw.c b/dcraw/dcraw.c\nindex 8ea5cd72..938cab6a 100644\n--- a/dcraw/dcraw.c\n+++ b/dcraw/dcraw.c\n@@ -841,7 +841,8 @@ struct jhead {\n \n int CLASS ljpeg_start (struct jhead *jh, int info_only)\n {\n-  int c, tag, len;\n+  int c, tag;\n+  ushort len;\n   uchar data[0x10000];\n   const uchar *dp;\n \ndiff --git a/internal/dcraw_common.cpp b/internal/dcraw_common.cpp\nindex 2dcb886f..3a3c6824 100644\n--- a/internal/dcraw_common.cpp\n+++ b/internal/dcraw_common.cpp\n@@ -21,6 +21,7 @@ it under the terms of the one of three licenses as you choose:\n    for more information\n */\n \n+#line 261 \"dcraw/dcraw.c\"\n #include <math.h>\n #define CLASS LibRaw::\n #include \"libraw/libraw_types.h\"\n@@ -29,6 +30,7 @@ it under the terms of the one of three licenses as you choose:\n #include \"libraw/libraw.h\"\n #include \"internal/defines.h\"\n #include \"internal/var_defines.h\"\n+#line 272 \"dcraw/dcraw.c\"\n int CLASS fcol (int row, int col)\n {\n   static const char filter[16][16] =\n@@ -75,6 +77,7 @@ char *my_strcasestr (char *haystack, const char *needle)\n }\n #define strcasestr my_strcasestr\n #endif\n+#line 340 \"dcraw/dcraw.c\"\n ushort CLASS sget2 (uchar *s)\n {\n   if (order == 0x4949)\t\t/* \"II\" means little-endian */\n@@ -564,10 +567,12 @@ void CLASS canon_load_raw()\n #endif\n   FORC(2) free (huff[c]);\n }\n+#line 841 \"dcraw/dcraw.c\"\n \n int CLASS ljpeg_start (struct jhead *jh, int info_only)\n {\n-  int c, tag, len;\n+  int c, tag;\n+  ushort len;\n   uchar data[0x10000];\n   const uchar *dp;\n \n@@ -1153,6 +1158,7 @@ int CLASS minolta_z2()\n     if (tail[i]) nz++;\n   return nz > 20;\n }\n+#line 1436 \"dcraw/dcraw.c\"\n void CLASS ppm_thumb()\n {\n   char *thumb;\n@@ -2976,6 +2982,7 @@ void CLASS redcine_load_raw()\n #endif\n #endif\n }\n+#line 3983 \"dcraw/dcraw.c\"\n void CLASS crop_masked_pixels()\n {\n   int row, col;\n@@ -3081,6 +3088,7 @@ void CLASS remove_zeroes()\n   RUN_CALLBACK(LIBRAW_PROGRESS_REMOVE_ZEROES,1,2);\n #endif\n }\n+#line 4254 \"dcraw/dcraw.c\"\n void CLASS gamma_curve (double pwr, double ts, int mode, int imax)\n {\n   int i;\n@@ -4790,6 +4798,7 @@ void CLASS parse_thumb_note (int base, unsigned toff, unsigned tlen)\n     fseek (ifp, save, SEEK_SET);\n   }\n }\n+#line 5968 \"dcraw/dcraw.c\"\n void CLASS parse_makernote (int base, int uptag)\n {\n   static const uchar xlat[2][256] = {\n@@ -5349,6 +5358,7 @@ void CLASS parse_kodak_ifd (int base)\n     fseek (ifp, save, SEEK_SET);\n   }\n }\n+#line 6533 \"dcraw/dcraw.c\"\n int CLASS parse_tiff_ifd (int base)\n {\n   unsigned entries, tag, type, len, plen=16, save;\n@@ -6648,6 +6658,7 @@ void CLASS parse_redcine()\n     data_offset = get4();\n   }\n }\n+#line 7936 \"dcraw/dcraw.c\"\n \n /*\n    All matrices are from Adobe DNG Converter unless otherwise noted.\n@@ -8923,6 +8934,7 @@ void CLASS identify()\n }\n \n \n+#line 10303 \"dcraw/dcraw.c\"\n void CLASS convert_to_rgb()\n {\n #ifndef LIBRAW_LIBRARY_BUILD\n@@ -9153,6 +9165,7 @@ int CLASS flip_index (int row, int col)\n   if (flip & 1) col = iwidth  - 1 - col;\n   return row * iwidth + col;\n }\n+#line 10559 \"dcraw/dcraw.c\"\n void CLASS tiff_set (ushort *ntag,\n \tushort tag, ushort type, int count, int val)\n {\ndiff --git a/internal/dcraw_fileio.cpp b/internal/dcraw_fileio.cpp\nindex f099eeea..06933de4 100644\n--- a/internal/dcraw_fileio.cpp\n+++ b/internal/dcraw_fileio.cpp\n@@ -21,7 +21,7 @@ it under the terms of the one of three licenses as you choose:\n    for more information\n */\n \n-#line 4090 \"dcraw/dcraw.c\"\n+#line 4091 \"dcraw/dcraw.c\"\n #include <math.h>\n #define CLASS LibRaw::\n #include \"libraw/libraw_types.h\"\n@@ -29,7 +29,7 @@ it under the terms of the one of three licenses as you choose:\n #include \"libraw/libraw.h\"\n #include \"internal/defines.h\"\n #include \"internal/var_defines.h\"\n-#line 4101 \"dcraw/dcraw.c\"\n+#line 4102 \"dcraw/dcraw.c\"\n /*\n    Seach from the current directory up to the root looking for\n    a \".badpixels\" file, and fix those pixels now.\n@@ -54,7 +54,7 @@ void CLASS bad_pixels (const char *cfname)\n #endif\n   if (cfname)\n     fp = fopen (cfname, \"r\");\n-#line 4151 \"dcraw/dcraw.c\"\n+#line 4152 \"dcraw/dcraw.c\"\n   if (!fp)\n       {\n #ifdef LIBRAW_LIBRARY_BUILD\n@@ -154,7 +154,7 @@ void CLASS subtract (const char *fname)\n   RUN_CALLBACK(LIBRAW_PROGRESS_DARK_FRAME,1,2);\n #endif\n }\n-#line 10213 \"dcraw/dcraw.c\"\n+#line 10214 \"dcraw/dcraw.c\"\n #ifndef NO_LCMS\n void CLASS apply_profile (const char *input, const char *output)\n {\ndiff --git a/libraw/libraw_version.h b/libraw/libraw_version.h\nindex 3594136f..030a477e 100644\n--- a/libraw/libraw_version.h\n+++ b/libraw/libraw_version.h\n@@ -25,7 +25,7 @@ it under the terms of the one of three licenses as you choose:\n \n #define LIBRAW_MAJOR_VERSION  0\n #define LIBRAW_MINOR_VERSION  16\n-#define LIBRAW_PATCH_VERSION  0\n+#define LIBRAW_PATCH_VERSION  1\n #define LIBRAW_VERSION_TAIL   Release\n \n #define LIBRAW_SHLIB_CURRENT  \t10\n",
        "label": 1,
        "partition": "test"
    },
    {
        "commit_id": "858da537bde4de9d8c92466d5a866505310bc328",
        "repo": "pcmacdon/jsish",
        "msg": "Release \"3.0.8\": Address Array alloc sizing issues from issue \"integer overflow and buffer overflow #5\".\n\nFossilOrigin-Name: 8c46a1d465b358110dcfb271721d35fe843a1b52f2fa24ccc10094eb8aaf6fe4Integer overflow vulnerability in function Jsi_ObjArraySizer in jsish before 3.0.8, allows remote attackers to execute arbitrary code.",
        "filename": "None",
        "diff": "diff --git a/md/Reference.md b/md/Reference.md\nindex f8313ea..a99d36c 100644\n--- a/md/Reference.md\n+++ b/md/Reference.md\n@@ -600,7 +600,7 @@ Otherwise waits until the sub-interp is idle, to make call and return result.</t\n <tr><td>lockTimeout</td><td><i>INT</i></td><td>Thread time-out for mutex lock acquires (milliseconds).</td><td><i></i></td></tr>\n <tr><td>logOpts</td><td><i><a href='#logOptsOptions'>options</a></i></td><td>Options for log output to add file/line/time.</td><td><i></i></td></tr>\n <tr><td>maxDepth</td><td><i>INT</i></td><td>Depth limit of recursive function calls (1000).</td><td><i></i></td></tr>\n-<tr><td>maxArrayList</td><td><i>INT</i></td><td>Maximum array convertable to list (100000).</td><td><i></i></td></tr>\n+<tr><td>maxArrayList</td><td><i>UINT</i></td><td>Maximum array convertable to list (100000).</td><td><i></i></td></tr>\n <tr><td>maxIncDepth</td><td><i>INT</i></td><td>Maximum allowed source/require nesting depth (50).</td><td><i></i></td></tr>\n <tr><td>maxInterpDepth</td><td><i>INT</i></td><td>Maximum nested subinterp create depth (10).</td><td><i></i></td></tr>\n <tr><td>maxUserObjs</td><td><i>INT</i></td><td>Maximum number of 'new' object calls, eg. File, RegExp, etc.</td><td><i></i></td></tr>\ndiff --git a/src/jsi.h b/src/jsi.h\nindex ba55da4..8a0b178 100644\n--- a/src/jsi.h\n+++ b/src/jsi.h\n@@ -4,7 +4,7 @@\n \n #define JSI_VERSION_MAJOR   3\n #define JSI_VERSION_MINOR   0\n-#define JSI_VERSION_RELEASE 7\n+#define JSI_VERSION_RELEASE 8\n \n #define JSI_VERSION (JSI_VERSION_MAJOR + ((Jsi_Number)JSI_VERSION_MINOR/100.0) + ((Jsi_Number)JSI_VERSION_RELEASE/10000.0))\n \ndiff --git a/src/jsiArray.c b/src/jsiArray.c\nindex 298ec75..64f9555 100644\n--- a/src/jsiArray.c\n+++ b/src/jsiArray.c\n@@ -267,7 +267,7 @@ static Jsi_RC jsi_ArrayFlatSub(Jsi_Interp *interp, Jsi_Obj* nobj, Jsi_Value *arr\n             rc = jsi_ArrayFlatSub(interp, nobj, t , depth-1);\n         else if (!Jsi_ValueIsUndef(interp, t))\n             Jsi_ObjArrayAdd(interp, nobj, t);\n-        if ((++n + clen)>interp->maxArrayList)\n+        if ((uint)(++n + clen)>interp->maxArrayList)\n             return Jsi_LogError(\"array size exceeded\");\n     }\n     return rc;\ndiff --git a/src/jsiCData.c b/src/jsiCData.c\nindex 4dbc91e..0bb82d9 100644\n--- a/src/jsiCData.c\n+++ b/src/jsiCData.c\n@@ -1276,8 +1276,8 @@ static Jsi_RC CDataStructDefineCmd(Jsi_Interp *interp, Jsi_Value *args, Jsi_Valu\n             sf->flags |= JSI_OPT_BITSET_ENUM;\n         }\n         if (sf->arrSize) {\n-            if (sf->arrSize>MAX_ARRAY_LIST) {\n-                rc = Jsi_LogError(\"array size too big: %d >= %d\", sf->arrSize, MAX_ARRAY_LIST);\n+            if (sf->arrSize>interp->maxArrayList) {\n+                rc = Jsi_LogError(\"array size too big: %d >= %d\", sf->arrSize, interp->maxArrayList);\n                 goto bail;\n             }\n             if (sf->bits || isEnum) {\ndiff --git a/src/jsiInt.h b/src/jsiInt.h\nindex 03fa347..87cb6eb 100644\n--- a/src/jsiInt.h\n+++ b/src/jsiInt.h\n@@ -1259,7 +1259,7 @@ struct Jsi_Interp {\n     Jsi_Value *Top_object;\n     Jsi_ScopeStrs *scopes[JSI_MAX_SCOPE];\n     int cur_scope;\n-    int maxArrayList;\n+    uint maxArrayList;\n     int delRBCnt;\n     Jsi_Func *activeFunc;  // Currently active function call.\n     Jsi_Func *prevActiveFunc;  // Prev active function call.\ndiff --git a/src/jsiInterp.c b/src/jsiInterp.c\nindex 508f62f..133a74e 100644\n--- a/src/jsiInterp.c\n+++ b/src/jsiInterp.c\n@@ -100,7 +100,7 @@ static Jsi_OptionSpec InterpOptions[] = {\n     JSI_OPT(INT,   Jsi_Interp, lockTimeout, .help=\"Thread time-out for mutex lock acquires (milliseconds)\" ),\n     JSI_OPT(CUSTOM,Jsi_Interp, logOpts,     .help=\"Options for log output to add file/line/time\", .flags=0, .custom=Jsi_Opt_SwitchSuboption, .data=jsi_InterpLogOptions),\n     JSI_OPT(INT,   Jsi_Interp, maxDepth,    .help=\"Depth limit of recursive function calls (1000)\", .flags=JSI_OPT_LOCKSAFE),\n-    JSI_OPT(INT,   Jsi_Interp, maxArrayList,.help=\"Maximum array convertable to list (100000)\", .flags=JSI_OPT_LOCKSAFE),\n+    JSI_OPT(UINT,  Jsi_Interp, maxArrayList,.help=\"Maximum array convertable to list (100000)\", .flags=JSI_OPT_LOCKSAFE),\n     JSI_OPT(INT,   Jsi_Interp, maxIncDepth, .help=\"Maximum allowed source/require nesting depth (50)\", .flags=JSI_OPT_LOCKSAFE),\n     JSI_OPT(INT,   Jsi_Interp, maxInterpDepth,.help=\"Maximum nested subinterp create depth (10)\", .flags=JSI_OPT_LOCKSAFE),\n     JSI_OPT(INT,   Jsi_Interp, maxUserObjs, .help=\"Maximum number of 'new' object calls, eg. File, RegExp, etc\", .flags=JSI_OPT_LOCKSAFE ),\n@@ -1146,6 +1146,7 @@ static Jsi_Interp* jsi_InterpNew(Jsi_Interp *parent, Jsi_Value *opts, Jsi_Interp\n     }\n     interp->maxDepth = JSI_MAX_EVAL_DEPTH;\n     interp->maxIncDepth = JSI_MAX_INCLUDE_DEPTH;\n+    interp->maxArrayList = MAX_ARRAY_LIST;\n     interp->typeWarnMax = 50;\n     interp->subOpts.dblPrec = __DBL_DECIMAL_DIG__-1;\n     interp->subOpts.prompt = \"$ \";\n@@ -1482,7 +1483,6 @@ static Jsi_Interp* jsi_InterpNew(Jsi_Interp *parent, Jsi_Value *opts, Jsi_Interp\n #endif\n     if (interp->typeCheck.all|interp->typeCheck.parse|interp->typeCheck.funcsig)\n         interp->staticFuncsTbl = Jsi_HashNew(interp, JSI_KEYS_STRING, NULL);\n-    interp->maxArrayList = MAX_ARRAY_LIST;\n     if (!jsiIntData.isInit) {\n         jsiIntData.isInit = 1;\n         jsi_InitValue(interp, 0);\ndiff --git a/src/jsiObj.c b/src/jsiObj.c\nindex eae81de..7a11f49 100644\n--- a/src/jsiObj.c\n+++ b/src/jsiObj.c\n@@ -76,7 +76,7 @@ static Jsi_RC ObjListifyCallback(Jsi_Tree *tree, Jsi_TreeEntry *hPtr, void *data\n         if (!cp || !isdigit(*cp))\n             return JSI_OK;\n         n = (int)strtol(cp, &ep, 0);\n-        if (n<0 || n >= interp->maxArrayList)\n+        if (n<0 || (uint)n >= interp->maxArrayList)\n             return JSI_OK;\n         hPtr->f.bits.isarrlist = 1;\n         if (Jsi_ObjArraySizer(interp, obj, n) <= 0) \n@@ -414,12 +414,12 @@ int Jsi_ObjDecrRefCount(Jsi_Interp *interp, Jsi_Obj *obj)  {\n \n int Jsi_ObjArraySizer(Jsi_Interp *interp, Jsi_Obj *obj, uint len)\n {\n-    int nsiz = len + 1, mod = ALLOC_MOD_SIZE;\n+    uint nsiz = len + 1, mod = ALLOC_MOD_SIZE;\n     assert(obj->isarrlist);\n     if (mod>1)\n         nsiz = nsiz + ((mod-1) - (nsiz + mod - 1)%mod);\n-    if (nsiz > MAX_ARRAY_LIST) {\n-        Jsi_LogError(\"array size too large\");\n+    if (len >= interp->maxArrayList || nsiz > interp->maxArrayList) {\n+        Jsi_LogError(\"array size too big: %u >= %u\", len, interp->maxArrayList);\n         return 0;\n     }\n     if (len >= obj->arrMaxSize) {\ndiff --git a/src/jsiValue.c b/src/jsiValue.c\nindex a9fa8a2..c520084 100644\n--- a/src/jsiValue.c\n+++ b/src/jsiValue.c\n@@ -1036,7 +1036,7 @@ Jsi_Value *jsi_ValueObjKeyAssign(Jsi_Interp *interp, Jsi_Value *target, Jsi_Valu\n     }\n     /* TODO: array[\"1\"] also extern the length of array */\n     \n-    if (arrayindex >= 0 && arrayindex < MAX_ARRAY_LIST &&\n+    if (arrayindex >= 0 && (uint)arrayindex < interp->maxArrayList &&\n         target->vt == JSI_VT_OBJECT && target->d.obj->arr) {\n         return jsi_ObjArraySetDup(interp, target->d.obj, value, arrayindex);\n     }\n@@ -1373,7 +1373,7 @@ Jsi_RC Jsi_ValueInsertArray(Jsi_Interp *interp, Jsi_Value *target, int key, Jsi_\n     Jsi_Obj *obj = target->d.obj;\n     \n     if (obj->isarrlist) {\n-        if (key >= 0 && key < interp->maxArrayList) {\n+        if (key >= 0 && (uint)key < interp->maxArrayList) {\n             Jsi_ObjArraySet(interp, obj, val, key);\n             return JSI_OK;\n         }\ndiff --git a/tools/protos.jsi b/tools/protos.jsi\nindex 76d21d1..f2c4608 100755\n--- a/tools/protos.jsi\n+++ b/tools/protos.jsi\n@@ -1,4 +1,4 @@\n-//JSI Command Prototypes: version 3.0.6\n+//JSI Command Prototypes: version 3.0.8\n throw(\"NOT EXECUTABLE: USE FILE IN GEANY EDITOR FOR CMD LINE COMPLETION + GOTO TAG\");\n \n var Array = function(cmd,args) {};\ndiff --git a/www/reference.wiki b/www/reference.wiki\nindex 2b11595..51f6cdb 100644\n--- a/www/reference.wiki\n+++ b/www/reference.wiki\n@@ -633,7 +633,7 @@ Otherwise waits until the sub-interp is idle, to make call and return result.</t\n <tr><td>lockTimeout</td><td><i>INT</i></td><td>Thread time-out for mutex lock acquires (milliseconds).</td><td><i></i></td></tr>\n <tr><td>logOpts</td><td><i><a href='#logOptsOptions'>options</a></i></td><td>Options for log output to add file/line/time.</td><td><i></i></td></tr>\n <tr><td>maxDepth</td><td><i>INT</i></td><td>Depth limit of recursive function calls (1000).</td><td><i></i></td></tr>\n-<tr><td>maxArrayList</td><td><i>INT</i></td><td>Maximum array convertable to list (100000).</td><td><i></i></td></tr>\n+<tr><td>maxArrayList</td><td><i>UINT</i></td><td>Maximum array convertable to list (100000).</td><td><i></i></td></tr>\n <tr><td>maxIncDepth</td><td><i>INT</i></td><td>Maximum allowed source/require nesting depth (50).</td><td><i></i></td></tr>\n <tr><td>maxInterpDepth</td><td><i>INT</i></td><td>Maximum nested subinterp create depth (10).</td><td><i></i></td></tr>\n <tr><td>maxUserObjs</td><td><i>INT</i></td><td>Maximum number of 'new' object calls, eg. File, RegExp, etc.</td><td><i></i></td></tr>\n",
        "label": 0,
        "partition": "test"
    },
    {
        "commit_id": "49a4cee2feef7deaf9d89e5e793a8824930284d7",
        "repo": "ilanschnell/bsdiff4",
        "msg": "apply patch from Robert Scott to fix - shifting some bounds checkingA buffer overflow in the patching routine of bsdiff4 before 1.2.0 allows an attacker to write to heap memory (beyond allocated bounds) via a crafted patch file.",
        "filename": "None",
        "diff": "diff --git a/bsdiff4/core.c b/bsdiff4/core.c\nindex 91be7f8..11b6806 100644\n--- a/bsdiff4/core.c\n+++ b/bsdiff4/core.c\n@@ -431,8 +431,7 @@ static PyObject* patch(PyObject* self, PyObject* args)\n         y = PyLong_AsLong(PyTuple_GET_ITEM(tuple, 1));\n         z = PyLong_AsLong(PyTuple_GET_ITEM(tuple, 2));\n         if (newpos + x > newDataLength ||\n-                diffPtr + x > diffBlock + diffBlockLength ||\n-                extraPtr + y > extraBlock + extraBlockLength) {\n+                diffPtr + x > diffBlock + diffBlockLength) {\n             PyMem_Free(newData);\n             PyErr_SetString(PyExc_ValueError, \"corrupt patch (overflow)\");\n             return NULL;\n@@ -444,6 +443,12 @@ static PyObject* patch(PyObject* self, PyObject* args)\n                 newData[newpos + j] += origData[oldpos + j];\n         newpos += x;\n         oldpos += x;\n+        if (newpos + y > newDataLength ||\n+                extraPtr + y > extraBlock + extraBlockLength) {\n+            PyMem_Free(newData);\n+            PyErr_SetString(PyExc_ValueError, \"corrupt patch (overflow)\");\n+            return NULL;\n+        }\n         memcpy(newData + newpos, extraPtr, y);\n         extraPtr += y;\n         newpos += y;\n",
        "label": 0,
        "partition": "test"
    },
    {
        "commit_id": "a06f9efca373e25328b1c53639a48decd0854570",
        "repo": "stnoonan/spnego-http-auth-nginx-module",
        "msg": "Check basic auth result against != NGX_OK rather than == NGX_DECLINED\n\nThis corrects the error handling case when ngx_http_auth_spnego_basic is called with a bad configuration or bad username. These cases return NGX_ERROR, which allowed basic auth to proceed.\n\nThanks to Prakapovich Pavel aka Flyguy.by for pointing this out.In the SPNEGO HTTP Authentication Module for nginx (spnego-http-auth-nginx-module) before version 1.1.1 basic Authentication can be bypassed using a malformed username. This affects users of spnego-http-auth-nginx-module that have enabled basic authentication. This is fixed in version 1.1.1 of spnego-http-auth-nginx-module. As a workaround, one may disable basic authentication.",
        "filename": "None",
        "diff": "diff --git a/ngx_http_auth_spnego_module.c b/ngx_http_auth_spnego_module.c\nindex 97c0b44..25683f2 100644\n--- a/ngx_http_auth_spnego_module.c\n+++ b/ngx_http_auth_spnego_module.c\n@@ -1043,7 +1043,7 @@ ngx_http_auth_spnego_handler(\n             /* If basic auth is enabled and basic creds are supplied\n              * attempt basic auth.  If we attempt basic auth, we do\n              * not fall through to real SPNEGO */\n-            if (NGX_DECLINED == ngx_http_auth_spnego_basic(r, ctx, alcf)) {\n+            if (NGX_OK != ngx_http_auth_spnego_basic(r, ctx, alcf)) {\n                 spnego_debug0(\"Basic auth failed\");\n                 if (NGX_ERROR == ngx_http_auth_spnego_headers_basic_only(r, ctx, alcf)) {\n                     spnego_debug0(\"Error setting headers\");\n",
        "label": 1,
        "partition": "test"
    }
]